{"auto_keywords": [{"score": 0.04827337430415872, "phrase": "proposed_approach"}, {"score": 0.04265499609391253, "phrase": "c.c._chang"}, {"score": 0.04243032195732421, "phrase": "y.c._hu"}, {"score": 0.04121469750954369, "phrase": "digital_color_images"}, {"score": 0.010612387000973441, "phrase": "image_context_analysis"}, {"score": 0.0077716872734235635, "phrase": "edge_detection_scheme"}, {"score": 0.004775466707014647, "phrase": "new_adaptive_edge_detection_approach"}, {"score": 0.004570265610324106, "phrase": "predictive_error_values"}, {"score": 0.004520351823685038, "phrase": "gap_predictor"}, {"score": 0.004446496840860133, "phrase": "experimental_results"}, {"score": 0.0043858695571251174, "phrase": "objective_performance_evaluations"}, {"score": 0.004349888963714649, "phrase": "detected_image"}, {"score": 0.004255371088912042, "phrase": "edge_detection"}, {"score": 0.004232065634114875, "phrase": "sobel"}, {"score": 0.0042088843581463125, "phrase": "canny"}, {"score": 0.0041400946070776256, "phrase": "tsai_et_al"}, {"score": 0.004094865861070259, "phrase": "tsai"}, {"score": 0.0036286201767444922, "phrase": "threshold_selection"}, {"score": 0.003102411189152985, "phrase": "detection_scheme"}, {"score": 0.0027945966402685278, "phrase": "object_contours"}, {"score": 0.0027413098418869056, "phrase": "complex_scenes"}, {"score": 0.0024154816080358336, "phrase": "extreme_importance"}, {"score": 0.0023759346019385638, "phrase": "data_hiding"}, {"score": 0.002330612108529907, "phrase": "pattern_recognition"}, {"score": 0.002254914147694574, "phrase": "prediction-based_lossless_image_compression_scheme"}, {"score": 0.002175673985064338, "phrase": "image_transmission"}, {"score": 0.002163732292308364, "phrase": "objects_recognition"}, {"score": 0.0021518560029604515, "phrase": "medical_diagnoses"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["edge detection", " predictive error value", " GAP", " image context analysis"], "paper_abstract": "A new adaptive edge detection approach based on image context analysis is presented in this paper. The proposed approach uses the information from predictive error values produced by the GAP predictor to detect edges. The experimental results indicate that both the visual evaluations and objective performance evaluations of the detected image in the proposed approach are superior to the edge detection of Sobel, Canny and the scheme presented by Tsai et al. [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343]. To meet the needs of users, the flexibility in the threshold selection in the proposed approach is the same as that of the edge detection scheme [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343]. The proposed approach, which is far more accurate than the detection scheme in [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343], can precisely locate object contours in the image, especially for complex scenes. This feature, which the edge detection scheme [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343] lacks, is of extreme importance to some applications such as data hiding, watermarking, morph, and pattern recognition. In addition, the approach can be integrated into a prediction-based lossless image compression scheme to provide both the lossless compression codes and edge maps of objects, which facilitate the image transmission and objects recognition for medical diagnoses and other applications. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "A new edge detection approach based on image context analysis", "paper_id": "WOS:000241228300005"}