{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "bayes"}, {"score": 0.004287680323820891, "phrase": "learning_machines"}, {"score": 0.0041051328120736575, "phrase": "hidden_variables"}, {"score": 0.003987755561492638, "phrase": "hierarchical_structures"}, {"score": 0.0038737214010638745, "phrase": "singular_statistical_models"}, {"score": 0.0036553070575015344, "phrase": "singular_fisher_information_matrices"}, {"score": 0.0035507457285983268, "phrase": "different_learning_performance"}, {"score": 0.0034491650585057754, "phrase": "regular_statistical_models"}, {"score": 0.002940095976373734, "phrase": "learning_coefficient"}, {"score": 0.0027341763737751467, "phrase": "analytic_equivalence_class"}, {"score": 0.002655894070657161, "phrase": "kullback_information"}, {"score": 0.0023990982005125763, "phrase": "stochastic_complexity"}, {"score": 0.0022967713922705, "phrase": "mcmc_method"}, {"score": 0.0021049977753042253, "phrase": "equivalence_class"}], "paper_keywords": [""], "paper_abstract": "A lot of learning machines which have hidden variables or hierarchical structures are singular statistical models. They have singular Fisher information matrices and different learning performance from regular statistical models. In this paper, we prove mathematically that the learning coefficient is determined by the analytic equivalence class of Kullback information, and show experimentally that the stochastic complexity by the MCMC method is also given by the equivalence class.", "paper_title": "Analytic equivalence of Bayes a posteriori distributions", "paper_id": "WOS:000241472100012"}