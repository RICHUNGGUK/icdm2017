{"auto_keywords": [{"score": 0.04550288640963527, "phrase": "computational_challenge"}, {"score": 0.03211942512231789, "phrase": "low-dimensional_data_sets"}, {"score": 0.031808082480101287, "phrase": "high-dimensional_data_sets"}, {"score": 0.00481495049065317, "phrase": "k-means_algorithm"}, {"score": 0.004719473826242326, "phrase": "cluster_analysis"}, {"score": 0.0046491050101721545, "phrase": "critical_role"}, {"score": 0.004579780586951551, "phrase": "wide_variety"}, {"score": 0.004269630481719451, "phrase": "continuously_increasing_data_volume"}, {"score": 0.0038431888954930083, "phrase": "parallelizing_k-means"}, {"score": 0.0036188435232325337, "phrase": "widely_available_graphics_processing_units"}, {"score": 0.0034940519373446335, "phrase": "existing_gpu-based_k-means_algorithms"}, {"score": 0.003407549468745519, "phrase": "data_dimensionality"}, {"score": 0.003356675879109443, "phrase": "important_factor"}, {"score": 0.0028877818105020434, "phrase": "best_use"}, {"score": 0.002858952758523772, "phrase": "gpu_computing_horsepower"}, {"score": 0.002665027876903159, "phrase": "chip_registers"}, {"score": 0.0025989960809479104, "phrase": "data_access_latency"}, {"score": 0.002496722870659199, "phrase": "novel_algorithm"}, {"score": 0.002459414063407306, "phrase": "matrix_multiplication"}, {"score": 0.002327310963701377, "phrase": "high_compute-to-memory-access_ratio"}, {"score": 0.0021693692831601745, "phrase": "best_reported_cpu-based_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Clustering", " k-Means", " GPU computing", " CUDA"], "paper_abstract": "Cluster analysis plays a critical role in a wide variety of applications; but it is now facing the computational challenge due to the continuously increasing data volume. Parallel computing is one of the most promising solutions to overcoming the computational challenge. In this paper, we target at parallelizing k-Means, which is one of the most popular clustering algorithms, by using the widely available Graphics Processing Units (GPUs). Different from existing GPU-based k-Means algorithms, we observe that data dimensionality is an important factor that should be taken into consideration when parallelizing k-Means on CPUs. In particular, we use two different strategies for low-dimensional data sets and high-dimensional data sets respectively, in order to make the best use of GPU computing horsepower. For low-dimensional data sets, we design an algorithm that exploits CPU on-chip registers to significantly decrease the data access latency. For high-dimensional data sets, we design another novel algorithm that simulates matrix multiplication and exploits CPU on-chip shared memory to achieve high compute-to-memory-access ratio. Our experimental results show that our CPU-based k-Means algorithms are three to eight times faster than the best reported CPU-based algorithms. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Speeding up k-Means algorithm by GPUs", "paper_id": "WOS:000312354000005"}