{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "simple_control_task"}, {"score": 0.0491952477301852, "phrase": "spike_response_model"}, {"score": 0.0458078008187391, "phrase": "direct_reinforcement"}, {"score": 0.004359328949187473, "phrase": "learning_algorithm"}, {"score": 0.003922204523581119, "phrase": "srm"}, {"score": 0.0037087324991876727, "phrase": "kernel_functions"}, {"score": 0.0035728978842974246, "phrase": "spike_reception"}, {"score": 0.0034634973175137486, "phrase": "membrane_potential"}, {"score": 0.0031944286166257466, "phrase": "srm_neuron"}, {"score": 0.003115908199991072, "phrase": "input_signals"}, {"score": 0.0030017207229983385, "phrase": "reinforcement_signal"}, {"score": 0.0027172101552870973, "phrase": "synaptic_weights"}, {"score": 0.002474961375646351, "phrase": "better_performance"}, {"score": 0.002384206251320424, "phrase": "obtained_results"}, {"score": 0.0022967713922705, "phrase": "classic_methods"}, {"score": 0.0022542611024997474, "phrase": "value_function_approximation"}, {"score": 0.002226357953581725, "phrase": "temporal_difference"}, {"score": 0.0021851480717840484, "phrase": "simple_control_tasks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["spiking neuron", " reinforcement learning", " spike response model"], "paper_abstract": "In this work, we propose a variation of a direct reinforcement learning algorithm, suitable for usage with spiking neurons based on the spike response model (SRM). The SRM is a biologically inspired, flexible model of spiking neuron based on kernel functions that describe the effect of spike reception and emission on the membrane potential of the neuron. In our experiments, the spikes emitted by a SRM neuron are used as input signals in a simple control task. The reinforcement signal obtained from the environment is used by the direct reinforcement learning algorithm, that modifies the synaptic weights of the neuron, adjusting the spiking firing times in order to obtain a better performance at the given problem. The obtained results are comparable to those from classic methods based on value function approximation and temporal difference, for simple control tasks. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Reinforcement learning of a simple control task using the spike response model", "paper_id": "WOS:000242602300004"}