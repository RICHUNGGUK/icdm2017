{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dictionary_learning"}, {"score": 0.004672953146379813, "phrase": "visual_tracking"}, {"score": 0.004645057834614705, "phrase": "multiple_human_speakers"}, {"score": 0.004603525341738782, "phrase": "office_environment"}, {"score": 0.004508048086020253, "phrase": "novel_solutions"}, {"score": 0.004284302478991387, "phrase": "changing_appearance"}, {"score": 0.004182871028054003, "phrase": "different_lighting_conditions"}, {"score": 0.004157889052612049, "phrase": "camera_resolutions"}, {"score": 0.00407161650109722, "phrase": "full_or_partial_occlusions"}, {"score": 0.0037104876694493815, "phrase": "e._g."}, {"score": 0.003688316529071842, "phrase": "limited_camera_views"}, {"score": 0.0036225919379274875, "phrase": "new_algorithms"}, {"score": 0.003600944099419042, "phrase": "appearance_modeling"}, {"score": 0.0035687137873965684, "phrase": "moving_speakers"}, {"score": 0.0034633412134999425, "phrase": "off-line_training_process"}, {"score": 0.0034220655476652683, "phrase": "tracking_phase"}, {"score": 0.003321008590273796, "phrase": "image_patches"}, {"score": 0.0032814236411444022, "phrase": "learned_dictionaries"}, {"score": 0.0032229262928681304, "phrase": "likelihood_functions"}, {"score": 0.0030997236644076196, "phrase": "measurement_step"}, {"score": 0.003071965703296204, "phrase": "classical_particle_filtering"}, {"score": 0.0029901699209266435, "phrase": "computational_efficiency"}, {"score": 0.0029280552768499056, "phrase": "soft_voting_technique"}, {"score": 0.0029018301277718415, "phrase": "approximate_locality-constrained_soft_assignment"}, {"score": 0.0028076592725295646, "phrase": "dictionary_atoms"}, {"score": 0.0027575842698911173, "phrase": "histogram_encoding"}, {"score": 0.0027165361453855095, "phrase": "adaptive_identity_model"}, {"score": 0.0026760974046034854, "phrase": "multiple_speakers"}, {"score": 0.0025354258731826148, "phrase": "adaptation_rate"}, {"score": 0.0025127084501976745, "phrase": "spatial_relationship"}, {"score": 0.002445767214680791, "phrase": "automatic_initialization"}, {"score": 0.00242385118139873, "phrase": "visual_trackers"}, {"score": 0.0023949342544966916, "phrase": "audio_information"}, {"score": 0.0023033100935570755, "phrase": "microphone_array_recordings"}, {"score": 0.0022019274077124795, "phrase": "search_space"}, {"score": 0.0021821915946356168, "phrase": "speaker's_faces"}, {"score": 0.00216263228969761, "phrase": "proposed_system"}], "paper_keywords": ["Visual Tracking", " Particle Filters", " Dictionary Learning"], "paper_abstract": "We investigate the problem of visual tracking of multiple human speakers in an office environment. In particular, we propose novel solutions to the following challenges: (1) robust and computationally efficient modeling and classification of the changing appearance of the speakers in a variety of different lighting conditions and camera resolutions; (2) dealing with full or partial occlusions when multiple speakers cross or come into very close proximity; (3) automatic initialization of the trackers, or re-initialization when the trackers have lost lock caused by e. g. the limited camera views. First, we develop new algorithms for appearance modeling of the moving speakers based on dictionary learning (DL), using an off-line training process. In the tracking phase, the histograms (coding coefficients) of the image patches derived from the learned dictionaries are used to generate the likelihood functions based on Support Vector Machine (SVM) classification. This likelihood function is then used in the measurement step of the classical particle filtering (PF) algorithm. To improve the computational efficiency of generating the histograms, a soft voting technique based on approximate Locality-constrained Soft Assignment (LcSA) is proposed to reduce the number of dictionary atoms (codewords) used for histogram encoding. Second, an adaptive identity model is proposed to track multiple speakers whilst dealing with occlusions. This model is updated online using Maximum a Posteriori (MAP) adaptation, where we control the adaptation rate using the spatial relationship between the subjects. Third, to enable automatic initialization of the visual trackers, we exploit audio information, the Direction of Arrival (DOA) angle, derived from microphone array recordings. Such information provides, a priori, the number of speakers and constrains the search space for the speaker's faces. The proposed system is tested on a number of sequences from three publicly available and challenging data corpora (AV16.3, EPFL pedestrian data set and CLEAR) with up to five moving subjects.", "paper_title": "Robust Multi-Speaker Tracking via Dictionary Learning and Identity Modeling", "paper_id": "WOS:000333111500024"}