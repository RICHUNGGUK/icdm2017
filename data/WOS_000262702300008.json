{"auto_keywords": [{"score": 0.035861129654360134, "phrase": "amom"}, {"score": 0.015719711310935386, "phrase": "multiple_object_tracking"}, {"score": 0.0046831243531799205, "phrase": "mot"}, {"score": 0.004523272849033429, "phrase": "conventional_well-studied_single_object_tracking"}, {"score": 0.004460913065100164, "phrase": "sot"}, {"score": 0.004278807087784626, "phrase": "severe_expansion"}, {"score": 0.004219774794569897, "phrase": "configuration_space"}, {"score": 0.004161553532799662, "phrase": "high_complexity"}, {"score": 0.004104132253183181, "phrase": "motion_conditions"}, {"score": 0.0040194764936614565, "phrase": "visual_ambiguities"}, {"score": 0.003964007795174772, "phrase": "nearby_targets"}, {"score": 0.0038286491141253584, "phrase": "visual_ambiguity_problem"}, {"score": 0.003749654338704576, "phrase": "central_challenge"}, {"score": 0.003449585750738867, "phrase": "adaptive_mixture_observation_models"}, {"score": 0.003308649946463136, "phrase": "mixture_tracker"}, {"score": 0.0031955979242589494, "phrase": "particle_filter_framework"}, {"score": 0.0030650070965891653, "phrase": "extracted_multiple_features"}, {"score": 0.0030226700832113942, "phrase": "appearance_description"}, {"score": 0.002879029968532794, "phrase": "ambiguity_prone_objects"}, {"score": 0.002685558057339722, "phrase": "online_entropy-based_feature_selection_techniques"}, {"score": 0.0024533019565858073, "phrase": "conventional_mixture_tracker"}, {"score": 0.0024026156525362684, "phrase": "object_occlusions"}, {"score": 0.0022567398334877847, "phrase": "high_efficiency"}, {"score": 0.0022101055924375725, "phrase": "final_experiments"}, {"score": 0.0021795515361987144, "phrase": "significant_improvement"}, {"score": 0.002149418970824546, "phrase": "mot_scenarios"}], "paper_keywords": ["motion tracking", " mixture tracker", " particle filter", " online feature selection"], "paper_abstract": "Multiple object tracking (MOT) poses many difficulties to conventional well-studied single object tracking (SOT) algorithms, such as severe expansion of configuration space, high complexity of motion conditions, and visual ambiguities among nearby targets, among which the visual ambiguity problem is the central challenge. In this paper, we address this problem by embedding adaptive mixture observation models (AMOM) into a mixture tracker which is implemented in Particle Filter framework. In AMOM, the extracted multiple features for appearance description are combined according to their discriminative power between ambiguity prone objects, where the discriminability of features are evaluated by online entropy-based feature selection techniques. The induction of AMOM can help to surmount the incapability of conventional mixture tracker in handling object occlusions, and meanwhile retain its merits of flexibility and high efficiency. The final experiments show significant improvement in MOT scenarios compared with other methods.", "paper_title": "Adaptive mixture observation models for multiple object tracking", "paper_id": "WOS:000262702300008"}