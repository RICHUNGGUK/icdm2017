{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "data_representation"}, {"score": 0.0047273577269638725, "phrase": "informative_data_representation"}, {"score": 0.004662705558154439, "phrase": "vital_importance"}, {"score": 0.004620093797504386, "phrase": "multidisciplinary_applications"}, {"score": 0.004473982381245469, "phrase": "collaborative_filtering"}, {"score": 0.004352411290383643, "phrase": "nonnegative_matrix_factorization"}, {"score": 0.004312710767969128, "phrase": "nmf"}, {"score": 0.004157058883925715, "phrase": "well-structured_data_representation"}, {"score": 0.004081385289516914, "phrase": "geometrical_structure"}, {"score": 0.003916098498242888, "phrase": "previous_nmf_variants"}, {"score": 0.0038624981944755813, "phrase": "existing_works"}, {"score": 0.0037921662574137535, "phrase": "discriminant_information"}, {"score": 0.0037231102027070724, "phrase": "between-class_scatter"}, {"score": 0.0036721416244816455, "phrase": "total_scatter"}, {"score": 0.003459191419478298, "phrase": "novel_approach"}, {"score": 0.003427540517249369, "phrase": "discriminative_orthogonal_nonnegative"}, {"score": 0.0032436052954996097, "phrase": "global_discriminant_information"}, {"score": 0.0031991799574455555, "phrase": "manifold_discriminant_learning"}, {"score": 0.003083655376444887, "phrase": "discriminant_structure"}, {"score": 0.0029722900280316216, "phrase": "scaled_indicator_matrix"}, {"score": 0.0028914057633212045, "phrase": "orthogonality_condition"}, {"score": 0.002799810685137358, "phrase": "orthogonality_constraints"}, {"score": 0.0027614468443073028, "phrase": "objective_function"}, {"score": 0.002405496949144104, "phrase": "optimization_framework"}, {"score": 0.0023725232579531273, "phrase": "convergence_proof"}, {"score": 0.0023400004981080818, "phrase": "updating_rules"}, {"score": 0.002318566141177149, "phrase": "extensive_comparisons"}, {"score": 0.002163930783583212, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Nonnegative matrix factorization", " Flexible orthogonality", " Manifold discriminant learning", " Data representation"], "paper_abstract": "Learning an informative data representation is of vital importance in multidisciplinary applications, e.g., face analysis, document clustering and collaborative filtering. As a very useful tool, Nonnegative matrix factorization (NMF) is often employed to learn a well-structured data representation. While the geometrical structure of the data has been studied in some previous NMF variants, the existing works typically neglect the discriminant information revealed by the between-class scatter and the total scatter of the data. To address this issue, we present a novel approach named Discriminative Orthogonal Nonnegative matrix factorization (DON), which preserves both the local manifold structure and the global discriminant information simultaneously through manifold discriminant learning. In particular, to learn the discriminant structure for the data representation, we introduce the scaled indicator matrix, which naturally satisfies the orthogonality condition. Thus, we impose the orthogonality constraints on the objective function. However, too heavy constraints will lead to a very sparse data representation that is unexpected in reality. So we further make this orthogonality flexible. In addition, we provide the optimization framework with the convergence proof of the updating rules. Extensive comparisons over several state-of-the-art approaches demonstrate the efficacy of the proposed method. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Discriminative Orthogonal Nonnegative matrix factorization with flexibility for data representation", "paper_id": "WOS:000330158700031"}