{"auto_keywords": [{"score": 0.04833320368251523, "phrase": "time-series_data"}, {"score": 0.00481495049065317, "phrase": "interactive_sonifications"}, {"score": 0.004554082077300675, "phrase": "multi-touch_computing"}, {"score": 0.004347473906950474, "phrase": "interaction_design"}, {"score": 0.004267468074128779, "phrase": "interactive_sonification"}, {"score": 0.004036141321779216, "phrase": "multi-touch_contexts"}, {"score": 0.003852939975815287, "phrase": "data_analysis"}, {"score": 0.0033515736929172644, "phrase": "navigation_issues"}, {"score": 0.0025121156016001886, "phrase": "gestural_interaction"}, {"score": 0.002331909406363425, "phrase": "user_interface"}], "paper_keywords": ["Interaction", " Sonification", " Tabletop", " Data analysis"], "paper_abstract": "This paper discusses interaction design for interactive sonification and visualisation of data in multi-touch contexts. Interaction design for data analysis is becoming increasingly important as data becomes more openly available. We discuss how navigation issues such as zooming, selection, arrangement and playback of data relate to both the auditory and visual modality in different ways, and how they may be linked through the modality of touch and gestural interaction. For this purpose we introduce a user interface for exploring and interacting with representations of time-series data simultaneously in both the visual and auditory modalities.", "paper_title": "Navigation of interactive sonifications and visualisations of time-series data using multi-touch computing", "paper_id": "WOS:000309998300003"}