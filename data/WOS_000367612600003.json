{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "evaluation_panels"}, {"score": 0.004747714939490445, "phrase": "research_interests"}, {"score": 0.004697902218671618, "phrase": "research_groups"}, {"score": 0.004648609688625397, "phrase": "quantitative_approach"}, {"score": 0.004567596860086148, "phrase": "discipline-specific_research_evaluation_exercises"}, {"score": 0.004378854464130883, "phrase": "expert_panels"}, {"score": 0.0040957690050613185, "phrase": "expert_panel"}, {"score": 0.00395417485449239, "phrase": "bibliometric_approaches"}, {"score": 0.003621160116056119, "phrase": "test_case"}, {"score": 0.0035330290755534234, "phrase": "overlay_mapping"}, {"score": 0.003495915995048885, "phrase": "global_map"}, {"score": 0.0032013710938940424, "phrase": "entity's_barycenter"}, {"score": 0.0030689098754563982, "phrase": "similarity_matrix"}, {"score": 0.00304737045343781, "phrase": "subject_categories"}, {"score": 0.0028301085867789076, "phrase": "n-dimensional_method"}, {"score": 0.002770920590799572, "phrase": "kamada-kawai"}, {"score": 0.0027417992938343952, "phrase": "vos"}, {"score": 0.002555247330102505, "phrase": "expertise_overlap"}, {"score": 0.002449454693767392, "phrase": "panel's_and_the_groups'_publications"}, {"score": 0.0023897719795915, "phrase": "physics_departments"}, {"score": 0.002234988641498543, "phrase": "chemistry_panel"}, {"score": 0.0021652024032375833, "phrase": "physics_panel"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Research evaluation", " Expert panel", " Barycenter", " Overlay map", " Matching research expertise", " Similarity matrix"], "paper_abstract": "Discipline-specific research evaluation exercises are typically carried out by panels of peers, known as expert panels. To the best of our knowledge, no methods are available to measure overlap in expertise between an expert panel and the units under evaluation. This paper explores bibliometric approaches to determine this overlap, using two research evaluations of the departments of Chemistry (2009) and Physics (2010) of the University of Antwerp as a test case. We explore the usefulness of overlay mapping on a global map of science (with Web of Science subject categories) to gauge overlap of expertise and introduce a set of methods to determine an entity's barycenter according to its publication output. Barycenters can be calculated starting from a similarity matrix of subject categories (N dimensions) or from a visualization thereof (2 dimensions). We compare the results of the N-dimensional method with those of two 2-dimensional ones (Kamada-Kawai maps and VOS maps) and find that they yield very similar results. The distance between barycenters is used as an indicator of expertise overlap. The results reveal that there is some discrepancy between the panel's and the groups' publications in both the Chemistry and the Physics departments. The panels were not as diverse as the groups that were assessed. The match between the Chemistry panel and the Department was better than that between the Physics panel and the Department. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Is the expertise of evaluation panels congruent with the research interests of the research groups: A quantitative approach based on barycenters", "paper_id": "WOS:000367612600003"}