{"auto_keywords": [{"score": 0.04881990207677595, "phrase": "visual_models"}, {"score": 0.00481495049065317, "phrase": "automatic_image_annotation"}, {"score": 0.004763895422211728, "phrase": "sparse_model_coding"}, {"score": 0.004613940521007727, "phrase": "important_way"}, {"score": 0.004540734419151103, "phrase": "visual_concepts"}, {"score": 0.0042820680211904235, "phrase": "visual_diversity"}, {"score": 0.003952828685048176, "phrase": "visual_relatedness"}, {"score": 0.0036488111139918135, "phrase": "novel_annotation_method"}, {"score": 0.003571751184289622, "phrase": "visual_relatedness_information"}, {"score": 0.0035338315037521627, "phrase": "different_concepts"}, {"score": 0.0034963129868796033, "phrase": "collaborative_visual_modeling"}, {"score": 0.003314591878914152, "phrase": "convex_combination"}, {"score": 0.0031422859551159506, "phrase": "sparsity_nature"}, {"score": 0.0030923570058383355, "phrase": "high_dimensional_model_reconstruction_space"}, {"score": 0.002947266048104005, "phrase": "sparse_reconstruction_coefficients"}, {"score": 0.0026914710445743693, "phrase": "efficient_strategy"}, {"score": 0.002592693161475495, "phrase": "sparse_model_reconstruction_problem"}, {"score": 0.002470987929071079, "phrase": "first_effort"}, {"score": 0.0023549822490693327, "phrase": "proposed_method"}, {"score": 0.00232995025271599, "phrase": "general_significance"}, {"score": 0.0022928991183989115, "phrase": "experimental_results"}, {"score": 0.0022685255265595624, "phrase": "benchmark_corel_dataset"}, {"score": 0.0022444104439449737, "phrase": "flickr_dataset"}, {"score": 0.0021735890994119757, "phrase": "proposed_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Automatic image annotation", " Visual relatedness", " Sparse model reconstruction"], "paper_abstract": "Building visual models provides an important way to detect visual concepts from images. However, due to the problems of visual diversity and uncertainty, the estimation based on these models is not satisfactory. The visual relatedness among visual models is ignored for most previous methods. In this paper, we propose a novel annotation method which exploits the visual relatedness information among different concepts by collaborative visual modeling. We propose to approximate a given visual model as a convex combination of other reference models. l(1)-penalized regularization is used to exploit the sparsity nature underlying the high dimensional model reconstruction space. The relatedness is well represented in the sparse reconstruction coefficients and used to enhance the discriminativeness and robustness of the visual models. We further provide an efficient strategy to learn the coefficients by solving sparse model reconstruction problem. As we know, it is the first effort to deal with this problem. So the proposed method has general significance. The experimental results on benchmark Corel dataset and Flickr dataset demonstrate the effectiveness of the proposed methods. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Collaborative visual modeling for automatic image annotation via sparse model coding", "paper_id": "WOS:000307152800004"}