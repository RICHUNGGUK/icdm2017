{"auto_keywords": [{"score": 0.036061824286892266, "phrase": "hlnlc"}, {"score": 0.011863523543075257, "phrase": "first_stage"}, {"score": 0.007661877313869234, "phrase": "computer-aided_diagnosis"}, {"score": 0.006621372724282572, "phrase": "scalar_variable"}, {"score": 0.005887683839267761, "phrase": "optimal_linear_function"}, {"score": 0.00481495049065317, "phrase": "two-class_classification"}, {"score": 0.004763983897656182, "phrase": "algorithm"}, {"score": 0.004692227830462433, "phrase": "classifier_design"}, {"score": 0.0043299856054821355, "phrase": "limited_training_data"}, {"score": 0.004135635566256163, "phrase": "simple_structure"}, {"score": 0.003927358142506799, "phrase": "novel_two-class_classifier"}, {"score": 0.0037295306308856887, "phrase": "input_features"}, {"score": 0.0035213462189102713, "phrase": "decision_variable"}, {"score": 0.003372844338742438, "phrase": "feature_data"}, {"score": 0.003353521531649663, "phrase": "normal_distributions"}, {"score": 0.003296212583539166, "phrase": "commonly_used_fisher's_linear_discriminant_function"}, {"score": 0.003193669607059425, "phrase": "hlnlc."}, {"score": 0.003157174936641705, "phrase": "optimization_problem"}, {"score": 0.0029467742734417255, "phrase": "receiver_operating_characteristic"}, {"score": 0.00292989371977162, "phrase": "roc"}, {"score": 0.0028715299874549245, "phrase": "practical_applications"}, {"score": 0.0028305586112921583, "phrase": "robust_implementation"}, {"score": 0.0027741761880779535, "phrase": "loose_assumption"}, {"score": 0.0027503564589458837, "phrase": "two-class_feature_data"}, {"score": 0.0026267205286767577, "phrase": "linear_discriminant_analysis"}, {"score": 0.0025892330566358503, "phrase": "quadratic_discriminant_analysis"}, {"score": 0.0024800064654993048, "phrase": "lda"}, {"score": 0.002444544487772349, "phrase": "qda._simulation_studies"}, {"score": 0.0023480892503414596, "phrase": "classifier_complexity"}, {"score": 0.0023145690608400425, "phrase": "finite_number"}, {"score": 0.002301295044886946, "phrase": "training_samples"}, {"score": 0.0022296340517805125, "phrase": "ideal_observer"}, {"score": 0.0021049977753042253, "phrase": "ultrasound_images"}], "paper_keywords": ["Computer-aided diagnosis (CAD)", " hybrid linear/nonlinear classifier", " linear classifier", " linear discriminant analysis", " receiver operating characteristic (ROC) analysis"], "paper_abstract": "Classifier design for a given classification task needs to take into consideration both the complexity of the classifier and the size of the dataset that is available for training the classifier. With limited training data, as often is the situation in computer-aided diagnosis of medical images, a classifier with simple structure (e.g., a linear classifier) is more robust and therefore preferred. We propose a novel two-class classifier, which we call a hybrid linear/nonlinear classifier (HLNLC), that involves two stages: the input features are linearly combined to form a scalar variable in the first stage and then the likelihood ratio of the scalar variable is used as the decision variable for classification. We first develop the theory of HLNLC by assuming that the feature data follow normal distributions. We show that the commonly used Fisher's linear discriminant function is generally not the optimal linear function in the first stage of the HLNLC. We formulate an optimization problem to solve for the optimal linear function in the first stage of the HLNLC, i.e., the linear function that maximizes the area under the receiver operating characteristic (ROC) curve of the HLNLC. For practical applications, we propose a robust implementation of the HLNLC by making a loose assumption that the two-class feature data arise from a pair of latent (rather than explicit) multivariate normal distributions. The novel hybrid classifier fills a gap between linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA) in the sense that both its theoretical performance and its complexity lie between those of the LDA and those of the QDA. Simulation studies show that the hybrid linear/nonlinear classifier performs better than LDA without increasing the classifier complexity accordingly. With a finite number of training samples, the HLNLC can perform better than that of the ideal observer due to its simplicity. Finally, we demonstrate the application of the HLNLC in computer-aided diagnosis of breast lesions in ultrasound images.", "paper_title": "A Novel Hybrid Linear/Nonlinear Classifier for Two-Class Classification: Theory, Algorithm, and Applications", "paper_id": "WOS:000274211700017"}