{"auto_keywords": [{"score": 0.03604976072922867, "phrase": "scalce"}, {"score": 0.034280582196135646, "phrase": "compression_rate"}, {"score": 0.0263410151243231, "phrase": "quality_scores"}, {"score": 0.014900867126229749, "phrase": "data_management"}, {"score": 0.008396194043036388, "phrase": "running_time"}, {"score": 0.008041964044377485, "phrase": "read_names"}, {"score": 0.00481495049065317, "phrase": "sequence_compression_algorithms"}, {"score": 0.0047941691087656, "phrase": "locally_consistent_encoding"}, {"score": 0.0046612490104673355, "phrase": "unprecedented_amounts"}, {"score": 0.004581281865088399, "phrase": "computational_infrastructure"}, {"score": 0.004492950096237056, "phrase": "major_logistical_obstacles"}, {"score": 0.004444611631621345, "phrase": "new_platforms"}, {"score": 0.004396790930873782, "phrase": "large_investment"}, {"score": 0.004274843822340666, "phrase": "ncbi"}, {"score": 0.0042014749492374995, "phrase": "sequence_data"}, {"score": 0.004102639724186862, "phrase": "general_purpose_algorithms"}, {"score": 0.003962998498942111, "phrase": "hts_platforms"}, {"score": 0.0038613835226952117, "phrase": "specific_nature"}, {"score": 0.0038447018470115146, "phrase": "genomic_sequence_data"}, {"score": 0.003770518293865006, "phrase": "fast_and_efficient_compression_algorithms"}, {"score": 0.003738007202508549, "phrase": "hts_data"}, {"score": 0.0035333872049703187, "phrase": "additional_capabilities"}, {"score": 0.003510507340837656, "phrase": "random_access"}, {"score": 0.0034576934978960703, "phrase": "efficient_sequence_similarity_search"}, {"score": 0.0033544295486106867, "phrase": "locally_consistent_parsing_technique"}, {"score": 0.003261295948815592, "phrase": "higher_compression_speed"}, {"score": 0.0032122192818652114, "phrase": "compression_algorithm"}, {"score": 0.003163878786694538, "phrase": "reference_genome"}, {"score": 0.002945577363013198, "phrase": "scalce_reordered_reads"}, {"score": 0.0029328404397836847, "phrase": "gzip_running_time"}, {"score": 0.0028699748445157975, "phrase": "standard_pc"}, {"score": 0.0028513785049061767, "phrase": "single_core"}, {"score": 0.0028145455182562807, "phrase": "even_the_running_time"}, {"score": 0.0027010090486418513, "phrase": "recently_published_beetl"}, {"score": 0.002631667162614833, "phrase": "lexicographic_order"}, {"score": 0.0023056996845692355, "phrase": "reordering_scalce"}, {"score": 0.0022464835515931592, "phrase": "gzip_compression"}, {"score": 0.002231918154290298, "phrase": "unordered_fastq_files"}, {"score": 0.0021511430180912164, "phrase": "arithmetic_encoding"}], "paper_keywords": [""], "paper_abstract": "Motivation: The high throughput sequencing (HTS) platforms generate unprecedented amounts of data that introduce challenges for the computational infrastructure. Data management, storage and analysis have become major logistical obstacles for those adopting the new platforms. The requirement for large investment for this purpose almost signalled the end of the Sequence Read Archive hosted at the National Center for Biotechnology Information (NCBI), which holds most of the sequence data generated world wide. Currently, most HTS data are compressed through general purpose algorithms such as gzip. These algorithms are not designed for compressing data generated by the HTS platforms; for example, they do not take advantage of the specific nature of genomic sequence data, that is, limited alphabet size and high similarity among reads. Fast and efficient compression algorithms designed specifically for HTS data should be able to address some of the issues in data management, storage and communication. Such algorithms would also help with analysis provided they offer additional capabilities such as random access to any read and indexing for efficient sequence similarity search. Here we present SCALCE, a 'boosting' scheme based on Locally Consistent Parsing technique, which reorganizes the reads in a way that results in a higher compression speed and compression rate, independent of the compression algorithm in use and without using a reference genome. Results: Our tests indicate that SCALCE can improve the compression rate achieved through gzip by a factor of 4.19-when the goal is to compress the reads alone. In fact, on SCALCE reordered reads, gzip running time can improve by a factor of 15.06 on a standard PC with a single core and 6 GB memory. Interestingly even the running time of SCALCE + gzip improves that of gzip alone by a factor of 2.09. When compared with the recently published BEETL, which aims to sort the (inverted) reads in lexicographic order for improving bzip2, SCALCE+gzip provides up to 2.01 times better compression while improving the running time by a factor of 5.17. SCALCE also provides the option to compress the quality scores as well as the read names, in addition to the reads themselves. This is achieved by compressing the quality scores through order-3 Arithmetic Coding (AC) and the read names through gzip through the reordering SCALCE provides on the reads. This way, in comparison with gzip compression of the unordered FASTQ files (including reads, read names and quality scores), SCALCE (together with gzip and arithmetic encoding) can provide up to 3.34 improvement in the compression rate and 1.26 improvement in running time.", "paper_title": "SCALCE: boosting sequence compression algorithms using locally consistent encoding", "paper_id": "WOS:000311902700006"}