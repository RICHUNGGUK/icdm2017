{"auto_keywords": [{"score": 0.04455442320959089, "phrase": "cpu_time"}, {"score": 0.03764052237931414, "phrase": "high_approximation_level"}, {"score": 0.00481495049065317, "phrase": "data_streams"}, {"score": 0.004775918707955445, "phrase": "memory_constraints"}, {"score": 0.004493045859210086, "phrase": "high-dimensional_and_high_speed_data_streams"}, {"score": 0.004209679094023478, "phrase": "high_speed_data_streams"}, {"score": 0.004091370602573054, "phrase": "high_accuracy"}, {"score": 0.004058180509184539, "phrase": "small_memory"}, {"score": 0.0038962096720793443, "phrase": "existing_algorithms"}, {"score": 0.0038645966233348933, "phrase": "similar_approximation_behaviors"}, {"score": 0.0037406791638601206, "phrase": "noticeably_different_worst_case_theoretical_guarantees"}, {"score": 0.0035332741328861776, "phrase": "smallest_possible_memory"}, {"score": 0.0034761488481944657, "phrase": "rather_complex_techniques"}, {"score": 0.003378385493203297, "phrase": "time_dimension"}, {"score": 0.003310236836421397, "phrase": "existing_off-line_clustering_algorithms"}, {"score": 0.0031910037920846817, "phrase": "optimal_clustering_result"}, {"score": 0.0031650944584992726, "phrase": "data_segments"}, {"score": 0.003126623133221065, "phrase": "data_stream"}, {"score": 0.0029291801502381513, "phrase": "approximation_level"}, {"score": 0.0028351712509358997, "phrase": "new_grid-based_approach"}, {"score": 0.0027893011631269873, "phrase": "entire_data"}, {"score": 0.0025918745925152423, "phrase": "novel_concept"}, {"score": 0.0024680632991561074, "phrase": "data_stream_context"}, {"score": 0.0024182330686905256, "phrase": "density-based_heuristic_and_frequent_item_mining_techniques"}, {"score": 0.0023121112251855667, "phrase": "existing_clustering"}, {"score": 0.0021659920594094407, "phrase": "extensive_experimental_studies"}], "paper_keywords": ["data streams", " k-medians", " cluster", " data mining"], "paper_abstract": "In this paper, we study the problem of efficiently computing k-medians over high-dimensional and high speed data streams. The focus of this paper is on the issue of minimizing CPU time to handle high speed data streams on top of the requirements of high accuracy and small memory. Our work is motivated by the following observation: the existing algorithms have similar approximation behaviors in practice, even though they make noticeably different worst case theoretical guarantees. The underlying reason is that in order to achieve high approximation level with the smallest possible memory, they need rather complex techniques to maintain a sketch, along time dimension, by using some existing off-line clustering algorithms. Those clustering algorithms cannot guarantee the optimal clustering result over data segments in a data stream but accumulate errors over segments, which makes most algorithms behave the same in terms of approximation level, in practice. We propose a new grid-based approach which divides the entire data set into cells (not along time dimension). We can achieve high approximation level based on a novel concept called (1 - epsilon)-dominant. We further extend the method to the data stream context, by leveraging a density-based heuristic and frequent item mining techniques over data streams. We only need to apply an existing clustering once to computing k-medians, on demand, which reduces CPU time significantly. We conducted extensive experimental studies, and show that our approaches outperform other well-known approaches.", "paper_title": "Efficient computation of k-medians over data streams under memory constraints", "paper_id": "WOS:000236292700022"}