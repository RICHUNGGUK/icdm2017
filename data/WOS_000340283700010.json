{"auto_keywords": [{"score": 0.029295667226764133, "phrase": "system_scheduler"}, {"score": 0.02739849325518926, "phrase": "resource_use"}, {"score": 0.00481495049065317, "phrase": "hpc_systems"}, {"score": 0.004768012159430855, "phrase": "important_role"}, {"score": 0.004752467467173928, "phrase": "high-performance_computing"}, {"score": 0.004614815588012902, "phrase": "engineering_research"}, {"score": 0.004540064673326908, "phrase": "high_cost"}, {"score": 0.004408537640504066, "phrase": "short_life"}, {"score": 0.004211441113293312, "phrase": "adequate_analytical_data"}, {"score": 0.00411620854480626, "phrase": "systems_management"}, {"score": 0.0040893952934649485, "phrase": "different_granularities_-_job"}, {"score": 0.003906510969606783, "phrase": "comprehensive_job"}, {"score": 0.0038431888954930083, "phrase": "resource_use_measurement"}, {"score": 0.0036832960694422765, "phrase": "system-wide_collection"}, {"score": 0.0036592924763139915, "phrase": "comprehensive_resource_use"}, {"score": 0.0035648266669315943, "phrase": "node_levels"}, {"score": 0.0035300318844877286, "phrase": "uniform_format"}, {"score": 0.0034164751616551437, "phrase": "resultant_job-wise_data"}, {"score": 0.003210652026669616, "phrase": "specific_statistical_and_analytical_algorithms"}, {"score": 0.0031277316566463978, "phrase": "different_levels"}, {"score": 0.0029392523663327253, "phrase": "new_lightweight_job-centric_measurement_tool"}, {"score": 0.0028727045847620957, "phrase": "comprehensive_set"}, {"score": 0.00285396838599055, "phrase": "resource_use_metrics"}, {"score": 0.002735118294625477, "phrase": "data_mapping"}, {"score": 0.0026557415971295633, "phrase": "xdmod_project"}, {"score": 0.002545128004893842, "phrase": "ranger"}, {"score": 0.0025285202557857323, "phrase": "stampede_supercomputers"}, {"score": 0.0025038150103055823, "phrase": "hpc_cluster"}, {"score": 0.002352844633115289, "phrase": "system_usage_patterns"}, {"score": 0.0023374910885214815, "phrase": "also_anomalous_behavior"}, {"score": 0.0022182072857447684, "phrase": "tacc_stats_measurement_tool"}, {"score": 0.002175058780645677, "phrase": "job_execution_environment_data"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["TACC_Stats", " XDMoD", " XSEDE", " system management", " performance analysis", " usage analysis", " SUPReMM", " HPC resource management"], "paper_abstract": "The important role high-performance computing (HPC) resources play in science and engineering research, coupled with its high cost (capital, power and manpower), short life and oversubscription, requires us to optimize its usage - an outcome that is only possible if adequate analytical data are collected and used to drive systems management at different granularities - job, application, user and system. This paper presents a method for comprehensive job, application and system-level resource use measurement, and analysis and its implementation. The steps in the method are system-wide collection of comprehensive resource use and performance statistics at the job and node levels in a uniform format across all resources, mapping and storage of the resultant job-wise data to a relational database, which enables further implementation and transformation of the data to the formats required by specific statistical and analytical algorithms. Analyses can be carried out at different levels of granularity: job, user, application or system-wide. Measurements are based on a new lightweight job-centric measurement tool TACC_Stats', which gathers a comprehensive set of resource use metrics on all compute nodes and data logged by the system scheduler. The data mapping and analysis tools are an extension of the XDMoD project. The method is illustrated with analyses of resource use for the Texas Advanced Computing Center's Lonestar4, Ranger and Stampede supercomputers and the HPC cluster at the Center for Computational Research. The illustrations are focused on resource use at the system, job and application levels and reveal many interesting insights into system usage patterns and also anomalous behavior due to failure/misuse. The method can be applied to any system that runs the TACC_Stats measurement tool and a tool to extract job execution environment data from the system scheduler. Copyright (c) 2014 John Wiley & Sons, Ltd.", "paper_title": "Comprehensive, open-source resource usage measurement and analysis for HPC systems", "paper_id": "WOS:000340283700010"}