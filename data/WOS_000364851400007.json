{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "online_structure_analysis_for_real-time_indoor_scene_reconstruction"}, {"score": 0.004662036750452837, "phrase": "real-time_approach"}, {"score": 0.004602233424629559, "phrase": "indoor_scene_reconstruction"}, {"score": 0.003916098498242888, "phrase": "consumer_depth_camera"}, {"score": 0.003816197777388722, "phrase": "explicit_representations"}, {"score": 0.003767203575060969, "phrase": "planar_regions"}, {"score": 0.0037188360359702182, "phrase": "nonplanar_objects"}, {"score": 0.003623949225126944, "phrase": "noisy_feed"}, {"score": 0.0035543706594585076, "phrase": "depth_camera"}, {"score": 0.0034636656250083744, "phrase": "online_structure_analysis"}, {"score": 0.003331915219811852, "phrase": "structural_information"}, {"score": 0.0032259472087775138, "phrase": "volumetric_representation"}, {"score": 0.00306334226516593, "phrase": "seamless_integration"}, {"score": 0.0030239842475439814, "phrase": "kinectfusion's_global_data_structure"}, {"score": 0.0028901595183546576, "phrase": "whole_reconstruction_process"}, {"score": 0.0027622407190589326, "phrase": "rectilinear_shapes"}, {"score": 0.002726740692380339, "phrase": "typical_indoor_scenes"}, {"score": 0.0026743419827100225, "phrase": "camera_tracking_drift"}, {"score": 0.0026060359255636444, "phrase": "reconstruction_accuracy"}, {"score": 0.002555950807368337, "phrase": "instantaneous_feedback"}, {"score": 0.0022457226013538343, "phrase": "high-fidelity_large-scale_models"}, {"score": 0.0021049977753042253, "phrase": "real-life_examples"}], "paper_keywords": ["Algorithms", " Experimentation", " Performance", " 3D scanning", " plane detection", " object detection", " camera tracking", " drifting"], "paper_abstract": "We propose a real-time approach for indoor scene reconstruction. It is capable of producing a ready-to-use 3D geometric model even while the user is still scanning the environment with a consumer depth camera. Our approach features explicit representations of planar regions and nonplanar objects extracted from the noisy feed of the depth camera, via an online structure analysis on the dynamic, incomplete data. The structural information is incorporated into the volumetric representation of the scene, resulting in a seamless integration with KinectFusion's global data structure and an efficient implementation of the whole reconstruction process. Moreover, heuristics based on rectilinear shapes in typical indoor scenes effectively eliminate camera tracking drift and further improve reconstruction accuracy. The instantaneous feedback enabled by our on-the-fly structure analysis, including repeated object recognition, allows the user to selectively scan the scene and produce high-fidelity large-scale models efficiently. We demonstrate the capability of our system with real-life examples.", "paper_title": "Online Structure Analysis for Real-Time Indoor Scene Reconstruction", "paper_id": "WOS:000364851400007"}