{"auto_keywords": [{"score": 0.004671803485255806, "phrase": "exponential-time_backtracking_algorithms"}, {"score": 0.0045158206186680224, "phrase": "exact_solutions"}, {"score": 0.004481868017991508, "phrase": "np-hard_problems"}, {"score": 0.0042351951710402425, "phrase": "tight_worst-case"}, {"score": 0.0036969566358089644, "phrase": "careful_design"}, {"score": 0.0036553070575015344, "phrase": "nonstandard_measure"}, {"score": 0.003614124997453808, "phrase": "subproblem_size"}, {"score": 0.0033765627434550432, "phrase": "branching_step"}, {"score": 0.0032884384364324395, "phrase": "smarter_measure"}, {"score": 0.0031784960695034645, "phrase": "standard_measure"}, {"score": 0.003026127736667187, "phrase": "significantly_better_worst-case_time_analysis"}, {"score": 0.0028164399450837465, "phrase": "maximum_independent_set"}, {"score": 0.0027741761880779535, "phrase": "first_problem"}, {"score": 0.002722234804904997, "phrase": "current_best_algorithm"}, {"score": 0.0026411384812121503, "phrase": "better_measure"}, {"score": 0.002514464610980629, "phrase": "second_problem"}, {"score": 0.0023758152068732025, "phrase": "current_best_time_bounds"}, {"score": 0.002340147988348115, "phrase": "far_more_complicated_algorithms"}, {"score": 0.0023137485947956732, "phrase": "standard_analysis"}, {"score": 0.002253299769886694, "phrase": "good_choice"}, {"score": 0.002169667676959813, "phrase": "exact_algorithms_design"}, {"score": 0.002129020447793464, "phrase": "tremendous_impact"}, {"score": 0.0021049977753042253, "phrase": "running_time"}], "paper_keywords": ["Algorithms", " Theory", " Dominating set", " exact algorithm", " independent set"], "paper_abstract": "For more than 40 years, Branch & Reduce exponential-time backtracking algorithms have been among the most common tools used for finding exact solutions of NP-hard problems. Despite that, the way to analyze such recursive algorithms is still far from producing tight worst-case running time bounds. Motivated by this, we use an approach, that we call \"Measure& Conquer\", as an attempt to step beyond such limitations. The approach is based on the careful design of a nonstandard measure of the subproblem size; this measure is then used to lower bound the progress made by the algorithm at each branching step. The idea is that a smarter measure may capture behaviors of the algorithm that a standard measure might not be able to exploit, and hence lead to a significantly better worst-case time analysis. In order to show the potentialities of Measure & Conquer, we consider two well-studied NP-hard problems: minimum dominating set and maximum independent set. For the first problem, we consider the current best algorithm, and prove (thanks to a better measure) a much tighter running time bound for it. For the second problem, we describe a new, simple algorithm, and show that its running time is competitive with the current best time bounds, achieved with far more complicated algorithms (and standard analysis). Our examples show that a good choice of the measure, made in the very first stages of exact algorithms design, can have a tremendous impact on the running time bounds achievable.", "paper_title": "A Measure & Conquer Approach for the Analysis of Exact Algorithms", "paper_id": "WOS:000270098500001"}