{"auto_keywords": [{"score": 0.049818512053858996, "phrase": "coevolutionary_learning"}, {"score": 0.02261384735049501, "phrase": "ipd"}, {"score": 0.02086668730170014, "phrase": "cooperative_behaviors"}, {"score": 0.009316850330259191, "phrase": "direct_reciprocity"}, {"score": 0.00481495049065317, "phrase": "multiagent_interactions"}, {"score": 0.004654779963297256, "phrase": "reputation_scores"}, {"score": 0.004485385874698246, "phrase": "complex_environment"}, {"score": 0.00441257945244739, "phrase": "adaptation_process"}, {"score": 0.0043766186644841575, "phrase": "strategic_interactions"}, {"score": 0.0034422330919613294, "phrase": "intermediate_choice"}, {"score": 0.0033131323758456978, "phrase": "subtle_exploitation"}, {"score": 0.003286102075191774, "phrase": "likely_consequence"}, {"score": 0.003241539155408198, "phrase": "lower_cooperation"}, {"score": 0.0032063229232501965, "phrase": "higher_payoffs"}, {"score": 0.003180161250635426, "phrase": "short-term_view"}, {"score": 0.003052510519032211, "phrase": "complex_human_interactions"}, {"score": 0.0030193416820392554, "phrase": "indirect_interactions"}, {"score": 0.002994701080666466, "phrase": "direct_interactions"}, {"score": 0.0028432334129420305, "phrase": "current_behavioral_interactions"}, {"score": 0.0027817658627604653, "phrase": "previous_moves"}, {"score": 0.002466634951303726, "phrase": "future_partners"}, {"score": 0.0024398167078355224, "phrase": "mutual_cooperation"}, {"score": 0.002310026299345283, "phrase": "reputation_estimation"}, {"score": 0.0022911610600672445, "phrase": "strategy_behaviors"}, {"score": 0.0022786697084960224, "phrase": "different_implementations"}, {"score": 0.002133969592219807, "phrase": "previous_generations"}], "paper_keywords": ["coevolutionary learning", " evolutionary computation", " evolutionary games", " iterated prisoner's dilemma (IPD)", " reputation"], "paper_abstract": "Coevolutionary learning provides a framework for modeling more realistic iterated prisoner's dilemma (IPD) interactions and to study conditions of how and why certain behaviors (e.g., cooperation) in a complex environment can be learned through an adaptation process guided by strategic interactions. The coevolutionary learning of cooperative behaviors can be attributed to the mechanism of direct reciprocity (e.g., repeated encounters). However, for the more complex IPD game with more choices, it is unknown precisely why the mechanism of direct reciprocity is less effective in promoting the learning of cooperative behaviors. Here, our study suggests that the evolution of defection may be a result of strategies effectively having more opportunities to exploit others when there are more choices. We note that strategies are less able to resolve the intention of an intermediate choice, e.g., whether it is a signal to engender further cooperation or a subtle exploitation. A likely consequence is strategies adapting to lower cooperation plays that offer higher payoffs in the short-term view when they cannot resolve the intention of opponents. However, cooperation in complex human interactions may also involve indirect interactions rather than direct interactions only. Following this, we study the coevolutionary learning of IPD with more choices and reputation. Here, current behavioral interactions depend not only on choices made in previous moves (direct interactions), but also choices made in past interactions that are reflected by their reputation scores (indirect interactions). The coevolutionary learning of cooperative behaviors is possible in the IPD with more choices when strategies use reputation as a mechanism to estimate behaviors of future partners and to elicit mutual cooperation play right from the start of interactions. In addition, we study the impact of the accuracy of reputation estimation in reflecting strategy behaviors of different implementations and why it is important for the evolution of cooperation. We show that the accuracy is related to how memory of games from previous generations is incorporated to calculate reputation scores and how frequently reputation scores are updated.", "paper_title": "Multiple choices and reputation in multiagent interactions", "paper_id": "WOS:000251376600001"}