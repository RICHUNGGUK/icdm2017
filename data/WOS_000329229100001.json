{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "constrained_spectral_clustering"}, {"score": 0.041726498903390224, "phrase": "spectral_clustering"}, {"score": 0.004726382602809228, "phrase": "constrained_clustering"}, {"score": 0.004512099566027791, "phrase": "k-means"}, {"score": 0.0044702911400353535, "phrase": "hierarchical_clustering"}, {"score": 0.004267468074128779, "phrase": "algorithmic_settings"}, {"score": 0.003888905257972882, "phrase": "developing_area"}, {"score": 0.00372965096877929, "phrase": "flexible_framework"}, {"score": 0.003593555152077465, "phrase": "previous_efforts"}, {"score": 0.0034472656699143425, "phrase": "laplacian"}, {"score": 0.0033828748627992193, "phrase": "underlying_eigenspace"}, {"score": 0.003140401552000472, "phrase": "constrained_optimization_problem"}, {"score": 0.002942495422585405, "phrase": "ml_and_cl_constraints"}, {"score": 0.002731500545019039, "phrase": "user-specified_threshold"}, {"score": 0.0026317312518257803, "phrase": "polynomial_time"}, {"score": 0.002607362103727335, "phrase": "generalized_eigendecomposition"}, {"score": 0.002523828967909659, "phrase": "objective_function"}, {"score": 0.0023867931451842087, "phrase": "existing_analysis"}, {"score": 0.0023646866829474798, "phrase": "unconstrained_spectral_clustering_techniques"}, {"score": 0.0022258906408344973, "phrase": "empirical_results"}, {"score": 0.002195033004022173, "phrase": "artificial_and_real_datasets"}, {"score": 0.002134592410214824, "phrase": "innovative_use"}, {"score": 0.0021049977753042253, "phrase": "large_number"}], "paper_keywords": ["Spectral clustering", " Constrained clustering", " Transfer learning", " Graph partition"], "paper_abstract": "Constrained clustering has been well-studied for algorithms such as K-means and hierarchical clustering. However, how to satisfy many constraints in these algorithmic settings has been shown to be intractable. One alternative to encode many constraints is to use spectral clustering, which remains a developing area. In this paper, we propose a flexible framework for constrained spectral clustering. In contrast to some previous efforts that implicitly encode Must-Link (ML) and Cannot-Link (CL) constraints by modifying the graph Laplacian or constraining the underlying eigenspace, we present a more natural and principled formulation, which explicitly encodes the constraints as part of a constrained optimization problem. Our method offers several practical advantages: it can encode the degree of belief in ML and CL constraints; it guarantees to lower-bound how well the given constraints are satisfied using a user-specified threshold; it can be solved deterministically in polynomial time through generalized eigendecomposition. Furthermore, by inheriting the objective function from spectral clustering and encoding the constraints explicitly, much of the existing analysis of unconstrained spectral clustering techniques remains valid for our formulation. We validate the effectiveness of our approach by empirical results on both artificial and real datasets. We also demonstrate an innovative use of encoding large number of constraints: transfer learning via constraints.", "paper_title": "On constrained spectral clustering and its applications", "paper_id": "WOS:000329229100001"}