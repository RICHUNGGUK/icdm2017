{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "bayesian_mixed-effects_inference"}, {"score": 0.004771196027464407, "phrase": "classification_performance"}, {"score": 0.004727837281331949, "phrase": "hierarchical_data_sets"}, {"score": 0.0046848707075530256, "phrase": "classification_algorithms"}, {"score": 0.004516856326107826, "phrase": "natural_hierarchical_structure"}, {"score": 0.004276016541197123, "phrase": "trial-wise_measurements"}, {"score": 0.004029517895918228, "phrase": "classification_outcomes"}, {"score": 0.003974673997871831, "phrase": "individual_subjects"}, {"score": 0.0035945701438887282, "phrase": "novel_statistical_models"}, {"score": 0.003371773890338284, "phrase": "hierarchical_nature"}, {"score": 0.0030076088903023034, "phrase": "variance_components"}, {"score": 0.002953097497434808, "phrase": "maximum-likelihood_estimation"}, {"score": 0.0028995712226514746, "phrase": "full_bayesian_inference"}, {"score": 0.0028340217672278975, "phrase": "natural_regularization"}, {"score": 0.0027954035431845344, "phrase": "estimation_problem"}, {"score": 0.0026949679939994226, "phrase": "posterior_probability_statements"}, {"score": 0.0026461080202599694, "phrase": "classification_accuracy"}, {"score": 0.0025627194819793347, "phrase": "balanced_accuracy"}, {"score": 0.0025047659706737215, "phrase": "accuracy_estimates"}, {"score": 0.0024819522818492284, "phrase": "imbalanced_data_sets"}, {"score": 0.00243694486220507, "phrase": "hierarchical_models"}, {"score": 0.0023386327847292805, "phrase": "conventional_methods"}, {"score": 0.0023173287402646577, "phrase": "mcmc_implementations"}, {"score": 0.0022962183207691188, "phrase": "model_inversion"}, {"score": 0.002275299774554847, "phrase": "model_selection"}, {"score": 0.0021243539405631866, "phrase": "statistical_inference"}, {"score": 0.0021049977753042253, "phrase": "future_hierarchical_classification_studies"}], "paper_keywords": ["beta-binomial", " normal-binomial", " balanced accuracy", " Bayesian inference", " group studies"], "paper_abstract": "Classification algorithms are frequently used on data with a natural hierarchical structure. For instance, classifiers are often trained and tested on trial-wise measurements, separately for each subject within a group. One important question is how classification outcomes observed in individual subjects can be generalized to the population from which the group was sampled. To address this question, this paper introduces novel statistical models that are guided by three desiderata. First, all models explicitly respect the hierarchical nature of the data, that is, they are mixed-effects models that simultaneously account for within-subjects (fixed-effects) and across-subjects (random-effects) variance components. Second, maximum-likelihood estimation is replaced by full Bayesian inference in order to enable natural regularization of the estimation problem and to afford conclusions in terms of posterior probability statements. Third, inference on classification accuracy is complemented by inference on the balanced accuracy, which avoids inflated accuracy estimates for imbalanced data sets. We introduce hierarchical models that satisfy these criteria and demonstrate their advantages over conventional methods using MCMC implementations for model inversion and model selection on both synthetic and empirical data. We envisage that our approach will improve the sensitivity and validity of statistical inference in future hierarchical classification studies.", "paper_title": "Bayesian Mixed-Effects Inference on Classification Performance in Hierarchical Data Sets", "paper_id": "WOS:000313200200001"}