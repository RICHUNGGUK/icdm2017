{"auto_keywords": [{"score": 0.027708409639554052, "phrase": "dtw"}, {"score": 0.01716544731422466, "phrase": "fh"}, {"score": 0.00481495049065317, "phrase": "twofold_video_hashing_with_automatic_synchronization"}, {"score": 0.004701825207431857, "phrase": "robust_media_representation_technique"}, {"score": 0.004483450050677258, "phrase": "near-duplicate_detection"}, {"score": 0.004326321719714357, "phrase": "antipiracy_search"}, {"score": 0.004125314447335291, "phrase": "spatial_modifications"}, {"score": 0.004004436217742343, "phrase": "temporal_de-synchronization"}, {"score": 0.003933609372601274, "phrase": "joint_spatio-temporal_attacks"}, {"score": 0.003818326867123525, "phrase": "increasingly_difficult_case"}, {"score": 0.003706410380455668, "phrase": "spatio-temporal_modifications"}, {"score": 0.0035977623578676496, "phrase": "new_framework"}, {"score": 0.003369778677878286, "phrase": "efficient_automatic_synchronization"}, {"score": 0.003290494847464381, "phrase": "dynamic_time"}, {"score": 0.0031561961485589633, "phrase": "complementary_video_comparison_measure"}, {"score": 0.003063627258654102, "phrase": "flow_hashing"}, {"score": 0.0028865314258560214, "phrase": "synchronized_videos"}, {"score": 0.002801849371896573, "phrase": "fusion_mechanism"}, {"score": 0.002532035301903554, "phrase": "future-proof_manner"}, {"score": 0.0024577274522206436, "phrase": "model_retraining"}, {"score": 0.002385595105638277, "phrase": "existing_hash_vectors"}, {"score": 0.0022476051902301187, "phrase": "real_video_collections"}, {"score": 0.002142970278347126, "phrase": "unprecedented_robustness"}, {"score": 0.0021049977753042253, "phrase": "spatial_and_temporal_attacks"}], "paper_keywords": ["Automatic temporal synchronization", " flow hashing", " distance boosting"], "paper_abstract": "As a robust media representation technique, video hashing is frequently used in near-duplicate detection, video authentication, and antipiracy search. Distortions to a video may include spatial modifications to each frame, temporal de-synchronization, and joint spatio-temporal attacks. To address the increasingly difficult case of finding videos under spatio-temporal modifications, we propose a new framework called two-stage video hashing. First, an efficient automatic synchronization is achieved using dynamic time warping (DTW) and a complementary video comparison measure is developed based on flow hashing (FH), which is extracted from the synchronized videos. Next, a fusion mechanism called distance boosting is proposed to fuse the information extracted by DTW and FH in a future-proof manner in the sense whenever model retraining is needed, the existing hash vectors do not need to be regenerated. Experiments on real video collections show that such a hash extraction and fusion method enables unprecedented robustness under both spatial and temporal attacks.", "paper_title": "Twofold Video Hashing With Automatic Synchronization", "paper_id": "WOS:000359984600015"}