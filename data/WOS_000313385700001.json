{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "human_recognition"}, {"score": 0.004559661374976129, "phrase": "automatic_extraction"}, {"score": 0.003978866233891427, "phrase": "feature_and_score_levels"}, {"score": 0.003378385493203297, "phrase": "feature_level_fusion"}, {"score": 0.0032282396745967504, "phrase": "ear_and_frontal_face_data"}, {"score": 0.0030847461428168614, "phrase": "based_matching"}, {"score": 0.002947611960613497, "phrase": "iterative_closest_point_algorithm"}, {"score": 0.002816556934231128, "phrase": "weighted_sum_rule"}, {"score": 0.0023694065215394593, "phrase": "non-neutral_facial_expressions"}, {"score": 0.002305589818994465, "phrase": "largest_public_databases"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["3D face", " Local 3D surface features", " Multibiometric multimodal recognition", " Score-level fusion", " Feature-level fusion"], "paper_abstract": "We present automatic extraction of local 3D features (L3DF) from ear and face biometrics and their combination at the feature and score levels for robust identification. To the best of our knowledge, this paper is the first to present feature level fusion of 3D features extracted from ear and frontal face data. Scores from L3DF based matching are also fused with iterative closest point algorithm based matching using a weighted sum rule. We achieve identification and verification (at 0.001 FAR) rates of 99.0% and 99.4%, respectively, with neutral and 96.8% and 97.1% with non-neutral facial expressions on the largest public databases of 3D ear and face. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Multibiometric human recognition using 3D ear and face features", "paper_id": "WOS:000313385700001"}