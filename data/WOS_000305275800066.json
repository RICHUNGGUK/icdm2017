{"auto_keywords": [{"score": 0.0337082311858877, "phrase": "baldwinian_learning_strategy"}, {"score": 0.03182000304460018, "phrase": "miab"}, {"score": 0.00481495049065317, "phrase": "baldwinian_learning"}, {"score": 0.004714023408114857, "phrase": "selection_component"}, {"score": 0.004556901872357751, "phrase": "scalar_optimization_problems"}, {"score": 0.0043678116213858, "phrase": "multi-objective_optimization_problems"}, {"score": 0.004186534737631288, "phrase": "existing_multi-objective_evolutionary_algorithms"}, {"score": 0.003945266418163835, "phrase": "research_effort"}, {"score": 0.0038789122930433305, "phrase": "conventional_reproduction_operators"}, {"score": 0.003670843919846253, "phrase": "different_optima_structures"}, {"score": 0.003459191419478298, "phrase": "searching_efficiency"}, {"score": 0.0031110402375026016, "phrase": "nondominated_neighbor_immune_algorithm"}, {"score": 0.003071682293903262, "phrase": "multi-objective_immune_algorithm"}, {"score": 0.0030457207372977537, "phrase": "baldwinian"}, {"score": 0.002857849698346116, "phrase": "evolving_environment"}, {"score": 0.002833689453299307, "phrase": "current_population"}, {"score": 0.002785978280998868, "phrase": "probability_distribution_model"}, {"score": 0.0027390682208834013, "phrase": "predictive_improving_direction"}, {"score": 0.0026929458952693465, "phrase": "environment_information"}, {"score": 0.002658863179011018, "phrase": "evolving_history"}, {"score": 0.0026252106881752067, "phrase": "parent_individual"}, {"score": 0.002603012037901889, "phrase": "experimental_results"}, {"score": 0.002570064617803693, "phrase": "ten_representative_benchmark_problems"}, {"score": 0.0024947959375982614, "phrase": "original_immune_algorithm"}, {"score": 0.0023708445073819277, "phrase": "nsgaii"}, {"score": 0.0023309080951251335, "phrase": "solution_quality"}, {"score": 0.002281930100792185, "phrase": "eight_testing_mops"}, {"score": 0.002224510044064184, "phrase": "proposed_baldwinian_learning_strategy"}], "paper_keywords": ["Multi-objective optimization problems", " Immune optimization algorithm", " Memetic algorithm", " Baldwinian learning"], "paper_abstract": "By replacing the selection component, a well researched evolutionary algorithm for scalar optimization problems (SOPs) can be directly used to solve multi-objective optimization problems (MOPs). Therefore, in most of existing multi-objective evolutionary algorithms (MOEAs), selection and diversity maintenance have attracted a lot of research effort. However, conventional reproduction operators designed for SOPs might not be suitable for MOPs due to the different optima structures between them. At present, few works have been done to improve the searching efficiency of MOEAs according to the characteristic of MOPs. Based on the regularity of continues MOPs, a Baldwinian learning strategy is designed for improving the nondominated neighbor immune algorithm and a multi-objective immune algorithm with Baldwinian learning (MIAB) is proposed in this study. The Baldwinian learning strategy extracts the evolving environment of current population by building a probability distribution model and generates a predictive improving direction by combining the environment information and the evolving history of the parent individual. Experimental results based on ten representative benchmark problems indicate that, MIAB outperforms the original immune algorithm, it performs better or similarly the other two outstanding approached NSGAII and MOEA/D in solution quality on most of the eight testing MOPs. The efficiency of the proposed Baldwinian learning strategy has also been experimentally investigated in this work. (C) 2012 Elsevier B. V. All rights reserved.", "paper_title": "Multi-objective immune algorithm with Baldwinian learning", "paper_id": "WOS:000305275800066"}