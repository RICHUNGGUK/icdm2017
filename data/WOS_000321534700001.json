{"auto_keywords": [{"score": 0.048966702050942536, "phrase": "agent_search"}, {"score": 0.04547624598453918, "phrase": "agent_values"}, {"score": 0.00481495049065317, "phrase": "threshold_search"}, {"score": 0.004782718554230406, "phrase": "best-valued_agents"}, {"score": 0.0046092435167207095, "phrase": "best_value"}, {"score": 0.004563028873351776, "phrase": "multi-agent_system"}, {"score": 0.0044870272550540415, "phrase": "value_assignment"}, {"score": 0.004195418010131832, "phrase": "classic_state-space_search_methods"}, {"score": 0.003909522412849038, "phrase": "best-valued_agent"}, {"score": 0.0036553070575015344, "phrase": "iteratively_publishing_thresholds"}, {"score": 0.00363080961099728, "phrase": "acceptable_agent_values"}, {"score": 0.0034638476252104706, "phrase": "first_responders"}, {"score": 0.0034290777464571895, "phrase": "sensor_networks"}, {"score": 0.0033156708990372047, "phrase": "fixed_cost"}, {"score": 0.003238517900104576, "phrase": "variable_cost"}, {"score": 0.0030688220103201836, "phrase": "threshold-based_sequence"}, {"score": 0.0030380052848799155, "phrase": "probability-based_one"}, {"score": 0.0029873281676201565, "phrase": "minimum_expected_cost"}, {"score": 0.002869115451202179, "phrase": "increasing_thresholds"}, {"score": 0.002811770047652563, "phrase": "simplified_characterization"}, {"score": 0.002783527398566117, "phrase": "optimal_thresholds_sequence"}, {"score": 0.0026111116934081284, "phrase": "multiple_agents"}, {"score": 0.0024993218789131437, "phrase": "legacy_economic-search_methods"}, {"score": 0.0024493494346360415, "phrase": "\"search_theory"}, {"score": 0.0023603078194781965, "phrase": "threshold-based_search"}, {"score": 0.0023131084326717755, "phrase": "existing_economic_search_techniques"}, {"score": 0.002282166507956957, "phrase": "economic_search_technique"}, {"score": 0.002206606452557159, "phrase": "best-value_search"}, {"score": 0.0021479597698614355, "phrase": "synthetic_environment"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Expanding extent search", " Optimal stopping rule"], "paper_abstract": "This paper investigates agent search for the agent with the best value in a multi-agent system, according to some value assignment. In the type of setting considered, agent values are independent of one another. Under this condition, classic state-space search methods are not very suitable solutions since they must probe the values of all agents in order to determine who the best-valued agent is. The method considered in this paper refines the number of agents that need to be probed by iteratively publishing thresholds on acceptable agent values. This kind of agent search is applicable to various domains, including auctions, first responders, and sensor networks. In the model considered, there is a fixed cost for publishing the thresholds and a variable cost for obtaining agent values that increases with the number of values obtained. By transforming the threshold-based sequence to a probability-based one, the sequence with minimum expected cost is proven to consist of either a single search round or an infinite sequence of increasing thresholds. This leads to a simplified characterization of the optimal thresholds sequence from which the sequence can be derived. The analysis is extended to the case of search for multiple agents. One important implication of this method is that it improves the performance of legacy economic-search methods that are commonly used in \"search theory\". Within this context, we show how a threshold-based search can be used to augment existing economic search techniques or as an economic search technique itself. The effectiveness of the methods for both best-value search and economic-search is demonstrated numerically using a synthetic environment. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Increasing threshold search for best-valued agents", "paper_id": "WOS:000321534700001"}