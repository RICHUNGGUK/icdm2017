{"auto_keywords": [{"score": 0.03446276292426166, "phrase": "regression_models"}, {"score": 0.03106397644758873, "phrase": "gaussian_process_regression"}, {"score": 0.00481495049065317, "phrase": "automated_crowd_counting"}, {"score": 0.0047468516620285525, "phrase": "active_field"}, {"score": 0.004713162564945179, "phrase": "computer_vision_research"}, {"score": 0.004646496622257368, "phrase": "existing_approaches"}, {"score": 0.004420472010542188, "phrase": "single_camera_viewpoint"}, {"score": 0.0042809854543795255, "phrase": "real_world_camera_networks"}, {"score": 0.0042354707960660706, "phrase": "multiple_viewpoints"}, {"score": 0.004029359223675788, "phrase": "novel_scene"}, {"score": 0.004015025120733852, "phrase": "invariant_crowd"}, {"score": 0.00388828234270598, "phrase": "multiple_cameras"}, {"score": 0.003819599991449801, "phrase": "camera_calibration"}, {"score": 0.0037924666577694222, "phrase": "normalise_features"}, {"score": 0.0032302647179383915, "phrase": "invariant_crowd_counting"}, {"score": 0.003128216758835217, "phrase": "object_size"}, {"score": 0.0029971349193857093, "phrase": "neural_networks"}, {"score": 0.002975826686621829, "phrase": "k-nearest_neighbours"}, {"score": 0.002881793492919646, "phrase": "accurate_crowd_counting"}, {"score": 0.0028409576481842457, "phrase": "seven_benchmark_datasets"}, {"score": 0.0028107098861552124, "phrase": "optimal_performance"}, {"score": 0.002654730366598922, "phrase": "scene_invariance"}, {"score": 0.002635850034826311, "phrase": "multi_camera_crowd"}, {"score": 0.002516350372379076, "phrase": "qut_camera_network"}, {"score": 0.002359759876402679, "phrase": "mean_relative_error"}, {"score": 0.0023015232625177755, "phrase": "pre-trained_system"}, {"score": 0.0022527488455744656, "phrase": "new_environment"}, {"score": 0.0022287497627555895, "phrase": "additional_training"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Crowd counting", " Multi camera", " Scene invariant"], "paper_abstract": "Automated crowd counting has become an active field of computer vision research in recent years. Existing approaches are scene-specific, as they are designed to operate in the single camera viewpoint that was used to train the system. Real world camera networks often span multiple viewpoints within a facility, including many regions of overlap. This paper proposes a novel scene invariant crowd counting algorithm that is designed to operate across multiple cameras. The approach uses camera calibration to normalise features between viewpoints and to compensate for regions of overlap. This compensation is performed by constructing an `overlap map' which provides a measure of how much an object at one location is visible within other viewpoints. An investigation into the suitability of various feature types and regression models for scene invariant crowd counting is also conducted. The features investigated include object size, shape, edges and keypoints. The regression models evaluated include neural networks, K-nearest neighbours, linear and Gaussian process regression. Our experiments demonstrate that accurate crowd counting was achieved across seven benchmark datasets, with optimal performance observed when all features were used and when Gaussian process regression was used. The combination of scene invariance and multi camera crowd counting is evaluated by training the system on footage obtained from the QUT camera network and testing it on three cameras from the PETS 2009 database. Highly accurate crowd counting was observed with a mean relative error of less than 10%. Our approach enables a pre-trained system to be deployed on a new environment without any additional training, bringing the field one step closer toward a `plug and play' system. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Scene invariant multi camera crowd counting", "paper_id": "WOS:000335906100012"}