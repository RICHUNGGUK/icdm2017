{"auto_keywords": [{"score": 0.04798652790106826, "phrase": "visual_neighbours"}, {"score": 0.04063906342715258, "phrase": "candidate_tag"}, {"score": 0.009601432282221834, "phrase": "tag-dependent_trust_degrees"}, {"score": 0.00481495049065317, "phrase": "tag-dependent_random_search"}, {"score": 0.004761494044422926, "phrase": "range-constrained_visual_neighbours"}, {"score": 0.003808209866576388, "phrase": "to-be-annotated_image"}, {"score": 0.0035811651542886746, "phrase": "score_prediction"}, {"score": 0.003367611042980526, "phrase": "constrained_range"}, {"score": 0.003293142761521425, "phrase": "identical_and_fixed_number"}, {"score": 0.003202361402737197, "phrase": "vnb_methods"}, {"score": 0.0029945352738604742, "phrase": "novel_tag-dependent_random_search_process"}, {"score": 0.0027382040767844093, "phrase": "effective_image_auto-annotation_method"}, {"score": 0.0026478260192958924, "phrase": "widely-used_conditional_probability_model"}, {"score": 0.0025461386232786356, "phrase": "image-dependent_weights"}, {"score": 0.0023151088048303705, "phrase": "extensive_experiments"}, {"score": 0.002251227801482381, "phrase": "real-world_web_images"}, {"score": 0.0022013916728990564, "phrase": "proposed_tagsearcher"}, {"score": 0.002164738347530834, "phrase": "inspiring_annotation_performance"}, {"score": 0.0021049977753042253, "phrase": "performance_sensitivity"}], "paper_keywords": ["Image auto-annotation", " TagSearcher", " Tag-dependent random search", " Range-constrained visual neighbours"], "paper_abstract": "The quantity setting of visual neighbours can be critical for the performance of many previously proposed visual-neighbour-based (VNB) image auto-annotation methods. And in those methods, each candidate tag of a to-be-annotated image would be better to have its own trustworthy part of visual neighbours for score prediction. Hence in this paper we propose to use a constrained range rather than an identical and fixed number of visual neighbours for VNB methods to allow more flexible choices of neighbours, and then put forward a novel tag-dependent random search process to estimate the tag-dependent trust degrees of visual neighbours for each candidate tag. We further propose an effective image auto-annotation method termed TagSearcher based on a widely-used conditional probability model for auto-annotation, considering image-dependent weights of visual neighbours, tag-dependent trust degrees of visual neighbours and votes for a candidate tag from visual neighbours. Extensive experiments conducted on both a benchmark dataset and real-world web images present that the proposed TagSearcher can yield inspiring annotation performance and also reduce the performance sensitivity to the quantity setting of visual neighbours.", "paper_title": "Image auto-annotation via tag-dependent random search over range-constrained visual neighbours", "paper_id": "WOS:000354898800022"}