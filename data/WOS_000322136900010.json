{"auto_keywords": [{"score": 0.013244058806639829, "phrase": "hidden_information"}, {"score": 0.01246148783993861, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "large-scale_learning"}, {"score": 0.004306205029641728, "phrase": "perceptron-style_method"}, {"score": 0.004141093507753515, "phrase": "fast_discriminative_learning"}, {"score": 0.00409508755819924, "phrase": "structured_classification"}, {"score": 0.0039380388343479384, "phrase": "theoretical_analysis"}, {"score": 0.0038725824361608243, "phrase": "good_convergence_properties"}, {"score": 0.003703282519292336, "phrase": "perceptron_algorithm"}, {"score": 0.003641713874009232, "phrase": "learning_task"}, {"score": 0.0034437574674180365, "phrase": "traditional_models"}, {"score": 0.0033488470615819915, "phrase": "viterbi"}, {"score": 0.003293142761521425, "phrase": "latent_variables"}, {"score": 0.0032203158828810244, "phrase": "simple_additive_updates"}, {"score": 0.00269263690712392, "phrase": "real-world_tasks"}, {"score": 0.0026330549554033876, "phrase": "existing_heavy_probabilistic_models"}, {"score": 0.0024075916292945715, "phrase": "training_cost"}, {"score": 0.002263861731320045, "phrase": "comparable_or_even_superior_classification_accuracy"}, {"score": 0.002128694000627911, "phrase": "good_scalability"}, {"score": 0.0021049977753042253, "phrase": "large-scale_problems"}], "paper_keywords": ["Structured perceptron", " latent variable", " hidden information", " convergence analysis", " large-scale learning"], "paper_abstract": "Many real-world data mining problems contain hidden information (e.g., unobservable latent dependencies). We propose a perceptron-style method, latent structured perceptron, for fast discriminative learning of structured classification with hidden information. We also give theoretical analysis and demonstrate good convergence properties of the proposed method. Our method extends the perceptron algorithm for the learning task with hidden information, which can be hardly captured by traditional models. It relies on Viterbi decoding over latent variables, combined with simple additive updates. We perform experiments on one synthetic data set and two real-world structured classification tasks. Compared to conventional nonlatent models (e.g., conditional random fields, structured perceptrons), our method is more accurate on real-world tasks. Compared to existing heavy probabilistic models of latent variables (e.g., latent conditional random fields), our method lowers the training cost significantly (almost one order magnitude faster) yet with comparable or even superior classification accuracy. In addition, experiments demonstrate that the proposed method has good scalability on large-scale problems.", "paper_title": "Latent Structured Perceptrons for Large-Scale Learning with Hidden Information", "paper_id": "WOS:000322136900010"}