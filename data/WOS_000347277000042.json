{"auto_keywords": [{"score": 0.04980116224241549, "phrase": "cohort_selection"}, {"score": 0.00481495049065317, "phrase": "data_sources"}, {"score": 0.004690521763591147, "phrase": "predictive_model"}, {"score": 0.004636252403395063, "phrase": "thirty-day_hospital_readmissions"}, {"score": 0.004503297824977738, "phrase": "motivated_area"}, {"score": 0.004386887374401584, "phrase": "hospital_readmissions_reduction_program"}, {"score": 0.004361428012479218, "phrase": "cms._multiple_models"}, {"score": 0.004273473221214617, "phrase": "variable_discriminatory_performances"}, {"score": 0.004187284711626886, "phrase": "design_factors"}, {"score": 0.004139128484792199, "phrase": "objectives"}, {"score": 0.004055329874540865, "phrase": "varying_three_factors"}, {"score": 0.004031786919040826, "phrase": "model_development"}, {"score": 0.003938968581984988, "phrase": "health_record_data"}, {"score": 0.0034655299412139668, "phrase": "lasso"}, {"score": 0.0034052040544137255, "phrase": "readmissions_risk"}, {"score": 0.003385422532841961, "phrase": "prevalence_sampling"}, {"score": 0.003365755538047523, "phrase": "support_vector_machine"}, {"score": 0.0032882197112190756, "phrase": "cohort_selection_testing"}, {"score": 0.003221837753001224, "phrase": "outcome_prevalence"}, {"score": 0.003175241510860455, "phrase": "readmission_risk"}, {"score": 0.003156791656819646, "phrase": "multiple_reasons"}, {"score": 0.0031111332159761344, "phrase": "roc_areas"}, {"score": 0.003048315312818542, "phrase": "congestive_heart_failure"}, {"score": 0.002978070402783044, "phrase": "all-cause_readmission"}, {"score": 0.0029349892964423197, "phrase": "laboratory_tests"}, {"score": 0.002867348342846275, "phrase": "readmission_diagnosis"}, {"score": 0.002850682396853918, "phrase": "cohort_definition"}, {"score": 0.0028094389072212352, "phrase": "parametric_and_nonparametric_algorithms"}, {"score": 0.0026349227856780175, "phrase": "average_roc"}, {"score": 0.0025817252759764153, "phrase": "roc"}, {"score": 0.0025221759076833124, "phrase": "calibration_plots"}, {"score": 0.002507511169156787, "phrase": "good_calibration"}, {"score": 0.00249293148301837, "phrase": "low_mean"}, {"score": 0.0024496978447849835, "phrase": "targeting_reason"}, {"score": 0.002421291757425244, "phrase": "risk_prediction"}, {"score": 0.0024072121760839427, "phrase": "discriminatory_performance"}, {"score": 0.0023585737444452573, "phrase": "history_data"}, {"score": 0.002244494905883452, "phrase": "large_impact"}, {"score": 0.002231441081806766, "phrase": "model_performance"}, {"score": 0.002154693685426657, "phrase": "different_studies"}, {"score": 0.002142161017595363, "phrase": "predictive_risk_modeling"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Readmissions", " Predictive analytics", " Electronic health record", " Regularized Logistic Regression", " Text mining", " Risk modeling"], "paper_abstract": "Background: Hospital readmission risk prediction remains a motivated area of investigation and operations in light of the hospital readmissions reduction program through CMS. Multiple models of risk have been reported with variable discriminatory performances, and it remains unclear how design factors affect performance. Objectives: To study the effects of varying three factors of model development in the prediction of risk based on health record data: (1) reason for readmission (primary readmission diagnosis); (2) available data and data types (e.g. visit history, laboratory results, etc); (3) cohort selection. Methods: Regularized regression (LASSO) to generate predictions of readmissions risk using prevalence sampling. Support Vector Machine (SVM) used for comparison in cohort selection testing. Calibration by model refitting to outcome prevalence. Results: Predicting readmission risk across multiple reasons for readmission resulted in ROC areas ranging from 0.92 for readmission for congestive heart failure to 0.71 for syncope and 0.68 for all-cause readmission. Visit history and laboratory tests contributed the most predictive value; contributions varied by readmission diagnosis. Cohort definition affected performance for both parametric and nonparametric algorithms. Compared to all patients, limiting the cohort to patients whose index admission and readmission diagnoses matched resulted in a decrease in average ROC from 0.78 to 0.55 (difference in ROC 0.23, p value 0.01). Calibration plots demonstrate good calibration with low mean squared error. Conclusion: Targeting reason for readmission in risk prediction impacted discriminatory performance. In general, laboratory data and visit history data contributed the most to prediction; data source contributions varied by reason for readmission. Cohort selection had a large impact on model performance, and these results demonstrate the difficulty of comparing results across different studies of predictive risk modeling. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "The effects of data sources, cohort selection, and outcome definition on a predictive model of risk of thirty-day hospital readmissions", "paper_id": "WOS:000347277000042"}