{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "critical_events"}, {"score": 0.004701825207431857, "phrase": "video_networks"}, {"score": 0.004646258518859209, "phrase": "predictive_driver_assistance_systems"}, {"score": 0.004404188306112211, "phrase": "real-world_human_activities"}, {"score": 0.0041995784967999985, "phrase": "distributed_vision_sensors"}, {"score": 0.004100851549096203, "phrase": "early_prediction"}, {"score": 0.0037731618765688584, "phrase": "particular_domain"}, {"score": 0.003619235073669304, "phrase": "early_knowledge"}, {"score": 0.003576416581189713, "phrase": "driver_behavior"}, {"score": 0.0032130703855586685, "phrase": "dangerous_situations"}, {"score": 0.0030454408569868347, "phrase": "effective_warning"}, {"score": 0.003009390313137981, "phrase": "driver_assistance_systems"}, {"score": 0.0029737652463012318, "phrase": "multiple_perspectives"}, {"score": 0.002768674345336861, "phrase": "comprehensive_representation"}, {"score": 0.0026874405408023956, "phrase": "temporal_activities"}, {"score": 0.002608583927848071, "phrase": "multi-camera_head"}, {"score": 0.0024577274522206436, "phrase": "ego-vehicle_parameters"}, {"score": 0.002399850604120431, "phrase": "road_geometry_analysis"}, {"score": 0.0023433334920926713, "phrase": "vehicle_trajectories"}, {"score": 0.002234252028553481, "phrase": "challenging_dataset"}, {"score": 0.0022077827041801193, "phrase": "naturalistic_driving"}, {"score": 0.002181626277903721, "phrase": "real-world_settings"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Early activity recognition", " Behavior-intent analysis", " Multi-modal sensor fusion", " Human-machine interactivity", " Intelligent vehicles"], "paper_abstract": "We study techniques for monitoring and understanding real-world human activities, in particular of drivers, from distributed vision sensors. Real-time and early prediction of maneuvers is emphasized, specifically overtake and brake events. Study this particular domain is motivated by the fact that early knowledge of driver behavior, in concert with the dynamics of the vehicle and surrounding agents, can help to recognize dangerous situations. Furthermore, it can assist in developing effective warning and driver assistance systems. Multiple perspectives and modalities are captured and fused in order to achieve a comprehensive representation of the scene. Temporal activities are learned from a multi-camera head pose estimation module, hand and foot tracking, ego-vehicle parameters, lane and road geometry analysis, and surround vehicle trajectories. The system is evaluated on a challenging dataset of naturalistic driving in real-world settings. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "On surveillance for safety critical events: In-vehicle video networks for predictive driver assistance systems", "paper_id": "WOS:000360592500011"}