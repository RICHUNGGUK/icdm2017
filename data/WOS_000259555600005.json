{"auto_keywords": [{"score": 0.03502138116720421, "phrase": "optical_flow"}, {"score": 0.02856315118446264, "phrase": "colour-gradient_redundancy"}, {"score": 0.004739416327250269, "phrase": "autonomous_navigation"}, {"score": 0.004176102823067887, "phrase": "rigid_body"}, {"score": 0.003998286635727259, "phrase": "autonomous_navigation_tasks"}, {"score": 0.0038584250641318057, "phrase": "mobile_targets"}, {"score": 0.0037978390554858766, "phrase": "object's_complete_six-dof_pose"}, {"score": 0.003607404191062938, "phrase": "planar_motion"}, {"score": 0.0033460624879847667, "phrase": "textured_model_projection"}, {"score": 0.0032804824152243106, "phrase": "main_contribution"}, {"score": 0.0032161835102640372, "phrase": "novel_combination"}, {"score": 0.00316565009987584, "phrase": "z-buffer_depth_information"}, {"score": 0.0031035949505887083, "phrase": "model_projection"}, {"score": 0.0030187498405804315, "phrase": "six-dof_tracking"}, {"score": 0.0029830992938695033, "phrase": "single_camera"}, {"score": 0.002947868524740683, "phrase": "localized_illumination_normalization_filter"}, {"score": 0.0027999339042953076, "phrase": "real-time_operation"}, {"score": 0.0027559226203857316, "phrase": "gpu-based_filters"}, {"score": 0.002723367507064405, "phrase": "new_data-reduction_algorithm"}, {"score": 0.002546002312015341, "phrase": "important_property"}, {"score": 0.0025259082947443343, "phrase": "colour_images"}, {"score": 0.002437425029824563, "phrase": "colour_channels"}, {"score": 0.0023427323356117365, "phrase": "threefold_increase"}, {"score": 0.0022967713922705, "phrase": "processing_rate"}, {"score": 0.002207530926563892, "phrase": "synthetic_and_real_target-motion_sequences"}, {"score": 0.0021049977753042253, "phrase": "different_lighting_conditions"}], "paper_keywords": ["computer vision", " real-time object tracking", " pose tracking", " mobile-robot navigation"], "paper_abstract": "This paper presents a novel 3D-model-based computer-vision method for tracking the full six degree-of-freedom (dof) pose (position and orientation) of a rigid body, in real-time. The methodology has been targeted for autonomous navigation tasks, such as interception of or rendezvous with mobile targets. Tracking an object's complete six-dof pose makes the proposed algorithm useful even when targets are not restricted to planar motion (e.g., flying or rough-terrain navigation). Tracking is achieved via a combination of textured model projection and optical flow. The main contribution of our work is the novel combination of optical flow with z-buffer depth information that is produced during model projection. This allows us to achieve six-dof tracking with a single camera. A localized illumination normalization filter also has been developed in order to improve robustness to shading. Real-time operation is achieved using GPU-based filters and a new data-reduction algorithm based on colour-gradient redundancy, which was developed within the framework of our project. Colour-gradient redundancy is an important property of colour images, namely, that the gradients of all colour channels are generally aligned. Exploiting this property provides a threefold increase in speed. A processing rate of approximately 80 to 100 fps has been obtained in our work when utilizing synthetic and real target-motion sequences. Sub-pixel accuracies were obtained in tests performed under different lighting conditions.", "paper_title": "Visual-model-based, real-time 3D pose tracking for autonomous navigation: methodology and experiments", "paper_id": "WOS:000259555600005"}