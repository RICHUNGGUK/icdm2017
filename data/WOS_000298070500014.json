{"auto_keywords": [{"score": 0.0398472650073434, "phrase": "webspam"}, {"score": 0.007598389207727474, "phrase": "target_page"}, {"score": 0.00481495049065317, "phrase": "search_engines"}, {"score": 0.004677965073019951, "phrase": "specific_query"}, {"score": 0.004479726755921316, "phrase": "ranking_web_pages"}, {"score": 0.0041677440361312604, "phrase": "high_quality_results"}, {"score": 0.004034504342397309, "phrase": "equally_relevant_web_pages"}, {"score": 0.003849502288990788, "phrase": "page_rank"}, {"score": 0.003726398477619122, "phrase": "web_pages"}, {"score": 0.0036333693364337953, "phrase": "ranking_algorithms"}, {"score": 0.003343691804204423, "phrase": "important_issue"}, {"score": 0.0033196177202591843, "phrase": "web_search_engines"}, {"score": 0.003190265467214105, "phrase": "nonbiased_list"}, {"score": 0.0031444844772458504, "phrase": "webspam_techniques"}, {"score": 0.0029464414592923196, "phrase": "specific_linking_architecture"}, {"score": 0.002760836859397696, "phrase": "node_aggregation"}, {"score": 0.0027310567737368033, "phrase": "well-known_ranking_algorithm"}, {"score": 0.002711422191025615, "phrase": "google"}, {"score": 0.0024770482478966896, "phrase": "sole_node"}, {"score": 0.0024503217593801587, "phrase": "pagerank_computation"}, {"score": 0.0024151333926491878, "phrase": "web_graph"}, {"score": 0.002354762471810519, "phrase": "classic_clustering_techniques"}, {"score": 0.002279349794239273, "phrase": "experimental_results"}, {"score": 0.002151183757599893, "phrase": "statistical_evidence"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Webspam demotion", " Clustering"], "paper_abstract": "Search engines result pages (SERPs) for a specific query are constructed according to several mechanisms. One of them consists in ranking Web pages regarding their importance, regardless of their semantic. Indeed, relevance to a query is not enough to provide high quality results, and popularity is used to arbitrate between equally relevant Web pages. The most well-known algorithm that ranks Web pages according to their popularity is the Page Rank. The term Webspam was coined to denotes Web pages created with the only purpose of fooling ranking algorithms such as the Page Rank. Indeed, the goal of Webspam is to promote a target page by increasing its rank. It is an important issue for Web search engines to spot and discard Webspam to provide their users with a nonbiased list of results. Webspam techniques are evolving constantly to remain efficient but most of the time they still consist in creating a specific linking architecture around the target page to increase its rank. In this paper we propose to study the effects of node aggregation on the well-known ranking algorithm of Google (the PageRank) in the presence of Webspam. Our node aggregation methods have the purpose to construct clusters of nodes that are considered as a sole node in the PageRank computation. Since the Web graph is way to big to apply classic clustering techniques, we present four lightweight aggregation techniques suitable for its size. Experimental results on the WEBSPAM-UK2007 dataset show the interest of the approach, which is moreover confirmed by statistical evidence. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Webspam demotion: Low complexity node aggregation methods", "paper_id": "WOS:000298070500014"}