{"auto_keywords": [{"score": 0.04872357153155877, "phrase": "full-text_articles"}, {"score": 0.01156957940637246, "phrase": "similarity_values"}, {"score": 0.00856171868544655, "phrase": "pubmed_central_open_access"}, {"score": 0.007469193675396471, "phrase": "full_content"}, {"score": 0.006529547657537187, "phrase": "concept-based_annotations"}, {"score": 0.00481495049065317, "phrase": "semantic_similarity"}, {"score": 0.004772593750252861, "phrase": "umls_annotations"}, {"score": 0.004606843145343611, "phrase": "electronic_formats"}, {"score": 0.004526129302830441, "phrase": "related_work"}, {"score": 0.004476399615305783, "phrase": "abstract_context"}, {"score": 0.004446823283475876, "phrase": "related_articles"}, {"score": 0.004378566229970024, "phrase": "good_starting_point"}, {"score": 0.004254558771304349, "phrase": "full-text_based_similarity"}, {"score": 0.0040886093072615, "phrase": "highly_related_abstracts"}, {"score": 0.003964007795174772, "phrase": "title-and-abstract_versus_full-text"}, {"score": 0.003834700685199439, "phrase": "main_issues"}, {"score": 0.0037260386566859197, "phrase": "pmra"}, {"score": 0.0037014387992436227, "phrase": "cosine"}, {"score": 0.0035885578835219683, "phrase": "full-text_documents"}, {"score": 0.003410565849262162, "phrase": "genomics_track_article_collection"}, {"score": 0.003335948601271999, "phrase": "entity_recognition_software"}, {"score": 0.003198629836006853, "phrase": "umls"}, {"score": 0.00312863447374513, "phrase": "document_profile"}, {"score": 0.003080548510001051, "phrase": "identified_concepts"}, {"score": 0.0029733865110222785, "phrase": "document_profiles"}, {"score": 0.0027823821818620535, "phrase": "pmc"}, {"score": 0.002733539375462443, "phrase": "dispersion_analyses"}, {"score": 0.0026209522797963447, "phrase": "pubmed_related_articles_similarity_metric"}, {"score": 0.0025692477422626678, "phrase": "umls_concepts"}, {"score": 0.0024416894762565107, "phrase": "highest_precision_close"}, {"score": 0.0023988186238648908, "phrase": "concept-based_metrics"}, {"score": 0.0023724065150232897, "phrase": "word-stem-based_one"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Semantic similarity", " Scientific publications", " Similarity metrics", " Semantic annotations", " Related articles"], "paper_abstract": "Motivation: Although full-text articles are provided by the publishers in electronic formats, it remains a challenge to find related work beyond the title and abstract context. Identifying related articles based on their abstract is indeed a good starting point; this process is straightforward and does not consume as many resources as full-text based similarity would require. However, further analyses may require in-depth understanding of the full content. Two articles with highly related abstracts can be substantially different regarding the full content. How similarity differs when considering title-and-abstract versus full-text and which semantic similarity metric provides better results when dealing with full-text articles are the main issues addressed in this manuscript. Methods: We have benchmarked three similarity metrics - BM25, PMRA, and Cosine, in order to determine which one performs best when using concept-based annotations on full-text documents. We also evaluated variations in similarity values based on title-and-abstract against those relying on full-text. Our test dataset comprises the Genomics track article collection from the 2005 Text Retrieval Conference. Initially, we used an entity recognition software to semantically annotate titles and abstracts as well as full-text with concepts defined in the Unified Medical Language System (UMLS). For each article, we created a document profile, i.e., a set of identified concepts, term frequency, and inverse document frequency; we then applied various similarity metrics to those document profiles. We considered correlation, precision, recall, and F1 in order to determine which similarity metric performs best with concept-based annotations. For those full-text articles available in PubMed Central Open Access (PMC-OA), we also performed dispersion analyses in order to understand how similarity varies when considering full-text articles. Results: We have found that the PubMed Related Articles similarity metric is the most suitable for full-text articles annotated with UMLS concepts. For similarity values above 0.8, all metrics exhibited an F1 around 0.2 and a recall around 0.1; BM25 showed the highest precision close to 1; in all cases the concept-based metrics performed better than the word-stem-based one. Our experiments show that similarity values vary when considering only title-and-abstract versus full-text similarity. Therefore, analyses based on full-text become useful when a given research requires going beyond title and abstract, particularly regarding connectivity across articles. Availability: Visualization available at ljgarcia.github.io/semsim.benchmark/, data available at http://dx.doi.org/10.5281/zenodo.13323. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "In the pursuit of a semantic similarity metric based on UMLS annotations for articles in PubMed Central Open Access", "paper_id": "WOS:000363437500019"}