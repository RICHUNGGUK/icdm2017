{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "image_sequences"}, {"score": 0.004747997855358171, "phrase": "new_computational_architecture"}, {"score": 0.004703878334423852, "phrase": "dynamic_visual_attention"}, {"score": 0.00436530211426514, "phrase": "active_attention_focus"}, {"score": 0.004304574865291508, "phrase": "dynamic_scene"}, {"score": 0.004224911726496726, "phrase": "still_or_moving_camera"}, {"score": 0.003994624397219346, "phrase": "observer's_attention"}, {"score": 0.0038661089070527424, "phrase": "predefined_features"}, {"score": 0.0036213041338584756, "phrase": "selective_visual_attention_problem"}, {"score": 0.0035376693476114733, "phrase": "input_images"}, {"score": 0.0034884152484429207, "phrase": "indefinite_sequence"}, {"score": 0.0032522091171602557, "phrase": "user's_interest"}, {"score": 0.0029757667083164627, "phrase": "attention_model"}, {"score": 0.0029069972482610403, "phrase": "feature-extraction_task"}, {"score": 0.0027100527874262446, "phrase": "object_segmentation"}, {"score": 0.0026722904884984348, "phrase": "attention-capture_task"}, {"score": 0.002479579797152119, "phrase": "extracted_features"}, {"score": 0.0024336086025284836, "phrase": "different_parts"}, {"score": 0.00237733844863506, "phrase": "potential_interest"}, {"score": 0.0023223663501882917, "phrase": "attention-reinforcement_task"}, {"score": 0.0022058510091498666, "phrase": "image_sequence"}, {"score": 0.0021649437083408425, "phrase": "real_interest"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["dynamic visual attention", " motion", " segmentation", " feature extraction", " feature integration"], "paper_abstract": "A new computational architecture of dynamic visual attention is introduced in this paper. Our approach defines a model for the generation of an active attention focus on a dynamic scene captured from a still or moving camera. The aim is to obtain the objects that keep the observer's attention in accordance with a set of predefined features, including color, motion and shape. The solution proposed to the selective visual attention problem consists in decomposing the input images of an indefinite sequence of images into its moving objects, by defining which of these elements are of the user's interest, and by keeping attention on those elements through time. Thus, the three tasks involved in the attention model are introduced. The Feature-Extraction task obtains those features (color, motion and shape features) necessary to perform object segmentation. The Attention-Capture task applies the criteria established by the user (values provided through parameters) to the extracted features and obtains the different parts of the objects of potential interest. Lastly, the Attention-Reinforcement task maintains attention on certain elements (or objects) of the image sequence that are of real interest. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Dynamic visual attention model in image sequences", "paper_id": "WOS:000245166200007"}