{"auto_keywords": [{"score": 0.049203403415225264, "phrase": "feature_analysis"}, {"score": 0.00481495049065317, "phrase": "image_feature_extraction"}, {"score": 0.004534517530868195, "phrase": "multimedia_data"}, {"score": 0.004192190072470619, "phrase": "object_recognition"}, {"score": 0.004153647187175639, "phrase": "image_annotation"}, {"score": 0.004096493540086106, "phrase": "multimedia_information_retrieval"}, {"score": 0.004002972723329302, "phrase": "considerable_work"}, {"score": 0.0037177622939493084, "phrase": "large-scale_datasets"}, {"score": 0.0036496814103475174, "phrase": "comparative_study"}, {"score": 0.003177154457204775, "phrase": "key_observations"}, {"score": 0.0029369970132915456, "phrase": "feature_extraction_principles"}, {"score": 0.002702415623060517, "phrase": "large_training_dataset"}, {"score": 0.002652878591019016, "phrase": "image_category"}, {"score": 0.0025329623864528317, "phrase": "category-prediction_accuracy"}, {"score": 0.002429668083484833, "phrase": "data-driven_approach"}, {"score": 0.0023198180380964305, "phrase": "algorithm's_confusion_matrix"}, {"score": 0.002266765479420981, "phrase": "fusion_algorithm"}, {"score": 0.002164264600379492, "phrase": "class-prediction_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Image annotation", " Image feature", " Web-scale", " Fusion"], "paper_abstract": "Feature analysis is the extraction and comparison of signals from multimedia data, which can subsequently be semantically analyzed. Feature analysis is the foundation of many multimedia computing tasks such as object recognition, image annotation, and multimedia information retrieval. In recent decades, considerable work has been devoted to the research of feature analysis. In this work, we use large-scale datasets to conduct a comparative study of four state-of-the-art, representative feature extraction algorithms: color-texture codebook (CT), SIFT codebook, HMAX, and convolutional networks (ConvNet). Our comparative evaluation demonstrates that different feature extraction algorithms enjoy their own advantages, and excel in different image categories. We provide key observations to explain where these algorithms excel and why. Based on these observations, we recommend feature extraction principles and identify several pitfalls for researchers and practitioners to avoid. Furthermore, we determine that in a large training dataset with more than 10,000 instances per image category, the four evaluated algorithms can converge to the same high level of category-prediction accuracy. This result supports the effectiveness of the data-driven approach. Finally, based on learned clues from each algorithm's confusion matrix, we devise a fusion algorithm to harvest synergies between these four algorithms and further improve class-prediction accuracy. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "A data-driven study of image feature extraction and fusion", "paper_id": "WOS:000340315600037"}