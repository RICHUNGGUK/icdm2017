{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "clustering_effectiveness"}, {"score": 0.004429388453288922, "phrase": "new_optimal_clustering_effectiveness_measure"}, {"score": 0.00390792986752692, "phrase": "single_optimal_cluster"}, {"score": 0.003685972800046028, "phrase": "hierarchical_clustering"}, {"score": 0.003279039724748895, "phrase": "optimal_combinations"}, {"score": 0.0032246835734680377, "phrase": "disjoint_clusters"}, {"score": 0.003092690568543981, "phrase": "hierarchical_structure"}, {"score": 0.002682917193736698, "phrase": "exact_solution"}, {"score": 0.002551612225562499, "phrase": "linear_time_algorithm"}, {"score": 0.0022886952510350416, "phrase": "overlapping_clusters"}, {"score": 0.0021049977753042253, "phrase": "greedy_algorithms"}], "paper_keywords": [""], "paper_abstract": "We propose a new optimal clustering effectiveness measure, called CS1, based on a combination of clusters rather than selecting a single optimal cluster as in the traditional MK1 measure. For hierarchical clustering, we present an algorithm to compute CS1, defined by seeking the optimal combinations of disjoint clusters obtained by cutting the hierarchical structure at a certain similarity level. By reformulating the optimization to a 0-1 linear fractional programming problem, we demonstrate that an exact solution can be obtained by a linear time algorithm. We further discuss how our approach can be generalized to more general problems involving overlapping clusters, and we show how optimal estimates can be obtained by greedy algorithms.", "paper_title": "A new measure of clustering effectiveness: Algorithms and experimental studies", "paper_id": "WOS:000252821600004"}