{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "kpca"}, {"score": 0.004701556483912018, "phrase": "gaussianity_estimation"}, {"score": 0.004627441072541506, "phrase": "kernel-based_principle_component_analysis"}, {"score": 0.004412000844879264, "phrase": "effective_feature_extraction_method"}, {"score": 0.00427410782586596, "phrase": "pca"}, {"score": 0.004206548500039536, "phrase": "nonlinear_cases"}, {"score": 0.004140203942496321, "phrase": "kernel_trick"}, {"score": 0.00385431710959668, "phrase": "pre-selected_parameter"}, {"score": 0.003503497128638099, "phrase": "kernel_parameter_optimisation_method"}, {"score": 0.0034208822062692127, "phrase": "principle_component"}, {"score": 0.0033937776228549557, "phrase": "subspace-based_gaussianity_estimation"}, {"score": 0.0032099453192629976, "phrase": "optimal_kernel_parameters"}, {"score": 0.0031342307827666675, "phrase": "mapped_feature_space"}, {"score": 0.0030602966787192745, "phrase": "gaussian_distribution"}, {"score": 0.002964415652865295, "phrase": "subspace_coordinates"}, {"score": 0.002917604283241353, "phrase": "feature_space"}, {"score": 0.0027815466400771768, "phrase": "mapping_data_problem"}, {"score": 0.0025687008721685454, "phrase": "gaussian_distribution_approximation_degree"}, {"score": 0.0024488738006005133, "phrase": "establishing_condition"}, {"score": 0.0024101837218440834, "phrase": "multidimensional_gaussian_distribution"}, {"score": 0.0023346234464901978, "phrase": "experiment_results"}, {"score": 0.002225691463551672, "phrase": "kernel_parameter_optimisation_algorithm"}, {"score": 0.0021049977753042253, "phrase": "real-world_data"}], "paper_keywords": ["optimisation", " principle component analysis", " feature space", " Gaussian distribution estimation", " Kernel parameter"], "paper_abstract": "Kernel-based principle component analysis (KPCA) is an effective feature extraction method. It extends PCA to nonlinear cases using kernel trick. The performance of KPCA relies on the pre-selected parameter of kernel function. In this paper, we propose a kernel parameter optimisation method by using principle component subspace-based Gaussianity estimation, based on the idea that optimal kernel parameters lead the mapped feature space close to Gaussian distribution. By using subspace coordinates in feature space generalised by KPCA, the mapping data problem is properly solved. Further, we estimate the Gaussian distribution approximation degree in subspace by using the establishing condition for multidimensional Gaussian distribution in statistics. Experiment results are shown to verify the kernel parameter optimisation algorithm by testing on both simulation and real-world data.", "paper_title": "Kernel optimisation for KPCA based on Gaussianity estimation", "paper_id": "WOS:000335497200002"}