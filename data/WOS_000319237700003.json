{"auto_keywords": [{"score": 0.04236164108815413, "phrase": "aann"}, {"score": 0.015719713042815744, "phrase": "nonlinear_system_modeling"}, {"score": 0.01457137650904662, "phrase": "network_architecture"}, {"score": 0.004633888966463624, "phrase": "dynamic_behaviors"}, {"score": 0.004575053987970206, "phrase": "neural_system"}, {"score": 0.004421770937919324, "phrase": "learning_process"}, {"score": 0.004328576620172571, "phrase": "artificial_neural_network"}, {"score": 0.004292105446274487, "phrase": "ann"}, {"score": 0.0042373381286051354, "phrase": "self-organizing_architecture"}, {"score": 0.0040779081518317415, "phrase": "automatic_axon-neural_network"}, {"score": 0.0037287578312533596, "phrase": "hidden_neurons"}, {"score": 0.0036501160751879784, "phrase": "neural_network"}, {"score": 0.0036037265181631324, "phrase": "training_process"}, {"score": 0.003512702405367876, "phrase": "adaptive_connecting-and-pruning_algorithm"}, {"score": 0.003482883670203578, "phrase": "acp"}, {"score": 0.003394891095032025, "phrase": "mixed_mode_operation"}, {"score": 0.003117307618682836, "phrase": "required_neurons"}, {"score": 0.0029617414861784525, "phrase": "feedforward_computation"}, {"score": 0.0029366279271774583, "phrase": "fc"}, {"score": 0.0027311076665349657, "phrase": "previous_studies"}, {"score": 0.0025291601927956765, "phrase": "network_performances"}, {"score": 0.002475755804232436, "phrase": "proposed_aann"}, {"score": 0.0023926387830753033, "phrase": "benchmark_problems"}, {"score": 0.00235213013487844, "phrase": "nonlinear_function"}, {"score": 0.0023221983158528163, "phrase": "nonlinear_systems_modeling"}, {"score": 0.0022926465161639633, "phrase": "experimental_results"}, {"score": 0.0022346638243276717, "phrase": "better_performances"}, {"score": 0.002187464225869713, "phrase": "existing_neural_networks"}, {"score": 0.0021688641066186817, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Automatic axon-neural network", " Adaptive connecting and pruning algorithm", " Modeling", " Feedforward computation", " Information theory"], "paper_abstract": "It has been shown extensively that the dynamic behaviors of a neural system are strongly influenced by the network architecture and learning process. To establish an artificial neural network (ANN) with self-organizing architecture and suitable learning algorithm for nonlinear system modeling, an automatic axon-neural network (AANN) is investigated in the following respects. First, the network architecture is constructed automatically to change both the number of hidden neurons and topologies of the neural network during the training process. The approach introduced in adaptive connecting-and-pruning algorithm (ACP) is a type of mixed mode operation, which is equivalent to pruning or adding the connecting of the neurons, as well as inserting some required neurons directly. Secondly, the weights are adjusted, using a feedforward computation (FC) to obtain the information for the gradient during learning computation. Unlike most of the previous studies, AANN is able to self-organize the architecture and weights, and to improve the network performances. Also, the proposed AANN has been tested on a number of benchmark problems, ranging from nonlinear function approximating to nonlinear systems modeling. The experimental results show that AANN can have better performances than that of some existing neural networks. Crown Copyright (c) 2013 Published by Elsevier Ltd. All rights reserved.", "paper_title": "Efficient self-organizing multilayer neural network for nonlinear system modeling", "paper_id": "WOS:000319237700003"}