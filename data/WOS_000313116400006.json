{"auto_keywords": [{"score": 0.04838919478929022, "phrase": "constrained_spaces"}, {"score": 0.045562301690922014, "phrase": "markov_boundary"}, {"score": 0.00481495049065317, "phrase": "markov_boundaries"}, {"score": 0.004521566043596533, "phrase": "probabilistic_classification_problems"}, {"score": 0.0042459818200777846, "phrase": "class_variable"}, {"score": 0.004096082254543022, "phrase": "optimal_approach"}, {"score": 0.004023120753104693, "phrase": "feature_subset_selection"}, {"score": 0.0035473867669654174, "phrase": "selected_variable"}, {"score": 0.0032132782979796895, "phrase": "bayesian_networks"}, {"score": 0.003071965703296204, "phrase": "standard_scoring_functions"}, {"score": 0.0027328817607818207, "phrase": "acyclic_graphs"}, {"score": 0.0022019274077124773, "phrase": "wide_spectrum"}], "paper_keywords": ["Feature subset selection", " Markov boundary", " Bayesian networks", " Local learning", " Score plus search"], "paper_abstract": "Within probabilistic classification problems, learning the Markov boundary of the class variable consists in the optimal approach for feature subset selection. In this paper we propose two algorithms that learn the Markov boundary of a selected variable. These algorithms are based on the score+search paradigm for learning Bayesian networks. Both algorithms use standard scoring functions but they perform the search in constrained spaces of class-focused directed acyclic graphs, going through the space by means of operators adapted for the problem. The algorithms have been validated experimentally by using a wide spectrum of databases, and their results show a performance competitive with the state-of-the-art.", "paper_title": "Score-based methods for learning Markov boundaries by searching in constrained spaces", "paper_id": "WOS:000313116400006"}