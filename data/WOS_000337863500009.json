{"auto_keywords": [{"score": 0.03622410301658812, "phrase": "spectral_dictionary"}, {"score": 0.03581429241725392, "phrase": "spatial-detail_dictionary"}, {"score": 0.00481495049065317, "phrase": "multispectral_and_panchromatic_images"}, {"score": 0.004721602309430702, "phrase": "local_autoregressive_model"}, {"score": 0.004214637810698362, "phrase": "observed_images"}, {"score": 0.004084584884062157, "phrase": "unknown_firms_image"}, {"score": 0.004036852178449883, "phrase": "restoration_model"}, {"score": 0.003927765465842966, "phrase": "firms"}, {"score": 0.00385141330111392, "phrase": "employed_sparse_domain"}, {"score": 0.003776674472150248, "phrase": "new_sparse_representation_model"}, {"score": 0.003732526540522333, "phrase": "firms_image"}, {"score": 0.003589046900483573, "phrase": "low-frequency_and_high-frequency_components"}, {"score": 0.003547085511662278, "phrase": "hrms"}, {"score": 0.0032539388572032563, "phrase": "source_images"}, {"score": 0.0028588847851995533, "phrase": "spatial_structure"}, {"score": 0.002825435048559866, "phrase": "hrms_image_patch"}, {"score": 0.002748895580860912, "phrase": "ar_model_parameters"}, {"score": 0.0026954938318408464, "phrase": "pan_image_patches"}, {"score": 0.0026431267487109543, "phrase": "local_spatial_structure"}, {"score": 0.0025614418906438744, "phrase": "ar_model"}, {"score": 0.002531463482341473, "phrase": "learned_parameters"}, {"score": 0.0024150092189446424, "phrase": "hrms_image"}, {"score": 0.0023039008264052405, "phrase": "quickbird"}, {"score": 0.0022414566728770745, "phrase": "simulated_and_real_experiments"}, {"score": 0.0021721582450016, "phrase": "visual_analysis"}, {"score": 0.0021551702945512494, "phrase": "quantitative_evaluation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Fusion", " Multispectral (MS)", " Panchromatic (PAN)", " Sparse representation", " Local autoregressive model (AR)"], "paper_abstract": "In this paper, a novel model-based pan-sharpening method via sparse representation and local autoregressive (AR) model is proposed. To recover the high-resolution multispectral (HRMS) image from the observed images, we impose sparsity prior on the unknown FIRMS image in the restoration model. The quality of the recovered FIRMS image depends on the employed sparse domain. Hence, a new sparse representation model for the FIRMS image is constructed, in which we suppose that the low-frequency and high-frequency components of the HRMS image can be sparsely represented by a spectral dictionary and a spatial-detail dictionary respectively. The spectral dictionary and spatial-detail dictionary are learned from the source images: low-spatial-resolution multispectral (LRMS) image and high-spatial-resolution panchromatic (HRP) image adaptively. Additionally, local autoregressive (AR) model is employed to improve the spatial structure of the HRMS image patch. Firstly, a set of AR model parameters are learned from the PAN image patches. Then, the local spatial structure of a given HRMS image patch is regularized by an AR model with the learned parameters. By solving the l(1) -norm optimization problem, the HRMS image can be well reconstructed. Experiments are carried out on very high-resolution QuickBird and GeoEye-1 images. In the simulated and real experiments, our proposed method demonstrates its good performance in terms of visual analysis and quantitative evaluation. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Fusion of multispectral and panchromatic images via sparse representation and local autoregressive model", "paper_id": "WOS:000337863500009"}