{"auto_keywords": [{"score": 0.049596205816074275, "phrase": "human_action_recognition"}, {"score": 0.036480295477136625, "phrase": "action_representation"}, {"score": 0.00481495049065317, "phrase": "structural_features"}, {"score": 0.004530794611704416, "phrase": "structural_information"}, {"score": 0.0043506951029334984, "phrase": "local_representations"}, {"score": 0.004285010985001827, "phrase": "detected_spatio-temporal_interest_points"}, {"score": 0.004073113268289532, "phrase": "important_cues"}, {"score": 0.004032002950217453, "phrase": "motion_structures"}, {"score": 0.003991305899593133, "phrase": "video_sequences"}, {"score": 0.0038520615699124123, "phrase": "complementary_information"}, {"score": 0.0033759367489122716, "phrase": "previous_work"}, {"score": 0.0032415934630668484, "phrase": "optimised_version"}, {"score": 0.003144345057121367, "phrase": "layout_information"}, {"score": 0.0028263192354046245, "phrase": "action_classification"}, {"score": 0.0027554538693034163, "phrase": "proposed_descriptor"}, {"score": 0.0026863605504566924, "phrase": "extensive_experiments"}, {"score": 0.00264574778810568, "phrase": "kth"}, {"score": 0.0026057256900479026, "phrase": "ucf_youtube_datasets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Human action recognition", " Spatio-temporal interest points", " Bag of words", " 3D shape context", " Feature combination", " Structural features"], "paper_abstract": "In this paper, we propose to integrate structural information with appearance features for human action recognition. In local representations based on detected spatio-temporal interest points (STIPs), the layout of STIPs carries important cues of motion structures in video sequences, and is assumed to contain complementary information to appearance features. We aim to incorporate structures into the description of STIPs by combing with appearance features for action representation. Based on the previous work of the 3D shape context, we present an optimised version of 3D shape context to encode the layout information of STIPs. By combining the proposed optimised 3D shape context with appearance descriptors, e.g., HOG3D and 3D gradients, we provide a more informative and discriminative description of STIPs for action classification. To validate the proposed descriptor, we have conducted extensive experiments on the KTH and the UCF YouTube datasets. The results prove that the optimised 3D shape context offers complementary information to appearance features, showing its effectiveness for action representation; moreover, the proposed descriptor yields comparable results with the state-of-the-art methods. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Combining appearance and structural features for human action recognition", "paper_id": "WOS:000319952700009"}