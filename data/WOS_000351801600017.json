{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "posterior_distribution_learning"}, {"score": 0.04712665802421912, "phrase": "unlabeled_samples"}, {"score": 0.044340662163821175, "phrase": "data_space"}, {"score": 0.04312685577856799, "phrase": "labeled_samples"}, {"score": 0.004440780432053927, "phrase": "classification_performance"}, {"score": 0.004339293854115301, "phrase": "supervised_model"}, {"score": 0.004289419884432487, "phrase": "good_generalization_ability"}, {"score": 0.004167218012926657, "phrase": "tiny_number"}, {"score": 0.0036907133026806327, "phrase": "labeling_process"}, {"score": 0.0034233569308012982, "phrase": "new_supervised_two-step_learning_framework"}, {"score": 0.0032309093154028663, "phrase": "robust_supervised_model"}, {"score": 0.0031026497891826726, "phrase": "new_constrained_graph_method"}, {"score": 0.003031650815900696, "phrase": "posterior_probability"}, {"score": 0.0028446460307503343, "phrase": "real_function_regression_model"}, {"score": 0.002795671770303977, "phrase": "vector-valued_function_model"}, {"score": 0.00273167822885383, "phrase": "nonlinear_function"}, {"score": 0.0026846436189970446, "phrase": "posterior_probability_distribution"}, {"score": 0.0026384167183586015, "phrase": "input_data_space"}, {"score": 0.0025780134737796085, "phrase": "traditional_supervised_learning_method"}, {"score": 0.0025483432276129855, "phrase": "pdl"}, {"score": 0.002447101794397243, "phrase": "training_samples"}, {"score": 0.002349884235026956, "phrase": "nonlinear_manifold_classification"}, {"score": 0.0023228223366301226, "phrase": "experimental_results"}, {"score": 0.0021794454466797382, "phrase": "proposed_supervised_architecture"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Supervised learning", " Posterior Distribution Learning", " Supervised manifold classification"], "paper_abstract": "Building a supervised model with good generalization ability in data space using a tiny number of labeled samples is always practically significant and attractive, because labeled samples are generally very expensive to obtain, as the labeling process usually takes much time and resource. In this paper we propose a new supervised two-step learning framework, Posterior Distribution Learning (PDL), to build a robust supervised model in data space by first describing a new constrained graph method to estimate the posterior probability of the unlabeled samples in learning set and then extending a real function regression model to a vector-valued function model to fit a nonlinear function for the posterior probability distribution in the input data space. Compared with traditional supervised learning method, PDL can significantly reduce the demand upon training samples and exhibits the potential to perform nonlinear manifold classification. Experimental results on both synthetic and real world data sets are presented to demonstrate the validity of the proposed supervised architecture. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Posterior Distribution Learning (PDL): A novel supervised learning framework using unlabeled samples to improve classification performance", "paper_id": "WOS:000351801600017"}