{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "hessian"}, {"score": 0.04649805083663778, "phrase": "linear_vector_gaussian_channels"}, {"score": 0.029664823555633206, "phrase": "mutual_information"}, {"score": 0.004732785510739708, "phrase": "concavity_of_mutual_information"}, {"score": 0.004652016085325825, "phrase": "differential_entropy"}, {"score": 0.004533427352547707, "phrase": "entropy_power"}, {"score": 0.003916098498242888, "phrase": "minimum_mean_square_error"}, {"score": 0.00384960457891634, "phrase": "fisher"}, {"score": 0.0036553070575015344, "phrase": "arbitrary_parameters"}, {"score": 0.003296212583539166, "phrase": "prior_research"}, {"score": 0.003157174936641705, "phrase": "square_error"}, {"score": 0.0031032109441552287, "phrase": "fisher_information_matrices"}, {"score": 0.0029980260560551982, "phrase": "information-theoretic_quantities"}, {"score": 0.0024586427394152196, "phrase": "concavity_properties"}, {"score": 0.0023346234464901978, "phrase": "different_channel_conditions"}, {"score": 0.0022168460543913787, "phrase": "multivariate_version"}, {"score": 0.0021601997088758957, "phrase": "entropy_power_inequality"}, {"score": 0.0021050156432688392, "phrase": "costa"}], "paper_keywords": ["Concavity properties", " differential entropy", " entropy power", " Fisher information matrix", " Gaussian noise", " Hessian matrices", " linear vector Gaussian channels", " minimum mean-square error (MMSE)", " mutual information", " nonlinear estimation"], "paper_abstract": "Within the framework of linear vector Gaussian channels with arbitrary signaling, the Jacobian of the minimum mean square error and Fisher information matrices with respect to arbitrary parameters of the system are calculated in this paper. Capitalizing on prior research where the minimum mean square error and Fisher information matrices were linked to information-theoretic quantities through differentiation, the Hessian of the mutual information and the entropy are derived. These expressions are then used to assess the concavity properties of mutual information and entropy under different channel conditions and also to derive a multivariate version of an entropy power inequality due to Costa.", "paper_title": "Hessian and Concavity of Mutual Information, Differential Entropy, and Entropy Power in Linear Vector Gaussian Channels", "paper_id": "WOS:000268107200017"}