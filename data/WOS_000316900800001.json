{"auto_keywords": [{"score": 0.030872167073125734, "phrase": "novel_images"}, {"score": 0.02793829552192061, "phrase": "local_features"}, {"score": 0.00481495049065317, "phrase": "unsupervised_discovery_of_visual"}, {"score": 0.0047979812040897275, "phrase": "face_categories._human"}, {"score": 0.00469740813902244, "phrase": "different_face_categories"}, {"score": 0.004631527916092452, "phrase": "common_visual_cues"}, {"score": 0.004377077848734575, "phrase": "face_categorization"}, {"score": 0.004330941610682453, "phrase": "precursor_step"}, {"score": 0.004255121395629569, "phrase": "recognition_rates"}, {"score": 0.004092937456065441, "phrase": "common_visual_cues_yields"}, {"score": 0.00385431710959668, "phrase": "overall_number"}, {"score": 0.0038271712887391015, "phrase": "possible_face_categories"}, {"score": 0.0037336520904376687, "phrase": "unbalanced_face_categories"}, {"score": 0.003681238363808568, "phrase": "recognition_performance"}, {"score": 0.0035283552859817764, "phrase": "human_faces"}, {"score": 0.003466536738232506, "phrase": "unlabeled_face"}, {"score": 0.0034057975804778293, "phrase": "predefined_visual_cues"}, {"score": 0.003310813458610484, "phrase": "face_images"}, {"score": 0.0032527939106509946, "phrase": "known_individuals"}, {"score": 0.0030738557655525913, "phrase": "gallery_set"}, {"score": 0.002793874145713024, "phrase": "correct_face_category"}, {"score": 0.0027741761880779535, "phrase": "high_accuracy"}, {"score": 0.002687235334499192, "phrase": "face_category_discovery"}, {"score": 0.002603012037901889, "phrase": "unsupervised_learning"}, {"score": 0.002468450551616404, "phrase": "nearest-neighbor_algorithms"}, {"score": 0.002433754579432554, "phrase": "separating_boundaries"}, {"score": 0.00241658945942583, "phrase": "face_categories"}, {"score": 0.0023995451127366983, "phrase": "supervised_learning"}, {"score": 0.00232431758517087, "phrase": "face_categorization_robustness"}, {"score": 0.002157811371348755, "phrase": "proposed_approach"}, {"score": 0.0021425882815624803, "phrase": "extensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "feret_database"}], "paper_keywords": ["Face categorization", " face recognition", " local features", " clustering", " classification"], "paper_abstract": "Human faces can be arranged into different face categories using information from common visual cues such as gender, ethnicity, and age. It has been demonstrated that using face categorization as a precursor step to face recognition improves recognition rates and leads to more graceful errors. 1 Although face categorization using common visual cues yields meaningful face categories, developing accurate and robust gender, ethnicity, and age categorizers is a challenging issue. Moreover, it limits the overall number of possible face categories and, in practice, yields unbalanced face categories which can compromise recognition performance. This paper investigates ways to automatically discover a categorization of human faces from a collection of unlabeled face images without relying on predefined visual cues. Specifically, given a set of face images from a group of known individuals (i.e., gallery set), our goal is finding ways to robustly partition the gallery set (i.e., face categories). The objective is being able to assign novel images of the same individuals (i.e., query set) to the correct face category with high accuracy and robustness. To address the issue of face category discovery, we represent faces using local features and apply unsupervised learning (i.e., clustering). To categorize faces in novel images, we employ nearest-neighbor algorithms or learn the separating boundaries between face categories using supervised learning (i.e., classification). To improve face categorization robustness, we allow face categories to share local features as well as to overlap. We demonstrate the performance of the proposed approach through extensive experiments and comparisons using the FERET database.", "paper_title": "UNSUPERVISED DISCOVERY OF VISUAL FACE CATEGORIES", "paper_id": "WOS:000316900800001"}