{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "genetic_algorithm"}, {"score": 0.04856860260919925, "phrase": "unlabeled_data_points"}, {"score": 0.044142808729772144, "phrase": "higher_classification_accuracy"}, {"score": 0.04309795273052841, "phrase": "traditional_ssls"}, {"score": 0.031063976447588744, "phrase": "cluster_assumption"}, {"score": 0.02928440808154909, "phrase": "cluster_configuration_problems"}, {"score": 0.004797835176186123, "phrase": "classifier_system"}, {"score": 0.004763785973620115, "phrase": "semi-supervised_learning._real-world_datasets"}, {"score": 0.004580769304731227, "phrase": "additional_cost"}, {"score": 0.0044047788894179705, "phrase": "ssl"}, {"score": 0.004326987090971404, "phrase": "labeled_and_unlabeled_data_points"}, {"score": 0.0039723268236794935, "phrase": "smoothness_assumption"}, {"score": 0.003944112858235306, "phrase": "neighboring_points"}, {"score": 0.0037789720824759503, "phrase": "unlabeled_points"}, {"score": 0.003685840071638243, "phrase": "final_classifier"}, {"score": 0.003633652174971415, "phrase": "ssl_approach"}, {"score": 0.0032650443509355627, "phrase": "ctl"}, {"score": 0.0025434384320561403, "phrase": "new_framework"}, {"score": 0.0023769489045048285, "phrase": "ga"}, {"score": 0.002359759876402679, "phrase": "irrelevant_attributes"}, {"score": 0.002150580119047236, "phrase": "comparable_or_higher_accuracy"}], "paper_keywords": ["semi-supervised learning", " cluster-then-label", " unsupervised clustering", " genetic algorithm"], "paper_abstract": "Real-world datasets often contain large numbers of unlabeled data points, because there is additional cost for obtaining the labels. Semi-supervised learning (SSL) algorithms use both labeled and unlabeled data points for training that can result in higher classification accuracy on these datasets. Generally, traditional SSLs tentatively label the unlabeled data points on the basis of the smoothness assumption that neighboring points should have the same label. When this assumption is violated, unlabeled points are mislabeled injecting noise into the final classifier. An alternative SSL approach is cluster-then-label (CTL), which partitions all the data points (labeled and unlabeled) into clusters and creates a classifier by using those clusters. CTL is based on the less restrictive cluster assumption that data points in the same cluster should have the same label. As shown, this allows CTLs to achieve higher classification accuracy on many datasets where the cluster assumption holds for the CTLs, but smoothness does not hold for the traditional SSLs. However, cluster configuration problems (e.g., irrelevant features, insufficient clusters, and incorrectly shaped clusters) could violate the cluster assumption. We propose a new framework for CTLs by using a genetic algorithm (GA) to evolve classifiers without the cluster configuration problems (e.g., the GA removes irrelevant attributes, updates number of clusters, and changes the shape of the clusters). We demonstrate that a CTL based on this framework achieves comparable or higher accuracy with both traditional SSLs and CTLs on 12 University of California, Irvine machine learning datasets.", "paper_title": "GENETIC ALGORITHM CLASSIFIER SYSTEM FOR SEMI-SUPERVISED LEARNING", "paper_id": "WOS:000354136500001"}