{"auto_keywords": [{"score": 0.04804050199975018, "phrase": "automated_test_data_generation"}, {"score": 0.00481495049065317, "phrase": "empirical_investigation"}, {"score": 0.004768649568826951, "phrase": "branch_coverage"}, {"score": 0.004722791767189843, "phrase": "c_programs"}, {"score": 0.004677372885331908, "phrase": "cute"}, {"score": 0.004632388761885302, "phrase": "austin."}, {"score": 0.004478308876320956, "phrase": "considerable_interest"}, {"score": 0.0041450181887917135, "phrase": "software_testing"}, {"score": 0.0039685202936462815, "phrase": "empirical_study"}, {"score": 0.003911367220315185, "phrase": "dynamic_symbolic-execution_tool"}, {"score": 0.0037267326904533767, "phrase": "austin"}, {"score": 0.0036908381347418805, "phrase": "five_non-trivial_open_source_applications"}, {"score": 0.003399466007862412, "phrase": "existing_techniques"}, {"score": 0.003270396852243212, "phrase": "baseline_data"}, {"score": 0.0031922210879462513, "phrase": "subsequent_work"}, {"score": 0.002801166393333128, "phrase": "subject_programs"}, {"score": 0.0027341763737751467, "phrase": "mere_fact"}, {"score": 0.0025059724686541263, "phrase": "growing_maturity"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Automated test data generation", " Search based testing", " Concolic testing", " Symbolic execution"], "paper_abstract": "Automated test data generation has remained a topic of considerable interest for several decades because it lies at the heart of attempts to automate the process of Software Testing. This paper reports the results of an empirical study using the dynamic symbolic-execution tool. CUTE, and a search based tool, AUSTIN on five non-trivial open source applications. The aim is to provide practitioners with an assessment of what can be achieved by existing techniques with little or no specialist knowledge and to provide researchers with baseline data against which to measure subsequent work. To achieve this, each tool is applied 'as is', with neither additional tuning nor supporting harnesses and with no adjustments applied to the subject programs under test. The mere fact that these tools can be applied 'out of the box' in this manner reflects the growing maturity of Automated test data generation. However, as might be expected, the study reveals opportunities for improvement and suggests ways to hybridize these two approaches that have hitherto been developed entirely independently. (C) 2010 Elsevier Inc. All rights reserved.", "paper_title": "An empirical investigation into branch coverage for C programs using CUTE and AUSTIN", "paper_id": "WOS:000284674200003"}