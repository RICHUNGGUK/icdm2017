{"auto_keywords": [{"score": 0.02921737138023634, "phrase": "process_models"}, {"score": 0.01639763445329316, "phrase": "event_data"}, {"score": 0.00481495049065317, "phrase": "good_process"}, {"score": 0.004673530058379246, "phrase": "never_ending_stream"}, {"score": 0.004633888966463624, "phrase": "new_process"}, {"score": 0.004273614150823741, "phrase": "petri"}, {"score": 0.00397495478332679, "phrase": "short_while"}, {"score": 0.003760685138103153, "phrase": "good_process_model"}, {"score": 0.0036657110980445416, "phrase": "large_scale_experiences"}, {"score": 0.0034977560416755726, "phrase": "process_mining_techniques"}, {"score": 0.0033517342967390065, "phrase": "discover_models"}, {"score": 0.0032531496610470377, "phrase": "measure_conformance"}, {"score": 0.003157455511069507, "phrase": "future_events"}, {"score": 0.003130633384437765, "phrase": "today's_processes"}, {"score": 0.0030776686414001964, "phrase": "data_bases"}, {"score": 0.0030515222178491923, "phrase": "audit_trails"}, {"score": 0.003025597247856977, "phrase": "message_logs"}, {"score": 0.0029998918671747168, "phrase": "transaction_logs"}, {"score": 0.002696366237523415, "phrase": "actual_behavior"}, {"score": 0.0025183881730011597, "phrase": "checking_techniques"}, {"score": 0.0024863459251358217, "phrase": "important_deviations"}, {"score": 0.00235213013487844, "phrase": "process_mining"}, {"score": 0.0023221983158528163, "phrase": "new_light"}, {"score": 0.0023024551893939403, "phrase": "process_model_quality"}, {"score": 0.0021968238865548812, "phrase": "seven_problems"}], "paper_keywords": ["Process mining", " Process modeling", " Process model quality"], "paper_abstract": "There seems to be a never ending stream of new process modeling notations. Some of these notations are foundational and have been around for decades (e.g., Petri nets). Other notations are vendor specific, incremental, or are only popular for a short while. Discussions on the various competing notations concealed the more important question \"What makes a good process model?\". Fortunately, large scale experiences with process mining allow us to address this question. Process mining techniques can be used to extract knowledge from event data, discover models, align logs and models, measure conformance, diagnose bottlenecks, and predict future events. Today's processes leave many trails in data bases, audit trails, message logs, transaction logs, etc. Therefore, it makes sense to relate these event data to process models independent of their particular notation. Process models discovered based on the actual behavior tend to be very different from the process models made by humans. Moreover, conformance checking techniques often reveal important deviations between models and reality. The lessons that can be learned from process mining shed a new light on process model quality. This paper discusses the role of process models and lists seven problems related to process modeling. Based on our experiences in over 100 process mining projects, we discuss these problems. Moreover, we show that these problems can be addressed by exposing process models and modelers to event data.", "paper_title": "What makes a good process model?", "paper_id": "WOS:000310087500009"}