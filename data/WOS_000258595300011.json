{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "echocardiogram_video"}, {"score": 0.04621807134587006, "phrase": "video_segments"}, {"score": 0.004636594774238505, "phrase": "hierarchical_state-based_model"}, {"score": 0.004390517953424082, "phrase": "dynamic_characteristics"}, {"score": 0.004157446556371582, "phrase": "effective_method"}, {"score": 0.0040882422992520925, "phrase": "echo_video"}, {"score": 0.0038549394272661356, "phrase": "efficient_indexing_tools"}, {"score": 0.0038066979615349822, "phrase": "better_content_management"}, {"score": 0.003398714712611042, "phrase": "view_classification"}, {"score": 0.0033561632967173856, "phrase": "artificial_neural_network"}, {"score": 0.0031778255332904487, "phrase": "video_frame"}, {"score": 0.0031512402798625056, "phrase": "object_states"}, {"score": 0.003059925849144792, "phrase": "synthetic_m-mode_images"}, {"score": 0.00299632091372281, "phrase": "traditional_single_m-mode"}, {"score": 0.0029340342068081247, "phrase": "novel_approach"}, {"score": 0.00284899583294417, "phrase": "state_detection"}, {"score": 0.002789763110395331, "phrase": "radial_m-mode"}, {"score": 0.0026975346834867335, "phrase": "video_model"}, {"score": 0.0025974077149412, "phrase": "first-order_predicates"}, {"score": 0.0023481578019624843, "phrase": "manual_annotation"}, {"score": 0.002289667393538803, "phrase": "classification_accuracy"}, {"score": 0.0022420373745572837, "phrase": "misclassification_error"}, {"score": 0.0022139352210982398, "phrase": "state_detection_stage"}, {"score": 0.002149722786728988, "phrase": "acceptable_range"}, {"score": 0.0021049977753042253, "phrase": "state_boundaries"}], "paper_keywords": ["color flow imaging", " echocardiogram", " radial M-mode", " state-based modeling", " sweep M-mode", " video calculus", " video database"], "paper_abstract": "In this paper, we propose a hierarchical state-based model for representing an echocardiogram video. It captures the semantics of video segments from dynamic characteristics of objects present in each segment. Our objective is to provide an effective method for segmenting an echo video into view, state, and substate levels. This is motivated by the need for building efficient indexing tools to support better content management. The modeling is done using four different views, namely, short axis, long axis, apical four chamber, and apical two chamber. For view classification, an artificial neural network is trained with the histogram of a region of interest of each video frame. Object states are detected with the help of synthetic M-mode images. In contrast to traditional single M-mode, we present a novel approach named sweep M-mode for state detection. We also introduce radial M-mode for substate identification from color flow Doppler 2-D imaging. The video model described here represents the semantics of video segments using first-order predicates. Suitable operators have been defined for querying the segments. We have carried out experiments on 20 echo videos and compared the results with manual annotation done by two experts. View classification accuracy is. 97.19%. Misclassification error of the state detection stage is less than 13%, which is within acceptable range since only frames at the state boundaries are found to be misclassified.", "paper_title": "State-based modeling and object extraction from echocardiogram video", "paper_id": "WOS:000258595300011"}