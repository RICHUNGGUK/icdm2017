{"auto_keywords": [{"score": 0.04008010591131816, "phrase": "creative_autonomy"}, {"score": 0.00481495049065317, "phrase": "artificial_intelligence"}, {"score": 0.004682708592184678, "phrase": "greatest_rhetorical_challenge"}, {"score": 0.0045119929871912405, "phrase": "creative_artificial_intelligence_systems"}, {"score": 0.003140401552000472, "phrase": "explicit_direction"}, {"score": 0.0030257422786589723, "phrase": "necessary_condition"}, {"score": 0.0025355968118803956, "phrase": "human_influence"}, {"score": 0.0021445492649196955, "phrase": "broader_society"}], "paper_keywords": ["Computational creativity", " Autonomy", " Socially-inspired computing"], "paper_abstract": "The greatest rhetorical challenge to developers of creative artificial intelligence systems is convincingly arguing that their software is more than just an extension of their own creativity. This paper suggests that \"creative autonomy,\" which exists when a system not only evaluates creations on its own, but also changes its standards without explicit direction, is a necessary condition for making this argument. Rather than requiring that the system be hermetically sealed to avoid perceptions of human influence, developing creative autonomy is argued to be more plausible if the system is intimately embedded in a broader society of other creators and critics. Ideas are presented for constructing systems that might be able to achieve creative autonomy.", "paper_title": "Developing Creativity: Artificial Barriers in Artificial Intelligence", "paper_id": "WOS:000284546600002"}