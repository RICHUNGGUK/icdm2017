{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dynamic_optimization"}, {"score": 0.020324105253938015, "phrase": "mepso"}, {"score": 0.008614396860967061, "phrase": "dynamic_environments"}, {"score": 0.005848819135211159, "phrase": "ii"}, {"score": 0.004705332186103205, "phrase": "real-world_applications"}, {"score": 0.004638085752617182, "phrase": "optimization_algorithms"}, {"score": 0.004198673658751342, "phrase": "dynamic_rastrigin_function"}, {"score": 0.00415732498274046, "phrase": "good_balance"}, {"score": 0.003890811062960818, "phrase": "pso"}, {"score": 0.0034671773098114192, "phrase": "new_multistrategy_ensemble_particle_swarm_optimization"}, {"score": 0.0031713536750056534, "phrase": "gaussian"}, {"score": 0.003036545541805334, "phrase": "experimental_analyses"}, {"score": 0.0029332611651817528, "phrase": "convergence_ability"}, {"score": 0.002817181909556205, "phrase": "searching_area"}, {"score": 0.0027929100418926725, "phrase": "particle_population"}, {"score": 0.002591101181961524, "phrase": "whole_algorithm"}, {"score": 0.002403839385995682, "phrase": "mqso"}, {"score": 0.002335465722613665, "phrase": "moving_peaks"}, {"score": 0.002295376442690866, "phrase": "experimental_results"}, {"score": 0.002262493690015901, "phrase": "pretty_good_performance"}, {"score": 0.0022494725694725244, "phrase": "almost_all_testing_problems"}, {"score": 0.0021791815390109744, "phrase": "dynamic_environment"}, {"score": 0.0021171843749653455, "phrase": "great_number"}, {"score": 0.0021049977753042253, "phrase": "local_optima"}], "paper_keywords": ["dynamic optimization", " multi-strategy ensemble", " particle swarm optimization", " Gaussian local search", " differential mutation"], "paper_abstract": "Optimization in dynamic environments is important in real-world applications, which requires the optimization algorithms to be able to find and track the changing optimum efficiently over time. Among various algorithms for dynamic optimization, particle swarm optimization algorithms (PSOs) are attracting more and more attentions in recent years, due to their ability of keeping good balance between convergence and diversity maintenance. To tackle the challenges of dynamic optimization, several strategies have been proposed to enhance the performance of PSO, and have gained success on various dynamic optimization problems. But there still exist some issues in dynamic optimization which need to be studied carefully, i.e. the robustness of the algorithm to problems of various dynamic features. In this paper, a new multistrategy ensemble particle swarm optimization (MEPSO) for dynamic optimization is proposed. In MEPSO, all particles are divided into two parts, denoted as part I and part II, respectively. Two new strategies, Gaussian local search and differential mutation, are introduced into these two parts, respectively. Experimental analyses reveal that the mechanisms used in part I can enhance the convergence ability of the algorithm, while mechanisms used in part II can extend the searching area of the particle population to avoid being trapped into the local optimum, and can enhance the ability of catching up with the changing optimum in dynamic environments. The whole algorithm has few parameters that need to be tuned, and all of them are not sensitive to problems. We compared MEPSO with other PSOs, including MQSO, PHPSO and Standard PSO with re-initialization, on moving peaks Benchmark and dynamic Rastrigin function. The experimental results show that MEPSO has pretty good performance on almost all testing problems adopted in this paper, and outperforms other algorithms when the dynamic environment is unimodal and changes severely, or has a great number of local optima as dynamic Rastrigin function does. (c) 2008 Elsevier Inc. All rights reserved.", "paper_title": "Multi-strategy ensemble particle swarm optimization for dynamic optimization", "paper_id": "WOS:000257404100007"}