{"auto_keywords": [{"score": 0.049404922364310655, "phrase": "imagenet"}, {"score": 0.00481495049065317, "phrase": "imagenet_auto-annotation"}, {"score": 0.004780926543714981, "phrase": "segmentation_propagation"}, {"score": 0.004696909870731282, "phrase": "large-scale_hierarchical_database"}, {"score": 0.004437807397753662, "phrase": "pixelwise_object-background_segmentations"}, {"score": 0.004375286710337962, "phrase": "existing_manual_annotations"}, {"score": 0.004298367681427065, "phrase": "class_labels"}, {"score": 0.004207840198934805, "phrase": "key_idea"}, {"score": 0.004003925104720979, "phrase": "new_images"}, {"score": 0.0039195744361570075, "phrase": "propagation_process"}, {"score": 0.0036251554804124066, "phrase": "semantically_most_related_classes"}, {"score": 0.003400736815046841, "phrase": "image_level"}, {"score": 0.0033527773742790695, "phrase": "existing_segmentations"}, {"score": 0.0031451673059794236, "phrase": "class_level"}, {"score": 0.0030032443093632125, "phrase": "appearance_models"}, {"score": 0.002767613012044169, "phrase": "wide_range"}, {"score": 0.002728557856380231, "phrase": "accurate_segmentations"}, {"score": 0.00265208877121581, "phrase": "hierarchical_structure"}, {"score": 0.00240089402509933, "phrase": "image_center"}, {"score": 0.002325306388085057, "phrase": "fixed_source_pool"}, {"score": 0.0022762383517229957, "phrase": "target_image"}, {"score": 0.002260112998123604, "phrase": "kuettel"}, {"score": 0.002244120335686525, "phrase": "ferrari"}, {"score": 0.0021049977753042253, "phrase": "recent_icoseg_dataset"}], "paper_keywords": ["Figure-ground segmentation", " ImageNet", " Knowledge transfer", " Object localization", " Large-scale computer vision"], "paper_abstract": "ImageNet is a large-scale hierarchical database of object classes with millions of images. We propose to automatically populate it with pixelwise object-background segmentations, by leveraging existing manual annotations in the form of class labels and bounding-boxes. The key idea is to recursively exploit images segmented so far to guide the segmentation of new images. At each stage this propagation process expands into the images which are easiest to segment at that point in time, e. g. by moving to the semantically most related classes to those segmented so far. The propagation of segmentation occurs both (a) at the image level, by transferring existing segmentations to estimate the probability of a pixel to be foreground, and (b) at the class level, by jointly segmenting images of the same class and by importing the appearance models of classes that are already segmented. Through experiments on 577 classes and 500k images we show that our technique (i) annotates a wide range of classes with accurate segmentations; (ii) effectively exploits the hierarchical structure of ImageNet; (iii) scales efficiently, especially when implemented on superpixels; (iv) outperforms a baselineGrabCut (Rother et al. 2004) initialized on the image center, as well as segmentation transfer from a fixed source pool and run independently on each target image (Kuettel and Ferrari 2012). Moreover, our method also delivers state-of-the-art results on the recent iCoseg dataset for co-segmentation.", "paper_title": "ImageNet Auto-Annotation with Segmentation Propagation", "paper_id": "WOS:000344754500007"}