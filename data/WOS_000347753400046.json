{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "self-organizing_maps"}, {"score": 0.004386887374401584, "phrase": "squared_error"}, {"score": 0.004043541331944951, "phrase": "poor_performance"}, {"score": 0.0035989687070420977, "phrase": "robust_m-estimators"}, {"score": 0.0033952989364738353, "phrase": "least_squares"}, {"score": 0.003129317057177867, "phrase": "new_learning_rules"}, {"score": 0.002884111441153185, "phrase": "original_kohonen's_sofm_learning_rule"}, {"score": 0.0026892447164623247, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Self-organizing maps", " M-estimators", " Robust statistics", " Multivariate data visualization", " Image segmentation"], "paper_abstract": "Most of the work done on self-organizing maps relies on the minimization of the mean squared error. This nonrobust approach leads to poor performance in the presence of outliers. Here we consider robust M-estimators as an alternative for least squares in the context of self-organization. New learning rules are derived, so that the original Kohonen's SOFM learning rule is a particular case. Experimental results are presented which demonstrate the robustness of our method against outliers, when compared to other robust self-organizing maps. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Robust self-organization with M-estimators", "paper_id": "WOS:000347753400046"}