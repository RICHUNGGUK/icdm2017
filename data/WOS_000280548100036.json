{"auto_keywords": [{"score": 0.03970543330650032, "phrase": "hybrid_use"}, {"score": 0.00481495049065317, "phrase": "dominant_factors"}, {"score": 0.004687305496643216, "phrase": "high-performance_computing_systems"}, {"score": 0.0045324756541157574, "phrase": "negative_impact"}, {"score": 0.004209539728590977, "phrase": "asynchronous_communication_primitives"}, {"score": 0.0040978781692373005, "phrase": "code_complexity"}, {"score": 0.003729920506452605, "phrase": "mpi"}, {"score": 0.002830757050018908, "phrase": "high-performance_linpack_benchmark"}, {"score": 0.002646501671714952, "phrase": "pure_mpi_implementation"}, {"score": 0.002558909812664716, "phrase": "look-ahead_technique"}, {"score": 0.0023131084326717755, "phrase": "pure_mpi_version"}, {"score": 0.0022215160785078775, "phrase": "asymptotic_performance"}, {"score": 0.0021917966722180132, "phrase": "medium_problem_sizes"}, {"score": 0.0021335427588412077, "phrase": "significant_benefits"}], "paper_keywords": ["Algorithms", " Performance", " Languages", " parallel programming model", " MPI", " hybrid MPI/SMPSs", " LINPACK"], "paper_abstract": "Communication overhead is one of the dominant factors affecting performance in high-performance computing systems. To reduce the negative impact of communication, programmers overlap communication and computation by using asynchronous communication primitives. This increases code complexity, requiring more development effort and making less readable programs. This paper presents the hybrid use of MPI and SMPSs (SMP superscalar, a task-based shared-memory programming model) that allows the programmer to easily introduce the asynchrony necessary to overlap communication and computation. We demonstrate the hybrid use of MPI/SMPSs with the high-performance LINPACK benchmark (HPL), and compare it to the pure MPI implementation, which uses the look-ahead technique to overlap communication and computation. The hybrid MPI/SMPSs version significantly improves the performance of the pure MPI version, getting close to the asymptotic performance at medium problem sizes and still getting significant benefits at small/large problem sizes.", "paper_title": "Effective Communication and Computation Overlap with Hybrid MPI/SMPSs", "paper_id": "WOS:000280548100036"}