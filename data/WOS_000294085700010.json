{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "run_time_predictions"}, {"score": 0.03868757677576376, "phrase": "performance_predictions"}, {"score": 0.010311304931198306, "phrase": "asynchronous_model"}, {"score": 0.004776484866276242, "phrase": "automatic_co-allocation"}, {"score": 0.004738325072560588, "phrase": "multi-cluster_resources"}, {"score": 0.004700468701207975, "phrase": "iterative_parallel_applications"}, {"score": 0.004515655183335171, "phrase": "fixed_number"}, {"score": 0.00444377150105556, "phrase": "usage_time"}, {"score": 0.004338076511024884, "phrase": "static_requests"}, {"score": 0.004201033616196156, "phrase": "initial_scheduling"}, {"score": 0.0038305869305614504, "phrase": "heterogeneous_environments"}, {"score": 0.0036504182609411852, "phrase": "automatic_resource_selection"}, {"score": 0.0035635256137029592, "phrase": "resource_co-allocation_technique"}, {"score": 0.0034508665218929745, "phrase": "multi-cluster_iterative_parallel_applications"}, {"score": 0.00319732428387928, "phrase": "large-scale_computations"}, {"score": 0.003034633345146293, "phrase": "iterative_parallel_application"}, {"score": 0.002974281028713475, "phrase": "benchmark_multiobjective_problems"}, {"score": 0.0028229071631385634, "phrase": "average_error"}, {"score": 0.002711714675297321, "phrase": "run_time_overestimations"}, {"score": 0.0026577673946415583, "phrase": "synchronous_and_asynchronous_models"}, {"score": 0.0025736694380861604, "phrase": "application_source_code_access"}, {"score": 0.0025224615049571427, "phrase": "main_findings"}, {"score": 0.002384422461262006, "phrase": "network_information"}, {"score": 0.0023558375480288297, "phrase": "execution_times"}, {"score": 0.002244876254113051, "phrase": "process_mapping"}, {"score": 0.0022179605282337395, "phrase": "application_rescheduling"}, {"score": 0.002156402793481102, "phrase": "burden_tasks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Rescheduling", " Resource co-allocation", " Grid Computing", " Metascheduling", " Parallel computing", " Performance prediction", " Run time estimates", " Quality-of-service", " Asynchronous communication"], "paper_abstract": "Metaschedulers co-allocate resources by requesting a fixed number of processors and usage time for each cluster. These static requests, defined by users, limit the initial scheduling and prevent rescheduling of applications to other resource sets. It is also difficult for users to estimate application execution times, especially on heterogeneous environments. To overcome these problems, metaschedulers can use performance predictions for automatic resource selection. This paper proposes a resource co-allocation technique with rescheduling support based on performance predictions for multi-cluster iterative parallel applications. Iterative applications have been used to solve a variety of problems in science and engineering, including large-scale computations based on the asynchronous model more recently. We performed experiments using an iterative parallel application, which consists of benchmark multiobjective problems, with both synchronous and asynchronous communication models on Grid'5000. The results show run time predictions with an average error of 7% and prevention of up to 35% and 57% of run time overestimations to support rescheduling for synchronous and asynchronous models, respectively. The performance predictions require no application source code access. One of the main findings is that as the asynchronous model masks communication and computation, it requires no network information to predict execution times. By using our co-allocation technique, metaschedulers become responsible for run time predictions, process mapping, and application rescheduling; releasing the user from these burden tasks. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "Use of run time predictions for automatic co-allocation of multi-cluster resources for iterative parallel applications", "paper_id": "WOS:000294085700010"}