{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "generalized_inverted_dirichlet_mixture_models"}, {"score": 0.004413846562278824, "phrase": "unsupervised_learning_methods"}, {"score": 0.004329331617724, "phrase": "clustering_approaches"}, {"score": 0.004205570965859848, "phrase": "data_engineering"}, {"score": 0.0040656296649390486, "phrase": "finite_mixture_models"}, {"score": 0.003637669525737665, "phrase": "challenging_task"}, {"score": 0.0034491650585057754, "phrase": "high-dimensional_data"}, {"score": 0.003350480663660326, "phrase": "feature_selection_techniques"}, {"score": 0.00317681090697906, "phrase": "cluster_validation"}, {"score": 0.002968695624366393, "phrase": "positive_data"}, {"score": 0.002925899335792914, "phrase": "proposed_statistical_framework"}, {"score": 0.002855934865505357, "phrase": "generalized_inverted_dirichlet_distribution"}, {"score": 0.002579847272930948, "phrase": "resulting_model"}, {"score": 0.0024818194799172263, "phrase": "message_length_objective"}, {"score": 0.0024578987081792405, "phrase": "prior_knowledge"}, {"score": 0.0024107449502335583, "phrase": "synthetic_data"}, {"score": 0.002387507583705495, "phrase": "real_data"}, {"score": 0.0023530698447434308, "phrase": "challenging_applications"}, {"score": 0.0021670777282518424, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Positive data", " Generalized inverted Dirichlet", " Finite mixture", " Feature selection", " Outliers", " Model selection", " Images clustering"], "paper_abstract": "The discovery, extraction and analysis of knowledge from data rely generally upon the use of unsupervised learning methods, in particular clustering approaches. Much recent research in clustering and data engineering has focused on the consideration of finite mixture models which allow to reason in the face of uncertainty and to learn by example. The adoption of these models becomes a challenging task in the presence of outliers and in the case of high-dimensional data which necessitates the deployment of feature selection techniques. In this paper we tackle simultaneously the problems of cluster validation (i.e. model selection), feature selection and outliers rejection when clustering positive data. The proposed statistical framework is based on the generalized inverted Dirichlet distribution that offers a more practical and flexible alternative to the inverted Dirichlet which has a very restrictive covariance structure. The learning of the parameters of the resulting model is based on the minimization of a message length objective incorporating prior knowledge. We use synthetic data and real data generated from challenging applications, namely visual scenes and objects clustering, to demonstrate the feasibility and advantages of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Robust simultaneous positive data clustering and unsupervised feature selection using generalized inverted Dirichlet mixture models", "paper_id": "WOS:000333946400019"}