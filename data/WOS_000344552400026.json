{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "asymmetric_workload"}, {"score": 0.00471811808206897, "phrase": "upc_conjugate_gradient_method"}, {"score": 0.004262273304740847, "phrase": "parallel_conjugate_gradient"}, {"score": 0.003956113993518042, "phrase": "overall_performance"}, {"score": 0.003671865026158296, "phrase": "cg_computations"}, {"score": 0.0034311578789991363, "phrase": "cg_method"}, {"score": 0.0028569549040495163, "phrase": "sparse_storage_schemes"}, {"score": 0.0027616550517346066, "phrase": "unified_parallel_c"}, {"score": 0.0022836785412390544, "phrase": "distinct_sparse_patterns"}], "paper_keywords": ["Conjugate gradient", " PGAS", " UPC", " Performance optimization", " Data distribution"], "paper_abstract": "This paper examines four different strategies, each one with its own data distribution, for implementing the parallel conjugate gradient (CG) method and how they impact communication and overall performance. Firstly, typical 1D and 2D distributions of the matrix involved in CG computations are considered. Then, a new 2D version of the CG method with asymmetric workload, based on leaving some threads idle during part of the computation to reduce communication, is proposed. The four strategies are independent of sparse storage schemes and are implemented using Unified Parallel C (UPC), a Partitioned Global Address Space (PGAS) language. The strategies are evaluated on two different platforms through a set of matrices that exhibit distinct sparse patterns, demonstrating that our asymmetric proposal outperforms the others except for one matrix on one platform.", "paper_title": "A 2D algorithm with asymmetric workload for the UPC conjugate gradient method", "paper_id": "WOS:000344552400026"}