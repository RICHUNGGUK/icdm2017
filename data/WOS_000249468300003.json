{"auto_keywords": [{"score": 0.04967088836874542, "phrase": "positive_examples"}, {"score": 0.0492663932388163, "phrase": "membership_queries"}, {"score": 0.00481495049065317, "phrase": "tree_languages"}, {"score": 0.00443878620915958, "phrase": "input_data"}, {"score": 0.004216434794603139, "phrase": "new_trees"}, {"score": 0.0037078961288626185, "phrase": "correct_grammar"}, {"score": 0.0036448787596988423, "phrase": "target_language"}, {"score": 0.003537158562090376, "phrase": "angluin"}, {"score": 0.0034919649825540396, "phrase": "seminal_work"}, {"score": 0.003274499008699115, "phrase": "regular_languages"}, {"score": 0.0032585197486865135, "phrase": "information"}, {"score": 0.0030705342386533083, "phrase": "regular_word_languages"}, {"score": 0.003031287195944274, "phrase": "negative_examples"}, {"score": 0.0030054007508185858, "phrase": "equivalence_queries"}, {"score": 0.002854645802851, "phrase": "efficient_algorithm"}, {"score": 0.0026998264237910884, "phrase": "whole_class"}, {"score": 0.0026767629720554397, "phrase": "regular_tree_languages"}, {"score": 0.0025315664299815537, "phrase": "representative_sample"}, {"score": 0.0024461474613359994, "phrase": "finite_subset_s"}, {"score": 0.0024148618915672353, "phrase": "regular_tree_language"}, {"score": 0.0024075040253952905, "phrase": "l"}, {"score": 0.0023035249767734286, "phrase": "minimal_tree_automaton"}, {"score": 0.002150659690967412, "phrase": "set_s."}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["learning", " grammatical inference", " regular tree language", " positive example", " queries"], "paper_abstract": "We investigate regular tree languages' exact learning from positive examples and membership queries. Input data are trees of the language to infer. The learner computes new trees from the inputs and asks the oracle whether or not they belong to the language. From the answers, the learner may ask further membership queries until he finds the correct grammar that generates the target language. This paradigm was introduced by Angluin in the seminal work [D. Angluin, A note on the number of queries needed to identify regular languages, Information and Control 51 (1981) 76-87] for the case of regular word languages. Neither negative examples, equivalence queries nor counter-examples are allowed in this paradigm. We describe an efficient algorithm which is polynomial in the size of the examples for learning the whole class of regular tree languages. The convergence is ensured when the set of examples contains a representative sample of the language to guess. A finite subset S of a regular tree language L is representative for L if every transition of the minimal tree automaton for L is used at least once for the derivation of an element of the set S. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Learning tree languages from positive examples and membership queries", "paper_id": "WOS:000249468300003"}