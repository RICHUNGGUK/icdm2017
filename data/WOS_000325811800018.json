{"auto_keywords": [{"score": 0.04974351188371698, "phrase": "graph_model"}, {"score": 0.03062023849585726, "phrase": "grid_cells"}, {"score": 0.00481495049065317, "phrase": "context-aware_video_retargeting"}, {"score": 0.004747714939490445, "phrase": "video_retargeting"}, {"score": 0.004697902218671618, "phrase": "crowded_but_challenging_research_area"}, {"score": 0.004567596860086148, "phrase": "viewers'_watching_experience"}, {"score": 0.004425299304063172, "phrase": "spatial_shape"}, {"score": 0.004394281902031765, "phrase": "important_objects"}, {"score": 0.0043481611772332495, "phrase": "temporal_smoothness"}, {"score": 0.004272361887713488, "phrase": "retargeting_techniques"}, {"score": 0.0042126709243529275, "phrase": "spatial-temporal_requirements"}, {"score": 0.004124688058533477, "phrase": "spatial_geometry"}, {"score": 0.0040957690050613185, "phrase": "temporal_coherence"}, {"score": 0.003982098149664708, "phrase": "spatial-temporal_property"}, {"score": 0.003940286428597882, "phrase": "video_content"}, {"score": 0.003724566354526513, "phrase": "uniform_spatial-temporal_transformation"}, {"score": 0.003659597920882104, "phrase": "contextual_information"}, {"score": 0.003621160116056119, "phrase": "divide-and-rule_strategy"}, {"score": 0.0034713900276078786, "phrase": "satisfactory_spatial-temporal_coherent_video_retargeting"}, {"score": 0.0033868916699805224, "phrase": "novel_context-aware_solution"}, {"score": 0.0032582312803728698, "phrase": "grid-based_warping_framework"}, {"score": 0.003212663446866794, "phrase": "spatial_structure"}, {"score": 0.0031901183059524804, "phrase": "temporal_motion_trend"}, {"score": 0.0031344430376015033, "phrase": "grid_cell"}, {"score": 0.0030581212589623737, "phrase": "graph-based_motion_layer_partition_algorithm"}, {"score": 0.0029109914689364465, "phrase": "contextual_relationship"}, {"score": 0.002770920590799572, "phrase": "salience-based_spatial-temporal_information_preservation"}, {"score": 0.002609840513713399, "phrase": "uniform_spatial_and_temporal_transformation"}, {"score": 0.002528379400564723, "phrase": "objective_function"}, {"score": 0.002501793273494325, "phrase": "quadratic_programming_problem"}, {"score": 0.0024581013157048926, "phrase": "satisfactory_spatial-temporal_coherence"}, {"score": 0.0023480317852018133, "phrase": "grid-cell-wise_motion_estimation"}, {"score": 0.002234988641498543, "phrase": "experimental_results"}], "paper_keywords": ["Context-aware", " grid graph model", " spatial-temporal correlation", " video retargeting"], "paper_abstract": "Video retargeting is a crowded but challenging research area. In order to maximally comfort the viewers' watching experience, the most challenging issue is how to retain the spatial shape of important objects while ensure temporal smoothness and coherence. Existing retargeting techniques deal with these spatial-temporal requirements individually, which preserve the spatial geometry and temporal coherence for each region. However, the spatial-temporal property of the video content should be context-relevant, i.e., the regions belonging to the same object are supposed to undergo uniform spatial-temporal transformation. Regardless of the contextual information, the divide-and-rule strategy of existing techniques usually incurs various spatial-temporal artifacts. In order to achieve satisfactory spatial-temporal coherent video retargeting, in this paper, a novel context-aware solution is proposed via graph model. First, we employ a grid-based warping framework to preserve the spatial structure and temporal motion trend at the unit of grid cell. Second, we propose a graph-based motion layer partition algorithm to estimate motions of different regions, which simultaneously provides the evaluation of contextual relationship between grid cells while estimating the motions of regions. Third, complementing the salience-based spatial-temporal information preservation, two novel context constraints are encoded for encouraging the grid cells of the same object to undergo uniform spatial and temporal transformation, respectively. Finally, we formulate the objective function as a quadratic programming problem. Our method achieves a satisfactory spatial-temporal coherence while maximally avoiding the influence of artifacts. In addition, the grid-cell-wise motion estimation could be calculated every few frames, which obviously improves the speed. Experimental results and comparisons with state-of-the-art methods demonstrate the effectiveness and efficiency of our approach.", "paper_title": "Context-Aware Video Retargeting via Graph Model", "paper_id": "WOS:000325811800018"}