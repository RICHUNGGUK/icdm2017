{"auto_keywords": [{"score": 0.044728827124546816, "phrase": "final_states"}, {"score": 0.03992659287798474, "phrase": "eager_markov_chains"}, {"score": 0.0304242490196952, "phrase": "expected_reward"}, {"score": 0.00481495049065317, "phrase": "markov_chains"}, {"score": 0.004674952036988355, "phrase": "infinite-state_discrete_markov_chains"}, {"score": 0.004342430078306461, "phrase": "defined_set"}, {"score": 0.004063348730077936, "phrase": "exponentially_decreasing_function"}, {"score": 0.003664315990489347, "phrase": "probabilistic_lossy_channel_systems"}, {"score": 0.0036105923401756126, "phrase": "probabilistic_vector_addition_systems"}, {"score": 0.003479692058963528, "phrase": "noisy_turing"}, {"score": 0.0033288399506044763, "phrase": "bounding_function_f"}, {"score": 0.0025324393547676623, "phrase": "individual_runs"}, {"score": 0.002495268931035983, "phrase": "computable_reward_functions"}, {"score": 0.0023869914500743083, "phrase": "effective_path_exploration_scheme"}, {"score": 0.002317423416027688, "phrase": "forward_reachability_analysis"}, {"score": 0.0021049977753042253, "phrase": "arbitrarily_small_error"}], "paper_keywords": [""], "paper_abstract": "We consider infinite-state discrete Markov chains which are eager: the probability of avoiding a defined set of final states for more than n steps is bounded by some exponentially decreasing function f (n). We prove that eager Markov chains include those induced by Probabilistic Lossy Channel Systems, Probabilistic Vector Addition Systems with States, and Noisy Turing Machines, and that the bounding function f (n) can be effectively constructed for them. Furthermore, we study the problem of computing the expected reward (or cost) of runs until reaching the final states, where rewards are assigned to individual runs by computable reward functions. For eager Markov chains, an effective path exploration scheme, based on forward reachability analysis, can be used to approximate the expected reward up-to an arbitrarily small error.", "paper_title": "Eager Markov chains", "paper_id": "WOS:000241648200005"}