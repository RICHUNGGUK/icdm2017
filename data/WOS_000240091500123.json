{"auto_keywords": [{"score": 0.048877326221094676, "phrase": "information_bottleneck_method"}, {"score": 0.00481495049065317, "phrase": "optimal_parameter"}, {"score": 0.004518442937844318, "phrase": "natural_question"}, {"score": 0.0038789122930433305, "phrase": "prior_knowledge"}, {"score": 0.0028944757265206332, "phrase": "model_selection_problem"}, {"score": 0.0026475981474045414, "phrase": "minimum_message_length_principle"}, {"score": 0.0024527767211457046, "phrase": "documentation_clustering_scenario"}, {"score": 0.0023309080951251335, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "optimal_parameter_value"}], "paper_keywords": [""], "paper_abstract": "A natural question in Information Bottleneck method is how many \"groups\" are appropriate. The dependency on prior knowledge restricts the applications of many Information Bottleneck algorithms. In this paper we aim to remove this dependency by formulating the parameter choosing as a model selection problem, and solve it using the minimum message length principle. Empirical results in the documentation clustering scenario indicates that the proposed method works well for the determination of the optimal parameter value for information bottleneck method.", "paper_title": "Determine the optimal parameter for Information Bottleneck method", "paper_id": "WOS:000240091500123"}