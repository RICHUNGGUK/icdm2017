{"auto_keywords": [{"score": 0.0349694581102903, "phrase": "hashing_functions"}, {"score": 0.009688884502033177, "phrase": "bit-label_association"}, {"score": 0.00481495049065317, "phrase": "multilabel_images"}, {"score": 0.0047385702897315436, "phrase": "new_hashing_task"}, {"score": 0.004700833606836244, "phrase": "real-world_applications"}, {"score": 0.004675842139433654, "phrase": "content-based_image_retrieval"}, {"score": 0.004540734419151103, "phrase": "mixed_query"}, {"score": 0.004468684611798047, "phrase": "user-provided_keywords"}, {"score": 0.004386063799793622, "phrase": "state-of-the-art_hashing_research"}, {"score": 0.004270665568018583, "phrase": "conventional_image_retrieval_systems"}, {"score": 0.004236639288852276, "phrase": "input_query"}, {"score": 0.004169394481182493, "phrase": "exemplar_image"}, {"score": 0.004070515037356991, "phrase": "input_image_data"}, {"score": 0.004016594765266821, "phrase": "multiple_labels"}, {"score": 0.0038900709793274484, "phrase": "realistic_scenarios"}, {"score": 0.0038590653130931222, "phrase": "mixed_image-keyword_query"}, {"score": 0.0038283058265876713, "phrase": "traditional_image-based_query"}, {"score": 0.003777581820724243, "phrase": "user_intention"}, {"score": 0.003727527379253624, "phrase": "semantics-based_indexing"}, {"score": 0.0036978124513441755, "phrase": "multilabel_data"}, {"score": 0.003600456768296912, "phrase": "indexing_task"}, {"score": 0.0035150223642728437, "phrase": "low_effectiveness"}, {"score": 0.0034684348261345295, "phrase": "hashing_efficiency"}, {"score": 0.003422462630994095, "phrase": "novel_scheme"}, {"score": 0.00335016692413066, "phrase": "prior_works"}, {"score": 0.0032706520949775065, "phrase": "single_label"}, {"score": 0.003218690074119103, "phrase": "hashing_function"}, {"score": 0.003108911488613549, "phrase": "optimal_label_subset"}, {"score": 0.0030270132320276096, "phrase": "hash_bits"}, {"score": 0.0029394074636168435, "phrase": "greatly_reduced_computation"}, {"score": 0.002884979280317279, "phrase": "new_sample"}, {"score": 0.002801472611575172, "phrase": "specific_sample"}, {"score": 0.0027643161113894018, "phrase": "boosting_style_algorithm"}, {"score": 0.002720376476146181, "phrase": "optimal_label"}, {"score": 0.0026771333996253783, "phrase": "unified_formulation"}, {"score": 0.0026345758986796703, "phrase": "query-adaptive_retrieval_mechanism"}, {"score": 0.002613550853729262, "phrase": "hash_bit_selection"}, {"score": 0.002599627212829187, "phrase": "mixed_queries"}, {"score": 0.0025446686046680005, "phrase": "query_words"}, {"score": 0.0025176254484917224, "phrase": "training_data"}, {"score": 0.002464396152735001, "phrase": "proposed_method"}, {"score": 0.00239943553947507, "phrase": "data_similarity"}, {"score": 0.0023739321566540682, "phrase": "nonlinear_kernel_functions"}, {"score": 0.002361282057435583, "phrase": "extensive_experiments"}, {"score": 0.0023361832548454207, "phrase": "standard_image_benchmarks"}, {"score": 0.0023113511333916923, "phrase": "nus-wide"}, {"score": 0.002214625963845614, "phrase": "proposed_algorithm"}, {"score": 0.002179404723362044, "phrase": "proposed_hashing_scheme"}, {"score": 0.002167788960426031, "phrase": "substantially_superior_performances"}], "paper_keywords": [""], "paper_abstract": "This article defines a new hashing task motivated by real-world applications in content-based image retrieval, that is, effective data indexing and retrieval given mixed query (query image together with user-provided keywords). Our work is distinguished from state-of-the-art hashing research by two unique features: (1) Unlike conventional image retrieval systems, the input query is a combination of an exemplar image and several descriptive keywords, and (2) the input image data are often associated with multiple labels. It is an assumption that is more consistent with the realistic scenarios. The mixed image-keyword query significantly extends traditional image-based query and better explicates the user intention. Meanwhile it complicates semantics-based indexing on the multilabel data. Though several existing hashing methods can be adapted to solve the indexing task, unfortunately they all prove to suffer from low effectiveness. To enhance the hashing efficiency, we propose a novel scheme \"boosted shared hashing\". Unlike prior works that learn the hashing functions on either all image labels or a single label, we observe that the hashing function can be more effective if it is designed to index over an optimal label subset. In other words, the association between labels and hash bits are moderately sparse. The sparsity of the bit-label association indicates greatly reduced computation and storage complexities for indexing a new sample, since only limited number of hashing functions will become active for the specific sample. We develop a Boosting style algorithm for simultaneously optimizing both the optimal label subsets and hashing functions in a unified formulation, and further propose a query-adaptive retrieval mechanism based on hash bit selection for mixed queries, no matter whether or not the query words exist in the training data. Moreover, we show that the proposed method can be easily extended to the case where the data similarity is gauged by nonlinear kernel functions. Extensive experiments are conducted on standard image benchmarks like CIFAR-10, NUS-WIDE and a-TRECVID. The results validate both the sparsity of the bit-label association and the convergence of the proposed algorithm, and demonstrate that the proposed hashing scheme achieves substantially superior performances over state-of-the-art methods under the same hash bit budget.", "paper_title": "Mixed Image-Keyword Query Adaptive Hashing over Multilabel Images", "paper_id": "WOS:000331879000007"}