{"auto_keywords": [{"score": 0.041300200338926535, "phrase": "lexical_chains"}, {"score": 0.00481495049065317, "phrase": "roget-based_weighted_lexical_chains."}, {"score": 0.00445293569103488, "phrase": "new_method"}, {"score": 0.004354572391793908, "phrase": "text_segmentation"}, {"score": 0.0029447150254434842, "phrase": "roget's_thesaurus"}, {"score": 0.0024897902536499005, "phrase": "ten_texts"}, {"score": 0.002251227801482381, "phrase": "cast_project_corpus"}, {"score": 0.0021526564019119466, "phrase": "manual_segmentation"}, {"score": 0.0021049977753042253, "phrase": "gold_standard"}], "paper_keywords": ["Lexical chains", " text segmentation", " topic boundaries", " Roget's thesaurus", " segmentation evaluation"], "paper_abstract": "In this article we present a new method for text segmentation. The method relies on the number of lexical chains (LCs) which end in a sentence, which begin in the following sentence and which traverse the two successive sentences. The lexical chains are based on Roget's thesaurus (the 1987 and the 1911 version). We evaluate the method on ten texts from the DUC 2002 conference and on twenty texts from the CAST project corpus, using a manual segmentation as gold standard.", "paper_title": "TEXT SEGMENTATION USING ROGET-BASED WEIGHTED LEXICAL CHAINS", "paper_id": "WOS:000319490600009"}