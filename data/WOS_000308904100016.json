{"auto_keywords": [{"score": 0.03949226645185938, "phrase": "sphere_camera_model"}, {"score": 0.030649871883611197, "phrase": "omnidirectional_images"}, {"score": 0.00481495049065317, "phrase": "hybrid_camera_scenarios"}, {"score": 0.004468415400599571, "phrase": "mixed_camera_types"}, {"score": 0.004127394241838696, "phrase": "new_approaches"}, {"score": 0.004050996777117918, "phrase": "existing_perspective_camera_methods"}, {"score": 0.003812299519486331, "phrase": "different_types"}, {"score": 0.003689628075766217, "phrase": "feature_points"}, {"score": 0.003604421041893448, "phrase": "preprocessing_algorithm"}, {"score": 0.0035376693476114733, "phrase": "scale_invariant_feature_transform"}, {"score": 0.003504795450883863, "phrase": "sift"}, {"score": 0.0034238045290210534, "phrase": "hybrid_image_pairs"}, {"score": 0.003329117824699891, "phrase": "automatic_point_matching"}, {"score": 0.00329813918116714, "phrase": "omnidirectional_and_perspective_images"}, {"score": 0.0031770714776989282, "phrase": "hybrid_fundamental_matrix"}, {"score": 0.0031328221096543823, "phrase": "obtained_point_correspondences"}, {"score": 0.0030604342671868836, "phrase": "normalization_matrices"}, {"score": 0.0030319482153908037, "phrase": "lifted_coordinates"}, {"score": 0.0027483472371835865, "phrase": "hybrid_pairs"}, {"score": 0.0027100527874262446, "phrase": "weighting_strategy"}, {"score": 0.0026598200370569433, "phrase": "iterative_linear_triangulation"}, {"score": 0.0026105159490849364, "phrase": "structure_estimation_accuracy"}, {"score": 0.002538263784314365, "phrase": "multiple_perspective"}, {"score": 0.0024336086025284836, "phrase": "sparse_bundle_adjustment"}, {"score": 0.0023996890513009743, "phrase": "estimated_structure"}, {"score": 0.0022686625017583387, "phrase": "end-to-end_multi-view_sfm_pipeline"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Omnidirectional cameras", " Hybrid camera systems", " Feature matching", " Epipolar geometry", " Multi-view", " Structure-from-motion"], "paper_abstract": "We describe a pipeline for structure-from-motion (SfM) with mixed camera types, namely omnidirectional and perspective cameras. For the steps of this pipeline, we propose new approaches or adapt the existing perspective camera methods to make the pipeline effective and automatic. We model our cameras of different types with the sphere camera model. To match feature points, we describe a preprocessing algorithm which significantly increases scale invariant feature transform (SIFT) matching performance for hybrid image pairs. With this approach, automatic point matching between omnidirectional and perspective images is achieved. We robustly estimate the hybrid fundamental matrix with the obtained point correspondences. We introduce the normalization matrices for lifted coordinates so that normalization and denormalization can be performed linearly for omnidirectional images. We evaluate the alternatives of estimating camera poses in hybrid pairs. A weighting strategy is proposed for iterative linear triangulation which improves the structure estimation accuracy. Following the addition of multiple perspective and omnidirectional images to the structure, we perform sparse bundle adjustment on the estimated structure by adapting it to use the sphere camera model. Demonstrations of the end-to-end multi-view SfM pipeline with the real images of mixed camera types are presented. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Multi-view structure-from-motion for hybrid camera scenarios", "paper_id": "WOS:000308904100016"}