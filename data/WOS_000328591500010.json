{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "novel_keyframe-based_global_localization_method"}, {"score": 0.004769444094319619, "phrase": "markerless_real-time_camera_tracking"}, {"score": 0.004635477242873163, "phrase": "offline_module"}, {"score": 0.004462663711734448, "phrase": "reference_images"}, {"score": 0.004399525320473839, "phrase": "online_module"}, {"score": 0.004136044939878838, "phrase": "camera_pose"}, {"score": 0.004077508669922702, "phrase": "main_contribution"}, {"score": 0.00398177607914381, "phrase": "optimal_set"}, {"score": 0.00388828234270598, "phrase": "input_reference_images"}, {"score": 0.003725470458263889, "phrase": "entire_space"}, {"score": 0.0035864603175592854, "phrase": "content_redundancy"}, {"score": 0.0035356745476539885, "phrase": "selected_frames"}, {"score": 0.0032456625605347417, "phrase": "repeated_features"}, {"score": 0.0031845067058084583, "phrase": "large-scale_scene"}, {"score": 0.0031096747349602344, "phrase": "significant_effort"}, {"score": 0.003065619675251781, "phrase": "sufficient_reference_images"}, {"score": 0.002881793492919646, "phrase": "offline_preprocessing"}, {"score": 0.0028274743316389437, "phrase": "tracking_ability"}, {"score": 0.002787406053363446, "phrase": "larger_scale_scene"}, {"score": 0.002708960273193547, "phrase": "online_reference_map_extension_module"}, {"score": 0.0025954008219792337, "phrase": "online_keyframes"}, {"score": 0.0024397017438101726, "phrase": "parallel-computing_framework"}, {"score": 0.002304263635960015, "phrase": "experimental_results"}, {"score": 0.0022287497627555895, "phrase": "computing_efficiency"}, {"score": 0.002186712881521657, "phrase": "uttering_artifacts"}, {"score": 0.0021659920594094407, "phrase": "real-time_camera_tracking"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Keyframe selection", " Real-time camera tracking", " Global localization", " Online map extension"], "paper_abstract": "We present a novel keyframe-based global localization method for markerless real-time camera tracking. Our system contains an offline module to select features from a group of reference images and an online module to match them to the input live video for quickly estimating the camera pose. The main contribution lies in constructing an optimal set of keyframes from the input reference images, which are required to approximately cover the entire space and at the same time to minimize the content redundancy among the selected frames. This strategy not only greatly saves computation, but also helps significantly reduce the number of repeated features. For a large-scale scene, it requires a significant effort to capture sufficient reference images and reconstruct the 3D environment. In order to alleviate the effort of offline preprocessing and enhance the tracking ability in a larger scale scene, we also propose an online reference map extension module, which can real-time reconstruct new 3D features and select online keyframes to extend the keyframe set. In addition, we develop a parallel-computing framework that employs both GPUs and multi-threading for speedup. Experimental results show that our method dramatically enhances the computing efficiency and eliminates the uttering artifacts in real-time camera tracking. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Efficient keyframe-based real-time camera tracking", "paper_id": "WOS:000328591500010"}