{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "current_multicomponent_volume_segmentation"}, {"score": 0.004620093797504386, "phrase": "correct_segmentation"}, {"score": 0.004577869668211548, "phrase": "labeling_results"}, {"score": 0.004453488286477661, "phrase": "experts'_aids"}, {"score": 0.004372442291178139, "phrase": "related_volume_exploration"}, {"score": 0.0039522429946090174, "phrase": "novel_volume_exploration_method"}, {"score": 0.0037921662574137535, "phrase": "gaussian_mixture_models"}, {"score": 0.0037231102027070724, "phrase": "raw_volume"}, {"score": 0.0036553070575015344, "phrase": "different_components"}, {"score": 0.0036218682585355895, "phrase": "similar_value"}, {"score": 0.00338060449446278, "phrase": "region-grown_principle"}, {"score": 0.0033190180867511605, "phrase": "fine-grained_part_segmentation"}, {"score": 0.0032585499655442404, "phrase": "different_parts"}, {"score": 0.0030695103543472908, "phrase": "annotated_model"}, {"score": 0.003027462227648001, "phrase": "human_anatomy_model"}, {"score": 0.002999749669403939, "phrase": "plasticboycc"}, {"score": 0.002799810685137358, "phrase": "segmented_volume"}, {"score": 0.0027741761880779535, "phrase": "geometric_model"}, {"score": 0.0026494723416072316, "phrase": "comput_graph_forum"}, {"score": 0.0025420267431501367, "phrase": "volume-model_correspondence_schema"}, {"score": 0.0024956789310376635, "phrase": "intractable_challenge"}, {"score": 0.0023944552329463035, "phrase": "intuitive_interactive_methods"}, {"score": 0.0023725232579531273, "phrase": "interactive_exploration"}, {"score": 0.0023079225317714815, "phrase": "practical_precise_interaction_techniques"}, {"score": 0.002276283303864666, "phrase": "volume_exploration"}, {"score": 0.0021342613107011624, "phrase": "efficient_and_impactful_way"}, {"score": 0.0021049977753042253, "phrase": "volume_data"}], "paper_keywords": ["Interactive volume visualization", " Volume segmentation", " Volume correspondence", " Knowledge-assisted visualization"], "paper_abstract": "The current multicomponent volume segmentation and labeling methods are mostly hard to get correct segmentation and labeling results automatically and rely hardly on experts' aids, which make related volume exploration to be time consuming, laborious and prone to errors and omissions. To solve this problem, we present a novel volume exploration method driven by admitted model. We first apply Gaussian mixture models to segment the raw volume. However, different components with similar value are still mixed. To segment these components further, we make use of region-grown principle to produce a fine-grained part segmentation. To label different parts automatically, we found that it is helpful to take advantage of annotated model, like human anatomy model (PlasticboyCC, http://www.plasticboy.co.uk/store/index.html, 2013). However, it is not straightforward to label segmented volume with geometric model automatically. Inspired by electors voting (Au et al., Comput Graph Forum 29:645-654, 2010), we propose a volume-model correspondence schema to overcome this intractable challenge. Moreover, it is essential to exploit intuitive interactive methods for interactive exploration, so we also developed practical precise interaction techniques to assist volume exploration. Our experiments with various data and discussion with specialists show that our method provides an efficient and impactful way to explore volume data.", "paper_title": "Model-driven multicomponent volume exploration", "paper_id": "WOS:000350901600006"}