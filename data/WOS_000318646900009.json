{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "semantic_architecture"}, {"score": 0.04916809664432026, "phrase": "multimodal_interaction"}, {"score": 0.004089239912167375, "phrase": "multi_agent_systems"}, {"score": 0.0038230844545071303, "phrase": "ontologies_and_inference_system"}, {"score": 0.003750260412839128, "phrase": "multi_levels_concepts"}, {"score": 0.0036788184374592706, "phrase": "behavioural_models"}, {"score": 0.0034063576796640603, "phrase": "fast_high_level_reasoning"}, {"score": 0.003309452522760298, "phrase": "big_amount"}, {"score": 0.0031845067058084583, "phrase": "low_level_actions"}, {"score": 0.002837188425640173, "phrase": "different_situations"}, {"score": 0.002677964894127131, "phrase": "object_behaviours"}, {"score": 0.0022956075241520064, "phrase": "assistant_robot"}, {"score": 0.002251813863195168, "phrase": "blind_or_disabled_people"}, {"score": 0.0021049977753042253, "phrase": "virtual_reality_environment"}], "paper_keywords": ["Knowledge representation language", " Description logic", " Ontologies", " Multi-agent systems", " Semantic memory", " Multimodal interaction"], "paper_abstract": "This paper presents a semantic architecture for solving multimodal interaction. Our architecture is based on multi agent systems where agents are purely semantic using ontologies and inference system. Multi levels concepts and behavioural models are taken into account to bring a fast high level reasoning on a big amount of percepts and low level actions. We apply this architecture to make a system aware of different situations in a network like tracking object behaviours of the environment. As a proof of concept, we apply our architecture to an assistant robot helping blind or disabled people to cross a road in a virtual reality environment.", "paper_title": "Multi levels semantic architecture for multimodal interaction", "paper_id": "WOS:000318646900009"}