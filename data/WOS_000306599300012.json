{"auto_keywords": [{"score": 0.04962913836247387, "phrase": "visual_concept_learning"}, {"score": 0.032204439559752066, "phrase": "target_concept"}, {"score": 0.00481495049065317, "phrase": "web_images"}, {"score": 0.004724878518219719, "phrase": "sufficient_training_examples"}, {"score": 0.0046364836476864325, "phrase": "effective_learning"}, {"score": 0.004592905436175987, "phrase": "semantic_visual_concepts"}, {"score": 0.004422632150619634, "phrase": "noise-free_training_examples"}, {"score": 0.004258644418211771, "phrase": "rapid_popularization"}, {"score": 0.004218602458288531, "phrase": "social_media_websites"}, {"score": 0.004139693328125379, "phrase": "flickr"}, {"score": 0.003986103192038901, "phrase": "training_exemplars"}, {"score": 0.003948613642680196, "phrase": "human_assistance"}, {"score": 0.003802135020791801, "phrase": "efficient_approach"}, {"score": 0.0037486121194392564, "phrase": "training_samples"}, {"score": 0.0036958398682001015, "phrase": "noisily_tagged_web_images"}, {"score": 0.003410479630045025, "phrase": "automatically_generated_training_sets"}, {"score": 0.003299460925313939, "phrase": "simple_method_named_semantic_field"}, {"score": 0.003207173639414978, "phrase": "imprecise_and_incomplete_image_tags"}, {"score": 0.0029454679553901613, "phrase": "associated_tag_list"}, {"score": 0.0027829390976722153, "phrase": "flickr.com"}, {"score": 0.0026543514413663893, "phrase": "training_sets"}, {"score": 0.002580061425699194, "phrase": "ontology-based_hierarchical_pooling_method"}, {"score": 0.00240328454980006, "phrase": "ontologically_neighboring_concepts"}, {"score": 0.0023806459272452353, "phrase": "extensive_experiments"}, {"score": 0.0023360059818787844, "phrase": "nus-wide"}, {"score": 0.0023139986108451967, "phrase": "pascal_voc"}, {"score": 0.0022814028243395047, "phrase": "imagenet"}, {"score": 0.00218623706110975, "phrase": "competitive_performance"}, {"score": 0.0021351033500114735, "phrase": "concept_classifiers"}, {"score": 0.0021049977753042253, "phrase": "expert-labeled_training_examples"}], "paper_keywords": ["Training set construction", " visual concept learning", " web images"], "paper_abstract": "Sufficient training examples are essential for effective learning of semantic visual concepts. In practice, however, acquiring noise-free training examples has always been expensive. Recently the rapid popularization of social media websites, such as Flickr, has made it possible to collect training exemplars without human assistance. This paper proposes a novel and efficient approach to collect training samples from the noisily tagged Web images for visual concept learning, where we try to maximize two important criteria, relevancy and coverage, of the automatically generated training sets. For the former, a simple method named semantic field is introduced to handle the imprecise and incomplete image tags. Specifically, the relevancy of an image to a target concept is predicted by collectively analyzing the associated tag list of the image using two knowledge sources: WordNet corpus and statistics from Flickr.com. To boost the coverage or diversity of the training sets, we further propose an ontology-based hierarchical pooling method to collect samples not only based on the target concept alone, but also from ontologically neighboring concepts. Extensive experiments on three different datasets (NUS-WIDE, PASCAL VOC, and ImageNet) demonstrate the effectiveness of our proposed approach, producing competitive performance even when comparing with concept classifiers learned using expert-labeled training examples.", "paper_title": "Sampling and Ontologically Pooling Web Images for Visual Concept Learning", "paper_id": "WOS:000306599300012"}