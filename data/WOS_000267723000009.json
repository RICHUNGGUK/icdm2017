{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "object_recognition"}, {"score": 0.049694663394766886, "phrase": "multiple_cameras"}, {"score": 0.004718897469501381, "phrase": "prior_relevant_research"}, {"score": 0.004681012408089219, "phrase": "active_object"}, {"score": 0.004550783060775205, "phrase": "single-camera_systems"}, {"score": 0.0043533862892678864, "phrase": "object_recognition_rate"}, {"score": 0.004164516065972361, "phrase": "proposed_methods"}, {"score": 0.0040485975929323, "phrase": "different_view_angles"}, {"score": 0.0038885527668812807, "phrase": "priori_known_objects"}, {"score": 0.003810909603178837, "phrase": "available_information"}, {"score": 0.003765067028482197, "phrase": "recursive_bayesian_framework"}, {"score": 0.003459191419478298, "phrase": "high_confidence_level"}, {"score": 0.003335804608791029, "phrase": "next_most_informative_camera_positions"}, {"score": 0.0032428780373184207, "phrase": "principle_component_analysis"}, {"score": 0.003217157777634113, "phrase": "pca"}, {"score": 0.0031271827534050493, "phrase": "measurement_vector"}, {"score": 0.003077092305006702, "phrase": "acquired_images"}, {"score": 0.0029553380263320195, "phrase": "novel_probabilistic_modelling_approach"}, {"score": 0.002861402531078998, "phrase": "recognition_process"}, {"score": 0.0028155572612699976, "phrase": "structured_noise"}, {"score": 0.0027816546451972725, "phrase": "camera_positions"}, {"score": 0.002748159131396737, "phrase": "recognition_step"}, {"score": 0.002555580662218227, "phrase": "mi"}, {"score": 0.002357131515622894, "phrase": "prior_relevant_work"}, {"score": 0.00224558083320154, "phrase": "extensive_monte_carlo_experiments"}, {"score": 0.0022095803687183107, "phrase": "two-camera_system"}, {"score": 0.0021566565951738658, "phrase": "proposed_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Active object recognition", " Pose estimation", " View planning", " Occlusion", " Sensor fusion", " Machine vision", " Cramer-Rao lower bound", " Mutual information"], "paper_abstract": "While prior relevant research in active object recognition/pose estimation has mostly focused on single-camera systems, we propose two multi-camera solutions to this problem that can enhance object recognition rate, particularly in the presence of occlusion. In the proposed methods, multiple cameras simultaneously acquire images from different view angles of an unknown, randomly occluded object belonging to a set of a priori known objects. By processing the available information within a recursive Bayesian framework at each step, the recognition algorithms attempt to classify the object, if its identity/pose can be determined with a high confidence level. Otherwise, the algorithms would compute the next most informative camera positions for capturing more images. The principle component analysis (PCA) is used to produce a measurement vector based on the acquired images. Occlusions in the images are handled by a novel probabilistic modelling approach that can increase the robustness of the recognition process with respect to structured noise. The camera positions at each recognition step are selected based on two statistical metrics quantifying the quality of the observations, namely the mutual information (MI) and the Cramer-Rao lower bound (CRLB). While the former has also been used in a prior relevant work, the latter is new in the context of object recognition. Extensive Monte Carlo experiments conducted with a two-camera system demonstrate the effectiveness of the proposed approaches. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Robust sequential view planning for object recognition using multiple cameras", "paper_id": "WOS:000267723000009"}