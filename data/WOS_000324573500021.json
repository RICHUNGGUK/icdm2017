{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "error_rates"}, {"score": 0.049387234800605376, "phrase": "convexity_properties"}, {"score": 0.042506405968858046, "phrase": "spherically_invariant_noise"}, {"score": 0.030518781917023993, "phrase": "channel_coding_theorem"}, {"score": 0.02763054986459418, "phrase": "convex_error_rates"}, {"score": 0.0271435100210684, "phrase": "noise_power"}, {"score": 0.004780030485538593, "phrase": "digital_communications"}, {"score": 0.004412155302768363, "phrase": "arbitrary_constellations"}, {"score": 0.004380143676997257, "phrase": "bit_mapping"}, {"score": 0.00430112267051817, "phrase": "earlier_results"}, {"score": 0.004238929161010395, "phrase": "additive_white_gaussian_noise_channel"}, {"score": 0.004162445117081609, "phrase": "wide_class"}, {"score": 0.004132237700479874, "phrase": "noise_densities"}, {"score": 0.003998983496539902, "phrase": "broad_conditions"}, {"score": 0.003969957613513855, "phrase": "symbol_and_bit_error_rates"}, {"score": 0.003898307690037192, "phrase": "convex_functions"}, {"score": 0.0038559375376635047, "phrase": "signal-to-noise_ratio"}, {"score": 0.0037725685596495355, "phrase": "high-snr_regime"}, {"score": 0.0037315599283579593, "phrase": "explicitly_determined_threshold"}, {"score": 0.0036375920152538783, "phrase": "constellation_dimensionality"}, {"score": 0.003611179715045633, "phrase": "minimum_distance"}, {"score": 0.00350742771604554, "phrase": "powerful_tools"}, {"score": 0.003481957226813911, "phrase": "convex_optimization"}, {"score": 0.003419084516677794, "phrase": "rigorous_way"}, {"score": 0.003357343256340741, "phrase": "decreasing_nature"}, {"score": 0.003320833167729157, "phrase": "noise_power_density"}, {"score": 0.003284718806701356, "phrase": "decision_region_boundaries"}, {"score": 0.003213660268958121, "phrase": "symbol_error_rates"}, {"score": 0.0031787077057214086, "phrase": "general_case"}, {"score": 0.00293370839211022, "phrase": "high-snr_bound"}, {"score": 0.0028183634079717136, "phrase": "capacity-achieving_ones"}, {"score": 0.0027674397462322435, "phrase": "hardened_noise_spheres"}, {"score": 0.002727362288104989, "phrase": "noise_sphere"}, {"score": 0.002717433692385074, "phrase": "hardening_argument"}, {"score": 0.0026392916936302355, "phrase": "high-snr_requirement"}, {"score": 0.0024987660207458555, "phrase": "capacity-achieving_codes"}, {"score": 0.002444668348634501, "phrase": "signal_amplitude"}, {"score": 0.0021752783872387173, "phrase": "low_dimensions"}, {"score": 0.0021049977753042253, "phrase": "linear_diversity"}], "paper_keywords": ["Bit error rate (BER)", " convexity/concavity", " error rate", " maximum-likelihood (ML) decoding", " pairwise probability of error", " spherically invariant noise", " unimodal noise"], "paper_abstract": "Convexity properties of error rates of a class of decoders, including the maximum-likelihood/min-distance one as a special case, are studied for arbitrary constellations, bit mapping, and coding. Earlier results obtained for the additive white Gaussian noise channel are extended to a wide class of noise densities, including unimodal and spherically invariant noise. Under these broad conditions, symbol and bit error rates are shown to be convex functions of the signal-to-noise ratio (SNR) in the high-SNR regime with an explicitly determined threshold, which depends only on the constellation dimensionality and minimum distance, thus enabling an application of the powerful tools of convex optimization to such digital communication systems in a rigorous way. It is the decreasing nature of the noise power density around the decision region boundaries that ensures the convexity of symbol error rates in the general case. The known high/low-SNR bounds of the convexity/concavity regions are tightened and no further improvement is shown to be possible in general. The high-SNR bound fits closely into the channel coding theorem: all codes, including capacity-achieving ones, whose decision regions include the hardened noise spheres (from the noise sphere hardening argument in the channel coding theorem), satisfy this high-SNR requirement and thus has convex error rates in both SNR and noise power. We conjecture that all capacity-achieving codes have convex error rates. Convexity properties in signal amplitude and noise power are also investigated. Some applications of the results are discussed. In particular, it is shown that fading is convexity-preserving and is never good in low dimensions under spherically invariant noise, which may also include any linear diversity combining.", "paper_title": "On Convexity of Error Rates in Digital Communications", "paper_id": "WOS:000324573500021"}