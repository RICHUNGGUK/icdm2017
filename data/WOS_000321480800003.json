{"auto_keywords": [{"score": 0.042208046004301246, "phrase": "fused_image"}, {"score": 0.004815607935434171, "phrase": "bayesian"}, {"score": 0.004747620102130588, "phrase": "visualization-oriented_hyperspectral_image_fusion"}, {"score": 0.004551199992546761, "phrase": "bayesian_approach"}, {"score": 0.004466519142879166, "phrase": "hyperspectral_images"}, {"score": 0.004362870617347183, "phrase": "efficient_visualization"}, {"score": 0.004322701943391709, "phrase": "fusion"}, {"score": 0.004201991568145053, "phrase": "estimation_problem"}, {"score": 0.004143196873246147, "phrase": "observed_hyperspectral_bands"}, {"score": 0.0039716833701918365, "phrase": "first_order_model"}, {"score": 0.003934540154108188, "phrase": "image_formation"}, {"score": 0.0034984340449789745, "phrase": "higher_contribution"}, {"score": 0.0034494494982242187, "phrase": "\"visually_important\"_pixels"}, {"score": 0.003401148484767927, "phrase": "final_fused_image"}, {"score": 0.003322140088192527, "phrase": "two-step_framework"}, {"score": 0.0032602525602322832, "phrase": "hyperspectral_image"}, {"score": 0.0031995142224983094, "phrase": "first_step"}, {"score": 0.0029816229984366374, "phrase": "local_quality_measures"}, {"score": 0.002939853413763817, "phrase": "hyperspectral_data"}, {"score": 0.002726740692380339, "phrase": "map_framework"}, {"score": 0.0026633568650501873, "phrase": "total_variation"}, {"score": 0.0025290375256888883, "phrase": "sharp_discontinuities"}, {"score": 0.0024586427394152196, "phrase": "fused_images"}, {"score": 0.0022378101636842296, "phrase": "visual_as_well_as_quantitative_results"}, {"score": 0.0021652891317252994, "phrase": "proposed_technique"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Hyperspectral image fusion", " MAP framework", " Total variation"], "paper_abstract": "In this paper, we propose a Bayesian approach towards fusion of hyperspectral images for the purpose of efficient visualization. Fusion has been posed as an estimation problem where the observed hyperspectral bands have been related to the fused image through a first order model of image formation. The parameters of the model indicate the quality of the pixel captured locally. As visualization is our primary aim of fusion, we expect higher contribution of the \"visually important\" pixels towards the final fused image. We propose a two-step framework for fusion of hyperspectral image, where the first step identifies the quality of each pixel of the data based on some of the local quality measures of the hyperspectral data. Subsequently, we formulate the problem of the estimation of the fused image in a MAP framework. We incorporate the total variation (TV) norm-based prior which preserves the sharp discontinuities in the fused image. The fused images, thus, appear sharp and natural where the edges and boundaries have been retained. We have provided visual as well as quantitative results to substantiate the effectiveness of the proposed technique. (c) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A Bayesian approach to visualization-oriented hyperspectral image fusion", "paper_id": "WOS:000321480800003"}