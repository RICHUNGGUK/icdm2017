{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "dynamic_activation_policies_for_event_capture"}, {"score": 0.00450933377534525, "phrase": "rechargeable_sensor_network"}, {"score": 0.004297560964892607, "phrase": "renewal_process"}, {"score": 0.004260134699483774, "phrase": "inter-arrival_times"}, {"score": 0.004167982855788402, "phrase": "general_probability_distribution"}, {"score": 0.00407781620412982, "phrase": "stochastic_recharge_process"}, {"score": 0.003937573222812911, "phrase": "sensors'_operation"}, {"score": 0.003818807671883534, "phrase": "recharge_processes"}, {"score": 0.003769006950727621, "phrase": "optimal_sensor_activation_problem"}, {"score": 0.0035918768194006735, "phrase": "single-sensor_problem"}, {"score": 0.003545024951402821, "phrase": "dynamic_control_theory"}, {"score": 0.003468287913322255, "phrase": "full-information_model"}, {"score": 0.003191485583025302, "phrase": "last_time_slot"}, {"score": 0.003068166587650604, "phrase": "simple_and_optimal_greedy_policy"}, {"score": 0.0029110999689379497, "phrase": "partial-information_model"}, {"score": 0.002598480396489947, "phrase": "markov"}, {"score": 0.002497319603143104, "phrase": "pomdp's_optimal_policy"}, {"score": 0.002475532161577715, "phrase": "exponential_computational_complexity"}, {"score": 0.002359046870732839, "phrase": "efficient_heuristic_clustering_policy"}, {"score": 0.002228412982799273, "phrase": "network_setting"}, {"score": 0.0021993066642488237, "phrase": "multiple_sensors"}, {"score": 0.0021049977753042253, "phrase": "extensive_simulation_results"}], "paper_keywords": ["Rechargeable sensors", " event capture", " dynamic activation", " Markov decision process"], "paper_abstract": "We consider the problem of event capture by a rechargeable sensor network. We assume that the events of interest follow a renewal process whose event inter-arrival times are drawn from a general probability distribution, and that a stochastic recharge process is used to provide energy for the sensors' operation. Dynamics of the event and recharge processes make the optimal sensor activation problem highly challenging. In this paper we first consider the single-sensor problem. Using dynamic control theory, we consider a full-information model in which, independent of its activation schedule, the sensor will know whether an event has occurred in the last time slot or not. In this case, a simple and optimal greedy policy for the solution is developed. We then further consider a partial-information model where the sensor knows about the occurrence of an event only when it is active. This problem falls into the class of partially observable Markov decision processes (POMDP). Since the POMDP's optimal policy has exponential computational complexity and is intrinsically hard to solve, we propose an efficient heuristic clustering policy and evaluate its performance. Finally, our solutions are extended to handle a network setting in which multiple sensors collaborate to capture the events. We also provide extensive simulation results to evaluate the performance of our solutions.", "paper_title": "Dynamic Activation Policies for Event Capture in Rechargeable Sensor Network", "paper_id": "WOS:000347015800008"}