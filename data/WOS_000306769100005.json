{"auto_keywords": [{"score": 0.04927465911141673, "phrase": "omnidirectional_vision"}, {"score": 0.004576253356889219, "phrase": "current_work"}, {"score": 0.0043678116213858, "phrase": "monocular_and_stereo_omnidirectional_vision"}, {"score": 0.004258128672571261, "phrase": "camera_pose"}, {"score": 0.004064117897000019, "phrase": "line_segments"}, {"score": 0.004012751049253625, "phrase": "straight_line_feature"}, {"score": 0.0037654565082218595, "phrase": "mobile_robot_navigation"}, {"score": 0.0037021153060910164, "phrase": "structured_environments"}, {"score": 0.0034886660821793576, "phrase": "omnidirectional_images"}, {"score": 0.0031375577552605533, "phrase": "new_spherical_formulation"}, {"score": 0.003097865379563127, "phrase": "pose_estimation"}, {"score": 0.0030199761431186434, "phrase": "object_model"}, {"score": 0.002944039482467119, "phrase": "theoretical_formulation"}, {"score": 0.0028822153400215973, "phrase": "synthetic_images"}, {"score": 0.002821685815956478, "phrase": "new_formulation"}, {"score": 0.0027741761880779535, "phrase": "former_image_plane"}, {"score": 0.0027274643070540733, "phrase": "second_contribution"}, {"score": 0.002658863179011018, "phrase": "spherical_representation"}, {"score": 0.0026252106881752067, "phrase": "stereovision_case"}, {"score": 0.002380934815435267, "phrase": "illumination_changes"}, {"score": 0.002360796860462937, "phrase": "local_mistracking"}, {"score": 0.0023210293050850276, "phrase": "final_result"}, {"score": 0.00229164285862567, "phrase": "proposed_new_stereo_spherical_formulation"}, {"score": 0.002168531704054597, "phrase": "classical_formulation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Omnidirectional vision", " Stereovision", " Spherical optimization", " Tracking"], "paper_abstract": "The current work addresses the problem of 3D model tracking in the context of monocular and stereo omnidirectional vision in order to estimate the camera pose. To this end, we track 3D objects modeled by line segments because the straight line feature is often used to model the environment. Indeed, we are interested in mobile robot navigation using omnidirectional vision in structured environments. In the case of omnidirectional vision, 3D straight lines are projected as conics in omnidirectional images. Under certain conditions, these conics may have singularities. In this paper, we present two contributions. We, first, propose a new spherical formulation of the pose estimation withdrawing singularities, using an object model composed of lines. The theoretical formulation and the validation on synthetic images thus show that the new formulation clearly outperforms the former image plane one. The second contribution is the extension of the spherical representation to the stereovision case. We consider in the paper a sensor which combines a camera and four mirrors. Results in various situations show the robustness to illumination changes and local mistracking. As a final result, the proposed new stereo spherical formulation allows us to localize online a robot indoor and outdoor whereas the classical formulation fails. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "3D model based tracking for omnidirectional vision: A new spherical approach", "paper_id": "WOS:000306769100005"}