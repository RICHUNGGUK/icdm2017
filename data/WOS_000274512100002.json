{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "vertical_and_cutting_multi-hyperplane_decision_tree_induction"}, {"score": 0.004450568197899267, "phrase": "key_task"}, {"score": 0.004363846362238565, "phrase": "decision_making"}, {"score": 0.004278807087784626, "phrase": "data_mining_applications"}, {"score": 0.003916098498242888, "phrase": "multiple_separating_hyperplanes"}, {"score": 0.0036553070575015344, "phrase": "previous_piecewise-linear_models"}, {"score": 0.0028293966058473476, "phrase": "particular_types"}, {"score": 0.0027741761880779535, "phrase": "decision_trees"}, {"score": 0.0024405312482831646, "phrase": "computational_results"}, {"score": 0.002323142666222693, "phrase": "better_classification_accuracy"}, {"score": 0.002233301265743633, "phrase": "previous_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Data mining", " Discrimination analysis", " Piecewise-linear models", " Mathematical programming"], "paper_abstract": "Two-group classification is a key task in decision making and data mining applications. We introduce two new mixed integer programming formulations that make use of multiple separating hyperplanes. They represent a generalization of previous piecewise-linear models that embed rules having the form of hyperplanes, which are used to successively separate the two groups. In fact, the classifiers obtained are particular types of decision trees which are allowed to grow in depth and not in width. Computational results show that our models achieve better classification accuracy in less time than previous approaches. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Classification by vertical and cutting multi-hyperplane decision tree induction", "paper_id": "WOS:000274512100002"}