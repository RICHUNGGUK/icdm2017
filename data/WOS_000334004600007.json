{"auto_keywords": [{"score": 0.04787636758356028, "phrase": "training_data"}, {"score": 0.015719716506582538, "phrase": "one-class_support_vector_machine"}, {"score": 0.01006237968350793, "phrase": "osvm_method"}, {"score": 0.004740009255053372, "phrase": "one-class_classification"}, {"score": 0.004666228956744244, "phrase": "low_variance_directions"}, {"score": 0.004545793387330536, "phrase": "crucial_information"}, {"score": 0.004451676867747938, "phrase": "good_model"}, {"score": 0.004382364826200616, "phrase": "target_class"}, {"score": 0.0043367547691560175, "phrase": "boundary-based_methods"}, {"score": 0.004030449969901066, "phrase": "large_variance_directions"}, {"score": 0.0037653554368382814, "phrase": "initial_properties"}, {"score": 0.0037066895459425824, "phrase": "original_data"}, {"score": 0.0035176353680157367, "phrase": "limited_training_samples"}, {"score": 0.0031678720736808574, "phrase": "important_characteristics"}, {"score": 0.0031348622158167195, "phrase": "cosvm"}, {"score": 0.0029593432468318745, "phrase": "separating_hyperplane"}, {"score": 0.0028828348726682965, "phrase": "estimated_covariance_matrix"}, {"score": 0.0027645030021576926, "phrase": "convex_optimization_problem"}, {"score": 0.0025824576209656676, "phrase": "existing_numerical_methods"}, {"score": 0.0024894376091589244, "phrase": "principal_structure"}, {"score": 0.0023254633298356894, "phrase": "existing_osvm_libraries"}, {"score": 0.002301211274459965, "phrase": "comparative_experimental_results"}, {"score": 0.0022772115643656153, "phrase": "contemporary_one-class_classifiers"}, {"score": 0.002253461585851626, "phrase": "numerous_artificial_and_benchmark_datasets"}, {"score": 0.002172266188075892, "phrase": "significantly_better_classification_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Covariance", " Support Vector Machine", " One-class classification", " Outlier detection"], "paper_abstract": "In one-class classification, the low variance directions in the training data carry crucial information to build a good model of the target class. Boundary-based methods like One-Class Support Vector Machine (OSVM) preferentially separates the data from outliers along the large variance directions. On the other hand, retaining only the low variance directions can result in sacrificing some initial properties of the original data and is not desirable, specially in case of limited training samples. This paper introduces a Covariance-guided One-Class Support Vector Machine (COSVM) classification method which emphasizes the low variance projectional directions of the training data without compromising any important characteristics. COSVM improves upon the OSVM method by controlling the direction of the separating hyperplane through incorporation of the estimated covariance matrix from the training data. Our proposed method is a convex optimization problem resulting in one global optimum solution which can be solved efficiently with the help of existing numerical methods. The method also keeps the principal structure of the OSVM method intact, and can be implemented easily with the existing OSVM libraries. Comparative experimental results with contemporary one-class classifiers on numerous artificial and benchmark datasets demonstrate that our method results in significantly better classification performance. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Covariance-guided One-Class Support Vector Machine", "paper_id": "WOS:000334004600007"}