{"auto_keywords": [{"score": 0.04362466714994538, "phrase": "dtsa"}, {"score": 0.015394501421906114, "phrase": "di"}, {"score": 0.012374709418488896, "phrase": "local_structure"}, {"score": 0.009899974329210139, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "second-order_discriminant_tensor_subspace_analysis"}, {"score": 0.004634799977448855, "phrase": "critical_role"}, {"score": 0.00459568664065473, "phrase": "face_recognition"}, {"score": 0.004204320052179726, "phrase": "tensor_data"}, {"score": 0.004081385289516914, "phrase": "previous_methods"}, {"score": 0.003995772867224968, "phrase": "tensor_methods"}, {"score": 0.003945266418163835, "phrase": "spatial_structure_information"}, {"score": 0.0038953958723049287, "phrase": "original_image_matrices"}, {"score": 0.003829877278269543, "phrase": "manifold_methods"}, {"score": 0.0037336520904376687, "phrase": "samples_distribution"}, {"score": 0.003533347967582184, "phrase": "-class_similarity_matrix"}, {"score": 0.0034886660821793576, "phrase": "within-class_similarity_matrix"}, {"score": 0.0033865859510157238, "phrase": "point_pairs"}, {"score": 0.003287482882222731, "phrase": "between-class_similarity_matrix"}, {"score": 0.0028944757265206332, "phrase": "manifold_structure"}, {"score": 0.002870006736445581, "phrase": "facial_images"}, {"score": 0.0028457440091791252, "phrase": "high_dimensional_space"}, {"score": 0.0026929458952693465, "phrase": "tensor_based_method"}, {"score": 0.0026701760128830573, "phrase": "two-sided_transformations"}, {"score": 0.0026363807171515255, "phrase": "single-sided_one"}, {"score": 0.002526780881314497, "phrase": "tensor_method"}, {"score": 0.0024736973328071026, "phrase": "iterative_procedure"}, {"score": 0.0024320326084093465, "phrase": "optimal_solution"}, {"score": 0.0023309080951251335, "phrase": "dtsa's_connections"}, {"score": 0.0022916447353726562, "phrase": "tsa"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Face recognition", " Locality preserving projection", " Discriminant information", " Tensor subspace"], "paper_abstract": "Discriminant information (DI) plays a critical role in face recognition. In this paper, we proposed a second-order discriminant tensor subspace analysis (DTSA) algorithm to extract discriminant features from the intrinsic manifold structure of the tensor data. DTSA combines the advantages of previous methods with DI, the tensor methods preserving the spatial structure information of the original image matrices, and the manifold methods preserving the local structure of the samples distribution. DTSA defines two similarity matrices, namely within-class similarity matrix and between-class similarity matrix. The within-class similarity matrix is determined by the distances of point pairs in the same class, while the between-class similarity matrix is determined by the distances between the means of each pair of classes. Using these two matrices, the proposed method preserves the local structure of the samples to fit the manifold structure of facial images in high dimensional space better than other methods. Moreover, compared to the 2D methods, the tensor based method employs two-sided transformations rather than single-sided one, and yields higher compression ratio. As a tensor method, DTSA uses an iterative procedure to calculate the optimal solution of two transformation matrices. In this paper, we analyzed DTSA's connections to 2D-DLPP and TSA, theoretically. The experiments on the ORL, Yale and YaleB facial databases show the effectiveness of the proposed method. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Face recognition using second-order discriminant tensor subspace analysis", "paper_id": "WOS:000291915500011"}