{"auto_keywords": [{"score": 0.04531239791485495, "phrase": "phonation_modes"}, {"score": 0.004815089217749444, "phrase": "resonant"}, {"score": 0.004650086856905758, "phrase": "phonation_mode"}, {"score": 0.004604023526673226, "phrase": "audio_recordings_of_singing"}, {"score": 0.0043804319008535555, "phrase": "automatic_detection"}, {"score": 0.004251500979153001, "phrase": "sustained_sung_vowels"}, {"score": 0.0041469500929423595, "phrase": "open_dataset"}, {"score": 0.0039651694106206245, "phrase": "nine_vowels"}, {"score": 0.00392586404888927, "phrase": "multiple_languages"}, {"score": 0.003829290275367182, "phrase": "female_singer"}, {"score": 0.003380791705551809, "phrase": "creative_commons_license"}, {"score": 0.0032975819773787985, "phrase": "glottal_flow_waveform"}, {"score": 0.0032324864013225166, "phrase": "inverse_filtering"}, {"score": 0.003152915289414825, "phrase": "audio_recordings"}, {"score": 0.0031061129850110994, "phrase": "six_parameters"}, {"score": 0.0030600032877646263, "phrase": "glottal_flow"}, {"score": 0.0028536871476905847, "phrase": "phonation_mode_classes"}, {"score": 0.0027834145465170292, "phrase": "iaif_approach"}, {"score": 0.002687922713487696, "phrase": "input_arguments_-_lip_radiation"}, {"score": 0.0025827837420330816, "phrase": "best-performing_svm_classifiers"}, {"score": 0.002444883254621769, "phrase": "physical_model"}, {"score": 0.002234893735225432, "phrase": "experimental_work"}, {"score": 0.0021049977753042253, "phrase": "ethnomusicological_investigations"}], "paper_keywords": [""], "paper_abstract": "In this paper we present an experiment on automatic detection of phonation modes from recordings of sustained sung vowels. We created an open dataset specifically for this experiment, containing recordings of nine vowels from multiple languages, sung by a female singer on all pitches in her vocal range in phonation modes breathy, neutral, flow (resonant) and pressed. The dataset is available under a Creative Commons license at . First, glottal flow waveform is estimated via inverse filtering (IAIF) from audio recordings. Then six parameters of the glottal flow waveform are calculated. A 4-class Support Vector Machine classifier is constructed to separate these features into phonation mode classes. We automated the IAIF approach by computing the values of the input arguments - lip radiation and formant count - leading to the best-performing SVM classifiers (average classification accuracy over 60%), yielding a physical model for the articulation of the vowels. We examine the steps needed to generalize and extend the experimental work presented in this paper in order to apply this method in ethnomusicological investigations.", "paper_title": "Breathy, Resonant, Pressed - Automatic Detection of Phonation Mode from Audio Recordings of Singing", "paper_id": "WOS:000323243600006"}