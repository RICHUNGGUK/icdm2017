{"auto_keywords": [{"score": 0.04409251033766783, "phrase": "recognition_performance"}, {"score": 0.00481495049065317, "phrase": "mobile_user_interfaces"}, {"score": 0.004701985831087475, "phrase": "new_interfaces"}, {"score": 0.004657542074154025, "phrase": "semi-synchronous_speech"}, {"score": 0.004548253531664032, "phrase": "mobile_environments"}, {"score": 0.004337276328199398, "phrase": "pen_input"}, {"score": 0.004000741805312148, "phrase": "input_speed"}, {"score": 0.003962899903266524, "phrase": "input_information"}, {"score": 0.0037432199549135826, "phrase": "time_lag"}, {"score": 0.003603549914861701, "phrase": "conventional_multi-modal_recognition_algorithms"}, {"score": 0.003307988966112615, "phrase": "multi-modal_recognition_algorithm"}, {"score": 0.0030949200330108156, "phrase": "segment-based_unification_scheme"}, {"score": 0.0029793675408245047, "phrase": "time-lag_characteristics"}, {"score": 0.002909342017421165, "phrase": "five_different_pen-input_interfaces"}, {"score": 0.0027479040199262393, "phrase": "phrase_unit"}, {"score": 0.002657890175649468, "phrase": "speech_recognition_experiments"}, {"score": 0.002632716358833918, "phrase": "noisy_speech_data"}, {"score": 0.0025954008219792337, "phrase": "recognition_accuracy"}, {"score": 0.0025586128304269616, "phrase": "proposed_method"}, {"score": 0.0024397017438101726, "phrase": "five_interfaces"}, {"score": 0.002359759876402679, "phrase": "subjective_test"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["User interfaces", " Speech recognition", " Handwritten character recognition", " Multi-modal recognition", " Adaptation"], "paper_abstract": "This paper proposes new interfaces using semi-synchronous speech and pen input for mobile environments. A user speaks while writing, and the pen input complements the speech so that recognition performance will be higher than with speech alone. Since the input speed and input information are different between the two modes, speaking and writing, a time lag always exists between them. Therefore, conventional multi-modal recognition algorithms cannot be directly applied to this interface. To tackle this problem, we developed a multi-modal recognition algorithm that can handle this asynchronicity (time-lag) by using a segment-based unification scheme and a method of adapting to the time-lag characteristics of individual users. Five different pen-input interfaces, each of which is assumed to be given for a phrase unit in speech, were evaluated in speech recognition experiments using noisy speech data. The recognition accuracy of the proposed method was higher than that of speech alone in all five interfaces. We also carried out a subjective test to examine the usability of each interface. We found a trade-off between usability and improvement in recognition performance. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Semi-synchronous speech and pen input for mobile user interfaces", "paper_id": "WOS:000287561300002"}