{"auto_keywords": [{"score": 0.02864039936811681, "phrase": "laplace"}, {"score": 0.00481495049065317, "phrase": "large_and_infinite_alphabets"}, {"score": 0.004283019592801715, "phrase": "discrete_source"}, {"score": 0.004224418476742716, "phrase": "unknown_statistics"}, {"score": 0.0034118234596993836, "phrase": "great_importance"}, {"score": 0.0033651019362620866, "phrase": "data_compression"}, {"score": 0.0032065418360603293, "phrase": "probability_distributions"}, {"score": 0.0031626225189867354, "phrase": "ppm_algorithms"}, {"score": 0.002931569771634119, "phrase": "classical_problem"}, {"score": 0.0021049977753042253, "phrase": "new_methods"}], "paper_keywords": ["adaptive coding", " Laplace problem of succession", " lossless data compression", " prediction of random processes", " Shannon entropy", " source coding"], "paper_abstract": "The problem of predicting a sequence x(1), x(2), .... generated by a discrete source with unknown statistics is considered. Each letter x(t+1) is predicted using the information on the word x(1), x(2), .... x(t) only. This problem is of great importance for data compression, because of its use to estimate probability distributions for PPM algorithms and other adaptive codes. On the other hand, such prediction is a classical problem which has received much attention. Its history can be traced back to Laplace. We address the problem where the sequence is generated by an independent and identically distributed (i.i.d.) source with some large (or even infinite) alphabet and suggest a class of new methods of prediction.", "paper_title": "Adaptive coding and prediction of sources with large and infinite alphabets", "paper_id": "WOS:000257861400043"}