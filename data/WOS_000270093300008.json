{"auto_keywords": [{"score": 0.03377281650584252, "phrase": "end_users"}, {"score": 0.00481495049065317, "phrase": "user-centered_evaluation"}, {"score": 0.004736820055728928, "phrase": "visual_analytic_environments"}, {"score": 0.004224130367280183, "phrase": "symposium_contests"}, {"score": 0.003556873173040169, "phrase": "better_understanding"}, {"score": 0.003331275574328097, "phrase": "potential_end_users"}, {"score": 0.003069230909006614, "phrase": "time_constraints"}, {"score": 0.002994701080666466, "phrase": "classified_nature"}, {"score": 0.0021049977753042253, "phrase": "vast_challenges"}], "paper_keywords": ["user-centered evaluation", " synthetic data", " metrics", " visual analytics"], "paper_abstract": "In this paper, the authors describe the Visual Analytics Science and Technology (VAST) Symposium contests run in 2006 and 2007 and the VAST 2008 and 2009 challenges. These contests were designed to provide researchers with a better understanding of the tasks and data that face potential end users. Access to these end users is limited because of time constraints and the classified nature of the tasks and data. In that respect, the contests serve as an intermediary, with the metrics and feedback serving as measures of utility to the end users. The authors summarize the lessons learned and the future directions for VAST Challenges. Information Visualization (2009) 8, 230 - 238. doi: 10.1057/ivs.2009.16", "paper_title": "Advancing user-centered evaluation of visual analytic environments through contests", "paper_id": "WOS:000270093300008"}