{"auto_keywords": [{"score": 0.04939024695118498, "phrase": "memory-level_parallelism"}, {"score": 0.00893662888750038, "phrase": "baseline_embedded_processor_platform"}, {"score": 0.00481495049065317, "phrase": "application-specific_reconfigurable_hardware"}, {"score": 0.00459338480279876, "phrase": "xilinx"}, {"score": 0.004494570360108983, "phrase": "unprecedented_opportunity"}, {"score": 0.004397875849247165, "phrase": "real-time_responsiveness"}, {"score": 0.004366106816225457, "phrase": "memory-intensive_embedded_applications"}, {"score": 0.004210656614914171, "phrase": "application-specific_hardware_constructs"}, {"score": 0.004075469816959996, "phrase": "key_challenge"}, {"score": 0.00393032656248792, "phrase": "new_fpga-based_embedded_computer_architecture"}, {"score": 0.0037903327482565097, "phrase": "reconfigurable_optimization"}, {"score": 0.003668591097652231, "phrase": "integrated_methodology"}, {"score": 0.003563651133299401, "phrase": "application-specific_memory_access_network"}, {"score": 0.0034995881411519925, "phrase": "maximum_amount"}, {"score": 0.0034366728236876016, "phrase": "per-application_basis"}, {"score": 0.0033021988455635403, "phrase": "dynamic_memory_analysis"}, {"score": 0.003242820629121494, "phrase": "target_application's_instruction"}, {"score": 0.003161474881435185, "phrase": "performance_enhancement"}, {"score": 0.0030933709720820605, "phrase": "highly_efficient_accelerators"}, {"score": 0.003059869469624301, "phrase": "parallelized_memory_accesses"}, {"score": 0.0029722900280316216, "phrase": "effective_data_orchestration"}, {"score": 0.0029082496141037764, "phrase": "modern_fpga_devices"}, {"score": 0.0026366753045215558, "phrase": "centralized_single_memory"}, {"score": 0.0025892820006205475, "phrase": "astro"}, {"score": 0.0025518930446603335, "phrase": "xilinx_microblaze_technology"}, {"score": 0.0024430653423699327, "phrase": "mibench"}, {"score": 0.0023903999901926224, "phrase": "astro_machine"}, {"score": 0.002239103860494545, "phrase": "astro_platform"}, {"score": 0.002206801982145622, "phrase": "energy-delay_product"}, {"score": 0.002151388538895855, "phrase": "centralized_memory"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Memory-level parallelism", " FPGA", " Application-specific", " Reconfigurable", " Memory structure", " HLS"], "paper_abstract": "Emerging integrated CPU + FPGA hybrid platforms, such as the Extensible Processing Platform architecture from Xilinx [1], offer unprecedented opportunity to achieving both multifunctionality and real-time responsiveness for memory-intensive embedded applications. However, how to cost-effectively synthesize application-specific hardware constructs that fully exploit memory-level parallelism remains to be a key challenge. To address this problem, we propose a new FPGA-based embedded computer architecture, ASTRO (Application-Specific Hardware Traces with Reconfigurable Optimization). Our main contribution is the development of an integrated methodology that focuses on how to construct an application-specific memory access network capable of extracting the maximum amount of memory-level parallelism on a per-application basis. In particular, our proposed ASTRO architecture can (I) perform dynamic memory analysis to maximally extract the target application's instruction, loop and memory-level parallelism for performance enhancement, (2) synthesize highly efficient accelerators that enable parallelized memory accesses, and therefore (3) accomplish effective data orchestration by utilizing the capabilities of modern FPGA devices: abundant distributed block RAMs and reprogrammability. To empirically validate our ASTRO methodology, we have implemented a baseline embedded processor platform, a conventional CPU + accelerator with a centralized single memory, and a prototype ASTRO machine based on Xilinx MicroBlaze technology. Our experimental results show that on average for 10 benchmark applications from SPEC2006 and MiBench [2], the ASTRO machine achieves 8.6 times speedup compared to the baseline embedded processor platform and 1.7 times speedup compared to a conventional CPU + accelerator platform. More interestingly, the ASTRO platform achieves more than 40% reduction in energy-delay product compared to a conventional CPU + accelerator with a centralized memory. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "ASTRO: Synthesizing application-specific reconfigurable hardware traces to exploit memory-level parallelism", "paper_id": "WOS:000361924000013"}