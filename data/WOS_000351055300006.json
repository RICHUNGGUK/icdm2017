{"auto_keywords": [{"score": 0.042645023415629375, "phrase": "first_case"}, {"score": 0.015719716506582538, "phrase": "pairwise_comparisons"}, {"score": 0.011977399041953872, "phrase": "second_case"}, {"score": 0.011655501389519873, "phrase": "feature_importance"}, {"score": 0.004785682967399109, "phrase": "support_vector_machines"}, {"score": 0.0042490799524136594, "phrase": "consistent_weights"}, {"score": 0.004197551473726497, "phrase": "obvious_task"}, {"score": 0.0031124046570971398, "phrase": "new_approach"}, {"score": 0.002991262005863753, "phrase": "discrimination_power"}, {"score": 0.002771352849127134, "phrase": "distance-based_inconsistency_reduction"}, {"score": 0.002737695457580011, "phrase": "weight_assessment"}, {"score": 0.0026070935979443646, "phrase": "fully_consistent_or_almost_consistent_pairwise_comparison_tables"}, {"score": 0.002544141963686395, "phrase": "novel_concept"}, {"score": 0.0025286424059485745, "phrase": "feature_domain_overlappings"}, {"score": 0.0024600517975561127, "phrase": "feature_discrimination_power"}, {"score": 0.002265217884758413, "phrase": "particular_features"}, {"score": 0.002224056824144391, "phrase": "weighted_svms"}, {"score": 0.002117933042057335, "phrase": "iris"}, {"score": 0.0021049977753042253, "phrase": "vertebral"}], "paper_keywords": ["classification", " weighted features", " pairwise comparisons", " distance-based inconsistency", " support vector machines", " feature domain overlapping"], "paper_abstract": "Most existing classification algorithms either consider all features as equally important (equal weights), or do not analyze the consistency of weights assigned to features. When features are not equally important, assigning consistent weights is not an obvious task. In general, we have two cases. The first case assumes that a given sample of data does not contain any clues about the importance of features, so the weights are provided by a pool of experts and they are usually inconsistent. The second case assumes that the given sample contains some information about feature importance, hence we can derive the weights directly from the sample. In this paper, we deal with both cases. Pairwise comparisons and weighted support vector machines (SVMs) are used for the first case. For the second case, a new approach based on the observation that the feature importance could be determined by the discrimination power of features has been proposed. For the first case, we start with pairwise comparisons to rank the importance of features, then we use distance-based inconsistency reduction to refine the weight assessment and make the comparisons more precise. Next, we calculate the weights through the fully consistent or almost consistent pairwise comparison tables. For the second case, a novel concept of feature domain overlappings has been introduced. It can measure the feature discrimination power. This model is based on the assumption that less overlapping means more discriminatory ability, and this can be used to calculate weights characterizing the importance of particular features. For both cases, weighted SVMs are used to classify the data. Both methods have been tested using two benchmark datasets, Iris and Vertebral. The results were especially superior to those obtained without weights.", "paper_title": "On Classification with Pairwise Comparisons, Support Vector Machines and Feature Domain Overlapping", "paper_id": "WOS:000351055300006"}