{"auto_keywords": [{"score": 0.023437952156177652, "phrase": "fpga"}, {"score": 0.00481495049065317, "phrase": "matrix_operations"}, {"score": 0.004732785510739708, "phrase": "improved_deeply_pipelined_vector_reduction"}, {"score": 0.004195418010131832, "phrase": "common_operation"}, {"score": 0.004053362743156545, "phrase": "core_operator"}, {"score": 0.003501175642882274, "phrase": "input_data_elements"}, {"score": 0.003441352119167824, "phrase": "data_hazards"}, {"score": 0.003157174936641705, "phrase": "new_reduction_method"}, {"score": 0.0031032109441552287, "phrase": "low_latency"}, {"score": 0.0030501665085457606, "phrase": "high_pipeline_utilization"}, {"score": 0.0028963961037320805, "phrase": "proposed_design"}, {"score": 0.0027741761880779535, "phrase": "single_data"}, {"score": 0.002703327151461985, "phrase": "multiple_data"}, {"score": 0.002566997205079849, "phrase": "qr_decomposition"}, {"score": 0.00241658945942583, "phrase": "proposed_method"}], "paper_keywords": ["Reconfigurable hardware", " pipeline processors", " parallel algorithms", " parallel and vector implementations", " algorithm design and analysis"], "paper_abstract": "Many scientific or engineering applications involve matrix operations, in which reduction of vectors is a common operation. If the core operator of the reduction is deeply pipelined, which is usually the case, dependencies between the input data elements cause data hazards. To tackle this problem, we propose a new reduction method with low latency and high pipeline utilization. The performance of the proposed design is evaluated for both single data set and multiple data set scenarios. Further, QR decomposition is used to demonstrate how the proposed method can accelerate its execution. We implement the design on an FPGA and compare its results to other methods.", "paper_title": "Accelerating Matrix Operations with Improved Deeply Pipelined Vector Reduction", "paper_id": "WOS:000298381100002"}