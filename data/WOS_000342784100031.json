{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "vocal-tract_parameters"}, {"score": 0.028064332743181628, "phrase": "small_number"}, {"score": 0.0044922081848067135, "phrase": "voice_conversion"}, {"score": 0.004435972264700219, "phrase": "vc"}, {"score": 0.004325339932975582, "phrase": "articulatory_features"}, {"score": 0.004009894739765119, "phrase": "artificial_neural_network"}, {"score": 0.003960068662658058, "phrase": "ann"}, {"score": 0.0036476222647061243, "phrase": "speaker's_voice"}, {"score": 0.003579179502431823, "phrase": "target-speaker's_voice"}, {"score": 0.0032763212574036748, "phrase": "parallel_utterances"}, {"score": 0.00301801991152303, "phrase": "arbitrary_source-speaker"}, {"score": 0.0028511898481970595, "phrase": "source-speaker_data"}, {"score": 0.002780025943393764, "phrase": "vc_model"}, {"score": 0.002609770322855842, "phrase": "target-speaker_training_data"}, {"score": 0.002512650904797186, "phrase": "baseline_system"}, {"score": 0.0024654516678953658, "phrase": "gaussian_mixture_model"}, {"score": 0.0023290951071300433, "phrase": "experimental_results"}, {"score": 0.002256619934086924, "phrase": "training_data"}, {"score": 0.0022002633747977593, "phrase": "converted_voice"}, {"score": 0.0021049977753042253, "phrase": "speaker_individuality"}], "paper_keywords": ["voice conversion", " articulatory feature", " neural network", " arbitrary speaker"], "paper_abstract": "In this paper, we propose voice conversion (VC) based on articulatory features (AF) to vocal-tract parameters (VTP) mapping. An artificial neural network (ANN) is applied to map AF to VTP and to convert a speaker's voice to a target-speaker's voice. The proposed system is not only text-independent VC, in which it does not need parallel utterances between source and target-speakers, but can also be used for an arbitrary source-speaker. This means that our approach does not require source-speaker data to build the VC model. We are also focusing on a small number of target-speaker training data. For comparison, a baseline system based on Gaussian mixture model (GMM) approach is conducted. The experimental results for a small number of training data show that the converted voice of our approach is intelligible and has speaker individuality of the target-speaker.", "paper_title": "Mapping Articulatory-Features to Vocal-Tract Parameters for Voice Conversion", "paper_id": "WOS:000342784100031"}