{"auto_keywords": [{"score": 0.046040545801964726, "phrase": "mutual_information"}, {"score": 0.010612387000973441, "phrase": "fuzzy_rule-based_classifiers"}, {"score": 0.004648609688625397, "phrase": "incomplete_and_imprecise_data"}, {"score": 0.004472234553892357, "phrase": "numerical_tools"}, {"score": 0.004378854464130883, "phrase": "fuzzy_random_variables"}, {"score": 0.004067051881100314, "phrase": "crisp_estimations"}, {"score": 0.003996133359116611, "phrase": "continuous_variables"}, {"score": 0.003940286428597882, "phrase": "vague_datasets"}, {"score": 0.003659597920882104, "phrase": "mutual_information-based_ranking"}, {"score": 0.0035206146304891973, "phrase": "crisp_or_fuzzy_data"}, {"score": 0.003495915995048885, "phrase": "fuzzy_rule-based_systems"}, {"score": 0.0034228513102041182, "phrase": "fuzzification_interface"}, {"score": 0.0033868916699805224, "phrase": "fuzzification_process"}, {"score": 0.0032582312803728724, "phrase": "input_data"}, {"score": 0.0030689098754563982, "phrase": "fuzzy_rule-based_system"}, {"score": 0.0029627094945653427, "phrase": "fuzzified_variables"}, {"score": 0.00284009509859163, "phrase": "crisp_variables"}, {"score": 0.0026750045328382717, "phrase": "extended_definition"}, {"score": 0.0025733173062050018, "phrase": "numerical_algorithm"}, {"score": 0.0024929933447362554, "phrase": "vague_data"}, {"score": 0.002381365139274329, "phrase": "feature_selection_algorithm"}, {"score": 0.002298902547676131, "phrase": "genetic_optimization"}, {"score": 0.0021049977753042253, "phrase": "benchmark_problems"}], "paper_keywords": ["Genetic fuzzy systems", " Feature selection", " Vague data", " Fuzzy fitness"], "paper_abstract": "Algorithms for preprocessing databases with incomplete and imprecise data are seldom studied. For the most part, we lack numerical tools to quantify the mutual information between fuzzy random variables. Therefore, these algorithms (discretization, instance selection, feature selection, etc.) have to use crisp estimations of the interdependency between continuous variables, whose application to vague datasets is arguable. In particular, when we select features for being used in fuzzy rule-based classifiers, we often use a mutual information-based ranking of the relevance of inputs. But, either with crisp or fuzzy data, fuzzy rule-based systems route the input through a fuzzification interface. The fuzzification process may alter this ranking, as the partition of the input data does not need to be optimal. In our opinion, to discover the most important variables for a fuzzy rule-based system, we want to compute the mutual information between the fuzzified variables, and we should not assume that the ranking between the crisp variables is the best one. In this paper we address these problems, and propose an extended definition of the mutual information between two fuzzified continuous variables. We also introduce a numerical algorithm for estimating the mutual information from a sample of vague data. We will show that this estimation can be included in a feature selection algorithm, and also that, in combination with a genetic optimization, the same definition can be used to obtain the most informative fuzzy partition for the data. Both applications will be exemplified with the help of some benchmark problems. (C) 2008 Elsevier Inc. All rights reserved.", "paper_title": "Mutual information-based feature selection and partition design in fuzzy rule-based classifiers from vague data", "paper_id": "WOS:000261713600006"}