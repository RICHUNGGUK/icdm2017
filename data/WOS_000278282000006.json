{"auto_keywords": [{"score": 0.04367410472844428, "phrase": "visual_information"}, {"score": 0.011203281044380746, "phrase": "acoustic_signal"}, {"score": 0.00481495049065317, "phrase": "audiovisual_speech_perception"}, {"score": 0.00469678464293492, "phrase": "facial_gestures"}, {"score": 0.004553128404612054, "phrase": "phonemic_identification"}, {"score": 0.004122179528285764, "phrase": "consonant_articulation"}, {"score": 0.004071249707923223, "phrase": "lexical_representations"}, {"score": 0.003946650265907885, "phrase": "phoneme_monitoring_task"}, {"score": 0.0034851070574149993, "phrase": "white_noise"}, {"score": 0.0032546105164772995, "phrase": "consonant_detection"}, {"score": 0.0032143649757754595, "phrase": "noisy_conditions"}, {"score": 0.0030582832134483685, "phrase": "phoneme_detection_process"}, {"score": 0.00265038878247831, "phrase": "consonant_phonemes"}, {"score": 0.0023990982005125763, "phrase": "av_condition"}, {"score": 0.0022683432490549064, "phrase": "phoneme_identity"}, {"score": 0.002212535878761148, "phrase": "lexical_activation_processes"}, {"score": 0.0021851480717840484, "phrase": "word_recognition"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Audiovisual speech", " Lexical access", " Speech perception in noise", " Word recognition"], "paper_abstract": "Seeing the facial gestures of a speaker enhances phonemic identification in noise. The goal of this study was to assess whether the visual information regarding consonant articulation activates lexical representations. We conducted a phoneme monitoring task with word and pseudo-words in audio only (A) and audiovisual (AV) contexts with two levels of white noise masking the acoustic signal. The results confirmed that visual information enhances consonant detection in noisy conditions and also revealed that it accelerates the phoneme detection process. The consonants were detected faster in AV than in A only condition. Furthermore, when the acoustic signal was deteriorated, the consonant phonemes were better recognized when they were embedded in words rather than in pseudo-words in the AV condition. This provides evidence indicating that visual information on phoneme identity can contribute to lexical activation processes during word recognition. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "The word superiority effect in audiovisual speech perception", "paper_id": "WOS:000278282000006"}