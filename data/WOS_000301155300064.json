{"auto_keywords": [{"score": 0.03950870653097926, "phrase": "facial_surface"}, {"score": 0.00481495049065317, "phrase": "markerless_registration_framework"}, {"score": 0.004686963264680882, "phrase": "cranial_augmented-reality"}, {"score": 0.00450130420152996, "phrase": "image-to-patient_registration"}, {"score": 0.0042650992966174065, "phrase": "commercial_spatial_digitizing_devices"}, {"score": 0.004226949670141375, "phrase": "artificial_skin_markers"}, {"score": 0.004005083535629333, "phrase": "stereo-vision_system"}, {"score": 0.003933736547198066, "phrase": "third_camera"}, {"score": 0.00384633057714983, "phrase": "real-time_images"}, {"score": 0.0038119123317396954, "phrase": "ar-fusion_display"}, {"score": 0.003628024127607343, "phrase": "stereo_vision"}, {"score": 0.0034841647157189985, "phrase": "preoperative_computed_tomography"}, {"score": 0.003099723664407622, "phrase": "anatomical_information"}, {"score": 0.003058179790439378, "phrase": "ct_images"}, {"score": 0.0030171910207671205, "phrase": "physical_space"}, {"score": 0.002936849401568391, "phrase": "stereo-vision_reconstruction"}, {"score": 0.0028844769395018595, "phrase": "noisy_data"}, {"score": 0.002845809662579165, "phrase": "conventional_icp"}, {"score": 0.002708399936381754, "phrase": "improved_icp"}, {"score": 0.0025316254589087973, "phrase": "noise_resistance"}, {"score": 0.0024421008630165046, "phrase": "seamless_integration"}, {"score": 0.0024093494406195386, "phrase": "preoperative_ct_images"}, {"score": 0.0023451553255837317, "phrase": "stereo-vision_cameras"}, {"score": 0.0022422426163747925, "phrase": "ar"}, {"score": 0.0021920373388760314, "phrase": "markerless_image-to-patient_registration"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Medical augment reality", " Stereo vision", " ICP", " Registration"], "paper_abstract": "This study proposes a cranial augmented-reality (AR) system which characterizes on performing image-to-patient registration using only natural facial features. Its hardware includes only three calibrated CCD cameras but any commercial spatial digitizing devices or artificial skin markers. Two of the cameras are mounted together to form a stereo-vision system, while the third camera moves freely and captures real-time images for AR-fusion display. The facial surface of a patient is first reconstructed by stereo vision. Meanwhile, another facial surface is reconstructed from preoperative computed tomography (CT) images of the patient. A iterative closest point (ICP)-based algorithm is then used to register the two facial data sets, which transfers the anatomical information from the CT images to the physical space. Since the natural of stereo-vision reconstruction usually accompanies with noisy data, the conventional ICP also suffers from its inherent local-minimum problem. Therefore, we propose an improved ICP which embeds a weighting and perturbing strategy to increase robustness and the ability of noise resistance. As a result, with a seamless integration among the preoperative CT images, the patient, the stereo-vision cameras, and the movable camera, an immersive medical AR environment based on a markerless image-to-patient registration is thus accomplished. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Medical augment reality using a markerless registration framework", "paper_id": "WOS:000301155300064"}