{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multi-scale_support_vector_regression"}, {"score": 0.004653667500876187, "phrase": "non-flat_function"}, {"score": 0.004421770937919324, "phrase": "smooth_variations"}, {"score": 0.004310173770196077, "phrase": "hard_problem"}, {"score": 0.004060566667226606, "phrase": "common_support_vector_methods"}, {"score": 0.003991945164759028, "phrase": "svr"}, {"score": 0.0039244583421549585, "phrase": "lpr"}, {"score": 0.0031440159350875057, "phrase": "linear_regression"}, {"score": 0.0030645676308053444, "phrase": "combined_feature_space"}, {"score": 0.002838033152426417, "phrase": "translation_invariant_kernels"}, {"score": 0.002790004829699627, "phrase": "different_scales"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["non-flat function", " combination of feature spaces", " multi-scale support vector regression", " sparse representation", " loss function"], "paper_abstract": "Estimating the non-flat function which comprises both the steep variations and the smooth variations is a hard problem. The results achieved by the common support vector methods like SVR, LPR and LS-SVM are often unsatisfactory, because they cannot avoid underfitting and overfitting simultaneously. This paper takes this problem as a linear regression in a combined feature space which is implicitly defined by a set of translation invariant kernels with different scales, and proposes a multi-scale support vector regression (MS-SVR) method. MS-SVR performs better than SVR, LPR and LS-SVM in the experiments tried. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Non-flat function estimation with a multi-scale support vector regression", "paper_id": "WOS:000242602300042"}