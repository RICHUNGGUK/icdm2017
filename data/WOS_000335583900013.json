{"auto_keywords": [{"score": 0.03395416915055737, "phrase": "training_data"}, {"score": 0.00481495049065317, "phrase": "self-training_author_name"}, {"score": 0.004746065479362881, "phrase": "information_scarce_scenarios"}, {"score": 0.00433200902751133, "phrase": "manual_labeling"}, {"score": 0.004208881856146758, "phrase": "real-world_scenarios"}, {"score": 0.004050116768809519, "phrase": "common_situation"}, {"score": 0.0035914198812657897, "phrase": "first_step"}, {"score": 0.0035570425396761122, "phrase": "real-world_heuristics"}, {"score": 0.003169222811082848, "phrase": "third_supervised_author_assignment_step"}, {"score": 0.0030642636185693054, "phrase": "state-of-the-art_transductive_disambiguation_method"}, {"score": 0.0029203055813347874, "phrase": "training_example"}, {"score": 0.0028784478769295204, "phrase": "reliable_predictions"}, {"score": 0.0027697290872182477, "phrase": "standard_public_collections"}, {"score": 0.002716915166374506, "phrase": "minimum_set"}, {"score": 0.0025521085778978042, "phrase": "representative_unsupervised_author_grouping_disambiguation_methods"}, {"score": 0.00247944491239733, "phrase": "fully_supervised_author_assignment_methods"}, {"score": 0.0022626835039082746, "phrase": "personal_information"}, {"score": 0.002219516542316085, "phrase": "topnotch_performance"}, {"score": 0.0021049977753042253, "phrase": "scarce_information"}], "paper_keywords": [""], "paper_abstract": "We present a novel 3-step self-training method for author name disambiguation-SAND (self-training associative name disambiguator)-which requires no manual labeling, no parameterization (in real-world scenarios) and is particularly suitable for the common situation in which only the most basic information about a citation record is available (i.e., author names, and work and venue titles). During the first step, real-world heuristics on coauthors are able to produce highly pure (although fragmented) clusters. The most representative of these clusters are then selected to serve as training data for the third supervised author assignment step. The third step exploits a state-of-the-art transductive disambiguation method capable of detecting unseen authors not included in any training example and incorporating reliable predictions to the training data. Experiments conducted with standard public collections, using the minimum set of attributes present in a citation, demonstrate that our proposed method outperforms all representative unsupervised author grouping disambiguation methods and is very competitive with fully supervised author assignment methods. Thus, different from other bootstrapping methods that explore privileged, hard to obtain information such as self-citations and personal information, our proposed method produces topnotch performance with no (manual) training data or parameterization and in the presence of scarce information.", "paper_title": "Self-Training Author Name Disambiguation for Information Scarce Scenarios", "paper_id": "WOS:000335583900013"}