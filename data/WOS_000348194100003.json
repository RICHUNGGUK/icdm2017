{"auto_keywords": [{"score": 0.049613254104042076, "phrase": "conditional_random_field_model"}, {"score": 0.00481495049065317, "phrase": "spatiotemporal_activity"}, {"score": 0.004345085569121329, "phrase": "overlapping_views"}, {"score": 0.004260906498835763, "phrase": "different_stationary_uncalibrated_video_cameras"}, {"score": 0.003901754272977278, "phrase": "illumination_conditions"}, {"score": 0.003697287104870263, "phrase": "matching_method"}, {"score": 0.0036434002236454305, "phrase": "low-level_feature"}, {"score": 0.003319830633865628, "phrase": "proposed_method"}, {"score": 0.003192312493850036, "phrase": "geometric_effects"}, {"score": 0.00311510526624626, "phrase": "author's_matching_problem"}, {"score": 0.0029807934480637855, "phrase": "graph_cuts"}, {"score": 0.0029086869572567072, "phrase": "exhaustive_pixel-wise_matching"}, {"score": 0.0028106505443369545, "phrase": "performance_improvement"}, {"score": 0.0027561164046279413, "phrase": "temporal_activity-based_matching_method"}, {"score": 0.0026243534128245886, "phrase": "mathematical_model"}, {"score": 0.0025860636370864084, "phrase": "quantitative_results"}, {"score": 0.0025358880826911088, "phrase": "tam"}, {"score": 0.002498873893632726, "phrase": "scale-invariant_feature_transform"}, {"score": 0.002474532776776207, "phrase": "sift"}, {"score": 0.002414616656410503, "phrase": "real_life_examples"}, {"score": 0.0021999341184897217, "phrase": "higher_accuracy"}, {"score": 0.0021049977753042253, "phrase": "comparable_ones"}], "paper_keywords": [""], "paper_abstract": "In this study, the authors investigate how to find correspondences (pixel-level matches) between two video sequences with overlapping views, recorded by different stationary uncalibrated video cameras, without imposing any constrains on, or requiring any a priori knowledge of, the viewing or the illumination conditions under which these videos were obtained. They propose a matching method using a low-level feature, spatiotemporal activity (STA), which effectively combines both the photometric features and the statistic features and makes the proposed method robust to the pose, illumination and geometric effects. They formulate the author's matching problem as a conditional random field model and optimise it by using graph cuts, instead of applying exhaustive pixel-wise matching. A qualitative analysis of the performance improvement compared with the temporal activity-based matching method (TAM) is given by inference from a mathematical model and the quantitative results compared with the TAM and the scale-invariant feature transform (SIFT) are presented with real life examples. The experiments show that their method significantly outperforms the state-of-the-art methods with a higher accuracy and is orders of magnitudes faster than the comparable ones.", "paper_title": "Camera matching based on spatiotemporal activity and conditional random field model", "paper_id": "WOS:000348194100003"}