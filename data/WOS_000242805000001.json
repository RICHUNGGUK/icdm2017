{"auto_keywords": [{"score": 0.041317453120078444, "phrase": "micasa"}, {"score": 0.007004596951017792, "phrase": "experienced_analysts"}, {"score": 0.00481495049065317, "phrase": "input_command_syntax"}, {"score": 0.004662913362513954, "phrase": "interface_and_requirements_specifications"}, {"score": 0.004515655183335171, "phrase": "test_cases"}, {"score": 0.00444377150105556, "phrase": "dynamic_input_validation_testing"}, {"score": 0.004003511299646736, "phrase": "concept_tool"}, {"score": 0.003694652993546994, "phrase": "case_study_validation"}, {"score": 0.003549245218355768, "phrase": "empirical_validation"}, {"score": 0.0034926916198124484, "phrase": "large-scale_industrial_software"}, {"score": 0.002880196765572443, "phrase": "higher_syntactic_coverage"}, {"score": 0.0027890803075309926, "phrase": "additional_defects"}, {"score": 0.002553063001454625, "phrase": "experienced_testers'_cases"}, {"score": 0.0024524733595572084, "phrase": "test_case"}, {"score": 0.0022630008787375435, "phrase": "micasa_test_cases"}], "paper_keywords": ["specification analysis", " software testing", " input validation", " fault-based analysis", " fault-based testing", " empirical research", " syntax-based", " interface verification", " system testing", " static analysis", " dynamic testing", " case study"], "paper_abstract": "This research addresses the problem of statically analyzing input command syntax as defined in interface and requirements specifications and then generating test cases for dynamic input validation testing. The IVAT (Input Validation Analysis and Testing) technique has been developed, a proof-of-concept tool (MICASA) has been implemented, and a case study validation has been performed. Empirical validation on large-scale industrial software (from the Tomahawk Cruise Missile) shows that as compared with senior, experienced analysts and testers, MICASA found more syntactic requirement specification defects, generated test cases with higher syntactic coverage, and found additional defects. The experienced analysts found more semantic defects than MICASA, and the experienced testers' cases found 7.4 defects per test case as opposed to an average of 4.6 defects found by MICASA test cases. Additionally, the MICASA tool performed at less cost.", "paper_title": "Input validation analysis and testing", "paper_id": "WOS:000242805000001"}