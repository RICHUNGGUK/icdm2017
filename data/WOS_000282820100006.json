{"auto_keywords": [{"score": 0.043015938347115645, "phrase": "fda"}, {"score": 0.015719643769178723, "phrase": "dimensionality_reduction"}, {"score": 0.013580676367691752, "phrase": "fisher_discriminant_analysis"}, {"score": 0.004558564684763264, "phrase": "high-dimensional_data"}, {"score": 0.00441130431691048, "phrase": "important_task"}, {"score": 0.004363277689798392, "phrase": "information_processing"}, {"score": 0.004292212137716459, "phrase": "class_labels"}, {"score": 0.004245476558619167, "phrase": "training_data"}, {"score": 0.003466780226380516, "phrase": "good_classification_surface"}, {"score": 0.0032819448594643853, "phrase": "supervised_dimensionality_reduction"}, {"score": 0.00319324425647735, "phrase": "information_theory"}, {"score": 0.0030395624703152212, "phrase": "class-conditional_entropy_minimization"}, {"score": 0.002989991779830814, "phrase": "proposed_linear_dimensionality-reduction_technique"}, {"score": 0.002709045632654716, "phrase": "multiple_kernel_learning_problem"}, {"score": 0.0026357877401570764, "phrase": "proposed_framework"}, {"score": 0.0025786066704445304, "phrase": "novel_algorithm"}, {"score": 0.002454432810862053, "phrase": "classification_function"}, {"score": 0.0024276590297034064, "phrase": "kernel_combination_coefficients"}, {"score": 0.002223696715077018, "phrase": "kfda"}, {"score": 0.0021994343316143125, "phrase": "large-scale_benchmark_data_sets"}, {"score": 0.0021049977753042253, "phrase": "yeast_protein_function_annotation_task"}], "paper_keywords": [""], "paper_abstract": "Reducing the dimensionality of high-dimensional data without losing its essential information is an important task in information processing. When class labels of training data are available, Fisher discriminant analysis (FDA) has been widely used. However, the optimality of FDA is guaranteed only in a very restricted ideal circumstance, and it is often observed that FDA does not provide a good classification surface for many real problems. This letter treats the problem of supervised dimensionality reduction from the viewpoint of information theory and proposes a framework of dimensionality reduction based on class-conditional entropy minimization. The proposed linear dimensionality-reduction technique is validated both theoretically and experimentally. Then, through kernel Fisher discriminant analysis (KFDA), the multiple kernel learning problem is treated in the proposed framework, and a novel algorithm, which iteratively optimizes the parameters of the classification function and kernel combination coefficients, is proposed. The algorithm is experimentally shown to be comparable to or outperforms KFDA for large-scale benchmark data sets, and comparable to other multiple kernel learning techniques on the yeast protein function annotation task.", "paper_title": "A Conditional Entropy Minimization Criterion for Dimensionality Reduction and Multiple Kernel Learning", "paper_id": "WOS:000282820100006"}