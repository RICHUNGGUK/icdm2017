{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "auxiliary_information"}, {"score": 0.010741612432932469, "phrase": "low-rank_assumption"}, {"score": 0.004676895436217523, "phrase": "existing_analysis_methods"}, {"score": 0.004542780650208743, "phrase": "multi-way_arrays"}, {"score": 0.0042610532651691305, "phrase": "low_rank"}, {"score": 0.003950453462399077, "phrase": "completion_problems"}, {"score": 0.0031660031870090434, "phrase": "tensor_decomposition"}, {"score": 0.0030572112793962004, "phrase": "graph_laplacians"}, {"score": 0.002917931350071647, "phrase": "moderately_sparse_cases"}, {"score": 0.0028341130433482565, "phrase": "extremely_sparse_cases"}, {"score": 0.002752695791351096, "phrase": "present_two_kinds"}, {"score": 0.002720785798036066, "phrase": "iterative_algorithms"}, {"score": 0.0026892447164623247, "phrase": "approximate_solutions"}, {"score": 0.0025967927629150715, "phrase": "em-like_algorithms"}, {"score": 0.0023932142697579506, "phrase": "gradient-based_optimization"}, {"score": 0.002324433454350402, "phrase": "large_scale_datasets"}, {"score": 0.0022974765563692776, "phrase": "numerical_experiments"}, {"score": 0.0022708315711029423, "phrase": "tensor_completion"}, {"score": 0.002244494905883452, "phrase": "synthetic_and_benchmark_datasets"}, {"score": 0.002142161017595363, "phrase": "completion_accuracy"}, {"score": 0.0021049977753042253, "phrase": "existing_methods"}], "paper_keywords": ["Tensors", " Multi-way arrays", " CP-decomposition", " Tucker decomposition", " Side information"], "paper_abstract": "Most of the existing analysis methods for tensors (or multi-way arrays) only assume that tensors to be completed are of low rank. However, for example, when they are applied to tensor completion problems, their prediction accuracy tends to be significantly worse when only a limited number of entries are observed. In this paper, we propose to use relationships among data as auxiliary information in addition to the low-rank assumption to improve the quality of tensor decomposition. We introduce two regularization approaches using graph Laplacians induced from the relationships, one for moderately sparse cases and the other for extremely sparse cases. We also give present two kinds of iterative algorithms for approximate solutions: one based on an EM-like algorithms which is stable but not so scalable, and the other based on gradient-based optimization which is applicable to large scale datasets. Numerical experiments on tensor completion using synthetic and benchmark datasets show that the use of auxiliary information improves completion accuracy over the existing methods based only on the low-rank assumption, especially when observations are sparse.", "paper_title": "Tensor factorization using auxiliary information", "paper_id": "WOS:000306439000006"}