{"auto_keywords": [{"score": 0.031191120200075233, "phrase": "group_structure"}, {"score": 0.029498666301862063, "phrase": "learning_problem"}, {"score": 0.00481495049065317, "phrase": "support_vector_machine"}, {"score": 0.004698229304089357, "phrase": "acknowledged_powerful_tool"}, {"score": 0.003924121879214595, "phrase": "multiple_kernel_learning"}, {"score": 0.0035861227263414537, "phrase": "basis_kernels"}, {"score": 0.003386301445203071, "phrase": "learning_process"}, {"score": 0.003223883109446599, "phrase": "composite_kernel_learning"}, {"score": 0.0030692309090066166, "phrase": "distinct_components"}, {"score": 0.0023418133729330303, "phrase": "general_wrapper_algorithm"}, {"score": 0.002303720729387236, "phrase": "computing_solutions"}, {"score": 0.0021049977753042253, "phrase": "multi-channel_data"}], "paper_keywords": ["Supervized learning", " Support vector machine", " Kernel learning", " Structured kernels", " Feature selection and sparsity"], "paper_abstract": "The Support Vector Machine is an acknowledged powerful tool for building classifiers, but it lacks flexibility, in the sense that the kernel is chosen prior to learning. Multiple Kernel Learning enables to learn the kernel, from an ensemble of basis kernels, whose combination is optimized in the learning process. Here, we propose Composite Kernel Learning to address the situation where distinct components give rise to a group structure among kernels. Our formulation of the learning problem encompasses several setups, putting more or less emphasis on the group structure. We characterize the convexity of the learning problem, and provide a general wrapper algorithm for computing solutions. Finally, we illustrate the behavior of our method on multi-channel data where groups correspond to channels.", "paper_title": "Composite kernel learning", "paper_id": "WOS:000275754600005"}