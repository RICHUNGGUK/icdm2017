{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "large_data_sets"}, {"score": 0.004308630865024719, "phrase": "new_technique"}, {"score": 0.0036722834182246933, "phrase": "experimental_data"}, {"score": 0.003308649946463136, "phrase": "non-robust_methods"}, {"score": 0.003217896008931311, "phrase": "least_sum"}, {"score": 0.002899125545529459, "phrase": "trimmed_sub-set"}, {"score": 0.002761340122199076, "phrase": "least_trimmed_sum"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Outliers", " Reliable parameter estimation", " Robustness", " Large data sets"], "paper_abstract": "In this paper we propose a method for correctly detecting outliers based on a new technique developed to simultaneously evaluate mean, variance and outliers. This method is capable of self-regulating its robustness to suit the experimental data set under analysis, so as to overcome shortcomings of: (i) non-robust methods such as the least sum of squares; (ii) the need of the user in defining a trimmed sub-set of experimental points such as in least trimmed sum of squares; and (iii) the possibility to read the data set only once to evaluate the mean, variance, and outliers of a population by preserving robustness. (C) 2010 Published by Elsevier Ltd.", "paper_title": "Outlier detection in large data sets", "paper_id": "WOS:000287385800018"}