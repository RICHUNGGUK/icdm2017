{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "simultaneous_recognition"}, {"score": 0.004594582559945568, "phrase": "new_linear_model"}, {"score": 0.0041657281535389615, "phrase": "bilinear_models"}, {"score": 0.00397495478332679, "phrase": "algebraic_operations"}, {"score": 0.003941215575554871, "phrase": "facial_data_analysis"}, {"score": 0.00387459052649752, "phrase": "facial_emotion"}, {"score": 0.0037928847801943404, "phrase": "linear_combination"}, {"score": 0.003697100573612401, "phrase": "principal_components"}, {"score": 0.0036501160751879784, "phrase": "training_data"}, {"score": 0.0036191240628152205, "phrase": "neutral-to-emotion_deformations"}, {"score": 0.003468053168607071, "phrase": "pose_variations"}, {"score": 0.003409399407390298, "phrase": "recently_available_techniques"}, {"score": 0.0033660587983313536, "phrase": "proposed_approach"}, {"score": 0.003239304090565123, "phrase": "person's_neutral_and_emotion"}, {"score": 0.0031845067058084613, "phrase": "facial_deformations"}, {"score": 0.003117307618682836, "phrase": "identity_and_expression_recognition_accuracies"}, {"score": 0.0030515222178491923, "phrase": "resampled_matrices"}, {"score": 0.003025597247856977, "phrase": "linear_combinations"}, {"score": 0.002850168497994985, "phrase": "simultaneous_identity-expression"}, {"score": 0.002790004829699627, "phrase": "expression-only_recognition"}, {"score": 0.0027311076665349657, "phrase": "facial_action_codes"}, {"score": 0.0026620655619396263, "phrase": "annotated_facial_points"}, {"score": 0.002583713580625699, "phrase": "proposed_framework"}, {"score": 0.0025076619172878945, "phrase": "synthetic_matrices"}, {"score": 0.002475755804232436, "phrase": "wide_array"}, {"score": 0.0024547103576350233, "phrase": "natural_and_mixed_emotions"}, {"score": 0.0024234763342790852, "phrase": "chosen_identity"}, {"score": 0.0022062235065459274, "phrase": "first-order_deformations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["3D face recognition", " 3D facial expression recognition", " Bilinear model", " Biometrics", " Classification", " Deformable models"], "paper_abstract": "We propose a new linear model, based on resampling 3D face meshes to convert them to 3D matrices, to recognize identity and expression simultaneously. This contrasts with bilinear models currently used with 3D meshes. The matrices are amenable to algebraic operations for facial data analysis and synthesis. Facial emotion is represented as a linear combination of its identity and expression using principal components extracted from training data as neutral-to-emotion deformations. The linear model is applicable to other mesh data with pose variations after correction using recently available techniques. The proposed approach avoids the problem of correspondence between pairs of person's neutral and emotion meshes for estimating facial deformations used as features. Identity and expression recognition accuracies, obtained by representing resampled matrices as linear combinations of composite depth-color (gray) PCs, are better than the results in the literature on both simultaneous identity-expression using bilinear models and expression-only recognition using deformable models, facial action codes, distances between pairs of annotated facial points as features and others. The proposed framework can also be used to generate synthetic matrices displaying a wide array of natural and mixed emotions for any chosen identity. A byproduct is the result that second-order deformations as features do not seem to perform as effectively as first-order deformations for identity and expression recognition. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "On the simultaneous recognition of identity and expression from BU-3DFE datasets", "paper_id": "WOS:000308385800016"}