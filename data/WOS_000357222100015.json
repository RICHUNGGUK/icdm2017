{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "hmm-based_speech_synthesis"}, {"score": 0.0046781613377273774, "phrase": "emotion_transplantation_method"}, {"score": 0.004567129988306349, "phrase": "synthetic_speech_model"}, {"score": 0.004458722048888919, "phrase": "csmaplr_adaptation"}, {"score": 0.004352876088312741, "phrase": "emotional_information"}, {"score": 0.004270003565426343, "phrase": "different_speaker_model"}, {"score": 0.0041287394089001405, "phrase": "original_speaker"}, {"score": 0.003992129945230457, "phrase": "proposed_method"}, {"score": 0.0037864980290391354, "phrase": "average_voice_model"}, {"score": 0.0036611708297251645, "phrase": "single_cascade"}, {"score": 0.0035570425396761122, "phrase": "desired_emotion"}, {"score": 0.0035060903664150115, "phrase": "target_speaker"}, {"score": 0.0030058503645435455, "phrase": "perceptual_tests"}, {"score": 0.0028646286762572274, "phrase": "perceived_naturalness"}, {"score": 0.002837188425640173, "phrase": "emotional_text"}, {"score": 0.0027431953780099826, "phrase": "proposed_transplanted_emotional_speech_synthesis"}, {"score": 0.002690886043654469, "phrase": "traditional_neutral_speech_synthesis"}, {"score": 0.0026268961477241026, "phrase": "big_increase"}, {"score": 0.0025892330566358503, "phrase": "perceived_emotional_strength"}, {"score": 0.0025521085778978042, "phrase": "synthesized_utterances"}, {"score": 0.0025155150482635688, "phrase": "slight_cost"}, {"score": 0.0024914105981393127, "phrase": "speech_quality"}, {"score": 0.0024556852466581527, "phrase": "final_evaluation"}, {"score": 0.00242047093248845, "phrase": "robotic_laboratory_assistant_application"}, {"score": 0.00236289633510808, "phrase": "emotional_speech"}, {"score": 0.0022956075241520064, "phrase": "students'_satisfaction"}, {"score": 0.0022626835039082746, "phrase": "dialog_system"}, {"score": 0.002208853811052348, "phrase": "proposed_emotion_transplantation_system"}, {"score": 0.002166711569953301, "phrase": "real_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Statistical parametric speech synthesis", " Expressive speech synthesis", " Cascade adaptation", " Emotion transplantation"], "paper_abstract": "This paper proposes an emotion transplantation method capable of modifying a synthetic speech model through the use of CSMAPLR adaptation in order to incorporate emotional information learned from a different speaker model while maintaining the identity of the original speaker as much as possible. The proposed method relies on learning both emotional and speaker identity information by means of their adaptation function from an average voice model, and combining them into a single cascade transform capable of imbuing the desired emotion into the target speaker. This method is then applied to the task of transplanting four emotions (anger, happiness, sadness and surprise) into 3 male speakers and 3 female speakers and evaluated in a number of perceptual tests. The results of the evaluations show how the perceived naturalness for emotional text significantly favors the use of the proposed transplanted emotional speech synthesis when compared to traditional neutral speech synthesis, evidenced by a big increase in the perceived emotional strength of the synthesized utterances at a slight cost in speech quality. A final evaluation with a robotic laboratory assistant application shows how by using emotional speech we can significantly increase the students' satisfaction with the dialog system, proving how the proposed emotion transplantation system provides benefits in real applications. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Emotion transplantation through adaptation in HMM-based speech synthesis", "paper_id": "WOS:000357222100015"}