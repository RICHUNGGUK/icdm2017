{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "view-independent_face_recognition"}, {"score": 0.0038392331564122387, "phrase": "face_space"}, {"score": 0.0032760377953971248, "phrase": "predetermined_views"}, {"score": 0.0032026066791743866, "phrase": "experimental_results"}, {"score": 0.0028271058251633815, "phrase": "intermediate_unseen_views"}, {"score": 0.0027017308406240563, "phrase": "neurophysiological_evidences"}, {"score": 0.0025819015229390663, "phrase": "proposed_model"}, {"score": 0.002495521662819317, "phrase": "similar_mechanisms"}, {"score": 0.002253299769886694, "phrase": "view_independent_face_recognition"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["view-independent face recognition", " mixture of experts", " teacher-directed learning", " principal component analysis"], "paper_abstract": "A model for view-independent face recognition, based on Mixture of Experts, ME, is presented. Instead of allowing ME to partition the face space automatically, it is directed to adapt to a particular partitioning corresponding to predetermined views. Experimental results show that this model performs well in recognizing faces of intermediate unseen views. There are neurophysiological evidences that underpin the proposed model, reporting similar mechanisms of pooling the outputs of several view-specific modules to perform view independent face recognition. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "View-independent face recognition with mixture of experts", "paper_id": "WOS:000253663800068"}