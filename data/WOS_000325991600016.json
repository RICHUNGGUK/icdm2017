{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "medical_image_analysis"}, {"score": 0.004776669953449352, "phrase": "spectral_clustering"}, {"score": 0.004719816332271661, "phrase": "powerful_and_versatile_technique"}, {"score": 0.004463278123628969, "phrase": "tedious_and_time-consuming_process"}, {"score": 0.004357627943575288, "phrase": "application-specific_choices"}, {"score": 0.004254467919664946, "phrase": "training_data"}, {"score": 0.004220624516321415, "phrase": "labeled_clusters"}, {"score": 0.004137184278868391, "phrase": "human_analyst"}, {"score": 0.003927848423072668, "phrase": "hierarchical_clustering"}, {"score": 0.0038043055953253047, "phrase": "appropriate_distance_measures"}, {"score": 0.003729065012001506, "phrase": "underlying_graph"}, {"score": 0.003641212302819532, "phrase": "laplacian"}, {"score": 0.0034981163169818803, "phrase": "open-box_approach"}, {"score": 0.0034289106230496816, "phrase": "interactive_system"}, {"score": 0.0033880439015902476, "phrase": "involved_mathematical_quantities"}, {"score": 0.00334766260508788, "phrase": "parameter_values"}, {"score": 0.003294566092612857, "phrase": "immediate_feedback"}, {"score": 0.0032423089921154503, "phrase": "required_decisions"}, {"score": 0.0030904433394138963, "phrase": "abstract_high-dimensional_feature_space"}, {"score": 0.003005151718290603, "phrase": "three-dimensional_data_space"}, {"score": 0.002945669860541221, "phrase": "better_understanding"}, {"score": 0.0028076592725295646, "phrase": "specific_parameter_settings"}, {"score": 0.0027631038845413393, "phrase": "similar_tasks"}, {"score": 0.0026336242881032645, "phrase": "final_clusters"}, {"score": 0.0025918235228843444, "phrase": "user_actions"}, {"score": 0.0025202582748972122, "phrase": "different_data"}, {"score": 0.0023925401023682717, "phrase": "wide_range"}, {"score": 0.0023451553255837317, "phrase": "triangular_meshes"}, {"score": 0.002326464619238653, "phrase": "regular_grids"}, {"score": 0.0022262909736042212, "phrase": "segmentation_protocols"}, {"score": 0.0022085455097790537, "phrase": "chest_ct"}, {"score": 0.0021909411820497707, "phrase": "brain_mri"}, {"score": 0.0021049977753042253, "phrase": "automated_manner"}], "paper_keywords": ["Image segmentation", " spectral clustering", " high-dimensional embeddings", " linked views", " programming with example"], "paper_abstract": "Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.", "paper_title": "Open-Box Spectral Clustering: Applications to Medical Image Analysis", "paper_id": "WOS:000325991600016"}