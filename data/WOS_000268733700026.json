{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "basis_functions"}, {"score": 0.008962508105913446, "phrase": "computational_effort"}, {"score": 0.0047057084749407485, "phrase": "comparative_study"}, {"score": 0.004412780054037622, "phrase": "regression_tasks"}, {"score": 0.004273196830970426, "phrase": "practical_requirements"}, {"score": 0.0038981499110532273, "phrase": "implicit_or_explicit_nature"}, {"score": 0.0038447943243941685, "phrase": "selection_process"}, {"score": 0.0037921662574137535, "phrase": "explicit_selection_methods"}, {"score": 0.0035887342563437935, "phrase": "search_process"}, {"score": 0.0035395987202335223, "phrase": "implicit_methods"}, {"score": 0.0033961782274326948, "phrase": "model_parameters"}, {"score": 0.0031991799574455555, "phrase": "former_methods"}, {"score": 0.0029722900280316216, "phrase": "earlier_work"}, {"score": 0.002945081009084692, "phrase": "bayesian_interpolation"}, {"score": 0.00290473242917264, "phrase": "efficient_methods"}, {"score": 0.002878140062594849, "phrase": "explicit_selection"}, {"score": 0.00283870598459543, "phrase": "model_evidence"}, {"score": 0.0027741761880779535, "phrase": "strong_indication"}, {"score": 0.002711109302199029, "phrase": "simple_models"}, {"score": 0.00257735013358606, "phrase": "implicit_and_explicit_methods"}, {"score": 0.002518746501941657, "phrase": "generalization_performance"}, {"score": 0.002427732996314194, "phrase": "different_numbers"}, {"score": 0.0022347698358650514, "phrase": "highest_evidence"}, {"score": 0.0021639307835832136, "phrase": "best_generalization_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Selection of basis functions", " Evidence maximization", " Regression"], "paper_abstract": "A comparative study is carried out in the problem of selecting a subset of basis functions in regression tasks. The emphasis is put on practical requirements, such as the sparsity of the solution or the computational effort. A distinction is made according to the implicit or explicit nature of the selection process. In explicit selection methods the basis functions are selected from a set of candidates with a search process. In implicit methods a model with all the basis functions is considered and the model parameters are computed in such a way that several of them become zero. The former methods have the advantage that both the sparsity and the computational effort can be controlled. We build on earlier work on Bayesian interpolation to design efficient methods for explicit selection guided by model evidence, since there is strong indication that the evidence prefers simple models that generalize fairly well. Our experimental results indicate that very similar results between implicit and explicit methods can be obtained regarding generalization performance. However, they make use of different numbers of basis functions and are obtained at very different computational costs. It is also reported that the models with the highest evidence are not necessarily those with the best generalization performance. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "An experimental study on methods for the selection of basis functions in regression", "paper_id": "WOS:000268733700026"}