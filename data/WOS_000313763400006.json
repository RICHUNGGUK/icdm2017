{"auto_keywords": [{"score": 0.04922237591220716, "phrase": "contextual_cues"}, {"score": 0.04015076015860894, "phrase": "semi-local_scale"}, {"score": 0.00481495049065317, "phrase": "interest_point"}, {"score": 0.0045404698551856125, "phrase": "context-aware_semi-local_detector"}, {"score": 0.0043793594257092805, "phrase": "systematic_answer"}, {"score": 0.00414830454375092, "phrase": "interest_points"}, {"score": 0.003929391999210588, "phrase": "interest_point_detectors"}, {"score": 0.0038764861784138117, "phrase": "traditionally_local_scale"}, {"score": 0.0034780071331554003, "phrase": "subsequent_recognition_phase"}, {"score": 0.0034311578789991363, "phrase": "interest_point_detection"}, {"score": 0.003235305151177897, "phrase": "first_phase"}, {"score": 0.003206179381953766, "phrase": "multiscale_spatial_correlations"}, {"score": 0.0031773149810690494, "phrase": "local_features"}, {"score": 0.0031062822219953524, "phrase": "contextual_gaussians"}, {"score": 0.003023129616910419, "phrase": "docg"}, {"score": 0.0029959082125682918, "phrase": "detector_context"}, {"score": 0.002955533639862811, "phrase": "contextually_salient_regions"}, {"score": 0.0028505007899807446, "phrase": "visual_attentions"}, {"score": 0.0027741761880779535, "phrase": "second_phase"}, {"score": 0.0027491902732542013, "phrase": "contextual_peaks"}, {"score": 0.0026634937939104177, "phrase": "docg_field"}, {"score": 0.0025804616931593897, "phrase": "feature_description"}, {"score": 0.0024440836179156593, "phrase": "mean_shift_search_kernels"}, {"score": 0.0024111277643627154, "phrase": "learning-based_casl_mechanism"}, {"score": 0.0023253967212081626, "phrase": "subsequent_visual_categorization_process"}, {"score": 0.0022631003204259224, "phrase": "image_search"}, {"score": 0.0022427071130840647, "phrase": "object_characterization"}, {"score": 0.0021434588322608653, "phrase": "superior_discriminability"}, {"score": 0.0021241414408077895, "phrase": "comparable_repeatability"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_works"}], "paper_keywords": ["Algorithms", " Semi-local feature", " context-aware feature", " learning-based feature extraction", " mean shift", " contextual Gaussian field", " supervised kernel learning", " multimedia systems", " knowledge representation", " Internet", " image analysis"], "paper_abstract": "How can interest point detectors benefit from contextual cues? In this articles, we introduce a context-aware semi-local detector (CASL) framework to give a systematic answer with three contributions: (1) We integrate the context of interest points to recurrently refine their detections. (2) This integration boosts interest point detectors from the traditionally local scale to a semi-local scale to discover more discriminative salient regions. (3) Such context-aware structure further enables us to bring forward category learning (usually in the subsequent recognition phase) into interest point detection to locate category-aware, meaningful salient regions. Our CASL detector consists of two phases. The first phase accumulates multiscale spatial correlations of local features into a difference of contextual Gaussians (DoCG) field. DoCG quantizes detector context to highlight contextually salient regions at a semi-local scale, which also reveals visual attentions to a certain extent. The second phase locates contextual peaks by mean shift search over the DoCG field, which subsequently integrates contextual cues into feature description. This phase enables us to integrate category. learning into mean shift search kernels. This learning-based CASL mechanism produces more category-aware features, which substantially benefits the subsequent visual categorization process. We conducted experiments in image search, object characterization, and feature detector repeatability evaluations, which reported superior discriminability and comparable repeatability to state-of-the-art works.", "paper_title": "Context-Aware Semi-Local Feature Detector", "paper_id": "WOS:000313763400006"}