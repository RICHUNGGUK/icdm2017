{"auto_keywords": [{"score": 0.04542490996391517, "phrase": "proposed_method"}, {"score": 0.0435912329636539, "phrase": "inter-camera_delays"}, {"score": 0.00481495049065317, "phrase": "multi-camera_synchronization"}, {"score": 0.0046875099587735825, "phrase": "multimodal_method"}, {"score": 0.004612662942073808, "phrase": "automatic_synchronization"}, {"score": 0.004563427013973105, "phrase": "audio-visual_recordings"}, {"score": 0.00441883624011048, "phrase": "independent_cameras"}, {"score": 0.004233119608341877, "phrase": "audio_and_video_channels"}, {"score": 0.003701401653850141, "phrase": "temporally_sharp_audio-visual_events"}, {"score": 0.0036422425344358037, "phrase": "audio-visual_events"}, {"score": 0.0035078427258024613, "phrase": "audio_onset"}, {"score": 0.0034148795808317555, "phrase": "well-localized_spatio-temporal_change"}, {"score": 0.002937879003671346, "phrase": "cross-validation_procedure"}, {"score": 0.0028293966058473476, "phrase": "camera_pairs"}, {"score": 0.002724909017963099, "phrase": "global_timeline"}, {"score": 0.002681315076008658, "phrase": "important_feature"}, {"score": 0.0025546627686955656, "phrase": "confidence_level"}, {"score": 0.0021392418081444798, "phrase": "audio-only_or_video-only_analysis"}, {"score": 0.0021049977753042253, "phrase": "fixed_and_hand-held_moving_cameras"}], "paper_keywords": ["Audio-visual processing", " Multiple cameras", " Synchronization", " Event detection"], "paper_abstract": "We present a multimodal method for the automatic synchronization of audio-visual recordings captured with a set of independent cameras. The proposed method jointly processes data from audio and video channels to estimate inter-camera delays that are used to temporally align the recordings. Our approach is composed of three main steps. First we extract from each recording temporally sharp audio-visual events. These audio-visual events are short and characterized by an audio onset happening jointly to a well-localized spatio-temporal change in the video data. Then, we estimate the inter-camera delays by assessing the co-occurrence of the events in the various recordings. Finally, we use a cross-validation procedure that combines the results for all camera pairs and aligns the recordings in a global timeline. An important feature of the proposed method is the estimation of the confidence level on the results that allows us to automatically reject recordings that are not reliable for the alignment. Results show that our method outperforms state-of-the-art approaches based on audio-only or video-only analysis with both fixed and hand-held moving cameras.", "paper_title": "Audio-visual events for multi-camera synchronization", "paper_id": "WOS:000349356300009"}