{"auto_keywords": [{"score": 0.043965416920295285, "phrase": "fda"}, {"score": 0.03779618007410234, "phrase": "lpp"}, {"score": 0.00481495049065317, "phrase": "dimensionality_reduction"}, {"score": 0.004666228956744244, "phrase": "local_fisher_discriminant_analysis"}, {"score": 0.004451676867747938, "phrase": "intrinsic_information"}, {"score": 0.004382364826200616, "phrase": "important_preprocessing_step"}, {"score": 0.0043367547691560175, "phrase": "high-dimensional_data_analysis"}, {"score": 0.004115697805448384, "phrase": "traditional_technique"}, {"score": 0.004072851768196397, "phrase": "supervised_dimensionality_reduction"}, {"score": 0.003926359151817743, "phrase": "undesired_results"}, {"score": 0.0037261429556468217, "phrase": "unsupervised_dimensionality_reduction_method"}, {"score": 0.003480993634130542, "phrase": "multimodal_data"}, {"score": 0.003251920460276645, "phrase": "label_information"}, {"score": 0.003085989256759819, "phrase": "supervised_learning_scenarios"}, {"score": 0.0029438813080245544, "phrase": "new_linear_supervised_dimensionality_reduction_method"}, {"score": 0.0028982724449557397, "phrase": "fisher"}, {"score": 0.002678944072162297, "phrase": "lpp._lfda"}, {"score": 0.002637160140011997, "phrase": "analytic_form"}, {"score": 0.0025960262223338293, "phrase": "embedding_transformation"}, {"score": 0.0024377918036784336, "phrase": "generalized_eigenvalue_problem"}, {"score": 0.002374735066990346, "phrase": "practical_usefulness"}, {"score": 0.0023499703712897293, "phrase": "high_scalability"}, {"score": 0.0023133055945761235, "phrase": "lfda_method"}, {"score": 0.002289180040240783, "phrase": "data_visualization"}, {"score": 0.0022299587520401747, "phrase": "extensive_simulation_studies"}, {"score": 0.0021609076467365247, "phrase": "lfda"}, {"score": 0.0021049977753042253, "phrase": "non-linear_dimensionality_reduction_scenarios"}], "paper_keywords": ["dimensionality reduction", " supervised learning", " Fisher discriminant analysis", " locality preserving projection", " affinity matrix"], "paper_abstract": "Reducing the dimensionality of data without losing intrinsic information is an important preprocessing step in high-dimensional data analysis. Fisher discriminant analysis (FDA) is a traditional technique for supervised dimensionality reduction, but it tends to give undesired results if samples in a class are multimodal. An unsupervised dimensionality reduction method called locality-preserving projection (LPP) can work well with multimodal data due to its locality preserving property. However, since LPP does not take the label information into account, it is not necessarily useful in supervised learning scenarios. In this paper, we propose a new linear supervised dimensionality reduction method called local Fisher discriminant analysis (LFDA), which effectively combines the ideas of FDA and LPP. LFDA has an analytic form of the embedding transformation and the solution can be easily computed just by solving a generalized eigenvalue problem. We demonstrate the practical usefulness and high scalability of the LFDA method in data visualization and classification tasks through extensive simulation studies. We also show that LFDA can be extended to non-linear dimensionality reduction scenarios by applying the kernel trick.", "paper_title": "Dimensionality reduction of multimodal labeled data by local fisher discriminant analysis", "paper_id": "WOS:000248351700005"}