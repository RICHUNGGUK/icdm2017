{"auto_keywords": [{"score": 0.03754487150281628, "phrase": "image_pairs"}, {"score": 0.03644451033122438, "phrase": "human_stereo_vision"}, {"score": 0.03046698918573996, "phrase": "stereo_viewing_condition"}, {"score": 0.00481495049065317, "phrase": "selective_rendering"}, {"score": 0.004778088905211055, "phrase": "efficient_ray"}, {"score": 0.0047415081747150065, "phrase": "stereoscopic_images"}, {"score": 0.004705206179790976, "phrase": "depth-related_visual_effects"}, {"score": 0.004545240514015278, "phrase": "stereo-based_systems"}, {"score": 0.004493130934067195, "phrase": "depth_effect"}, {"score": 0.004357061494162031, "phrase": "disparate_image_pairs"}, {"score": 0.00429057323623293, "phrase": "monocular_environments"}, {"score": 0.004160612392068268, "phrase": "depth_information"}, {"score": 0.004112894218792621, "phrase": "single_image"}, {"score": 0.0038526069752138196, "phrase": "psychophysical_experiments"}, {"score": 0.003764713814123286, "phrase": "computational_effort"}, {"score": 0.0037072310568610723, "phrase": "perceptually_high-quality_rendering"}, {"score": 0.003512841739654183, "phrase": "fusing_capability"}, {"score": 0.003485913728272778, "phrase": "depth_perception"}, {"score": 0.0034194902384248006, "phrase": "ray-tracing-based_global_illumination_systems"}, {"score": 0.003290403747743492, "phrase": "rendering_process"}, {"score": 0.0030938932434437178, "phrase": "human_binocular"}, {"score": 0.002897906501262407, "phrase": "high_perceptual_quality"}, {"score": 0.0028100102841877835, "phrase": "subjects'_performance"}, {"score": 0.0027777389949155975, "phrase": "specific_visual_task"}, {"score": 0.0027458373015999916, "phrase": "accurate_depth_perception"}, {"score": 0.0026728137770370176, "phrase": "far_fewer_rendered_depth_cues"}, {"score": 0.0026421139329830755, "phrase": "stereo_viewing_environment"}, {"score": 0.002542298702137655, "phrase": "detailed_cues"}, {"score": 0.002522791642460087, "phrase": "significant_computational_time"}, {"score": 0.002427473263013356, "phrase": "better_task_performance"}, {"score": 0.002372015603684862, "phrase": "combined_rendering_time"}, {"score": 0.002273605493468005, "phrase": "single_monocular_image"}, {"score": 0.002154226045704907, "phrase": "depth-related_visual_tasks"}, {"score": 0.0021049977753042253, "phrase": "inherent_features"}], "paper_keywords": ["Stereoscopic images", " Perceptually-guided rendering", " Virtual reality"], "paper_abstract": "Depth-related visual effects are a key feature of many virtual environments. In stereo-based systems, the depth effect can be produced by delivering frames of disparate image pairs, while in monocular environments, the viewer has to extract this depth information from a single image by examining details such as perspective and shadows. This paper investigates via a number of psychophysical experiments, whether we can reduce computational effort and still achieve perceptually high-quality rendering for stereo imagery. We examined selectively rendering the image pairs by exploiting the fusing capability and depth perception underlying human stereo vision. In ray-tracing-based global illumination systems, a higher image resolution introduces more computation to the rendering process since many more rays need to be traced. We first investigated whether we could utilise the human binocular fusing ability and significantly reduce the resolution of one of the image pairs and yet retain a high perceptual quality under stereo viewing condition. Secondly, we evaluated subjects' performance on a specific visual task that required accurate depth perception. We found that subjects required far fewer rendered depth cues in the stereo viewing environment to perform the task well. Avoiding rendering these detailed cues saved significant computational time. In fact it was possible to achieve a better task performance in the stereo viewing condition at a combined rendering time for the image pairs less than that required for the single monocular image. The outcome of this study suggests that we can produce more efficient stereo images for depth-related visual tasks by selective rendering and exploiting inherent features of human stereo vision.", "paper_title": "Selective rendering for efficient ray traced stereoscopic images", "paper_id": "WOS:000273595200002"}