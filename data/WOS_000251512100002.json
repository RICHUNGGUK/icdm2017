{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "tempo"}, {"score": 0.004674952036988355, "phrase": "audio_recordings"}, {"score": 0.004073359218158693, "phrase": "musical_recordings"}, {"score": 0.003548905904860611, "phrase": "seven_submissions"}, {"score": 0.00266693888510356, "phrase": "musically_relevant_events"}, {"score": 0.0021682027434117095, "phrase": "contiguous_and_overlapping_excerpts"}, {"score": 0.0021049977753042253, "phrase": "detection_function_signal"}], "paper_keywords": [""], "paper_abstract": "This article describes a method to estimate and track the tempo of musical recordings which was submitted to the MIREX 2006 evaluation contest where it was ranked third out of seven submissions. The algorithm that we present is composed of three stages: first a front-end analyses the audio signal in order to extract a representation of the musically relevant events, the so-called \"detection function\". Then, the periodicity of these events is estimated in contiguous and overlapping excerpts of the detection function signal. Finally, the periodicities are tracked through time and the most energetic are selected as tempi.", "paper_title": "Tempo estimation for audio recordings", "paper_id": "WOS:000251512100002"}