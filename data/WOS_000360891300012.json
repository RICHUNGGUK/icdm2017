{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "det_curves"}, {"score": 0.004720606036240263, "phrase": "biometric_performance"}, {"score": 0.004605258779434384, "phrase": "experimental_outcome"}, {"score": 0.004404658750724105, "phrase": "chosen_application_scenario"}, {"score": 0.004212759658511567, "phrase": "biometric_samples"}, {"score": 0.0037039021744127783, "phrase": "typical_performance_curve"}, {"score": 0.003649277504586372, "phrase": "biometric_experiment"}, {"score": 0.0035424245257172234, "phrase": "different_application"}, {"score": 0.00320826350799124, "phrase": "biometric_performance_curve"}, {"score": 0.0031453010852936334, "phrase": "detection_error_tradeoff"}, {"score": 0.003114283314285167, "phrase": "equivalently_receiver's_operating_characteristics"}, {"score": 0.0030081030319492343, "phrase": "system_operator"}, {"score": 0.0029344771385297163, "phrase": "biometric_researcher"}, {"score": 0.002657511557782469, "phrase": "different_operating_conditions"}, {"score": 0.0025415366388578465, "phrase": "target_application"}, {"score": 0.0023245146355917626, "phrase": "system_performance"}, {"score": 0.002301572462091142, "phrase": "varying_quality"}], "paper_keywords": ["Biometrics", " perform evaluation/prediction", " bootstrap subset"], "paper_abstract": "Assessing biometric performance is challenging because an experimental outcome depends on the choice of demographics and the chosen application scenario of an experiment. If one can quantify biometric samples into good, bad, and ugly categories for one application, the proportion of these categories is likely to be different for another application. As a result, a typical performance curve of a biometric experiment cannot generalize to another different application setting, even though the same system is used. We propose an algorithm that is capable of generalizing a biometric performance curve in terms of detection error tradeoff or equivalently receiver's operating characteristics, by allowing the user (system operator, policy-maker, and biometric researcher) to explicitly set the proportion of data differently. This offers the possibility for the user to simulate different operating conditions that can better match the setting of a target application. We demonstrated the utility of the algorithm in three scenarios, namely: 1) estimating the system performance under varying quality; 2) spoof and zero-effort attacks; and 3) cross-device matching. Based on the results of 1300 use-case experiments, we found that the quality of prediction on unseen (test) data, measured in terms of coverage, is typically between 60% and 80%, which is significantly better than random, that is, 50%.", "paper_title": "Generalizing DET Curves Across Application Scenarios", "paper_id": "WOS:000360891300012"}