{"auto_keywords": [{"score": 0.04953289560992991, "phrase": "speech_prosody"}, {"score": 0.00481495049065317, "phrase": "negative_emotions"}, {"score": 0.0047057084749407485, "phrase": "everyday_communication"}, {"score": 0.0046253989970108985, "phrase": "nonverbal_emotional_cues"}, {"score": 0.0045726187330434025, "phrase": "auditory_and_visual_stimuli"}, {"score": 0.004443276312972159, "phrase": "emotional_meanings"}, {"score": 0.004243862930012258, "phrase": "facial_expressions"}, {"score": 0.004123781267600542, "phrase": "cross-modal_priming_task"}, {"score": 0.004053362743156545, "phrase": "facial_affect_decision_task"}, {"score": 0.00400709738633039, "phrase": "pell"}, {"score": 0.0038936755823756226, "phrase": "emotional_stimuli"}, {"score": 0.0037188360359702182, "phrase": "emotion_category"}, {"score": 0.003471135453226184, "phrase": "neutral_vocal_primes"}, {"score": 0.003372844338742438, "phrase": "facial_affect_decision"}, {"score": 0.0033152062780180073, "phrase": "emotionally_congruent_or_incongruent_face_target"}, {"score": 0.0031121406603482112, "phrase": "face_targets"}, {"score": 0.00298942278888105, "phrase": "vocal_prime"}, {"score": 0.002649472341607234, "phrase": "prime_and_target"}, {"score": 0.002530359917257626, "phrase": "attention_biases"}, {"score": 0.0025014259919355453, "phrase": "disgust-related_stimuli"}, {"score": 0.002416589459425828, "phrase": "vocal_emotional_expressions"}, {"score": 0.0023889533502525527, "phrase": "similar_valence"}, {"score": 0.0023346234464901978, "phrase": "category_specificity"}, {"score": 0.0022815262950738814, "phrase": "discrete_emotion_knowledge"}, {"score": 0.0022041312401435346, "phrase": "emotional_faces"}, {"score": 0.0021789194955896124, "phrase": "sensory_modalities"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Prosody", " Facial expressions", " Emotion", " Nonverbal cues", " Priming", " Category-specific processing"], "paper_abstract": "Everyday communication involves processing nonverbal emotional cues from auditory and visual stimuli. To characterize whether emotional meanings are processed with category-specificity from speech prosody and facial expressions, we employed a cross-modal priming task (the Facial Affect Decision Task; Pell, 2005a) using emotional stimuli with the same valence but that differed by emotion category. After listening to angry, sad, disgusted, or neutral vocal primes, subjects rendered a facial affect decision about an emotionally congruent or incongruent face target. Our results revealed that participants made fewer errors when judging face targets that conveyed the same emotion as the vocal prime, and responded significantly faster for most emotions (anger and sadness). Surprisingly, participants responded slower when the prime and target both conveyed disgust, perhaps due to attention biases for disgust-related stimuli. Our findings suggest that vocal emotional expressions with similar valence are processed with category specificity, and that discrete emotion knowledge implicitly affects the processing of emotional faces between sensory modalities. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Categorical processing of negative emotions from speech prosody", "paper_id": "WOS:000295745800001"}