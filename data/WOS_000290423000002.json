{"auto_keywords": [{"score": 0.03521977079607267, "phrase": "hmc"}, {"score": 0.00481495049065317, "phrase": "human_motion_capture"}, {"score": 0.00467207889925365, "phrase": "mobile_robot"}, {"score": 0.004552981066668676, "phrase": "multiple_feature_data_fusion"}, {"score": 0.004475266375001531, "phrase": "particle_filter"}, {"score": 0.0044369056710423065, "phrase": "marker-less_human_motion"}, {"score": 0.004286708921931472, "phrase": "single_camera"}, {"score": 0.004213519983188574, "phrase": "assistant_mobile_robot"}, {"score": 0.0041773934798743405, "phrase": "particle_filters"}, {"score": 0.0040186038781533946, "phrase": "robotic_context"}, {"score": 0.003967021436047945, "phrase": "numerous_approaches"}, {"score": 0.003799796252156605, "phrase": "model's_silhouette"}, {"score": 0.003751011827704279, "phrase": "tracked_human_limbs"}, {"score": 0.0036395944934310524, "phrase": "model_surface"}, {"score": 0.003426556090707852, "phrase": "best_model-to-image_fits"}, {"score": 0.0031166151196841308, "phrase": "so-called_auxiliary_scheme"}, {"score": 0.0028963961037320805, "phrase": "conventional_particle_filters"}, {"score": 0.002822434555587263, "phrase": "well-known_burst"}, {"score": 0.002738523189244011, "phrase": "high_dimensional_state-space"}, {"score": 0.002668582249630492, "phrase": "investigation_concerns_data_fusion"}, {"score": 0.002437525632451029, "phrase": "current_human_posture"}, {"score": 0.0024061887405214186, "phrase": "environmental_context"}, {"score": 0.0023046064114537503, "phrase": "indoor_sequences"}, {"score": 0.0022651818270925704, "phrase": "assistant_mobile_robot_highlight"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Computer vision", " Data fusion", " Particle filtering", " Human motion capture", " Assistant robot"], "paper_abstract": "This article describes a multiple feature data fusion applied to a particle filter for marker-less human motion capture (HMC) by using a single camera devoted to an assistant mobile robot. Particle filters have proved to be well suited to this robotic context. Like numerous approaches, the principle relies on the projection of the model's silhouette of the tracked human limbs and appearance features located on the model surface, to validate the particles (associated configurations) which correspond to the best model-to-image fits. Our particle filter based HMC system is improved and extended in two ways. First, our estimation process is based on the so-called AUXILIARY scheme which has been surprisingly seldom exploited for tracking purpose. This scheme is shown to outperform conventional particle filters as it limits drastically the well-known burst in term of particles when considering high dimensional state-space. The second line of investigation concerns data fusion. Data fusion is considered both in the importance and measurement functions with some degree of adaptability depending on the current human posture and the environmental context encountered by the robot. Implementation and experiments on indoor sequences acquired by an assistant mobile robot highlight the relevance and versatility of our HMC system. Extensions are finally discussed. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Towards human motion capture from a camera mounted on a mobile robot", "paper_id": "WOS:000290423000002"}