{"auto_keywords": [{"score": 0.045366511165128576, "phrase": "proposed_method"}, {"score": 0.007251755647093223, "phrase": "real-world_applications"}, {"score": 0.00481495049065317, "phrase": "learning_novel_objects_for_extended_mobile_manipulation"}, {"score": 0.004518442937844318, "phrase": "novel_objects"}, {"score": 0.004447201233380302, "phrase": "audio_visual_input"}, {"score": 0.0037935066882208235, "phrase": "complex_environments"}, {"score": 0.0037040785566765954, "phrase": "voice_conversion_technique"}, {"score": 0.003313741359811683, "phrase": "acquired_oov_word"}, {"score": 0.0031342307827666675, "phrase": "robotic_system"}, {"score": 0.003036040409062437, "phrase": "interactive_mobile_manipulation_tasks"}, {"score": 0.0022434880661725493, "phrase": "standard_task"}], "paper_keywords": ["Mobile manipulation", " Object learning", " Object recognition", " Out-of-vocabulary", " RoboCup@Home"], "paper_abstract": "We propose a method for learning novel objects from audio visual input. The proposed method is based on two techniques: out-of-vocabulary (OOV) word segmentation and foreground object detection in complex environments. A voice conversion technique is also involved in the proposed method so that the robot can pronounce the acquired OOV word intelligibly. We also implemented a robotic system that carries out interactive mobile manipulation tasks, which we call \"extended mobile manipulation\", using the proposed method. In order to evaluate the robot as a whole, we conducted a task \"Supermarket\" adopted from the RoboCup@Home league as a standard task for real-world applications. The results reveal that our integrated system works well in real-world applications.", "paper_title": "Learning Novel Objects for Extended Mobile Manipulation", "paper_id": "WOS:000300706800012"}