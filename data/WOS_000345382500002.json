{"auto_keywords": [{"score": 0.033466395273283905, "phrase": "processor_stall_cycles"}, {"score": 0.02793829552192061, "phrase": "rbr"}, {"score": 0.00481495049065317, "phrase": "retention_benefit_based_intelligent_cache_replacement"}, {"score": 0.004739056045644449, "phrase": "performance_loss"}, {"score": 0.004664352260912174, "phrase": "different_cache"}, {"score": 0.004542441734438654, "phrase": "modern_systems"}, {"score": 0.004400329132129292, "phrase": "memory_access_latency"}, {"score": 0.004129248271757936, "phrase": "different_misses"}, {"score": 0.004042635935882651, "phrase": "parallel_misses"}, {"score": 0.004000010693331517, "phrase": "store_misses"}, {"score": 0.003957833102043277, "phrase": "isolated_fetch"}, {"score": 0.0036167509502276294, "phrase": "cache_replacement_policy"}, {"score": 0.003287482882222731, "phrase": "retention_benefit"}, {"score": 0.0032527939106509946, "phrase": "retention_benefits"}, {"score": 0.0031342307827666675, "phrase": "cache_misses"}, {"score": 0.0029722900280316216, "phrase": "cache_hits"}, {"score": 0.002879158342988017, "phrase": "retention_benefit_based_replacement"}, {"score": 0.002744888626958772, "phrase": "aggregate_retention_benefits"}, {"score": 0.002561892963059385, "phrase": "total_retention_benefit"}, {"score": 0.0023532890136269986, "phrase": "minimum_total_retention_benefit"}, {"score": 0.002219790619936024, "phrase": "cache_performance"}, {"score": 0.0021501863832966966, "phrase": "multi-core_environment"}, {"score": 0.0021049977753042253, "phrase": "low_storage_overhead"}], "paper_keywords": ["retention benefit", " replacement", " last-level cache"], "paper_abstract": "The performance loss resulting from different cache misses is variable in modern systems for two reasons: 1) memory access latency is not uniform, and 2) the latency toleration ability of processor cores varies across different misses. Compared with parallel misses and store misses, isolated fetch and load misses are more costly. The variation of cache miss penalty suggests that the cache replacement policy should take it into account. To that end, first, we propose the notion of retention benefit. Retention benefits can evaluate not only the increment of processor stall cycles on cache misses, but also the reduction of processor stall cycles due to cache hits. Then, we propose Retention Benefit Based Replacement (RBR) which aims to maximize the aggregate retention benefits of blocks reserved in the cache. RBR keeps track of the total retention benefit for each block in the cache, and it preferentially evicts the block with the minimum total retention benefit on replacement. The evaluation shows that RBR can improve cache performance significantly in both single-core and multi-core environment while requiring a low storage overhead. It also outperforms other state-of-the-art techniques.", "paper_title": "Retention Benefit Based Intelligent Cache Replacement", "paper_id": "WOS:000345382500002"}