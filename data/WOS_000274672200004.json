{"auto_keywords": [{"score": 0.0466181575125851, "phrase": "ans"}, {"score": 0.04606394416606776, "phrase": "rousset"}, {"score": 0.009514153555997338, "phrase": "catastrophic_forgetting"}, {"score": 0.008678337332730476, "phrase": "connection_science"}, {"score": 0.008381607816404301, "phrase": "french"}, {"score": 0.00833984301116485, "phrase": "r.m."}, {"score": 0.00827785561741335, "phrase": "musca"}, {"score": 0.0082367717306342, "phrase": "s.c."}, {"score": 0.006124457577179684, "phrase": "opposition_method"}, {"score": 0.005234048020353545, "phrase": "never_seen_source_items"}, {"score": 0.005182074368673374, "phrase": "never_seen_control_items"}, {"score": 0.00481495049065317, "phrase": "nonlinear_system_attractors"}, {"score": 0.004767118498560508, "phrase": "never_seen_items"}, {"score": 0.0047197594186799054, "phrase": "nonlinear_neural_systems"}, {"score": 0.004638005069508673, "phrase": "memory_self-refreshing_mechanism"}, {"score": 0.0044898971618201255, "phrase": "distributed_network"}, {"score": 0.0042605287427860865, "phrase": "life_sciences"}, {"score": 0.00400263757329054, "phrase": "self-refreshing_memory"}, {"score": 0.0039529560974368595, "phrase": "sequential_learning_tasks_without_catastrophic_forgetting'"}, {"score": 0.003676681302049705, "phrase": "preventing_catastrophic_interference_in_multiple-sequence_learning"}, {"score": 0.0036583529244497504, "phrase": "coupled_reverberating_elman_networks"}, {"score": 0.0035591620927676463, "phrase": "w.d._gray"}, {"score": 0.0035414174699534133, "phrase": "c.d._schunn"}, {"score": 0.0035237610021979096, "phrase": "mahwah"}, {"score": 0.00348871079461183, "phrase": "lawrence_erlbaum"}, {"score": 0.0032124925725216303, "phrase": "artificial_neural_networks"}, {"score": 0.0031964707671375517, "phrase": "learning_temporal_sequences"}, {"score": 0.003025402277791397, "phrase": "realistic_self-refreshing_memory"}, {"score": 0.0029803524515453657, "phrase": "neural_information_processing-letters"}, {"score": 0.0028349616930802763, "phrase": "attractor_patterns"}, {"score": 0.002806743548497984, "phrase": "highly_distributed_artificial_neural_network"}, {"score": 0.0025331747901955266, "phrase": "centroid_level"}, {"score": 0.0025079529641763095, "phrase": "control_items"}, {"score": 0.002482981636848938, "phrase": "source_items"}, {"score": 0.002433780600402175, "phrase": "blank_networks"}, {"score": 0.0024095460126633294, "phrase": "selected_attractors"}, {"score": 0.002152947617684499, "phrase": "particular_type"}, {"score": 0.002126175824349934, "phrase": "distributed_artificial_neural_networks"}], "paper_keywords": ["human memory", " distributed neural networks", " memory self-refreshing", " nonlinear system attractors", " catastrophic forgetting", " familiarity"], "paper_abstract": "Attractors of nonlinear neural systems are at the core of the memory self-refreshing mechanism of human memory models that suppose memories are dynamically maintained in a distributed network [Ans, B., and Rousset, S. (1997), 'Avoiding Catastrophic Forgetting by Coupling Two Reverberating Neural Networks' Comptes Rendus de l'Academie des Sciences Paris, Life Sciences, 320, 989-997; Ans, B., and Rousset, S. (2000), 'Neural Networks with a Self-Refreshing Memory: Knowledge Transfer in Sequential Learning Tasks Without Catastrophic Forgetting', Connection Science, 12, 1-19; Ans, B., Rousset, S., French, R.M., and Musca, S.C. (2002), 'Preventing Catastrophic Interference in Multiple-Sequence Learning Using Coupled Reverberating Elman Networks', in Proceedings of the 24th Annual Meeting of the Cognitive Science Society, eds. W.D. Gray and C.D. Schunn, Mahwah, NJ: Lawrence Erlbaum Associates, pp. 71-76; Ans, B., Rousset, S., French, R.M., and Musca, S.C. (2004), 'Self-Refreshing Memory in Artificial Neural Networks: Learning Temporal Sequences Without Catastrophic Forgetting', Connection Science, 16, 71-99; Ans, B. (2004), 'Sequential Learning in Distributed Neural Networks Without Catastrophic Forgetting: A Single and Realistic Self-Refreshing Memory can do it', Neural Information Processing-Letters and Reviews, 4, 27-32]. Are humans able to learn never seen items from attractor patterns generated by a highly distributed artificial neural network? First, an opposition method was implemented to ensure that the attractors are not the items used to train the network, the source items: attractors were selected to be more similar (both at the exemplar and the centroid level) to some control items than to the source items. In spite of this very severe selection, blank networks trained only on selected attractors performed better at test on the never seen source items than on the never seen control items. The results of two behavioural experiments using the opposition method show that humans exhibit more familiarity with the never seen source items than with the never seen control items, just as networks do. Thus, humans are sensitive to the particular type of information that allows distributed artificial neural networks to dynamically maintain their memory, and this information does not amount to the exemplars used to train the network that produced the attractors.", "paper_title": "Artificial neural networks whispering to the brain: nonlinear system attractors induce familiarity with never seen items", "paper_id": "WOS:000274672200004"}