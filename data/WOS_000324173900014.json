{"auto_keywords": [{"score": 0.049272197070513044, "phrase": "clustered_architectures"}, {"score": 0.010243158598126696, "phrase": "greedy_approaches"}, {"score": 0.009969762971430216, "phrase": "spatial_and_temporal_scheduling"}, {"score": 0.00481495049065317, "phrase": "integrated_spatial"}, {"score": 0.00457553517865013, "phrase": "instruction-level_parallelism"}, {"score": 0.004529093447865156, "phrase": "cost-effective_manner"}, {"score": 0.004467900288375827, "phrase": "clustered_architecture"}, {"score": 0.004392565073466714, "phrase": "functional_units"}, {"score": 0.004333208536635007, "phrase": "smaller_units"}, {"score": 0.004188287972391714, "phrase": "copy_operations"}, {"score": 0.0041598882840506385, "phrase": "texas_instruments"}, {"score": 0.004007083686875716, "phrase": "embedded_processors"}, {"score": 0.003873027670786261, "phrase": "heavier_burden"}, {"score": 0.003532977898022071, "phrase": "schedule_copy_operations"}, {"score": 0.003391556348707911, "phrase": "local_blocks"}, {"score": 0.0031790892089501345, "phrase": "hard_problem"}, {"score": 0.003157510936118389, "phrase": "previous_work"}, {"score": 0.0028997895009747502, "phrase": "spatial_assignment"}, {"score": 0.002860546817196148, "phrase": "temporal_scheduling"}, {"score": 0.0027180455234834993, "phrase": "partitioning_approaches"}, {"score": 0.002681255756642227, "phrase": "well-known_phase"}, {"score": 0.0025826247025542213, "phrase": "constraint_programming_approach"}, {"score": 0.0024961041872030073, "phrase": "problem_decomposition_technique"}, {"score": 0.0024455860314641243, "phrase": "integrated_manner"}, {"score": 0.0023879358679564527, "phrase": "different_hardware_parameters"}, {"score": 0.002292243761395491, "phrase": "intercluster_communication_cost-on_application_performance"}, {"score": 0.0021338975690903014, "phrase": "state-of-the-art_technique"}, {"score": 0.0021050073366750198, "phrase": "spec"}], "paper_keywords": ["Design", " Algorithms", " Performance", " Automatic parallelization", " constraint programming"], "paper_abstract": "Many embedded processors use clustering to scale up instruction-level parallelism in a cost-effective manner. In a clustered architecture, the registers and functional units are partitioned into smaller units and clusters communicate through register-to-register copy operations. Texas Instruments, for example, has a series of architectures for embedded processors which are clustered. Such an architecture places a heavier burden on the compiler, which must now assign instructions to clusters (spatial scheduling), assign instructions to cycles (temporal scheduling), and schedule copy operations to move data between clusters. We consider instruction scheduling of local blocks of code on clustered architectures to improve performance. Scheduling for space and time is known to be a hard problem. Previous work has proposed greedy approaches based on list scheduling to simultaneously perform spatial and temporal scheduling and phased approaches based on first partitioning a block of code to do spatial assignment and then performing temporal scheduling. Greedy approaches risk making mistakes that are then costly to recover from, and partitioning approaches suffer from the well-known phase ordering problem. In this article, we present a constraint programming approach for scheduling instructions on clustered architectures. We employ a problem decomposition technique that solves spatial and temporal scheduling in an integrated manner. We analyze the effect of different hardware parameters-such as the number of clusters, issue-width, and intercluster communication cost-on application performance. We found that our approach was able to achieve an improvement of up to 26%, on average, over a state-of-the-art technique on superblocks from SPEC 2000 benchmarks.", "paper_title": "A Constraint Programming Approach for Integrated Spatial and Temporal Scheduling for Clustered Architectures", "paper_id": "WOS:000324173900014"}