{"auto_keywords": [{"score": 0.049734762741514144, "phrase": "facial_expression_recognition"}, {"score": 0.00481495049065317, "phrase": "texture_descriptors"}, {"score": 0.004745965928357563, "phrase": "thermal_imagery"}, {"score": 0.004661116930794176, "phrase": "active_research_area"}, {"score": 0.004594326191526569, "phrase": "potential_application"}, {"score": 0.0045612889352793584, "phrase": "human_emotion_analysis"}, {"score": 0.0044635893862404385, "phrase": "illumination_independent_approach"}, {"score": 0.004383766516923386, "phrase": "long_wave_infrared_imagery"}, {"score": 0.004305364955542171, "phrase": "facial_expression_recognition_systems"}, {"score": 0.004228359613476549, "phrase": "visible_spectrum"}, {"score": 0.004152725837204292, "phrase": "recognition_process"}, {"score": 0.004034504342397309, "phrase": "poorly_illuminated_environments"}, {"score": 0.004005476499933792, "phrase": "common_approaches"}, {"score": 0.003948043391567917, "phrase": "static_images"}, {"score": 0.003794297119656863, "phrase": "interest_selection"}, {"score": 0.0034541965053691307, "phrase": "decoupled_way"}, {"score": 0.003392363211686023, "phrase": "visual_learning_approach"}, {"score": 0.0033557940171476683, "phrase": "evolutionary_computation"}, {"score": 0.0032601856292942106, "phrase": "single_evolving_process"}, {"score": 0.0032250366795039715, "phrase": "first_task"}, {"score": 0.0031218401638802053, "phrase": "suitable_regions"}, {"score": 0.003088178133049113, "phrase": "feature_extraction"}, {"score": 0.0030328769643087066, "phrase": "second_task"}, {"score": 0.002905876524269158, "phrase": "matrix"}, {"score": 0.002862462250995423, "phrase": "region_descriptors"}, {"score": 0.0027708353425467927, "phrase": "best_subsets"}, {"score": 0.002624577999455744, "phrase": "svm_committee"}, {"score": 0.002577557228072987, "phrase": "thermal_images"}, {"score": 0.002486021541116251, "phrase": "experimental_results"}, {"score": 0.002468107263634476, "phrase": "effective_classification"}, {"score": 0.002423882939663573, "phrase": "human_observer"}, {"score": 0.0023719428612450546, "phrase": "pca"}, {"score": 0.0022466142994860445, "phrase": "fer"}, {"score": 0.0021825348057711628, "phrase": "developed_methodology"}, {"score": 0.00213567715613494, "phrase": "efficient_learning_mechanism"}, {"score": 0.0021202820950055193, "phrase": "different_types"}, {"score": 0.0021049977753042253, "phrase": "pattern_recognition_problems"}], "paper_keywords": ["facial expression recognition", " evolutionary computation", " co-occurrence matrix", " support vector machine"], "paper_abstract": "Facial expression recognition is an active research area that finds a potential application in human emotion analysis. This work presents an illumination independent approach for facial expression recognition based on long wave infrared imagery. In general, facial expression recognition systems are designed considering the visible spectrum. This makes the recognition process not robust enough to be deployed in poorly illuminated environments. Common approaches to facial expression recognition of static images are designed considering three main parts: (1) region of interest selection, (2) feature extraction, and (3) image classification. Most published articles propose methodologies that solve each of these tasks in a decoupled way. We propose a Visual Learning approach based on evolutionary computation that solves the first two tasks simultaneously using a single evolving process. The first task consists in the selection of a set of suitable regions where the feature extraction is performed. The second task consists in tuning the parameters that defines the extraction of the Gray Level Co-occurrence Matrix used to compute region descriptors, as well as the selection of the best subsets of descriptors. The output of these two tasks is used for classification by a SVM committee. A dataset of thermal images with three different expression classes is used to validate the performance. Experimental results show effective classification when compared to a human observer, as well as a PCA-SVM approach. This paper concludes that: (1) thermal Imagery provides relevant information for FER, and (2) that the developed methodology can be taken as an efficient learning mechanism for different types of pattern recognition problems. (C) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Visual learning of texture descriptors for facial expression recognition in thermal imagery", "paper_id": "WOS:000246747600010"}