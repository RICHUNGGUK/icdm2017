{"auto_keywords": [{"score": 0.04218262960910763, "phrase": "previous_work"}, {"score": 0.029420333683948755, "phrase": "geometric_space"}, {"score": 0.00481495049065317, "phrase": "matching_configurations"}, {"score": 0.0047709540557306284, "phrase": "image_features"}, {"score": 0.004684157900507474, "phrase": "attributed_graphs"}, {"score": 0.004577869668211548, "phrase": "model_features"}, {"score": 0.004515252649226697, "phrase": "important_component"}, {"score": 0.004332471656145115, "phrase": "imprecise_feature_detection"}, {"score": 0.004195418010131832, "phrase": "visually_similar_configurations"}, {"score": 0.004081385289516914, "phrase": "injective_matching"}, {"score": 0.0038624981944755813, "phrase": "explicit_many-to-many_vertex_correspondence"}, {"score": 0.0036553070575015344, "phrase": "low_distortion_embedding_function"}, {"score": 0.0035072146967082083, "phrase": "point_sets"}, {"score": 0.003459191419478298, "phrase": "vector_space"}, {"score": 0.0032585499655442404, "phrase": "resulting_points"}, {"score": 0.0031991799574455555, "phrase": "computed_flows"}, {"score": 0.0031553611552558986, "phrase": "many-to-many_vertex_correspondences"}, {"score": 0.0029586543333524904, "phrase": "distortion-free_embedding"}, {"score": 0.00290473242917264, "phrase": "input_graphs"}, {"score": 0.002878140062594849, "phrase": "metric_trees"}, {"score": 0.0026494723416072316, "phrase": "representational_power"}, {"score": 0.002461472107682778, "phrase": "recent_developments"}, {"score": 0.002405496949144104, "phrase": "l._empirical_evaluation"}, {"score": 0.002318566141177149, "phrase": "recognition_trials"}, {"score": 0.002255431275670053, "phrase": "previous_approaches"}, {"score": 0.002163930783583212, "phrase": "proposed_framework"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Distortion-free metric embedding", " Earth Mover's Distance", " Many-to-many matching", " Object recognition"], "paper_abstract": "Matching configurations of image features, represented as attributed graphs, to configurations of model features is an important component in many object recognition algorithms. Noisy segmentation of images and imprecise feature detection may lead to graphs that represent visually similar configurations that do not admit an injective matching. In previous work, we presented a framework which computed an explicit many-to-many vertex correspondence between attributed graphs of features configurations. The framework utilized a low distortion embedding function to map the nodes of the graphs into point sets in a vector space. The Earth Movers Distance (EMD) algorithm was then used to match the resulting points, with the computed flows specifying the many-to-many vertex correspondences between the input graphs. In this paper, we will present a distortion-free embedding, which represents input graphs as metric trees and then embeds them isometrically in the geometric space under the I, norm. This not only improves the representational power of graphs in the geometric space, it also reduces the complexity of the previous work using recent developments in computing EMD under l. Empirical evaluation of the algorithm on a set of recognition trials, including a comparison with previous approaches, demonstrates the effectiveness and robustness of the proposed framework. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "Efficient many-to-many feature matching under the l(1) norm", "paper_id": "WOS:000291507100007"}