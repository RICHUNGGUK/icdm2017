{"auto_keywords": [{"score": 0.03193798136705121, "phrase": "cuda"}, {"score": 0.00481495049065317, "phrase": "cuda_compiler"}, {"score": 0.00462919213721188, "phrase": "parallel_processor_architectures"}, {"score": 0.004551781491498328, "phrase": "programming_and_code_generation"}, {"score": 0.004376131419366239, "phrase": "programmability_challenge"}, {"score": 0.004372451254991936, "phrase": "bones"}, {"score": 0.0041136473765874815, "phrase": "efficient_and_readable_code"}, {"score": 0.003717528595128948, "phrase": "algorithmic_skeletons"}, {"score": 0.0036759314172445934, "phrase": "traditional_compilation"}, {"score": 0.0036144035798673967, "phrase": "\"algorithmic_species"}, {"score": 0.0034944094552943, "phrase": "program_code"}, {"score": 0.0033594249301033604, "phrase": "c_code"}, {"score": 0.0033218213825698417, "phrase": "class_information"}, {"score": 0.003070086433952691, "phrase": "skeleton-based_source-to-source_compiler_bones"}, {"score": 0.002805597755796506, "phrase": "host-accelerator_transfer_optimization"}, {"score": 0.00266693888510356, "phrase": "unique_approach"}, {"score": 0.002607527117561699, "phrase": "skeleton-based_compiler"}, {"score": 0.0025638362414466278, "phrase": "first_time"}, {"score": 0.0025208755851561368, "phrase": "automated_flow"}, {"score": 0.0024097920845706795, "phrase": "polybench_gpu_kernels"}, {"score": 0.0023694065215394593, "phrase": "geometric_mean_speed-ups"}, {"score": 0.0023035922232490106, "phrase": "ppcg"}, {"score": 0.0022270182923887012, "phrase": "five_rodinia_gpu_benchmarks"}, {"score": 0.0021049977753042253, "phrase": "hand-optimized_code"}], "paper_keywords": ["Performance", " Languages", " GPU", " algorithmic skeletons", " parallel programming", " compiler", " CUDA"], "paper_abstract": "The shift toward parallel processor architectures has made programming and code generation increasingly challenging. To address this programmability challenge, this article presents a technique to fully automatically generate efficient and readable code for parallel processors (with a focus on GPUs). This is made possible by combining algorithmic skeletons, traditional compilation, and \"algorithmic species,\" a classification of program code. Compilation starts by automatically annotating C code with class information (the algorithmic species). This code is then fed into the skeleton-based source-to-source compiler BONES to generate CUDA code. To generate efficient code, BONES also performs optimizations including host-accelerator transfer optimization and kernel fusion. This results in a unique approach, integrating a skeleton-based compiler for the first time into an automated flow. The benefits are demonstrated experimentally for PolyBench GPU kernels, showing geometric mean speed-ups of 1.4x and 2.4x compared to PPCG and PAR4ALL, and for five Rodinia GPU benchmarks, showing a gap of only 1.2x compared to hand-optimized code.", "paper_title": "Bones: An Automatic Skeleton-Based C-to-CUDA Compiler for GPUs", "paper_id": "WOS:000348232000001"}