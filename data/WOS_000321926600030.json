{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "joint_sparse_learning"}, {"score": 0.004427366754240748, "phrase": "intensive_attentions"}, {"score": 0.004044645056447888, "phrase": "specific_expressions"}, {"score": 0.003992729692096799, "phrase": "modern_film_production_and_computer_games"}, {"score": 0.0036006068766833103, "phrase": "mapping_functions"}, {"score": 0.0032468685934998335, "phrase": "different_expressions"}, {"score": 0.0026916956768363158, "phrase": "jsl"}, {"score": 0.0024906610581090223, "phrase": "mapping_function"}, {"score": 0.0024586427394152196, "phrase": "incomplete_and_intact_data"}, {"score": 0.0023650305205893353, "phrase": "wide_range"}, {"score": 0.0022457226013538343, "phrase": "proposed_approach"}, {"score": 0.0021883400011393564, "phrase": "representative_ones"}, {"score": 0.0021049977753042253, "phrase": "time_cost"}], "paper_keywords": ["3D facial expression generation", " facial expression retargeting", " sparse learning"], "paper_abstract": "3-D facial expression generation, including synthesis and retargeting, has received intensive attentions in recent years, because it is important to produce realistic 3-D faces with specific expressions in modern film production and computer games. In this paper, we present joint sparse learning (JSL) to learn mapping functions and their respective inverses to model the relationship between the high-dimensional 3-D faces (of different expressions and identities) and their corresponding low-dimensional representations. Based on JSL, we can effectively and efficiently generate various expressions of a 3-D face by either synthesizing or retargeting. Furthermore, JSL is able to restore 3-D faces with holes by learning a mapping function between incomplete and intact data. Experimental results on a wide range of 3-D faces demonstrate the effectiveness of the proposed approach by comparing with representative ones in terms of quality, time cost, and robustness.", "paper_title": "Joint Sparse Learning for 3-D Facial Expression Generation", "paper_id": "WOS:000321926600030"}