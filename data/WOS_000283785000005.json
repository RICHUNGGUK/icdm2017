{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "virtual_reality_applications"}, {"score": 0.004581162468419365, "phrase": "industrial_production_chains"}, {"score": 0.0044685410845412745, "phrase": "significant_investment_costs"}, {"score": 0.004402295697276237, "phrase": "adequate_supporting_hardware"}, {"score": 0.004188459638572375, "phrase": "major_companies"}, {"score": 0.004065156038847781, "phrase": "production_processes"}, {"score": 0.004024863549087511, "phrase": "small_and_medium_enterprises"}, {"score": 0.0035183010916001664, "phrase": "virtual_reality"}, {"score": 0.003264872488939969, "phrase": "single_camera_tracking"}, {"score": 0.0031061129850110994, "phrase": "video_camera"}, {"score": 0.0030600032877646263, "phrase": "infrared_strobes"}, {"score": 0.00299958349498286, "phrase": "novel_iterative_geometric_pose_estimation_algorithm"}, {"score": 0.002955050521440921, "phrase": "marker-based_single_camera_tracking"}, {"score": 0.0028536871476905847, "phrase": "multiple_ptrack_units"}, {"score": 0.002797329638474873, "phrase": "tracking_range"}, {"score": 0.002701361707441567, "phrase": "smooth_transition"}, {"score": 0.0026745503978347143, "phrase": "tracked_labels"}, {"score": 0.002595698433525986, "phrase": "camera_range_areas"}, {"score": 0.0025191653363555193, "phrase": "contiguous_tracking_space"}, {"score": 0.002481747081849503, "phrase": "ptrack_sensor_fusion_module"}, {"score": 0.0023727863021828547, "phrase": "tracking_space"}, {"score": 0.0023143284925318916, "phrase": "interested_applications"}, {"score": 0.0022799458141165587, "phrase": "universal_test_setup"}, {"score": 0.0022573076362326135, "phrase": "optical_tracking_systems"}, {"score": 0.0021798257311714665, "phrase": "translational_and_rotational_accuracy"}, {"score": 0.0021049977753042253, "phrase": "competing_systems"}], "paper_keywords": ["Mixed reality", " Optical tracking", " Pose estimation"], "paper_abstract": "One of the reasons of how virtual reality applications penetrate industrial production chains slowly is because of significant investment costs to purchase adequate supporting hardware. As a consequence such applications are only available to major companies and fail to benefit the production processes of small and medium enterprises. In this article, we introduce PTrack, a real-time, low-cost, marker-based multiple camera tracking solution for virtual reality providing the accuracy and scalability usually found in much more expensive tracking systems. PTrack is composed of single camera tracking PTrack Units. Each unit is connected to a video camera equipped with infrared strobes and features a novel iterative geometric pose estimation algorithm which does marker-based single camera tracking and is therefore completely autonomous. Multiple PTrack units successively extend the tracking range of the system. For a smooth transition of tracked labels from one camera to another, camera range areas must overlap to form a contiguous tracking space. A PTrack Sensor Fusion Module then computes the pose of a certain label within tracking space and forwards it to interested applications. A universal test setup for optical tracking systems has been built allowing to measure translational and rotational accuracy of PTrack as well as of competing systems.", "paper_title": "A real-time low-cost marker-based multiple camera tracking solution for virtual reality applications", "paper_id": "WOS:000283785000005"}