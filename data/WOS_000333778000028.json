{"auto_keywords": [{"score": 0.03829477508328845, "phrase": "kernel_learning_algorithm"}, {"score": 0.00481495049065317, "phrase": "online_learning"}, {"score": 0.00475924837336259, "phrase": "kernel-based_algorithms"}, {"score": 0.004464156619275582, "phrase": "computational_complexity"}, {"score": 0.004412494693940597, "phrase": "classical_kernel-based_methods"}, {"score": 0.0042859292226559535, "phrase": "increasing_number"}, {"score": 0.004236321075918639, "phrase": "training_data"}, {"score": 0.004067152645111547, "phrase": "online_applications"}, {"score": 0.003770633265791941, "phrase": "information_theoretic_method"}, {"score": 0.0036838048761094933, "phrase": "sparse_version"}, {"score": 0.0035366216368204182, "phrase": "instantaneous_mutual_information"}, {"score": 0.003415137969569376, "phrase": "system_reliability"}, {"score": 0.0033559647822437298, "phrase": "estimated_output"}, {"score": 0.0030750809317435304, "phrase": "training_sample"}, {"score": 0.003039445153076014, "phrase": "informative_ones"}, {"score": 0.0029349892964423197, "phrase": "compact_dictionary"}, {"score": 0.002867348342846275, "phrase": "whole_data"}, {"score": 0.002752695791351096, "phrase": "robust_learning_scheme"}, {"score": 0.0026119782818898193, "phrase": "adaptive_learning_rate"}, {"score": 0.002492931483018372, "phrase": "learning_algorithm"}, {"score": 0.0023932142697579506, "phrase": "steady_state"}, {"score": 0.002205560249972527, "phrase": "recent_kernel_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Kernel methods", " Information theoretic", " Sparsification", " Online learning", " Mutual information"], "paper_abstract": "Kernel-based algorithms have been proven successful in many nonlinear modeling applications. However, the computational complexity of classical kernel-based methods grows superlinearly with the increasing number of training data, which is too expensive for online applications. In order to solve this problem, the paper presents an information theoretic method to train a sparse version of kernel learning algorithm. A concept named instantaneous mutual information is investigated to measure the system reliability of the estimated output. This measure is used as a criterion to determine the novelty of the training sample and informative ones are selected to form a compact dictionary to represent the whole data. Furthermore, we propose a robust learning scheme for the training of the kernel learning algorithm with an adaptive learning rate. This ensures the convergence of the learning algorithm and makes it converge to the steady state faster. We illustrate the performance of our proposed algorithm and compare it with some recent kernel algorithms by several experiments. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "An information theoretic sparse kernel algorithm for online learning", "paper_id": "WOS:000333778000028"}