{"auto_keywords": [{"score": 0.035992921575902365, "phrase": "capo"}, {"score": 0.015719709579057044, "phrase": "performance_measures"}, {"score": 0.014362992619295665, "phrase": "specific_performance_measures"}, {"score": 0.01354729815369643, "phrase": "needed_classifier"}, {"score": 0.010379886429556178, "phrase": "auxiliary_classifiers"}, {"score": 0.008383511424105903, "phrase": "linear_svmperf"}, {"score": 0.0069894099476264515, "phrase": "high_computational_efficiency"}, {"score": 0.004763565662615503, "phrase": "classifier_adaptation"}, {"score": 0.0046875099587735825, "phrase": "practical_applications"}, {"score": 0.004637478829869904, "phrase": "machine_learning_algorithms"}, {"score": 0.004011867299107537, "phrase": "nonlinear_classifier"}, {"score": 0.003969018740062018, "phrase": "nonlinear_and_nonsmooth_performance_measures"}, {"score": 0.0036422425344358037, "phrase": "specific_performance_measure"}, {"score": 0.003451766520526601, "phrase": "novel_two-step_approach"}, {"score": 0.0033243718810317254, "phrase": "first_train_nonlinear_auxiliary_classifiers"}, {"score": 0.003066945490483524, "phrase": "first_step"}, {"score": 0.002875391177926809, "phrase": "-shelf_learning_algorithms"}, {"score": 0.0028142286985235977, "phrase": "second_step"}, {"score": 0.002724909017963099, "phrase": "classifier_adaptation_problem"}, {"score": 0.0026384167183586015, "phrase": "quadratic_program_problem"}, {"score": 0.0024339783012484032, "phrase": "nonlinear_auxiliary_classifiers"}, {"score": 0.002306543826130521, "phrase": "large_variety"}, {"score": 0.0021975548867457606, "phrase": "contingency_table"}, {"score": 0.0021740540104138823, "phrase": "auc"}, {"score": 0.0021049977753042253, "phrase": "empirical_studies"}], "paper_keywords": ["Optimize performance measures", " classifier adaptation", " ensemble learning", " curriculum learning"], "paper_abstract": "In practical applications, machine learning algorithms are often needed to learn classifiers that optimize domain specific performance measures. Previously, the research has focused on learning the needed classifier in isolation, yet learning nonlinear classifier for nonlinear and nonsmooth performance measures is still hard. In this paper, rather than learning the needed classifier by optimizing specific performance measure directly, we circumvent this problem by proposing a novel two-step approach called CAPO, namely, to first train nonlinear auxiliary classifiers with existing learning methods and then to adapt auxiliary classifiers for specific performance measures. In the first step, auxiliary classifiers can be obtained efficiently by taking off-the-shelf learning algorithms. For the second step, we show that the classifier adaptation problem can be reduced to a quadratic program problem, which is similar to linear SVMperf and can be efficiently solved. By exploiting nonlinear auxiliary classifiers, CAPO can generate nonlinear classifier which optimizes a large variety of performance measures, including all the performance measures based on the contingency table and AUC, while keeping high computational efficiency. Empirical studies show that CAPO is effective and of high computational efficiency, and it is even more efficient than linear SVMperf.", "paper_title": "Efficient Optimization of Performance Measures by Classifier Adaptation", "paper_id": "WOS:000317857900008"}