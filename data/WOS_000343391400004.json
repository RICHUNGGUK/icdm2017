{"auto_keywords": [{"score": 0.035431234390884234, "phrase": "result_list"}, {"score": 0.010388950905180537, "phrase": "medline"}, {"score": 0.008449369147440622, "phrase": "medical_knowledge"}, {"score": 0.004573842508130535, "phrase": "clinical_decision_making"}, {"score": 0.004544561688606184, "phrase": "prevailing_approach"}, {"score": 0.004515467468684217, "phrase": "retrieved_articles"}, {"score": 0.004448300015467547, "phrase": "rank-ordered_list"}, {"score": 0.004382127278148236, "phrase": "higher_an_article"}, {"score": 0.004225474050046332, "phrase": "common_list-based_organization"}, {"score": 0.003954030683259778, "phrase": "case_study"}, {"score": 0.0039287021139713055, "phrase": "physician_preferences"}, {"score": 0.003895181909029215, "phrase": "medical_articles"}, {"score": 0.003780088982983617, "phrase": "comprehensive_relevance_evaluations"}, {"score": 0.0037238193456845124, "phrase": "hypothetical_articles"}, {"score": 0.0036683842424190378, "phrase": "online_medical_knowledge_source"}, {"score": 0.0036137713873827374, "phrase": "comprehensive_relevance_evaluations_asses"}, {"score": 0.0034621581245372138, "phrase": "correct_list_position"}, {"score": 0.00319134078848996, "phrase": "incorrect_list_position"}, {"score": 0.002998963650660305, "phrase": "relevance_evaluations"}, {"score": 0.00297335241739509, "phrase": "six_senior_physicians"}, {"score": 0.002916521664779295, "phrase": "article's_relevance"}, {"score": 0.002873069842157501, "phrase": "pairwise_comparisons"}, {"score": 0.0028607740220327857, "phrase": "different_combinations"}, {"score": 0.0028302635493019867, "phrase": "elicited_preferences"}, {"score": 0.0027642778632776207, "phrase": "additive_value_function"}, {"score": 0.0027524463528136966, "phrase": "value_functions"}, {"score": 0.0027289346217406357, "phrase": "individual_physicians"}, {"score": 0.0026312238938540787, "phrase": "significant_value"}, {"score": 0.002504558173968217, "phrase": "correctly_placed_article"}, {"score": 0.0024461474613359994, "phrase": "misplaced_relevant_article"}, {"score": 0.0024356742694508662, "phrase": "low_consideration"}, {"score": 0.002235356010935877, "phrase": "derived_value_functions"}, {"score": 0.0022020301282096194, "phrase": "clinical_decision_support_applications"}, {"score": 0.0021599099979586946, "phrase": "decision_making"}, {"score": 0.0021414489155042885, "phrase": "personalized_evaluation_measures"}, {"score": 0.0021231452870210965, "phrase": "typical_measures"}, {"score": 0.0021049977753042253, "phrase": "information_retrieval_systems"}], "paper_keywords": ["Organization of medical evidence", " physician preferences", " rank-ordered lists", " evidence-based medicine", " information retrieval", " decision support systems", " clinical"], "paper_abstract": "Background: Online medical knowledge repositories such as MEDLINE and The Cochrane Library are increasingly used by physicians to retrieve articles to aid with clinical decision making. The prevailing approach for organizing retrieved articles is in the form of a rank-ordered list, with the assumption that the higher an article is presented on a list, the more relevant it is. Objectives: Despite this common list-based organization, it is seldom studied how physicians perceive the association between the relevance of articles and the order in which articles are presented. In this paper we describe a case study that captured physician preferences for 3-element lists of medical articles in order to learn how to organize medical knowledge for decision-making. Methods: Comprehensive relevance evaluations were developed to represent 3-element lists of hypothetical articles that may be retrieved from an online medical knowledge source such as MEDLINE or The Cochrane Library. Comprehensive relevance evaluations asses not only an article's relevance for a query, but also whether it has been placed on the correct list position. In other words an article may be relevant and correctly placed on a result list (e.g. the most relevant article appears first in the result list), an article may be relevant for a query but placed on an incorrect list position (e.g. the most relevant article appears second in a result list), or an article may be irrelevant for a query yet still appear in the result list. The relevance evaluations were presented to six senior physicians who were asked to express their preferences for an article's relevance and its position on a list by pairwise comparisons representing different combinations of 3-element lists. The elicited preferences were assessed using a novel GRIP (Generalized Regression with Intensities of Preference) method and represented as an additive value function. Value functions were derived for individual physicians as well as the group of physicians. Results: The results show that physicians assign significant value to the 1st position on a list and they expect that the most relevant article is presented first. Whilst physicians still prefer obtaining a correctly placed article on position 2, they are also quite satisfied with misplaced relevant article. Low consideration of the 3rd position was uniformly confirmed. Conclusions: Our findings confirm the importance of placing the most relevant article on the 1st position on a list and the importance paid to position on a list significantly diminishes after the 2nd position.The derived value functions may be used by developers of clinical decision support applications to decide how best to organize medical knowledge for decision making and to create personalized evaluation measures that can augment typical measures used to evaluate information retrieval systems.", "paper_title": "Learning the Preferences of Physicians for the Organization of Result Lists of Medical Evidence Articles", "paper_id": "WOS:000343391400004"}