{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "video_visualization"}, {"score": 0.007831516474797238, "phrase": "motion_events"}, {"score": 0.006314811761246799, "phrase": "visual_signatures"}, {"score": 0.00468991337957911, "phrase": "computation_process"}, {"score": 0.0046164478775379105, "phrase": "meaningful_information"}, {"score": 0.004568108391981922, "phrase": "original_video_data_sets"}, {"score": 0.004472935829694716, "phrase": "extracted_information"}, {"score": 0.004379737380744606, "phrase": "appropriate_visual_representations"}, {"score": 0.004243552607799184, "phrase": "broad_treatment"}, {"score": 0.004089991141220082, "phrase": "typical_research_pipeline"}, {"score": 0.004047141845635495, "phrase": "concept_formulation"}, {"score": 0.0040047396607954325, "phrase": "system_development"}, {"score": 0.003941964605885606, "phrase": "path-finding_user_study"}, {"score": 0.0038597866217852353, "phrase": "field_trial"}, {"score": 0.003819339842998955, "phrase": "real_application_data"}, {"score": 0.0036424917384748024, "phrase": "fundamental_study"}, {"score": 0.003383475802364289, "phrase": "first_time"}, {"score": 0.003330406613112555, "phrase": "flow_visualization_techniques"}, {"score": 0.0031594291695784286, "phrase": "different_abstract_visual_representations"}, {"score": 0.003028969851366049, "phrase": "user_study"}, {"score": 0.002697245874076643, "phrase": "different_visualization_techniques"}, {"score": 0.0025858215477025117, "phrase": "developed_techniques"}, {"score": 0.002518525107994039, "phrase": "application_video_clips"}, {"score": 0.002266364679369248, "phrase": "first_set"}, {"score": 0.002207363758847308, "phrase": "ordinary_users"}, {"score": 0.0021385822825864425, "phrase": "visual_features"}, {"score": 0.0021049977753042253, "phrase": "video_visualizations"}], "paper_keywords": ["video visualization", " volume visualization", " flow visualization", " human factors", " user study", " visual signatures", " video processing", " optical flow", " GPU rendering"], "paper_abstract": "Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events.", "paper_title": "Visual signatures in video visualization", "paper_id": "WOS:000241383300056"}