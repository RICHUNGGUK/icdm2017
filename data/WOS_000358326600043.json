{"auto_keywords": [{"score": 0.049651030276363126, "phrase": "rgbd_images"}, {"score": 0.00481495049065317, "phrase": "smartannotator_an_interactive_tool_for_annotating_indoor_rgbd_images"}, {"score": 0.0047292449487169345, "phrase": "high_quality_annotations"}, {"score": 0.004208002469225673, "phrase": "valuable_priors"}, {"score": 0.00415166680936294, "phrase": "diverse_range"}, {"score": 0.0040777192615062815, "phrase": "scene_understanding"}, {"score": 0.004041238873048836, "phrase": "image_manipulation"}, {"score": 0.0036443699829248584, "phrase": "smartannotator"}, {"score": 0.003531474887552889, "phrase": "annotating_raw_rgbd_images"}, {"score": 0.003437486158494063, "phrase": "tedious_tasks"}, {"score": 0.0033459905006404207, "phrase": "potential_abstracted_cuboids"}, {"score": 0.0033011569787033297, "phrase": "object_interactions"}, {"score": 0.003198860258228543, "phrase": "ordered_list"}, {"score": 0.0030036501770192865, "phrase": "segment_labels"}, {"score": 0.0028586409810976367, "phrase": "remaining_hypotheses"}, {"score": 0.002543043781904587, "phrase": "better_suggestions"}, {"score": 0.00249767641333441, "phrase": "structural_and_geometric_priors"}, {"score": 0.0024641814990854463, "phrase": "previous_annotation_sessions"}, {"score": 0.0023770362063833903, "phrase": "large_number"}, {"score": 0.0023557346035701096, "phrase": "indoor_scenes"}, {"score": 0.0023346234464901978, "phrase": "different_users"}, {"score": 0.002313701040445819, "phrase": "experimental_settings"}, {"score": 0.0022520496048464406, "phrase": "existing_benchmark_datasets"}, {"score": 0.0022118619998034742, "phrase": "significant_improvements"}, {"score": 0.0021920373388760314, "phrase": "low-level_annotation_alternatives"}, {"score": 0.00216263228969761, "phrase": "code_and_benchmark_datasets"}, {"score": 0.0021049977753042253, "phrase": "project_page"}], "paper_keywords": [""], "paper_abstract": "RGBD images with high quality annotations, both in the form of geometric (i.e., segmentation) and structural (i.e., how do the segments mutually relate in 3D) information, provide valuable priors for a diverse range of applications in scene understanding and image manipulation. While it is now simple to acquire RGBD images, annotating them, automatically or manually, remains challenging. We present SMARTANNOTATOR, an interactive system to facilitate annotating raw RGBD images. The system performs the tedious tasks of grouping pixels, creating potential abstracted cuboids, inferring object interactions in 3D, and generates an ordered list of hypotheses. The user simply has to flip through the suggestions for segment labels, finalize a selection, and the system updates the remaining hypotheses. As annotations are finalized, the process becomes simpler with fewer ambiguities to resolve. Moreover, as more scenes are annotated, the system makes better suggestions based on the structural and geometric priors learned from previous annotation sessions. We test the system on a large number of indoor scenes across different users and experimental settings, validate the results on existing benchmark datasets, and report significant improvements over low-level annotation alternatives. (Code and benchmark datasets are publicly available on the project page.)", "paper_title": "SMARTANNOTATOR An Interactive Tool for Annotating Indoor RGBD Images", "paper_id": "WOS:000358326600043"}