{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "fully_empirical_stability-based_bound"}, {"score": 0.004521566043596533, "phrase": "learning_procedure"}, {"score": 0.0041703614123283165, "phrase": "structural_risk_minimization_framework"}, {"score": 0.003916098498242888, "phrase": "desirable_property"}, {"score": 0.0038119123317396954, "phrase": "learning_algorithm"}, {"score": 0.0031845067058084583, "phrase": "algorithmic-dependent_way"}, {"score": 0.002936849401568391, "phrase": "well-known_and_widespread_classifier"}, {"score": 0.002833035775182696, "phrase": "support_vector_machine"}, {"score": 0.0025892330566358503, "phrase": "obtained_bound"}, {"score": 0.00247529638625566, "phrase": "model_selection_purposes"}, {"score": 0.0024311346712789553, "phrase": "svm_classification"}, {"score": 0.002282667669149476, "phrase": "real-world_benchmarking_datasets"}], "paper_keywords": ["Algorithmic stability", " data-dependent bounds", " fully empirical bounds", " in-sample", " model selection", " out-of-sample", " support vector machine (SVM)"], "paper_abstract": "The purpose of this paper is to obtain a fully empirical stability-based bound on the generalization ability of a learning procedure, thus, circumventing some limitations of the structural risk minimization framework. We show that assuming a desirable property of a learning algorithm is sufficient to make data-dependency explicit for stability, which, instead, is usually bounded only in an algorithmic-dependent way. In addition, we prove that a well-known and widespread classifier, like the support vector machine (SVM), satisfies this condition. The obtained bound is then exploited for model selection purposes in SVM classification and tested on a series of real-world benchmarking datasets demonstrating, in practice, the effectiveness of our approach.", "paper_title": "Fully Empirical and Data-Dependent Stability-Based Bounds", "paper_id": "WOS:000360019000017"}