{"auto_keywords": [{"score": 0.040241282148229925, "phrase": "ri"}, {"score": 0.00481495049065317, "phrase": "simple_cell-like"}, {"score": 0.004569905085027681, "phrase": "patterned_firings"}, {"score": 0.004420472010542188, "phrase": "global_state_transitions"}, {"score": 0.004357927940322685, "phrase": "recurrent_networks"}, {"score": 0.004316722156877335, "phrase": "central_nervous_systems"}, {"score": 0.004215397034321004, "phrase": "learning_algorithm"}, {"score": 0.0040969285074699, "phrase": "information_maximization"}, {"score": 0.004038943596016986, "phrase": "recurrent_network"}, {"score": 0.0037969755088553326, "phrase": "information_retention"}, {"score": 0.003725470458263889, "phrase": "information_loss"}, {"score": 0.0035189057079817285, "phrase": "external_inputs"}, {"score": 0.0033875770020590796, "phrase": "natural_scenes"}, {"score": 0.0033395980635636644, "phrase": "ri-based_model"}, {"score": 0.0032922964156452696, "phrase": "recurrent_network_results"}, {"score": 0.0032149396890830575, "phrase": "gabor-like_selectivity"}, {"score": 0.003109674734960237, "phrase": "simple_cells"}, {"score": 0.0030656196752517836, "phrase": "primary_visual_cortex"}, {"score": 0.002979367540824502, "phrase": "external_input"}, {"score": 0.0028274743316389437, "phrase": "chain-like_spontaneous_activity"}, {"score": 0.0027610089418453614, "phrase": "critical_neuronal_avalanche"}, {"score": 0.0026202187680903063, "phrase": "input_temporal_firing_patterns"}, {"score": 0.002416589459425828, "phrase": "simple_framework"}, {"score": 0.002371018116266096, "phrase": "wide_range"}, {"score": 0.0022715929119140194, "phrase": "vitro_neuronal_networks"}, {"score": 0.0021971473452127126, "phrase": "novel_understanding"}, {"score": 0.0021763278640166707, "phrase": "experimental_results"}, {"score": 0.0021557052355026048, "phrase": "multineuronal_activity"}, {"score": 0.0021049977753042253, "phrase": "information-theoretic_point"}], "paper_keywords": [""], "paper_abstract": "Recently multineuronal recording has allowed us to observe patterned firings, synchronization, oscillation, and global state transitions in the recurrent networks of central nervous systems. We propose a learning algorithm based on the process of information maximization in a recurrent network, which we call recurrent infomax (RI). RI maximizes information retention and thereby minimizes information loss through time in a network. We find that feeding in external inputs consisting of information obtained from photographs of natural scenes into an RI-based model of a recurrent network results in the appearance of Gabor-like selectivity quite similar to that existing in simple cells of the primary visual cortex. We find that without external input, this network exhibits cell assembly-like and synfire chain-like spontaneous activity as well as a critical neuronal avalanche. In addition, we find that RI embeds externally input temporal firing patterns to the network so that it spontaneously reproduces these patterns after learning. RI provides a simple framework to explain a wide range of phenomena observed in in vivo and in vitro neuronal networks, and it will provide a novel understanding of experimental results for multineuronal activity and plasticity from an information-theoretic point of view.", "paper_title": "Recurrent Infomax Generates Cell Assemblies, Neuronal Avalanches, and Simple Cell-Like Selectivity", "paper_id": "WOS:000264896200006"}