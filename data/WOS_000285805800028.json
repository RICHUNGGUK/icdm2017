{"auto_keywords": [{"score": 0.03630916610929367, "phrase": "sg"}, {"score": 0.015719340735055466, "phrase": "dimensionality_reduction"}, {"score": 0.015600307550422998, "phrase": "graph_construction"}, {"score": 0.013195076667586526, "phrase": "intrinsic_structures"}, {"score": 0.004723322467153553, "phrase": "key_role"}, {"score": 0.004545240514015278, "phrase": "traditional_graph_construction_approaches"}, {"score": 0.0041446453895708, "phrase": "parameter_selection"}, {"score": 0.003764713814123286, "phrase": "sample_dependent_approach"}, {"score": 0.0036788184374592706, "phrase": "so-constructed_graph"}, {"score": 0.003650622777534568, "phrase": "sample-dependent_graph"}, {"score": 0.0032526334220034326, "phrase": "sample_pairs"}, {"score": 0.0031178024467857215, "phrase": "high_expense"}, {"score": 0.0030938932434437178, "phrase": "neighbor_parameter_selection"}, {"score": 0.0027670642397888494, "phrase": "graph_embedding"}, {"score": 0.0025917301734334395, "phrase": "lpp"}, {"score": 0.002542298702137655, "phrase": "sample-dependent_lpp"}, {"score": 0.0024088451312725924, "phrase": "attractive_properties"}, {"score": 0.002381169982803105, "phrase": "traditional_lpp"}, {"score": 0.002282380944889266, "phrase": "recognition_object_category"}, {"score": 0.0022648637058989463, "phrase": "handwritten_digits_recognition"}, {"score": 0.0021625417261202603, "phrase": "slpp"}, {"score": 0.002145942273032774, "phrase": "promising_results"}, {"score": 0.0021050027910612945, "phrase": "elsevier"}], "paper_keywords": ["Graph Laplacian", " Graph construction", " Dimensionality reduction (DR)", " Graph embedding", " Similarity neighborhood", " Local neighbor"], "paper_abstract": "Graph construction plays a key role on learning algorithms based on graph Laplacian However the traditional graph construction approaches of epsilon-neighborhood and k-nearest-neighbor need to predefine the same neighbor parameter epsilon (or k) for all samples which usually suffers from the difficulty of parameter selection and generally fail to effectively fit intrinsic structures of data To mitigate these limitations to a certain extent in this paper we present a novel and sample dependent approach of graph construction and name the so-constructed graph as Sample-dependent Graph (SG) Specifically instead of predefining the same neighbor parameter for all sample, the SG depends on samples in question to determine neighbors of each sample and similarities between sample pairs As a result it not only avoids the intractability and high expense of neighbor parameter selection but also can more effectively fit the intrinsic structures of data Further in order to show the effectiveness of the SG we apply it to the dimensionality reduction based on graph embedding and incorporate it into the state-of-the-art off-the-shelf unsupervised locality preserving projection (LPP) to develop the sample-dependent LPP (SLPP) SLPP naturally inherits the merits of SG and maintains the attractive properties of the traditional LPP The experiments on the toy and benchmark (UCI face recognition object category and handwritten digits recognition) datasets show the effectiveness and feasibility of the SG and SLPP with promising results (C) 2010 Elsevier B V All rights reserved", "paper_title": "Sample-dependent graph construction with application to dimensionality reduction", "paper_id": "WOS:000285805800028"}