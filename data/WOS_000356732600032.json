{"auto_keywords": [{"score": 0.03774156611827689, "phrase": "gp"}, {"score": 0.015719103545831094, "phrase": "large-scale_image_classification"}, {"score": 0.004644014990871423, "phrase": "classical_research_area"}, {"score": 0.004275650416511604, "phrase": "fast_and_accurate_applications"}, {"score": 0.004081385289516914, "phrase": "novel_framework"}, {"score": 0.0039772848945723435, "phrase": "task-specific_compact_coding"}, {"score": 0.0036616109902631293, "phrase": "optimization_algorithm"}, {"score": 0.003623949225126944, "phrase": "genetic_programming"}, {"score": 0.003513264130359459, "phrase": "boosting_trick"}, {"score": 0.003441352119167824, "phrase": "evolutionary_computation_methodology"}, {"score": 0.003301899275278983, "phrase": "natural_evolution"}, {"score": 0.0032510690712452147, "phrase": "prior_knowledge"}, {"score": 0.0030712785940935857, "phrase": "ece"}, {"score": 0.002977419551510206, "phrase": "binary_classification_function"}, {"score": 0.002769395841379498, "phrase": "adaboost_strategy"}, {"score": 0.002726740692380339, "phrase": "training_set"}, {"score": 0.002643386043540555, "phrase": "greedy_optimization"}, {"score": 0.0026026666736474404, "phrase": "small_hamming_distances"}, {"score": 0.00257586859792573, "phrase": "similar_samples"}, {"score": 0.0025493457404304446, "phrase": "large_distances"}, {"score": 0.0025230952890994236, "phrase": "dissimilar_samples"}, {"score": 0.0024082663813205195, "phrase": "usps"}, {"score": 0.0023346234464901978, "phrase": "cmu_pie"}, {"score": 0.0022283519468680475, "phrase": "accurate_and_robust_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Dimensionality reduction", " Large-scale image classification", " Evolutionary compact embedding", " Genetic programming", " AdaBoost"], "paper_abstract": "Effective dimensionality reduction is a classical research area for many large-scale analysis tasks in computer vision. Several recent methods attempt to learn either graph embedding or binary hashing for fast and accurate applications. In this paper, we propose a novel framework to automatically learn the task-specific compact coding, called evolutionary compact embedding (ECE), which can be regarded as an optimization algorithm combining genetic programming (GP) and a boosting trick. As an evolutionary computation methodology, GP can solve problems inspired by natural evolution without any prior knowledge of the solutions. In our evolutionary architecture, each bit of ECE is iteratively computed using a binary classification function, which is generated through GP evolving by jointly minimizing its empirical risk with the AdaBoost strategy on a training set. We address this as greedy optimization leading to small Hamming distances for similar samples and large distances for dissimilar samples. We then evaluate ECE on four image datasets: USPS digital hand-writing, CMU PIE face, CIFAR-10 tiny image and SUN397 scene, showing the accurate and robust performance of our method for large-scale image classification. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Evolutionary compact embedding for large-scale image classification", "paper_id": "WOS:000356732600032"}