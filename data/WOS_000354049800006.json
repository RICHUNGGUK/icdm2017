{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "rgb-d_images"}, {"score": 0.0076337732012340806, "phrase": "new_category"}, {"score": 0.004775335634705251, "phrase": "rgb_images"}, {"score": 0.004677711903652145, "phrase": "mining_visual_models"}, {"score": 0.004620093797504386, "phrase": "object-level_knowledge"}, {"score": 0.004488384083300084, "phrase": "comprehensive_category_model_base"}, {"score": 0.004414806639101985, "phrase": "large_set"}, {"score": 0.004378469469879815, "phrase": "cluttered_scenes"}, {"score": 0.004324521292490181, "phrase": "considerable_challenge"}, {"score": 0.004236074477264561, "phrase": "artificial_intelligence"}, {"score": 0.004081385289516914, "phrase": "least_human_supervision"}, {"score": 0.0038838500580958744, "phrase": "structural_knowledge"}, {"score": 0.0034879261743468574, "phrase": "model-learning_method"}, {"score": 0.0034165310204389682, "phrase": "single-labeled_object"}, {"score": 0.0031452231581533814, "phrase": "target_objects"}, {"score": 0.0030680994147125364, "phrase": "large_variations"}, {"score": 0.0028953973490895746, "phrase": "model_bias"}, {"score": 0.0026543514413663893, "phrase": "properly_trained_category_models"}, {"score": 0.002621590601574503, "phrase": "object_detection"}, {"score": 0.0025257081555100556, "phrase": "model_training"}, {"score": 0.0022679195103377124, "phrase": "depth_information"}, {"score": 0.002184943946549964, "phrase": "preliminary_testing"}, {"score": 0.0021490449563443025, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "fully_supervised_learning_methods"}], "paper_keywords": ["Design", " Algorithms", " Performance", " Theory", " Data mining", " computer vision", " big visual data", " visual mining", " transfer learning", " visual knowledge base", " RGB-D sensor"], "paper_abstract": "Mining object-level knowledge, that is, building a comprehensive category model base, from a large set of cluttered scenes presents a considerable challenge to the field of artificial intelligence. How to initiate model learning with the least human supervision (i.e., manual labeling) and how to encode the structural knowledge are two elements of this challenge, as they largely determine the scalability and applicability of any solution. In this article, we propose a model-learning method that starts from a single-labeled object for each category, and mines further model knowledge from a number of informally captured, cluttered scenes. However, in these scenes, target objects are relatively small and have large variations in texture, scale, and rotation. Thus, to reduce the model bias normally associated with less supervised learning methods, we use the robust 3D shape in RGB-D images to guide our model learning, then apply the properly trained category models to both object detection and recognition in more conventional RGB images. In addition to model training for their own categories, the knowledge extracted from the RGB-D images can also be transferred to guide model learning for a new category, in which only RGB images without depth information in the new category are provided for training. Preliminary testing shows that the proposed method performs as well as fully supervised learning methods.", "paper_title": "From RGB-D Images to RGB Images: Single Labeling for Mining Visual Models", "paper_id": "WOS:000354049800006"}