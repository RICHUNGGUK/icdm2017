{"auto_keywords": [{"score": 0.00440976345264104, "phrase": "edge-guided_dual-modality_image_reconstruction_approach"}, {"score": 0.0040385352882334235, "phrase": "knowledge-based_connection"}, {"score": 0.0037973594873521596, "phrase": "tight_fusion"}, {"score": 0.0037311260623089436, "phrase": "different_imaging_modalities"}, {"score": 0.0031289290660162145, "phrase": "image_reconstruction"}, {"score": 0.0025106241866273897, "phrase": "sampled_data"}, {"score": 0.0021049977753042253, "phrase": "simultaneous_ct-mri_system"}], "paper_keywords": ["l(1)-norm minimization", " multi-modality imaging", " CT-MRI system", " image reconstruction"], "paper_abstract": "To utilize the synergy between computed tomography (CT) and magnetic resonance imaging (MRI) data sets from an object at the same time, an edge-guided dual-modality image reconstruction approach is proposed. The key is to establish a knowledge-based connection between these two data sets for the tight fusion of different imaging modalities. Our scheme consists of four inter-related elements: 1) segmentation; 2) initial guess generation; 3) CT image reconstruction; and 4) MRI image reconstruction. Our experiments show that, aided by the image obtained from one imaging modality, even with highly under sampled data, we can better reconstruct the image of the other modality. This approach can be potentially useful for a simultaneous CT-MRI system.", "paper_title": "Edge-Guided Dual-Modality Image Reconstruction", "paper_id": "WOS:000209653800100"}