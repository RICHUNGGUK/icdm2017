{"auto_keywords": [{"score": 0.03963434235999932, "phrase": "single_node"}, {"score": 0.0338260040779578, "phrase": "dedicated_gpgpu_servers"}, {"score": 0.0048150405939747735, "phrase": "cuda"}, {"score": 0.004724158990345732, "phrase": "hpc_clusters"}, {"score": 0.004582423717777699, "phrase": "key_features"}, {"score": 0.004547656324173302, "phrase": "architectural_design"}, {"score": 0.0044111930537670705, "phrase": "advanced_framework"}, {"score": 0.004361077072629878, "phrase": "remote_and_transparent_gpgpu_acceleration"}, {"score": 0.004328042212335065, "phrase": "hpc"}, {"score": 0.004246333442872459, "phrase": "decoupling_gpus"}, {"score": 0.004134596278123439, "phrase": "shared_accelerators"}, {"score": 0.0040720661634333424, "phrase": "enhanced_flexibility"}, {"score": 0.004041155193307942, "phrase": "cluster_configurations"}, {"score": 0.0037161794591176033, "phrase": "whole_set"}, {"score": 0.00356359155432419, "phrase": "cuda_applications"}, {"score": 0.003483275102925249, "phrase": "gpu"}, {"score": 0.0031422859551159506, "phrase": "cluster_administrator's_policy"}, {"score": 0.002922637921202474, "phrase": "maintenance_costs"}, {"score": 0.0028893844749296863, "phrase": "performance_evaluation"}, {"score": 0.0027706507124407686, "phrase": "production_application"}, {"score": 0.002646665861584495, "phrase": "matrix-matrix_product"}, {"score": 0.0025867643733794724, "phrase": "regular_executions"}, {"score": 0.002557322657104706, "phrase": "local_cpu"}, {"score": 0.0024899186481178075, "phrase": "gpu-accelerated_lammps"}, {"score": 0.0022806798371116698, "phrase": "compute_nodes"}, {"score": 0.0021785729703227698, "phrase": "similar_cpu_virtualization_frameworks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Graphics processors", " Virtualization", " High performance computing", " Clusters"], "paper_abstract": "In this paper we detail the key features, architectural design, and implementation of rCUDA, an advanced framework to enable remote and transparent GPGPU acceleration in HPC clusters. rCUDA allows decoupling GPUs from nodes, forming pools of shared accelerators, which brings enhanced flexibility to cluster configurations. This opens the door to configurations with fewer accelerators than nodes, as well as permits a single node to exploit the whole set of GPUs installed in the cluster. In our proposal, CUDA applications can seamlessly interact with any GPU in the cluster, independently of its physical location. Thus, GPUs can be either distributed among compute nodes or concentrated in dedicated GPGPU servers, depending on the cluster administrator's policy. This proposal leads to savings not only in space but also in energy, acquisition, and maintenance costs. The performance evaluation in this paper with a series of benchmarks and a production application clearly demonstrates the viability of this proposal. Concretely, experiments with the matrix-matrix product reveal excellent performance compared with regular executions on the local CPU; on a much more complex application, the GPU-accelerated LAMMPS, we attain up to 11x speedup employing 8 remote accelerators from a single node with respect to a 12-core CPU-only execution. GPGPU service interaction in compute nodes, remote acceleration in dedicated GPGPU servers, and data transfer performance of similar CPU virtualization frameworks are also evaluated. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A complete and efficient CUDA-sharing solution for HPC clusters", "paper_id": "WOS:000347018800002"}