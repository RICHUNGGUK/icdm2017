{"auto_keywords": [{"score": 0.046073288735862604, "phrase": "em"}, {"score": 0.011195764282818719, "phrase": "hmm_estimation"}, {"score": 0.010592058752278553, "phrase": "hmm."}, {"score": 0.007740318778911741, "phrase": "expectation_maximization"}, {"score": 0.007616872798810595, "phrase": "ea"}, {"score": 0.007606962557403374, "phrase": "hidden_markov_model"}, {"score": 0.007554260704434371, "phrase": "signal_modeling"}, {"score": 0.00556158630962845, "phrase": "mathematical_reformulation"}, {"score": 0.004553725265085244, "phrase": "standard_training_algorithm"}, {"score": 0.004527931700922439, "phrase": "ea-sasem"}, {"score": 0.0044496727876592885, "phrase": "cel-em"}, {"score": 0.004367108655796158, "phrase": "local_convergence_problem"}, {"score": 0.004144510906908392, "phrase": "hybrid_metaheuristic_approaches"}, {"score": 0.004115697805448384, "phrase": "em_for"}, {"score": 0.003988487841970088, "phrase": "constraint-based_evolutionary_learning_approach"}, {"score": 0.0037456980766939836, "phrase": "hybrid_simulated_annealing_stochastic_version"}, {"score": 0.0036856760630599936, "phrase": "proposed_approaches"}, {"score": 0.0036425727071563965, "phrase": "simulated_annealing"}, {"score": 0.0033851312604425516, "phrase": "stochastic_step"}, {"score": 0.0033498651263935194, "phrase": "em_steps"}, {"score": 0.0032576020692463873, "phrase": "better_control"}, {"score": 0.0031458272260508637, "phrase": "better_hmm_estimation"}, {"score": 0.0030167329549240078, "phrase": "second_hybrid"}, {"score": 0.0029131986574478046, "phrase": "proposed_sasem"}, {"score": 0.0027838831266525773, "phrase": "best_constraint-based_ea_strategies"}, {"score": 0.002697726021470387, "phrase": "complementary_properties"}, {"score": 0.002660315261743895, "phrase": "sa"}, {"score": 0.002596026299616864, "phrase": "sasem"}, {"score": 0.0025600002954246567, "phrase": "sufficient_potential"}, {"score": 0.0025333084852052147, "phrase": "better_estimation"}, {"score": 0.002321417578175471, "phrase": "hmm"}, {"score": 0.002249527353528286, "phrase": "comprehensive_experiments"}, {"score": 0.0021875036343988806, "phrase": "speech_corpus"}, {"score": 0.0021646872269755067, "phrase": "experimental_results"}, {"score": 0.002127186380459509, "phrase": "higher_recognition_accuracies"}, {"score": 0.0021049977753042253, "phrase": "em_algorithm"}], "paper_keywords": ["Constraint-based probabilistic models", " expectation maximization (EM)", " hidden Markov model (HMM)", " hybrid metaheuristics", " signal modeling and classification", " speech recognition."], "paper_abstract": "The expectation maximization (EM) is the standard training algorithm for hidden Markov model (HMM). However, EM faces a local convergence problem in HMM estimation. This paper attempts to overcome this problem of EM and proposes hybrid metaheuristic approaches to EM for HMM. In our earlier research, a hybrid of a constraint-based evolutionary learning approach to EM (CEL-EM) improved HMM estimation. In this paper, we propose a hybrid simulated annealing stochastic version of EM (SASEM) that combines simulated annealing (SA) with EM. The novelty of our approach is that we develop a mathematical reformulation of HMM estimation by introducing a stochastic step between the EM steps and combine SA with EM to provide better control over the acceptance of stochastic and EM steps for better HMM estimation. We also extend our earlier work [1] and propose a second hybrid which is a combination of an EA and the proposed SASEM, (EA-SASEM). The proposed EA-SASEM uses the best constraint-based EA strategies from CEL-EM and stochastic reformulation of HMM. The complementary properties of EA and SA and stochastic reformulation of HMM of SASEM provide EA-SASEM with sufficient potential to find better estimation for HMM. To the best of our knowledge, this type of hybridization and mathematical reformulation have not been explored in the context of EM and HMM training. The proposed approaches have been evaluated through comprehensive experiments to justify their effectiveness in signal modeling using the speech corpus: TIMIT. Experimental results show that proposed approaches obtain higher recognition accuracies than the EM algorithm and CEL-EM as well.", "paper_title": "Hybrid Metaheuristic Approaches to the Expectation Maximization for Estimation of the Hidden Markov Model for Signal Modeling", "paper_id": "WOS:000342228100021"}