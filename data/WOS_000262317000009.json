{"auto_keywords": [{"score": 0.04440921591961226, "phrase": "wavelet_coefficients"}, {"score": 0.00481495049065317, "phrase": "wavelet_decomposition"}, {"score": 0.004740009255053372, "phrase": "proven_tool"}, {"score": 0.004666228956744244, "phrase": "concise_synopses"}, {"score": 0.0046176782475198085, "phrase": "large_data_sets"}, {"score": 0.004451676867747938, "phrase": "fast_approximate_answers"}, {"score": 0.004405348628112645, "phrase": "existing_research_studies"}, {"score": 0.004291617358806677, "phrase": "optimal_set"}, {"score": 0.0037261429556468217, "phrase": "real_data"}, {"score": 0.003629882559085245, "phrase": "large_spikes"}, {"score": 0.0035733198242955634, "phrase": "data_values_results"}, {"score": 0.0034267429854665035, "phrase": "conceptual_tree_structure"}, {"score": 0.003355717283753749, "phrase": "error_tree"}, {"score": 0.0031348622158167195, "phrase": "novel_compression_scheme"}, {"score": 0.003102195256794215, "phrase": "wavelet_synopses"}, {"score": 0.0029284999172756103, "phrase": "hierarchical_relationships"}, {"score": 0.0027356847952125433, "phrase": "larger_number"}, {"score": 0.00256895975568914, "phrase": "increased_accuracy"}, {"score": 0.0025288869172313674, "phrase": "produced_synopsis"}, {"score": 0.0024377918036784336, "phrase": "hierarchically_compressed_wavelet_synopses"}, {"score": 0.0022772115643656153, "phrase": "extensive_experimental_results"}, {"score": 0.0021049977753042253, "phrase": "existing_synopsis_construction_algorithms"}], "paper_keywords": ["Wavelet synopsis", " Data streams", " Compression"], "paper_abstract": "The wavelet decomposition is a proven tool for constructing concise synopses of large data sets that can be used to obtain fast approximate answers. Existing research studies focus on selecting an optimal set of wavelet coefficients to store so as to minimize some error metric, without however seeking to reduce the size of the wavelet coefficients themselves. In many real data sets the existence of large spikes in the data values results in many large coefficient values lying on paths of a conceptual tree structure known as the error tree. To exploit this fact, we introduce in this paper a novel compression scheme for wavelet synopses, termed hierarchically compressed wavelet synopses, that fully exploits hierarchical relationships among coefficients in order to reduce their storage. Our proposed compression scheme allows for a larger number of coefficients to be stored for a given space constraint thus resulting in increased accuracy of the produced synopsis. We propose optimal, approximate and greedy algorithms for constructing hierarchically compressed wavelet synopses that minimize the sum squared error while not exceeding a given space budget. Extensive experimental results on both synthetic and real-world data sets validate our novel compression scheme and demonstrate the effectiveness of our algorithms against existing synopsis construction algorithms.", "paper_title": "Hierarchically compressed wavelet synopses", "paper_id": "WOS:000262317000009"}