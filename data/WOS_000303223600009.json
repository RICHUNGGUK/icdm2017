{"auto_keywords": [{"score": 0.04180180938967789, "phrase": "logical_inference"}, {"score": 0.00481495049065317, "phrase": "coupled_temporal_and_perceptual_visual_structures"}, {"score": 0.003949377440799037, "phrase": "index_and_query_documents"}, {"score": 0.0037267132967205136, "phrase": "low-level_visual_features"}, {"score": 0.0036908381347418805, "phrase": "high-dimensional_spaces"}, {"score": 0.0034491650585057754, "phrase": "perceptual_symbolic_representation"}, {"score": 0.003399466007862412, "phrase": "color_and_texture_concepts"}, {"score": 0.0032389001343643064, "phrase": "retrieval_model"}, {"score": 0.0030709962527878656, "phrase": "window_process"}, {"score": 0.002801166393333128, "phrase": "general_video_editing"}, {"score": 0.00269475174341129, "phrase": "re-broadcasted_video_search"}, {"score": 0.0026049517737353365, "phrase": "large_quantities"}, {"score": 0.002579847272930948, "phrase": "video_data"}, {"score": 0.002319127685733821, "phrase": "empirical_comparison"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Near-duplicate video detection", " Perceptual visual indexing", " Logical inference", " Lattice-based processing", " Empirical evaluation"], "paper_abstract": "We propose in this paper an architecture for near-duplicate video detection based on: (i) index and query signature based structures integrating temporal and perceptual visual features and (ii) a matching framework computing the logical inference between index and query documents. As far as indexing is concerned, instead of concatenating low-level visual features in high-dimensional spaces which results in curse of dimensionality and redundancy issues, we adopt a perceptual symbolic representation based on color and texture concepts. For matching, we propose to instantiate a retrieval model based on logical inference through the coupling of an N-gram sliding window process and theoretically-sound lattice-based structures. The techniques we cover are robust and insensitive to general video editing and/or degradation, making it ideal for re-broadcasted video search. Experiments are carried out on large quantities of video data collected from the TRECVID 02, 03 and 04 collections and real-world video broadcasts recorded from two German TV stations. An empirical comparison over two state-of-the-art dynamic programming techniques is encouraging and demonstrates the advantage and feasibility of our method. (C) 2011 Published by Elsevier Ltd.", "paper_title": "Near-duplicate video detection featuring coupled temporal and perceptual visual structures and logical inference based matching", "paper_id": "WOS:000303223600009"}