{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "simplex_search"}, {"score": 0.00476697427418509, "phrase": "unconstrained_optimization"}, {"score": 0.004579780586951551, "phrase": "simple_but_efficient_modification"}, {"score": 0.004511485198940203, "phrase": "well-known_nelder-mead"}, {"score": 0.004291073117901643, "phrase": "n_simplex_vertices"}, {"score": 0.004122490120202936, "phrase": "best_vertex"}, {"score": 0.004020492138367616, "phrase": "\"_step"}, {"score": 0.0036188435232325337, "phrase": "non-convex_problems"}, {"score": 0.003306559295382181, "phrase": "previous_phase"}, {"score": 0.003113441660343867, "phrase": "objective_function_value"}, {"score": 0.003021141590548526, "phrase": "rmnm"}, {"score": 0.002931569771634119, "phrase": "deterministic_method"}, {"score": 0.002830410693265704, "phrase": "extended_local_search"}, {"score": 0.0028021527740710508, "phrase": "continuous_optimization"}, {"score": 0.002719055901632759, "phrase": "computational_complexity"}, {"score": 0.0026252106881752067, "phrase": "heap_data_structure"}, {"score": 0.002560162916190598, "phrase": "simplex_vertices"}, {"score": 0.002534596206835737, "phrase": "extensive_empirical_analysis"}, {"score": 0.0023507916951658455, "phrase": "global_optimization_problems"}, {"score": 0.0021802872319258977, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Unconstrained optimization", " Global optimization", " Direct search methods", " Nelder-Mead method", " Restarted modified simplex search", " Metaheuristics"], "paper_abstract": "In this paper we propose a simple but efficient modification of the well-known Nelder-Mead (NM) simplex search method for unconstrained optimization. Instead of moving all n simplex vertices at once in the direction of the best vertex, our \"shrink\" step moves them in the same direction but one by one until an improvement is obtained. In addition, for solving non-convex problems, we simply restart the so-modified NM (MNM) method by constructing an initial simplex around the solution obtained in the previous phase. We repeat restarts until there is no improvement in the objective function value. Thus. our restarted modified NM (RMNM) is a descent and deterministic method and may be seen as an extended local search for continuous optimization. In order to improve computational complexity and efficiency, we use the heap data structure for storing and updating simplex vertices. Extensive empirical analysis shows that: our modified method outperforms in average the original version as well as some other recent successful modifications: in solving global optimization problems, it is comparable with the state-of-the-art heuristics. Crown Copyright (C) 2009 Published by Elsevier Ltd. All rights reserved.", "paper_title": "A restarted and modified simplex search for unconstrained optimization", "paper_id": "WOS:000267320700019"}