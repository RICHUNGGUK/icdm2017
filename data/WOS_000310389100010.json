{"auto_keywords": [{"score": 0.04963419481547922, "phrase": "video_sequences"}, {"score": 0.048756712287817146, "phrase": "facial_expressions"}, {"score": 0.02875806215342705, "phrase": "au_intensity_estimation"}, {"score": 0.004725886853744007, "phrase": "high_precision_evaluation"}, {"score": 0.004552648949390462, "phrase": "invariant_estimations"}, {"score": 0.004468415400599571, "phrase": "action_unit"}, {"score": 0.004385733482617193, "phrase": "intensity_estimation"}, {"score": 0.004304574865291508, "phrase": "situation_analysis"}, {"score": 0.0042446888127531945, "phrase": "automated_video_annotation"}, {"score": 0.004050996777117918, "phrase": "procrustes_transformation"}, {"score": 0.003994624397219346, "phrase": "multi-class_svm_leave-one-out_method"}, {"score": 0.0035542408902458677, "phrase": "constrained_local_models"}, {"score": 0.0032219438233946312, "phrase": "estimated_clm_shapes"}, {"score": 0.0030604342671868836, "phrase": "independent_emotion_estimation"}, {"score": 0.00297576670831646, "phrase": "significant_improvements"}, {"score": 0.0027483472371835865, "phrase": "emotion_classification"}, {"score": 0.002622755848331379, "phrase": "invariant_emotion_estimation"}, {"score": 0.002514625755809045, "phrase": "different_poses"}, {"score": 0.0024912073108138613, "phrase": "different_subjects"}, {"score": 0.0024336086025284836, "phrase": "frontal_shapes"}, {"score": 0.0023996890513009743, "phrase": "clm_fits"}, {"score": 0.002289993730291136, "phrase": "shape_estimation"}, {"score": 0.0022058510091498666, "phrase": "high_quality"}, {"score": 0.002185301851004467, "phrase": "invariant_emotion_classification"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Constrained Local Model", " Shape information", " Action unit recognition", " Emotion classification", " CK", " BU-4DFE"], "paper_abstract": "Person independent and pose invariant estimations of facial expressions and action unit (AU) intensity estimation are important for situation analysis and for automated video annotation. We evaluated raw 2D shape data of the CK+ database, used Procrustes transformation and the multi-class SVM leave-one-out method for classification. We found close to 100% performance demonstrating the relevance and the strength of details of the shape. Precise 3D shape information was computed by means of constrained local models (CLM) on video sequences. Such sequences offer the opportunity to compute a time-averaged '3D personal mean shape' (PMS) from the estimated CLM shapes, which - upon subtraction - gives rise to person independent emotion estimation. On CK+ data PMS showed significant improvements over AU0 normalization: performance reached and sometimes surpassed state-of-the-art results on emotion classification and on AU intensity estimation. 3D PMS from 3D CLM offers pose invariant emotion estimation that we studied by rendering a 3D emotional database for different poses and different subjects from the BU 4DFE database. Frontal shapes derived from CLM fits of the 3D shape were evaluated. Results demonstrate that shape estimation alone can be used for robust, high quality pose invariant emotion classification and AU intensity estimation. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "3D shape estimation in video sequences provides high precision evaluation of facial expressions", "paper_id": "WOS:000310389100010"}