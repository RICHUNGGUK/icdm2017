{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "symmetrical_restricted_states"}, {"score": 0.004664352260912174, "phrase": "reinforcement_learning_method"}, {"score": 0.003773449694108617, "phrase": "action_selection"}, {"score": 0.0032184697893776052, "phrase": "restricted_state"}, {"score": 0.003150900886669123, "phrase": "corresponding_action"}, {"score": 0.0030199761431186434, "phrase": "restricted_states"}, {"score": 0.0029565620771207003, "phrase": "different_actions"}, {"score": 0.002468450551616404, "phrase": "reinforcement_learning_problem_size"}, {"score": 0.002219790619936024, "phrase": "simulation_results"}], "paper_keywords": ["reinforcement learning", " high dimensionality", " symmetry", " elevator group control system"], "paper_abstract": "A reinforcement learning method is proposed that can utilize parts of states and their partial symmetries to solve a problem efficiently. In most cases the action selection does not need considering all the states but only needs looking at parts of states or restricted state of corresponding action. Moreover, restricted states of different actions arc symmetrical, and thus the action value function based on restricted states can be shared which further reduces the reinforcement learning problem size. The method is compared, in terms Of simulation results and other aspects, with other standard reinforcement learning methods. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Reinforcement learning for problems with symmetrical restricted states", "paper_id": "WOS:000259686500001"}