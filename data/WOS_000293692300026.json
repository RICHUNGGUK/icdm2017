{"auto_keywords": [{"score": 0.05007641415946019, "phrase": "image_quality_assessment"}, {"score": 0.04671946646341984, "phrase": "image_quality"}, {"score": 0.04597573781687575, "phrase": "subjective_evaluations"}, {"score": 0.04476131591157873, "phrase": "iqa"}, {"score": 0.029366992796809717, "phrase": "gm"}, {"score": 0.004579005794486596, "phrase": "computational_models"}, {"score": 0.004330321475256457, "phrase": "well-known_structural_similarity_index"}, {"score": 0.004187614134377688, "phrase": "structure-based_stage"}, {"score": 0.0037658881407605445, "phrase": "human_visual_system"}, {"score": 0.003724054369644711, "phrase": "hvs"}, {"score": 0.0034630606658026595, "phrase": "phase_congruency"}, {"score": 0.003311604528903634, "phrase": "dimensionless_measure"}, {"score": 0.003202361402737197, "phrase": "local_structure"}, {"score": 0.0030967107893195246, "phrase": "primary_feature"}, {"score": 0.002977835845437357, "phrase": "contrast_invariant"}, {"score": 0.0029282926103224717, "phrase": "contrast_information"}, {"score": 0.0028795712616923462, "phrase": "hvs'_perception"}, {"score": 0.002800158709933889, "phrase": "image_gradient_magnitude"}, {"score": 0.002677616534005393, "phrase": "secondary_feature"}, {"score": 0.0026478260192958924, "phrase": "fsim._pc"}, {"score": 0.0025892330566358503, "phrase": "complementary_roles"}, {"score": 0.002531933388815139, "phrase": "image_local_quality"}, {"score": 0.0024620842899061614, "phrase": "local_quality_map"}, {"score": 0.002354302193867031, "phrase": "weighting_function"}, {"score": 0.0023021895404322767, "phrase": "single_quality_score"}, {"score": 0.002276566401216226, "phrase": "extensive_experiments"}, {"score": 0.0022386642196006567, "phrase": "six_benchmark_iqa_databases"}, {"score": 0.0022013920007122032, "phrase": "fsim"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_iqa_metrics"}], "paper_keywords": ["Gradient", " image quality assessment (IQA)", " low-level feature", " phase congruency (PC)"], "paper_abstract": "Image quality assessment (IQA) aims to use computational models to measure the image quality consistently with subjective evaluations. The well-known structural similarity index brings IQA from pixel- to structure-based stage. In this paper, a novel feature similarity (FSIM) index for full reference IQA is proposed based on the fact that human visual system (HVS) understands an image mainly according to its low-level features. Specifically, the phase congruency (PC), which is a dimensionless measure of the significance of a local structure, is used as the primary feature in FSIM. Considering that PC is contrast invariant while the contrast information does affect HVS' perception of image quality, the image gradient magnitude (GM) is employed as the secondary feature in FSIM. PC and GM play complementary roles in characterizing the image local quality. After obtaining the local quality map, we use PC again as a weighting function to derive a single quality score. Extensive experiments performed on six benchmark IQA databases demonstrate that FSIM can achieve much higher consistency with the subjective evaluations than state-of-the-art IQA metrics.", "paper_title": "FSIM: A Feature Similarity Index for Image Quality Assessment", "paper_id": "WOS:000293692300026"}