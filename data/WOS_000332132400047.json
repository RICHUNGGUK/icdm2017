{"auto_keywords": [{"score": 0.045184180069738004, "phrase": "slfn"}, {"score": 0.03769716586279513, "phrase": "optimization_method"}, {"score": 0.00481495049065317, "phrase": "single-hidden_layer_feedforward_neural_network"}, {"score": 0.004442032546224076, "phrase": "learning_framework"}, {"score": 0.004382737590042589, "phrase": "single-hidden_layer_feedforward_neural_networks"}, {"score": 0.003510754567808717, "phrase": "output_weights"}, {"score": 0.0033946556965877873, "phrase": "batch_elm"}, {"score": 0.003260377175139591, "phrase": "least_squares_algorithm"}, {"score": 0.0031738126998349775, "phrase": "tikhonov's_regularization"}, {"score": 0.0030482430937467013, "phrase": "slfn_performance"}, {"score": 0.0029473940028924748, "phrase": "noisy_data"}, {"score": 0.002755567647101251, "phrase": "input_variables"}, {"score": 0.002700485592691974, "phrase": "hidden-layer_configuration"}, {"score": 0.0026111116934081284, "phrase": "input_weights"}, {"score": 0.0025761937402886954, "phrase": "tikhonov's_regularization_factor"}, {"score": 0.002524688179363081, "phrase": "proposed_framework"}, {"score": 0.0021917966722180132, "phrase": "public_repositories"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Optimized extreme learning machine", " Single-hidden layer feedforward neural networks", " Genetic algorithms", " Simulated annealing", " Differential evolution"], "paper_abstract": "This paper proposes a learning framework for single-hidden layer feedforward neural networks (SLFN) called optimized extreme learning machine (O-ELM). In O-ELM, the structure and the parameters of the SLFN are determined using an optimization method. The output weights, like in the batch ELM, are obtained by a least squares algorithm, but using Tikhonov's regularization in order to improve the SLFN performance in the presence of noisy data. The optimization method is used to the set of input variables, the hidden-layer configuration and bias, the input weights and Tikhonov's regularization factor. The proposed framework has been tested with three optimization methods (genetic algorithms, simulated annealing, and differential evolution) over 16 benchmark problems available in public repositories. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Learning of a single-hidden layer feedforward neural network using an optimized extreme learning machine", "paper_id": "WOS:000332132400047"}