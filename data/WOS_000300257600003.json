{"auto_keywords": [{"score": 0.045462223221237344, "phrase": "wfst"}, {"score": 0.03278828442720067, "phrase": "active_working_set"}, {"score": 0.029210907807976808, "phrase": "dram-oriented_system"}, {"score": 0.00481495049065317, "phrase": "weighted_finite_state_transducers"}, {"score": 0.004710306419574744, "phrase": "speech_recognition"}, {"score": 0.0046079260641779755, "phrase": "decoding_speed"}, {"score": 0.004567596860086148, "phrase": "real-time_processing"}, {"score": 0.004468304427278713, "phrase": "power_consumption"}, {"score": 0.00439041997682389, "phrase": "weighted_finite_state_transducer"}, {"score": 0.004238682850598745, "phrase": "major_recognition_network_representation"}, {"score": 0.004146510711518748, "phrase": "algorithmic_complexity"}, {"score": 0.0041102032028337366, "phrase": "decoding_procedures"}, {"score": 0.0038989120088094185, "phrase": "hardware_implementation"}, {"score": 0.0038647641000798135, "phrase": "continuous_speech_recognition"}, {"score": 0.0038309648074240994, "phrase": "csr"}, {"score": 0.00376409764683147, "phrase": "wfst_network"}, {"score": 0.0036660436272785476, "phrase": "viterbi_search"}, {"score": 0.0036020923276404403, "phrase": "large_sized_network"}, {"score": 0.0035705347414368726, "phrase": "limited_hardware_resources"}, {"score": 0.0033868916699805224, "phrase": "first_one"}, {"score": 0.003198554193075258, "phrase": "internal_sram"}, {"score": 0.0031565959573536194, "phrase": "hash_table"}, {"score": 0.0029548937818509656, "phrase": "different_speech_recognition_tasks"}, {"score": 0.002890557197908352, "phrase": "sram_space"}, {"score": 0.0028276174348291923, "phrase": "easy_expansion"}, {"score": 0.0026585629592360085, "phrase": "external_dram."}, {"score": 0.002623669616798891, "phrase": "long_latency"}, {"score": 0.002600661525224505, "phrase": "dram_access"}, {"score": 0.0025665261770229757, "phrase": "split_dram_hash_table"}, {"score": 0.0024451427672857458, "phrase": "opened_rows"}, {"score": 0.0023604768913655463, "phrase": "row_misses"}, {"score": 0.002339771435910601, "phrase": "experimental_results"}, {"score": 0.002298902547676131, "phrase": "sram-oriented_system"}], "paper_keywords": ["Continuous speech recognition (CSR)", " Weighted finite states transducer (WFST)", " FPGA implementation of speech recognition"], "paper_abstract": "Hardware implementation of speech recognition can not only accelerate decoding speed for real-time processing but also reduce the power consumption. Recently the weighted finite state transducer (WFST) has emerged as a major recognition network representation because it reduces the algorithmic complexity of decoding procedures by applying many optimizations on the network in offline. However, hardware implementation of continuous speech recognition (CSR) with the WFST network is challenging, mainly because Viterbi search should traverse a large sized network with limited hardware resources. This paper presents two hardware speech recognition systems with the WFST network. The first one, which is called the SRAM-oriented system, utilizes the internal SRAM as a hash table to efficiently manage active working set. This system is flexible because it can easily accommodate different speech recognition tasks as long as the SRAM space is allowed. For easy expansion, we also propose the DRAM-oriented system where the active working set is stored in the external DRAM. To hide long latency of DRAM access, a split DRAM hash table is employed, which stores active working set in the opened rows of DRAM to reduce the number of row misses. Experimental results show that the SRAM-oriented system decodes the 5k-word CSR task 4.93 times faster than real-time, while the DRAM-oriented system runs 4.48 times faster than real-time with only about a half SRAM capacity.", "paper_title": "Flexible and Expandable Speech Recognition Hardware with Weighted Finite State Transducers", "paper_id": "WOS:000300257600003"}