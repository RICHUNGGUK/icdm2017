{"auto_keywords": [{"score": 0.049378038061471535, "phrase": "software_testing"}, {"score": 0.023026363439868983, "phrase": "random_testing"}, {"score": 0.017885461426085096, "phrase": "rt"}, {"score": 0.015234893283683054, "phrase": "failure-causing_inputs"}, {"score": 0.00887225727137967, "phrase": "test_cases"}, {"score": 0.004368142221528535, "phrase": "case_selection"}, {"score": 0.004329630571352367, "phrase": "fundamental_issue"}, {"score": 0.004228577663320847, "phrase": "large_body"}, {"score": 0.0039509464162209565, "phrase": "software's_input_domain"}, {"score": 0.003802135020791801, "phrase": "first_study"}, {"score": 0.003768594674768144, "phrase": "sufficient_condition"}, {"score": 0.0037463983616303786, "phrase": "partition_testing"}, {"score": 0.0035842759004298657, "phrase": "pt"}, {"score": 0.003459191419478298, "phrase": "second_study"}, {"score": 0.003270340336894077, "phrase": "fundamental_and_popular_testing_technique"}, {"score": 0.0032128654564385494, "phrase": "rt_fault_detection_effectiveness"}, {"score": 0.0031563974745349235, "phrase": "common_observation"}, {"score": 0.0030464123943266673, "phrase": "new_family"}, {"score": 0.0030284566685355456, "phrase": "rt_techniques"}, {"score": 0.002905686674076947, "phrase": "even_spread"}, {"score": 0.0028630535573013686, "phrase": "input_domain"}, {"score": 0.0028293966058473476, "phrase": "successful_use"}, {"score": 0.0027878797103973313, "phrase": "region_contiguity_insights"}, {"score": 0.002722712628307598, "phrase": "third_study"}, {"score": 0.002551231163230566, "phrase": "testing_strategies"}, {"score": 0.0024622810950164415, "phrase": "interesting_and_important_results"}, {"score": 0.002348475124046182, "phrase": "key_concept"}], "paper_keywords": ["adaptive random testing", " diversity", " metamorphic testing", " proportional sampling strategy", " random testing", " software testing"], "paper_abstract": "Software testing is an approach that ensures the quality of software through execution, with a goal being to reveal failures and other problems as quickly as possible. Test case selection is a fundamental issue in software testing, and has generated a large body of research, especially with regards to the effectiveness of random testing (RT), where test cases are randomly selected from the software's input domain. In this paper, we revisit three of our previous studies. The first study investigated a sufficient condition for partition testing (PT) to outperform RT, and was motivated by various controversial and conflicting results suggesting that sometimes PT performed better than RT, and sometimes the opposite. The second study aimed at enhancing RT itself, and was motivated by the fact that RT continues to be a fundamental and popular testing technique. This second study enhanced RT fault detection effectiveness by making use of the common observation that failure-causing inputs tend to cluster together, and resulted in a new family of RT techniques: adaptive random testing (ART), which is random testing with an even spread of test cases across the input domain. Following the successful use of failure-causing region contiguity insights to develop ART, we conducted a third study on how to make use of other characteristics of failure-causing inputs to develop more effective test case selection strategies. This third study revealed how best to approach testing strategies when certain characteristics of the failure-causing inputs are known, and produced some interesting and important results. In revisiting these three previous studies, we explore their unexpected commonalities, and identify diversity as a key concept underlying their effectiveness. This observation further prompted us to examine whether or not such a concept plays a role in other areas of software testing, and our conclusion is that, yes, diversity appears to be one of the most important concepts in the field of software testing.", "paper_title": "A revisit of three studies related to random testing", "paper_id": "WOS:000353818200013"}