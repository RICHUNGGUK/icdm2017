{"auto_keywords": [{"score": 0.0444227308407221, "phrase": "dialogue_system"}, {"score": 0.00481495049065317, "phrase": "grounded_objects"}, {"score": 0.004774937143916685, "phrase": "home_environments"}, {"score": 0.004676345706416371, "phrase": "spoken_interaction"}, {"score": 0.004598933498016774, "phrase": "human_users"}, {"score": 0.004447915226010682, "phrase": "sensory_information"}, {"score": 0.004337900700685262, "phrase": "semantic_level"}, {"score": 0.004108742905942481, "phrase": "human-like_and_intuitive_manner"}, {"score": 0.003924284136338428, "phrase": "perceptual_anchoring"}, {"score": 0.0038112201846057445, "phrase": "symbol-percept_correspondence"}, {"score": 0.003701401653850141, "phrase": "multimodal_dialogues"}, {"score": 0.0036097844103129043, "phrase": "fluent_interaction"}, {"score": 0.0034476484413811987, "phrase": "everyday_objects"}, {"score": 0.003376369479008885, "phrase": "so-called_symbiotic_system"}, {"score": 0.0031845067058084583, "phrase": "home_environment"}, {"score": 0.0030797912111959137, "phrase": "iristk_dialogue_platform"}, {"score": 0.0030160945545795468, "phrase": "iristk_system"}, {"score": 0.0028805474861014722, "phrase": "different_modules"}, {"score": 0.002682917193736698, "phrase": "mobile_robot_device"}, {"score": 0.0026055251533586804, "phrase": "distributed_sensor_network"}, {"score": 0.0025730425700096365, "phrase": "perceptual_anchoring_framework"}, {"score": 0.0024573577356299765, "phrase": "consistent_identity"}, {"score": 0.00231759652007697, "phrase": "flexible_dialogues"}, {"score": 0.0021857667493036786, "phrase": "experimental_validation"}, {"score": 0.0021049977753042253, "phrase": "possible_candidates"}], "paper_keywords": ["Human-robot interaction", " Perceptual anchoring", " Symbol grounding", " Spoken dialogue systems", " Social robotics"], "paper_abstract": "To provide a spoken interaction between robots and human users, an internal representation of the robots sensory information must be available at a semantic level and accessible to a dialogue system in order to be used in a human-like and intuitive manner. In this paper, we integrate the fields of perceptual anchoring (which creates and maintains the symbol-percept correspondence of objects) in robotics with multimodal dialogues in order to achieve a fluent interaction between humans and robots when talking about objects. These everyday objects are located in a so-called symbiotic system where humans, robots, and sensors are co-operating in a home environment. To orchestrate the dialogue system, the IrisTK dialogue platform is used. The IrisTK system is based on modelling the interaction of events, between different modules, e.g. speech recognizer, face tracker, etc. This system is running on a mobile robot device, which is part of a distributed sensor network. A perceptual anchoring framework, recognizes objects placed in the home and maintains a consistent identity of the objects consisting of their symbolic and perceptual data. Particular effort is placed on creating flexible dialogues where requests to objects can be made in a variety of ways. Experimental validation consists of evaluating the system when many objects are possible candidates for satisfying these requests.", "paper_title": "Fluent Human-Robot Dialogues About Grounded Objects in Home Environments", "paper_id": "WOS:000345994900022"}