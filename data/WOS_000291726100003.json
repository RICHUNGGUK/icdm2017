{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "on-the-fly_detection"}, {"score": 0.00471003041684707, "phrase": "multicore_processors"}, {"score": 0.004675565200598801, "phrase": "large_performance_benefits"}, {"score": 0.004641351004344458, "phrase": "parallel_applications"}, {"score": 0.004457579615095599, "phrase": "parallel_application"}, {"score": 0.004408729661992651, "phrase": "good_performance"}, {"score": 0.004328494656899359, "phrase": "performance_debugging"}, {"score": 0.004126623209579942, "phrase": "parallel_programs"}, {"score": 0.004007083686875716, "phrase": "sequential_programs"}, {"score": 0.0038483286199081, "phrase": "biggest_challenges"}, {"score": 0.0035887342563437935, "phrase": "extra_misses"}, {"score": 0.003510439768484619, "phrase": "tricky_task"}, {"score": 0.0033961782274326948, "phrase": "interthread_communication"}, {"score": 0.0032021226849872054, "phrase": "true_or_false_sharing"}, {"score": 0.002975024676463106, "phrase": "new_programmer-centric_definition"}, {"score": 0.0027844017803674444, "phrase": "existing_data-centric_definitions"}, {"score": 0.002723607240517261, "phrase": "straightforward_implementation"}, {"score": 0.0026252106881752067, "phrase": "real_hardware"}, {"score": 0.002558450494671067, "phrase": "design_space"}, {"score": 0.002539689093411356, "phrase": "low-cost_hardware_support"}, {"score": 0.0024389277933858054, "phrase": "true_and_false_sharing_misses"}, {"score": 0.00241214634516517, "phrase": "existing_performance_counters"}, {"score": 0.0023944552329463035, "phrase": "profiling_tools"}, {"score": 0.0022909940601580675, "phrase": "good_accuracy"}, {"score": 0.002224510044064184, "phrase": "ideal_scheme"}, {"score": 0.002128376306688074, "phrase": "case_study"}, {"score": 0.0021049977753042253, "phrase": "real_application"}], "paper_keywords": ["Algorithms", " Design", " Performance", " Performance debugging", " false sharing", " multicore processors", " coherence misses"], "paper_abstract": "While multicore processors promise large performance benefits for parallel applications, writing these applications is notoriously difficult. Tuning a parallel application to achieve good performance, also known as performance debugging, is often more challenging than debugging the application for correctness. Parallel programs have many performance-related issues that are not seen in sequential programs. An increase in cache misses is one of the biggest challenges that programmers face. To minimize these misses, programmers must not only identify the source of the extra misses, but also perform the tricky task of determining if the misses are caused by interthread communication (i.e., coherence misses) and if so, whether they are caused by true or false sharing (since the solutions for these two are quite different). In this article, we propose a new programmer-centric definition of false sharing misses and describe our novel algorithm to perform coherence miss classification. We contrast our approach with existing data-centric definitions of false sharing. A straightforward implementation of our algorithm is too expensive to be incorporated in real hardware. Therefore, we explore the design space for low-cost hardware support that can classify coherence misses on-the-fly into true and false sharing misses, allowing existing performance counters and profiling tools to expose and attribute them. We find that our approximate schemes achieve good accuracy at only a fraction of the cost of the ideal scheme. Additionally, we demonstrate the usefulness of our work in a case study involving a real application.", "paper_title": "DeFT: Design Space Exploration for On-the-Fly Detection of Coherence Misses", "paper_id": "WOS:000291726100003"}