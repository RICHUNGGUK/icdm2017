{"auto_keywords": [{"score": 0.0490692031182167, "phrase": "mutuality_strategies"}, {"score": 0.00481495049065317, "phrase": "lazy_multi-label"}, {"score": 0.0047893552527040195, "phrase": "learning_algorithms"}, {"score": 0.004663396040465122, "phrase": "lazy_multi-label_learning_algorithms"}, {"score": 0.004565007074039171, "phrase": "important_research_topic"}, {"score": 0.004492573860101133, "phrase": "multi-label_community"}, {"score": 0.0042820680211904235, "phrase": "standard_k-nearest_neighbors"}, {"score": 0.0038283058265876713, "phrase": "voting_criteria"}, {"score": 0.003668333531296882, "phrase": "k-nearest_neighbors"}, {"score": 0.0036100762867678415, "phrase": "new_instance"}, {"score": 0.003108911488613549, "phrase": "lazy_single-learning_algorithms"}, {"score": 0.002900426826591769, "phrase": "lazy_multi-label_algorithm"}, {"score": 0.0027058852678238632, "phrase": "original_brknn_algorithm"}, {"score": 0.002662871928330334, "phrase": "well-known_mlknn_lazy_algorithm"}, {"score": 0.0025243592424524764, "phrase": "best_predictive_performance"}, {"score": 0.0024842242921857705, "phrase": "hamming-loss_evaluation_measure"}, {"score": 0.0023424381236711606, "phrase": "f-measure"}, {"score": 0.0022806798371116698, "phrase": "best_results"}, {"score": 0.0022444104439449737, "phrase": "lazy_algorithms"}], "paper_keywords": ["Machine learning", " Multi-label learning", " Lazy algorithms", " Nearest Neighbors"], "paper_abstract": "Lazy multi-label learning algorithms have become an important research topic within the multi-label community. These algorithms usually consider the set of standard k-Nearest Neighbors of a new instance to predict its labels (multi-label). The prediction is made by following a voting criteria within the multi-labels of the set of k-Nearest Neighbors of the new instance. This work proposes the use of two alternative strategies to identify the set of these examples: the Mutual and Not Mutual Nearest Neighbors rules, which have already been used by lazy single-learning algorithms. In this work, we use these strategies to extend the lazy multi-label algorithm BRkNN. An experimental evaluation carried out to compare both mutuality strategies with the original BRkNN algorithm and the well-known MLkNN lazy algorithm on 15 benchmark datasets showed that MLkNN presented the best predictive performance for the Hamming-Loss evaluation measure, although it was significantly outperformed by the mutuality strategies when F-Measure is considered. The best results of the lazy algorithms were also compared with the results obtained by the Binary Relevance approach using three different base learning algorithms.", "paper_title": "Lazy Multi-label Learning Algorithms Based on Mutuality Strategies", "paper_id": "WOS:000368189000017"}