{"auto_keywords": [{"score": 0.028290720011665136, "phrase": "lr_input"}, {"score": 0.00481495049065317, "phrase": "unified_learning_framework"}, {"score": 0.004762550320451225, "phrase": "single_image_super-resolution"}, {"score": 0.004199247711875386, "phrase": "single_low-resolution"}, {"score": 0.003997343989408636, "phrase": "-based_methods"}, {"score": 0.0038893838564184107, "phrase": "unexpected_details"}, {"score": 0.0038470175104007524, "phrase": "resultant_hr_images"}, {"score": 0.003784328428527216, "phrase": "reconstruction-based_methods"}, {"score": 0.003702323283528696, "phrase": "obvious_artifacts"}, {"score": 0.0035826234811610316, "phrase": "fine_details"}, {"score": 0.003485824905231454, "phrase": "unnatural_results"}, {"score": 0.003318108914777263, "phrase": "new_sr_framework"}, {"score": 0.0031069334778456633, "phrase": "single_image_sr"}, {"score": 0.0030064251340251196, "phrase": "unexpected_artifacts"}, {"score": 0.00294122712771669, "phrase": "-based_sr"}, {"score": 0.0028460640294160383, "phrase": "missing_high-frequency_details"}, {"score": 0.0027996401456881806, "phrase": "reconstruction-based_sr."}, {"score": 0.002709045632654716, "phrase": "single_dictionary"}, {"score": 0.0026070408483940535, "phrase": "external_images"}, {"score": 0.002522662955545598, "phrase": "nonlocal_means"}, {"score": 0.0024679299547216956, "phrase": "reconstruction-based_sr"}, {"score": 0.002273025527678093, "phrase": "desired_high-quality_sr_result"}, {"score": 0.0021516991383785985, "phrase": "proposed_framework"}, {"score": 0.002128220632893247, "phrase": "better_results"}, {"score": 0.0021049977753042253, "phrase": "previous_methods"}], "paper_keywords": ["Example learning-based", " image super-resolution (SR)", " reconstruction-based", " self-similarity"], "paper_abstract": "It has been widely acknowledged that learning- and reconstruction-based super-resolution (SR) methods are effective to generate a high-resolution (HR) image from a single low-resolution (LR) input. However, learning-based methods are prone to introduce unexpected details into resultant HR images. Although reconstruction-based methods do not generate obvious artifacts, they tend to blur fine details and end up with unnatural results. In this paper, we propose a new SR framework that seamlessly integrates learning-and reconstruction-based methods for single image SR to: 1) avoid unexpected artifacts introduced by learning-based SR and 2) restore the missing high-frequency details smoothed by reconstruction-based SR. This integrated framework learns a single dictionary from the LR input instead of from external images to hallucinate details, embeds nonlocal means filter in the reconstruction-based SR to enhance edges and suppress artifacts, and gradually magnifies the LR input to the desired high-quality SR result. We demonstrate both visually and quantitatively that the proposed framework produces better results than previous methods from the literature.", "paper_title": "A Unified Learning Framework for Single Image Super-Resolution", "paper_id": "WOS:000333098700011"}