{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "fast_marching_method"}, {"score": 0.04435870485847808, "phrase": "depth_maps"}, {"score": 0.004762202897268383, "phrase": "range_imaging_sensors"}, {"score": 0.004684178078607861, "phrase": "kinect"}, {"score": 0.0045318666714939905, "phrase": "flight_cameras"}, {"score": 0.004457579615095599, "phrase": "aligned_depth"}, {"score": 0.004408729661992651, "phrase": "color_images"}, {"score": 0.004360412703519539, "phrase": "real_time"}, {"score": 0.004126623209579942, "phrase": "numerous_invalid_regions"}, {"score": 0.0040366412779632085, "phrase": "heavy_noise"}, {"score": 0.00379914165379475, "phrase": "depth_information"}, {"score": 0.003757480190200645, "phrase": "practical_applications"}, {"score": 0.0034975571855450343, "phrase": "new_inpainting_approach"}, {"score": 0.00327356326590461, "phrase": "inpainting_model"}, {"score": 0.0032198357970567595, "phrase": "propagation_strategy"}, {"score": 0.0031845370252545227, "phrase": "fmm"}, {"score": 0.003132236287543072, "phrase": "color_information"}, {"score": 0.003097865379563127, "phrase": "depth_inpainting"}, {"score": 0.0030470127429039497, "phrase": "edge-preserving_guided_filter"}, {"score": 0.0029641011108505785, "phrase": "noise_reduction"}, {"score": 0.002789528662623221, "phrase": "kinect_data"}, {"score": 0.002758907973783665, "phrase": "middlebury_dataset"}, {"score": 0.002669042572650594, "phrase": "qualitative_and_quantitative_results"}, {"score": 0.0025257081555100556, "phrase": "original_fmm"}, {"score": 0.002337848196418384, "phrase": "local_methods"}, {"score": 0.0022741894748181243, "phrase": "visual_and_metric_qualities"}, {"score": 0.0022122603123901114, "phrase": "visually_comparable_results"}, {"score": 0.002175913488493802, "phrase": "time-consuming_global_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Depth enhancement", " Image inpainting", " Fast marching method"], "paper_abstract": "Range imaging sensors such as Kinect and time-of-flight cameras can produce aligned depth and color images in real time. However, the depth maps captured by such sensors contain numerous invalid regions and suffer from heavy noise. These defects more or less influence the use of depth information in practical applications. In order to enhance the depth maps, this paper proposes a new inpainting approach based on the fast marching method (FMM). We extend the inpainting model and the propagation strategy of FMM to incorporate color information for depth inpainting. An edge-preserving guided filter is further applied for noise reduction. To validate our algorithm, we perform experiments on both Kinect data and Middlebury dataset which, respectively, provide qualitative and quantitative results. Meanwhile, we also compare it to the original FMM and other two state-of-the-art depth enhancement methods. Experimental results show that our method performs better than the local methods in terms of both visual and metric qualities, and it achieves visually comparable results to the time-consuming global method. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Guided depth enhancement via a fast marching method", "paper_id": "WOS:000326211900001"}