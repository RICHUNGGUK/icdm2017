{"auto_keywords": [{"score": 0.04174998765555268, "phrase": "sso"}, {"score": 0.00481495049065317, "phrase": "artificial_neural_network_training"}, {"score": 0.00458488025289647, "phrase": "time_series"}, {"score": 0.004501453956464956, "phrase": "new_soft_computing_method"}, {"score": 0.004106701730413583, "phrase": "ann"}, {"score": 0.003293688299319582, "phrase": "sso."}, {"score": 0.003097865379563127, "phrase": "five_other_famous_soft_computing_methods"}, {"score": 0.002949598537993663, "phrase": "genetic_algorithm"}, {"score": 0.002706979614143284, "phrase": "pso"}, {"score": 0.0025148871904409095, "phrase": "five_famous_time-series_benchmark_data"}, {"score": 0.0022519745140925475, "phrase": "experimental_results"}], "paper_keywords": ["Artificial intelligence", " evolutionary computation", " machine learning", " neural network"], "paper_abstract": "A new soft computing method called the parameter-free simplified swarm optimization (SSO)-based artificial neural network (ANN), or improved SSO for short, is proposed to adjust the weights in ANNs. The method is a modification of the SSO, and seeks to overcome some of the drawbacks of SSO. In the experiments, the iSSO is compared with five other famous soft computing methods, including the backpropagation algorithm, the genetic algorithm, the particle swarm optimization (PSO) algorithm, cooperative random learning PSO, and the SSO, and its performance is tested on five famous time-series benchmark data to adjust the weights of two ANN models (multilayer perceptron and single multiplicative neuron model). The experimental results demonstrate that iSSO is robust and more efficient than the other five algorithms.", "paper_title": "New Parameter-Free Simplified Swarm Optimization for Artificial Neural Network Training and Its Application in the Prediction of Time Series", "paper_id": "WOS:000315517400013"}