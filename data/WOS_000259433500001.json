{"auto_keywords": [{"score": 0.04325684761378906, "phrase": "model_development"}, {"score": 0.004728122501822142, "phrase": "model_formulation"}, {"score": 0.0046938292389998824, "phrase": "model_reduction"}, {"score": 0.004642852977065663, "phrase": "mechanistic_models"}, {"score": 0.00444439983637316, "phrase": "real_systems"}, {"score": 0.004238929161010395, "phrase": "appropriate_level"}, {"score": 0.0034440966820590024, "phrase": "simpler_models"}, {"score": 0.0033942533792009687, "phrase": "model_variables"}, {"score": 0.003308751289007707, "phrase": "variable_replacement"}, {"score": 0.003213660268958121, "phrase": "simpler_model_formulations"}, {"score": 0.0030986183831544487, "phrase": "observed_data"}, {"score": 0.0030426463790590445, "phrase": "bayesian_framework"}, {"score": 0.0029551803384781604, "phrase": "posterior_model_probabilities"}, {"score": 0.00293370839211022, "phrase": "replacement_probabilities"}, {"score": 0.0029123920023263446, "phrase": "individual_variables"}, {"score": 0.0028597742552122305, "phrase": "mechanistic_interpretation"}, {"score": 0.0028183634079717136, "phrase": "powerful_diagnostic_information"}, {"score": 0.002648935542912504, "phrase": "model_results"}, {"score": 0.00250789768689397, "phrase": "reduced_models"}, {"score": 0.002453602802736223, "phrase": "original_full_model"}, {"score": 0.002280948283235427, "phrase": "proposed_approach"}, {"score": 0.0021752783872387173, "phrase": "based_mathematical_models"}, {"score": 0.0021049977753042253, "phrase": "empirically_based_relationships"}], "paper_keywords": ["model reduction", " model complexity", " over-parameterisation", " structural error", " structural uncertainty", " Bayesian evaluation"], "paper_abstract": "While mechanistic models tend to be detailed, they are less detailed than the real systems they seek to describe, so judgements are being made about the appropriate level of detail within the process of model development. These judgements are difficult to test, consequently it is easy for models to become over-parameterised, potentially increasing uncertainty in predictions. The work we describe is a step towards addressing these difficulties. We propose and implement a method which explores a family of simpler models obtained by replacing model variables with constants (model reduction by variable replacement). The procedure iteratively searches the simpler model formulations and compares models in terms of their ability to predict observed data, evaluated within a Bayesian framework. The results can be summarised as posterior model probabilities and replacement probabilities for individual variables which lend themselves to mechanistic interpretation. This provides powerful diagnostic information to support model development, and can identify areas of model over-parameterisation with implications for interpretation of model results. We present the application of the method to 3 example models. In each case reduced models are identified which outperform the original full model in terms of comparisons to observations, suggesting some over-parameterisation has occurred during model development. We argue that the proposed approach is relevant to anyone involved in the development or use of process based mathematical models, especially those where understanding is encoded via empirically based relationships. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "Is my model too complex? Evaluating model formulation using model reduction", "paper_id": "WOS:000259433500001"}