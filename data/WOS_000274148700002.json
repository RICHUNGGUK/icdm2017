{"auto_keywords": [{"score": 0.03543536085562809, "phrase": "behavior_modules"}, {"score": 0.023095500295005674, "phrase": "cooperative_co-evolution"}, {"score": 0.008185183226319307, "phrase": "meme_metaphor"}, {"score": 0.008091138537489873, "phrase": "lifetime_performance"}, {"score": 0.00481495049065317, "phrase": "culture-based_learning"}, {"score": 0.004718230196581402, "phrase": "automatic_behavior-based_system_design"}, {"score": 0.004663832186991562, "phrase": "intelligent_situated_agent"}, {"score": 0.004623443744732925, "phrase": "difficult_task"}, {"score": 0.004491313367627919, "phrase": "agent's_viewpoint"}, {"score": 0.004388321050344759, "phrase": "computation_systems"}, {"score": 0.004275262915031191, "phrase": "bio-inspired_hybridization"}, {"score": 0.004081385289516914, "phrase": "automatic_development"}, {"score": 0.004057774582761155, "phrase": "behavior-based_agents"}, {"score": 0.003964684344001532, "phrase": "individual-level_adaptation"}, {"score": 0.0038962653593060427, "phrase": "population_level"}, {"score": 0.0038624981944755813, "phrase": "basic_decision-making_modules"}, {"score": 0.003829022549422405, "phrase": "reinforcement-learning_procedure"}, {"score": 0.0037958359268041426, "phrase": "culture-based_memetic_algorithm"}, {"score": 0.0037411604449359794, "phrase": "new_computational_interpretation"}, {"score": 0.003613119346373748, "phrase": "learning_experiences"}, {"score": 0.003479331357315815, "phrase": "design_problem"}, {"score": 0.0032830808525570903, "phrase": "agent's_architecture"}, {"score": 0.0029830992938695007, "phrase": "namely_uniform_and_value-based_fitness_sharing_mechanisms"}, {"score": 0.002831158147480665, "phrase": "mathematical_formulation"}, {"score": 0.0027183379628570835, "phrase": "simpler_components"}, {"score": 0.0025723630851105304, "phrase": "agent's_lifetime"}, {"score": 0.002535265741041731, "phrase": "learning_process"}, {"score": 0.0024987020562103448, "phrase": "culture-based_method"}, {"score": 0.0023990982005125763, "phrase": "learned_structures"}, {"score": 0.002283460959126296, "phrase": "real-world_applications"}, {"score": 0.0022439896633013297, "phrase": "memetic_algorithm"}, {"score": 0.002154517283108316, "phrase": "abstract_problem"}, {"score": 0.002135812692862058, "phrase": "decentralized_multirobot_object-lifting_task"}, {"score": 0.0021049977753042253, "phrase": "human-competitive_architecture_designs"}], "paper_keywords": ["Behavior-based system design", " behavior cooperative co-evolution", " cooperative co-evolution", " culture-based method", " memetic algorithm", " reinforcement learning", " structure learning"], "paper_abstract": "Designing an intelligent situated agent is a difficult task because the designer must see the problem from the agent's viewpoint, considering all its sensors, actuators, and computation systems. In this paper, we introduce a bio-inspired hybridization of reinforcement learning, cooperative co-evolution, and a cultural-inspired memetic algorithm for the automatic development of behavior-based agents. Reinforcement learning is responsible for the individual-level adaptation. Cooperative co-evolution performs at the population level and provides basic decision-making modules for the reinforcement-learning procedure. The culture-based memetic algorithm, which is a new computational interpretation of the meme metaphor, increases the lifetime performance of agents by sharing learning experiences between all agents in the society. In this paper, the design problem is decomposed into two different parts: 1) developing a repertoire of behavior modules and 2) organizing them in the agent's architecture. Our proposed cooperative co-evolutionary approach solves the first problem by evolving behavior modules in their separate genetic pools. We address the problem of relating the fitness of the agent to the fitness of behavior modules by proposing two fitness sharing mechanisms, namely uniform and value-based fitness sharing mechanisms. The organization of behavior modules in the architecture is determined by our structure learning method. A mathematical formulation is provided that shows how to decompose the value of the structure into simpler components. These values are estimated during learning and are used to find the organization of behavior modules during the agent's lifetime. To accelerate the learning process, we introduce a culture-based method based on our new interpretation of the meme metaphor. Our proposed memetic algorithm is a mechanism for sharing learned structures among agents in the society. Lifetime performance of the agent, which is quite important for real-world applications, increases considerably when the memetic algorithm is in action. Finally, we apply our methods to two benchmark problems: an abstract problem and a decentralized multirobot object-lifting task, and we achieve human-competitive architecture designs.", "paper_title": "Interaction of Culture-Based Learning and Cooperative Co-evolution and its Application to Automatic Behavior-Based System Design", "paper_id": "WOS:000274148700002"}