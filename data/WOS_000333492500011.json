{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "difficult_classes"}, {"score": 0.004763565662615503, "phrase": "similarity-based_aggregation"}, {"score": 0.00472961267657106, "phrase": "multi-class_classification_problems"}, {"score": 0.004579780586951551, "phrase": "original_multi-class_problem"}, {"score": 0.00441883624011048, "phrase": "independent_base_classifiers"}, {"score": 0.004202931484732134, "phrase": "single_class_label"}, {"score": 0.00406971620207041, "phrase": "baseline_classifiers"}, {"score": 0.0038846843242954935, "phrase": "binary_classifiers"}, {"score": 0.003829455440282146, "phrase": "support_vector_machines"}, {"score": 0.003775008774288817, "phrase": "multi-class_problems"}, {"score": 0.003616252896285766, "phrase": "recognizable_classes"}, {"score": 0.003552084379143929, "phrase": "accuracy_enhancement"}, {"score": 0.0034890505116128606, "phrase": "higher_correct_classification_rates"}, {"score": 0.003378385493203297, "phrase": "significant_improvements"}, {"score": 0.003055977395076106, "phrase": "lower_correct_classification_rate"}, {"score": 0.002764252199256058, "phrase": "novel_similarity-based_aggregation"}, {"score": 0.002695768552609587, "phrase": "well-known_weighted_voting"}, {"score": 0.002619571161767134, "phrase": "new_methodology"}, {"score": 0.0024383449794706477, "phrase": "desirable_behavior"}, {"score": 0.0021975548867457623, "phrase": "proper_statistical_tests"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Multi-class classification", " Pairwise learning", " One-vs-One", " Decomposition strategies", " Tuning", " Difficult classes"], "paper_abstract": "One-vs-One strategy divides the original multi-class problem into as many binary classification problems as pairs of classes. Then, independent base classifiers are learned to face each problem, whose outputs are combined to predict a single class label. This way, the accuracy of the baseline classifiers without decomposition is usually enhanced, aside from enabling the usage of binary classifiers, i.e., Support Vector Machines, to solve multi-class problems. This paper analyzes the fact that existing aggregations favor easily recognizable classes; hence, the accuracy enhancement mainly comes from the higher correct classification rates over these classes. Using other evaluation criteria, the significant improvements of One-vs-One are diminished, showing a weakness due to the presence of difficult classes. Difficult classes can be defined as those obtaining a lower correct classification rate than that obtained by the other classes in the problem. After studying the problem of difficult classes in this framework and aiming to empower these classes, a novel similarity-based aggregation is presented, which generalizes the well-known weighted voting. The experimental analysis shows that the new methodology is able to increase the recognition of difficult classes, obtaining a more balanced performance over all classes, which is a desirable behavior. The methodology is tested within several Machine Learning paradigms and is compared with the state-of-the-art on aggregations for One-vs-One strategy. The results are contrasted by the proper statistical tests, as suggested in the literature. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Empowering difficult classes with a similarity-based aggregation in multi-class classification problems", "paper_id": "WOS:000333492500011"}