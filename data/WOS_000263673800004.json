{"auto_keywords": [{"score": 0.03786990417643338, "phrase": "adaboost"}, {"score": 0.00481495049065317, "phrase": "graph_mining_methods"}, {"score": 0.004689321062844586, "phrase": "subgraph_patterns"}, {"score": 0.004418456827500267, "phrase": "subsequent_classification"}, {"score": 0.00424659225577246, "phrase": "frequent_patterns"}, {"score": 0.003922580121023413, "phrase": "mathematical_programming"}, {"score": 0.0036958398682001015, "phrase": "informative_patterns"}, {"score": 0.003459191419478298, "phrase": "prediction_rule"}, {"score": 0.0033025823350563087, "phrase": "boosting_method"}, {"score": 0.0031739835218110015, "phrase": "branch-and-bound_pattern_search_algorithm"}, {"score": 0.003050376875258722, "phrase": "dfs_code_tree"}, {"score": 0.0029903851294825023, "phrase": "constructed_search_space"}, {"score": 0.002912222095383313, "phrase": "later_iterations"}, {"score": 0.0028360962841331634, "phrase": "computation_time"}, {"score": 0.002671990515821213, "phrase": "simpler_method"}, {"score": 0.0026194209399161184, "phrase": "frequent_substructure_mining"}, {"score": 0.0025509294021449254, "phrase": "output_labels"}, {"score": 0.0024678216843278806, "phrase": "extra_information_source"}, {"score": 0.00240328454980006, "phrase": "search_space"}, {"score": 0.002294369814584028, "phrase": "mathematical_program"}, {"score": 0.0022049428043454966, "phrase": "machine_learning_problems"}, {"score": 0.0021049977753042253, "phrase": "pattern_search_algorithm"}], "paper_keywords": ["Graph mining", " Mathematical programming", " Classification", " Regression", " QSAR"], "paper_abstract": "Graph mining methods enumerate frequently appearing subgraph patterns, which can be used as features for subsequent classification or regression. However, frequent patterns are not necessarily informative for the given learning problem. We propose a mathematical programming boosting method (gBoost) that progressively collects informative patterns. Compared to AdaBoost, gBoost can build the prediction rule with fewer iterations. To apply the boosting method to graph data, a branch-and-bound pattern search algorithm is developed based on the DFS code tree. The constructed search space is reused in later iterations to minimize the computation time. Our method can learn more efficiently than the simpler method based on frequent substructure mining, because the output labels are used as an extra information source for pruning the search space. Furthermore, by engineering the mathematical program, a wide range of machine learning problems can be solved without modifying the pattern search algorithm.", "paper_title": "gBoost: a mathematical programming approach to graph classification and regression", "paper_id": "WOS:000263673800004"}