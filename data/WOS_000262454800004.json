{"auto_keywords": [{"score": 0.040705286218606904, "phrase": "test_cases"}, {"score": 0.03266262632417083, "phrase": "eig"}, {"score": 0.015719709579057044, "phrase": "pilot_study"}, {"score": 0.011379712562907669, "phrase": "previous_work"}, {"score": 0.010435404397591046, "phrase": "eig_model"}, {"score": 0.004688894532233354, "phrase": "automated_testing"}, {"score": 0.004653485665080485, "phrase": "graphical_user_interfaces"}, {"score": 0.004480394224548146, "phrase": "today's_software"}, {"score": 0.004346547997061901, "phrase": "functional_correctness"}, {"score": 0.004297388539539564, "phrase": "understudied_area"}, {"score": 0.004248782702870078, "phrase": "typical_gui"}, {"score": 0.004059772950454586, "phrase": "enormous_input_event_interaction_space"}, {"score": 0.00393844255111604, "phrase": "test_designers"}, {"score": 0.0037918465913284478, "phrase": "user_events"}, {"score": 0.0036093693971289754, "phrase": "fault_detection"}, {"score": 0.0035685175471526823, "phrase": "nontrivial_task"}, {"score": 0.0034226302212225206, "phrase": "informal_gui_code_examination"}, {"score": 0.0033329032920236994, "phrase": "event-interaction_graph"}, {"score": 0.002996840657035727, "phrase": "empirical_derivation_process"}, {"score": 0.002951673109860487, "phrase": "model_evolution"}, {"score": 0.002907184330345933, "phrase": "gui_faults"}, {"score": 0.002841701708055512, "phrase": "pilot_study_show"}, {"score": 0.002788257824525862, "phrase": "complex_ways"}, {"score": 0.0027566738323014, "phrase": "gui's_response"}, {"score": 0.0026338658998573752, "phrase": "preceding_events"}, {"score": 0.002488001663771768, "phrase": "gui_events"}, {"score": 0.0023235629819760018, "phrase": "event_space"}, {"score": 0.002305974875400655, "phrase": "new_test_adequacy_criteria"}, {"score": 0.0022454559805729717, "phrase": "new_algorithms"}], "paper_keywords": ["Verification", " Reliability", " Graphical user interfaces", " model-based testing", " test minimization", " test suite management"], "paper_abstract": "Graphical user interfaces (GUIs) are one of the most commonly used parts of today's software. Despite their ubiquity, testing GUIs for functional correctness remains an understudied area. A typical GUI gives many degrees of freedom to an end-user, leading to an enormous input event interaction space that needs to be tested. GUI test designers generate and execute test cases (modeled as sequences of user events) to traverse its parts; targeting a subspace in order to maximize fault detection is a nontrivial task. In this vein, in previous work, we used informal GUI code examination and personal intuition to develop an event-interaction graph (EIG). In this article we empirically derive the EIG model via a pilot study, and the resulting EIG validates our intuition used in previous work; the empirical derivation process also allows for model evolution as our understanding of GUI faults improves. Results of the pilot study show that events interact in complex ways; a GUI's response to an event may vary depending on the context established by preceding events and their execution order. The EIG model helps testers to understand the nature of interactions between GUI events when executed in test cases and why certain events detect faults, so that they can better traverse the event space. New test adequacy criteria are defined for the EIG; new algorithms use these criteria and EIG to systematically generate test cases that are shown to be effective on four fielded open-source applications.", "paper_title": "Using a Pilot Study to Derive a GUI Model for Automated Testing", "paper_id": "WOS:000262454800004"}