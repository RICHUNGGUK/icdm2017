{"auto_keywords": [{"score": 0.03932122714942605, "phrase": "closed-form_solution"}, {"score": 0.01556384438336407, "phrase": "visual_sensor_networks"}, {"score": 0.011476775992190092, "phrase": "new_target_detection_model"}, {"score": 0.00481495049065317, "phrase": "crowded_targets"}, {"score": 0.004718897469501381, "phrase": "coverage_estimation"}, {"score": 0.004601508848655033, "phrase": "fundamental_problems"}, {"score": 0.004555371402128666, "phrase": "sensor_networks"}, {"score": 0.0040978781692373005, "phrase": "directional_sensing_nature"}, {"score": 0.003955787027818305, "phrase": "visual_occlusion"}, {"score": 0.003916098498242888, "phrase": "crowded_environments"}, {"score": 0.0037993970934472243, "phrase": "first_attempt"}, {"score": 0.0036861605703168397, "phrase": "visual_coverage_estimation_problem"}, {"score": 0.0034003686971964707, "phrase": "certainty-based_target_detection"}, {"score": 0.0032989853590079153, "phrase": "traditional_uncertainty-based_target_detection"}, {"score": 0.0031684791285366315, "phrase": "visual_coverage_problem"}, {"score": 0.002982307044758515, "phrase": "visual_coverage_probability"}, {"score": 0.002878785759716458, "phrase": "visual_occlusions"}, {"score": 0.0027788478707700274, "phrase": "coverage_estimation_model"}, {"score": 0.0026554236621262515, "phrase": "minimum_sensor_density"}, {"score": 0.0025761937402886954, "phrase": "visual_k-coverage"}, {"score": 0.0025374674652885354, "phrase": "crowded_sensing_field"}, {"score": 0.0024493494346360415, "phrase": "extreme_consistency"}, {"score": 0.002400373755068185, "phrase": "theoretical_formulation"}, {"score": 0.0023405257495466352, "phrase": "boundary_effect"}, {"score": 0.0022365262201954643, "phrase": "visual_coverage_estimation"}, {"score": 0.0021697677572213086, "phrase": "real_scenarios"}, {"score": 0.0021263705039915198, "phrase": "efficient_sensor_deployment"}, {"score": 0.0021049977753042253, "phrase": "optimal_sleep_scheduling"}], "paper_keywords": ["Algorithms", " Theory", " Measurement", " Performance", " Directional coverage", " visual occlusions", " visual sensor network", " coverage estimation"], "paper_abstract": "Coverage estimation is one of the fundamental problems in sensor networks. Coverage estimation in visual sensor networks (VSNs) is more challenging than in conventional 1-D (omnidirectional) scalar sensor networks (SSNs) because of the directional sensing nature of cameras and the existence of visual occlusion in crowded environments. This article represents a first attempt toward a closed-form solution for the visual coverage estimation problem in the presence of occlusions. We investigate a new target detection model, referred to as the certainty-based target detection (as compared to the traditional uncertainty-based target detection) to facilitate the formulation of the visual coverage problem. We then derive the closed-form solution for the estimation of the visual coverage probability based on this new target detection model that takes visual occlusions into account, According to the coverage estimation model, we further propose an estimate of the minimum sensor density that suffices to ensure a visual K-coverage in a crowded sensing field. Simulation is conducted which shows extreme consistency with results from theoretical formulation, especially when the boundary effect is considered. Thus, the closed-form solution for visual coverage estimation is effective when applied to real scenarios, such as efficient sensor deployment and optimal sleep scheduling.", "paper_title": "Coverage Estimation for Crowded Targets in Visual Sensor Networks", "paper_id": "WOS:000307607800008"}