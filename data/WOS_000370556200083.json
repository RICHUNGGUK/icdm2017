{"auto_keywords": [{"score": 0.04546953738033993, "phrase": "large_request_fan-outs"}, {"score": 0.00481495049065317, "phrase": "better_batch_scheduling"}, {"score": 0.004754600386388821, "phrase": "reduce_tail_latencies"}, {"score": 0.00469500313566324, "phrase": "cloud_data_stores"}, {"score": 0.0046069985410261746, "phrase": "common_pattern"}, {"score": 0.004463958296056236, "phrase": "modern_interactive_web-services"}, {"score": 0.004271100220705305, "phrase": "even_a_single_end-user_request"}, {"score": 0.00408654006336477, "phrase": "application_server"}, {"score": 0.003984665807155269, "phrase": "data_accesses"}, {"score": 0.0038124354878360032, "phrase": "different_stateful_backend_servers"}, {"score": 0.0037409118365761894, "phrase": "overall_response_time"}, {"score": 0.00355665081072721, "phrase": "completion_time"}, {"score": 0.0034899090274046014, "phrase": "slowest_sub-task"}, {"score": 0.003276321257403678, "phrase": "latency_distribution"}, {"score": 0.0032148229832850215, "phrase": "backend_tier"}, {"score": 0.0031544754107802413, "phrase": "large_number"}, {"score": 0.0031148723927633955, "phrase": "decentralized_application_servers"}, {"score": 0.003075765038696993, "phrase": "skewed_workload_patterns"}, {"score": 0.002815383690003621, "phrase": "better_batch"}, {"score": 0.002626317051411829, "phrase": "decentralized_and_task"}, {"score": 0.0025607529411368632, "phrase": "brb"}, {"score": 0.0025285834281312705, "phrase": "low-latency_distributed_storage_systems"}, {"score": 0.0023144166368024603, "phrase": "production_workloads"}, {"score": 0.0021453112313233554, "phrase": "ideal_system_model"}, {"score": 0.0021049977753042253, "phrase": "latency_improvements"}], "paper_keywords": [""], "paper_abstract": "A common pattern in the architectures of modern interactive web-services is that of large request fan-outs, where even a single end-user request (task) arriving at an application server triggers tens to thousands of data accesses (sub-tasks) to different stateful backend servers. The overall response time of each task is bottlenecked by the completion time of the slowest sub-task, making such workloads highly sensitive to the tail of latency distribution of the backend tier. The large number of decentralized application servers and skewed workload patterns exacerbate the challenge in addressing this problem. We address these challenges through BetteR Batch (BRB). By carefully scheduling requests in a decentralized and task aware manner, BRB enables low-latency distributed storage systems to deliver predictable performance in the presence of large request fan-outs. Our preliminary simulation results based on production workloads show that our proposed design is at the 99th percentile latency within 38% of an ideal system model while offering latency improvements over the state-of-the-art by a factor of 2.", "paper_title": "BRB: BetteR Batch Scheduling to Reduce Tail Latencies in Cloud Data Stores", "paper_id": "WOS:000370556200083"}