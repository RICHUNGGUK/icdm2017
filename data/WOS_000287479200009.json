{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "nested_generalized_exemplar_learning"}, {"score": 0.0047409388179452255, "phrase": "nested_generalized_exemplar_theory"}, {"score": 0.0045726187330434025, "phrase": "euclidean_n-space"}, {"score": 0.004410248125081398, "phrase": "new_data"}, {"score": 0.004231699728933577, "phrase": "nearest_\"generalized_exemplar"}, {"score": 0.004102528738941734, "phrase": "learning_method"}, {"score": 0.0039772848945723435, "phrase": "distance-based_classification"}, {"score": 0.003916098498242888, "phrase": "axis-parallel_rectangle_representation"}, {"score": 0.0037965243835456214, "phrase": "rule-learning_systems"}, {"score": 0.0035866734383189396, "phrase": "evolutionary_algorithms"}, {"score": 0.003459191419478298, "phrase": "accurate_and_simple_models"}, {"score": 0.003201018846103988, "phrase": "hyperrectangle_learning"}, {"score": 0.0031193028729331667, "phrase": "bnge"}, {"score": 0.0030933302376135044, "phrase": "rise"}, {"score": 0.0030554727497206563, "phrase": "inner"}, {"score": 0.003008400471588303, "phrase": "sia"}, {"score": 0.0027982016314450717, "phrase": "classical_rule_induction_algorithms"}, {"score": 0.002726740692380339, "phrase": "ripper."}, {"score": 0.0026297428083782875, "phrase": "non-parametric_statistical_tests"}, {"score": 0.0023958326775913165, "phrase": "lower_number"}, {"score": 0.002286781334850213, "phrase": "simpler_models"}, {"score": 0.00226322835801988, "phrase": "previous_nge_approaches"}, {"score": 0.0022399174232611853, "phrase": "larger_data_sets"}, {"score": 0.0021714122348552747, "phrase": "promising_outcomes"}, {"score": 0.002105007807034302, "phrase": "elsevier"}], "paper_keywords": ["Nested generalized exemplar", " Nearest neighbor", " Hyperrectangles", " Evolutionary algorithms", " Data reduction", " Classification"], "paper_abstract": "The nested generalized exemplar theory accomplishes learning by storing objects in Euclidean n-space, as hyperrectangles. Classification of new data is performed by computing their distance to the nearest \"generalized exemplar\" or hyperrectangle. This learning method allows the combination of the distance-based classification with the axis-parallel rectangle representation employed in most of the rule-learning systems. In this paper, we propose the use of evolutionary algorithms to select the most influential hyperrectangles to obtain accurate and simple models in classification tasks. The proposal has been compared with the most representative models based on hyperrectangle learning; such as the BNGE, RISE, INNER, and SIA genetics based learning approach. Our approach is also very competitive with respect to classical rule induction algorithms such as C4.5Rules and RIPPER. The results have been contrasted through non-parametric statistical tests over multiple data sets and they indicate that our approach outperforms them in terms of accuracy requiring a lower number of hyperrectangles to be stored, thus obtaining simpler models than previous NGE approaches. Larger data sets have also been tackled with promising outcomes. (C) 2010 Elsevier B. V. All rights reserved.", "paper_title": "Evolutionary selection of hyperrectangles in nested generalized exemplar learning", "paper_id": "WOS:000287479200009"}