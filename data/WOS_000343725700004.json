{"auto_keywords": [{"score": 0.04406294859026498, "phrase": "visual_words"}, {"score": 0.00481495049065317, "phrase": "image_classification"}, {"score": 0.004642604455537883, "phrase": "structurally_enhanced_incremental_neural_learning_technique"}, {"score": 0.00453113241842654, "phrase": "discriminative_codebook_representation"}, {"score": 0.00445830200258645, "phrase": "effective_image_classification_applications"}, {"score": 0.004161553532799662, "phrase": "codebook_learning_process"}, {"score": 0.004078078530972285, "phrase": "online_codebook_graph"}, {"score": 0.0038375280115736958, "phrase": "\"visualization-induced_self-organized_incremental_neural_network"}, {"score": 0.0035819501337406596, "phrase": "graph_representation"}, {"score": 0.0035100601949451028, "phrase": "adaptive_and_competitive_learning_mechanism"}, {"score": 0.003453584878128719, "phrase": "image_features"}, {"score": 0.003370565320453525, "phrase": "sub-graph_extraction_process"}, {"score": 0.0033163269450817716, "phrase": "learned_codebook_graph"}, {"score": 0.003171615440419782, "phrase": "image_classification_task"}, {"score": 0.0030455297429878873, "phrase": "visoinn"}, {"score": 0.0028425481299483254, "phrase": "small_training"}, {"score": 0.002696479050724968, "phrase": "metric_scaling_fashion"}, {"score": 0.0026530590435527527, "phrase": "high_discriminative_power"}, {"score": 0.002526938673434697, "phrase": "fixed_pre-defined_size"}, {"score": 0.0024264193359373977, "phrase": "better_the_structure"}, {"score": 0.0023298892270500983, "phrase": "image_classification_performance"}, {"score": 0.002255431275670053, "phrase": "large-scale_image_classification_tasks"}, {"score": 0.0021394674440767124, "phrase": "markedly_improved_performance"}, {"score": 0.0021049977753042253, "phrase": "computational_cost"}], "paper_keywords": ["Incremental neural learning", " competitive learning", " codebook graph learning", " self-organized neural network", " image classification"], "paper_abstract": "In this paper, a structurally enhanced incremental neural learning technique is proposed to learn a discriminative codebook representation of images for effective image classification applications. In order to accommodate the relationships such as structures and distributions among visual words into the codebook learning process, we develop an online codebook graph learning method based on a novel structurally enhanced incremental learning technique, called as \"visualization-induced self-organized incremental neural network (ViSOINN)\". The hidden structural information in the images is embedded into the graph representation evolving dynamically with the adaptive and competitive learning mechanism. Afterwards, image features can be coded using a sub-graph extraction process based on the learned codebook graph, and a classifier is subsequently used to complete the image classification task. Compared with other codebook learning algorithms originated from the classical Bag-of-Features (BoF) model, ViSOINN holds the following advantages: (1) it learns codebook efficiently and effectively from a small training set; (2) it models the relationships among visual words in metric scaling fashion, so preserving high discriminative power; (3) it automatically learns the codebook without a fixed pre-defined size; and (4) it enhances and preserves better the structure of the data. These characteristics help to improve image classification performance and make it more suitable for handling large-scale image classification tasks. Experimental results on the widely used Caltech-101 and Caltech-256 benchmark datasets demonstrate that ViSOINN achieves markedly improved performance and reduces the computational cost considerably.", "paper_title": "STRUCTURALLY ENHANCED INCREMENTAL NEURAL LEARNING FOR IMAGE CLASSIFICATION WITH SUBGRAPH EXTRACTION", "paper_id": "WOS:000343725700004"}