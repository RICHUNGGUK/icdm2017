{"auto_keywords": [{"score": 0.03505401256188379, "phrase": "overall_task"}, {"score": 0.00481495049065317, "phrase": "decentralized_object"}, {"score": 0.004759507166427077, "phrase": "complex_scenes"}, {"score": 0.004668510065740584, "phrase": "visual_sensor_networks"}, {"score": 0.004632597963417253, "phrase": "video_surveillance"}, {"score": 0.004422827355213055, "phrase": "multiple_cameras"}, {"score": 0.0043215158337835706, "phrase": "potential_advantage"}, {"score": 0.004271729935895193, "phrase": "complementary_observations"}, {"score": 0.004190019394361629, "phrase": "visual_coverage"}, {"score": 0.00406250784433007, "phrase": "tracking_tasks"}, {"score": 0.003923671536980019, "phrase": "real_time_performance"}, {"score": 0.003760385494931853, "phrase": "global_tracking_task"}, {"score": 0.0037170399498025215, "phrase": "distributed_sensing"}, {"score": 0.0036884198249734863, "phrase": "processing_infrastructure"}, {"score": 0.0034140224493254935, "phrase": "three-layer_architecture"}, {"score": 0.0032092293346843224, "phrase": "available_cameras"}, {"score": 0.0031599739264865554, "phrase": "vision_based_state_estimation_problem"}, {"score": 0.003051887221639784, "phrase": "available_sensing"}, {"score": 0.0030283730114326014, "phrase": "processing_resources"}, {"score": 0.00297037471252423, "phrase": "geometric_relations"}, {"score": 0.002913483929932102, "phrase": "people's_positions"}, {"score": 0.0027386335451725762, "phrase": "nearly_independent_subtasks"}, {"score": 0.002686169280393858, "phrase": "occlusion_reasoning"}, {"score": 0.0024479627964740748, "phrase": "task_complexity"}, {"score": 0.0023550410480905727, "phrase": "system's_real_time_throughput"}, {"score": 0.00230098581403254, "phrase": "intrinsic_uncertainty"}, {"score": 0.0022481685132781626, "phrase": "visual_clutter"}, {"score": 0.0021544587602892466, "phrase": "challenging_indoor_and_outdoor_video_sequences"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Multi-camera tracking", " Object tracking", " Distributed tracking", " Camera selection", " Resource allocation", " Task assignment", " Performance evaluation"], "paper_abstract": "The employment of visual sensor networks for video surveillance has brought in as many challenges as advantages. While the integration of multiple cameras into a network has the potential advantage of fusing complementary observations from sensors and enlarging visual coverage, it also increases the complexity of tracking tasks and poses challenges to system scalability. For real time performance, a key approach to tackling these challenges is the mapping of the global tracking task onto a distributed sensing and processing infrastructure. In this paper, we present an efficient and scalable multi-camera multi-people tracking system with a three-layer architecture, in which we formulate the overall task (i.e., tracking all people using all available cameras) as a vision based state estimation problem and aim to maximize utility and sharing of available sensing and processing resources. By exploiting the geometric relations between sensing geometry and people's positions, our method is able to dynamically and adaptively partition the overall task into a number of nearly independent subtasks with the aid of occlusion reasoning, each of which tracks a subset of people with a subset of cameras (or agencies). The method hereby reduces task complexity dramatically and helps to boost parallelization and maximize the system's real time throughput and reliability while accounting for intrinsic uncertainty induced, e.g., by visual clutter and occlusions. We demonstrate the efficiency of our decentralized tracker on challenging indoor and outdoor video sequences. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Dynamic task decomposition for decentralized object tracking in complex scenes", "paper_id": "WOS:000360592500008"}