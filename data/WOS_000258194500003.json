{"auto_keywords": [{"score": 0.048929739366992464, "phrase": "transductive_learning"}, {"score": 0.03919769031169631, "phrase": "hypothesis_space"}, {"score": 0.00481495049065317, "phrase": "large_volume"}, {"score": 0.004422325007817267, "phrase": "large_volume_principle"}, {"score": 0.0041112665381266315, "phrase": "transductive_equivalence_classes"}, {"score": 0.0035530197642369464, "phrase": "volume_maximization"}, {"score": 0.00342568771304873, "phrase": "geometric_interpretation"}, {"score": 0.0031845067058084613, "phrase": "resulting_algorithm"}, {"score": 0.0029965060407413898, "phrase": "non-convex_optimization_problem"}, {"score": 0.002466139325703204, "phrase": "test_error"}, {"score": 0.0022371907579775796, "phrase": "transductive_svm"}, {"score": 0.002183348273627852, "phrase": "tsvm"}], "paper_keywords": ["transductive learning", " large margin", " large volume", " TSVM", " learning principles"], "paper_abstract": "We consider a large volume principle for transductive learning that prioritizes the transductive equivalence classes according to the volume they occupy in hypothesis space. We approximate volume maximization using a geometric interpretation of the hypothesis space. The resulting algorithm is defined via a non-convex optimization problem that can still be solved exactly and efficiently. We provide a bound on the test error of the algorithm and compare it to transductive SVM (TSVM) using 31 datasets.", "paper_title": "Large margin vs. large volume in transductive learning", "paper_id": "WOS:000258194500003"}