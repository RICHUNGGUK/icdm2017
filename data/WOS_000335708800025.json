{"auto_keywords": [{"score": 0.04293428941101478, "phrase": "bpsvm"}, {"score": 0.00481495049065317, "phrase": "pu_learning"}, {"score": 0.004342430078306461, "phrase": "new_version"}, {"score": 0.004243862930012258, "phrase": "support_vector_machine"}, {"score": 0.004195418010131832, "phrase": "named_biased_p-norm_support_vector_machine"}, {"score": 0.0038271712887391015, "phrase": "positive_and_unlabeled_examples"}, {"score": 0.003613556291453534, "phrase": "previous_works"}, {"score": 0.00307657476125683, "phrase": "relevant_features"}, {"score": 0.00290473242917264, "phrase": "theoretically_the_lower_bounds"}, {"score": 0.002806256131739047, "phrase": "nonzero_components"}, {"score": 0.0026191799769765063, "phrase": "corresponding_optimization_problem"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Support vector machine", " Feature selection", " p-Norm", " Positive unlabeled learning"], "paper_abstract": "In this paper, we propose a new version of support vector machine named biased p-norm support vector machine (BPSVM) involved in learning from positive and unlabeled examples. Compared with the previous works, BPSVM can not only improve the performance of classification but also select relevant features automatically based on estimating theoretically the lower bounds for the nonzero components in the solution to the corresponding optimization problem. Preliminary, numerical results show that our BPSVM is effective in both classification and features selection. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Biased p-norm support vector machine for PU learning", "paper_id": "WOS:000335708800025"}