{"auto_keywords": [{"score": 0.04204484988742837, "phrase": "multifactor_images"}, {"score": 0.04139831617780965, "phrase": "multilinear_models"}, {"score": 0.02444286627634483, "phrase": "mge"}, {"score": 0.00481495049065317, "phrase": "multilinear_graph_embedding"}, {"score": 0.00441883624011048, "phrase": "compact_and_discriminative_representation"}, {"score": 0.004324985524216987, "phrase": "big_challenge"}, {"score": 0.004255902303152008, "phrase": "multiple_latent_factors"}, {"score": 0.00409895142748329, "phrase": "data_generation"}, {"score": 0.0036815763368083197, "phrase": "high-order_singular_value_decomposition"}, {"score": 0.0035457302646174148, "phrase": "global_statistics"}, {"score": 0.0034890505116128606, "phrase": "local_variations"}, {"score": 0.003306559295382181, "phrase": "novel_method"}, {"score": 0.002985631781749091, "phrase": "manifold_learning_techniques"}, {"score": 0.002652639568848117, "phrase": "supervised_mge_encodes_informative_image_priors"}, {"score": 0.002473560912156024, "phrase": "high-order_tensor"}, {"score": 0.0023314867226678555, "phrase": "superior_performance"}, {"score": 0.002233301265743633, "phrase": "classic_methods"}, {"score": 0.002197557504730741, "phrase": "hosvd"}, {"score": 0.0021049977753042253, "phrase": "significant_improvement"}], "paper_keywords": ["Multi-factor data", " graph embedding", " manifold learning", " image regularization"], "paper_abstract": "Given a set of images, finding a compact and discriminative representation is still a big challenge especially when multiple latent factors are hidden in the way of data generation. To represent multifactor images, although multilinear models are widely used to parameterize the data, most methods are based on high-order singular value decomposition (HOSVD), which preserves global statistics but interprets local variations inadequately. To this end, we propose a novel method, called multilinear graph embedding (MGE), as well as its kernelization MKGE to leverage the manifold learning techniques into multilinear models. Our method theoretically links the linear, nonlinear, and multilinear dimensionality reduction. We also show that the supervised MGE encodes informative image priors for image regularization, provided that an image is represented as a high-order tensor. From our experiments on face and gait recognition, the superior performance demonstrates that MGE better represents multifactor images than classic methods, including HOSVD and its variants. In addition, the significant improvement in image (or tensor) completion validates the potential of MGE for image regularization.", "paper_title": "Multilinear Graph Embedding: Representation and Regularization for Images", "paper_id": "WOS:000329581800020"}