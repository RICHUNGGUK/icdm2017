{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "generative_neural_networks"}, {"score": 0.004767826806287385, "phrase": "multi-task_life-long_learning"}, {"score": 0.004606518656177626, "phrase": "mtl"}, {"score": 0.004516733575701128, "phrase": "established_method"}, {"score": 0.004406994912939125, "phrase": "neural_network_learning"}, {"score": 0.004195418010131832, "phrase": "knowledge_transfer"}, {"score": 0.004154332348800334, "phrase": "sequential_learning_tasks"}, {"score": 0.003935420482629049, "phrase": "impoverished_training_data"}, {"score": 0.003877737556673229, "phrase": "standard_problem"}, {"score": 0.0038397509389856625, "phrase": "neural_networks"}, {"score": 0.003728000957725218, "phrase": "proper_network_structure"}, {"score": 0.003531474887552889, "phrase": "mtl_case"}, {"score": 0.003296212583539166, "phrase": "mtl_method"}, {"score": 0.0031532895341013297, "phrase": "sequential_or_life-long_learning_case"}, {"score": 0.003016544840824688, "phrase": "unknown_number"}, {"score": 0.0027878797103973313, "phrase": "cascade_correlation"}, {"score": 0.002706659627293686, "phrase": "generative_neural_network_algorithm"}, {"score": 0.002627803819033149, "phrase": "mtl."}, {"score": 0.002538687900036229, "phrase": "cc_algorithm"}, {"score": 0.0023928819778638055, "phrase": "network_structure"}, {"score": 0.0023003498123420237, "phrase": "functional_transfer"}, {"score": 0.0022665781920241245, "phrase": "mtl_techniques"}, {"score": 0.002233301265743633, "phrase": "generative_structure"}, {"score": 0.0022113879114507577, "phrase": "cc_networks"}, {"score": 0.0021682027434117095, "phrase": "dual_network_life-long_learning_system"}, {"score": 0.0021049977753042253, "phrase": "network_topology"}], "paper_keywords": ["multi-task learning", " neural networks", " generative network topology", " life-long learning"], "paper_abstract": "Multi-task learning (MTL) is an established method of inducing bias in neural network learning. It has been used as a method of knowledge transfer in sequential learning tasks, and as a method of overcoming the problem of impoverished training data. A standard problem in neural networks is the establishment of the proper network structure for a given problem. This problem is compounded in the MTL case since the structure of the network can significantly impact the effectiveness of the MTL method. This problem is exacerbated further in the sequential or life-long learning case, as choosing structure a priori for an unknown number of tasks is not possible. In this paper, we explore the use of cascade correlation (CC) as a generative neural network algorithm to overcome these limitations in MTL. We show that generative neural networks using the CC algorithm can display the same MTL advantages while alleviating the need to choose the network structure a priori. We then incorporate the functional transfer from the MTL techniques with the generative structure of CC networks to build a dual network life-long learning system that does not require the network topology or the number of tasks to be predefined.", "paper_title": "Generative Neural Networks for Multi-task Life-Long Learning", "paper_id": "WOS:000332331700006"}