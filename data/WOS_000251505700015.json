{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "weak_detectors"}, {"score": 0.013508003732321746, "phrase": "cell_images"}, {"score": 0.013083052768253962, "phrase": "previous_work"}, {"score": 0.009650844238488582, "phrase": "adaboost"}, {"score": 0.009573662477278762, "phrase": "erc"}, {"score": 0.004606148097788071, "phrase": "protein_expression"}, {"score": 0.004514241562580097, "phrase": "protein_function"}, {"score": 0.004442032546224076, "phrase": "green_fluorescence_protein"}, {"score": 0.004370973501074594, "phrase": "fusion_proteins"}, {"score": 0.0043358695338488445, "phrase": "automated_fluorescence_microscopy"}, {"score": 0.004283739213556286, "phrase": "rapid_acquisition"}, {"score": 0.004249332848326785, "phrase": "large_collections"}, {"score": 0.00421520166010848, "phrase": "protein_localization_images"}, {"score": 0.004081385289516914, "phrase": "automated_image_analysis_system"}, {"score": 0.0038885527668812807, "phrase": "optimal_features"}, {"score": 0.0038263136898042285, "phrase": "standard_machine-learning_algorithms"}, {"score": 0.003719773848735395, "phrase": "recent_advances"}, {"score": 0.0036898803847106023, "phrase": "machine_learning"}, {"score": 0.0036602262729063775, "phrase": "computer_vision"}, {"score": 0.003459191419478298, "phrase": "multiclass_learning"}, {"score": 0.003431384878608803, "phrase": "error-correcting_output_codes"}, {"score": 0.003269162006886173, "phrase": "large_number"}, {"score": 0.0031271827534050493, "phrase": "real-world_scenes"}, {"score": 0.0029672941061574375, "phrase": "new_learning_algorithm"}, {"score": 0.002872979681637667, "phrase": "weak_and_strong_detectors"}, {"score": 0.0027929100418926725, "phrase": "automatic_recognition"}, {"score": 0.002759279370360986, "phrase": "subcellular_locations"}, {"score": 0.0026715708358705553, "phrase": "cho"}, {"score": 0.0026500670717765186, "phrase": "vero"}, {"score": 0.002597088221737922, "phrase": "hela_cell_image_data"}, {"score": 0.0025554669315362424, "phrase": "public_domain"}, {"score": 0.0023381630439887184, "phrase": "significant_performance_improvements"}, {"score": 0.0022095803687183107, "phrase": "heterogeneous_image_collections"}, {"score": 0.0021049977753042253, "phrase": "hela_cell_images"}], "paper_keywords": [""], "paper_abstract": "Motivation: Determining locations of protein expression is essential to understand protein function. Advances in green fluorescence protein (GFP) fusion proteins and automated fluorescence microscopy allow for rapid acquisition of large collections of protein localization images. Recognition of these cell images requires an automated image analysis system. Approaches taken by previous work concentrated on designing a set of optimal features and then applying standard machine-learning algorithms. In fact, trends of recent advances in machine learning and computer vision can be applied to improve the performance. One trend is the advances in multiclass learning with error-correcting output codes (ECOC). Another trend is the use of a large number of weak detectors with boosting for detecting objects in images of real-world scenes. Results: We take advantage of these advances to propose a new learning algorithm, AdaBoost.ERC, coupled with weak and strong detectors, to improve the performance of automatic recognition of protein subcellular locations in cell images. We prepared two image data sets of CHO and Vero cells and downloaded a HeLa cell image data set in the public domain to evaluate our new method. We show that AdaBoost.ERC outperforms other AdaBoost extensions. We demonstrate the benefit of weak detectors by showing significant performance improvements over classifiers using only strong detectors. We also empirically test our methods capability of generalizing to heterogeneous image collections. Compared with previous work, our method performs reasonably well for the HeLa cell images.", "paper_title": "Boosting multiclass learning with repeating codes and weak detectors for protein subcellular localization", "paper_id": "WOS:000251505700015"}