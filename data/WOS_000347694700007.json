{"auto_keywords": [{"score": 0.029680504926650964, "phrase": "rfe"}, {"score": 0.01001913547099286, "phrase": "guyon"}, {"score": 0.005615842167790704, "phrase": "rce"}, {"score": 0.00481495049065317, "phrase": "feature_selection"}, {"score": 0.004750178261675602, "phrase": "ensemble_learning"}, {"score": 0.004409127897028587, "phrase": "internal_estimates"}, {"score": 0.004262273304740847, "phrase": "variable_importance"}, {"score": 0.004204904449336037, "phrase": "random_forests"}, {"score": 0.003983016985197904, "phrase": "unsupervised_learning"}, {"score": 0.003850299959557491, "phrase": "new_method"}, {"score": 0.0037984549828326106, "phrase": "random_cluster_ensemble"}, {"score": 0.0035494788628319903, "phrase": "out-of-bag_feature_importance"}, {"score": 0.003249966782844541, "phrase": "different_bootstrap_sample"}, {"score": 0.0031845067058084583, "phrase": "random_subset"}, {"score": 0.003036832649117453, "phrase": "empirical_results"}, {"score": 0.0029959082125682918, "phrase": "nineteen_benchmark_data_sets"}, {"score": 0.0028376361457661415, "phrase": "recursive_feature_elimination_scheme"}, {"score": 0.0025284524249379265, "phrase": "significant_improvement"}], "paper_keywords": ["Unsupervised learning", " Feature selection", " Ensemble methods", " Random forest"], "paper_abstract": "In this paper, we show that the way internal estimates are used to measure variable importance in Random Forests are also applicable to feature selection in unsupervised learning. We propose a new method called Random Cluster Ensemble (RCE for short), that estimates the out-of-bag feature importance from an ensemble of partitions. Each partition is constructed using a different bootstrap sample and a random subset of the features. We provide empirical results on nineteen benchmark data sets indicating that RCE, boosted with a recursive feature elimination scheme (RFE) (Guyon and Elisseeff, Journal of Machine Learning Research, 3:1157-1182, 2003), can lead to significant improvement in terms of clustering accuracy, over several state-of-the-art supervised and unsupervised algorithms, with a very limited subset of features. The method shows promise to deal with very large domains. All results, datasets and algorithms are available on line (http://perso.univ-lyon1.fr/haytham.elghazel/RCE.zip)", "paper_title": "Unsupervised feature selection with ensemble learning", "paper_id": "WOS:000347694700007"}