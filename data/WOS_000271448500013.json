{"auto_keywords": [{"score": 0.04920822493417556, "phrase": "relieff"}, {"score": 0.00481495049065317, "phrase": "large_datasets"}, {"score": 0.004473982381245469, "phrase": "successful_feature_selector"}, {"score": 0.004273196830970426, "phrase": "large_dataset"}, {"score": 0.0038271712887391015, "phrase": "supervised_model_construction"}, {"score": 0.0037231102027070724, "phrase": "starter_selection"}, {"score": 0.0033961782274326948, "phrase": "clinical_diabetes_database"}, {"score": 0.0030135741897058844, "phrase": "computation_efficiency"}, {"score": 0.00290473242917264, "phrase": "classification_accuracy"}, {"score": 0.0026986685585382347, "phrase": "feature_selection"}, {"score": 0.0026252106881752067, "phrase": "fssmc"}, {"score": 0.002530359917257626, "phrase": "processing_time"}, {"score": 0.002265833357217618, "phrase": "naive_bayes"}], "paper_keywords": ["Relief", " Feature selection", " Classification", " Efficiency"], "paper_abstract": "ReliefF has proved to be a successful feature selector but when handling a large dataset, it is computationally expensive. We present an optimization using Supervised Model Construction which improves starter selection. Effectiveness has been evaluated using 12 UCI datasets and a clinical diabetes database. Experiments indicate that compared with ReliefF, the proposed method improved computation efficiency whilst maintaining the classification accuracy. In the clinical dataset (20,000 records with 47 features), feature selection via Supervised Model Construction (FSSMC) reduced the processing time by 80%, compared to ReliefF, and maintained accuracy for Naive Bayes, IB1 and C4.5 classifiers. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "An optimization of ReliefF for classification in large datasets", "paper_id": "WOS:000271448500013"}