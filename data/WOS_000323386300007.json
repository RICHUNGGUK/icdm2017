{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "interactive_information_retrieval_evaluation_studies"}, {"score": 0.004673079747693193, "phrase": "increasing_number"}, {"score": 0.0046037124365759215, "phrase": "search_tools"}, {"score": 0.004468037801239238, "phrase": "search_systems"}, {"score": 0.004385270183517169, "phrase": "user_perspective"}, {"score": 0.004192803336288522, "phrase": "interactive_information_retrieval"}, {"score": 0.00403885675788806, "phrase": "evaluation_methods"}, {"score": 0.003964007795174772, "phrase": "research_specialty"}, {"score": 0.0036235254023315798, "phrase": "historical_overview"}, {"score": 0.003569681826459428, "phrase": "iir_evaluation_studies"}, {"score": 0.003503497128638099, "phrase": "systematic_review"}, {"score": 0.003412887952564431, "phrase": "conference_units"}, {"score": 0.003214455466823939, "phrase": "predefined_inclusion"}, {"score": 0.0030275252142439213, "phrase": "publication_date"}, {"score": 0.002916238693326477, "phrase": "research_method"}, {"score": 0.00264561514767961, "phrase": "iir_studies"}, {"score": 0.0024000447011533078, "phrase": "additional_product"}, {"score": 0.0023291617361832157, "phrase": "iir_evaluation_research"}, {"score": 0.00216907363015155, "phrase": "authors'_knowledge"}, {"score": 0.0021049977753042253, "phrase": "iir_evaluation_literature"}], "paper_keywords": ["end user searching", " evaluation", " information retrieval"], "paper_abstract": "With the increasing number and diversity of search tools available, interest in the evaluation of search systems, particularly from a user perspective, has grown among researchers. More researchers are designing and evaluating interactive information retrieval (IIR) systems and beginning to innovate in evaluation methods. Maturation of a research specialty relies on the ability to replicate research, provide standards for measurement and analysis, and understand past endeavors. This article presents a historical overview of 40 years of IIR evaluation studies using the method of systematic review. A total of 2,791 journal and conference units were manually examined and 127 articles were selected for analysis in this study, based on predefined inclusion and exclusion criteria. These articles were systematically coded using features such as author, publication date, sources and references, and properties of the research method used in the articles, such as number of subjects, tasks, corpora, and measures. Results include data describing the growth of IIR studies over time, the most frequently occurring and cited authors and sources, and the most common types of corpora and measures used. An additional product of this research is a bibliography of IIR evaluation research that can be used by students, teachers, and those new to the area. To the authors' knowledge, this is the first historical, systematic characterization of the IIR evaluation literature, including the documentation of methods and measures used by researchers in this specialty.", "paper_title": "A systematic review of interactive information retrieval evaluation studies, 1967-2006", "paper_id": "WOS:000323386300007"}