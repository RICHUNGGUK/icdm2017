{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "minimum_classification_error"}, {"score": 0.004586531354697466, "phrase": "single-layer_feedforward_network"}, {"score": 0.004243289764306128, "phrase": "nonlinear_counting_step_function"}, {"score": 0.004121275290411653, "phrase": "quadratic_function"}, {"score": 0.0040027552011993005, "phrase": "classification_error_rate"}, {"score": 0.003631671435460452, "phrase": "derived_solution"}, {"score": 0.003459191419478298, "phrase": "existing_weighted_least-squares_method"}, {"score": 0.002903161412792026, "phrase": "class-specific_weights"}, {"score": 0.0027383842769094354, "phrase": "learning_formulation"}, {"score": 0.002659527314613792, "phrase": "classification_robustness"}, {"score": 0.0025829353063908256, "phrase": "slfn"}, {"score": 0.0024126686412257407, "phrase": "closed-form_algorithm"}, {"score": 0.0021464286727045623, "phrase": "slfn's_effectiveness"}, {"score": 0.0021049977753042253, "phrase": "classification_generalization"}], "paper_keywords": [""], "paper_abstract": "This letter presents a minimum classification error learning formulation for a single-layer feedforward network (SLFN). By approximating the nonlinear counting step function using a quadratic function, the classification error rate is shown to be deterministically solvable. Essentially the derived solution is related to an existing weighted least-squares method with class-specific weights set according to the size of data set. By considering the class-specific weights as adjustable parameters, the learning formulation extends the classification robustness of the SLFN without sacrificing its intrinsic advantage of being a closed-form algorithm. While the method is applicable to other linear formulations, our empirical results indicate SLFN's effectiveness on classification generalization.", "paper_title": "Deterministic neural classification", "paper_id": "WOS:000255518000009"}