{"auto_keywords": [{"score": 0.04317179544664411, "phrase": "patch"}, {"score": 0.012105055712524166, "phrase": "directory_protocols"}, {"score": 0.0052723583091776475, "phrase": "direct_requests"}, {"score": 0.00481495049065317, "phrase": "traditional_coherence_protocols"}, {"score": 0.00470325458481566, "phrase": "difficult_trade-offs"}, {"score": 0.004594137808658537, "phrase": "snoopy_protocols"}, {"score": 0.004452661454196753, "phrase": "broadcast-free_forward_progress"}, {"score": 0.00432208488976429, "phrase": "performance_penalty"}, {"score": 0.004281678802569817, "phrase": "sharing_misses"}, {"score": 0.003934540154108188, "phrase": "coherence_protocol"}, {"score": 0.003701401653850141, "phrase": "sharing_latency"}, {"score": 0.003615443704375908, "phrase": "standard_directory_protocol"}, {"score": 0.00351491577968631, "phrase": "token-counting_rules"}, {"score": 0.0034657012607680173, "phrase": "coherence_permissions"}, {"score": 0.0034332736827447654, "phrase": "token_counting"}, {"score": 0.003306559295382181, "phrase": "unordered_interconnect"}, {"score": 0.003125175084962886, "phrase": "directory_protocol's_per-block_point"}, {"score": 0.002939853413763817, "phrase": "explicit_race_notification_messages"}, {"score": 0.002804789959468603, "phrase": "token_tenure"}, {"score": 0.002726740692380339, "phrase": "token-counting_protocols"}, {"score": 0.0026508575391771807, "phrase": "best-effort_direct_requests"}, {"score": 0.002447101794397243, "phrase": "greater_scalability"}, {"score": 0.0023902026696615473, "phrase": "inexact_encodings"}, {"score": 0.0022064376000055764, "phrase": "\"one-size-fits-all\"_coherence_protocol"}, {"score": 0.0021249064184347658, "phrase": "small_systems"}, {"score": 0.0021049977753042253, "phrase": "large_systems"}], "paper_keywords": ["Design", " Performance", " Cache coherence protocol", " token coherence", " predictive", " adaptive", " bandwidth-efficiency"], "paper_abstract": "Traditional coherence protocols present a set of difficult trade-offs: the reliance of snoopy protocols on broadcast and ordered interconnects limits their scalability, while directory protocols incur a performance penalty on sharing misses due to indirection. This work introduces PATCH (Predictive/Adaptive Token-Counting Hybrid), a coherence protocol that provides the scalability of directory protocols while opportunistically sending direct requests to reduce sharing latency. PATCH extends a standard directory protocol to track tokens and use token-counting rules for enforcing coherence permissions. Token counting allows PATCH to support direct requests on an unordered interconnect, while a mechanism called token tenure provides broadcast-free forward progress using the directory protocol's per-block point of ordering at the home along with either timeouts at requesters or explicit race notification messages. PATCH makes three main contributions. First, PATCH introduces token tenure, which provides broadcast-free forward progress for token-counting protocols. Second, PATCH deprioritizes best-effort direct requests to match or exceed the performance of directory protocols without restricting scalability. Finally, PATCH provides greater scalability than directory protocols when using inexact encodings of sharers because only processors holding tokens need to acknowledge requests. Overall, PATCH is a \"one-size-fits-all\" coherence protocol that dynamically adapts to work well for small systems, large systems, and anywhere in between.", "paper_title": "Token Tenure and PATCH: A Predictive/Adaptive Token-Counting Hybrid", "paper_id": "WOS:000282764900001"}