{"auto_keywords": [{"score": 0.03521557352327997, "phrase": "mmi"}, {"score": 0.00481495049065317, "phrase": "isolated_handwritten_word_recognition"}, {"score": 0.004758457292840376, "phrase": "bernoulli_hmms"}, {"score": 0.004616719219697676, "phrase": "rimes"}, {"score": 0.0045122922461952805, "phrase": "handwritten_text_recognition"}, {"score": 0.004329630571352367, "phrase": "continuous_and_isolated_handwritten_words"}, {"score": 0.004178935413340453, "phrase": "generative_model_family"}, {"score": 0.0037797419108291227, "phrase": "baum-welch_algorithm"}, {"score": 0.0036914757355166966, "phrase": "good_properties"}, {"score": 0.003626626504149897, "phrase": "mle_criterion"}, {"score": 0.003541923233726252, "phrase": "better_training_criteria"}, {"score": 0.003479692058963528, "phrase": "maximum_mutual_information"}, {"score": 0.0032223742018434856, "phrase": "discriminative_models"}, {"score": 0.0030735451757603555, "phrase": "bhmm"}, {"score": 0.0028800314406625996, "phrase": "llhmm"}, {"score": 0.0028293966058473476, "phrase": "binary_data"}, {"score": 0.0027469703311742647, "phrase": "proposed_model"}, {"score": 0.002620040660435039, "phrase": "bhmm_classifier"}, {"score": 0.0024842242921857705, "phrase": "discriminative_training_framework"}, {"score": 0.002455009746748708, "phrase": "bhmm_classifiers"}, {"score": 0.0023415390666563177, "phrase": "proposed_discriminative_training_framework"}, {"score": 0.002259883463607508, "phrase": "well_known_task"}, {"score": 0.002233301265743633, "phrase": "isolated_word_recognition"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["HTR", " Bernoulli HMM", " Log-linear HMM", " MMI", " RIMES"], "paper_abstract": "Bernoulli HMMs (BHMMs) have been successfully applied to handwritten text recognition (HTR) tasks such as continuous and isolated handwritten words. BHMMs belong to the generative model family and, hence, are usually trained by (joint) maximum likelihood estimation (MLE) by means of the Baum-Welch algorithm. Despite the good properties of the MLE criterion, there are better training criteria such as maximum mutual information (MM!). The MMI is the most widespread criterion to train discriminative models such as log-linear (or maximum entropy) models. Inspired by a BHMM classifier, in this work, a log-linear HMM (LLHMM) for binary data is proposed. The proposed model is proved to be equivalent to the BHMM classifier, and, in this way, a discriminative training framework for BHMM classifiers is defined. The behavior of the proposed discriminative training framework is deeply studied in a well known task of isolated word recognition, the RIMES database. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Discriminative Bernoulli HMMs for isolated handwritten word recognition", "paper_id": "WOS:000327561000018"}