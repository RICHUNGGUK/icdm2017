{"auto_keywords": [{"score": 0.027191527959281904, "phrase": "abc"}, {"score": 0.00481495049065317, "phrase": "multiple_heterogeneous_swarm_intelligence"}, {"score": 0.0047395356621991935, "phrase": "neural_network_ensemble"}, {"score": 0.00468991337957911, "phrase": "nine"}, {"score": 0.004496542293425754, "phrase": "good_prediction_performance"}, {"score": 0.004089991141220082, "phrase": "interacting_agents"}, {"score": 0.003921369994362011, "phrase": "nne"}, {"score": 0.0037005154613244363, "phrase": "multi-population_swarm_intelligence"}, {"score": 0.0036812124287087726, "phrase": "fnn"}, {"score": 0.003492155652400838, "phrase": "component_forward_neural_network"}, {"score": 0.0033656930865509547, "phrase": "chaotic_particle_swarm_optimization"}, {"score": 0.0033568527122546047, "phrase": "cpso"}, {"score": 0.003278167066287366, "phrase": "gradient_gescending"}, {"score": 0.002997203022420553, "phrase": "multiple_obviously_different_populations"}, {"score": 0.0029501745152877706, "phrase": "swarm_intelligence"}, {"score": 0.002798662730881037, "phrase": "particle_swarm_optimization"}, {"score": 0.002654911400878851, "phrase": "differential_evolution"}, {"score": 0.0025858215477025117, "phrase": "artificial_bee_colony_algorithm"}, {"score": 0.0025052769325080255, "phrase": "ensemble_weights"}, {"score": 0.0024529757621396717, "phrase": "multi-population_co-evolution_pso-abc-de_chaotic_searching_algorithm"}, {"score": 0.002242577809454225, "phrase": "proposed_novel_inne_algorithm"}, {"score": 0.0021957487795963666, "phrase": "existing_popular_nne"}, {"score": 0.002172701452347454, "phrase": "function_prediction"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Neural network ensemble", " Particle swarm optimization", " Differential evolution", " Artificial bee colony", " Chaotic search"], "paper_abstract": "The neural network ensemble (NINE) is a very effective way to obtain a good prediction performance by combining the outputs of several independently trained neural networks. Swarm intelligence is applied here to model the population of interacting agents or swarms that are able to self-organize. In this paper, we combine NNE and multi-population swarm intelligence to construct our improved neural network ensemble (INNE). First, each component forward neural network (FNN) is optimized by chaotic particle swarm optimization (CPSO) and gradient gescending (GD) algorithm. Second, in contrast to most existing NNE training algorithm, we adopt multiple obviously different populations to construct swarm intelligence. As an example, one population is trained by particle swarm optimization (PSO) and the others are trained by differential evolution (DE) or artificial bee colony algorithm (ABC). The ensemble weights are trained by multi-population co-evolution PSO-ABC-DE chaotic searching algorithm (M-PSO-ABC-DE-CS). Our experiments demonstrate that the proposed novel INNE algorithm is superior to existing popular NNE in function prediction. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Evolved neural network ensemble by multiple heterogeneous swarm intelligence", "paper_id": "WOS:000360028800005"}