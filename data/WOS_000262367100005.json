{"auto_keywords": [{"score": 0.03574824228788165, "phrase": "new_extension"}, {"score": 0.02305973478827242, "phrase": "learning_classifier_systems"}, {"score": 0.012830787022149338, "phrase": "xcsfg"}, {"score": 0.009130088719039914, "phrase": "state-action_pairs"}, {"score": 0.00481495049065317, "phrase": "arbitrary_reinforcement_signal"}, {"score": 0.004744437370338926, "phrase": "micro_genetic_algorithm"}, {"score": 0.004674952036988355, "phrase": "evolutionary_learning_mechanisms"}, {"score": 0.004623503587186056, "phrase": "genetic_algorithm"}, {"score": 0.00447251540886613, "phrase": "state-action-reward_mappings"}, {"score": 0.004342430078306461, "phrase": "environmental_state"}, {"score": 0.004278807087784626, "phrase": "achieved_reward"}, {"score": 0.004216112320418982, "phrase": "first_versions"}, {"score": 0.004169692306713217, "phrase": "classifier_systems"}, {"score": 0.0040334640350288, "phrase": "constant_real-valued_reward"}, {"score": 0.003945117054416623, "phrase": "fairly_complex_environment"}, {"score": 0.003858697684681798, "phrase": "redundant_state-action_pairs"}, {"score": 0.0037602557461171478, "phrase": "different_reward_values"}, {"score": 0.003664315990489347, "phrase": "well-known_lcs"}, {"score": 0.003623949225126944, "phrase": "accuracy_based_learning_classifier_system"}, {"score": 0.0035972871819860055, "phrase": "xcs"}, {"score": 0.003428665921276366, "phrase": "linear_reward_function"}, {"score": 0.0033535218641905255, "phrase": "xcsf"}, {"score": 0.0032558762499901727, "phrase": "original_xcs."}, {"score": 0.003091767402370757, "phrase": "proper_mappings"}, {"score": 0.0030576885787607796, "phrase": "input_parameters"}, {"score": 0.002860938351029155, "phrase": "novel_solution"}, {"score": 0.0027878797103973313, "phrase": "evolutionary_approach"}, {"score": 0.0027469703311742647, "phrase": "reward_landscape"}, {"score": 0.002716681656135794, "phrase": "first_results"}, {"score": 0.0022665781920241245, "phrase": "reported_results"}, {"score": 0.0021842976754894846, "phrase": "alternative_approach"}, {"score": 0.0021682027434117095, "phrase": "xcsf_family"}, {"score": 0.002120624523437494, "phrase": "approximation_accuracy"}, {"score": 0.0021049977753042253, "phrase": "population_compactness"}], "paper_keywords": ["Function Approximation", " Learning Classifier Systems", " Micro Genetic Algorithm", " XCSF"], "paper_abstract": "Learning Classifier Systems are Evolutionary Learning mechanisms which combine Genetic Algorithm and the Reinforcement Learning paradigm. Learning Classifier Systems try to evolve state-action-reward mappings to propose the best action for each environmental state to maximize the achieved reward. In the first versions of learning classifier systems, state-action pairs can only be mapped to a constant real-valued reward. So to model a fairly complex environment, LCSs had to develop redundant state-action pairs which had to be mapped to different reward values. But an extension to a well-known LCS, called Accuracy Based Learning Classifier System or XCS, was recently developed which was able to map state-action pairs to a linear reward function. This new extension, called XCSF, can develop a more compact population than the original XCS. But some further researches have shown that this new extension is not able to develop proper mappings when the input parameters are from certain intervals. As a solution to this issue, in our previous works, we proposed a novel solution inspired by the idea of using evolutionary approach to approximate the reward landscape. The first results seem promising, but our approach, called XCSFG, converged to the goal very slowly. In this paper, we propose a new extension to XCSFG which employs micro-GA which its needed population is extremely smaller than simple GA. So we expect micro-GA to help XCSFG to converge faster. Reported results show that this new extension can be assumed as an alternative approach in XCSF family with respect to its convergence speed, approximation accuracy and population compactness.", "paper_title": "Approximating Arbitrary Reinforcement Signal by Learning Classifier Systems using Micro Genetic Algorithm", "paper_id": "WOS:000262367100005"}