{"auto_keywords": [{"score": 0.03556417972834715, "phrase": "aggressive_compression"}, {"score": 0.00481495049065317, "phrase": "interactive_remote"}, {"score": 0.004760017604908536, "phrase": "time-varying_data_sets"}, {"score": 0.004563880494020726, "phrase": "set_sizes"}, {"score": 0.004477407179841716, "phrase": "computer_network_performance"}, {"score": 0.003976523732243618, "phrase": "view_parameter_change"}, {"score": 0.003931118518507637, "phrase": "reduced_interactivity"}, {"score": 0.0038713805573219297, "phrase": "high_latency"}, {"score": 0.0036553070575015344, "phrase": "view_parameters"}, {"score": 0.003531474887552889, "phrase": "new_image"}, {"score": 0.0034512514926836667, "phrase": "second_problem"}, {"score": 0.0034118234596993836, "phrase": "image_quality"}, {"score": 0.003347105144425849, "phrase": "low_resolution"}, {"score": 0.003221316290858497, "phrase": "enhanced_images"}, {"score": 0.003160200215473349, "phrase": "quality_output_frame_reconstruction"}, {"score": 0.0030648097361278856, "phrase": "view_parameter_values"}, {"score": 0.0029270797740550973, "phrase": "additional_data"}, {"score": 0.002784828661426853, "phrase": "animated_depth_images"}, {"score": 0.0025110337774260773, "phrase": "sample_trajectories"}, {"score": 0.00241658945942583, "phrase": "-rigid_sample_clusters"}, {"score": 0.002361632539339945, "phrase": "rigid_body_transformations"}, {"score": 0.0022990901047984197, "phrase": "leverage_sample_trajectory_coherence"}, {"score": 0.0022640963589007457, "phrase": "good_compression"}, {"score": 0.002246799280512825, "phrase": "animation_data"}, {"score": 0.0022125996721544514, "phrase": "small_and_user-controllable_approximation_error"}, {"score": 0.0021212055097236527, "phrase": "finite_element_analysis"}, {"score": 0.0021049977753042253, "phrase": "sph_data_sets"}], "paper_keywords": ["Remote visualization", " time-varying data sets", " animation data compression", " rigid-body decomposition", " bounded error"], "paper_abstract": "Remote visualization has become both a necessity, as data set sizes have grown faster than computer network performance, and an opportunity, as laptop, tablet, and smartphone mobile computing platforms have become ubiquitous. However, the conventional remote visualization (CRV) approach of sending a new image from the server to the client for every view parameter change suffers from reduced interactivity. One problem is high latency, as the network has to be traversed twice, once to communicate the view parameters to the server and once to transmit the new image to the client. A second problem is reduced image quality due to aggressive compression or low resolution. We address these problems by constructing and transmitting enhanced images that are sufficient for quality output frame reconstruction at the client for a range of view parameter values. The client reconstructs thousands of frames locally, without any additional data from the server, which avoids latency and aggressive compression. We introduce animated depth images, which not only store a color and depth sample at every pixel, but also store the trajectory of the samples for a given time interval. Sample trajectories are stored compactly by partitioning the image into semi-rigid sample clusters and by storing one sequence of rigid body transformations per cluster. Animated depth images leverage sample trajectory coherence to achieve a good compression of animation data, with a small and user-controllable approximation error. We demonstrate animated depth images in the context of finite element analysis and SPH data sets.", "paper_title": "Animated Depth Images for Interactive Remote Visualization of Time-Varying Data Sets", "paper_id": "WOS:000343009400001"}