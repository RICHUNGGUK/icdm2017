{"auto_keywords": [{"score": 0.0486868426803837, "phrase": "monocular_images"}, {"score": 0.014613131834284658, "phrase": "action_recognition_feedback"}, {"score": 0.00481495049065317, "phrase": "feedback-based_framework"}, {"score": 0.004744437370338926, "phrase": "human_pose_reconstruction"}, {"score": 0.0045726187330434025, "phrase": "novel_framework"}, {"score": 0.004406994912939125, "phrase": "pose_reconstruction"}, {"score": 0.004342430078306461, "phrase": "articulated_human_body"}, {"score": 0.0040334640350288, "phrase": "intrinsic_ambiguity"}, {"score": 0.003945117054416623, "phrase": "perspective_projection"}, {"score": 0.0037463983616303786, "phrase": "articulated_poses"}, {"score": 0.0034540850937966336, "phrase": "high-level_motion_knowledge"}, {"score": 0.0032558762499901727, "phrase": "implausible_estimates"}, {"score": 0.003069006373093756, "phrase": "motion_constraints"}, {"score": 0.0030239842475439814, "phrase": "natural_human_movement"}, {"score": 0.0029576827451501956, "phrase": "motion_knowledge"}, {"score": 0.002850385670169814, "phrase": "local_and_global_motion_constraints"}, {"score": 0.0027878797103973313, "phrase": "local_spatial_constraint"}, {"score": 0.0027469703311742647, "phrase": "motion_correlation"}, {"score": 0.002706659627293686, "phrase": "body_parts"}, {"score": 0.00266693888510356, "phrase": "multiple_relevance_vector_machines"}, {"score": 0.0026084451971464867, "phrase": "global_temporal_constraint"}, {"score": 0.002570162055835289, "phrase": "temporal_coherence"}, {"score": 0.0025324393547676623, "phrase": "time-ordered_poses"}, {"score": 0.0024768883044869023, "phrase": "manifold_motion_template"}, {"score": 0.0023869914500743083, "phrase": "cmu_mocap_database"}, {"score": 0.0022665781920241245, "phrase": "estimation_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Human pose reconstruction", " Action recognition feedback", " Motion correlation", " Manifold motion template"], "paper_abstract": "A novel framework based on action recognition feedback for pose reconstruction of articulated human body from monocular images is proposed in this paper. The intrinsic ambiguity Caused by perspective projection makes it difficult to accurately recover articulated poses from Monocular images. To alleviate such ambiguity, we exploit the high-level motion knowledge as action recognition feedback to discard those implausible estimates and generate more accurate pose candidates using large number of motion constraints during natural human movement. The motion knowledge is represented by both local and global motion constraints. The local spatial constraint captures motion correlation between body parts by multiple relevance vector machines while the global temporal constraint preserves temporal coherence between time-ordered poses via a manifold motion template. Experiments oil the CMU Mocap database demonstrate that our method performs better on estimation accuracy than other methods without action recognition feedback. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Action recognition feedback-based framework for human pose reconstruction from monocular images", "paper_id": "WOS:000268866700005"}