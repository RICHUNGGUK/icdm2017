{"auto_keywords": [{"score": 0.04575326850542082, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "cost-based_feature_selection"}, {"score": 0.004571269461883144, "phrase": "data_mining_applications"}, {"score": 0.004238576355081601, "phrase": "dimensionality_reduction"}, {"score": 0.0041987222897385676, "phrase": "relevance_detection"}, {"score": 0.0037133478610481994, "phrase": "new_general_framework"}, {"score": 0.0035587046945919788, "phrase": "new_term"}, {"score": 0.0035085965086415474, "phrase": "evaluation_function"}, {"score": 0.003459191419478298, "phrase": "filter_feature_selection_method"}, {"score": 0.00326840809777013, "phrase": "proposed_methodology"}, {"score": 0.0031769866037536045, "phrase": "feature_selection_filter"}, {"score": 0.0029315889652602703, "phrase": "cfs"}, {"score": 0.002616943519478975, "phrase": "proposed_framework"}, {"score": 0.002519739850807611, "phrase": "support_vector_machine"}, {"score": 0.0023806459272452353, "phrase": "experimental_study"}, {"score": 0.0021656385587456952, "phrase": "classification_error"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Cost-based feature selection", " Machine learning", " Filter methods"], "paper_abstract": "Over the last few years, the dimensionality of datasets involved in data mining applications has increased dramatically. In this situation, feature selection becomes indispensable as it allows for dimensionality reduction and relevance detection. The research proposed in this paper broadens the scope of feature selection by taking into consideration not only the relevance of the features but also their associated costs. A new general framework is proposed, which consists of adding a new term to the evaluation function of a filter feature selection method so that the cost is taken into account. Although the proposed methodology could be applied to any feature selection filter, in this paper the approach is applied to two representative filter methods: Correlation-based Feature Selection (CFS) and Minimal-Redundancy-Maximal-Relevance (mRMR), as an example of use. The behavior of the proposed framework is tested on 17 heterogeneous classification datasets, employing a Support Vector Machine (SVM) as a classifier. The results of the experimental study show that the approach is sound and that it allows the user to reduce the cost without compromising the classification error. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "A framework for cost-based feature selection", "paper_id": "WOS:000334978100019"}