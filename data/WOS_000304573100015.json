{"auto_keywords": [{"score": 0.04878556281654673, "phrase": "video_conferencing"}, {"score": 0.00481495049065317, "phrase": "-level_mode-mapping"}, {"score": 0.004642292792558686, "phrase": "scalable_video_coding"}, {"score": 0.004315249628884236, "phrase": "flexible_adaptation"}, {"score": 0.004276016541197123, "phrase": "heterogeneous_networks"}, {"score": 0.004237138632255772, "phrase": "different_end-user_requirements"}, {"score": 0.004160435626849478, "phrase": "great_scalability"}, {"score": 0.004122604238556912, "phrase": "multi-point_applications"}, {"score": 0.003797181692850592, "phrase": "svc"}, {"score": 0.0036776458116294986, "phrase": "temporal_transcoding"}, {"score": 0.0036441884295335502, "phrase": "quality_transcoding"}, {"score": 0.003611034322786669, "phrase": "svc-to-avc_spatial_transcoding"}, {"score": 0.003561865840737996, "phrase": "straightforward_re-encoding_method"}, {"score": 0.0034027387694902287, "phrase": "low-complexity_avc-to-svc_spatial_transcoder"}, {"score": 0.003265591844292821, "phrase": "video_conferencing_scenes"}, {"score": 0.003177235604998673, "phrase": "unnecessary_motion_estimations"}, {"score": 0.0030771609361092164, "phrase": "reduced_resolution"}, {"score": 0.0029666322924554274, "phrase": "avc_mode_distribution"}, {"score": 0.0028995712226514746, "phrase": "adaptive_search_range"}, {"score": 0.0028470123663391104, "phrase": "probability-profile_based_scheme"}, {"score": 0.0026220103561723066, "phrase": "adaptive_usage"}, {"score": 0.0024147474002390763, "phrase": "top_layer"}, {"score": 0.0023927516438886445, "phrase": "direct_encapsulation"}, {"score": 0.0023386327847292805, "phrase": "better_quality"}, {"score": 0.0022857351723674004, "phrase": "inter-layer_predictions"}, {"score": 0.002234031373581961, "phrase": "bandwidth-crucial_applications"}, {"score": 0.0021735249249471614, "phrase": "proposed_transcoder"}, {"score": 0.0021340985236583034, "phrase": "significant_coding_efficiency_loss"}, {"score": 0.0021049977753042253, "phrase": "re-encoding_method"}], "paper_keywords": ["AVC-SVC transcoding", " spatial scalability", " mode-mapping", " low-complexity", " video conferencing"], "paper_abstract": "Scalable Video Coding (SVC) was standardized as an extension of H.264/AVC with the intention to provide flexible adaptation to heterogeneous networks and different end-user requirements, which provides great scalability in multi-point applications such as video conferencing. However, due to the existence of H.264/AVC-based systems, transcoding between AVC and SVC becomes necessary. Most existing works focus on temporal transcoding, quality transcoding or SVC-to-AVC spatial transcoding while the straightforward re-encoding method requires high computational cost. This paper proposes a low-complexity AVC-to-SVC spatial transcoder based on coarse-level mode mapping for video conferencing scenes. First, to omit unnecessary motion estimations (ME) for layers with reduced resolution, an ME skipping scheme based on AVC mode distribution is proposed with an adaptive search range. Then a probability-profile based scheme is proposed for further mode skipping. After that 3 coarse-level mode-mapping methods are presented for fast mode decision and the adaptive usage of the 3 methods is discussed. Finally, motion vector (MV) refinement is introduced for further lower-layer time reduction. As for the top layer, direct encapsulation is proposed to preserve better quality and another scheme involving inter-layer predictions is also provided for bandwidth-crucial applications. Simulation results show that proposed transcoder achieves up to 92.6% time reduction without significant coding efficiency loss compared to re-encoding method.", "paper_title": "Low-Complexity Coarse-Level Mode-Mapping Based H.264/AVC to H.264/SVC Spatial Transcoding for Video Conferencing", "paper_id": "WOS:000304573100015"}