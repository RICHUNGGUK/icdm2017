{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "last-level-cache_policies"}, {"score": 0.003900257249255497, "phrase": "many-core_architectures"}, {"score": 0.0035386420095120706, "phrase": "virtual_write_queue"}, {"score": 0.0033163269450817716, "phrase": "memory_controller's_scheduling_window"}, {"score": 0.003107935254560724, "phrase": "cache_behavior"}, {"score": 0.002865710140187219, "phrase": "physical_main_memory_layout"}, {"score": 0.00235843888868088, "phrase": "average_latency"}, {"score": 0.002246292543825748, "phrase": "memory_power_consumption"}, {"score": 0.0021049977753042253, "phrase": "overall_system_performance"}], "paper_keywords": [""], "paper_abstract": "To alleviate bottlenecks in this era of many-core architectures, the authors propose a virtual write queue to expand the memory controller's scheduling window through visibility of cache behavior. Awareness of the physical main memory layout and a focus on writes can shorten both read and write average latency, reduce memory power consumption, and improve overall system performance.", "paper_title": "COORDINATING DRAM AND LAST-LEVEL-CACHE POLICIES WITH THE VIRTUAL WRITE QUEUE", "paper_id": "WOS:000287244200010"}