{"auto_keywords": [{"score": 0.02963319490359678, "phrase": "proposed_algorithm"}, {"score": 0.00901596972798841, "phrase": "experimental_results"}, {"score": 0.00481495049065317, "phrase": "mlp_due"}, {"score": 0.004285594361623147, "phrase": "central_limit_theorem"}, {"score": 0.004122351497440992, "phrase": "multilayer_perceptron"}, {"score": 0.0033015555065209865, "phrase": "proposed_algorithm_show"}, {"score": 0.0025713100093065645, "phrase": "theoretical_ones"}, {"score": 0.002473203873496859, "phrase": "theoretical_results"}, {"score": 0.0021763973978248005, "phrase": "precisely_the_sensitivity"}, {"score": 0.0021049977753042253, "phrase": "available_activation_functions"}], "paper_keywords": ["Central limit theorem", " multilayer perceptron", " neural networks", " sensitivity analysis"], "paper_abstract": "In this paper, we propose an algorithm based on the central limit theorem to compute the sensitivity of the multilayer perceptron (MLP) due to the errors of the inputs and weights. For simplicity and practicality, all inputs and weights studied here are independently identically distributed (i.i.d.). The theoretical results derived from the proposed algorithm show that the sensitivity of the MLP is affected by the number of layers and the number of neurons adopted in each layer. To prove the reliability of the proposed algorithm, some experimental results of the sensitivity are also presented, and they match the theoretical ones. The good agreement between the theoretical results and the experimental results verifies the reliability and feasibility of the proposed algorithm. Furthermore, the proposed algorithm can also be applied to compute precisely the sensitivity of the MLP with any available activation functions and any types of i.i.d. inputs and weights.", "paper_title": "Computing and Analyzing the Sensitivity of MLP Due to the Errors of the i.i.d. Inputs and Weights Based on CLT", "paper_id": "WOS:000285053800003"}