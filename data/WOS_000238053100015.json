{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "decision_stumps"}, {"score": 0.0047292449487169345, "phrase": "parametric_models"}, {"score": 0.004603525341738782, "phrase": "linear_regression"}, {"score": 0.0038810583785936505, "phrase": "entire_data"}, {"score": 0.0033914308417007316, "phrase": "nonparametric_regression"}, {"score": 0.0030997236644076196, "phrase": "local_averaging_estimator"}, {"score": 0.0026126405272417783, "phrase": "local_boosting"}, {"score": 0.0023033100935570755, "phrase": "standard_benchmark_datasets"}, {"score": 0.0021821915946356168, "phrase": "proposed_technique"}], "paper_keywords": [""], "paper_abstract": "Parametric models such as linear regression can provide useful, interpretable descriptions of simple structure in data. However, sometimes such simple structure does not extend across an entire data set and may instead be confined more locally within subsets of the data. Nonparametric regression typically involves local averaging. In this study, local averaging estimator is coupled with a machine learning technique - boosting. In more detail, we propose a technique of local boosting of decision stumps. We performed a comparison with other well known methods and ensembles, on standard benchmark datasets and the performance of the proposed technique was greater in most cases.", "paper_title": "Local additive regression of decision stumps", "paper_id": "WOS:000238053100015"}