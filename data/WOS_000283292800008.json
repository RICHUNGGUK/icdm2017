{"auto_keywords": [{"score": 0.043855814204982885, "phrase": "overt_attention"}, {"score": 0.009543629985088233, "phrase": "head_movement"}, {"score": 0.008271262506916703, "phrase": "proposed_model"}, {"score": 0.00481495049065317, "phrase": "overt_visual_attention"}, {"score": 0.004765788394931875, "phrase": "cognitive_robots"}, {"score": 0.004717125879761534, "phrase": "visual_attention"}, {"score": 0.004597622380240611, "phrase": "major_requirements"}, {"score": 0.004412654209742722, "phrase": "cognitive_companion"}, {"score": 0.004300830853119242, "phrase": "robotic_visual_attention"}, {"score": 0.004085579055228594, "phrase": "eye_movements"}, {"score": 0.0038217146888983576, "phrase": "camera_head"}, {"score": 0.00368673793612343, "phrase": "namely_transformation"}, {"score": 0.003574830654211291, "phrase": "image_coordinate_systems"}, {"score": 0.0034485432592912917, "phrase": "visual_field"}, {"score": 0.0033957904376127187, "phrase": "partial_appearance"}, {"score": 0.0031277316566463978, "phrase": "meaningful_identification"}, {"score": 0.0030798711656591948, "phrase": "next_focus"}, {"score": 0.0027505037762786087, "phrase": "classical_models"}, {"score": 0.0027223626424366207, "phrase": "covert_visual_attention"}, {"score": 0.00263965046277432, "phrase": "bayesian_model"}, {"score": 0.0025992391074270097, "phrase": "robot-centric_solution"}, {"score": 0.002559444836360178, "phrase": "overt_visual_attention_problem"}, {"score": 0.0024311346712789553, "phrase": "primates_visual_attention_mechanism"}, {"score": 0.002250601866422547, "phrase": "particle_filter_implementation"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": ["Bayes filter", " biased competition (BC)", " overt visual attention", " probabilistic modeling", " scale invariant feature transform (SIFT)"], "paper_abstract": "Visual attention is one of the major requirements for a robot to serve as a cognitive companion for human. The robotic visual attention is mostly concerned with overt attention which accompanies head and eye movements of a robot. In this case, each movement of the camera head triggers a number of events, namely transformation of the camera and the image coordinate systems, change of content of the visual field, and partial appearance of the stimuli. All of these events contribute to the reduction in probability of meaningful identification of the next focus of attention. These events are specific to overt attention with head movement and, therefore, their effects are not addressed in the classical models of covert visual attention. This paper proposes a Bayesian model as a robot-centric solution for the overt visual attention problem. The proposed model, while taking inspiration from the primates visual attention mechanism, guides a robot to direct its camera toward behaviorally relevant and/or visually demanding stimuli. A particle filter implementation of this model addresses the challenges involved in overt attention with head movement. Experimental results demonstrate the performance of the proposed model.", "paper_title": "A Probabilistic Model of Overt Visual Attention for Cognitive Robots", "paper_id": "WOS:000283292800008"}