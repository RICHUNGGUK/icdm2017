{"auto_keywords": [{"score": 0.039670555366107786, "phrase": "emd"}, {"score": 0.011265445728029047, "phrase": "representative_data_subspace"}, {"score": 0.00481495049065317, "phrase": "data_clustering"}, {"score": 0.004725886853744007, "phrase": "digital_data"}, {"score": 0.004304574865291508, "phrase": "data_mining_research"}, {"score": 0.004127394241838696, "phrase": "theoretical_framework"}, {"score": 0.0040890178236849825, "phrase": "exemplar-based_low-rank_sparse_matrix_decomposition"}, {"score": 0.003957477564354679, "phrase": "large-scale_datasets"}, {"score": 0.003884212965525665, "phrase": "recent_advances"}, {"score": 0.003848088904418221, "phrase": "matrix_approximation"}, {"score": 0.003689628075766217, "phrase": "large_dimensions"}, {"score": 0.0036553070575015344, "phrase": "scalable_sizes"}, {"score": 0.0035376693476114733, "phrase": "data_matrix"}, {"score": 0.0033919477901198716, "phrase": "near-optimal_low-rank_approximation"}, {"score": 0.003206916619690171, "phrase": "matrix_decomposition"}, {"score": 0.0030891871245908665, "phrase": "cluster_centroids"}, {"score": 0.0029618842673339173, "phrase": "representative_exemplars"}, {"score": 0.002622755848331379, "phrase": "clustering_results"}, {"score": 0.0025028892126605124, "phrase": "theoretical_perspective"}, {"score": 0.002388487669097511, "phrase": "emd_algorithm"}, {"score": 0.002344201345813952, "phrase": "detailed_analysis"}, {"score": 0.002289993730291136, "phrase": "running_time"}, {"score": 0.0022686625017583387, "phrase": "spatial_requirements"}, {"score": 0.002237036807966899, "phrase": "extensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "large-scale_data"}], "paper_keywords": ["Clustering", " Low-rank approximation", " Subspaces", " Matrix decomposition"], "paper_abstract": "Today, digital data is accumulated at a faster than ever speed in science, engineering, biomedicine, and real-world sensing. The ubiquitous phenomenon of massive data and sparse information imposes considerable challenges in data mining research. In this paper, we propose a theoretical framework, Exemplar-based low-rank sparse matrix decomposition (EMD), to cluster large-scale datasets. Capitalizing on recent advances in matrix approximation and decomposition, EMD can partition datasets with large dimensions and scalable sizes efficiently. Specifically, given a data matrix, EMD first computes a representative data subspace and a near-optimal low-rank approximation. Then, the cluster centroids and indicators are obtained through matrix decomposition, in which we require that the cluster centroids lie within the representative data subspace. By selecting the representative exemplars, we obtain a compact \"sketch\"of the data. This makes the clustering highly efficient and robust to noise. In addition, the clustering results are sparse and easy for interpretation. From a theoretical perspective, we prove the correctness and convergence of the EMD algorithm, and provide detailed analysis on its efficiency, including running time and spatial requirements. Through extensive experiments performed on both synthetic and real datasets, we demonstrate the performance of EMD for clustering large-scale data.", "paper_title": "Exemplar-based low-rank matrix decomposition for data clustering", "paper_id": "WOS:000349369300002"}