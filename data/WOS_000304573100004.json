{"auto_keywords": [{"score": 0.04896221231267542, "phrase": "conditional_random_fields"}, {"score": 0.048412942923644654, "phrase": "multimodal_features"}, {"score": 0.004815227925364173, "phrase": "news"}, {"score": 0.004129873531628877, "phrase": "broadcast_news_stories"}, {"score": 0.0040334640350288, "phrase": "story_boundary_cues"}, {"score": 0.003802135020791801, "phrase": "lexical_features"}, {"score": 0.003735349093835257, "phrase": "lexical_similarity"}, {"score": 0.0036914757355166966, "phrase": "chain_strength"}, {"score": 0.0036481158025940016, "phrase": "overall_cohesiveness"}, {"score": 0.0036052633308076933, "phrase": "acoustic_features"}, {"score": 0.003562912424153324, "phrase": "pause_duration"}, {"score": 0.003479692058963528, "phrase": "speaker_change"}, {"score": 0.0034388111429203222, "phrase": "audio_event_type"}, {"score": 0.003378385493203297, "phrase": "visual_features"}, {"score": 0.003338690782620756, "phrase": "shot_boundaries"}, {"score": 0.0030195184114140063, "phrase": "boundary_candidate_positions"}, {"score": 0.002966438503447793, "phrase": "broadcast_news"}, {"score": 0.0028971416123237162, "phrase": "crf"}, {"score": 0.002651213849567608, "phrase": "important_interlabel_relations"}, {"score": 0.002620040660435039, "phrase": "contextual_feature_information"}, {"score": 0.0025286975935774245, "phrase": "sequential_learning_framework"}, {"score": 0.00246957392654378, "phrase": "story_segmentation_experiments"}, {"score": 0.0024118292918742967, "phrase": "crf_approach"}, {"score": 0.0023415390666563177, "phrase": "decision_trees"}, {"score": 0.002273292707863821, "phrase": "bayesian_networks"}, {"score": 0.0022070310530794097, "phrase": "naive_bayesian_classifiers"}, {"score": 0.002105025988953339, "phrase": "mlp"}], "paper_keywords": ["story segmentation", " conditional random fields"], "paper_abstract": "In this paper, we propose integration of multimodal features using conditional random fields (CRFs) for the segmentation of broadcast news stories. We study story boundary cues from lexical, audio and video modalities, where lexical features consist of lexical similarity, chain strength and overall cohesiveness; acoustic features involve pause duration, pitch, speaker change and audio event type; and visual features contain shot boundaries, anchor faces and news title captions. These features are extracted in a sequence of boundary candidate positions in the broadcast news. A linear-chain CRF is used to detect each candidate as boundary/non-boundary tags based on the multimodal features. Important interlabel relations and contextual feature information are effectively captured by the sequential learning framework of CRFs. Story segmentation experiments show that the CRF approach outperforms other popular classifiers, including decision trees (DTs), Bayesian networks (BNs), naive Bayesian classifiers (NBs), multilayer perception (MLP), support vector machines (SVMs) and maximum entropy (ME) classifiers.", "paper_title": "Broadcast News Story Segmentation Using Conditional Random Fields and Multimodal Features", "paper_id": "WOS:000304573100004"}