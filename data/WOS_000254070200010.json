{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "neural_model_selection"}, {"score": 0.046448599314105624, "phrase": "weighted_bootstrap_procedure"}, {"score": 0.004167982855788402, "phrase": "efficient_bootstrap_technique"}, {"score": 0.003802135020791801, "phrase": "computer_effort"}, {"score": 0.003423042581201533, "phrase": "original_bootstrap_procedure"}, {"score": 0.0032054891061528896, "phrase": "original_sample"}, {"score": 0.0027741761880779535, "phrase": "variance_reduction"}, {"score": 0.0025638362414466278, "phrase": "weighted_bootstrap"}, {"score": 0.0023079225317714815, "phrase": "experimental_results"}], "paper_keywords": ["Bayesian bootstrap", " Bayesian bootstrap clones", " bootstrap", " model selection", " weighted bootstrap"], "paper_abstract": "This article proposes a weighted bootstrap procedure, which is an efficient bootstrap technique for neural model selection. Our primary interest in reducing computer effort is to not resample (in the original bootstrap procedure) uniformly from the original sample, but to modify this distribution in order to obtain variance reduction. The performance of the weighted bootstrap is demonstrated on two artificial data sets and one real dataset. Experimental results show that the weighted bootstrap procedure permits an approximately 2 to 1 reduction in replication size.", "paper_title": "Weighted bootstrap for neural model selection", "paper_id": "WOS:000254070200010"}