{"auto_keywords": [{"score": 0.036425876030641534, "phrase": "regression_model"}, {"score": 0.0344403458220785, "phrase": "measured_samples"}, {"score": 0.03005907338620277, "phrase": "laplacian"}, {"score": 0.02805417793273087, "phrase": "data_space"}, {"score": 0.00481495049065317, "phrase": "regularized_d-optimal_design"}, {"score": 0.004677711903652145, "phrase": "image_retrieval"}, {"score": 0.004620093797504386, "phrase": "increasingly_many_cases"}, {"score": 0.0045443671106012405, "phrase": "computer_vision"}, {"score": 0.004506968388996092, "phrase": "pattern_recognition"}, {"score": 0.004324521292490181, "phrase": "data_size"}, {"score": 0.0036352070472201086, "phrase": "training_samples"}, {"score": 0.003502382624110703, "phrase": "active_learning"}, {"score": 0.0033883824438527316, "phrase": "experimental_design"}, {"score": 0.003360464999544279, "phrase": "classical_optimal_experimental_design_approaches"}, {"score": 0.0033053159828082095, "phrase": "least_square_errors"}, {"score": 0.003132236287543072, "phrase": "unmeasured_samples"}, {"score": 0.002755104031926742, "phrase": "least_square_error"}, {"score": 0.002676418520290942, "phrase": "local_geometrical_structure"}, {"score": 0.0025892330566358503, "phrase": "nearest_neighbor_graph"}, {"score": 0.00255727386763536, "phrase": "geometrical_structure"}, {"score": 0.0023540387251475615, "phrase": "optimal_experimental_design"}, {"score": 0.0022492129111567824, "phrase": "data_points"}, {"score": 0.0021049977753042253, "phrase": "conventional_algorithms"}], "paper_keywords": ["Active learning", " experimental design", " image retrieval", " regularization"], "paper_abstract": "In increasingly many cases of interest in computer vision and pattern recognition, one is often confronted with the situation where data size is very large. Usually, the labels are expensive and the challenge is, thus, to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples. Particularly, we consider the problem of active learning of a regression model in the context of experimental design. Classical optimal experimental design approaches are based on least square errors over the measured samples only. They fail to take into account the unmeasured samples. In this paper, we propose a novel active learning algorithm which operates over graphs. Our algorithm is based on a graph Laplacian regularized regression model which simultaneously minimizes the least square error on the measured samples and preserves the local geometrical structure of the data space. By constructing a nearest neighbor graph, the geometrical structure of the data space can be described by the graph Laplacian. We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of data points, which gives us the most amount of information. Experiments demonstrate its superior performance in comparison with conventional algorithms.", "paper_title": "Laplacian Regularized D-Optimal Design for Active Learning and Its Application to Image Retrieval", "paper_id": "WOS:000272844000023"}