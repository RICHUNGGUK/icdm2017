{"auto_keywords": [{"score": 0.03867712206987222, "phrase": "optimal_approach"}, {"score": 0.013971190144861659, "phrase": "temporal_boundaries"}, {"score": 0.01386520818645132, "phrase": "video_key_frames"}, {"score": 0.007968441784905116, "phrase": "computational_cost"}, {"score": 0.00481495049065317, "phrase": "temporal_sampling"}, {"score": 0.004778088905211055, "phrase": "video_sequences"}, {"score": 0.0047415081747150065, "phrase": "video_key_frame_extraction"}, {"score": 0.004357061494162031, "phrase": "ubiquitous_media_access"}, {"score": 0.004323690117778359, "phrase": "video_streaming"}, {"score": 0.004160612392068268, "phrase": "visual_content"}, {"score": 0.004003660777805554, "phrase": "temporal_video_sampling"}, {"score": 0.003957735532719663, "phrase": "unified_process"}, {"score": 0.003764713814123286, "phrase": "optimization_problem"}, {"score": 0.003636605792981828, "phrase": "temporal_video_sampling_error"}, {"score": 0.0035948757703015287, "phrase": "dynamic_programming_process"}, {"score": 0.003512841739654183, "phrase": "key_frame_hierarchy"}, {"score": 0.0032777653153451265, "phrase": "computational_complexity"}, {"score": 0.003202944392720772, "phrase": "suboptimal_greedy_algorithm"}, {"score": 0.003154012038613403, "phrase": "data_structure"}, {"score": 0.0031178024467857215, "phrase": "binary_heap"}, {"score": 0.003070166825722112, "phrase": "novel_\"look-ahead\"_computational_technique"}, {"score": 0.0029203055813347874, "phrase": "average-case_computational_time"}, {"score": 0.002842655426951218, "phrase": "memory_usage"}, {"score": 0.0027143009946473937, "phrase": "greedy_methods"}, {"score": 0.0026218430041123164, "phrase": "threshold-selection_problem"}, {"score": 0.002522791642460087, "phrase": "proposed_optimal_and_greedy_methods"}, {"score": 0.002446245096967702, "phrase": "video_sampling_error"}, {"score": 0.002344762593995099, "phrase": "eight_videos"}, {"score": 0.002326767693352058, "phrase": "different_genres"}, {"score": 0.0022911901892022847, "phrase": "greedy_approach"}, {"score": 0.002121281184742656, "phrase": "long_video_sequences"}, {"score": 0.0021049977753042253, "phrase": "large_video_databases"}], "paper_keywords": ["algorithms", " video summarization", " key frame selection", " video content analysis", " ubiquitous media access", " temporal video sampling"], "paper_abstract": "Video key frame extraction is one of the most important research problems for video summarization, indexing, and retrieval. For a variety of applications such as ubiquitous media access and video streaming, the temporal boundaries between video key frames are required for synchronizing visual content with audio. In this article, we define temporal video sampling as a unified process of extracting video key frames and computing their temporal boundaries, and formulate it as an optimization problem. We first provide an optimal approach that minimizes temporal video sampling error using a dynamic programming process. The optimal approach retrieves a key frame hierarchy and all temporal boundaries in 0(n(4)) time and O(n(2)) space. To further reduce computational complexity, we also provide a suboptimal greedy algorithm that exploits the data structure of a binary heap and uses a novel \"look-ahead\" computational technique, enabling all levels of key frames to be extracted with an average-case computational time of O(n log n) and memory usage of 0 (n). Both the optimal and the greedy methods are free of parameters, thus avoiding the threshold-selection problem that exists in other approaches. We empirically compare the proposed optimal and greedy methods with several existing methods in terms of video sampling error, computational cost, and subjective quality. An evaluation of eight videos of different genres shows that the greedy approach achieves performance very close to that of the optimal approach while drastically reducing computational cost, making it suitable for processing long video sequences in large video databases.", "paper_title": "Computational approaches to temporal sampling of video sequences", "paper_id": "WOS:000250871600001"}