{"auto_keywords": [{"score": 0.03843856552198327, "phrase": "iterative_q_function"}, {"score": 0.011695758068235168, "phrase": "optimal_q_function"}, {"score": 0.00481495049065317, "phrase": "discrete-time_nonlinear_systems"}, {"score": 0.0046253989970108985, "phrase": "novel_iterative_q-learning_algorithm"}, {"score": 0.004147523799581407, "phrase": "optimal_control_problems"}, {"score": 0.0041001740903338834, "phrase": "discrete-time_deterministic_nonlinear_systems"}, {"score": 0.003916098498242888, "phrase": "iterative_adaptive_dynamic_programming"}, {"score": 0.0038713894780850397, "phrase": "adp"}, {"score": 0.0037402558657576124, "phrase": "iterative_control_law"}, {"score": 0.003471135453226184, "phrase": "optimal_control_law"}, {"score": 0.0032398798149196432, "phrase": "mathematical_model"}, {"score": 0.003094306770612843, "phrase": "convergence_property"}, {"score": 0.002758273619951683, "phrase": "optimality_equation"}, {"score": 0.0026041635822373265, "phrase": "iterative_control_laws"}, {"score": 0.0025596276616952516, "phrase": "stable_control_law"}, {"score": 0.002530359917257626, "phrase": "neural_networks"}, {"score": 0.002444544487772349, "phrase": "policy_iteration"}, {"score": 0.0024305268807926056, "phrase": "based_deterministic_q-learning_algorithm"}, {"score": 0.0021049977753042253, "phrase": "developed_algorithm"}], "paper_keywords": ["adaptive critic designs", " adaptive dynamic programming", " approximate dynamic programming", " Q-learning", " policy iteration", " neural networks", " nonlinear systems", " optimal control"], "paper_abstract": "In this paper, a novel iterative Q-learning algorithm, called \"policy iteration based deterministic Q-learning algorithm\", is developed to solve the optimal control problems for discrete-time deterministic nonlinear systems. The idea is to use an iterative adaptive dynamic programming (ADP) technique to construct the iterative control law which optimizes the iterative Q function. When the optimal Q function is obtained, the optimal control law can be achieved by directly minimizing the optimal Q function, where the mathematical model of the system is not necessary. Convergence property is analyzed to show that the iterative Q function is monotonically non-increasing and converges to the solution of the optimality equation. It is also proven that any of the iterative control laws is a stable control law. Neural networks are employed to implement the policy iteration based deterministic Q-learning algorithm, by approximating the iterative Q function and the iterative control law, respectively. Finally, two simulation examples are presented to illustrate the performance of the developed algorithm.", "paper_title": "A novel policy iteration based deterministic Q-learning for discrete-time nonlinear systems", "paper_id": "WOS:000368790400015"}