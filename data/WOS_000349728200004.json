{"auto_keywords": [{"score": 0.042273723455691345, "phrase": "original_data"}, {"score": 0.014624056864324159, "phrase": "input_dimensions"}, {"score": 0.012226764782578918, "phrase": "covariance_matrices"}, {"score": 0.011114229547098526, "phrase": "training_instances"}, {"score": 0.00481495049065317, "phrase": "regression_problems"}, {"score": 0.004580314008293946, "phrase": "processing_inefficiency"}, {"score": 0.00451043437607004, "phrase": "large_number"}, {"score": 0.004081385289516914, "phrase": "generalization_capability"}, {"score": 0.0036646935906338414, "phrase": "inefficient_reduction_process"}, {"score": 0.003512841739654183, "phrase": "machine_learning_based_dimensionality_reduction_approach"}, {"score": 0.002427473263013356, "phrase": "extracted_features"}, {"score": 0.0022302306304023602, "phrase": "real-world_data_sets"}, {"score": 0.002154226045704907, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Machine learning", " Feature clustering", " Feature extraction", " Correlation coefficient", " Mutual information"], "paper_abstract": "One of the issues encountered in classification and regression is the processing inefficiency caused by a large number of input dimensions involved in the given training data set. Many dimensionality reduction approaches have been proposed to address this issue by reducing the number of input dimensions and maintaining the generalization capability of the original data set. However, less attention has been paid to regression than to classification. Besides, the computation with covariance matrices involved results in an inefficient reduction process in most existing methods. In this paper, we propose a machine learning based dimensionality reduction approach for regression problems. For a given set of training instances, a group of clusters are formed such that the instances included in the same cluster are similar to each other. Then one new feature is extracted from each cluster through a certain weighted combination of the training instances. Consequently, the dimensionality of the original data set is reduced. The clusters are created incrementally and automatically without the need of specifying the number of clusters in advance by the user. The characteristics of the original data set are substantially retained since all the original features are involved in the derivation of the extracted features. Also, the computation with covariance matrices is avoided, and thus efficiency is maintained. A number of experiments on real-world data sets are conducted to demonstrate the effectiveness of the proposed approach. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Dimensionality reduction by feature clustering for regression problems", "paper_id": "WOS:000349728200004"}