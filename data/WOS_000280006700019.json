{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "principal_direction_divisive_clustering"}, {"score": 0.004737579882204798, "phrase": "data_clustering"}, {"score": 0.004661446705304497, "phrase": "long_history"}, {"score": 0.004586531354697466, "phrase": "large_amount"}, {"score": 0.004345363360869553, "phrase": "numerous_clustering_techniques"}, {"score": 0.004298666679374568, "phrase": "significant_challenges"}, {"score": 0.003985487777785535, "phrase": "high_data_dimensionality"}, {"score": 0.003921393143378986, "phrase": "particular_class"}, {"score": 0.00355782527287734, "phrase": "principal_component_analysis"}, {"score": 0.0030250067691601967, "phrase": "true_clusters"}, {"score": 0.0028502479839354637, "phrase": "principal_components"}, {"score": 0.0027295084882654917, "phrase": "appropriate_criteria"}, {"score": 0.0026423134393535243, "phrase": "hierarchical_divisive_clustering"}, {"score": 0.0025440911575156755, "phrase": "new_algorithms"}, {"score": 0.0025031188149336257, "phrase": "proposed_algorithms"}, {"score": 0.0024761702541879213, "phrase": "minimal_user-defined_parameters"}, {"score": 0.0024231382864800173, "phrase": "desirable_feature"}, {"score": 0.002198173002125907, "phrase": "experimental_results"}, {"score": 0.0021510820434023207, "phrase": "proposed_techniques"}, {"score": 0.0021049977753042253, "phrase": "simulated_as_well_as_real_data_scenarios"}], "paper_keywords": ["Clustering", " Principal component analysis", " Kernel density estimation"], "paper_abstract": "While data clustering has a long history and a large amount of research has been devoted to the development of numerous clustering techniques, significant challenges still remain. One of the most important of them is associated with high data dimensionality. A particular class of clustering algorithms has been very successful in dealing with such datasets, utilising information driven by the principal component analysis. In this work, we try to deepen our understanding on what can be achieved by this kind of approaches. We attempt to theoretically discover the relationship between true clusters in the data and the distribution of their projection onto the principal components. Based on such findings, we propose appropriate criteria for the various steps involved in hierarchical divisive clustering and develop compilations of them into new algorithms. The proposed algorithms require minimal user-defined parameters and have the desirable feature of being able to provide approximations for the number of clusters present in the data. The experimental results indicate that the proposed techniques are effective in simulated as well as real data scenarios. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Enhancing principal direction divisive clustering", "paper_id": "WOS:000280006700019"}