{"auto_keywords": [{"score": 0.03843856552198327, "phrase": "hi-c_data"}, {"score": 0.00481495049065317, "phrase": "normalizing_large-scale"}, {"score": 0.004347984654755786, "phrase": "tcc"}, {"score": 0.004238452771031322, "phrase": "important_tools"}, {"score": 0.004174064076143015, "phrase": "spatial_genome_organization"}, {"score": 0.004068907083697369, "phrase": "chromatin_contact_matrices"}, {"score": 0.003946195919158241, "phrase": "critical_preprocessing_step"}, {"score": 0.003906116922372891, "phrase": "subsequent_analyses"}, {"score": 0.0038467574225322086, "phrase": "continuing_decline"}, {"score": 0.003807684498435389, "phrase": "sequencing_costs"}, {"score": 0.003711723285313348, "phrase": "ever-improving_resolution"}, {"score": 0.003545024951402821, "phrase": "chromatin_contacts"}, {"score": 0.003403122817578447, "phrase": "great_challenge"}, {"score": 0.003351381374975648, "phrase": "memory_usage"}, {"score": 0.0031682817605340028, "phrase": "urgent_need"}, {"score": 0.0031360786664165093, "phrase": "fast_and_memory-efficient_methods"}, {"score": 0.0028026735035370206, "phrase": "hi-c_data_normalization_algorithm"}, {"score": 0.0025826247025542213, "phrase": "normalizing_hi-c_data"}, {"score": 0.0025174594088331853, "phrase": "reasonable_times"}, {"score": 0.00240426758768164, "phrase": "sequential_version"}, {"score": 0.0023435920614377306, "phrase": "single_computer"}, {"score": 0.002126635713519053, "phrase": "multiple_computing_nodes"}, {"score": 0.0021049977753042253, "phrase": "limited_local_memory"}], "paper_keywords": [""], "paper_abstract": "Genome-wide proximity ligation assays, e.g. Hi-C and its variant TCC, have recently become important tools to study spatial genome organization. Removing biases from chromatin contact matrices generated by such techniques is a critical preprocessing step of subsequent analyses. The continuing decline of sequencing costs has led to an ever-improving resolution of the Hi-C data, resulting in very large matrices of chromatin contacts. Such large-size matrices, however, pose a great challenge on the memory usage and speed of its normalization. Therefore, there is an urgent need for fast and memory-efficient methods for normalization of Hi-C data. We developed Hi-Corrector, an easy-to-use, open source implementation of the Hi-C data normalization algorithm. Its salient features are (i) scalability-the software is capable of normalizing Hi-C data of any size in reasonable times; (ii) memory efficiency-the sequential version can run on any single computer with very limited memory, no matter how little; (iii) fast speed-the parallel version can run very fast on multiple computing nodes with limited local memory.", "paper_title": "Hi-Corrector: a fast, scalable and memory-efficient package for normalizing large-scale Hi-C data", "paper_id": "WOS:000352268900022"}