{"auto_keywords": [{"score": 0.04051211375775462, "phrase": "proposed_neural_network"}, {"score": 0.00481495049065317, "phrase": "pseudoconvex_optimization"}, {"score": 0.004545240514015278, "phrase": "one-layer_recurrent_neural_network"}, {"score": 0.004416079619543104, "phrase": "nonlinear_nonsmooth_pseudoconvex_optimization_problem"}, {"score": 0.00429057323623293, "phrase": "linear_equality_constraints"}, {"score": 0.004011366422179016, "phrase": "equilibrium_point"}, {"score": 0.0036788184374592706, "phrase": "optimal_solution"}, {"score": 0.0035741900278634616, "phrase": "original_optimization_problem"}, {"score": 0.0034063576796640603, "phrase": "objective_function"}, {"score": 0.002783239797148134, "phrase": "lyapunov"}, {"score": 0.002601727192945944, "phrase": "exact_optimal_solution"}, {"score": 0.002527654365712841, "phrase": "original_optimization"}, {"score": 0.00236289633510808, "phrase": "illustrative_examples"}], "paper_keywords": ["One-layer recurrent neural network", " Nonsmooth pseudoconvex optimization problem"], "paper_abstract": "This paper proposes a one-layer recurrent neural network for solving nonlinear nonsmooth pseudoconvex optimization problem subject to linear equality constraints. We first prove that the equilibrium point set of the proposed neural network is equivalent to the optimal solution of the original optimization problem, even though the objective function is pseudoconvex. Then, it is proved that the state of the proposed neural network is stable in the sense of Lyapunov, and globally convergent to an exact optimal solution of the original optimization. In the end, some illustrative examples are given to demonstrate the effectiveness of the proposed neural network. (c) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A new one-layer recurrent neural network for nonsmooth pseudoconvex optimization", "paper_id": "WOS:000324847100069"}