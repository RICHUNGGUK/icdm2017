{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "wearable_device"}, {"score": 0.004765482708043842, "phrase": "reading_positive_expressions"}, {"score": 0.004716520738331953, "phrase": "facial_emg_signals"}, {"score": 0.0043875257506180865, "phrase": "positive_facial_expressions"}, {"score": 0.004342430078306461, "phrase": "physiological_signals"}, {"score": 0.004231699728933577, "phrase": "facial_morphology"}, {"score": 0.004145143433523008, "phrase": "facial_electromyographic_signals"}, {"score": 0.004102528738941734, "phrase": "different_facial_locations"}, {"score": 0.003956784357357341, "phrase": "electromyographic_signals"}, {"score": 0.003916098498242888, "phrase": "high_amplitude"}, {"score": 0.003835972725191194, "phrase": "low_facial_mobility"}, {"score": 0.003513264130359459, "phrase": "traditional_surface"}, {"score": 0.0033883824438527316, "phrase": "facial_muscles"}, {"score": 0.003201018846103988, "phrase": "multi-attribute_decision-making_method"}, {"score": 0.0027982016314450717, "phrase": "ergonomic_wearable_device"}, {"score": 0.002769395841379498, "phrase": "high_reliability"}, {"score": 0.0026297428083782875, "phrase": "proposed_device"}, {"score": 0.0026026666736474404, "phrase": "independent_component_analysis"}, {"score": 0.0025625729433234644, "phrase": "artificial_neural_network"}, {"score": 0.002471400498582011, "phrase": "high_facial_expression_recognition_rate"}, {"score": 0.002358917661465133, "phrase": "recognized_emotional_facial_expressions"}, {"score": 0.0023225701080913388, "phrase": "wearable_interface_device"}, {"score": 0.00226322835801988, "phrase": "therapeutic_interventions"}, {"score": 0.0022283519468680475, "phrase": "long-term_facial_expression_recognition"}, {"score": 0.0021601997088758957, "phrase": "user's_affective_state"}, {"score": 0.0021049977753042253, "phrase": "medical_professionals"}], "paper_keywords": ["Electromyography", " face and gesture recognition", " pattern recognition", " wearable interface"], "paper_abstract": "In this paper we present the design of a wearable device that reads positive facial expressions using physiological signals. We first analyze facial morphology in 3 dimensions and facial electromyographic signals on different facial locations and show that we can detect electromyographic signals with high amplitude on areas of low facial mobility on the side of the face, which are correlated to ones obtained from electrodes on traditional surface electromyographic capturing positions on top of facial muscles on the front of the face. We use a multi-attribute decision-making method to find adequate electrode positions on the side of face to capture these signals. Based on this analysis, we design and implement an ergonomic wearable device with high reliability. Because the signals are recorded distally, the proposed device uses independent component analysis and an artificial neural network to analyze them and achieve a high facial expression recognition rate on the side of the face. The recognized emotional facial expressions through the wearable interface device can be recorded during therapeutic interventions and for long-term facial expression recognition to quantify and infer the user's affective state in order to support medical professionals.", "paper_title": "Design of a Wearable Device for Reading Positive Expressions from Facial EMG Signals", "paper_id": "WOS:000344589600004"}