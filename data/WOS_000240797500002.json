{"auto_keywords": [{"score": 0.034582024677350484, "phrase": "mmhc"}, {"score": 0.004816265469056722, "phrase": "bayesian"}, {"score": 0.004515967518891287, "phrase": "new_algorithm"}, {"score": 0.004452078350485375, "phrase": "bayesian_network_structure_learning"}, {"score": 0.004357927940322685, "phrase": "max-min_hill-climbing"}, {"score": 0.004058180509184539, "phrase": "local_learning"}, {"score": 0.0035949949979695063, "phrase": "bayesian_network"}, {"score": 0.0034690732089830045, "phrase": "bayesian-scoring_greedy_hill-climbing_search"}, {"score": 0.0027610089418453614, "phrase": "sparse_candidate"}, {"score": 0.002683304054823427, "phrase": "optimal_reinsertion"}, {"score": 0.0026452734009203764, "phrase": "greedy_equivalence_search"}, {"score": 0.0025892330566358503, "phrase": "greedy_search"}, {"score": 0.0024984517279573906, "phrase": "first_empirical_results"}, {"score": 0.0023936956017015696, "phrase": "major_bayesian_network_algorithms"}, {"score": 0.0021971473452127126, "phrase": "sparse_candidate_algorithm"}, {"score": 0.0021049977753042253, "phrase": "mmhc_and_detailed_results"}], "paper_keywords": ["Bayesian networks", " graphical models", " structure learning"], "paper_abstract": "We present a new algorithm for Bayesian network structure learning, called Max-Min Hill-Climbing (MMHC). The algorithm combines ideas from local learning, constraint-based, and search-and-score techniques in a principled and effective way. It first reconstructs the skeleton of a Bayesian network and then performs a Bayesian-scoring greedy hill-climbing search to orient the edges. In our extensive empirical evaluation MMHC outperforms on average and in terms of various metrics several prototypical and state-of-the-art algorithms, namely the PC, Sparse Candidate, Three Phase Dependency Analysis, Optimal Reinsertion, Greedy Equivalence Search, and Greedy Search. These are the first empirical results simultaneously comparing most of the major Bayesian network algorithms against each other. MMHC offers certain theoretical advantages, specifically over the Sparse Candidate algorithm, corroborated by our experiments. MMHC and detailed results of our study are publicly available at http://www.dsl-lab.org/supplements/mmhc_paper/mmhc_index.html.", "paper_title": "The max-min hill-climbing Bayesian network structure learning algorithm", "paper_id": "WOS:000240797500002"}