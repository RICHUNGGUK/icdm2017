{"auto_keywords": [{"score": 0.039154551865160495, "phrase": "hir_task"}, {"score": 0.00481495049065317, "phrase": "stip-based_models"}, {"score": 0.004766487181100495, "phrase": "human_interactions"}, {"score": 0.004734448316824488, "phrase": "tv_videos"}, {"score": 0.0047026237903774895, "phrase": "human_motion_recognition_-_action"}, {"score": 0.004671014956926119, "phrase": "har"}, {"score": 0.004531357177195719, "phrase": "real_video_data"}, {"score": 0.0043663006236597975, "phrase": "increasing_complexity"}, {"score": 0.003529984775927307, "phrase": "stip-based_features"}, {"score": 0.003506322395714961, "phrase": "bow"}, {"score": 0.003299460925313939, "phrase": "alternative_representation_models"}, {"score": 0.0032442139425705578, "phrase": "comprehensive_experimental_study"}, {"score": 0.0030220695120265974, "phrase": "recent_results"}, {"score": 0.0029118285733827406, "phrase": "cross-data_experiments"}, {"score": 0.002777302487818768, "phrase": "trained_models"}, {"score": 0.002758597251689795, "phrase": "different_datasets"}, {"score": 0.002450864311898833, "phrase": "compression_algorithms"}, {"score": 0.0024343522820859578, "phrase": "large_enough_initial_set"}, {"score": 0.0022829196538545885, "phrase": "stip"}, {"score": 0.002259883463607508, "phrase": "best_choice"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Human interaction", " TV video", " STIP", " BOW"], "paper_abstract": "Human motion recognition - action (HAR) or interaction (HIR) - in real video data is identified as a very challenging task. In the last few years models of increasing complexity have been proposed in order to improve the performance in the task. However, it still remains unclear whether it is the features or the models what deserves the increase in complexity. In this paper an evaluation of such problem is carried out in the HIR task. For that purpose, we compare the results obtained in our experiments - by using STIP-based features and BOW models as basis and combined with a standard classifier - with some of the more effective and recent approaches that use alternative representation models. We perform a comprehensive experimental study on two state-of-the-art databases in HIR: TV Human interactions and UT-interactions. We compare the results of our experiments with recent results published on these datasets. In addition, we run cross-data experiments on Hollywood-2 dataset in order to study the capability of generalization of the trained models through different datasets. The most relevant result is that the model combining STIP + BOW is competitive in the HIR task in comparison with the most complex ones. It is also shown that the vocabulary learning subtask can be improved by using compression algorithms on large enough initial set of features. In contrast to other categorization tasks the context does not help, the results show that dense sampling of STIP is the best choice, but only when it is used inside the region of interest of the interaction. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Exploring STIP-based models for recognizing human interactions in TV videos", "paper_id": "WOS:000324510900007"}