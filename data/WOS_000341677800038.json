{"auto_keywords": [{"score": 0.04249946592512057, "phrase": "tr-fsda"}, {"score": 0.034131792030379846, "phrase": "orthogonal_projection"}, {"score": 0.00481495049065317, "phrase": "dimension_reduction"}, {"score": 0.004773904938276846, "phrase": "image_classification"}, {"score": 0.004593467306126913, "phrase": "novel_orthogonal_manifold_learning_algorithm"}, {"score": 0.004419819325202464, "phrase": "flexible_orthogonal_semisupervised_dimension_reduction"}, {"score": 0.004234532601573088, "phrase": "recently-developed_algorithm"}, {"score": 0.00418046991987597, "phrase": "trace_ratio_based_flexible_semisupervised_discriminant_analysis"}, {"score": 0.004144989780570008, "phrase": "tr"}, {"score": 0.004005176784823524, "phrase": "orthogonality_constraint"}, {"score": 0.003954030683259778, "phrase": "flexible_regularizer"}, {"score": 0.0038702288460744274, "phrase": "semisupervised_discriminant_analysis"}, {"score": 0.0038372227350214417, "phrase": "sda"}, {"score": 0.0037719988989298983, "phrase": "low-dimensional_representation"}, {"score": 0.0036605323485683983, "phrase": "linear_subspace"}, {"score": 0.0034919649825540396, "phrase": "trace_ratio_problem"}, {"score": 0.002954287204671032, "phrase": "orthogonal_projection_vector"}, {"score": 0.0029165216647792924, "phrase": "one-dimensional_data_representation"}, {"score": 0.002842428606954139, "phrase": "standard_rayleigh_quotient_problem"}, {"score": 0.0027230880516264685, "phrase": "new_orthogonal_projection_vector"}, {"score": 0.0026312238938540787, "phrase": "specific_statistical_property"}, {"score": 0.002597577409911978, "phrase": "previously-obtained_orthogonal_projection_vectors"}, {"score": 0.0023534849686145, "phrase": "umist"}, {"score": 0.0023333808834242772, "phrase": "orl"}, {"score": 0.002313441589567359, "phrase": "yale"}, {"score": 0.0022740654470759783, "phrase": "feret"}, {"score": 0.002244969789802093, "phrase": "handwritten_digit"}, {"score": 0.0021599099979586946, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Manifold learning", " Orthogonal semisupervised", " dimension reduction", " Orthogonal projection vectors"], "paper_abstract": "In this paper, we propose a novel orthogonal manifold learning algorithm for semisupervised dimension reduction, referred to as Flexible Orthogonal Semisupervised Dimension Reduction (FODR). Our algorithm is based on the recently-developed algorithm, called Trace Ratio Based Flexible Semisupervised Discriminant Analysis (TR-FSDA). TR-FSDA introduces an orthogonality constraint and a flexible regularizer to relax such a hard linear constraint in Semisupervised Discriminant Analysis (SDA) that the low-dimensional representation is constrained to lie within the linear subspace spanned by the data, whose solution follows from solving a trace ratio problem iteratively. However, it is not guaranteed that TR-FSDA always converges. Instead of finding the orthogonal projection vectors once, our algorithm produces the orthogonal projection vectors, step by step. In each time of iterations, an orthogonal projection vector and a one-dimensional data representation are produced by solving a standard Rayleigh Quotient problem, and more importantly, the determination of a new orthogonal projection vector does not involve the knowledge of the specific statistical property for the previously-obtained orthogonal projection vectors. Therefore, it is not necessary for our FODR algorithm to guarantee the convergence. The experiments are tried out on COIL20, UMIST, ORL, YALE, MPEG-7, FERET, and Handwritten DIGIT databases, and show the effectiveness of the proposed algorithm. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Flexible orthogonal semisupervised learning for dimension reduction with image classification", "paper_id": "WOS:000341677800038"}