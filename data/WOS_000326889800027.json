{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "d-optimal_design"}, {"score": 0.0481268248059887, "phrase": "terrain_classification"}, {"score": 0.004149922666541166, "phrase": "large_amount"}, {"score": 0.004100851549096203, "phrase": "unlabeled_data"}, {"score": 0.003980687255880282, "phrase": "labeling_cost"}, {"score": 0.003619235073669304, "phrase": "unlabeled_samples"}, {"score": 0.0033898953358387075, "phrase": "classical_optimal_experimental_design_algorithms"}, {"score": 0.0033101397746161843, "phrase": "least-square_errors"}, {"score": 0.003251552926963083, "phrase": "labeled_samples"}, {"score": 0.0031750418391373035, "phrase": "unlabeled_points"}, {"score": 0.0029737652463012318, "phrase": "novel_active_learning_algorithm"}, {"score": 0.002768674345336861, "phrase": "neighborhood_preserving_regression_model"}, {"score": 0.0026874405408023956, "phrase": "least-square_error"}, {"score": 0.002639845784408318, "phrase": "measured_samples"}, {"score": 0.0025776913268808124, "phrase": "neighborhood_structure"}, {"score": 0.002532035301903554, "phrase": "data_space"}, {"score": 0.002357337046408753, "phrase": "regression_parameter"}, {"score": 0.0022610379771517966, "phrase": "nonlinear_case"}, {"score": 0.0022209780222461587, "phrase": "kernel_trick"}, {"score": 0.0021946656099592608, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Active learning", " Terrain classification", " Optimal experimental design (OED)", " Neighborhood preserving"], "paper_abstract": "In many real-world applications, labeled data are usually expensive to get, while there may be a large amount of unlabeled data. To reduce the labeling cost, active learning attempts to discover the most informative data points for labeling. The challenge is which unlabeled samples should be labeled to improve the classifier the most. Classical optimal experimental design algorithms are based on least-square errors over the labeled samples only while the unlabeled points are ignored. In this paper, we propose a novel active learning algorithm called neighborhood preserving D-optimal design. Our algorithm is based on a neighborhood preserving regression model which simultaneously minimizes the least-square error on the measured samples and preserves the neighborhood structure of the data space. It selects the most informative samples which minimize the variance of the regression parameter. We also extend our algorithm to nonlinear case by using kernel trick. Experimental results on terrain classification show the effectiveness of proposed approach.", "paper_title": "Neighborhood preserving D-optimal design for active learning and its application to terrain classification", "paper_id": "WOS:000326889800027"}