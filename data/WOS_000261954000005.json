{"auto_keywords": [{"score": 0.0475616067568024, "phrase": "knowledge_base"}, {"score": 0.00481495049065317, "phrase": "linguistic_fuzzy_rule-based_regression_models"}, {"score": 0.004734448316824488, "phrase": "multiobjective_genetic_algorithms"}, {"score": 0.004671012181488876, "phrase": "fuzzy_rules"}, {"score": 0.004623990904432388, "phrase": "iterative_rule_learning_technique"}, {"score": 0.0045160988337296605, "phrase": "fuzzy_rule-based_system"}, {"score": 0.004264395507931215, "phrase": "whole_training"}, {"score": 0.004122911675081472, "phrase": "obtained_rule"}, {"score": 0.003700833742881285, "phrase": "observation_error"}, {"score": 0.0032883370175509053, "phrase": "new_rule"}, {"score": 0.002740017649875685, "phrase": "high_discrepancies"}, {"score": 0.002685024286204448, "phrase": "actual_values"}, {"score": 0.0026045914281028473, "phrase": "missing_values"}, {"score": 0.00257831812581194, "phrase": "discretized_data"}, {"score": 0.0024926348205500715, "phrase": "iterative_learning"}, {"score": 0.002385479082527538, "phrase": "full_use"}, {"score": 0.0021049977753042253, "phrase": "maximum_coverage"}], "paper_keywords": [""], "paper_abstract": "Backfitting of fuzzy rules is an Iterative Rule Learning technique for obtaining the knowledge base of a fuzzy rule-based system in regression problems. It consists in fitting one fuzzy rule to the data, and replacing the whole training set by the residual of the approximation. The obtained rule is added to the knowledge base, and the process is repeated until the residual is zero, or near zero. Such a design has been extended to imprecise data for which the observation error is small. Nevertheless, when this error is moderate or high, the learning can stop early. In this kind of algorithms, the specificity of the residual might decrease when a new rule is added. There may happen that the residual grows so wide that it covers the value zero for all points (thus the algorithm stops), but we have not yet extracted all the information available in the dataset. Focusing on this problem, this paper is about datasets with medium to high discrepancies between the observed and the actual values of the variables, such as those containing missing values and coarsely discretized data. We will show that the quality of the iterative learning degrades in this kind of problems, because it does not make full use of all the available information. As an alternative to sequentially obtaining rules, we propose a new multiobjective Genetic Cooperative Competitive Learning (GCCL) algorithm. In our approach, each individual in the population codifies one rule, which competes in the population in terms of maximum coverage and fitting, while the individuals in the population cooperate to form the knowledge base.", "paper_title": "Obtaining linguistic fuzzy rule-based regression models from imprecise data with multiobjective genetic algorithms", "paper_id": "WOS:000261954000005"}