{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "nearest_neighbors"}, {"score": 0.03816494122726076, "phrase": "k-nn_classifier"}, {"score": 0.004735519962945449, "phrase": "k-nn_classification_algorithm"}, {"score": 0.004683292152590589, "phrase": "k-nearest_neighbor"}, {"score": 0.004309434349688514, "phrase": "new_instance"}, {"score": 0.0038782499819752423, "phrase": "k_nearest_neighbors"}, {"score": 0.0037721073763702486, "phrase": "appropriate_number"}, {"score": 0.0034324073240680213, "phrase": "systematical_solution"}, {"score": 0.0033570147767493746, "phrase": "specific_value"}, {"score": 0.003123203316511694, "phrase": "novel_method"}, {"score": 0.0030715948036518603, "phrase": "back-propagation_neural_networks"}, {"score": 0.002970914475538276, "phrase": "data_set_characteristics"}, {"score": 0.002921815042028607, "phrase": "optimal_values"}, {"score": 0.0027333769432036905, "phrase": "new_data_set"}, {"score": 0.0025713100093065645, "phrase": "data_set"}, {"score": 0.0025287979714720423, "phrase": "experimental_results"}, {"score": 0.0024054226746197706, "phrase": "optimal_k_values"}, {"score": 0.002262756631083292, "phrase": "average_classification_accuracy"}, {"score": 0.00218853009252455, "phrase": "recommended_k_values"}, {"score": 0.0021049977753042253, "phrase": "k_values"}], "paper_keywords": ["k-NN classification algorithm", " k value prediction model", " data set characteristics", " back-propagation neural networks"], "paper_abstract": "k-Nearest Neighbor (k-NN) is one of the most widely used classification algorithms. When classifying a new instance, k-NN first finds out its k nearest neighbors, and then classifies it by voting for the categories of the k nearest neighbors. Therefore, an appropriate number of nearest neighbors is critical for the k-NN classifier. However, in present, there is no systematical solution to determine the specific value of k. In order to address this problem, we propose a novel method of using back-propagation neural networks to explore the relationship between data set characteristics and the optimal values of k, then the relationship and the data set characteristics of a new data set are used to recommend the value of k for this data set. The experimental results on the 49 UCI benchmark data sets show that compared with the optimal k values, although there is a decrease of 1.61% in the average classification accuracy for the k-NN classifier with the recommended k values, the time for determining the k values is greatly shortened.", "paper_title": "Predicting the number of nearest neighbors for the k-NN classification algorithm", "paper_id": "WOS:000336086200008"}