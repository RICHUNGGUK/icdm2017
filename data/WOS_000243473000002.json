{"auto_keywords": [{"score": 0.04051211375775462, "phrase": "oscillatory_gestures"}, {"score": 0.036241675507294666, "phrase": "hand_motion_trajectory_signals"}, {"score": 0.030926517488363503, "phrase": "frequency_properties"}, {"score": 0.00481495049065317, "phrase": "motion_oscillatory_gestures"}, {"score": 0.0047689174754929195, "phrase": "multimodal_discourse_analysis"}, {"score": 0.004567129988306349, "phrase": "single_human_language_system"}, {"score": 0.004480196733208298, "phrase": "coexpressive_and_complementary_channels"}, {"score": 0.0042495320879288615, "phrase": "major_load"}, {"score": 0.004208881856146758, "phrase": "symbolic_presentation"}, {"score": 0.004108942392772092, "phrase": "imagistic_content"}, {"score": 0.004011366422179016, "phrase": "established_cotemporality"}, {"score": 0.0038230844545071303, "phrase": "multimodal_discourse"}, {"score": 0.003696550794743764, "phrase": "hand_gestures"}, {"score": 0.003643607569483598, "phrase": "frequency_domain"}, {"score": 0.0035229930971258316, "phrase": "individual's_hands"}, {"score": 0.0033737457695128233, "phrase": "real_video_datasets"}, {"score": 0.003215295260684715, "phrase": "frequency_ridges"}, {"score": 0.003169222811082848, "phrase": "frequency-time_space"}, {"score": 0.003034916887102753, "phrase": "wavelet_analysis"}, {"score": 0.0029914213495838998, "phrase": "wavelet_ridges"}, {"score": 0.002864628676257225, "phrase": "hand_motion_oscillatory_gestures"}, {"score": 0.0025644240336018045, "phrase": "first_dataset"}, {"score": 0.0022409963215568565, "phrase": "gestural_oscillations"}, {"score": 0.0021049977753042253, "phrase": "discourse_structure"}], "paper_keywords": [""], "paper_abstract": "Gesture and speech are part of a single human language system. They are coexpressive and complementary channels in the act of speaking. Whereas speech carries the major load of symbolic presentation, gesture provides the imagistic content. Proceeding from the established cotemporality of gesture and speech, our work on oscillatory gestures and multimodal discourse is discussed. Our new techniques of analyzing hand gestures in the frequency domain are described. By tracking an individual's hands during a speech, hand motion trajectory signals are extracted from real video datasets. Our wavelet-based approach in gestural oscillation extraction is presented as frequency ridges in a frequency-time space. Wavelet ridges are extracted from responses of wavelet analysis. These wavelet ridges are employed to characterize frequency properties of hand motion trajectory signals. Hand motion oscillatory gestures can be extracted from these frequency properties. The potential of such computational cross-modal language analysis is motivated by performing a microanalysis of 2 video datasets. In the first dataset, a participant describes her living space to an interlocutor. In the second, a participant describes her action plan to an interlocutor. The ability of our algorithm to extract gestural oscillations is demonstrated, and the way that oscillatory gestures reveal portions of the discourse structure is shown.", "paper_title": "Hand motion oscillatory gestures and multimodal discourse analysis", "paper_id": "WOS:000243473000002"}