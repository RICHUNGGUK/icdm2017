{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "manifold_mapping_machine"}, {"score": 0.030529977007677515, "phrase": "kernel_classifiers"}, {"score": 0.004769444094319619, "phrase": "nonlinear_classification"}, {"score": 0.0046797114400479135, "phrase": "non-trivial_task"}, {"score": 0.004462663711734448, "phrase": "kernel_machines"}, {"score": 0.004255639740735269, "phrase": "nonlinear_ones"}, {"score": 0.004136044939878838, "phrase": "high_or_infinite_dimensional_feature_space"}, {"score": 0.00398177607914381, "phrase": "unobservable_latent_feature_space"}, {"score": 0.0038332390893263844, "phrase": "intuitive_understanding"}, {"score": 0.0036379729015583975, "phrase": "comprehensible_framework"}, {"score": 0.003603549914861701, "phrase": "nonlinear_classifier_design"}, {"score": 0.0034037221513153566, "phrase": "linear_classifier"}, {"score": 0.0032766780632972363, "phrase": "low-dimensional_feature_space"}, {"score": 0.0030656196752517836, "phrase": "algorithmic_implementation"}, {"score": 0.003007846011394511, "phrase": "supervised_spectral_space_classifier"}, {"score": 0.0028006988338192375, "phrase": "similar_or_even_better_data_separation"}, {"score": 0.0027218799769229596, "phrase": "low-dimensional_spectral_space"}, {"score": 0.002632716358833918, "phrase": "new_feature_space"}, {"score": 0.0025103699913760057, "phrase": "discriminative_information"}, {"score": 0.0024630345285372958, "phrase": "spectral_space_transformation"}, {"score": 0.0022715929119140194, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Nonlinear classifier", " Manifold mapping", " Spectral space"], "paper_abstract": "Nonlinear classification has been a non-trivial task in machine learning for the past decades. In recent years, kernel machines have successfully generalized the inner-product based linear classifiers to nonlinear ones by transforming data into some high or infinite dimensional feature space. However, due to their implicit space transformation and unobservable latent feature space, it is hard to have an intuitive understanding of their working mechanism. In this paper, we propose a comprehensible framework for nonlinear classifier design, called Manifold Mapping Machine (M-3). M-3 can generalize any linear classifier to nonlinear by transforming data into some low-dimensional feature space explicitly. To demonstrate the effectiveness of M-3 framework, we further present an algorithmic implementation of M-3 named Supervised Spectral Space Classifier ((SC)-C-3). Compared with the kernel classifiers, (SC)-C-3 can achieve similar or even better data separation by mapping data into the low-dimensional spectral space, allowing both of its mapped data and new feature space to be examined directly. Moreover, with the discriminative information integrated into the spectral space transformation, the classification performance of (SC)-C-3 is more robust than that of the kernel classifiers. Experimental results show that (SC)-C-3 is superior to other state-of-the-art nonlinear classifiers on both synthetic and real-world data sets. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Manifold Mapping Machine", "paper_id": "WOS:000290078600017"}