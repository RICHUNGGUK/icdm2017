{"auto_keywords": [{"score": 0.049146612112995945, "phrase": "sobolev_spaces"}, {"score": 0.015719716506582538, "phrase": "svm_classifiers"}, {"score": 0.004494570360108983, "phrase": "statistical_performances"}, {"score": 0.004406994912939125, "phrase": "support_vector_machines"}, {"score": 0.003916098498242888, "phrase": "margin_parameter"}, {"score": 0.003445591238183763, "phrase": "tuning_parameter"}, {"score": 0.0028017384879042333, "phrase": "svm"}, {"score": 0.002640781900605126, "phrase": "numerically_realizable_aggregate"}, {"score": 0.0023694065215394593, "phrase": "practical_experiments"}, {"score": 0.0021049977753042253, "phrase": "gaussian_kernels"}], "paper_keywords": ["classification", " Support Vector Machines", " learning rates", " approximation", " aggregation of classifiers"], "paper_abstract": "This paper investigates statistical performances of Support Vector Machines (SVM) and considers the problem of adaptation to the margin parameter and to complexity. In particular we provide a classifier with no tuning parameter. It is a combination of SVM classifiers. Our contribution is two-fold: (1) we propose learning rates for SVM using Sobolev spaces and build a numerically realizable aggregate that converges with same rate; (2) we present practical experiments of this method of aggregation for SVM using both Sobolev spaces and Gaussian kernels.", "paper_title": "Aggregation of SVM classifiers using Sobolev spaces", "paper_id": "WOS:000258646800009"}