{"auto_keywords": [{"score": 0.047474187726966516, "phrase": "user-generated_content"}, {"score": 0.04551872326612427, "phrase": "rating_scores"}, {"score": 0.00481495049065317, "phrase": "online_collaborative_rating_systems"}, {"score": 0.004757643419056999, "phrase": "emerging_trend"}, {"score": 0.004719816332271661, "phrase": "social_information_processing"}, {"score": 0.004645057834614705, "phrase": "web_users"}, {"score": 0.004187049198138107, "phrase": "online_rating_systems"}, {"score": 0.004087910779160781, "phrase": "others'_opinions"}, {"score": 0.003684634192576662, "phrase": "overall_score"}, {"score": 0.0036262124965265015, "phrase": "object's_quality"}, {"score": 0.0035403060198952244, "phrase": "existing_approaches"}, {"score": 0.0033880439015902446, "phrase": "different_standards"}, {"score": 0.0030171910207671205, "phrase": "higher_scores"}, {"score": 0.0026022112631368223, "phrase": "rated_objects"}, {"score": 0.0025202582748972122, "phrase": "leniency-aware_quality"}, {"score": 0.0024901940672239784, "phrase": "lq_model"}, {"score": 0.0023357913211723884, "phrase": "ranked_solution"}, {"score": 0.0022712795176156536, "phrase": "real-life_and_synthetic_datasets"}, {"score": 0.0022442044308247197, "phrase": "lq"}, {"score": 0.002199725773957207, "phrase": "comparable_approaches"}, {"score": 0.0021049977753042253, "phrase": "different_parameter_settings"}], "paper_keywords": ["Algorithms", " Experimentation", " Human Factors", " Quality", " leniency", " rating", " link analysis", " social network mining"], "paper_abstract": "The emerging trend of social information processing has resulted in Web users' increased reliance on user-generated content contributed by others for information searching and decision making. Rating scores, a form of user-generated content contributed by reviewers in online rating systems, allow users to leverage others' opinions in the evaluation of objects. In this article, we focus on the problem of summarizing the rating scores given to an object into an overall score that reflects the object's quality. We observe that the existing approaches for summarizing scores largely ignores the effect of reviewers exercising different standards in assigning scores. Instead of treating all reviewers as equals, our approach models the leniency of reviewers, which refers to the tendency of a reviewer to assign higher scores than other coreviewers. Our approach is underlined by two insights: (1) The leniency of a reviewer depends not only on how the reviewer rates objects, but also on how other reviewers rate those objects and (2) The leniency of a reviewer and the quality of rated objects are mutually dependent. We develop the leniency-aware quality, or LQ model, which solves leniency and quality simultaneously. We introduce both an exact and a ranked solution to the model. Experiments on real-life and synthetic datasets show that LQ is more effective than comparable approaches. LQ is also shown to perform consistently better under different parameter settings.", "paper_title": "Quality and Leniency in Online Collaborative Rating Systems", "paper_id": "WOS:000302878600004"}