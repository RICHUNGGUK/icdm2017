{"auto_keywords": [{"score": 0.03132816988308867, "phrase": "classification_performance"}, {"score": 0.00481495049065317, "phrase": "bayesian_network_classifiers"}, {"score": 0.004764859786310636, "phrase": "reduced_precision_parameters"}, {"score": 0.004475022550508119, "phrase": "nowadays_desktop_computers"}, {"score": 0.0042692243768616455, "phrase": "embedded_or_low_power_systems"}, {"score": 0.00386519448487341, "phrase": "reduced_precision_implementations"}, {"score": 0.0035361001070845677, "phrase": "discrete_valued_nodes"}, {"score": 0.0034267429854665035, "phrase": "classification_rate"}, {"score": 0.0032689949867583633, "phrase": "probabilistic_bounds"}, {"score": 0.0031845067058084583, "phrase": "different_bit-widths"}, {"score": 0.0028527866590859967, "phrase": "generatively_and_discriminatively_optimized_parameters"}, {"score": 0.0027645030021576926, "phrase": "high_data_likelihood"}, {"score": 0.0026233771102489416, "phrase": "parameter_quantization"}, {"score": 0.0025960262223338293, "phrase": "generatively_optimized_parameters"}, {"score": 0.0023254633298356894, "phrase": "discriminatively_optimized_parameters"}, {"score": 0.002183684303511462, "phrase": "margin-optimized_tree_augmented_network"}, {"score": 0.0021049977753042253, "phrase": "generatively_optimized_tan_structures"}], "paper_keywords": ["Bayesian network classifiers", " custom precision", " quantization", " discriminative learning"], "paper_abstract": "Bayesian network classifier (BNCs) are typically implemented on nowadays desktop computers. However, many real world applications require classifier implementation on embedded or low power systems. Aspects for this purpose have not been studied rigorously. We partly close this gap by analyzing reduced precision implementations of BNCs. In detail, we investigate the quantization of the parameters of BNCs with discrete valued nodes including the implications on the classification rate (CR). We derive worst-case and probabilistic bounds on the CR for different bit-widths. These bounds are evaluated on several benchmark datasets. Furthermore, we compare the classification performance and the robustness of BNCs with generatively and discriminatively optimized parameters, i.e. parameters optimized for high data likelihood and parameters optimized for classification, with respect to parameter quantization. Generatively optimized parameters are more robust for very low bit-widths, i.e. less classifications change because of quantization. However, classification performance is better for discriminatively optimized parameters for all but very low bit-widths. Additionally, we perform analysis for margin-optimized tree augmented network (TAN) structures which outperform generatively optimized TAN structures in terms of CR and robustness.", "paper_title": "On Bayesian Network Classifiers with Reduced Precision Parameters", "paper_id": "WOS:000351213400006"}