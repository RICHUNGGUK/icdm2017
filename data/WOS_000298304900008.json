{"auto_keywords": [{"score": 0.04005742575771532, "phrase": "precise_network_measurement"}, {"score": 0.03474165949001382, "phrase": "anomalous_cases"}, {"score": 0.00481495049065317, "phrase": "traffic_anomaly_analysis"}, {"score": 0.004774288250682317, "phrase": "characteristics"}, {"score": 0.004701985831087475, "phrase": "virtualized_network_testbed"}, {"score": 0.004657542074154025, "phrase": "network_testbeds"}, {"score": 0.004548253531664032, "phrase": "network_measurement"}, {"score": 0.004058180509184539, "phrase": "node_utility"}, {"score": 0.0037610536973798113, "phrase": "internet_traffic_characteristics"}, {"score": 0.003725470458263889, "phrase": "virtualized_testbeds"}, {"score": 0.0036727235025069828, "phrase": "scheduling_latency_and_heavy_loads"}, {"score": 0.0035356745476539885, "phrase": "clear_conditions"}, {"score": 0.0033875770020590796, "phrase": "empirical-statistical_criteria"}, {"score": 0.003261133560558666, "phrase": "precise_network_experiments"}, {"score": 0.0031693980719538287, "phrase": "virtualization_technology"}, {"score": 0.0031096747349602344, "phrase": "provided_testbeds"}, {"score": 0.002937153116494391, "phrase": "'oversize_packet_spacing"}, {"score": 0.0028274743316389437, "phrase": "cpu_scheduling_latency"}, {"score": 0.0027741761880779535, "phrase": "major_cause"}, {"score": 0.0027479040199262393, "phrase": "throughput_instability"}, {"score": 0.002708960273193547, "phrase": "virtualized_network"}, {"score": 0.0026452734009203764, "phrase": "significant_changes"}, {"score": 0.0026077803487003, "phrase": "well-known_network_metrics"}, {"score": 0.0025586128304269616, "phrase": "unusual_anomalies"}, {"score": 0.0025343769150179764, "phrase": "virtualized_network_environment"}, {"score": 0.0024051153560799335, "phrase": "previous_work"}, {"score": 0.002371018116266096, "phrase": "network_throughput"}, {"score": 0.0022500695985527668, "phrase": "measurement_results"}, {"score": 0.0021352776064254195, "phrase": "cpu_availability"}, {"score": 0.0021049977753042253, "phrase": "important_criterion"}], "paper_keywords": ["network measurement", " virtualization", " PlanetLab"], "paper_abstract": "Network testbeds have been used for network measurement and experiments. In such testbeds, resources, such as CPU, memory, and I/O interfaces, are shared and virtualized to maximize node utility for many users. A few studies have investigated the impact of virtualization on precise network measurement and understood Internet traffic characteristics on virtualized testbeds. Although scheduling latency and heavy loads are reportedly affected in precise network measurement, no clear conditions or criteria have been established. Moreover, empirical-statistical criteria and methods that pick out anomalous cases for precise network experiments are required on userland because virtualization technology used in the provided testbeds is hardly replaceable. In this paper, we show that 'oversize packet spacing', which can be caused by CPU scheduling latency, is a major cause of throughput instability on a virtualized network testbed even when no significant changes occur in well-known network metrics. These are unusual anomalies on virtualized network environment. Empirical-statistical analysis results accord with results at previous work. If network throughput is decreased by the anomalies, we should carefully review measurement results. Our empirical approach enables anomalous cases to be identified. We present CPU availability as an important criterion for estimating the anomalies.", "paper_title": "Traffic Anomaly Analysis and Characteristics on a Virtualized Network Testbed", "paper_id": "WOS:000298304900008"}