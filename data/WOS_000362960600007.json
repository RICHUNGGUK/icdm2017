{"auto_keywords": [{"score": 0.02758346348962749, "phrase": "mars"}, {"score": 0.00481495049065317, "phrase": "risk-aware_robotic_space_exploration"}, {"score": 0.004708152527097594, "phrase": "dynamic_programming"}, {"score": 0.00448477700778838, "phrase": "objective_function"}, {"score": 0.004224286804379592, "phrase": "one-stage_costs"}, {"score": 0.004053994613859937, "phrase": "joint_probabilistic"}, {"score": 0.003761700847771486, "phrase": "novel_algorithmic_approach"}, {"score": 0.0037336520904376687, "phrase": "joint_chance-constrained_dynamic_programming_problems"}, {"score": 0.0035965032173588753, "phrase": "state_constraints"}, {"score": 0.00342568771304873, "phrase": "joint_chance_constraint"}, {"score": 0.003275197814021, "phrase": "random_variables"}, {"score": 0.003178550413662537, "phrase": "cost_function"}, {"score": 0.0031312981393997355, "phrase": "dual_formulation"}, {"score": 0.0030963190575539574, "phrase": "optimization_problem"}, {"score": 0.0030162086479223506, "phrase": "primal_variables"}, {"score": 0.0029602552900111407, "phrase": "standard_dynamic_programming"}, {"score": 0.002916238693326477, "phrase": "dual_variable"}, {"score": 0.00286213454317036, "phrase": "root-finding_algorithm"}, {"score": 0.0028090313440881937, "phrase": "error_bounds"}, {"score": 0.0027776422068966867, "phrase": "primal_and_dual_objective_values"}, {"score": 0.0027057544777834086, "phrase": "algorithm_effectiveness"}, {"score": 0.0025010515115806886, "phrase": "lunar"}, {"score": 0.0024546155360991567, "phrase": "mars_simulations"}, {"score": 0.002418099158357658, "phrase": "real_terrain_data"}, {"score": 0.002311769781106355, "phrase": "numerical_experiments"}, {"score": 0.002128801826067279, "phrase": "real-world_problems"}], "paper_keywords": ["Dynamic programming", " Constrained stochastic optimal control", " Chance-constrained optimization", " Markov decision processes", " Path planning"], "paper_abstract": "Existing approaches to constrained dynamic programming are limited to formulations where the constraints share the same additive structure of the objective function (that is, they can be represented as an expectation of the summation of one-stage costs). As such, these formulations cannot handle joint probabilistic (chance) constraints, whose structure is not additive. To bridge this gap, this paper presents a novel algorithmic approach for joint chance-constrained dynamic programming problems, where the probability of failure to satisfy given state constraints is explicitly bounded. Our approach is to (conservatively) reformulate a joint chance constraint as a constraint on the expectation of a summation of indicator random variables, which can be incorporated into the cost function by considering a dual formulation of the optimization problem. As a result, the primal variables can be optimized by standard dynamic programming, while the dual variable is optimized by a root-finding algorithm that converges exponentially. Error bounds on the primal and dual objective values are rigorously derived. We demonstrate algorithm effectiveness on three optimal control problems, namely a path planning problem, a Mars entry, descent and landing problem, and a Lunar landing problem. All Mars simulations are conducted using real terrain data of Mars, with four million discrete states at each time step. The numerical experiments are used to validate our theoretical and heuristic arguments that the proposed algorithm is both (i) computationally efficient, i.e., capable of handling real-world problems, and (ii) near-optimal, i.e., its degree of conservatism is very low.", "paper_title": "Chance-constrained dynamic programming with application to risk-aware robotic space exploration", "paper_id": "WOS:000362960600007"}