{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "forensic_analysis"}, {"score": 0.010665667938960153, "phrase": "k-medoids"}, {"score": 0.010414723164711436, "phrase": "average_link"}, {"score": 0.004701015188740582, "phrase": "computer_inspection"}, {"score": 0.004305740330804528, "phrase": "unstructured_text"}, {"score": 0.004237512575106522, "phrase": "computer_examiners"}, {"score": 0.00405538690701843, "phrase": "automated_methods"}, {"score": 0.003975200317233532, "phrase": "great_interest"}, {"score": 0.0038655854071187115, "phrase": "clustering_documents"}, {"score": 0.0037740295668681014, "phrase": "new_and_useful_knowledge"}, {"score": 0.003583002730249742, "phrase": "document_clustering_algorithms"}, {"score": 0.0034841647157189985, "phrase": "police_investigations"}, {"score": 0.0034152340901585374, "phrase": "proposed_approach"}, {"score": 0.003361069456060196, "phrase": "extensive_experimentation"}, {"score": 0.003334309053314909, "phrase": "six_well-known_clustering_algorithms"}, {"score": 0.003229374325577207, "phrase": "single_link"}, {"score": 0.0032036590920314725, "phrase": "complete_link"}, {"score": 0.0031402604946939713, "phrase": "cspa"}, {"score": 0.0030904433394138963, "phrase": "five_real-world_datasets"}, {"score": 0.0030171910207671205, "phrase": "real-world_investigations"}, {"score": 0.0029339151044984134, "phrase": "different_combinations"}, {"score": 0.0026654155072292707, "phrase": "related_studies"}, {"score": 0.0024901940672239784, "phrase": "complete_link_algorithms"}, {"score": 0.0024604876113911173, "phrase": "best_results"}, {"score": 0.002382987346529592, "phrase": "partitional_algorithms"}, {"score": 0.0021049977753042253, "phrase": "forensic_computing"}], "paper_keywords": ["Clustering", " forensic computing", " text mining"], "paper_abstract": "In computer forensic analysis, hundreds of thousands of files are usually examined. Much of the data in those files consists of unstructured text, whose analysis by computer examiners is difficult to be performed. In this context, automated methods of analysis are of great interest. In particular, algorithms for clustering documents can facilitate the discovery of new and useful knowledge from the documents under analysis. We present an approach that applies document clustering algorithms to forensic analysis of computers seized in police investigations. We illustrate the proposed approach by carrying out extensive experimentation with six well-known clustering algorithms (K-means, K-medoids, Single Link, Complete Link, Average Link, and CSPA) applied to five real-world datasets obtained from computers seized in real-world investigations. Experiments have been performed with different combinations of parameters, resulting in 16 different instantiations of algorithms. In addition, two relative validity indexes were used to automatically estimate the number of clusters. Related studies in the literature are significantly more limited than our study. Our experiments show that the Average Link and Complete Link algorithms provide the best results for our application domain. If suitably initialized, partitional algorithms (K-means and K-medoids) can also yield to very good results. Finally, we also present and discuss several practical results that can be useful for researchers and practitioners of forensic computing.", "paper_title": "Document Clustering for Forensic Analysis: An Approach for Improving Computer Inspection", "paper_id": "WOS:000318595000004"}