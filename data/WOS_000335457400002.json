{"auto_keywords": [{"score": 0.03868050804560159, "phrase": "aesvm"}, {"score": 0.008015519506028346, "phrase": "libsvm"}, {"score": 0.00481495049065317, "phrase": "approximate_extreme_points"}, {"score": 0.004740476936977635, "phrase": "non-linear_kernel_support_vector_machines"}, {"score": 0.004648995193787914, "phrase": "large_data_sets"}, {"score": 0.004024485331377682, "phrase": "svm_optimization"}, {"score": 0.003977672712305348, "phrase": "carefully_selected_subset"}, {"score": 0.0038404642251010797, "phrase": "training_data"}, {"score": 0.0037662852047763112, "phrase": "analytical_results"}, {"score": 0.0036506707803548896, "phrase": "svm"}, {"score": 0.0035940277928341265, "phrase": "linear_time_algorithm"}, {"score": 0.003552204377093386, "phrase": "convex_hulls"}, {"score": 0.0035245918797629804, "phrase": "extreme_points"}, {"score": 0.0034029588672379926, "phrase": "kernel_space"}, {"score": 0.00337650257503995, "phrase": "extensive_computational_experiments"}, {"score": 0.0033502512757488433, "phrase": "nine_data_sets"}, {"score": 0.0032855352048016635, "phrase": "chang"}, {"score": 0.0032600213228272763, "phrase": "lin"}, {"score": 0.0023029188952824685, "phrase": "aesvm_training"}, {"score": 0.00222335168916802, "phrase": "lasvm"}, {"score": 0.0021049977753042253, "phrase": "competitively_fast_classification_times"}], "paper_keywords": ["support vector machines", " convex hulls", " large scale classification", " non-linear kernels", " extreme points"], "paper_abstract": "Applications of non-linear kernel support vector machines (SVMs) to large data sets is seriously hampered by its excessive training time. We propose a modification, called the approximate extreme points support vector machine (AESVM), that is aimed at overcoming this burden. Our approach relies on conducting the SVM optimization over a carefully selected subset, called the representative set, of the training data set. We present analytical results that indicate the similarity of AESVM and SVM solutions. A linear time algorithm based on convex hulls and extreme points is used to compute the representative set in kernel space. Extensive computational experiments on nine data sets compared AESVM to LIBSVM (Chang and Lin, 2011), CVM (Tsang et al., 2005), BVM (Tsang et al., 2007), LASVM (Bordes et al., 2005), SVMperf (Joachims and Yu, 2009), and the random features method (Rahimi and Recht, 2007). Our AESVM implementation was found to train much faster than the other methods, while its classification accuracy was similar to that of LIBSVM in all cases. In particular, for a seizure detection data set, AESVM training was almost 500 times faster than LIBSVM and LASVM and 20 times faster than CVM and BVM. Additionally, AESVM also gave competitively fast classification times.", "paper_title": "Fast SVM Training Using Approximate Extreme Points", "paper_id": "WOS:000335457400002"}