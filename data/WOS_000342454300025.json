{"auto_keywords": [{"score": 0.03278315547300426, "phrase": "lock_conflict_rate"}, {"score": 0.00481495049065317, "phrase": "fine-grained_parallelism"}, {"score": 0.004778594263962987, "phrase": "graph_traversal_algorithms"}, {"score": 0.004742511243894382, "phrase": "lock_virtualization"}, {"score": 0.004706699397060569, "phrase": "multi-core_architecture"}, {"score": 0.004618342952383313, "phrase": "fundamental_procedure"}, {"score": 0.004497410940849537, "phrase": "massive_fine-grained_parallelism"}, {"score": 0.004396267325338022, "phrase": "fine-grained_data_synchronization"}, {"score": 0.004313713204732449, "phrase": "commodity_multi-core_processors"}, {"score": 0.004264923517966271, "phrase": "widely_adopted_solution"}, {"score": 0.004232702713825967, "phrase": "fine-grained_locks"}, {"score": 0.0040290957541568775, "phrase": "emerging_graph_analytics"}, {"score": 0.0039986494357811715, "phrase": "massive_irregular_graphs"}, {"score": 0.0038062581748678245, "phrase": "huge_memory_cost"}, {"score": 0.0037774893672602506, "phrase": "poor_locality"}, {"score": 0.0036645642553325215, "phrase": "inherent_random_vertex_access"}, {"score": 0.0035415392642831616, "phrase": "novel_fine-grained_lock_mechanism-lock_virtualization"}, {"score": 0.003383884759373793, "phrase": "huge_logical_lock_space"}, {"score": 0.0033455764382772754, "phrase": "small_fixed_physical_lock_space"}, {"score": 0.0032209766681045365, "phrase": "virtualization_mechanism"}, {"score": 0.0031845067058084583, "phrase": "lock_incurred_extra_memory_cost"}, {"score": 0.003042697264766327, "phrase": "high_portability"}, {"score": 0.0030196821790309165, "phrase": "legacy_codes"}, {"score": 0.002985484575498061, "phrase": "pthreads-like_application_programming_interface"}, {"score": 0.0028851913035322415, "phrase": "random_access_pattern"}, {"score": 0.0026945722090537397, "phrase": "physical_locks"}, {"score": 0.0026741832921475667, "phrase": "parallel_threads"}, {"score": 0.0026040262154057607, "phrase": "graph_topologies"}, {"score": 0.0025453546203590364, "phrase": "complete_description"}, {"score": 0.0025165151708122957, "phrase": "vlock_method"}, {"score": 0.0024319378563138223, "phrase": "vlock_library"}, {"score": 0.002368138263615496, "phrase": "bfs"}, {"score": 0.0023502005942734262, "phrase": "sssp"}, {"score": 0.0021782296784218923, "phrase": "pthreads_fine-grained_locks"}, {"score": 0.002137236968970666, "phrase": "lock's_cache"}], "paper_keywords": ["Graph traversal", " Fine-grained parallelism", " Data synchronization", " Parallel programming"], "paper_abstract": "Traversal is a fundamental procedure in most parallel graph algorithms. To explore the massive fine-grained parallelism in graph traversal, the fine-grained data synchronization is critical. On commodity multi-core processors, the widely adopted solution is fine-grained locks (i.e., one lock per vertex). However, in emerging graph analytics of massive irregular graphs (e.g., social network and web graph), it suffers huge memory cost and poor locality due to the large-scale vertex set and inherent random vertex access. In this paper, we propose a novel fine-grained lock mechanism-lock virtualization (vLock). The key idea is to map the huge logical lock space to a small fixed physical lock space that can reside in cache during runtime. The virtualization mechanism effectively reduces lock incurred extra memory cost and cache misses with only a slight increase of lock conflict rate, while it preserves high portability for legacy codes by providing Pthreads-like application programming interface. Our further analysis reveals that given the random access pattern, the lock conflict rate is no longer related to the size of vertex set but only the numbers of both physical locks and parallel threads, thus vLock is independent from graph topologies. This paper presents a complete description of the vLock method as well as its theoretic foundation. We implemented an vLock library and evaluated its performance in four classic graph traversal algorithms (BFS, SSSP, CC, PageRank). Experiments on the Intel Xeon E5 eight-core processor show that, compared to Pthreads fine-grained locks, vLock significantly reduces lock's cache misses and achieves 4-20 % performance improvement.", "paper_title": "Exploiting fine-grained parallelism in graph traversal algorithms via lock virtualization on multi-core architecture", "paper_id": "WOS:000342454300025"}