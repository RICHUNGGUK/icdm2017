{"auto_keywords": [{"score": 0.049378038061471535, "phrase": "distributed"}, {"score": 0.04845146056604559, "phrase": "distributed_data_copy"}, {"score": 0.040878505495036625, "phrase": "huge_number"}, {"score": 0.03806937488683271, "phrase": "soft-state_approach"}, {"score": 0.00481495049065317, "phrase": "data_recovery_of_distributed"}, {"score": 0.004791330993892003, "phrase": "hash_table"}, {"score": 0.004561386908745206, "phrase": "huge-scale_information_services"}, {"score": 0.004494570360108983, "phrase": "distributed_hash_table"}, {"score": 0.004450590017847229, "phrase": "dht"}, {"score": 0.004406994912939125, "phrase": "based_systems"}, {"score": 0.0041136473765874815, "phrase": "item-level_product_traceability_information"}, {"score": 0.003858697684681798, "phrase": "item-level_ids"}, {"score": 0.0036733470451885465, "phrase": "data_availability"}, {"score": 0.003531474887552889, "phrase": "previous_works"}, {"score": 0.0031532895341013297, "phrase": "traceability_case"}, {"score": 0.002680114113899346, "phrase": "data_loss"}, {"score": 0.0025892330566358503, "phrase": "dht_system"}, {"score": 0.0021789194955896124, "phrase": "low_rate"}, {"score": 0.0021049977753042253, "phrase": "data_entries"}], "paper_keywords": ["Distributed Hash Table", " data durability", " traceability system", " scalability"], "paper_abstract": "To realize huge-scale information services, many Distributed Hash Table (DHT) based systems have been proposed. For example, there are some proposals to manage item-level product traceability information with DHTs. In such an application, each entry of a huge number of item-level IDs need to be available on a DHT To ensure data availability, the soft-state approach has been employed in previous works. However, this does not scale well against the number of entries on it DHT. As we expect 1010 products in the traceability case, the soft-state approach is unacceptable. In this paper, we propose Distributed-to-Distributed Data Copy (D3C). With D3C, users can reconstruct the data as they detect data loss, or even migrate to another DHT system. We show why it scales well against the number of entries on a DHT. We have confirmed our approach with a prototype, Evaluation shows our approach fits. well on a DHT with a low rate of failure and a huge number of data entries.", "paper_title": "Data Recovery of Distributed Hash Table with Distributed-to-Distributed Data Copy", "paper_id": "WOS:000272394700022"}