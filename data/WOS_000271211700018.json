{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "well-known_optimization_technique"}, {"score": 0.00474827840031692, "phrase": "redundant_calls"}, {"score": 0.0047152877145889656, "phrase": "pure_functions"}, {"score": 0.0042617859335771615, "phrase": "f's_body"}, {"score": 0.0037326500020622715, "phrase": "inter-thread_dependencies"}, {"score": 0.0036809089768350496, "phrase": "communication_actions"}, {"score": 0.0036553070575015344, "phrase": "subsequent_calls"}, {"score": 0.003303412571939192, "phrase": "similar_issues"}, {"score": 0.0032462487283717546, "phrase": "additional_threads"}, {"score": 0.0031458272260508637, "phrase": "memoization_problem"}, {"score": 0.0031130463625133496, "phrase": "higher-order_concurrent_language"}, {"score": 0.003048502724695561, "phrase": "synchronous_message-based_communication"}, {"score": 0.002964515198409409, "phrase": "unbounded_state_space_search"}, {"score": 0.002872783899731766, "phrase": "communication_dependencies"}, {"score": 0.002832928222306059, "phrase": "earlier_call"}, {"score": 0.0027741761880779535, "phrase": "later_one"}, {"score": 0.00272614545678894, "phrase": "weaker_notion"}, {"score": 0.0025156683465194967, "phrase": "previously_memoized_call"}, {"score": 0.00227323596233465, "phrase": "transactional_applications"}, {"score": 0.002241679436497571, "phrase": "multi-core_machine"}, {"score": 0.0021271863804595108, "phrase": "substantial_performance_improvements"}, {"score": 0.0021049977753042253, "phrase": "high_memory_costs"}], "paper_keywords": ["Design", " Experimentation", " Languages", " Performance", " Theory", " Algorithms", " Concurrent Programming", " Partial Memoization", " Software Transactions", " Concurrent ML", " Multicore Systems"], "paper_abstract": "Memoization is a well-known optimization technique used to eliminate redundant calls for pure functions. If a call to a function f with argument v yields result r, a subsequent call to f with v can be immediately reduced to r without the need to re-evaluate f's body. Understanding memoization in the presence of concurrency and communication is significantly more challenging. For example, if f communicates with other threads, it is not sufficient to simply record its input/output behavior; we must also track inter-thread dependencies induced by these communication actions. Subsequent calls to f can be elided only if we can identify an interleaving of actions from these call-sites that lead to states in which these dependencies are satisfied. Similar issues arise if f spawns additional threads. In this paper, we consider the memoization problem for a higher-order concurrent language whose threads may communicate through synchronous message-based communication. To avoid the need to perform unbounded state space search that may be necessary to determine if all communication dependencies manifest in an earlier call can be satisfied in a later one, we introduce a weaker notion of memoization called partial memoization that gives implementations the freedom to avoid performing some part, if not all, of a previously memoized call. To validate the effectiveness of our ideas, we consider the benefits of memoization for reducing the overhead of recomputation for streaming, server-based, and transactional applications executed on a multi-core machine. We show that on a variety of workloads, memoization can lead to substantial performance improvements without incurring high memory costs.", "paper_title": "Partial Memoization of Concurrency and Communication", "paper_id": "WOS:000271211700018"}