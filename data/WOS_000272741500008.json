{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "kinematic_features"}, {"score": 0.021575355832557017, "phrase": "optical_flow"}, {"score": 0.014821335470777608, "phrase": "kinematic_modes"}, {"score": 0.010507254962917746, "phrase": "multiple_instance_learning"}, {"score": 0.0044219992735047954, "phrase": "human_action_recognition"}, {"score": 0.004101886428528311, "phrase": "antisymmetric_flow_fields"}, {"score": 0.004060986196931943, "phrase": "second_and_third_principal_invariants"}, {"score": 0.00392100783796804, "phrase": "strain_tensor"}, {"score": 0.0038624981944755813, "phrase": "third_principal_invariant"}, {"score": 0.003785836059995376, "phrase": "rotation_tensor"}, {"score": 0.003729335910488339, "phrase": "kinematic_feature"}, {"score": 0.003424677513304057, "phrase": "spatiotemporal_pattern"}, {"score": 0.0032900200522703923, "phrase": "representative_dynamics"}, {"score": 0.0031606404966938568, "phrase": "spatiotemporal_patterns"}, {"score": 0.0030823667846259836, "phrase": "dominant_kinematic_trends"}, {"score": 0.002931569771634119, "phrase": "principal_component_analysis"}, {"score": 0.0029024110650809824, "phrase": "pca"}, {"score": 0.0028446460307503343, "phrase": "spatiotemporal_volumes"}, {"score": 0.0025730425700096365, "phrase": "action_video"}, {"score": 0.0023745087648471613, "phrase": "kinematic-mode-based_feature_space"}, {"score": 0.0021912600076114033, "phrase": "nearest_neighbor_algorithm"}, {"score": 0.002158505888557746, "phrase": "qualitative_and_quantitative_results"}, {"score": 0.0021049977753042253, "phrase": "benchmark_data_sets"}], "paper_keywords": ["Action recognition", " motion", " video analysis", " principal component analysis", " kinematic features"], "paper_abstract": "We propose a set of kinematic features that are derived from the optical flow for human action recognition in videos. The set of kinematic features includes divergence, vorticity, symmetric and antisymmetric flow fields, second and third principal invariants of flow gradient and rate of strain tensor, and third principal invariant of rate of rotation tensor. Each kinematic feature, when computed from the optical flow of a sequence of images, gives rise to a spatiotemporal pattern. It is then assumed that the representative dynamics of the optical flow are captured by these spatiotemporal patterns in the form of dominant kinematic trends or kinematic modes. These kinematic modes are computed by performing Principal Component Analysis (PCA) on the spatiotemporal volumes of the kinematic features. For classification, we propose the use of multiple instance learning (MIL) in which each action video is represented by a bag of kinematic modes. Each video is then embedded into a kinematic-mode-based feature space and the coordinates of the video in that space are used for classification using the nearest neighbor algorithm. The qualitative and quantitative results are reported on the benchmark data sets.", "paper_title": "Human Action Recognition in Videos Using Kinematic Features and Multiple Instance Learning", "paper_id": "WOS:000272741500008"}