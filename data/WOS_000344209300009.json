{"auto_keywords": [{"score": 0.04889532068804289, "phrase": "cca"}, {"score": 0.044778825396535736, "phrase": "label_information"}, {"score": 0.036917572702233344, "phrase": "labeled_samples"}, {"score": 0.00481495049065317, "phrase": "multi-view_dimensionality_reduction"}, {"score": 0.004618166136069052, "phrase": "efficient_method"}, {"score": 0.004579780586951551, "phrase": "dimensionality_reduction"}, {"score": 0.004541712637353326, "phrase": "two-view_data"}, {"score": 0.004429388453288922, "phrase": "unsupervised_learning_method"}, {"score": 0.004248294537944227, "phrase": "multi-view_semi-supervised_scenarios"}, {"score": 0.0040916230716372265, "phrase": "novel_two-view_semi-supervised_learning_method"}, {"score": 0.00390792986752692, "phrase": "label_propagation"}, {"score": 0.0038271712887391015, "phrase": "lpbscca"}, {"score": 0.0037795163893761027, "phrase": "new_sparse_representation"}, {"score": 0.0037480753312398754, "phrase": "label_propagation_algorithm"}, {"score": 0.003670608022642996, "phrase": "unlabeled_data"}, {"score": 0.0034332736827447654, "phrase": "reconstruction_coefficients"}, {"score": 0.003404703106153948, "phrase": "unlabeled_samples"}, {"score": 0.003376369479008885, "phrase": "sparse_representation_technique"}, {"score": 0.0031712256091350316, "phrase": "unlabeled_ones"}, {"score": 0.0030797912111959137, "phrase": "soft_label_matrices"}, {"score": 0.002966084234963723, "phrase": "scatter_matrices"}, {"score": 0.0028327783069076883, "phrase": "discriminative_power"}, {"score": 0.0026384167183586015, "phrase": "cross_views"}, {"score": 0.0025409639091476363, "phrase": "low-dimensional_feature_space"}, {"score": 0.00241658945942583, "phrase": "general_model"}, {"score": 0.0022507188208913394, "phrase": "proposed_methods"}, {"score": 0.0022226496830385304, "phrase": "better_recognition_performances"}, {"score": 0.0021857667493036786, "phrase": "existing_related_methods"}, {"score": 0.00216755493625594, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Canonical correlation analysis", " Semi-supervised learning", " Label propagation", " Sparse representation", " Multi-view learning", " Feature extraction", " Dimensionality reduction", " Image recognition"], "paper_abstract": "Canonical correlation analysis (CCA) is an efficient method for dimensionality reduction on two-view data. However, as an unsupervised learning method, CCA cannot utilize partly given label information in multi-view semi-supervised scenarios. In this paper, we propose a novel two-view semi-supervised learning method, called semi-supervised canonical correlation analysis based on label propagation (LPbSCCA). LPbSCCA incorporates a new sparse representation based label propagation algorithm to infer label information for unlabeled data. Specifically, it firstly constructs dictionaries consisting of all labeled samples; and then obtains reconstruction coefficients of unlabeled samples using sparse representation technique; at last, by combining given labels of labeled samples, estimates label information for unlabeled ones. After that, it constructs soft label matrices of all samples and probabilistic within-class scatter matrices in each view. Finally, in order to enhance discriminative power of features, it is formulated to maximize the correlations between samples of the same class from cross views, while minimizing within-class variations in the low-dimensional feature space of each view simultaneously. Furthermore, we also extend a general model called LPbSMCCA to handle data from multiple (more than two) views. Extensive experimental results from several well-known datasets demonstrate that the proposed methods can achieve better recognition performances and robustness than existing related methods. Crown Copyright (C) 2014 Published by Elsevier Inc. All rights reserved.", "paper_title": "A novel semi-supervised canonical correlation analysis and extensions for multi-view dimensionality reduction", "paper_id": "WOS:000344209300009"}