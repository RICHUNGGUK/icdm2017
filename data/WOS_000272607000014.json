{"auto_keywords": [{"score": 0.04881990207677595, "phrase": "differential_equations"}, {"score": 0.020556178322448264, "phrase": "bp"}, {"score": 0.009975997477695718, "phrase": "reformulated_radial_basis_function_networks"}, {"score": 0.0063509466072528, "phrase": "specific_example"}, {"score": 0.00481495049065317, "phrase": "generalization_ability"}, {"score": 0.004405596416783185, "phrase": "gradient_descent_algorithms"}, {"score": 0.004066898031169739, "phrase": "multilayered_feed-forward_networks"}, {"score": 0.0033442114331500407, "phrase": "generalization_capability"}, {"score": 0.0031703706626348507, "phrase": "regularization_theory"}, {"score": 0.0025605773834404253, "phrase": "experimental_comparison"}, {"score": 0.0024273730899216006, "phrase": "rbfn"}, {"score": 0.0023845255359681143, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Backpropagation", " Differential equations", " Reformulated radial basis function"], "paper_abstract": "The gradient descent algorithms like backpropagation (BP) or its variations on multilayered feed-forward networks are widely used in many applications, especially on solving differential equations. Reformulated radial basis function networks (RBFN) are expected to have more accuracy in generalization capability than BP according to the regularization theory. We show how to apply the both networks to a specific example of differential equations and compare the capability of generalization and convergence. The experimental comparison of various approaches clarifies that reformulated RBFN shows better performance than BP for solving a specific example of differential equations. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Comparison of generalization ability on solving differential equations using backpropagation and reformulated radial basis function networks", "paper_id": "WOS:000272607000014"}