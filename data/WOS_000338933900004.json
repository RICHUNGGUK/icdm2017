{"auto_keywords": [{"score": 0.04706744733513921, "phrase": "surgical_tasks"}, {"score": 0.027831004963485614, "phrase": "proposed_approach"}, {"score": 0.00481495049065317, "phrase": "human-robot_skills"}, {"score": 0.004733458808453602, "phrase": "flexible_surgical_robot"}, {"score": 0.004685224205630963, "phrase": "minimally_invasive_surgery"}, {"score": 0.004605917942709477, "phrase": "narrow_openings"}, {"score": 0.004558977045730675, "phrase": "soft_organs"}, {"score": 0.0044209926093642235, "phrase": "current_robot-assisted_surgical_systems"}, {"score": 0.004331320910631647, "phrase": "robot_tools"}, {"score": 0.004243460284890507, "phrase": "stiff-flop_european_project"}, {"score": 0.00417160036938041, "phrase": "soft_robotic_arm"}, {"score": 0.003909413809681226, "phrase": "remote_areas"}, {"score": 0.0038300786263543835, "phrase": "challenging_procedures"}, {"score": 0.003688773272422118, "phrase": "learning_interfaces"}, {"score": 0.0036015684625793775, "phrase": "human_demonstration"}, {"score": 0.003577032245103867, "phrase": "robot_programming"}, {"score": 0.003516417950483685, "phrase": "wide_range"}, {"score": 0.0034924598001567944, "phrase": "learning_strategies"}, {"score": 0.003456827226847432, "phrase": "simple_mimicking"}, {"score": 0.0034215569542785907, "phrase": "demonstrator's_actions"}, {"score": 0.003386645324034521, "phrase": "higher_level_imitation"}, {"score": 0.003352088714126572, "phrase": "underlying_intent"}, {"score": 0.003239418275717787, "phrase": "last_form"}, {"score": 0.003141246279336443, "phrase": "objective_function"}, {"score": 0.003077451642616653, "phrase": "over-specified_set"}, {"score": 0.003056475095474338, "phrase": "candidate_reward_functions"}, {"score": 0.0028937142757436683, "phrase": "reinforcement_learning_strategies"}, {"score": 0.002815604242104671, "phrase": "reward_functions"}, {"score": 0.002777341265639153, "phrase": "entire_task"}, {"score": 0.002720916895509682, "phrase": "pre-defined_reward_profiles"}, {"score": 0.0025848074189353397, "phrase": "context-dependent_reward-weighted_learning"}, {"score": 0.002497862210672172, "phrase": "candidate_objective_functions"}, {"score": 0.002455489835065937, "phrase": "current_phase"}, {"score": 0.0024138345020219333, "phrase": "encountered_situation"}, {"score": 0.002308800317961002, "phrase": "policy_parameters_space"}, {"score": 0.0022311183974368484, "phrase": "cutting_task"}, {"score": 0.0022007808283071133, "phrase": "stiff-flop_flexible_robot"}, {"score": 0.002148677187261496, "phrase": "barrett_wam_manipulator"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ireland_ltd."}], "paper_keywords": ["Robot-assisted surgery", " Soft robotics", " Learning from demonstration", " Skills transfer", " Inverse reinforcement learning", " Stochastic optimization"], "paper_abstract": "In minimally invasive surgery, tools go through narrow openings and manipulate soft organs to perform surgical tasks. There are limitations in current robot-assisted surgical systems due to the rigidity of robot tools. The aim of the STIFF-FLOP European project is to develop a soft robotic arm to perform surgical tasks. The flexibility of the robot allows the surgeon to move within organs to reach remote areas inside the body and perform challenging procedures in laparoscopy. This article addresses the problem of designing learning interfaces enabling the transfer of skills from human demonstration. Robot programming by demonstration encompasses a wide range of learning strategies, from simple mimicking of the demonstrator's actions to the higher level imitation of the underlying intent extracted from the demonstrations. By focusing on this last form, we study the problem of extracting an objective function explaining the demonstrations from an over-specified set of candidate reward functions, and using this information for self-refinement of the skill. In contrast to inverse reinforcement learning strategies that attempt to explain the observations with reward functions defined for the entire task (or a set of pre-defined reward profiles active for different parts of the task), the proposed approach is based on context-dependent reward-weighted learning, where the robot can learn the relevance of candidate objective functions with respect to the current phase of the task or encountered situation. The robot then exploits this information for skills refinement in the policy parameters space. The proposed approach is tested in simulation with a cutting task performed by the STIFF-FLOP flexible robot, using kinesthetic demonstrations from a Barrett WAM manipulator. (C) 2014 Elsevier Ireland Ltd. All rights reserved.", "paper_title": "Human-robot skills transfer interfaces for a flexible surgical robot", "paper_id": "WOS:000338933900004"}