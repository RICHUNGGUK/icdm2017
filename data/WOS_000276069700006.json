{"auto_keywords": [{"score": 0.049734762741514144, "phrase": "symbolic_regression"}, {"score": 0.00889462311100322, "phrase": "similar_information_content"}, {"score": 0.007377795796726765, "phrase": "compressed_subset"}, {"score": 0.00481495049065317, "phrase": "data_balancing"}, {"score": 0.004711843410316589, "phrase": "input-output_data"}, {"score": 0.004661116930794176, "phrase": "data_records"}, {"score": 0.004528488165249491, "phrase": "automatic_assignment"}, {"score": 0.0044635893862404385, "phrase": "data_samples"}, {"score": 0.004352236750212992, "phrase": "sample's_relative_importance"}, {"score": 0.004137761530535196, "phrase": "real-life_data"}, {"score": 0.004049096735491828, "phrase": "fitness_function"}, {"score": 0.0036862417490612673, "phrase": "nearest-in-the-input-space_neighbors"}, {"score": 0.003581252556182843, "phrase": "large_imbalanced_data_sets"}, {"score": 0.003529880686744397, "phrase": "simple_multidimensional_iterative_technique"}, {"score": 0.0034293295415901807, "phrase": "sensible_partitioning"}, {"score": 0.00333163309034114, "phrase": "nested_subsets"}, {"score": 0.0032957163929772716, "phrase": "arbitrary_size"}, {"score": 0.0031331419276289306, "phrase": "presented_weighting_schemes"}, {"score": 0.002790940765338191, "phrase": "smaller_subset"}, {"score": 0.002643624979574088, "phrase": "better_exploration"}, {"score": 0.0026151058979100596, "phrase": "search_space"}, {"score": 0.0025962638592454974, "phrase": "potential_solutions"}, {"score": 0.002549749054599413, "phrase": "function_evaluations"}, {"score": 0.00251313643823856, "phrase": "different_approaches"}, {"score": 0.0024770482478966896, "phrase": "five_benchmark_problems"}, {"score": 0.0024503217593801587, "phrase": "fixed_budget_allocation"}, {"score": 0.0023977287074829798, "phrase": "significant_improvement"}, {"score": 0.0023462618437394616, "phrase": "regression_models"}, {"score": 0.0022876085523721324, "phrase": "weighted_regression"}, {"score": 0.0022711207841260767, "phrase": "exploratory_regression"}, {"score": 0.002198380879018061, "phrase": "exploratory_weighted_regression"}, {"score": 0.0021049977753042253, "phrase": "proposed_weighting_schemes"}], "paper_keywords": ["Compression", " data balancing", " data scoring", " data weighting", " fitting", " genetic programming", " information content", " modeling", " subset selection", " symbolic regression"], "paper_abstract": "Symbolic regression of input-output data conventionally treats data records equally. We suggest a framework for automatic assignment of weights to data samples, which takes into account the sample's relative importance. In this paper, we study the possibilities of improving symbolic regression on real-life data by incorporating weights into the fitness function. We introduce four weighting schemes de. ning the importance of a point relative to proximity, surrounding, remoteness, and nonlinear deviation from k nearest-in-the-input-space neighbors. For enhanced analysis and modeling of large imbalanced data sets we introduce a simple multidimensional iterative technique for subsampling. This technique allows a sensible partitioning (and compression) of data to nested subsets of an arbitrary size in such a way that the subsets are balanced with respect to either of the presented weighting schemes. For cases where a given input-output data set contains some redundancy, we suggest an approach to considerably improve the effectiveness of regression by applying more modeling effort to a smaller subset of the data set that has a similar information content. Such improvement is achieved due to better exploration of the search space of potential solutions at the same number of function evaluations. We compare different approaches to regression on five benchmark problems with a fixed budget allocation. We demonstrate that the significant improvement in the quality of the regression models can be obtained either with the weighted regression, exploratory regression using a compressed subset with a similar information content, or exploratory weighted regression on the compressed subset, which is weighted with one of the proposed weighting schemes.", "paper_title": "On the Importance of Data Balancing for Symbolic Regression", "paper_id": "WOS:000276069700006"}