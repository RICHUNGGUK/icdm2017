{"auto_keywords": [{"score": 0.033487695187782704, "phrase": "risk-averse_setting"}, {"score": 0.00481495049065317, "phrase": "risk-averse_multi-stage_stochastic_programming"}, {"score": 0.004596561972944185, "phrase": "risk-averse_multi-stage_stochastic_program"}, {"score": 0.004267468074128779, "phrase": "risk_measure"}, {"score": 0.00415019999222481, "phrase": "underlying_random_process"}, {"score": 0.003712362078915926, "phrase": "stochastic_dual_dynamic_programming"}, {"score": 0.0033515736929172644, "phrase": "poor_performance"}, {"score": 0.0032593915869553714, "phrase": "standard_upper_bound_estimator"}, {"score": 0.003054009753601139, "phrase": "new_approach"}, {"score": 0.0029699874949715367, "phrase": "importance_sampling"}, {"score": 0.0028615323526689582, "phrase": "improved_upper_bound_estimators"}, {"score": 0.0028087949095629955, "phrase": "modest_additional_computational_effort"}, {"score": 0.0025592969422491476, "phrase": "significant_improvement"}, {"score": 0.0024658019116387845, "phrase": "controlling_solution_quality"}, {"score": 0.002420339995088838, "phrase": "sddp-style_algorithms"}, {"score": 0.002267708463966758, "phrase": "computational_results"}, {"score": 0.0022258906408344973, "phrase": "multi-stage_asset_allocation"}, {"score": 0.002164602220179823, "phrase": "log-normal_distribution"}, {"score": 0.0021049977753042253, "phrase": "asset_returns"}], "paper_keywords": ["Multi-stage stochastic programming", " Stochastic dual dynamic programming", " Importance sampling", " Risk-averse optimization"], "paper_abstract": "We consider a risk-averse multi-stage stochastic program using conditional value at risk as the risk measure. The underlying random process is assumed to be stage-wise independent, and a stochastic dual dynamic programming (SDDP) algorithm is applied. We discuss the poor performance of the standard upper bound estimator in the risk-averse setting and propose a new approach based on importance sampling, which yields improved upper bound estimators. Modest additional computational effort is required to use our new estimators. Our procedures allow for significant improvement in terms of controlling solution quality in SDDP-style algorithms in the risk-averse setting. We give computational results for multi-stage asset allocation using a log-normal distribution for the asset returns.", "paper_title": "Evaluating policies in risk-averse multi-stage stochastic programming", "paper_id": "WOS:000358292600009"}