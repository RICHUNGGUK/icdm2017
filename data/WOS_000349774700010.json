{"auto_keywords": [{"score": 0.04945540937697203, "phrase": "novel_projective_invariant"}, {"score": 0.0308317584384051, "phrase": "shape_priors"}, {"score": 0.00481495049065317, "phrase": "fiducial_facial_point_extraction"}, {"score": 0.004710854091689325, "phrase": "automatic_extraction"}, {"score": 0.004669845451682529, "phrase": "fiducial_facial_points"}, {"score": 0.004568871736067739, "phrase": "key_steps"}, {"score": 0.004373398434399966, "phrase": "great_facial_variations"}, {"score": 0.004278807087784626, "phrase": "viewpoint_changes"}, {"score": 0.004149792080414689, "phrase": "classical_methods"}, {"score": 0.0041136473765874815, "phrase": "recent_learning"}, {"score": 0.00407781620412982, "phrase": "regression-based_approaches"}, {"score": 0.0038692638652494697, "phrase": "facial_variations"}, {"score": 0.0035605741849764187, "phrase": "characteristic_number"}, {"score": 0.0032336801561165113, "phrase": "strong_shape_priors"}, {"score": 0.0032054891061528896, "phrase": "cn_statistics"}, {"score": 0.0031636612155559267, "phrase": "moderate_size"}, {"score": 0.0030951536886513567, "phrase": "frontal_upright_faces"}, {"score": 0.0030148941188459987, "phrase": "intrinsic_geometries"}, {"score": 0.0029755458462182565, "phrase": "human_faces"}, {"score": 0.0028857130140890787, "phrase": "simple_appearance"}, {"score": 0.0028731024405707277, "phrase": "based_constraints"}, {"score": 0.002737960968372391, "phrase": "quadratic_optimization"}, {"score": 0.0026552818091968543, "phrase": "facial_point"}, {"score": 0.0025750928944698673, "phrase": "standard_gradient_descent"}, {"score": 0.0023902621773166963, "phrase": "projective_transformations"}, {"score": 0.0023694065215394593, "phrase": "extensive_experiments"}, {"score": 0.0023384629381463054, "phrase": "labeled_faces"}, {"score": 0.002218668420806254, "phrase": "helen_database"}, {"score": 0.0021049977753042253, "phrase": "cn-based_shape"}], "paper_keywords": ["Fiducial facial point extraction", " pose changes", " projective invariant", " characteristic number"], "paper_abstract": "Automatic extraction of fiducial facial points is one of the key steps to face tracking, recognition, and animation. Great facial variations, especially pose or viewpoint changes, typically degrade the performance of classical methods. Recent learning or regression-based approaches highly rely on the availability of a training set that covers facial variations as wide as possible. In this paper, we introduce and extend a novel projective invariant, named the characteristic number (CN), which unifies the collinearity, cross ratio, and geometrical characteristics given by more (6) points. We derive strong shape priors from CN statistics on a moderate size (515) of frontal upright faces in order to characterize the intrinsic geometries shared by human faces. We combine these shape priors with simple appearance based constraints, e.g., texture, edge, and corner, into a quadratic optimization. Thereafter, the solution to facial point extraction can be found by the standard gradient descent. The inclusion of these shape priors renders the robustness to pose changes owing to their invariance to projective transformations. Extensive experiments on the Labeled Faces in the Wild, Labeled Face Parts in the Wild and Helen database, and cross-set faces with various changes demonstrate the effectiveness of the CN-based shape priors compared with the state of the art.", "paper_title": "Fiducial Facial Point Extraction Using a Novel Projective Invariant", "paper_id": "WOS:000349774700010"}