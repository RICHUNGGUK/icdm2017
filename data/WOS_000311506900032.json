{"auto_keywords": [{"score": 0.029703842670749516, "phrase": "proposed_methods"}, {"score": 0.015719716506582538, "phrase": "ar_models"}, {"score": 0.004744437370338926, "phrase": "series_classification"}, {"score": 0.004539005582217309, "phrase": "large_margin_autoregressive"}, {"score": 0.004494570693993318, "phrase": "lmar"}, {"score": 0.004195418010131832, "phrase": "generative_ar_models"}, {"score": 0.004154332348800334, "phrase": "different_classes"}, {"score": 0.003896871009090446, "phrase": "optimization_criterion"}, {"score": 0.003479692058963528, "phrase": "single_ar_model"}, {"score": 0.0033452741392850523, "phrase": "mixture_model"}, {"score": 0.0032160319265621285, "phrase": "large_margin_mixture"}, {"score": 0.0030464123943266673, "phrase": "simulated_time_series_data"}, {"score": 0.002899965889623787, "phrase": "english_alphabet"}, {"score": 0.0028715299874549245, "phrase": "electroencephalogram_time_series_data"}, {"score": 0.0027200305495826797, "phrase": "support_vector_machine"}, {"score": 0.002693438626773467, "phrase": "svm"}, {"score": 0.00266693888510356, "phrase": "based_classifier"}, {"score": 0.0026277995163948263, "phrase": "ar_coefficients"}, {"score": 0.0026148807877309417, "phrase": "based_features"}, {"score": 0.002538687900036229, "phrase": "better_classification_performance"}, {"score": 0.0024891269874339553, "phrase": "svm_based_classifier"}, {"score": 0.0024525907271610125, "phrase": "generative_models"}, {"score": 0.002416589459425828, "phrase": "lmar_and_lmmar_models"}, {"score": 0.0023811153883132536, "phrase": "generative_interpretation"}, {"score": 0.0023117182131967523, "phrase": "rejection_option"}, {"score": 0.0022777800735119405, "phrase": "high_risk_classification_tasks"}, {"score": 0.002157538586313944, "phrase": "novel_time_series_data"}], "paper_keywords": ["Large margin autoregressive model", " Large margin mixture autoregressive model", " Time series classification", " Outlier detection", " Rejection option", " Generative and discriminative hybrid models"], "paper_abstract": "In this paper, we propose the large margin autoregressive (LMAR) model for classification of time series patterns. The parameters of the generative AR models for different classes are estimated using the margin of the boundaries of AR models as the optimization criterion. Models that use a mixture of AR (MAR) models are considered for representing the data that cannot be adequately represented using a single AR model for a class. Based on a mixture model representing each class, we propose the large margin mixture of AR (LMMAR) models. The proposed methods are applied on the simulated time series data, electrocardiogram data, speech data for E-set in English alphabet and electroencephalogram time series data. Performance of the proposed methods is compared with that of support vector machine (SVM) based classifier that uses AR coefficients based features. The proposed methods give a better classification performance compared to the SVM based classifier. Being generative models, the LMAR and LMMAR models provide a generative interpretation that enables utilization of the rejection option in the high risk classification tasks. The proposed methods can also be used for detection of novel time series data. (C) 2012 Elsevier B. V. All rights reserved.", "paper_title": "Large margin mixture of AR models for time series classification", "paper_id": "WOS:000311506900032"}