{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dialogue_acts"}, {"score": 0.0047517225918491226, "phrase": "prosodic_information"}, {"score": 0.004219369494932934, "phrase": "assessment"}, {"score": 0.004081385289516914, "phrase": "empirical_approach"}, {"score": 0.004027751272984522, "phrase": "manually_tagged_data"}, {"score": 0.003896717568943166, "phrase": "video_corpus"}, {"score": 0.0037699306119313154, "phrase": "cart-style_machine_learning_algorithm"}, {"score": 0.0033245147666408157, "phrase": "machine_learning_experiments"}, {"score": 0.0032376465741070274, "phrase": "first_stage"}, {"score": 0.0031950646670695546, "phrase": "human_annotators"}, {"score": 0.003153041030690117, "phrase": "dialogue_act_taggings"}, {"score": 0.003091036449708673, "phrase": "formal_methodology"}, {"score": 0.003010250522930773, "phrase": "highly_enough_tagging_agreement"}, {"score": 0.002931569771634119, "phrase": "kappa_statistics"}, {"score": 0.0028549396580672417, "phrase": "second_stage"}, {"score": 0.0028173769301594745, "phrase": "tagging_data"}, {"score": 0.0027256122357680393, "phrase": "decision_trees"}, {"score": 0.002689746491842271, "phrase": "preliminary_results"}, {"score": 0.002636828502928141, "phrase": "intonation_information"}, {"score": 0.0025509294021449254, "phrase": "sentence_mood"}, {"score": 0.00250073564820402, "phrase": "sentence_mood_and_utterance_duration_data"}, {"score": 0.0023894019651849482, "phrase": "precision"}, {"score": 0.0023251547402978164, "phrase": "kappa"}, {"score": 0.0022641658133181115, "phrase": "predictive_model"}, {"score": 0.0021330830123432614, "phrase": "automatic_speech_recognition"}, {"score": 0.0021049977753042253, "phrase": "dialogue_management_systems"}], "paper_keywords": [""], "paper_abstract": "In this paper, the influence of intonation to recognize dialogue acts from speech is assessed. Assessment is based on an empirical approach: manually tagged data from a spoken-dialogue and video corpus are used in a CART-style machine learning algorithm to produce a predictive model. Our approach involves two general stages: the tagging task, and the development of machine learning experiments. In the first stage, human annotators produce dialogue act taggings using a formal methodology, obtaining a highly enough tagging agreement, measured with Kappa statistics. In the second stage, tagging data are used to generate decision trees. Preliminary results show that intonation information is useful to recognize sentence mood, and sentence mood and utterance duration data contribute to recognize dialogue act. Precision, recall and Kappa values of the predictive model are promising. Our model can contribute to improve automatic speech recognition or dialogue management systems.", "paper_title": "Predicting dialogue acts from prosodic information", "paper_id": "WOS:000236109700037"}