{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "spectral_k-means"}, {"score": 0.012128966894016683, "phrase": "proposed_framework"}, {"score": 0.004778031885668542, "phrase": "efficient_bootstrap_accuracy_estimations"}, {"score": 0.0047292449487169345, "phrase": "distributed_clustering"}, {"score": 0.004597622380240611, "phrase": "central_concern"}, {"score": 0.004574085781766281, "phrase": "data_mining_researchers"}, {"score": 0.004492648247988178, "phrase": "rapid_increase"}, {"score": 0.004469646630310921, "phrase": "data_storage_capacities"}, {"score": 0.00421340730888561, "phrase": "sufficiently_accurate_models"}, {"score": 0.004012803888284523, "phrase": "spectral_relaxation"}, {"score": 0.003961613484271729, "phrase": "sequential_sampling_framework"}, {"score": 0.00391107353999773, "phrase": "sample_size"}, {"score": 0.0038217146888983576, "phrase": "cluster_structure"}, {"score": 0.0036678472439508484, "phrase": "commonly_applied_principle"}, {"score": 0.0036490529923833884, "phrase": "data_mining_research"}, {"score": 0.003611751858608048, "phrase": "use_of_minimal_assumptions_concerning_the_data_generating_distribution"}, {"score": 0.00347522512377874, "phrase": "sequential_sampling_procedure"}, {"score": 0.0033957904376127187, "phrase": "matrix_perturbation_theory"}, {"score": 0.00332670230152448, "phrase": "main_focus"}, {"score": 0.003192700856094016, "phrase": "spectral_clustering"}, {"score": 0.0031681812424108214, "phrase": "proposed_sequential_sampling_framework"}, {"score": 0.0031116963435584982, "phrase": "distributed_clustering_problem"}, {"score": 0.003040545635016655, "phrase": "global_model"}, {"score": 0.0029940152559879817, "phrase": "distributed_network_nodes"}, {"score": 0.002971016979295967, "phrase": "main_challenge"}, {"score": 0.002910545717767559, "phrase": "bandwidth_constraints"}, {"score": 0.002836679611901583, "phrase": "distributed_clustering_algorithm"}, {"score": 0.002814886483566627, "phrase": "minimal_amount"}, {"score": 0.002800450565219743, "phrase": "network_load"}, {"score": 0.002743441412836047, "phrase": "proposed_approach"}, {"score": 0.0026806884201358515, "phrase": "minimal_sample_size"}, {"score": 0.0026261108615242557, "phrase": "accurate_clustering_model"}, {"score": 0.0025992391074270097, "phrase": "distributional_characteristics"}, {"score": 0.002393907896783117, "phrase": "crucial_effect"}, {"score": 0.0023755083111584815, "phrase": "required_amount"}, {"score": 0.0023271295783184698, "phrase": "proposed_algorithm"}, {"score": 0.0022914917245958647, "phrase": "statistical_estimation"}, {"score": 0.0022738775158524793, "phrase": "required_relative_sizes"}, {"score": 0.0022563983975689393, "phrase": "possible_values"}, {"score": 0.002233301265743633, "phrase": "unique_feature"}, {"score": 0.0022047613106966723, "phrase": "network_administrator"}, {"score": 0.0021821915946356168, "phrase": "economic_solution"}, {"score": 0.002159852420283463, "phrase": "crude_cluster_structure"}, {"score": 0.002121306567029367, "phrase": "excessive_network_resources"}], "paper_keywords": ["Asymptotic convergence", " bootstrapping", " clustering", " distributed clustering", " matrix perturbation theory", " sampling", " spectral"], "paper_abstract": "The scalability of learning algorithms has always been a central concern for data mining researchers, and nowadays, with the rapid increase in data storage capacities and availability, its importance has increased. To this end, sampling has been studied by several researchers in an effort to derive sufficiently accurate models using only small data fractions. In this article we focus on spectral k-means, that is, the k-means approximation as derived by the spectral relaxation, and propose a sequential sampling framework that iteratively enlarges the sample size until the k-means results (objective function and cluster structure) become indistinguishable from the asymptotic (infinite-data) output. In the proposed framework we adopt a commonly applied principle in data mining research that considers the use of minimal assumptions concerning the data generating distribution. This restriction imposes several challenges, mainly related to the efficiency of the sequential sampling procedure. These challenges are addressed using elements of matrix perturbation theory and statistics. Moreover, although the main focus is on spectral k-means, we also demonstrate that the proposed framework can be generalized to handle spectral clustering. The proposed sequential sampling framework is consecutively employed for addressing the distributed clustering problem, where the task is to construct a global model for data that resides in distributed network nodes. The main challenge in this context is related to the bandwidth constraints that are commonly imposed, thus requiring that the distributed clustering algorithm consumes a minimal amount of network load. This illustrates the applicability of the proposed approach, as it enables the determination of a minimal sample size that can be used for constructing an accurate clustering model that entails the distributional characteristics of the data. As opposed to the relevant distributed k-means approaches, our framework takes into account the fact that the choice of the number of clusters has a crucial effect on the required amount of communication. More precisely, the proposed algorithm is able to derive a statistical estimation of the required relative sizes for all possible values of k. This unique feature of our distributed clustering framework enables a network administrator to choose an economic solution that identifies the crude cluster structure of a dataset and not devote excessive network resources for identifying all the \"correct\" detailed clusters.", "paper_title": "A Sequential Sampling Framework for Spectral k-Means Based on Efficient Bootstrap Accuracy Estimations: Application to Distributed Clustering", "paper_id": "WOS:000307540800001"}