{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "tensor_factorization"}, {"score": 0.00471465954562773, "phrase": "information_retrieval_field"}, {"score": 0.004665296491645837, "phrase": "effective_and_efficient_extraction"}, {"score": 0.004568108391981922, "phrase": "large-scale_online_text_streams"}, {"score": 0.004402854153653114, "phrase": "fully_unsupervised_learning_task"}, {"score": 0.004133292222875435, "phrase": "text_corpus"}, {"score": 0.00398370478688858, "phrase": "time_dimensions"}, {"score": 0.0039006600544599537, "phrase": "present_study"}, {"score": 0.003819339842998955, "phrase": "topic_detection"}, {"score": 0.0037594599958631404, "phrase": "temporal_optimization_problem"}, {"score": 0.003623352647973122, "phrase": "novel_approach"}, {"score": 0.0035853745478488254, "phrase": "incremental_topic_detection"}, {"score": 0.0032609360162842767, "phrase": "latent_dirichlet_allocation"}, {"score": 0.003028969851366049, "phrase": "current_time_slices"}, {"score": 0.0028886123801902517, "phrase": "time_dimension"}, {"score": 0.0026830601040919166, "phrase": "approximate_topics"}, {"score": 0.0025318431634446426, "phrase": "corresponding_topic_bins"}, {"score": 0.0024017638230939514, "phrase": "temporal_topic_detection"}, {"score": 0.002326938965568362, "phrase": "theoretical_analyses"}, {"score": 0.0023025177990160487, "phrase": "simulation_experiments"}, {"score": 0.0022783523466965187, "phrase": "otd-tf"}, {"score": 0.002207363758847308, "phrase": "space_and_time_complexity"}, {"score": 0.0021612684684351974, "phrase": "high_precision_ratio"}, {"score": 0.0021049977753042253, "phrase": "interesting_temporal_patterns"}], "paper_keywords": ["LDA", " tensor factorization", " topic detection", " topic tensor"], "paper_abstract": "In the information retrieval field, effective and efficient extraction of topics from large-scale online text streams is challenging because it is a fully unsupervised learning task without prior knowledge. Most previous studies have focused on how to analyse text corpus to extract topics, rarely considering time dimensions. In the present study, we approached topic detection as a temporal optimization problem. Here, we propose a novel approach to incremental topic detection, called online topic detection using tensor factorization (OTD-TF), which is based on latent Dirichlet allocation (LDA). First, topics are obtained from the corpus in current time slices using LDA. Second, a topic tensor with a time dimension is constructed to identify the correlations between pairs of topics. Then, approximate topics are merged using TF. Finally, documents are reallocated to corresponding topic bins. By executing these steps continuously and incrementally, temporal topic detection can be achieved. In theoretical analyses and simulation experiments, OTD-TF outperformed other systems in terms of space and time complexity and achieved a high precision ratio. Our experimental evaluations also revealed interesting temporal patterns in topic emergence, development, extinction, burst and transience.", "paper_title": "LDA-based online topic detection using tensor factorization", "paper_id": "WOS:000321979300003"}