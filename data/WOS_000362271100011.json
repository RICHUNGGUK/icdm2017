{"auto_keywords": [{"score": 0.049100450513748305, "phrase": "immersive_gestural_interaction"}, {"score": 0.00481495049065317, "phrase": "direct_hand"}, {"score": 0.0045726187330434025, "phrase": "novel_approach"}, {"score": 0.00450231514359539, "phrase": "intuitive_gesture"}, {"score": 0.004410248125081398, "phrase": "depth_data"}, {"score": 0.0043424487907572, "phrase": "kinect"}, {"score": 0.004275650416511604, "phrase": "main_challenge"}, {"score": 0.0041666157975446564, "phrase": "dynamic_gesture_recognition"}, {"score": 0.0038959121068990517, "phrase": "gesture_recognition"}, {"score": 0.0037381083634085424, "phrase": "fast_and_robust_pose_estimation_method"}, {"score": 0.0036052633308076933, "phrase": "great_extent"}, {"score": 0.003459191419478298, "phrase": "direct_method"}, {"score": 0.0034236045013591437, "phrase": "real-time_hand_pose_estimation"}, {"score": 0.003336225354214798, "phrase": "range_images"}, {"score": 0.0032848684681050745, "phrase": "new_version"}, {"score": 0.0032510690712452147, "phrase": "optical_flow_constraint_equation"}, {"score": 0.0029467742734417255, "phrase": "extensive_experiments"}, {"score": 0.0028864239961184364, "phrase": "proposed_approach"}, {"score": 0.0027982016314450717, "phrase": "high_accuracy"}, {"score": 0.002643386043540555, "phrase": "system_performance"}, {"score": 0.0025625729433234623, "phrase": "desktop_computing"}, {"score": 0.0025230952890994236, "phrase": "mobile_platform"}, {"score": 0.0024586427394152196, "phrase": "system_capability"}, {"score": 0.002420762293555924, "phrase": "different_interaction_procedures"}, {"score": 0.0023467391904246834, "phrase": "user_study"}, {"score": 0.00226322835801988, "phrase": "user_experience"}, {"score": 0.0022399174232611853, "phrase": "interaction_quality"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Immersive gestural interaction", " Dynamic gesture recognition", " Hand pose estimation"], "paper_abstract": "This paper presents a novel approach for performing intuitive gesture based interaction using depth data acquired by Kinect. The main challenge to enable immersive gestural interaction is dynamic gesture recognition. This problem can be formulated as a combination of two tasks; gesture recognition and gesture pose estimation. Incorporation of fast and robust pose estimation method would lessen the burden to a great extent. In this paper we propose a direct method for real-time hand pose estimation. Based on the range images, a new version of optical flow constraint equation is derived, which can be utilized to directly estimate 3D hand motion without any need of imposing other constraints. Extensive experiments illustrate that the proposed approach performs properly in real-time with high accuracy. As a proof of concept, we demonstrate the system performance in 3D object manipulation On two different setups; desktop computing, and mobile platform. This reveals the system capability to accommodate different interaction procedures. In addition, a user study is conducted to evaluate learnability, user experience and interaction quality in 3D gestural interaction in comparison to 2D touchscreen interaction. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Direct hand pose estimation for immersive gestural interaction", "paper_id": "WOS:000362271100011"}