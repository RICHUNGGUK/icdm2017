{"auto_keywords": [{"score": 0.04885877600670675, "phrase": "code_mistakes"}, {"score": 0.00481495049065317, "phrase": "random_and_designed_tests"}, {"score": 0.004612147352416241, "phrase": "scientific_software"}, {"score": 0.004456044928556639, "phrase": "computational_software"}, {"score": 0.004195418010131832, "phrase": "multiple_factors"}, {"score": 0.003916098498242888, "phrase": "test_output"}, {"score": 0.0036553070575015344, "phrase": "code_mistake"}, {"score": 0.003471135453226184, "phrase": "code_structure"}, {"score": 0.003296212583539166, "phrase": "test_input"}, {"score": 0.003130077012135034, "phrase": "randomly_generated_test_input"}, {"score": 0.0030501665085457606, "phrase": "viable_approach"}, {"score": 0.0028715299874549245, "phrase": "simple_structural_metrics"}, {"score": 0.0024586427394152196, "phrase": "expected_test_output"}, {"score": 0.002236055625099805, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Software testing", " Tolerance problem", " Random testing", " Computational software"], "paper_abstract": "Successfully testing computational software to detect code mistakes is impacted by multiple factors. One factor is the tolerance accepted in test output. Other factors are the nature of the code mistake, the characteristics of the code structure, and the choice of test input. We have found that randomly generated test input is a viable approach to testing for code mistakes and that simple structural metrics have little predictive power in the type of testing required. We provide further evidence that reduction of tolerance in expected test output has a much larger impact than running many more tests to discover code mistakes. Crown Copyright (C) 2011 Published by Elsevier B.V. All rights reserved.", "paper_title": "Examining random and designed tests to detect code mistakes in scientific software", "paper_id": "WOS:000208808100006"}