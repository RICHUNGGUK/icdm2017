{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dynamic_environments"}, {"score": 0.00950902318310618, "phrase": "goal_net_model"}, {"score": 0.008255881259246126, "phrase": "possible_solutions"}, {"score": 0.004534917050845832, "phrase": "significant_roles"}, {"score": 0.0044219147356791225, "phrase": "human_beings"}, {"score": 0.0042308653646339405, "phrase": "intelligent_agents"}, {"score": 0.0041384457437123635, "phrase": "soft_copy"}, {"score": 0.0038365781437074017, "phrase": "computer_games"}, {"score": 0.003776504983530801, "phrase": "optimal_solution"}, {"score": 0.0036823310827576628, "phrase": "recursive_algorithm"}, {"score": 0.003297080148944292, "phrase": "new_solution"}, {"score": 0.0032659907152779765, "phrase": "world's_change"}, {"score": 0.0031247264362609614, "phrase": "exact_outcome"}, {"score": 0.0027278178983579085, "phrase": "reorganization_algorithm"}, {"score": 0.0026850589169993143, "phrase": "goal_net"}, {"score": 0.00264296841319955, "phrase": "q-learning_algorithm"}, {"score": 0.002560751416355291, "phrase": "key_component"}, {"score": 0.0024654516678953658, "phrase": "goal_nets"}, {"score": 0.0023144166368024603, "phrase": "learning_algorithm"}, {"score": 0.0022637650216685906, "phrase": "recursive_searching_algorithm"}, {"score": 0.0022142194702079866, "phrase": "agent_model"}, {"score": 0.0021657559361692494, "phrase": "dynamic_time-sensitive_domain"}, {"score": 0.0021049977753042253, "phrase": "online_movie_watching"}], "paper_keywords": ["Agent", " Goal net", " Planning", " Machine learning", " Q-learning", " Aggregation operators"], "paper_abstract": "In psychology, goal-setting theory, which has been studied by psychologists for over 35 years, reveals that goals play significant roles in incentive, action and performance for human beings. Based on this theory, a goal net model has been proposed to design intelligent agents that can be viewed as a soft copy of human being somehow. The goal net model has been successfully applied in many agents, specially, non-player-character agents in computer games. Such an agent selects the optimal solution in all possible solutions found by using a recursive algorithm. However, if a goal net is very complex, the time of selection could be too long for the agent to respond quickly when the agent needs to re-select a new solution against the world's change. Moreover, in some dynamic environments, it is impossible to know the exact outcome of choosing a solution in advance, and so the possible solutions cannot be evaluated precisely. Thus, to address the problem, this paper applies learning algorithm into goal selection in dynamic environments. More specifically, we first develop a reorganization algorithm that can convert a goal net to its equivalent counterpart that a Q-learning algorithm can operate on; then, we define the key component of Q-learning, reward function, according to the feature of goal nets; and finally lots of experiments are conducted to show that, in dynamic environments, the agent with the learning algorithm significantly outperforms the one with the recursive searching algorithm. Therefore, our work suggests an agent model that can effectively be applied in dynamic time-sensitive domain, like computer games and the P2P systems of online movie watching.", "paper_title": "Adaptive goal selection for agents in dynamic environments", "paper_id": "WOS:000326936100007"}