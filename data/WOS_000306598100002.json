{"auto_keywords": [{"score": 0.04695140669556016, "phrase": "whole-frame_losses"}, {"score": 0.00481495049065317, "phrase": "frame_dropping_methods"}, {"score": 0.004681525814235883, "phrase": "visual_effect"}, {"score": 0.00462919213721188, "phrase": "whole-frame_loss"}, {"score": 0.004376131419366239, "phrase": "compressed_videos"}, {"score": 0.004183638135671596, "phrase": "different_common_concealment_effects"}, {"score": 0.003888659470009222, "phrase": "human_observers"}, {"score": 0.003266201217790818, "phrase": "b_frame_losses"}, {"score": 0.00305285084207725, "phrase": "simple_predictive_features"}, {"score": 0.0028214413724451442, "phrase": "original_video"}, {"score": 0.0027741761880779535, "phrase": "pixel_level_reconstruction"}, {"score": 0.0025638362414466278, "phrase": "whole_b_frame_losses"}, {"score": 0.0023827927890399357, "phrase": "visual_impact"}, {"score": 0.0023428586429492713, "phrase": "frame_loss"}, {"score": 0.0023035922232490106, "phrase": "intelligent_frame"}, {"score": 0.0022522565004588113, "phrase": "network_congestion"}, {"score": 0.0021288561076024844, "phrase": "random_dropping"}, {"score": 0.0021049977753042253, "phrase": "b_frames"}], "paper_keywords": ["Packet dropping policy", " packet loss", " perceptual video quality", " visibility model"], "paper_abstract": "We examine the visual effect of whole-frame loss by different decoders. Whole-frame losses are introduced in H.264/AVC compressed videos which are then decoded by two different decoders with different common concealment effects: frame copy and frame interpolation. The videos are seen by human observers who respond to each glitch they spot. We found that about 39% of whole-frame losses of B frames are not observed by any of the subjects, and over 58% of the B frame losses are observed by 20% or fewer of the subjects. Using simple predictive features that can be calculated inside a network node with no access to the original video and no pixel level reconstruction of the frame, we develop models that can predict the visibility of whole B frame losses. The models are then used in a router to predict the visual impact of a frame loss and perform intelligent frame dropping to relieve network congestion. Dropping frames based on their visual scores proves superior to random dropping of B frames.", "paper_title": "Network-Based H.264/AVC Whole-Frame Loss Visibility Model and Frame Dropping Methods", "paper_id": "WOS:000306598100002"}