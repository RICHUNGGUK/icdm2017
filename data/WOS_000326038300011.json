{"auto_keywords": [{"score": 0.03370484936008852, "phrase": "cuda"}, {"score": 0.032664372666329364, "phrase": "fcuda"}, {"score": 0.030678021556908346, "phrase": "autopilot"}, {"score": 0.00481495049065317, "phrase": "cuda_kernels_for_high-performance_computing"}, {"score": 0.004681012408089219, "phrase": "multicore_architectures"}, {"score": 0.004624751696958501, "phrase": "computing_domains"}, {"score": 0.004514241562580097, "phrase": "heterogeneous_multiprocessors"}, {"score": 0.004424160689087029, "phrase": "different_compute_characteristics"}, {"score": 0.00421520166010848, "phrase": "different_application_kernels"}, {"score": 0.00398380712846857, "phrase": "compute-intensive_kernels"}, {"score": 0.0038417798012011155, "phrase": "parallel_processing"}, {"score": 0.003810909603178837, "phrase": "heterogeneous_systems"}, {"score": 0.0036898803847106023, "phrase": "computing_community"}, {"score": 0.003431384878608803, "phrase": "programming_effort"}, {"score": 0.0033764382987428497, "phrase": "accelerator_models"}, {"score": 0.003114584448820957, "phrase": "new_fpga_design_flow"}, {"score": 0.00301560261110296, "phrase": "coarse-and_fine-grained_parallelism"}, {"score": 0.0029434299787644445, "phrase": "reconfigurable_fabric"}, {"score": 0.0027592838876116816, "phrase": "xilinx"}, {"score": 0.0027150658583211746, "phrase": "high-abstraction_fpga_programming"}, {"score": 0.002639385610609024, "phrase": "source-to-source_compilation"}, {"score": 0.002597089381491382, "phrase": "simt"}, {"score": 0.0024842242921857705, "phrase": "task-level_parallel_c_code"}, {"score": 0.0023099954987126, "phrase": "resulting_customized_fpga_multicore_accelerators"}, {"score": 0.0022095803687183107, "phrase": "first_cuda-to-fpga_flow"}, {"score": 0.0021566565951738658, "phrase": "potential_advantage"}, {"score": 0.0021220787047953093, "phrase": "cuda_programming_model"}, {"score": 0.0021049977753042253, "phrase": "high-performance_computing"}], "paper_keywords": ["Design", " Performance", " FPGA", " high-level synthesis", " parallel programming model", " high-performance computing", " source-to-source compiler", " heterogeneous compute systems"], "paper_abstract": "The rise of multicore architectures across all computing domains has opened the door to heterogeneous multiprocessors, where processors of different compute characteristics can be combined to effectively boost the performance per watt of different application kernels. GPUs, in particular, are becoming very popular for speeding up compute-intensive kernels of scientific, imaging, and simulation applications. New programming models that facilitate parallel processing on heterogeneous systems containing GPUs are spreading rapidly in the computing community. By leveraging these investments, the developers of other accelerators have an opportunity to significantly reduce the programming effort by supporting those accelerator models already gaining popularity. In this work, we adapt one such language, the CUDA programming model, into a new FPGA design flow called FCUDA, which efficiently maps the coarse-and fine-grained parallelism exposed in CUDA onto the reconfigurable fabric. Our CUDA-to-FPGA flow employs AutoPilot, an advanced high-level synthesis tool (available from Xilinx) which enables high-abstraction FPGA programming. FCUDA is based on a source-to-source compilation that transforms the SIMT (Single Instruction, Multiple Thread) CUDA code into task-level parallel C code for AutoPilot. We describe the details of our CUDA-to-FPGA flow and demonstrate the highly competitive performance of the resulting customized FPGA multicore accelerators. To the best of our knowledge, this is the first CUDA-to-FPGA flow to demonstrate the applicability and potential advantage of using the CUDA programming model for high-performance computing in FPGAs.", "paper_title": "Efficient Compilation of CUDA Kernels for High-Performance Computing on FPGAs", "paper_id": "WOS:000326038300011"}