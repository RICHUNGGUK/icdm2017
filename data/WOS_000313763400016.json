{"auto_keywords": [{"score": 0.03869898982926289, "phrase": "target_task"}, {"score": 0.015589848469957961, "phrase": "semi-supervised_extension"}, {"score": 0.014052965353091262, "phrase": "labeled_data"}, {"score": 0.012824706019532419, "phrase": "transfer-learning_setting"}, {"score": 0.011653889396688976, "phrase": "multitask_metric_learning"}, {"score": 0.009741326769881391, "phrase": "tml"}, {"score": 0.008174146766983272, "phrase": "unlabeled_data"}, {"score": 0.00481495049065317, "phrase": "transfer_metric_learning"}, {"score": 0.00471503739362446, "phrase": "metric_learning"}, {"score": 0.004390517953424082, "phrase": "good_metric"}, {"score": 0.0038549394272661356, "phrase": "related_source_tasks"}, {"score": 0.003589404014552974, "phrase": "convex_formulation"}, {"score": 0.0035001037990786727, "phrase": "task_relationships"}, {"score": 0.0034130176595901104, "phrase": "task_covariance_matrix"}, {"score": 0.0033420978105332686, "phrase": "transfer_learning"}, {"score": 0.00330025288273863, "phrase": "special_case"}, {"score": 0.0032726467814278345, "phrase": "multitask_learning"}, {"score": 0.002873038567884343, "phrase": "task_covariances"}, {"score": 0.0028370498057725796, "phrase": "source_tasks"}, {"score": 0.002766415324343602, "phrase": "unified_convex_formulation"}, {"score": 0.0027088948471991454, "phrase": "convex_optimization_problem"}, {"score": 0.0026525671788921205, "phrase": "alternating_method"}, {"score": 0.002575665611013556, "phrase": "efficient_solution"}, {"score": 0.002318728604587962, "phrase": "stml"}, {"score": 0.002270495425498003, "phrase": "generalization_performance"}, {"score": 0.0021953959824690316, "phrase": "manifold_assumption"}, {"score": 0.0021770116505684394, "phrase": "experimental_results"}, {"score": 0.002149722786728988, "phrase": "commonly_used_transfer-learning_applications"}], "paper_keywords": ["Algorithms", " Metric learning", " transfer learning", " multitask learning", " semi-supervised learning"], "paper_abstract": "Distance metric learning plays a very crucial role in many data mining algorithms because the performance of an algorithm relies heavily on choosing a good metric. However, the labeled data available in many applications is scarce, and hence the metrics learned are often unsatisfactory In this article, we consider a transfer-learning setting in which some related source tasks with labeled data are available to help the learning of the target task. We first propose a convex formulation for multitask metric learning by modeling the task relationships in the form of a task covariance matrix. Then we regard transfer learning as a special case of multitask learning and adapt the formulation of multitask metric learning to the transfer-learning setting for our method, called transfer metric learning (TML). In TML, we learn the metric and the task covariances between the source tasks and the target task under a unified convex formulation. To solve the convex optimization problem, we use an alternating method in which each subproblem has an efficient solution. Moreover, in many applications, some unlabeled data is also available in the target task, and so we propose a semi-supervised extension of TML called STML to further improve the generalization performance by exploiting the unlabeled data based on the manifold assumption. Experimental results on some commonly used transfer-learning applications demonstrate the effectiveness of our method.", "paper_title": "Transfer Metric Learning with Semi-Supervised Extension", "paper_id": "WOS:000313763400016"}