{"auto_keywords": [{"score": 0.03084720274853471, "phrase": "epi"}, {"score": 0.00481495049065317, "phrase": "multiterminal_information-theoretic_problems"}, {"score": 0.004440277230269978, "phrase": "new_extremal_inequality"}, {"score": 0.004094639048362357, "phrase": "vector_gaussian_broadcast_channel"}, {"score": 0.003900257249255497, "phrase": "distributed_source_coding"}, {"score": 0.0037150687722055727, "phrase": "single_quadratic_distortion_constraint_problems"}, {"score": 0.0030086877092638945, "phrase": "classical_entropy-power_inequality"}], "paper_keywords": ["differential entropy", " distributed source coding", " entropy-power inequality (EPT)", " Fisher information", " vector Gaussian broadcast channel"], "paper_abstract": "We prove a new extremal inequality, motivated by the vector Gaussian broadcast channel and the distributed source coding with a single quadratic distortion constraint problems. As a corollary, this inequality yields a generalization of the classical entropy-power inequality (EPI). As another corollary, this inequality sheds insight into maximizing the differential entropy of the sum of two dependent random variables.", "paper_title": "An extremal inequality motivated by multiterminal information-theoretic problems", "paper_id": "WOS:000246034600017"}