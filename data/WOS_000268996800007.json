{"auto_keywords": [{"score": 0.04162715718691742, "phrase": "gdr"}, {"score": 0.010193216037683592, "phrase": "ldr"}, {"score": 0.010074274008682002, "phrase": "adr"}, {"score": 0.00481495049065317, "phrase": "evaluating_dimensionality_reduction"}, {"score": 0.004777214679969785, "phrase": "high-dimensional_spaces"}, {"score": 0.004647442352794694, "phrase": "serious_problem"}, {"score": 0.004592905436175987, "phrase": "high-dimensional_space"}, {"score": 0.004312622975366672, "phrase": "retrieval_efficiency"}, {"score": 0.004178935413340453, "phrase": "entire_data"}, {"score": 0.0041136473765874815, "phrase": "fixed_lower_value"}, {"score": 0.004081385289516914, "phrase": "building_indexes"}, {"score": 0.004001828274595483, "phrase": "global_dimensionality_reduction"}, {"score": 0.003757480190200645, "phrase": "different_values"}, {"score": 0.003541923233726252, "phrase": "random_projection"}, {"score": 0.003472845095323694, "phrase": "approximate_dimensionality_reduction"}, {"score": 0.0033651019362620866, "phrase": "approximate_similarity_search"}, {"score": 0.0030374213037172803, "phrase": "range_query"}, {"score": 0.002897109710213723, "phrase": "general_cost_models"}, {"score": 0.002851790448644913, "phrase": "query_performance"}, {"score": 0.00281826552772148, "phrase": "reduced_data_sets"}, {"score": 0.0025436978068459565, "phrase": "randomized_search"}, {"score": 0.002464709648714996, "phrase": "high_retrieval_efficiency"}, {"score": 0.0023787690061742566, "phrase": "formal_models"}, {"score": 0.002286781334850213, "phrase": "reduced_partitions"}, {"score": 0.002268814162496699, "phrase": "fast_similarity_search"}, {"score": 0.0022509878391826867, "phrase": "extensive_experiments"}, {"score": 0.002181069180139225, "phrase": "real_and_synthetic_data_sets"}, {"score": 0.0021049977753042253, "phrase": "proposed_prans_method"}], "paper_keywords": ["High-dimensionality reduction", " similarity search"], "paper_abstract": "Similarity search usually encounters a serious problem in the high-dimensional space, known as the \"curse of dimensionality.\" In order to speed up the retrieval efficiency, most previous approaches reduce the dimensionality of the entire data set to a fixed lower value before building indexes (referred to as global dimensionality reduction (GDR)). More recent works focus on locally reducing the dimensionality of data to different values (called the local dimensionality reduction (LDR)). In addition, random projection is proposed as an approximate dimensionality reduction (ADR) technique to answer the approximate similarity search instead of the exact one. However, so far little work has formally evaluated the effectiveness and efficiency of GDR, LDR, and ADR for the range query. Motivated by this, in this paper, we propose general cost models for evaluating the query performance over the reduced data sets by GDR, LDR, and ADR, in light of which we introduce a novel (A) LDR method, Partitioning based on RANdomized Search (PRANS). It can achieve high retrieval efficiency with the guarantee of optimality given by the formal models. Finally, a B(+)-tree index is constructed over the reduced partitions for fast similarity search. Extensive experiments validate the correctness of our cost models on both real and synthetic data sets and demonstrate the efficiency and effectiveness of the proposed PRANS method.", "paper_title": "General Cost Models for Evaluating Dimensionality Reduction in High-Dimensional Spaces", "paper_id": "WOS:000268996800007"}