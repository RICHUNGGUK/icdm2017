{"auto_keywords": [{"score": 0.027723525233449356, "phrase": "bayes"}, {"score": 0.00481495049065317, "phrase": "f-measure_maximizers"}, {"score": 0.004579147045265106, "phrase": "information_retrieval"}, {"score": 0.004414907432703781, "phrase": "performance_metric"}, {"score": 0.004315249628884236, "phrase": "binary_classification"}, {"score": 0.004276016541197123, "phrase": "multi-label_classification"}, {"score": 0.0042178318724732005, "phrase": "structured_output_prediction"}, {"score": 0.004085115444878828, "phrase": "statistically_and_computationally_challenging_problem"}, {"score": 0.0040111533608228195, "phrase": "closed-form_solution"}, {"score": 0.003920573616298175, "phrase": "decision-theoretic_perspective"}, {"score": 0.003814563533445401, "phrase": "formal_and_experimental_analysis"}, {"score": 0.0035945701438887282, "phrase": "bayes-risk_analysis"}, {"score": 0.003561865840737996, "phrase": "related_loss_functions"}, {"score": 0.00349734405943853, "phrase": "hamming_loss"}, {"score": 0.003449718244515019, "phrase": "zero-one_loss"}, {"score": 0.0032211117623834828, "phrase": "high_worst-case_regret"}, {"score": 0.003119659433566212, "phrase": "similar_type"}, {"score": 0.0028863414975346512, "phrase": "additional_assumptions"}, {"score": 0.0028470123663391104, "phrase": "statistical_distribution"}, {"score": 0.0028082176224611542, "phrase": "binary_response_variables"}, {"score": 0.0027197343489967322, "phrase": "new_algorithm"}, {"score": 0.002527788827701828, "phrase": "underlying_distribution"}, {"score": 0.0023173287402646577, "phrase": "binary_responses"}, {"score": 0.002244277924422011, "phrase": "joint_distribution"}, {"score": 0.002193509835371438, "phrase": "practical_performance"}, {"score": 0.002163600705898299, "phrase": "analyzed_methods"}, {"score": 0.0021049977753042253, "phrase": "multi-label_classification_problems"}], "paper_keywords": ["F-measure", " Bayes-optimal predictions", " regret", " statistical decision theory", " multi-label classification", " structured output prediction"], "paper_abstract": "The F-measure, which has originally been introduced in information retrieval, is nowadays routinely used as a performance metric for problems such as binary classification, multi-label classification, and structured output prediction. Optimizing this measure is a statistically and computationally challenging problem, since no closed-form solution exists. Adopting a decision-theoretic perspective, this article provides a formal and experimental analysis of different approaches for maximizing the F-measure. We start with a Bayes-risk analysis of related loss functions, such as Hamming loss and subset zero-one loss, showing that optimizing such losses as a surrogate of the F-measure leads to a high worst-case regret. Subsequently, we perform a similar type of analysis for F-measure maximizing algorithms, showing that such algorithms are approximate, while relying on additional assumptions regarding the statistical distribution of the binary response variables. Furthermore, we present a new algorithm which is not only computationally efficient but also Bayes-optimal, regardless of the underlying distribution. To this end, the algorithm requires only a quadratic (with respect to the number of binary responses) number of parameters of the joint distribution. We illustrate the practical performance of all analyzed methods by means of experiments with multi-label classification problems.", "paper_title": "On the Bayes-Optimality of F-Measure Maximizers", "paper_id": "WOS:000353126200001"}