{"auto_keywords": [{"score": 0.036229190503611196, "phrase": "mlnb"}, {"score": 0.00481495049065317, "phrase": "multi-label_naive_bayes_classification"}, {"score": 0.0047057084749407485, "phrase": "multi-label_learning"}, {"score": 0.004598933498016774, "phrase": "training_set"}, {"score": 0.003916098498242888, "phrase": "label_sets"}, {"score": 0.00385658790017119, "phrase": "unseen_instances"}, {"score": 0.0036553070575015344, "phrase": "learning_problem"}, {"score": 0.003334309053314909, "phrase": "traditional_naive_bayes_classifiers"}, {"score": 0.0032336801561165113, "phrase": "multi-label_instances"}, {"score": 0.0031845067058084583, "phrase": "feature_selection_mechanisms"}, {"score": 0.0029270797740550973, "phrase": "feature_extraction_techniques"}, {"score": 0.002860546817196148, "phrase": "principal_component_analysis"}, {"score": 0.0027529929913806066, "phrase": "irrelevant_and_redundant_features"}, {"score": 0.0026494723416072316, "phrase": "feature_subset_selection_techniques"}, {"score": 0.0025892330566358503, "phrase": "genetic_algorithms"}, {"score": 0.002325689073229477, "phrase": "synthetic_and_real-world_data"}, {"score": 0.0022382002476510573, "phrase": "comparable_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Multi-label learning", " Naive Bayes", " Feature selection", " Principal component analysis", " Genetic algorithm"], "paper_abstract": "In multi-label learning, the training set is made up of instances each associated with a set of labels, and the task is to predict the label sets of unseen instances. In this paper, this learning problem is addressed by using a method called MLNB which adapts the traditional naive Bayes classifiers to deal with multi-label instances. Feature selection mechanisms are incorporated into MLNB to improve its performance. Firstly, feature extraction techniques based on principal component analysis are applied to remove irrelevant and redundant features. After that, feature subset selection techniques based on genetic algorithms are used to choose the most appropriate subset of features for prediction. Experiments on synthetic and real-world data show that MLNB achieves comparable performance to other well-established multi-label learning algorithms. (C) 2009 Elsevier Inc. All rights reserved.", "paper_title": "Feature selection for multi-label naive Bayes classification", "paper_id": "WOS:000269116700002"}