{"auto_keywords": [{"score": 0.004818774790609053, "phrase": "input"}, {"score": 0.004451676867747938, "phrase": "test_case_prioritization"}, {"score": 0.004382364826200616, "phrase": "execution_priorities"}, {"score": 0.004314127287770832, "phrase": "test_cases"}, {"score": 0.004137288854115515, "phrase": "full-fledged_availability"}, {"score": 0.0040942189695983185, "phrase": "code_coverage_data"}, {"score": 0.004051595625804513, "phrase": "fault_history"}, {"score": 0.003988487841970088, "phrase": "test_specification"}, {"score": 0.0038049789989278463, "phrase": "real-world_software_development_projects"}, {"score": 0.0036873373225096624, "phrase": "novel_family"}, {"score": 0.0036489343475053187, "phrase": "input-based_local-beam-search_adaptive-randomized_techniques"}, {"score": 0.0034267429854665035, "phrase": "randomized_candidate_test_set_strategy"}, {"score": 0.0033381913087533457, "phrase": "search_space_explorations"}, {"score": 0.003234934827553253, "phrase": "exploration_trees"}, {"score": 0.0031678720736808574, "phrase": "test_inputs"}, {"score": 0.003118486096035156, "phrase": "test_suite"}, {"score": 0.0030378759123133644, "phrase": "validation_experiment"}, {"score": 0.002750056254309311, "phrase": "apfd"}, {"score": 0.0025824576209656676, "phrase": "search-based_prioritization_techniques"}, {"score": 0.0023012445103133524, "phrase": "greedy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Regression testing", " Adaptive test case prioritization", " Randomized algorithm"], "paper_abstract": "Test case prioritization assigns the execution priorities of the test cases in a given test suite. Many existing test case prioritization techniques assume the full-fledged availability of code coverage data, fault history, or test specification, which are seldom well-maintained in real-world software development projects. This paper proposes a novel family of input-based local-beam-search adaptive-randomized techniques. They make adaptive tree-based randomized explorations with a randomized candidate test set strategy to even out the search space explorations among the branches of the exploration trees constructed by the test inputs in the test suite. We report a validation experiment on a suite of four medium-size benchmarks. The results show that our techniques achieve either higher APFD values than or the same mean APFD values as the existing code-coverage-based greedy or search-based prioritization techniques, including Genetic, Greedy and ART, in both our controlled experiment and case study. Our techniques are also significantly more efficient than the Genetic and Greedy, but are less efficient than ART. (c) 2015 The Authors. Published by Elsevier Inc.", "paper_title": "Input-based adaptive randomized test case prioritization: A local beam search approach", "paper_id": "WOS:000355707300007"}