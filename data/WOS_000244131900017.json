{"auto_keywords": [{"score": 0.03122236713759626, "phrase": "fsm"}, {"score": 0.00481495049065317, "phrase": "novel_framework"}, {"score": 0.004767546015485477, "phrase": "automatic_lecture_video_editing"}, {"score": 0.004605258779434384, "phrase": "video_text_recognition"}, {"score": 0.004537401559396022, "phrase": "content_analysis"}, {"score": 0.00442651096522781, "phrase": "hand_movement"}, {"score": 0.0043183186953102805, "phrase": "intentional_gestures"}, {"score": 0.0038919354605673104, "phrase": "complex_lighting_conditions"}, {"score": 0.0035424245257172234, "phrase": "regional_focuses"}, {"score": 0.0034901729647741353, "phrase": "human_postures"}, {"score": 0.00320826350799124, "phrase": "text_recognition"}, {"score": 0.0031297538950335233, "phrase": "external_documents"}, {"score": 0.0029784342137867776, "phrase": "finite_state_machine"}, {"score": 0.0027925723953701083, "phrase": "general_editing_rules"}, {"score": 0.002657511557782467, "phrase": "novel_views"}, {"score": 0.0025541693207036167, "phrase": "appropriate_simulated_camera_motion"}, {"score": 0.0024306105794630246, "phrase": "presenter's_gestures"}, {"score": 0.0023476849595393872, "phrase": "undesirable_visual_effects"}, {"score": 0.0023130151703068444, "phrase": "poor_lighting_conditions"}, {"score": 0.0021365562685368767, "phrase": "whiteboard_images"}, {"score": 0.0021049977753042253, "phrase": "edited_videos"}], "paper_keywords": ["gesture", " lecture video editing", " posture and video text recognition"], "paper_abstract": "This paper describes a novel framework for automatic lecture video editing by gesture, posture, and video text recognition. In content analysis, the trajectory of hand movement is tracked and the intentional gestures are automatically extracted for recognition. In addition, head pose is estimated through overcoming the difficulties due to the complex lighting conditions in classrooms. The aim of recognition is to characterize the flow of lecturing with a series of regional focuses depicted by human postures and gestures. The regions of interest (ROIs) in videos are semantically structured with text recognition and the aid of external documents. By tracing the flow of lecturing, a finite state machine (FSM) which incorporates the gestures, postures, ROIs, general editing rules and constraints, is proposed to edit videos with novel views. The FSM is designed to generate appropriate simulated camera motion and cutting effects that suit the pace of a presenter's gestures and postures. To remedy the undesirable visual effects due to poor lighting conditions, we also propose approaches to automatically enhance the visibility and readability of slides and whiteboard images in the edited videos.", "paper_title": "Lecture video enhancement and editing by integrating posture, gesture, and text", "paper_id": "WOS:000244131900017"}