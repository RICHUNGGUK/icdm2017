{"auto_keywords": [{"score": 0.01412108396569739, "phrase": "simplified_decision_table"}, {"score": 0.01123733678146036, "phrase": "compacted_decision_table"}, {"score": 0.00481495049065317, "phrase": "compacted_decision_tables"}, {"score": 0.003057503388220776, "phrase": "attributes'_inner_significance"}, {"score": 0.002895986736522535, "phrase": "positive_region"}, {"score": 0.0027616550517346066, "phrase": "decision_table"}, {"score": 0.0025456716198597627, "phrase": "compacted_decision"}, {"score": 0.002237637525225501, "phrase": "attribute_reduction_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Feature selection", " Attribute reduction", " Rough set", " Decision table"], "paper_abstract": "This paper first points out that the reducts obtained from a simplified decision table are different from those obtained from its original version, and from a simplified decision table, we cannot obtain the reducts in the sense of entropies. To solve these problems, we propose the compacted decision table that can preserve all the information coming from its original version. We theoretically demonstrate that the order preserving of attributes' inner significance and outer significance in the sense of positive region and two types of entropies after a decision table is compacted, which ensures that the reducts obtained from a compacted decision are identical to those obtained from its original version. Finally, several numerical experiments indicate the effectiveness and efficiency of the attribute reduction algorithms for a compacted decision table. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Compacted decision tables based attribute reduction", "paper_id": "WOS:000359887400021"}