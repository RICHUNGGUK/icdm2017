{"auto_keywords": [{"score": 0.04606577986186261, "phrase": "simulated_anticipatory_behavior"}, {"score": 0.04577010928578612, "phrase": "adaptive_agents"}, {"score": 0.043328886442782925, "phrase": "simulation_hypothesis"}, {"score": 0.004815012705729753, "phrase": "affect"}, {"score": 0.00473477283457869, "phrase": "anticipatory_simulation"}, {"score": 0.004703075081891693, "phrase": "artificial_adaptive_agents"}, {"score": 0.004624751696958501, "phrase": "important_role"}, {"score": 0.0044870272550540415, "phrase": "affective_control"}, {"score": 0.004338784112167614, "phrase": "computational_model"}, {"score": 0.0042521895049768875, "phrase": "model-based_reinforcement_learning"}, {"score": 0.004223811087540838, "phrase": "rl"}, {"score": 0.00411167353669181, "phrase": "cotterill"}, {"score": 0.004056769841308405, "phrase": "hesslow"}, {"score": 0.003909522412849035, "phrase": "internal_simulation"}, {"score": 0.003780286517897356, "phrase": "overt_behavior"}, {"score": 0.0036553070575015344, "phrase": "artificial_agent"}, {"score": 0.0036186222999811802, "phrase": "action-selection_bias"}, {"score": 0.003558294449586273, "phrase": "affect-controlled_amount"}, {"score": 0.0034290777464571864, "phrase": "affect-controlled_simulation-selection_mechanism"}, {"score": 0.0033492947290751996, "phrase": "agent's_rl_model"}, {"score": 0.0033156708990372047, "phrase": "anticipatory_behaviors"}, {"score": 0.002878785759716458, "phrase": "positive_affect"}, {"score": 0.0027929100418926725, "phrase": "best_potential_next_action"}, {"score": 0.00267335773670308, "phrase": "potential_next_actions"}, {"score": 0.002584879320145739, "phrase": "mental_exploration"}, {"score": 0.0024493494346360415, "phrase": "narrow_sense"}, {"score": 0.00241658945942583, "phrase": "working_memory_resources"}, {"score": 0.0023131084326717755, "phrase": "broad_sense"}, {"score": 0.0022744957687536307, "phrase": "working_memory"}, {"score": 0.0021049977753042253, "phrase": "positive_versus_negative_affect"}], "paper_keywords": ["affect", " action selection", " anticipatory simulation", " simulation selection", " working memory", " simulated adaptive agents"], "paper_abstract": "Emotion plays an important role in thinking. In this article we study affective control of the amount of simulated anticipatory behavior in adaptive agents using a computational model. Our approach is based on model-based reinforcement learning (RL) and inspired by the simulation hypothesis (Cotterill, 2001; Hesslow, 2002). The simulation hypothesis states that thinking is internal simulation of behavior using the same sensory-motor systems as those used for overt behavior. Here, we study the adaptiveness of an artificial agent, when action-selection bias is induced by an affect-controlled amount of simulated anticipatory behavior. To this end, we introduce an affect-controlled simulation-selection mechanism that uses the predictions of the agent's RL model to select anticipatory behaviors for simulation. Based on experiments with adaptive agents in two nondeterministic partially observable grid-worlds we conclude that (1) internal simulation has an adaptive benefit and (2) affective control can reduce the amount of simulation needed for this benefit. This is specifically the case if the following relation holds: positive affect decreases the amount of simulation towards simulating the best potential next action, while negative affect increases the amount of simulation towards simulating all potential next actions. In essence we use artificial affect to control mental exploration versus exploitations. Thus, agents \"feeling positive\" can think ahead in a narrow sense and free up working memory resources, while agents \"feeling negative\" must think ahead in a broad sense and maximize usage of working memory. Our results are consistent with several psychological findings on the relation between affect and learning, and contribute to answering the question of when positive versus negative affect is useful during adaptation.", "paper_title": "Affect, anticipation, and adaptation: Affect-controlled selection of anticipatory simulation in artificial adaptive agents", "paper_id": "WOS:000251368600003"}