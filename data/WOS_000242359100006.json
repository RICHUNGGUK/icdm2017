{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-robot_decision-making"}, {"score": 0.004635187610736025, "phrase": "mobile_robots"}, {"score": 0.004342430078306461, "phrase": "raw_sensor_inputs"}, {"score": 0.004157561334726201, "phrase": "resulting_primitive_actions"}, {"score": 0.003531474887552889, "phrase": "complete_vision-based_robotic_system"}, {"score": 0.0031845067058084583, "phrase": "particular_emphasis"}, {"score": 0.0028715299874549245, "phrase": "autonomous_color_calibration"}, {"score": 0.0028404241985421096, "phrase": "autonomous_sensor"}, {"score": 0.0028096544129939277, "phrase": "actuator_modeling"}, {"score": 0.002719325177422626, "phrase": "particle_filtering"}, {"score": 0.0026898636962522505, "phrase": "improved_localization"}, {"score": 0.0026607205525625995, "phrase": "legged_robots"}, {"score": 0.0025892330566358503, "phrase": "effective_planning"}, {"score": 0.0024923577071656014, "phrase": "goal-oriented_behavior"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["robotics", " planning under uncertainty", " robot vision", " localization", " multi-robot behavior"], "paper_abstract": "Mobile robots must cope with uncertainty from many sources along the path from interpreting raw sensor inputs to behavior selection to execution of the resulting primitive actions. This article identifies several such sources and introduces methods for (i) reducing uncertainty and (ii) making decisions in the face of uncertainty. We present a complete vision-based robotic system that includes several algorithms for learning models that are useful and necessary for planning, and then place particular emphasis on the planning and decision-making capabilities of the robot. Specifically, we present models for autonomous color calibration, autonomous sensor and actuator modeling, and an adaptation of particle filtering for improved localization on legged robots. These contributions enable effective planning under uncertainty for robots engaged in goal-oriented behavior within a dynamic, collaborative and adversarial environment. Each of our algorithms is fully implemented and tested on a commercial off-the-shelf vision-based quadruped robot. (C) 2006 Elsevier B.V. All rights reserved.", "paper_title": "From pixels to multi-robot decision-making: A study in uncertainty", "paper_id": "WOS:000242359100006"}