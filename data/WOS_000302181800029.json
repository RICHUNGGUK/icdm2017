{"auto_keywords": [{"score": 0.04768054909774768, "phrase": "input_images"}, {"score": 0.03608390790247671, "phrase": "feature_point"}, {"score": 0.03433183203055727, "phrase": "feature_points"}, {"score": 0.00481495049065317, "phrase": "super-resolution_without_dense_flow"}, {"score": 0.004703878334423852, "phrase": "widely_applied_technique"}, {"score": 0.00453144352814823, "phrase": "software_methods"}, {"score": 0.004304574865291508, "phrase": "input_frames"}, {"score": 0.004146716743362567, "phrase": "motion_estimation_result"}, {"score": 0.003994624397219346, "phrase": "optical_flow_estimation"}, {"score": 0.0038661089070527424, "phrase": "complicated_motion"}, {"score": 0.00379452936798156, "phrase": "real-world_videos"}, {"score": 0.0036382660173943393, "phrase": "new_way"}, {"score": 0.0035211747962710246, "phrase": "sparse_feature_point_correspondences"}, {"score": 0.0031036643805367487, "phrase": "dense_optical_flow_fields"}, {"score": 0.002989714021608139, "phrase": "well-selected_significant_locations"}, {"score": 0.0026974065918918275, "phrase": "sparse_correspondences"}, {"score": 0.0026722904884984348, "phrase": "conventional_super-resolution"}, {"score": 0.0026105159490849364, "phrase": "adaptive_support_region"}, {"score": 0.0025741370320813968, "phrase": "reliable_local_flow_field"}, {"score": 0.002538263784314365, "phrase": "corresponding_feature_point_pair"}, {"score": 0.002410942838102255, "phrase": "visual_consistency"}, {"score": 0.00237733844863506, "phrase": "reconstructed_result"}, {"score": 0.0023551955270737215, "phrase": "extensive_experiments"}, {"score": 0.002333258365963461, "phrase": "real_data"}, {"score": 0.002226592967032469, "phrase": "proposed_algorithm"}, {"score": 0.0022058510091498666, "phrase": "high-resolution_images"}, {"score": 0.0021049977753042253, "phrase": "large-scale_or_complicated_motion_fields"}], "paper_keywords": ["Feature point correspondence", " super-resolution reconstruction", " support region", " total variation (TV) prior"], "paper_abstract": "Super-resolution is a widely applied technique that improves the resolution of input images by software methods. Most conventional reconstruction-based super-resolution algorithms assume accurate dense optical flow fields between the input frames, and their performance degrades rapidly when the motion estimation result is not accurate enough. However, optical flow estimation is usually difficult, particularly when complicated motion is presented in real-world videos. In this paper, we explore a new way to solve this problem by using sparse feature point correspondences between the input images. The feature point correspondences, which are obtained by matching a set of feature points, are usually precise and much more robust than dense optical flow fields. This is because the feature points represent well-selected significant locations in the image, and performing matching on the feature point set is usually very accurate. In order to utilize the sparse correspondences in conventional super-resolution, we extract an adaptive support region with a reliable local flow field from each corresponding feature point pair. The normalized prior is also proposed to increase the visual consistency of the reconstructed result. Extensive experiments on real data were carried out, and results show that the proposed algorithm produces high-resolution images with better quality, particularly in the presence of large-scale or complicated motion fields.", "paper_title": "Super-Resolution Without Dense Flow", "paper_id": "WOS:000302181800029"}