{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "divclus-t"}, {"score": 0.00438105507792004, "phrase": "divisive_hierarchical_clustering_algorithm"}, {"score": 0.0042452552248398445, "phrase": "monothetic_bipartitional_approach"}, {"score": 0.0038624981944755813, "phrase": "decision_tree"}, {"score": 0.0036553070575015344, "phrase": "numerical_or_categorical_data"}, {"score": 0.003541923233726252, "phrase": "ward_agglomerative_hierarchical_clustering_algorithm"}, {"score": 0.003097865379563127, "phrase": "inertia_criterion"}, {"score": 0.0029782855468094933, "phrase": "ward"}, {"score": 0.0027741761880779535, "phrase": "simple_and_natural_interpretation"}, {"score": 0.002407078478216306, "phrase": "additional_interpretation"}, {"score": 0.002259883463607508, "phrase": "six_databases"}, {"score": 0.0022070310530794097, "phrase": "uci_machine_learning_repository"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["divisive clustering", " monothetic cluster", " decision dendrogram", " inertia criterion"], "paper_abstract": "DIVCLUS-T is a divisive hierarchical clustering algorithm based on a monothetic bipartitional approach allowing the dendrogram of the hierarchy to be read as a decision tree. It is designed for either numerical or categorical data. Like the Ward agglomerative hierarchical clustering algorithm and the k-means partitioning algorithm, it is based on the minimization of the inertia criterion. However, unlike Ward and k-means, it provides a simple and natural interpretation of the clusters. The price paid by construction in terms of inertia by DIVCLUS-T for this additional interpretation is studied by applying the three algorithms on six databases from the UCI Machine Learning repository. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "DIVCLUS-T: A monothetic divisive hierarchical clustering method", "paper_id": "WOS:000253365300007"}