{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "batch_back-propagation_algorithm"}, {"score": 0.04838919478929022, "phrase": "feedforward_neural_networks"}, {"score": 0.004096082254543022, "phrase": "usual_penalty"}, {"score": 0.0035156341294017685, "phrase": "learning_rate"}, {"score": 0.00333097896868937, "phrase": "small_constant"}, {"score": 0.0032423089921154503, "phrase": "adaptive_series"}, {"score": 0.0031559919178954644, "phrase": "main_contribution"}, {"score": 0.0027575842698911173, "phrase": "network_training_process"}, {"score": 0.0025202582748972122, "phrase": "convergence_results"}, {"score": 0.00216263228969761, "phrase": "theoretical_findings"}], "paper_keywords": ["Feedforward neural networks", " Batch back-propagation algorithm", " Penalty", " Boundedness", " Convergence"], "paper_abstract": "This paper investigates the batch back-propagation algorithm with penalty for training feedforward neural networks. A usual penalty is considered, which is a term proportional to the norm of the weights. The learning rate is set to be a small constant or an adaptive series. The main contribution of this paper is to theoretically prove the boundedness of the weights in the network training process. This boundedness is then used to prove some convergence results of the algorithm, which cover both the weak and strong convergence. Simulation results are given to support the theoretical findings. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Boundedness and convergence of batch back-propagation algorithm with penalty for feedforward neural networks", "paper_id": "WOS:000304638500015"}