{"auto_keywords": [{"score": 0.039717311925460824, "phrase": "fdda"}, {"score": 0.015329357550384136, "phrase": "effective_discriminant_subspace_dimensions"}, {"score": 0.008713768692145006, "phrase": "fisher_difference_discriminant_analysis"}, {"score": 0.004489810932879285, "phrase": "based_subspace_discriminant_analysis_algorithms"}, {"score": 0.004321772629297024, "phrase": "local_neighborhood_graphs"}, {"score": 0.0041074234667687875, "phrase": "difficult_but_important_problems"}, {"score": 0.0038789122930433305, "phrase": "novel_supervised_subspace_learning_method"}, {"score": 0.003709974534103202, "phrase": "linear_dimensionality_reduction"}, {"score": 0.003593812067062062, "phrase": "local_soft_scatter"}, {"score": 0.0033295966773779174, "phrase": "fisher_criterion"}, {"score": 0.003287482882222731, "phrase": "difference_criterion"}, {"score": 0.0031643005824589917, "phrase": "optimal_discriminant_subspace"}, {"score": 0.0030651710672229926, "phrase": "large_margin"}, {"score": 0.003026391655379905, "phrase": "different_classes"}, {"score": 0.002912963877144772, "phrase": "eigenvalue_analysis"}, {"score": 0.0026475981474045414, "phrase": "positive_eigenvalues"}, {"score": 0.002360796860462937, "phrase": "comprehensive_comparison"}, {"score": 0.0023309080951251335, "phrase": "extensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "face_recognition"}], "paper_keywords": ["Manifold learning", " Feature extraction", " Face recognition", " Eigen analysis", " Effective dimensions"], "paper_abstract": "In most manifold learning based subspace discriminant analysis algorithms, how to construct the local neighborhood graphs and determine the effective discriminant subspace dimensions in applications are difficult but important problems. In this paper, we propose a novel supervised subspace learning method called Fisher Difference Discriminant Analysis (FDDA) for linear dimensionality reduction. FDDA introduces the local soft scatter to characterize the distributions of the data set. By combining Fisher criterion and difference criterion together, FDDA obtains the optimal discriminant subspace, on which a large margin between different classes is provided for classification. Eigenvalue analysis shows that the effective discriminant subspace dimensions of FDDA can be automatically determined by the number of positive eigenvalues and are robust to noise and invariant to rotations, rescalings and translations of the data. Comprehensive comparison and extensive experiments show that FDDA is superior to some state-of-the-art techniques in face recognition.", "paper_title": "Fisher Difference Discriminant Analysis: Determining the Effective Discriminant Subspace Dimensions for Face Recognition", "paper_id": "WOS:000304114300001"}