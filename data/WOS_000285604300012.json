{"auto_keywords": [{"score": 0.049062712519921996, "phrase": "cqa"}, {"score": 0.0037213333316218522, "phrase": "multiple_answers"}, {"score": 0.0036422425344358037, "phrase": "varying_quality"}, {"score": 0.003451766520526601, "phrase": "new_approach"}, {"score": 0.003306559295382181, "phrase": "high-quality_answers"}, {"score": 0.0029064676523923886, "phrase": "new_question"}, {"score": 0.0025546627686955656, "phrase": "quality_framework"}, {"score": 0.0022453451864218477, "phrase": "logistic-regression_analysis"}, {"score": 0.002174041708084857, "phrase": "content-appraisal_features"}, {"score": 0.0021049977753042253, "phrase": "strongest_predictor"}], "paper_keywords": [""], "paper_abstract": "Community-driven question-answering (CQA) services on the Internet let users share content in the form of questions and answers. Usually, questions attract multiple answers of varying quality from other users. A new approach aims to identify high-quality answers from candidate answers to questions that are semantically similar to the new question. Toward that end, the authors developed and tested a quality framework comprising social, textual, and content-appraisal features of user-generated answers in CQA services. Logistic-regression analysis revealed that content-appraisal features were the strongest predictor of quality. These features include dimensions such as comprehensiveness, truthfulness, and practicality.", "paper_title": "What Makes a High-Quality User-Generated Answer?", "paper_id": "WOS:000285604300012"}