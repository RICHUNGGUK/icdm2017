{"auto_keywords": [{"score": 0.0370632148068783, "phrase": "multiple_cameras"}, {"score": 0.00481495049065317, "phrase": "multiple_airborne_cameras"}, {"score": 0.004670597652149685, "phrase": "aerial_vehicle"}, {"score": 0.004530552828603269, "phrase": "large_areas"}, {"score": 0.004375613460102577, "phrase": "different_aerial_vehicles"}, {"score": 0.004262881313926916, "phrase": "increased_visual_scope"}, {"score": 0.004153041453795458, "phrase": "multiple_targets"}, {"score": 0.0038737214010638745, "phrase": "airborne_cameras"}, {"score": 0.003806866174028117, "phrase": "geometric_constraints"}, {"score": 0.0035662378173267647, "phrase": "prior_calibration_information"}, {"score": 0.003384695931421288, "phrase": "essential_requirement"}, {"score": 0.0032974089700312423, "phrase": "transitive_closure"}, {"score": 0.003062091606343783, "phrase": "likelihood_function"}, {"score": 0.0030223381739019894, "phrase": "k-dimensional_matching"}, {"score": 0.002918826667294298, "phrase": "optimal_assignment"}, {"score": 0.002843519597398796, "phrase": "proposed_error_function"}, {"score": 0.002818850283787242, "phrase": "canonical_trajectories"}, {"score": 0.0027581067089091434, "phrase": "optimal_estimates"}, {"score": 0.0027341763737751467, "phrase": "intercamera_transformations"}, {"score": 0.002686935113435742, "phrase": "maximum_likelihood_sense"}, {"score": 0.0024412911465483225, "phrase": "special_conditions"}, {"score": 0.0023782753249846794, "phrase": "occlusion_or_missing_detections"}, {"score": 0.002257070536352418, "phrase": "real_and_controlled_scenarios"}, {"score": 0.0021049977753042253, "phrase": "quantitative_performance"}], "paper_keywords": ["applications", " scene analysis", " motion", " sensor fusion", " registration"], "paper_abstract": "A camera mounted on an aerial vehicle provides an excellent means to monitor large areas of a scene. Utilizing several such cameras on different aerial vehicles allows further flexibility in terms of increased visual scope and in the pursuit of multiple targets. In this paper, we address the problem of associating trajectories across multiple moving airborne cameras. We exploit geometric constraints on the relationship between the motion of each object across cameras without assuming any prior calibration information. Since multiple cameras exist, ensuring coherency in association is an essential requirement, e. g., that transitive closure is maintained between more than two cameras. To ensure such coherency, we pose the problem of maximizing the likelihood function as a k-dimensional matching and use an approximation to find the optimal assignment of association. Using the proposed error function, canonical trajectories of each object and optimal estimates of intercamera transformations ( in a maximum likelihood sense) are computed. Finally, we show that, as a result of associating trajectories across the cameras, under special conditions, trajectories interrupted due to occlusion or missing detections can be repaired. Results are shown on a number of real and controlled scenarios with multiple objects observed by multiple cameras, validating our qualitative models, and, through simulation, quantitative performance is also reported.", "paper_title": "Trajectory association across multiple airborne cameras", "paper_id": "WOS:000251580300014"}