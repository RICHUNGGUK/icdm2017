{"auto_keywords": [{"score": 0.0421287488544688, "phrase": "amc"}, {"score": 0.00481495049065317, "phrase": "main_memory_latency"}, {"score": 0.004656082803151484, "phrase": "modern_processors"}, {"score": 0.0045213598841171935, "phrase": "large-scale_shared_memory_systems"}, {"score": 0.00426344619171077, "phrase": "processor_cycles"}, {"score": 0.0040882422992520925, "phrase": "intelligent_memory"}, {"score": 0.004054071599735255, "phrase": "cache_coherence_controller"}, {"score": 0.003936698872193083, "phrase": "active_memory_operations"}, {"score": 0.0038227112550093863, "phrase": "select_operations"}, {"score": 0.003712011863784581, "phrase": "home_memory_controller"}, {"score": 0.003589404014552974, "phrase": "significant_number"}, {"score": 0.003559387846675818, "phrase": "coherence_messages"}, {"score": 0.003485437176235259, "phrase": "internode_memory_traffic"}, {"score": 0.0031912018800904314, "phrase": "processor_core"}, {"score": 0.0031645050772280033, "phrase": "dram_chips"}, {"score": 0.0030470980812086247, "phrase": "microarchitecture_design"}, {"score": 0.002885135695263876, "phrase": "amos'_performance"}, {"score": 0.002778064757980489, "phrase": "scientific_and_commercial_benchmarks"}, {"score": 0.0026637384761565605, "phrase": "dramatic_performance_improvements"}, {"score": 0.002630364569659529, "phrase": "important_set"}, {"score": 0.0026083473154448326, "phrase": "data-intensive_operations"}, {"score": 0.0025221012517852907, "phrase": "faster_spinlocks"}, {"score": 0.0024489727828322693, "phrase": "faster_database_queries"}, {"score": 0.0023879771786116228, "phrase": "analytical_model"}, {"score": 0.002338306897057454, "phrase": "performance_benefits"}, {"score": 0.002289667393538803, "phrase": "decent_accuracy"}, {"score": 0.0022609695885550058, "phrase": "silicon_cost"}, {"score": 0.0021770116505684394, "phrase": "die_area"}, {"score": 0.002149722786728988, "phrase": "typical_high_performance_processor"}, {"score": 0.0021049977753042253, "phrase": "standard_cell_implementation"}], "paper_keywords": ["Distributed shared memory", " Cache coherence", " Memory architecture", " Interprocessor synchronization", " DRAM organization"], "paper_abstract": "Inability to hide main memory latency has been increasingly limiting the performance of modern processors. The problem is worse in large-scale shared memory systems, where remote memory latencies are hundreds, and soon thousands, of processor cycles. To mitigate this problem, we propose an intelligent memory and cache coherence controller (AMC) that can execute Active Memory Operations (AMOs). AMOs are select operations sent to and executed on the home memory controller of data. AMOs can eliminate a significant number of coherence messages, minimize intranode and internode memory traffic, and create opportunities for parallelism. Our implementation of AMOs is cache-coherent and requires no changes to the processor core or DRAM chips. In this paper, we present the microarchitecture design of AMC, and the programming model of AMOs. We compare AMOs' performance to that of several other memory architectures on a variety of scientific and commercial benchmarks. Through simulation, we show that AMOs offer dramatic performance improvements for an important set of data-intensive operations, e.g., up to 50x faster barriers, 12x faster spinlocks, 8.5x-15x faster stream/array operations, and 3x faster database queries. We also present an analytical model that can predict the performance benefits of using AMOs with decent accuracy. The silicon cost required to support AMOs is less than 1% of the die area of a typical high performance processor, based on a standard cell implementation.", "paper_title": "Active memory controller", "paper_id": "WOS:000308110300026"}