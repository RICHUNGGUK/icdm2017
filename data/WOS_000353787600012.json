{"auto_keywords": [{"score": 0.042426970046247924, "phrase": "proposed_ensemble_methods"}, {"score": 0.012227068817389069, "phrase": "iterative_regularization"}, {"score": 0.012056865826445192, "phrase": "bayesian_inverse_problems"}, {"score": 0.007552071049739498, "phrase": "ensemble_methods"}, {"score": 0.007038449397203114, "phrase": "bayesian_posterior"}, {"score": 0.007001356348569857, "phrase": "proposed_methods"}, {"score": 0.00692775158441665, "phrase": "iterative_regularization_methods"}, {"score": 0.006806780756186772, "phrase": "deterministic_inverse_problems"}, {"score": 0.005922038858326327, "phrase": "regularization_parameters"}, {"score": 0.0058082748966800475, "phrase": "discrepancy_principle"}, {"score": 0.005479857137489777, "phrase": "present_work"}, {"score": 0.005142615817667537, "phrase": "approximation_properties"}, {"score": 0.004868810979684051, "phrase": "tunable_parameters"}, {"score": 0.004843096285982333, "phrase": "proposed_ir-enlm"}, {"score": 0.00481495049065317, "phrase": "ensemble_data_assimilation"}, {"score": 0.0047979812040897275, "phrase": "reservoir_models"}, {"score": 0.004582722012454012, "phrase": "variational_iterative_regularizing_ensemble_levenberg-marquardt_method"}, {"score": 0.004400329132129292, "phrase": "robust_ensemble_approximation"}, {"score": 0.004323299449585026, "phrase": "fundamental_ideas"}, {"score": 0.004180623336901781, "phrase": "gruyter"}, {"score": 0.004165890894472965, "phrase": "berlin"}, {"score": 0.003985901988504922, "phrase": "reservoir_modeling_applications"}, {"score": 0.003950846696972114, "phrase": "key_aspects"}, {"score": 0.003929961097925987, "phrase": "regularizing_levenberg-marquardt_scheme"}, {"score": 0.003909186520405823, "phrase": "hanke"}, {"score": 0.003786809926526263, "phrase": "iglesias"}, {"score": 0.0036942726653704213, "phrase": "stopping_criteria"}, {"score": 0.0035053668731666347, "phrase": "unregularized_methods"}, {"score": 0.003328419620909598, "phrase": "iterative_updates"}, {"score": 0.0032991276152705934, "phrase": "ill-posed_inverse_problems"}, {"score": 0.003270092550315648, "phrase": "convergence_properties"}, {"score": 0.0031342307827666675, "phrase": "open_problem"}, {"score": 0.003095674983836725, "phrase": "forward_operator"}, {"score": 0.0030580470865729376, "phrase": "gaussian"}, {"score": 0.0029513378882170243, "phrase": "resulting_schemes"}, {"score": 0.002930533009215635, "phrase": "standard_randomized_maximum_likelihood"}, {"score": 0.0028037753646260937, "phrase": "linear-gaussian_case"}, {"score": 0.0027741761880779535, "phrase": "es_methods"}, {"score": 0.0027546167254869493, "phrase": "nonlinear_case"}, {"score": 0.002663571038928919, "phrase": "numerical_investigation"}, {"score": 0.002525886911592777, "phrase": "iterative_regularization_techniques"}, {"score": 0.0025125151618810523, "phrase": "numerical_framework"}, {"score": 0.002481588370380518, "phrase": "state-of-the_art_markov_chain"}, {"score": 0.0024772013657695896, "phrase": "monte_carlo"}, {"score": 0.0024425164033962028, "phrase": "bayesian"}, {"score": 0.002429451930463481, "phrase": "synthetic_experiments"}, {"score": 0.00241658945942583, "phrase": "resolved_posterior"}, {"score": 0.002408095110592242, "phrase": "mcmc"}, {"score": 0.002391067964886602, "phrase": "gold_standard"}, {"score": 0.002336690082911605, "phrase": "clear_indication"}, {"score": 0.00232431758517087, "phrase": "regularizing_properties"}, {"score": 0.0023120104465263066, "phrase": "regularization_methods"}, {"score": 0.002275477757478827, "phrase": "significant_impact"}, {"score": 0.002196342933346204, "phrase": "proposed_regularizing_methods"}], "paper_keywords": ["Bayesian data assimilation", " Inverse problems", " Reservoir models"], "paper_abstract": "We propose the application of iterative regularization for the development of ensemble methods for solving Bayesian inverse problems. In concrete, we construct (i) a variational iterative regularizing ensemble Levenberg-Marquardt method (IR-enLM) and (ii) a derivative-free iterative ensemble Kalman smoother (IR-ES). The aim of these methods is to provide a robust ensemble approximation of the Bayesian posterior. The proposed methods are based on fundamental ideas from iterative regularization methods that have been widely used for the solution of deterministic inverse problems (Katltenbacher et al. de Gruyter, Berlin 2008). In this work, we are interested in the application of the proposed ensemble methods for the solution of Bayesian inverse problems that arise in reservoir modeling applications. The proposed ensemble methods use key aspects of the regularizing Levenberg-Marquardt scheme developed by Hanke (Inverse Problems 13,79-95 1997) and that we recently applied for history matching in Iglesias (Comput. Geosci. 1-21 2013). Unlike most existing methods where the stopping criteria and regularization parameters are typically selected heuristically, in the proposed ensemble methods, the discrepancy principle is applied for (i) the selection of the regularization parameters and (ii) the early termination of the scheme. The discrepancy principle is key for the theory of iterative regularization, and the purpose of the present work is to apply this principle for the development of ensemble methods defined as iterative updates of solutions to linear ill-posed inverse problems. The regularizing and convergence properties of iterative regularization methods for deterministic inverse problems have long been established. However, the approximation properties of the proposed ensemble methods in the context of Bayesian inverse problems is an open problem. In the case where the forward operator is linear and the prior is Gaussian, we show that the tunable parameters of the proposed IR-enLM and IR-ES can be chosen so that the resulting schemes coincide with the standard randomized maximum likelihood (RML) and the ensemble smoother (ES), respectively. Therefore, the proposed methods sample from the posterior in the linear-Gaussian case. Similar to RML and ES methods, in the nonlinear case, one may not conclude that the proposed methods produce samples from the posterior. The present work provides a numerical investigation of the performance of the proposed ensemble methods at capturing the posterior. In particular, we aim at understanding the role of the tunable parameters that arise from the application of iterative regularization techniques. The numerical framework for our investigations consists of using a state-of-the art Markov chain Monte Carlo (MCMC) method for resolving the Bayesian posterior from synthetic experiments. The resolved posterior via MCMC then provides a gold standard against to which compare the proposed IR-enLM and IR-ES. Our numerical experiments show clear indication that the regularizing properties of the regularization methods applied for the computation of each ensemble have significant impact of the approximation properties of the proposed ensemble methods at capturing the Bayesian posterior. Furthermore, we provide a comparison of the proposed regularizing methods with respect to some unregularized methods that have been typically used in the literature. Our numerical experiments showcase the advantage of using iterative regularization for obtaining more robust and stable approximation of the posterior than unregularized methods.", "paper_title": "Iterative regularization for ensemble data assimilation in reservoir models", "paper_id": "WOS:000353787600012"}