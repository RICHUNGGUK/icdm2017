{"auto_keywords": [{"score": 0.03160214435857137, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "efficient_subspace_learning"}, {"score": 0.00461302961851157, "phrase": "important_role"}, {"score": 0.004473982381245469, "phrase": "pattern_recognition"}, {"score": 0.004419538941706716, "phrase": "computer_vision"}, {"score": 0.004339108074589304, "phrase": "machine_learning"}, {"score": 0.004208282550386197, "phrase": "new_family"}, {"score": 0.003982835483457073, "phrase": "pca"}, {"score": 0.0038389110156920926, "phrase": "low-rank_subspace_analysis_problems"}, {"score": 0.0036107898615445797, "phrase": "missing_data"}, {"score": 0.003459191419478298, "phrase": "heavy_computation_loads"}, {"score": 0.003116913644889395, "phrase": "robust_orthogonal_matrix_approximation_method"}, {"score": 0.0030789331635764122, "phrase": "fixed-rank_factorization"}, {"score": 0.002931569771634119, "phrase": "robust_solution"}, {"score": 0.002878140062594849, "phrase": "orthogonality_and_smoothness_constraints"}, {"score": 0.0027069560455629917, "phrase": "rank_uncertainty_issue"}, {"score": 0.0026576091519087065, "phrase": "rank_estimation_strategy"}, {"score": 0.0026252106881752067, "phrase": "practical_real-world_problems"}, {"score": 0.002453934333239467, "phrase": "low-rank_matrix_approximation_problems"}, {"score": 0.002183938718432764, "phrase": "existing_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Low-rank matrix factorization", " l(1)-norm", " Subspace learning", " Augmented Lagrangian method", " Rank estimation"], "paper_abstract": "Low-rank matrix factorization plays an important role in the areas of pattern recognition, computer vision, and machine learning. Recently, a new family of methods, such as l(1)-norm minimization and robust PCA, has been proposed for low-rank subspace analysis problems and has shown to be robust against outliers and missing data. But these methods suffer from heavy computation loads and can fail to find a solution when highly corrupted data are presented. In this paper, a robust orthogonal matrix approximation method using fixed-rank factorization is proposed. The proposed method finds a robust solution efficiently using orthogonality and smoothness constraints. The proposed method is also extended to handle the rank uncertainty issue by a rank estimation strategy for practical real-world problems. The proposed method is applied to a number of low-rank matrix approximation problems and experimental results show that the proposed method is highly accurate, fast, and efficient compared to the existing methods. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Robust orthogonal matrix factorization for efficient subspace learning", "paper_id": "WOS:000358808500024"}