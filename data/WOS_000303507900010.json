{"auto_keywords": [{"score": 0.04399755003715801, "phrase": "st"}, {"score": 0.017601192488391083, "phrase": "bow"}, {"score": 0.00481495049065317, "phrase": "probabilistic_localized_video_representation"}, {"score": 0.00476697427418509, "phrase": "human_action_recognition"}, {"score": 0.004101886428528311, "phrase": "bow_video_representation"}, {"score": 0.003785836059995376, "phrase": "feature_space"}, {"score": 0.0036370297611938796, "phrase": "information_loss"}, {"score": 0.0036007478932719417, "phrase": "video_representation"}, {"score": 0.00347657813672945, "phrase": "universal_codebook"}, {"score": 0.003441891354624516, "phrase": "bow_representation"}, {"score": 0.0032571885279065126, "phrase": "video_corpus"}, {"score": 0.0029169007179202164, "phrase": "visual_and_motion_information"}, {"score": 0.0028446460307503343, "phrase": "local_st_features"}, {"score": 0.0027054473441439422, "phrase": "generative_probabilistic_model"}, {"score": 0.0026384167183586015, "phrase": "probabilistic_video_representation"}, {"score": 0.002560162916190598, "phrase": "information-theoretic_distance"}, {"score": 0.0023507916951658455, "phrase": "nearest_neighbor_schemes"}, {"score": 0.0021369416775353107, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "promising_results"}], "paper_keywords": ["Human action recognition", " Probabilistic video representation", " Information-theoretic video matching"], "paper_abstract": "In recent years, the bag-of-words (BoW) video representations have achieved promising results in human action recognition in videos. By vector quantizing local spatial temporal (ST) features, the BoW video representation brings in simplicity and efficiency, but limitations too. First, the discretization of feature space in BoW inevitably results in ambiguity and information loss in video representation. Second, there exists no universal codebook for BoW representation. The codebook needs to be re-built when video corpus is changed. To tackle these issues, this paper explores a localized, continuous and probabilistic video representation. Specifically, the proposed representation encodes the visual and motion information of an ensemble of local ST features of a video into a distribution estimated by a generative probabilistic model. Furthermore, the probabilistic video representation naturally gives rise to an information-theoretic distance metric of videos. This makes the representation readily applicable to most discriminative classifiers, such as the nearest neighbor schemes and the kernel based classifiers. Experiments on two datasets, KTH and UCF sports, show that the proposed approach could deliver promising results.", "paper_title": "Exploring probabilistic localized video representation for human action recognition", "paper_id": "WOS:000303507900010"}