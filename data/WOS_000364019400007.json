{"auto_keywords": [{"score": 0.03678902168567896, "phrase": "common_activation_matrix"}, {"score": 0.011605169235318354, "phrase": "source_dictionary"}, {"score": 0.00481495049065317, "phrase": "joint_nonnegative_matrix_factorization"}, {"score": 0.004768378525561471, "phrase": "exemplar-based_sparse_representation"}, {"score": 0.004631335513513859, "phrase": "voice_conversion"}, {"score": 0.004476399615305783, "phrase": "target_spectrum"}, {"score": 0.00436890075128947, "phrase": "weighted_linear_combination"}, {"score": 0.004263972370406983, "phrase": "basis_spectra"}, {"score": 0.004101281992566145, "phrase": "training_data"}, {"score": 0.0040027552011993005, "phrase": "coupled_source-target_dictionaries"}, {"score": 0.0039447744176901054, "phrase": "acoustically_aligned_source-target_exemplars"}, {"score": 0.003685067218455088, "phrase": "source_spectrogram"}, {"score": 0.003376037544631762, "phrase": "target_dictionary"}, {"score": 0.003310951184365485, "phrase": "target_spectrogram"}, {"score": 0.003048001809453513, "phrase": "low-resolution_features"}, {"score": 0.0029602552900111407, "phrase": "temporal_information"}, {"score": 0.0029031614127920232, "phrase": "computational_cost"}, {"score": 0.002861062731782219, "phrase": "memory_occupation"}, {"score": 0.0028058765785670546, "phrase": "high-resolution_spectra"}, {"score": 0.002778682854371595, "phrase": "significant_spectral_details"}, {"score": 0.002659527314613792, "phrase": "joint_nonnegative_matrix_factorization_technique"}, {"score": 0.0025578967205807843, "phrase": "high-resolution_features"}, {"score": 0.002366110899738696, "phrase": "low-_and_high-resolution_features"}, {"score": 0.0022756672722130424, "phrase": "voices_database"}, {"score": 0.002199363362666037, "phrase": "proposed_method"}, {"score": 0.0021674482571326283, "phrase": "objective_and_subjective_evaluations"}, {"score": 0.0021049977753042253, "phrase": "proposed_methods"}], "paper_keywords": ["Speech synthesis", " Voice conversion", " Exemplar", " Sparse representation", " Nonnegative matrix factorization", " Joint nonnegative matrix factorization"], "paper_abstract": "Exemplar-based sparse representation is a nonparametric framework for voice conversion. In this framework, a target spectrum is generated as a weighted linear combination of a set of basis spectra, namely exemplars, extracted from the training data. This framework adopts coupled source-target dictionaries consisting of acoustically aligned source-target exemplars, and assumes they can share the same activation matrix. At runtime, a source spectrogram is factorized as a product of the source dictionary and the common activation matrix, which is applied to the target dictionary to generate the target spectrogram. In practice, either low-resolution mel-scale filter bank energies or high-resolution spectra are adopted in the source dictionary. Low-resolution features are flexible in capturing the temporal information without increasing the computational cost and the memory occupation significantly, while high-resolution spectra contain significant spectral details. In this paper, we propose a joint nonnegative matrix factorization technique to find the common activation matrix using low- and high-resolution features at the same time. In this way, the common activation matrix is able to benefit from low- and high-resolution features directly. We conducted experiments on the VOICES database to evaluate the performance of the proposed method. Both objective and subjective evaluations confirmed the effectiveness of the proposed methods.", "paper_title": "Exemplar-based voice conversion using joint nonnegative matrix factorization", "paper_id": "WOS:000364019400007"}