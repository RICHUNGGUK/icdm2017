{"auto_keywords": [{"score": 0.04120087369549478, "phrase": "feature_vectors"}, {"score": 0.0044991925146184025, "phrase": "traditional_supervised_setting"}, {"score": 0.004335739075947899, "phrase": "test_samples"}, {"score": 0.00428257928723, "phrase": "individual_feature_vectors"}, {"score": 0.0036703791815812328, "phrase": "individual_samples"}, {"score": 0.0035588302267335046, "phrase": "individual_labels"}, {"score": 0.0031845067058084583, "phrase": "supervised_learning"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multiple instance learning", " Set classification", " Group-based classification", " Label dependencies", " Weakly labeled data"], "paper_abstract": "Many classification problems can be difficult to formulate directly in terms of the traditional supervised setting, where both training and test samples are individual feature vectors. There are cases in which samples are better described by sets of feature vectors, that labels are only available for sets rather than individual samples, or, if individual labels are available, that these are not independent. To better deal with such problems, several extensions of supervised learning have been proposed, where either training and/or test objects are sets of feature vectors. However, having been proposed rather independently of each other, their mutual similarities and differences have hitherto not been mapped out. In this work, we provide an overview of such learning scenarios, propose a taxonomy to illustrate the relationships between them, and discuss directions for further research in these areas. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "On classification with bags, groups and sets", "paper_id": "WOS:000355019100002"}