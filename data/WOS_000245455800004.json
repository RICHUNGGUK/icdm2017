{"auto_keywords": [{"score": 0.045920579453929744, "phrase": "sensitive_properties"}, {"score": 0.03797933328148866, "phrase": "sensitive_inferences"}, {"score": 0.03644451033122438, "phrase": "privacy_templates"}, {"score": 0.0351506449664449, "phrase": "sensitive_property"}, {"score": 0.029779277220589494, "phrase": "domain_values"}, {"score": 0.02246846748295755, "phrase": "personal_identities"}, {"score": 0.00481495049065317, "phrase": "attacker's_confidence"}, {"score": 0.00421410521089045, "phrase": "data_mining_abilities"}, {"score": 0.004103212598803194, "phrase": "dual_goals"}, {"score": 0.003952828685048176, "phrase": "wanted_data_analysis_request"}, {"score": 0.0038283058265876713, "phrase": "unwanted_sensitive_inferences"}, {"score": 0.0030758904011907533, "phrase": "maximum_threshold"}, {"score": 0.0029159568444629053, "phrase": "identifying_attributes"}, {"score": 0.0027495914857929584, "phrase": "maximum_confidence"}, {"score": 0.0026205405415623525, "phrase": "data_transformation"}, {"score": 0.002393034183276193, "phrase": "transformed_data"}, {"score": 0.0022685255265595624, "phrase": "data_mining_algorithms"}, {"score": 0.0022324489895237504, "phrase": "prior_k-anonymization_k"}], "paper_keywords": ["privacy protection", " k-anonymity", " sensitive inference", " data mining", " classification", " data sharing"], "paper_abstract": "We present an approach of limiting the confidence of inferring sensitive properties to protect against the threats caused by data mining abilities. The problem has dual goals: preserve the information for a wanted data analysis request and limit the usefulness of unwanted sensitive inferences that may be derived from the release of data. Sensitive inferences are specified by a set of \"privacy templates\". Each template specifies the sensitive property to be protected, the attributes identifying a group of individuals, and a maximum threshold for the confidence of inferring the sensitive property given the identifying attributes. We show that suppressing the domain values monotonically decreases the maximum confidence of such sensitive inferences. Hence, we propose a data transformation that minimally suppresses the domain values in the data to satisfy the set of privacy templates. The transformed data is free of sensitive inferences even in the presence of data mining algorithms. The prior k-anonymization k has been italicized consistently throughout this article. focuses on personal identities. This work focuses on the association between personal identities and sensitive properties.", "paper_title": "Handicapping attacker's confidence: an alternative to k-anonymization", "paper_id": "WOS:000245455800004"}