{"auto_keywords": [{"score": 0.04602548513647441, "phrase": "priori_knowledge"}, {"score": 0.014234653479032786, "phrase": "uncertain_variable"}, {"score": 0.008406010214611292, "phrase": "priori_probabilistic_knowledge"}, {"score": 0.008339096762477582, "phrase": "conditional_evidence_theory"}, {"score": 0.0077291917658697, "phrase": "probability_distribution"}, {"score": 0.0056336796479610676, "phrase": "combined_evidence"}, {"score": 0.00481495049065317, "phrase": "generalized_jeffrey's_rule"}, {"score": 0.00455202992136173, "phrase": "bayesian_probabilistic_approach"}, {"score": 0.004515655183335171, "phrase": "uncertain_reasoning"}, {"score": 0.004217925382695912, "phrase": "new_evidence_representable"}, {"score": 0.004167451906343558, "phrase": "constant_set"}, {"score": 0.004084662575167727, "phrase": "bayesian_conditioning"}, {"score": 0.003923965929636472, "phrase": "conventional_d-s_evidence_theory"}, {"score": 0.003606711217432998, "phrase": "so-called_dempster's_rule"}, {"score": 0.0035208552733545463, "phrase": "combined_body"}, {"score": 0.0032491108935498794, "phrase": "firstly_all_imprecise_and_uncertain_bodies"}, {"score": 0.0029504765287722465, "phrase": "priori_probability_distribution"}, {"score": 0.0027778947555117243, "phrase": "knowledge_updating_problem"}, {"score": 0.002668470532683947, "phrase": "new_evidence"}, {"score": 0.002615381301695394, "phrase": "random_set"}, {"score": 0.0023940274498526213, "phrase": "close_relationship"}, {"score": 0.0022268964676199292, "phrase": "posteriori_probability"}, {"score": 0.0022001958412800745, "phrase": "fused_body"}, {"score": 0.002156402793481102, "phrase": "bayesian_parallel_combination_rule"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["random set", " knowledge updating", " knowledge combining", " generalized Jeffrey's rule", " conditioned combination rule", " Bayesian parallel combination rule", " conditional evidence theory", " target identification"], "paper_abstract": "In Bayesian probabilistic approach for uncertain reasoning, one basic assumption is that a priori knowledge about the uncertain variable is modeled by a probability distribution. When new evidence representable by a constant set is available, the Bayesian conditioning is used to update a priori knowledge. In the conventional D-S evidence theory, all bodies of evidence about the uncertain variable are imprecise and uncertain. All bodies of evidence are combined by so-called Dempster's rule of combination to achieve a combined body of evidence without considering a priori knowledge. From our point of view, when identifying the true value of an uncertain variable, Bayesian approach and evidence theory can cooperate to deal with uncertain reasoning. Firstly all imprecise and uncertain bodies of evidence about the uncertain variable are fused to achieve a combined evidence based on a priori knowledge, then the a posteriori probability distribution is achieved from a priori probability distribution by conditioning on the combined evidence. In this paper we firstly deal with the knowledge updating problem where a priori knowledge is represented by a probability distribution and new evidence is represented by a random set. Then we review the conditional evidence theory which resolves the knowledge combining problem based on a priori probabilistic knowledge. Finally we discuss the close relationship between knowledge updating procedure and knowledge combining procedure presented in this paper. We show that a posteriori probability conditioned on fused body of evidence satisfies the Bayesian parallel combination rule. (C) 2005 Elsevier Inc. All rights reserved.", "paper_title": "Generalized Jeffrey's rule of conditioning and evidence combining rule for a priori probabilistic knowledge in conditional evidence theory", "paper_id": "WOS:000240511300006"}