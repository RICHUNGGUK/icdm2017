{"auto_keywords": [{"score": 0.048255519436473646, "phrase": "second-order_reward_models"}, {"score": 0.03110954582242528, "phrase": "accumulated_reward"}, {"score": 0.027027738905295983, "phrase": "second-order_feature"}, {"score": 0.004816293322450462, "phrase": "markov"}, {"score": 0.004683292152590589, "phrase": "qbd_processes"}, {"score": 0.004333406378146173, "phrase": "real-life_systems"}, {"score": 0.004238307626560739, "phrase": "reward_measure"}, {"score": 0.004122351497440992, "phrase": "underlying_noise"}, {"score": 0.00396530196547293, "phrase": "markov_chain"}, {"score": 0.003509487090932835, "phrase": "finite_number"}, {"score": 0.003283272764794988, "phrase": "quasi-birth-and-death_processes"}, {"score": 0.0031933617014256676, "phrase": "block-structured_markov_chains"}, {"score": 0.002987463078971627, "phrase": "laplace-stieltjes_transforms"}, {"score": 0.0026881926384093088, "phrase": "simple_example"}, {"score": 0.002486987042061596, "phrase": "significant_difference"}, {"score": 0.0023265270905455334, "phrase": "new_difficulties"}, {"score": 0.0022502133699402018, "phrase": "new_conditions"}, {"score": 0.0021885300925245516, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Reward model", " Quasi-birth-and-death (QBD) process", " RG-factorization", " Brownian motion"], "paper_abstract": "Second-order reward models are an important class of models for evaluating the performance of real-life systems in which the reward measure fluctuates according to some underlying noise. These models consist of a Markov chain driving the evolution of the system, and a continuous reward variable representing its performance. Thus far, only models with a finite number of states have been studied. We consider second-order reward models driven by Quasi-birth-and-death processes, a class of block-structured Markov chains with infinitely many states. We derive the expressions for the Laplace-Stieltjes transforms of the accumulated reward and demonstrate how they can be efficiently evaluated. We use our results to analyse a simple example and, in doing so, show that the second-order feature can make a significant difference to the accumulated reward. The inclusion of the second-order feature also creates new difficulties which require the development of new conditions in the analysis. Crown Copyright (C) 2012 Published by Elsevier B.V. All rights reserved.", "paper_title": "Second-order Markov reward models driven by QBD processes", "paper_id": "WOS:000308116700003"}