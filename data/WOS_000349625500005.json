{"auto_keywords": [{"score": 0.02246846748295755, "phrase": "wikipedia"}, {"score": 0.00481495049065317, "phrase": "nested_hierarchical_dirichlet_process"}, {"score": 0.004569630374630379, "phrase": "hierarchical_topic_modeling"}, {"score": 0.004291617358806677, "phrase": "nested_chinese_restaurant_process"}, {"score": 0.003554661425339528, "phrase": "per-document_distribution"}, {"score": 0.0033381913087533457, "phrase": "shared_tree"}, {"score": 0.002823050755743821, "phrase": "complex_thematic_borrowings"}, {"score": 0.002678944072162297, "phrase": "stochastic_variational_inference_algorithm"}, {"score": 0.0024894376091589244, "phrase": "efficient_inference"}, {"score": 0.0024377918036784336, "phrase": "massive_collections"}, {"score": 0.002387214876538434, "phrase": "text_documents"}], "paper_keywords": ["Bayesian nonparametrics", " Dirichlet process", " topic modeling", " stochastic optimization"], "paper_abstract": "We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical topic modeling. The nHDP generalizes the nested Chinese restaurant process (nCRP) to allow each word to follow its own path to a topic node according to a per-document distribution over the paths on a shared tree. This alleviates the rigid, single-path formulation assumed by the nCRP, allowing documents to easily express complex thematic borrowings. We derive a stochastic variational inference algorithm for the model, which enables efficient inference for massive collections of text documents. We demonstrate our algorithm on 1.8 million documents from The New York Times and 2.7 million documents from Wikipedia.", "paper_title": "Nested Hierarchical Dirichlet Processes", "paper_id": "WOS:000349625500005"}