{"auto_keywords": [{"score": 0.024171063237672482, "phrase": "prediction_function"}, {"score": 0.00481495049065317, "phrase": "regression_models"}, {"score": 0.004743806810821005, "phrase": "multidimensional_prediction_functions"}, {"score": 0.00443638953122199, "phrase": "fitting_regression_models"}, {"score": 0.004370814742381778, "phrase": "building_prediction_rules"}, {"score": 0.004274257668843713, "phrase": "notable_feature"}, {"score": 0.0038224221344037236, "phrase": "built-in_mechanism"}, {"score": 0.003737934295442975, "phrase": "coefficient_estimates"}, {"score": 0.0036826452656927877, "phrase": "variable_selection"}, {"score": 0.003601235776892337, "phrase": "regularization_mechanism"}, {"score": 0.0034954725617970294, "phrase": "suitable_method"}, {"score": 0.0033426036530090205, "phrase": "small_sample_sizes"}, {"score": 0.003293142761521425, "phrase": "large_numbers"}, {"score": 0.0031257046538823354, "phrase": "existing_methodology"}, {"score": 0.0030338645940033875, "phrase": "boosting_method"}, {"score": 0.0029889584492584073, "phrase": "prediction_functions"}, {"score": 0.0029447150254434842, "phrase": "multiple_components"}, {"score": 0.0027949428646076627, "phrase": "statistical_models"}, {"score": 0.00269263690712392, "phrase": "count_data_models"}, {"score": 0.0025940660106162404, "phrase": "outcome_variables"}, {"score": 0.0025366596616434793, "phrase": "mixture_distribution"}, {"score": 0.002389696110283506, "phrase": "new_algorithm"}, {"score": 0.0021049977753042253, "phrase": "nuisance_parameters"}], "paper_keywords": ["Gradient boosting", " Multidimensional prediction function", " Scale parameter estimation", " Variable selection", " Count data model"], "paper_abstract": "Boosting is one of the most important methods for fitting regression models and building prediction rules. A notable feature of boosting is that the technique can be modified such that it includes a built-in mechanism for shrinking coefficient estimates and variable selection. This regularization mechanism makes boosting a suitable method for analyzing data characterized by small sample sizes and large numbers of predictors. We extend the existing methodology by developing a boosting method for prediction functions with multiple components. Such multidimensional functions occur in many types of statistical models, for example in count data models and in models involving outcome variables with a mixture distribution. As will be demonstrated, the new algorithm is suitable for both the estimation of the prediction function and regularization of the estimates. In addition, nuisance parameters can be estimated simultaneously with the prediction function.", "paper_title": "Estimation and regularization techniques for regression models with multidimensional prediction functions", "paper_id": "WOS:000276075700003"}