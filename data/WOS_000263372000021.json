{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "graspable_objects"}, {"score": 0.004720043307726269, "phrase": "natural_and_artificial_systems"}, {"score": 0.004272724011826495, "phrase": "nearby_objects"}, {"score": 0.0041469500929423595, "phrase": "fundamental_skill"}, {"score": 0.004024863549087511, "phrase": "natural_or_artificial_agent"}, {"score": 0.0035358770665604657, "phrase": "visual_cues"}, {"score": 0.0034317185678527672, "phrase": "artificial_systems"}, {"score": 0.002955050521440921, "phrase": "biologically_plausible_model"}, {"score": 0.0027284410545226306, "phrase": "neuroscience_findings"}, {"score": 0.0024941578231560055, "phrase": "robotic_vision-based_grasping_setup"}, {"score": 0.002234893735225432, "phrase": "simple_retinal_and_proprioceptive_data"}, {"score": 0.0021049977753042253, "phrase": "stereoptic_and_perspective_cues"}], "paper_keywords": ["Vision-based grasping", " Pose estimation", " Cue integration", " Neural coding"], "paper_abstract": "Being able to estimate pose and location of nearby objects is a fundamental skill for any natural or artificial agent actively interacting with its environment. The methods for extraction and integration of visual cues employed in artificial systems are usually very different from the solutions found in nature. We present a biologically plausible model of distance and orientation estimation based on neuroscience findings that is suitable to be implemented in a robotic vision-based grasping setup. Key novelties of the model are the use of simple retinal and proprioceptive data, and the integration between stereoptic and perspective cues. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Distance and orientation estimation of graspable objects in natural and artificial systems", "paper_id": "WOS:000263372000021"}