{"auto_keywords": [{"score": 0.04963419481547922, "phrase": "image_classification"}, {"score": 0.03826559283990352, "phrase": "ss-mmsl"}, {"score": 0.03657649623565428, "phrase": "different_modalities"}, {"score": 0.00481495049065317, "phrase": "subspace_learning"}, {"score": 0.004573953147933065, "phrase": "high_accuracy"}, {"score": 0.004447600571127578, "phrase": "multiple_features"}, {"score": 0.004205226397573506, "phrase": "color_image"}, {"score": 0.0040890178236849825, "phrase": "visual_features"}, {"score": 0.0037242701420971062, "phrase": "new_subspace_learning_method"}, {"score": 0.003672427620845944, "phrase": "semi-supervised_multimodal_subspace_learning"}, {"score": 0.003504756881063581, "phrase": "different_features"}, {"score": 0.003407839062159497, "phrase": "meaningful_subspace"}, {"score": 0.003313592421224647, "phrase": "new_method"}, {"score": 0.0032674478600540477, "phrase": "discriminative_information"}, {"score": 0.0032219438233946312, "phrase": "labeled_data"}, {"score": 0.0031770714776989282, "phrase": "local_patches"}, {"score": 0.0030604342671868836, "phrase": "optimal_low_dimensional_subspace"}, {"score": 0.0029757667083164627, "phrase": "local_patch_construction"}, {"score": 0.0029343128039167185, "phrase": "data_distribution"}, {"score": 0.002893434697072309, "phrase": "unlabeled_data"}, {"score": 0.0027100527874262446, "phrase": "low_dimensional_subspace"}, {"score": 0.002538263784314365, "phrase": "alternating_and_iterative_optimization_algorithm"}, {"score": 0.0024912073108138613, "phrase": "complementary_characteristics"}, {"score": 0.0024336086025284836, "phrase": "iterative_procedure"}, {"score": 0.0023996890513009726, "phrase": "global_minimum"}, {"score": 0.0023223663501882896, "phrase": "strong_convexity"}, {"score": 0.002226592967032469, "phrase": "cartoon_retrieval"}, {"score": 0.0021649437083408425, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Subspace", " Image classification", " Semi-supervised learning", " Multimodality"], "paper_abstract": "In recent years we witnessed a surge of interest in subspace learning for image classification. However, the previous methods lack of high accuracy since they do not consider multiple features of the images. For instance, we can represent a color image by finding a set of visual features to represent the information of its color, texture and shape. According to the \"Patch Alignment\" Framework, we developed a new subspace learning method, termed Semi-Supervised Multimodal Subspace Learning (SS-MMSL), in which we can encode different features from different modalities to build a meaningful subspace. In particular, the new method adopts the discriminative information from the labeled data to construct local patches and aligns these patches to get the optimal low dimensional subspace for each modality. For local patch construction, the data distribution revealed by unlabeled data is utilized to enhance the subspace learning. In order to find a low dimensional subspace wherein the distribution of each modality is sufficiently smooth, SS-MMSL adopts an alternating and iterative optimization algorithm to explore the complementary characteristics of different modalities. The iterative procedure reaches the global minimum of the criterion due to the strong convexity of the criterion. Our experiments of image classification and cartoon retrieval demonstrate the validity of the proposed method. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Image classification by multimodal subspace learning", "paper_id": "WOS:000304235500021"}