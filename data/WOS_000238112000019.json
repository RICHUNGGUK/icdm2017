{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "global_exponential_stability"}, {"score": 0.04763743657605741, "phrase": "generalized_neural_networks"}, {"score": 0.04669299523622419, "phrase": "time-varying_delays"}, {"score": 0.04015739943513435, "phrase": "activation_functions"}, {"score": 0.003946960862020283, "phrase": "lipschitz_condition"}, {"score": 0.003668475643547562, "phrase": "lyapunov"}, {"score": 0.003629882559085245, "phrase": "functional_and_several_new_inequalities"}, {"score": 0.0029131986574478046, "phrase": "physical_parameters"}, {"score": 0.0028527866590859967, "phrase": "neural_networks"}, {"score": 0.0027356847952125433, "phrase": "new_criteria"}, {"score": 0.0024634797027967203, "phrase": "bounded_or_monotone_nondecreasing"}, {"score": 0.002387214876538434, "phrase": "connection_weight_matrices"}, {"score": 0.0021049977753042253, "phrase": "previously_known_criteria"}], "paper_keywords": [""], "paper_abstract": "In this paper, we essentially drop the requirement of Lipschitz condition on the activation functions. By employing Lyapunov functional and several new inequalities, some new criteria concerning global exponential stability for a class of generalized neural networks with time-varying delays are obtained, which only depend on physical parameters of neural networks. Since these new criteria do not require the activation functions to be differentiable. bounded or monotone nondecreasing and the connection weight matrices to be symmetric, they are mild and more general than previously known criteria.", "paper_title": "New criteria of global exponential stability for a class of generalized neural networks with time-varying delays", "paper_id": "WOS:000238112000019"}