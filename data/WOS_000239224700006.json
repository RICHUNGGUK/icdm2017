{"auto_keywords": [{"score": 0.04896848785083955, "phrase": "user_assistance"}, {"score": 0.00481495049065317, "phrase": "decision-theoretic_framework"}, {"score": 0.004594137808658537, "phrase": "increasing_interest"}, {"score": 0.004529881123652277, "phrase": "intelligent_human-computer_interaction_systems"}, {"score": 0.004362870617347183, "phrase": "user_affective_states"}, {"score": 0.004241648852523704, "phrase": "timely_and_appropriate_assistance"}, {"score": 0.004066076430818046, "phrase": "general_unified_decision-theoretic_framework"}, {"score": 0.003807242767474929, "phrase": "affective_state_recognition"}, {"score": 0.0037363522297378777, "phrase": "active_probabilistic_inference"}, {"score": 0.003684048704119722, "phrase": "available_multi_modality_sensory_data"}, {"score": 0.003531474887552889, "phrase": "decision-making_process"}, {"score": 0.003369322866499541, "phrase": "productive_affective_states"}, {"score": 0.0030525578912808647, "phrase": "active_sensory_action_selection"}, {"score": 0.002939853413763817, "phrase": "proposed_framework"}, {"score": 0.0028986672783671147, "phrase": "simulation_study"}, {"score": 0.0028446460307503343, "phrase": "efficient_user"}, {"score": 0.002765490759189057, "phrase": "timely_and_appropriate_user_assistance"}, {"score": 0.0027139447110929586, "phrase": "theoretical_contributions"}, {"score": 0.0026508575391771807, "phrase": "non-invasive_real-time_prototype_system"}, {"score": 0.002493592357827492, "phrase": "four-modality_user_measurements"}, {"score": 0.002291089893848235, "phrase": "affect_recognition"}, {"score": 0.0022589720760078274, "phrase": "prototype_system"}, {"score": 0.002196077907454079, "phrase": "real-world_study"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["affective computing", " human-computer interaction", " influence diagrams", " active sensing", " stress modeling", " fatigue recognition"], "paper_abstract": "There is an increasing interest in developing intelligent human-computer interaction systems that can fulfill two functions-recognizing user affective states and providing the user with timely and appropriate assistance. In this paper, we present a general unified decision-theoretic framework based on influence diagrams for simultaneously modeling user affect recognition and assistance. Affective state recognition is achieved through active probabilistic inference from the available multi modality sensory data. User assistance is automatically accomplished through a decision-making process that balances the benefits of keeping the user in productive affective states and the costs of performing user assistance. We discuss three theoretical issues within the framework, namely, user affect recognition, active sensory action selection, and user assistance. Validation of the proposed framework via a simulation study demonstrates its capability in efficient user affect recognition as well as timely and appropriate user assistance. Besides the theoretical contributions, we build a non-invasive real-time prototype system to recognize different user affective states (stress and fatigue) from four-modality user measurements, namely physical appearance features, physiological measures, user performance, and behavioral data. The affect recognition component.,of the prototype system is subsequently validated through a real-world study involving human subjects. (c) 2006 Elsevier Ltd. All rights reserved.", "paper_title": "Toward a decision-theoretic framework for affect recognition and user assistance", "paper_id": "WOS:000239224700006"}