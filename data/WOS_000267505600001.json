{"auto_keywords": [{"score": 0.013014855256672328, "phrase": "bias_problem"}, {"score": 0.00481495049065317, "phrase": "classification_error_rate"}, {"score": 0.004732215871738028, "phrase": "repeated_hold-out"}, {"score": 0.004544629724830453, "phrase": "accuracy_estimation"}, {"score": 0.004289419884432487, "phrase": "naive_resubstitution_estimate"}, {"score": 0.004143196873246147, "phrase": "downward_bias_problem"}, {"score": 0.004071957673937727, "phrase": "traditional_approach"}, {"score": 0.0036907133026806327, "phrase": "high_variability"}, {"score": 0.0035648266669315943, "phrase": "direct_comparison"}, {"score": 0.003287482882222731, "phrase": "latter_estimator"}, {"score": 0.003156984631072011, "phrase": "empirical_study"}, {"score": 0.0029794666460666646, "phrase": "repeated_one-third_holdout_estimator"}, {"score": 0.00273167822885383, "phrase": "simulation_study"}, {"score": 0.002608040688794517, "phrase": "better_performance"}, {"score": 0.002432971714608409, "phrase": "training_sample"}, {"score": 0.0022434880661725493, "phrase": "large_samples"}, {"score": 0.0021794454466797382, "phrase": "small_samples"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": [""], "paper_abstract": "We consider the accuracy estimation of a classifier constructed on a given training sample. The naive resubstitution estimate is known to have a downward bias problem. The traditional approach to tackling this bias problem is cross-validation. The bootstrap is another way to bring down the high variability of cross-validation. But a direct comparison of the two estimators, cross-validation and bootstrap, is not fair because the latter estimator requires much heavier computation. We performed an empirical study to compare the .632+ bootstrap estimator with the repeated 10-fold cross-validation and the repeated one-third holdout estimator. All the estimators were set to require about the same amount of computation. In the simulation study, the repeated 10-fold cross-validation estimator was found to have better performance than the .632+ bootstrap estimator when the classifier is highly adaptive to the training sample. We have also found that the .632+ bootstrap estimator suffers from a bias problem for large samples as well as for small samples. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Estimating classification error rate: Repeated cross-validation, repeated hold-out and bootstrap", "paper_id": "WOS:000267505600001"}