{"auto_keywords": [{"score": 0.04881182805984396, "phrase": "gesture-based_interaction"}, {"score": 0.004814951205791257, "phrase": "figi"}, {"score": 0.004539005582217305, "phrase": "promising_technology"}, {"score": 0.004466519142879166, "phrase": "wide_range"}, {"score": 0.00441883624011048, "phrase": "applicative_fields"}, {"score": 0.0043482604833437735, "phrase": "computer_based_training"}, {"score": 0.004301834610818624, "phrase": "systems_maintenance"}, {"score": 0.004255902303152008, "phrase": "medical_imaging"}, {"score": 0.004055176557424983, "phrase": "floating_interface"}, {"score": 0.004011867299107537, "phrase": "gesture-based_interaction_architecture"}, {"score": 0.0038226070564362697, "phrase": "context_adaptive_head-up_interface"}, {"score": 0.0036815763368083197, "phrase": "central_region"}, {"score": 0.0036227329311981195, "phrase": "user's_visual_field"}, {"score": 0.0032536902910768957, "phrase": "real_environment"}, {"score": 0.003150466780962537, "phrase": "interaction_paradigm"}, {"score": 0.003050508020268648, "phrase": "time-based_gestures"}, {"score": 0.0028293966058473476, "phrase": "even_conventional_keyboard-based_functions"}, {"score": 0.002695768552609587, "phrase": "physical_interface"}, {"score": 0.0026242699269026204, "phrase": "floating_keyboard_layout"}, {"score": 0.0025409639091476363, "phrase": "overall_system_architecture"}, {"score": 0.002473560912156024, "phrase": "interactive_visualization"}, {"score": 0.002447101794397243, "phrase": "tri-dimensional_models"}, {"score": 0.0023314867226678555, "phrase": "educational_purposes"}, {"score": 0.0022213218042340735, "phrase": "evaluation_study"}, {"score": 0.0021392418081444798, "phrase": "eventual_limitations"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Gesture-based interface", " 3D object manipulation", " Contact-less interaction", " Mixed reality", " Medical imaging"], "paper_abstract": "Mixed reality represents a promising technology for a wide range of applicative fields, including computer based training, systems maintenance and medical imaging, just to name a few. The floating interface for gesture-based interaction architecture presented in this study, puts together a context adaptive head-up interface, which is projected in the central region of the user's visual field, with gesture-based interaction, to enable easy, robust and powerful manipulation of the virtual contents which are visualized after being mapped onto the real environment surrounding the user. The interaction paradigm combines one-hand, two-hands and time-based gestures to select tools/functions among those available as well as to operate them. Even conventional keyboard-based functions like typing, can be performed without a physical interface by means of a floating keyboard layout. The paper describes the overall system architecture and its application to the interactive visualization of tri-dimensional models of human anatomy, for either training or educational purposes. We also report the results of an evaluation study to assess usability, effectiveness and eventual limitations of the proposed approach.", "paper_title": "FIGI: floating interface for gesture-based interaction", "paper_id": "WOS:000351240600005"}