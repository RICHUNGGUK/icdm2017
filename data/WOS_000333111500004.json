{"auto_keywords": [{"score": 0.04964156968469263, "phrase": "mobile_landmark_recognition"}, {"score": 0.00481495049065317, "phrase": "-visual_phrase"}, {"score": 0.00443308765153716, "phrase": "category-dependent_visual_phrases"}, {"score": 0.004081385289516914, "phrase": "neighboring_visual_words"}, {"score": 0.0038802832668554457, "phrase": "visual_phrase_learning"}, {"score": 0.0037402558657576124, "phrase": "generalized_phrase_dictionary"}, {"score": 0.0035887342563437935, "phrase": "descriptive_capability"}, {"score": 0.0035395987202335223, "phrase": "specific_category"}, {"score": 0.0033961782274326948, "phrase": "hard_assignment"}, {"score": 0.0033651019362620866, "phrase": "numerous_feature_sets"}, {"score": 0.0033190180867511605, "phrase": "limited_number"}, {"score": 0.003213920601037463, "phrase": "useful_feature_sets"}, {"score": 0.002945081009084692, "phrase": "discriminative_soft_bop_approach"}, {"score": 0.002878140062594849, "phrase": "candidate_phrases"}, {"score": 0.00283870598459543, "phrase": "adjacent_pairwise_codewords"}, {"score": 0.002723607240517261, "phrase": "important_candidates"}, {"score": 0.0026494723416072316, "phrase": "proposed_discriminative_visual_phrase"}, {"score": 0.0026011706232569316, "phrase": "selection_approach"}, {"score": 0.0025537472239953807, "phrase": "bop_dictionary"}, {"score": 0.0024956789310376635, "phrase": "soft_encoding_method"}, {"score": 0.0023944552329463035, "phrase": "bop_histogram"}, {"score": 0.002361632539339945, "phrase": "context_information"}, {"score": 0.002276283303864666, "phrase": "mobile_devices"}, {"score": 0.002214297250267208, "phrase": "proposed_bop-based_content_analysis"}, {"score": 0.002163930783583212, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Location and direction", " mobile landmark recognition", " soft BoP"], "paper_abstract": "This paper proposes a new bag-of-visual phrase (BoP) approach for mobile landmark recognition based on discriminative learning of category-dependent visual phrases. Many previous landmark recognition works adopt a bag-of-words (BoW) method which ignores the co-occurrence relationship between neighboring visual words in an image. Although some works that focus on visual phrase learning have appeared, they mainly construct a generalized phrase dictionary from all categories for recognition, which lacks descriptive capability for a specific category. Another shortcoming of these works is the hard assignment of numerous feature sets to a limited number of phrases, which causes some useful feature sets to be discarded, and yields information loss. In view of this, this paper presents a discriminative soft BoP approach for mobile landmark recognition. The candidate phrases defined as adjacent pairwise codewords are first generated for each category. The important candidates are then selected through a proposed discriminative visual phrase (DVP) selection approach to form the BoP dictionary. Finally, a soft encoding method is developed to quantize each image into a BoP histogram. The context information such as location and direction captured by mobile devices is also integrated with the proposed BoP-based content analysis for landmark recognition. Experimental results on two datasets show that the proposed method is effective in mobile landmark recognition.", "paper_title": "Discriminative Soft Bag-of-Visual Phrase for Mobile Landmark Recognition", "paper_id": "WOS:000333111500004"}