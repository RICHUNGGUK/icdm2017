{"auto_keywords": [{"score": 0.03889065839041926, "phrase": "face_images"}, {"score": 0.00481495049065317, "phrase": "realistic_facial_animation"}, {"score": 0.0047283116134926645, "phrase": "articulatory_dbn_model"}, {"score": 0.004685575787741084, "phrase": "aam_features"}, {"score": 0.004559661374976129, "phrase": "photo_realistic_facial_animation_synthesis_approach"}, {"score": 0.004477595431209663, "phrase": "audio_visual_articulatory_dynamic_bayesian_network_model"}, {"score": 0.004317848984770719, "phrase": "maximum_asynchronies"}, {"score": 0.004259418153299952, "phrase": "articulatory_features"}, {"score": 0.003996983218174335, "phrase": "perceptual_linear_prediction"}, {"score": 0.003960843994438556, "phrase": "plp"}, {"score": 0.0038895008852940323, "phrase": "audio_speech"}, {"score": 0.003802135020791801, "phrase": "active_appearance_model"}, {"score": 0.003767743594558914, "phrase": "aam"}, {"score": 0.0036497740708342093, "phrase": "audio_visual_continuous_speech_database"}, {"score": 0.003535489842686145, "phrase": "af_avdbn_model_parameters"}, {"score": 0.0034560481756572632, "phrase": "trained_model"}, {"score": 0.0033937776228549557, "phrase": "input_audio_speech"}, {"score": 0.00334780964309978, "phrase": "optimal_aam_visual_features"}, {"score": 0.0032725712584012953, "phrase": "maximum_likelihood_estimation"}, {"score": 0.002988101395789399, "phrase": "facial_animations"}, {"score": 0.0028813415821988156, "phrase": "proposed_af_avdbn_model"}, {"score": 0.0028037753646260937, "phrase": "state-of-art_methods"}, {"score": 0.002753224894944965, "phrase": "audio_visual_state_synchronous_dbn_model"}, {"score": 0.0026790983342162887, "phrase": "multi-stream_hidden_markov_model"}, {"score": 0.002536763634539386, "phrase": "objective_evaluations"}, {"score": 0.002502374576203785, "phrase": "learned_aam_features"}, {"score": 0.002401972657236928, "phrase": "af_avdbn_model"}, {"score": 0.0023802126605244438, "phrase": "subjective_evaluations"}, {"score": 0.0023372808856170386, "phrase": "synthesized_facial_animations"}, {"score": 0.002233301265743633, "phrase": "based_sa_dbn_and_ss_dbn_models"}, {"score": 0.002193013499219711, "phrase": "overall_naturalness"}, {"score": 0.002133937537670314, "phrase": "mouth_movements"}, {"score": 0.0021049977753042253, "phrase": "speech_content"}], "paper_keywords": ["Facial animation", " AF_AVDBN", " Asynchrony", " AAM"], "paper_abstract": "This paper presents a photo realistic facial animation synthesis approach based on an audio visual articulatory dynamic Bayesian network model (AF_AVDBN), in which the maximum asynchronies between the articulatory features, such as lips, tongue and glottis/velum, can be controlled. Perceptual Linear Prediction (PLP) features from audio speech, as well as active appearance model (AAM) features from face images of an audio visual continuous speech database, are adopted to train the AF_AVDBN model parameters. Based on the trained model, given an input audio speech, the optimal AAM visual features are estimated via a maximum likelihood estimation (MLE) criterion, which are then used to construct face images for the animation. In our experiments, facial animations are synthesized for 20 continuous audio speech sentences, using the proposed AF_AVDBN model, as well as the state-of-art methods, being the audio visual state synchronous DBN model (SS_DBN) implementing a multi-stream Hidden Markov Model, and the state asynchronous DBN model (SA_DBN). Objective evaluations on the learned AAM features show that much more accurate visual features can be learned from the AF_AVDBN model. Subjective evaluations show that the synthesized facial animations using AF_AVDBN are better than those using the state based SA_DBN and SS_DBN models, in the overall naturalness and matching accuracy of the mouth movements to the speech content.", "paper_title": "Speech driven photo realistic facial animation based on an articulatory DBN model and AAM features", "paper_id": "WOS:000342418700020"}