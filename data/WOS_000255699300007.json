{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "grapheme-to-phoneme_conversion"}, {"score": 0.004200724305692705, "phrase": "important_applications"}, {"score": 0.003953409087444568, "phrase": "speech_recognition"}, {"score": 0.0038938807148174975, "phrase": "joint-sequence_models"}, {"score": 0.0038062581748678245, "phrase": "simple_and_theoretically_stringent_probabilistic_framework"}, {"score": 0.0034749794034364197, "phrase": "self-contained_and_detailed_description"}, {"score": 0.0032702516771609957, "phrase": "novel_estimation_algorithm"}, {"score": 0.0031966173935538992, "phrase": "high_accuracy"}, {"score": 0.0028525124381208705, "phrase": "maximum_approximation"}, {"score": 0.0026640466056415298, "phrase": "model_size_parameters"}, {"score": 0.0021049977753042253, "phrase": "open_source_license"}], "paper_keywords": ["grapheme-to-phoneme", " letter-to-sound", " phonemic transcription", " joint-sequence model", " pronunciation modeling"], "paper_abstract": "Grapheme-to-phoneme conversion is the task of finding the pronunciation of a word given its written form. It has important applications in text-to-speech and speech recognition. Joint-sequence models are a simple and theoretically stringent probabilistic framework that is applicable to this problem. This article provides a self-contained and detailed description of this method. We present a novel estimation algorithm and demonstrate high accuracy on a variety of databases. Moreover, we study the impact of the maximum approximation in training and transcription, the interaction of model size parameters, n-best list generation, confidence measures, and phoneme-to-grapheme conversion. Our software implementation of the method proposed in this work is available under an Open Source license. (c) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Joint-sequence models for grapheme-to-phoneme conversion", "paper_id": "WOS:000255699300007"}