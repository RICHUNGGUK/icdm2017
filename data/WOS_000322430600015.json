{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "spectro-temporal_domain"}, {"score": 0.004524348699657099, "phrase": "significant_increase"}, {"score": 0.004423061344624088, "phrase": "auditory_models"}, {"score": 0.004373267443572639, "phrase": "speech_recognition_systems"}, {"score": 0.004156012879026324, "phrase": "new_evolutionary_tuned_feature_extraction_method"}, {"score": 0.0038610400240820307, "phrase": "special_subspace"}, {"score": 0.0037320255482878365, "phrase": "specific_best_scale"}, {"score": 0.0036691380448651443, "phrase": "spectral_filter"}, {"score": 0.0036073064072936626, "phrase": "specific_best_rate"}, {"score": 0.003546513036085932, "phrase": "temporal_filter"}, {"score": 0.0034086028336466688, "phrase": "genetic_cellular_automata_evolutionary_algorithm"}, {"score": 0.0032760377953971248, "phrase": "specific_subspace"}, {"score": 0.0031845067058084583, "phrase": "binary_one-versus-rest_support_vector_machine"}, {"score": 0.0028756028995504035, "phrase": "proposed_method"}, {"score": 0.0027325449069867222, "phrase": "highly_confusable_phonemes"}, {"score": 0.0026113524778702624, "phrase": "proposed_feature_sets"}, {"score": 0.0024673738215365104, "phrase": "achieved_relative_improvements"}, {"score": 0.0024120247307686084, "phrase": "classification_rate"}, {"score": 0.0023848164282879885, "phrase": "voiced_plosives"}, {"score": 0.0023579143175099324, "phrase": "unvoiced_plosives"}, {"score": 0.0022661190184053628, "phrase": "front_vowels"}, {"score": 0.0021778895748464045, "phrase": "art_baseline_model"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": [""], "paper_abstract": "Recently, there has been a significant increase in studies employing auditory models in speech recognition systems. In this paper, we propose a new evolutionary tuned feature extraction method by spectro-temporal analysis. In our proposed model, there is a special subspace for each phoneme with a specific best scale in the spectral filter and a specific best rate in the temporal filter. These two parameters were obtained by genetic cellular automata evolutionary algorithm. The extracted features from the specific subspace are classified by a binary one-versus-rest support vector machine. Finally, a multiclass classifier for all phonemes is employed by combining these sub-models. The proposed method improved the discrimination of phonemes significantly especially in highly confusable phonemes. To show the efficiency of the proposed feature sets, it was empirically compared with two baseline models. The achieved relative improvements are about 10% in classification rate for voiced plosives, unvoiced plosives and nasals; and about 7.38% for front vowels relative to the state of the art baseline model. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "A scale-rate filter selection method in the spectro-temporal domain for phoneme classification", "paper_id": "WOS:000322430600015"}