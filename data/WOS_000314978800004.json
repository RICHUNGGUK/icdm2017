{"auto_keywords": [{"score": 0.03315467897128237, "phrase": "schemol"}, {"score": 0.004657808551825796, "phrase": "competitive_advantage"}, {"score": 0.004520750567829338, "phrase": "social_networking_websites"}, {"score": 0.0044759626695474106, "phrase": "valuable_information"}, {"score": 0.0043731680194078046, "phrase": "third-party_applications"}, {"score": 0.004272724011826495, "phrase": "data_analysis"}, {"score": 0.004244449986839909, "phrase": "model-driven_engineering"}, {"score": 0.004065171748689355, "phrase": "mde"}, {"score": 0.003803939387792038, "phrase": "sql_scripts"}, {"score": 0.0036553070575015344, "phrase": "laborious_code"}, {"score": 0.0034317185678527672, "phrase": "domain-specific_language"}, {"score": 0.003352825186671963, "phrase": "\"how\"_concerns"}, {"score": 0.003106147643534726, "phrase": "dsl"}, {"score": 0.0029160193808720016, "phrase": "general_frameworks"}, {"score": 0.002830068550982961, "phrase": "database_schema"}, {"score": 0.002792684414954618, "phrase": "mediawiki"}, {"score": 0.0027284410545226306, "phrase": "table_names"}, {"score": 0.0026745503978347143, "phrase": "extraction_process"}, {"score": 0.002453027723284009, "phrase": "semantic_markups"}, {"score": 0.0024286751532861476, "phrase": "helpful_hints"}, {"score": 0.0024125742420201, "phrase": "model_extraction"}, {"score": 0.0023259039577313294, "phrase": "opaque_strings"}, {"score": 0.0022723746977318642, "phrase": "considerable_conceptual_gap"}, {"score": 0.002249811525923913, "phrase": "source_database"}, {"score": 0.0022274718912558343, "phrase": "target_metamodel"}, {"score": 0.0021980296285911915, "phrase": "extractive_functions"}, {"score": 0.002183454435945014, "phrase": "view-like_mechanisms"}, {"score": 0.002126111716875144, "phrase": "blojsom"}, {"score": 0.0021049977753042253, "phrase": "blog_engine"}], "paper_keywords": ["Model-driven engineering", " Web2.0", " Harvesting", " Data re-engineering", " Databases"], "paper_abstract": "Data rather than functionality are the sources of competitive advantage for Web2.0 applications such as wikis, blogs and social networking websites. This valuable information might need to be capitalized by third-party applications or be subject to migration or data analysis. Model-Driven Engineering (MDE) can be used for these purposes. However, MDE first requires obtaining models from the wiki/blog/website database (a.k.a. model harvesting). This can be achieved through SQL scripts embedded in a program. However, this approach leads to laborious code that exposes the iterations and table joins that serve to build the model. By contrast, a Domain-Specific Language (DSL) can hide these \"how\" concerns, leaving the designer to focus on the \"what\", i.e. the mapping of database schemas to model classes. This paper introduces Schemol, a DSL tailored for extracting models out of databases which considers Web2.0 specifics. Web2.0 applications are often built on top of general frameworks (a.k.a. engines) that set the database schema (e.g., MediaWiki, Blojsom). Hence, table names offer little help in automating the extraction process. In addition, Web2.0 data tend to be annotated. User-provided data (e.g., wiki articles, blog entries) might contain semantic markups which provide helpful hints for model extraction. Unfortunately, these data end up being stored as opaque strings. Therefore, there exists a considerable conceptual gap between the source database and the target metamodel. Schemol offers extractive functions and view-like mechanisms to confront these issues. Examples using Blojsom as the blog engine are available for download.", "paper_title": "Harvesting models from web 2.0 databases", "paper_id": "WOS:000314978800004"}