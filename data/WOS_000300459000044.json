{"auto_keywords": [{"score": 0.04916809664432026, "phrase": "multiple_data_sets"}, {"score": 0.00481495049065317, "phrase": "supervised_learning_algorithms"}, {"score": 0.0043738432231020885, "phrase": "statistical_tests"}, {"score": 0.003215295260684715, "phrase": "multiple_learning_algorithms"}, {"score": 0.002730023736069673, "phrase": "prior_cost_term"}, {"score": 0.0024088451312725924, "phrase": "pairwise_tests"}, {"score": 0.002166711569953301, "phrase": "space_complexity"}, {"score": 0.0021049977753042253, "phrase": "learning_algorithms"}], "paper_keywords": ["Machine learning", " Statistical tests", " Classifier comparison", " Model selection", " Model complexity"], "paper_abstract": "In the literature, there exist statistical tests to compare supervised learning algorithms on multiple data sets in terms of accuracy but they do not always generate an ordering. We propose Multi(2)Test, a generalization of our previous work, for ordering multiple learning algorithms on multiple data sets from \"best\" to \"worst\" where our goodness measure is composed of a prior cost term additional to generalization error. Our simulations show that Multi2Test generates orderings using pairwise tests on error and different types of cost using time and space complexity of the learning algorithms. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Cost-conscious comparison of supervised learning algorithms over multiple data sets", "paper_id": "WOS:000300459000044"}