{"auto_keywords": [{"score": 0.03812022871741232, "phrase": "partition-based_techniques"}, {"score": 0.00481495049065317, "phrase": "partition-based_dimension_reduction_techniques"}, {"score": 0.004692227830462433, "phrase": "high_dimensional_space"}, {"score": 0.004620093797504386, "phrase": "nontrivial_problem"}, {"score": 0.004525629293824217, "phrase": "so-called_curse"}, {"score": 0.00443308765153716, "phrase": "recent_techniques"}, {"score": 0.004364919932563366, "phrase": "piecewise_aggregate_approximation"}, {"score": 0.004188198923320451, "phrase": "smean"}, {"score": 0.004123781267600542, "phrase": "mean-standard_deviation"}, {"score": 0.0038959121068990517, "phrase": "data_dimensionality"}, {"score": 0.0037381083634085424, "phrase": "aggregate_values"}, {"score": 0.003680587852807675, "phrase": "dimension_subset"}, {"score": 0.0032510690712452147, "phrase": "different_characteristics"}, {"score": 0.0031845067058084583, "phrase": "diverse_applications"}, {"score": 0.0031193028729331667, "phrase": "subspace_projection"}, {"score": 0.0030239842475439814, "phrase": "unified_framework"}, {"score": 0.0028273061946184645, "phrase": "fixed_number"}, {"score": 0.0027982016314450717, "phrase": "salient_features"}, {"score": 0.002726740692380339, "phrase": "reference_vector"}, {"score": 0.0026161698049580804, "phrase": "query_selectivity"}, {"score": 0.00257586859792573, "phrase": "corresponding_space"}, {"score": 0.0023834640793589414, "phrase": "partitioning_configuration"}, {"score": 0.002298649369775623, "phrase": "greedy_algorithm"}, {"score": 0.0022399174232611853, "phrase": "good_partitioning"}, {"score": 0.0022053994402287925, "phrase": "data_dimensions"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["SubSpace Projection", " Dimensionality reduction", " Similarity search", " Multidimensional indexing", " Dimension partition"], "paper_abstract": "Similarity search in high dimensional space is a nontrivial problem due to the so-called curse of dimensionality. Recent techniques such as Piecewise Aggregate Approximation (PAA), Segmented Means (SMEAN) and Mean-Standard deviation (MS) prove to be very effective in reducing data dimensionality by partitioning dimensions into subsets and extracting aggregate values from each dimension subset. These partition-based techniques have many advantages including very efficient multi-phased approximation while being simple to implement. They, however, are not adaptive to the different characteristics of data in diverse applications. We propose SubSpace Projection (SSP) as a unified framework for these partition-based techniques. SSP projects data onto subspaces and computes a fixed number of salient features with respect to a reference vector. A study of the relationships between query selectivity and the corresponding space partitioning schemes uncovers indicators that can be used to predict the performance of the partitioning configuration. Accordingly, we design a greedy algorithm to efficiently determine a good partitioning of the data dimensions. The results of our extensive experiments indicate that the proposed method consistently outperforms state-of-the-art techniques. (C) 2008 Elsevier Inc. All rights reserved.", "paper_title": "SubSpace Projection: A unified framework for a class of partition-based dimension reduction techniques", "paper_id": "WOS:000264567500003"}