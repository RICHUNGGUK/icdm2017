{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "classification_time"}, {"score": 0.049521347818116, "phrase": "attribute_selection"}, {"score": 0.04869658238235114, "phrase": "data_preprocessing_step"}, {"score": 0.04735086985834179, "phrase": "relevant_attributes"}, {"score": 0.004461761855323898, "phrase": "target_machine"}, {"score": 0.00440976345264104, "phrase": "task_-_namely_classification"}, {"score": 0.0039218440805789965, "phrase": "lazy_learning_approach"}, {"score": 0.003367077034382727, "phrase": "attribute_values"}, {"score": 0.003138124398958758, "phrase": "best_attributes"}, {"score": 0.0030833537429977797, "phrase": "correct_classification"}, {"score": 0.0030295361111006866, "phrase": "particular_instance"}, {"score": 0.002994178996584381, "phrase": "experimental_results"}, {"score": 0.0029075757820516634, "phrase": "naive_bayes_classifiers"}, {"score": 0.0027905114793984084, "phrase": "five_large_data_sets"}, {"score": 0.002555247330102505, "phrase": "proposed_lazy_technique"}, {"score": 0.0023674192513753996, "phrase": "analogous_attribute_selection_approach"}, {"score": 0.0021677478798910565, "phrase": "specific_data_set"}, {"score": 0.0021049977753042253, "phrase": "lazy_attribute_selection_approach"}], "paper_keywords": ["Attribute selection", " classification", " lazy learning"], "paper_abstract": "Attribute selection is a data preprocessing step which aims at identifying relevant attributes for the target machine learning task - namely classification in this paper. In this paper, we propose a new attribute selection strategy - based on a lazy learning approach - which postpones the identification of relevant attributes until an instance is submitted for classification. Our strategy relies on the hypothesis that taking into account the attribute values of an instance to be classified may contribute to identifying the best attributes for the correct classification of that particular instance. Experimental results using the k-NN and Naive Bayes classifiers, over 40 different data sets from the UCI Machine Learning Repository and five large data sets from the NIPS 2003 feature selection challenge, show the effectiveness of delaying attribute selection to classification time. The proposed lazy technique in most cases improves the accuracy of classification, when compared with the analogous attribute selection approach performed as a data preprocessing step. We also propose a metric to estimate when a specific data set can benefit from the lazy attribute selection approach.", "paper_title": "Lazy attribute selection: Choosing attributes at classification time", "paper_id": "WOS:000294432100005"}