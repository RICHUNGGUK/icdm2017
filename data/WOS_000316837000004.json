{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "underdetermined_blind_speech_separation"}, {"score": 0.04754843024727077, "phrase": "proposed_algorithm"}, {"score": 0.004755054742217193, "phrase": "block-based_approach"}, {"score": 0.004695900553353526, "phrase": "adaptive_dictionary_learning"}, {"score": 0.004466519142879166, "phrase": "multi-stage_method"}, {"score": 0.004337900700685262, "phrase": "underdetermined_blind_source_separation_problem"}, {"score": 0.004283913685201902, "phrase": "sparse_coding_problem"}, {"score": 0.004195418010131832, "phrase": "mixing_matrix"}, {"score": 0.004108742905942481, "phrase": "transform_domain"}, {"score": 0.004057596233938867, "phrase": "clustering_algorithm"}, {"score": 0.00390792986752692, "phrase": "adaptive_learning_algorithm"}, {"score": 0.0037480753312398754, "phrase": "simultaneous_codeword_optimization"}, {"score": 0.0035499650812710806, "phrase": "estimated_mixing_matrix"}, {"score": 0.003505749731180509, "phrase": "learned_dictionary"}, {"score": 0.0033905067962602515, "phrase": "blocked_mixtures"}, {"score": 0.0033482708495261864, "phrase": "signal_recovery_approach"}, {"score": 0.003306559295382181, "phrase": "separated_source_components"}, {"score": 0.003197843245296877, "phrase": "whole_signal"}, {"score": 0.0031579997262619758, "phrase": "block-based_operation"}, {"score": 0.0030541531847589833, "phrase": "computational_efficiency"}, {"score": 0.0030160945545795468, "phrase": "source_recovery_process"}, {"score": 0.002953711377604328, "phrase": "numerical_experiments"}, {"score": 0.0028805474861014722, "phrase": "competitive_separation_performance"}, {"score": 0.002671722386856879, "phrase": "mutual_coherence"}, {"score": 0.0026494723416072316, "phrase": "sparsity_index"}, {"score": 0.002509284173541882, "phrase": "underdetermined_speech_separation"}, {"score": 0.0023864566654035924, "phrase": "speech_mixtures"}, {"score": 0.0023665766694993535, "phrase": "ground_truth_speech_sources"}, {"score": 0.0022886952510350416, "phrase": "mathematical_transforms"}, {"score": 0.0022601535748259785, "phrase": "discrete_cosine_transform"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Underdetermined blind speech separation (BSS)", " Sparse representation", " Signal recovery", " Adaptive dictionary learning"], "paper_abstract": "A block-based approach coupled with adaptive dictionary learning is presented for underdetermined blind speech separation. The proposed algorithm, derived as a multi-stage method, is established by reformulating the underdetermined blind source separation problem as a sparse coding problem. First, the mixing matrix is estimated in the transform domain by a clustering algorithm. Then a dictionary is learned by an adaptive learning algorithm for which three algorithms have been tested, including the simultaneous codeword optimization (SimCO) technique that we have proposed recently. Using the estimated mixing matrix and the learned dictionary, the sources are recovered from the blocked mixtures by a signal recovery approach. The separated source components from all the blocks are concatenated to reconstruct the whole signal. The block-based operation has the advantage of improving considerably the computational efficiency of the source recovery process without degrading its separation performance. Numerical experiments are provided to show the competitive separation performance of the proposed algorithm, as compared with the state-of-the-art approaches. Using mutual coherence and sparsity index, the performance of a variety of dictionaries that are applied in underdetermined speech separation is compared and analyzed, such as the dictionaries learned from speech mixtures and ground truth speech sources, as well as those predefined by mathematical transforms such as discrete cosine transform (DCT) and short time Fourier transform (STFT). (c) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Sparse coding with adaptive dictionary learning for underdetermined blind speech separation", "paper_id": "WOS:000316837000004"}