{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "real_world"}, {"score": 0.004548253531664032, "phrase": "duplicate_records"}, {"score": 0.004389089062127892, "phrase": "common_key"}, {"score": 0.004087207102190335, "phrase": "difficult_task"}, {"score": 0.0038332390893263844, "phrase": "transcription_errors"}, {"score": 0.0037789720824759503, "phrase": "incomplete_information"}, {"score": 0.0036727235025069828, "phrase": "standard_formats"}, {"score": 0.0032766780632972393, "phrase": "thorough_analysis"}, {"score": 0.003161870571621082, "phrase": "duplicate_record_detection"}, {"score": 0.003072918736387408, "phrase": "similarity_metrics"}, {"score": 0.002923214590192792, "phrase": "similar_field_entries"}, {"score": 0.0028006988338192375, "phrase": "extensive_set"}, {"score": 0.0027610089418453614, "phrase": "duplicate_detection_algorithms"}, {"score": 0.0024984517279573906, "phrase": "multiple_techniques"}, {"score": 0.002326304140277375, "phrase": "detection_algorithms"}, {"score": 0.002212892265364764, "phrase": "existing_tools"}, {"score": 0.002150580119047236, "phrase": "brief_discussion"}, {"score": 0.0021049977753042253, "phrase": "big_open_problems"}], "paper_keywords": ["duplicate detection", " data cleaning", " data integration", " record linkage", " data deduplication", " instance identification", " database hardening", " name matching", " identity uncertainty", " entity resolution", " fuzzy duplicate detection", " entity matching"], "paper_abstract": "Often, in the real world, entities have two or more representations in databases. Duplicate records do not share a common key and/or they contain errors that make duplicate matching a difficult task. Errors are introduced as the result of transcription errors, incomplete information, lack of standard formats, or any combination of these factors. In this paper, we present a thorough analysis of the literature on duplicate record detection. We cover similarity metrics that are commonly used to detect similar field entries, and we present an extensive set of duplicate detection algorithms that can detect approximately duplicate records in a database. We also cover multiple techniques for improving the efficiency and scalability of approximate duplicate detection algorithms. We conclude with coverage of existing tools and with a brief discussion of the big open problems in the area.", "paper_title": "Duplicate record detection: A survey", "paper_id": "WOS:000242041400001"}