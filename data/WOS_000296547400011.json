{"auto_keywords": [{"score": 0.040207278685735884, "phrase": "multiresolution_decomposition"}, {"score": 0.030408555694276515, "phrase": "multi-band_images"}, {"score": 0.02799616000166279, "phrase": "atf_method"}, {"score": 0.00481495049065317, "phrase": "computational_attention"}, {"score": 0.004774324145784758, "phrase": "image_fusion"}, {"score": 0.004615202066192795, "phrase": "new_fusion_image_scheme"}, {"score": 0.004537631845923196, "phrase": "attention_fusion"}, {"score": 0.004312622975366676, "phrase": "multiresolution_space"}, {"score": 0.004240116703465252, "phrase": "attention_map"}, {"score": 0.0037336520904376687, "phrase": "dual-tree_complex_wavelet_transform"}, {"score": 0.0036090884921108086, "phrase": "highest_attention_level"}, {"score": 0.0035634522350563107, "phrase": "input_images"}, {"score": 0.0034299649219748513, "phrase": "main_factors"}, {"score": 0.003301461490509176, "phrase": "fused_image"}, {"score": 0.003150900886669123, "phrase": "axiomatic_score_function"}, {"score": 0.0029565620771207003, "phrase": "multi-focus_images"}, {"score": 0.002821685815956478, "phrase": "first_experiment"}, {"score": 0.002785978280998868, "phrase": "proposed_method"}, {"score": 0.002603012037901889, "phrase": "good_performance"}, {"score": 0.002505412457777352, "phrase": "second_experiment"}, {"score": 0.0024012441367538434, "phrase": "best_performance"}, {"score": 0.0022916496831407386, "phrase": "cwt"}, {"score": 0.002272262136976179, "phrase": "pyr"}, {"score": 0.002253065079253095, "phrase": "dwt"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Computational attention model", " Saliency map", " Dual-tree wavelet transform", " Image fusion", " Objective evaluation"], "paper_abstract": "We present in this paper a new fusion image scheme called as \"Attention Fusion\" (ATF). This scheme, developed in a multiresolution space, uses an attention map to define the level of activity for each one of the coefficients and so, to derive the rules of fusion. The multiresolution decomposition is done by using the dual-tree complex wavelet transform. The fusion method assumes that the highest attention level for the input images to be fused must be one of the main factors to establish the information to put in the fused image. The performance of the method is tested by an axiomatic score function. Two sets of experiments have been carried out: (a) fusion on multi-focus images and (b) fusion on multi-band images. In the first experiment, the proposed method has been compared with PYR, DWT, CWT and SR methods. In this kind of images the ATF method has a good performance. On the other hand, results in the second experiment with multi-band images, demonstrate that the ATF method has the best performance (across several sets of images) in comparison with the CWT, PYR and DWT methods, all of them also based in a multiresolution decomposition. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "From computational attention to image fusion", "paper_id": "WOS:000296547400011"}