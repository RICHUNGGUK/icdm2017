{"auto_keywords": [{"score": 0.04969277448773696, "phrase": "multiobjective_optimization_problem"}, {"score": 0.04743685203399359, "phrase": "great_deal"}, {"score": 0.04238035317532914, "phrase": "evolutionary_algorithm"}, {"score": 0.03259663563788674, "phrase": "obl"}, {"score": 0.00481495049065317, "phrase": "opposition-based_learning"}, {"score": 0.004737579882204798, "phrase": "multiobjective_evolutionary_algorithm"}, {"score": 0.004440277230269978, "phrase": "enormous_success"}, {"score": 0.0043512358455892, "phrase": "evolutionary_multiobjective_optimization"}, {"score": 0.0042295656877259806, "phrase": "mop"}, {"score": 0.00412796126884884, "phrase": "scalar_optimization_subproblems"}, {"score": 0.004012586732524278, "phrase": "ea"}, {"score": 0.003640516896245813, "phrase": "reinforcement_learning"}, {"score": 0.0036111152143285838, "phrase": "neural_network"}, {"score": 0.0035386420095120706, "phrase": "simultaneous_consideration"}, {"score": 0.0034118234596993836, "phrase": "pure_randomness"}, {"score": 0.003370565320453525, "phrase": "new_scheme"}, {"score": 0.003158776195052182, "phrase": "machine_learning_field"}, {"score": 0.0026638482306228575, "phrase": "opposition-based_initial_population"}, {"score": 0.0026423134393535265, "phrase": "opposition-based_learning_strategy"}, {"score": 0.002578745296475411, "phrase": "evolutionary_process"}, {"score": 0.002387337550919433, "phrase": "experimental_results"}, {"score": 0.002264607102799332, "phrase": "parameter_sensitivity"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multi-objective optimization", " Evolutionary algorithm", " Decomposition", " Opposition-based learning"], "paper_abstract": "Multiobjective evolutionary algorithm based on decomposition (MOEA/D) has attracted a great deal of attention and has obtained enormous success in the field of evolutionary multiobjective optimization. It converts a multiobjective optimization problem (MOP) into a set of scalar optimization subproblems and then uses the evolutionary algorithm (EA) to optimize these subproblems simultaneously. However, there is a great deal of randomness in MOEA/D. Researchers in the field of evolutionary algorithm, reinforcement learning and neural network have reported that the simultaneous consideration of randomness and opposition has an advantage over pure randomness. A new scheme, called opposition-based learning (OBL), has been proposed in the machine learning field. In this paper, OBL has been integrated into the framework of MOEA/D to accelerate its convergence speed. Hence, our proposed approach is called opposition-based learning MOEA/D (MOEA/D-OBL). Compared with MOEA/D, MOEA/D-OBL uses an opposition-based initial population and opposition-based learning strategy to generate offspring during the evolutionary process. It is compared with its parent algorithm MOEA/D on four representative kinds of MOPs and many-objective optimization problems. Experimental results indicate that MOEA/D-OBL outperforms or performs similar to MOEA/D. Moreover, the parameter sensitivity of generalization opposite point and the probable to use OBL is experimentally investigated. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "MOEA/D with opposition-based learning for multiobjective optimization problem", "paper_id": "WOS:000342529500005"}