{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "tackling_resource_variations"}, {"score": 0.004769958800452922, "phrase": "adaptive_multicore_execution_frameworks"}, {"score": 0.004529881123652277, "phrase": "rising_performance_demand"}, {"score": 0.00440403952059725, "phrase": "high-end_supercomputing"}, {"score": 0.004362870617347183, "phrase": "low-end_consumer_electronics"}, {"score": 0.004241648852523704, "phrase": "ever_growing_integration_density"}, {"score": 0.004085221464783815, "phrase": "increased_level"}, {"score": 0.004047020753789236, "phrase": "core_availability_variations"}, {"score": 0.003897742942358768, "phrase": "device_failures"}, {"score": 0.003861288537079326, "phrase": "heat_buildup"}, {"score": 0.003771631577951067, "phrase": "resource_competitions"}, {"score": 0.003684048704119722, "phrase": "computational_resources"}, {"score": 0.003615443704375908, "phrase": "execution_schedules"}, {"score": 0.003548111729206587, "phrase": "diverse_performance_levels"}, {"score": 0.00348202932445197, "phrase": "varying_resource_allocations"}, {"score": 0.0034332736827447654, "phrase": "adaptive_execution_framework"}, {"score": 0.0033377940531761985, "phrase": "high-quality_schedules"}, {"score": 0.003229741076887151, "phrase": "gracefully_degrading_performance"}, {"score": 0.003154701855951328, "phrase": "resource_unavailability"}, {"score": 0.003066945490483524, "phrase": "novel_band_structure"}, {"score": 0.002995677265350124, "phrase": "possible_execution_schedules"}, {"score": 0.0028986672783671147, "phrase": "compile_time"}, {"score": 0.0028446460307503343, "phrase": "predictable_responses"}, {"score": 0.0028047899594686003, "phrase": "resource_variations"}, {"score": 0.002675914969626753, "phrase": "extra_degree"}, {"score": 0.002613709503583786, "phrase": "scheduling_process"}, {"score": 0.0025409639091476363, "phrase": "task_assignments"}, {"score": 0.0024241817763927163, "phrase": "preoptimized_schedules"}, {"score": 0.0024014759148123736, "phrase": "almost_no_cost"}, {"score": 0.0023346234464901978, "phrase": "proposed_technique"}, {"score": 0.0021049977753042253, "phrase": "single_core_degradations"}], "paper_keywords": ["Adaptive MPSoCs", " execution reconfiguration", " multicore scheduling", " resource degradation tolerance"], "paper_abstract": "Multicore architectures have been widely adopted to accommodate the rising performance demand in various application domains, ranging from high-end supercomputing to low-end consumer electronics. Yet due to the ever growing integration density and application complexity, such architectures suffer from increased level of core availability variations. At runtime, issues such as device failures, heat buildup, as well as resource competitions and preemptions can make computational resources unavailable, necessitating execution schedules capable of delivering diverse performance levels to match the varying resource allocations. The adaptive execution framework introduced in this paper delivers high-quality schedules capable of predictably reconfiguring execution and gracefully degrading performance in the face of resource unavailability. By adhering to a novel band structure, a set of possible execution schedules are compactly engendered in readiness at compile time, thus delivering predictable responses to runtime resource variations. More importantly, through the exploitation of an extra degree of freedom in the scheduling process, the scheduler can perform task assignments in such a way that adaptivity can be embedded within the preoptimized schedules at almost no cost. The efficacy of the proposed technique is confirmed by incorporating it into a conventional, widely adopted scheduling heuristic and experimentally verifying it in the context of single core degradations.", "paper_title": "Tackling Resource Variations Through Adaptive Multicore Execution Frameworks", "paper_id": "WOS:000298327500013"}