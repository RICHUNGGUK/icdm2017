{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "words_framework"}, {"score": 0.0047283116134926645, "phrase": "document_representation"}, {"score": 0.00460125407969429, "phrase": "popular_bag"}, {"score": 0.004518442937844318, "phrase": "words_assumption"}, {"score": 0.004201774694043468, "phrase": "word_occurrences"}, {"score": 0.003767738552860633, "phrase": "sequential_information"}, {"score": 0.003600351201298387, "phrase": "effective_sequential_document_representation"}, {"score": 0.003378385493203297, "phrase": "words_representation"}, {"score": 0.0030017207229983385, "phrase": "smooth_curves"}, {"score": 0.0029209233709517634, "phrase": "multinomial_simplex"}, {"score": 0.0028422946420821075, "phrase": "valuable_sequential_information"}, {"score": 0.002548331088496964, "phrase": "new_representation"}, {"score": 0.0024129269611844794, "phrase": "medium_and_long_range_sequential_trends"}], "paper_keywords": ["text processing", " local smoothing"], "paper_abstract": "The popular bag of words assumption represents a document as a histogram of word occurrences. While computationally efficient, such a representation is unable to maintain any sequential information. We present an effective sequential document representation that goes beyond the bag of words representation and its n-gram extensions. This representation uses local smoothing to embed documents as smooth curves in the multinomial simplex thereby preserving valuable sequential information. In contrast to bag of words or n-grams, the new representation is able to robustly capture medium and long range sequential trends in the document. We discuss the representation and its geometric properties and demonstrate its applicability for various text processing tasks.", "paper_title": "The locally weighted bag of words framework for document representation", "paper_id": "WOS:000252744800007"}