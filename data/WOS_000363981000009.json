{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "haptic_cues"}, {"score": 0.004770461993586338, "phrase": "self-supervised_learning"}, {"score": 0.004726382602809228, "phrase": "depth-based_robot_navigation_affordances"}, {"score": 0.004554082077300675, "phrase": "online_learning"}, {"score": 0.0045119929871912405, "phrase": "robot_navigation_affordances"}, {"score": 0.0044702911400353535, "phrase": "spatiotemporally_correlated_haptic"}, {"score": 0.0044289730051264116, "phrase": "depth_cues"}, {"score": 0.00398028819691605, "phrase": "critical_requirement"}, {"score": 0.0039252049353279556, "phrase": "wheeled_robot"}, {"score": 0.0038708810091769856, "phrase": "natural_environments"}, {"score": 0.0036951530348821116, "phrase": "non-traversable_obstacles"}, {"score": 0.003644001325962353, "phrase": "terrain_progression"}, {"score": 0.003593555152077465, "phrase": "wheeled_robot_prototype"}, {"score": 0.003446353878654566, "phrase": "proposed_method"}, {"score": 0.0033986345279488476, "phrase": "robot_prototype"}, {"score": 0.003367188029221534, "phrase": "haptic_and_depth_sensory_feedback"}, {"score": 0.003320561182494713, "phrase": "pan-tilt_telescopic_antenna"}, {"score": 0.0032593915869553714, "phrase": "structured_light_sensor"}, {"score": 0.0031697368057340895, "phrase": "presented_method"}, {"score": 0.003054009753601139, "phrase": "objects'_descriptors"}, {"score": 0.002997735656669146, "phrase": "range_data"}, {"score": 0.0026811531172346676, "phrase": "confidence_estimation"}, {"score": 0.0025474193855847074, "phrase": "required_physical_interactions"}, {"score": 0.002523828967909659, "phrase": "acquainted_objects"}, {"score": 0.0024429654627197393, "phrase": "meaningful_interactions"}, {"score": 0.002397923568994474, "phrase": "time_pressure"}, {"score": 0.0022258906408344973, "phrase": "morphological_criteria"}, {"score": 0.0022052711621931144, "phrase": "field_trials"}], "paper_keywords": ["Autonomous robots", " Self-supervised learning", " Affordances", " Terrain assessment", " Depth sensing", " Tactile sensing"], "paper_abstract": "This article presents a method for online learning of robot navigation affordances from spatiotemporally correlated haptic and depth cues. The method allows the robot to incrementally learn which objects present in the environment are actually traversable. This is a critical requirement for any wheeled robot performing in natural environments, in which the inability to discern vegetation from non-traversable obstacles frequently hampers terrain progression. A wheeled robot prototype was developed in order to experimentally validate the proposed method. The robot prototype obtains haptic and depth sensory feedback from a pan-tilt telescopic antenna and from a structured light sensor, respectively. With the presented method, the robot learns a mapping between objects' descriptors, given the range data provided by the sensor, and objects' stiffness, as estimated from the interaction between the antenna and the object. Learning confidence estimation is considered in order to progressively reduce the number of required physical interactions with acquainted objects. To raise the number of meaningful interactions per object under time pressure, the several segments of the object under analysis are prioritised according to a set of morphological criteria. Field trials show the ability of the robot to progressively learn which elements of the environment are traversable.", "paper_title": "On Exploiting Haptic Cues for Self-Supervised Learning of Depth-Based Robot Navigation Affordances", "paper_id": "WOS:000363981000009"}