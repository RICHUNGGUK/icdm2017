{"auto_keywords": [{"score": 0.03637124511862822, "phrase": "dnn"}, {"score": 0.01571956930362749, "phrase": "articulatory_mapping"}, {"score": 0.004765173195920904, "phrase": "deep_neural_network"}, {"score": 0.004453874101119545, "phrase": "human-computer_interactions"}, {"score": 0.004098397888277889, "phrase": "different_kinds"}, {"score": 0.003972504904621217, "phrase": "mapping_function"}, {"score": 0.0038907236419588255, "phrase": "general_linear_model"}, {"score": 0.003792261165599969, "phrase": "gaussian"}, {"score": 0.0035802466336393064, "phrase": "ann"}, {"score": 0.0032769720645483102, "phrase": "neural_network"}, {"score": 0.002968424524565369, "phrase": "real-time_speech"}, {"score": 0.0029224275921964724, "phrase": "avatar_system"}, {"score": 0.0027741761880779535, "phrase": "acoustic_speech"}, {"score": 0.002702887319160532, "phrase": "articulatory_movements"}, {"score": 0.0026061419474030633, "phrase": "input_speech"}, {"score": 0.0025524176761139413, "phrase": "three-dimensional_avatar"}, {"score": 0.0024103135784179375, "phrase": "glm"}, {"score": 0.002299921909935613, "phrase": "well_known_acoustic-articulatory_english_speech_corpus"}, {"score": 0.002206045784326466, "phrase": "proposed_acoustic"}, {"score": 0.002171836484200008, "phrase": "mapping_method"}, {"score": 0.0021049977753042253, "phrase": "best_performance"}], "paper_keywords": ["Acoustic to articulatory mapping", " Audio-visual mapping", " Deep neural network (DNN)", " Speech driven talking avatar"], "paper_abstract": "Synthetic talking avatar has been demonstrated to be very useful in human-computer interactions. In this paper, we discuss the problem of acoustic to articulatory mapping and explore different kinds of models to describe the mapping function. We try general linear model (GLM), Gaussian mixture model (GMM), artificial neural network (ANN) and deep neural network (DNN) for the problem. Taking the advantage of neural network that its prediction stage can be finished in a very short time (e.g. real-time), we develop a real-time speech driven talking avatar system based on DNN. The input of the system is acoustic speech and the output is articulatory movements (that are synchronized with the input speech) on a three-dimensional avatar. Several experiments are conducted to compare the performance of GLM, GMM, ANN and DNN on a well known acoustic-articulatory English speech corpus MNGU0. Experimental results demonstrate that the proposed acoustic to articulatory mapping method with DNN can achieve the best performance.", "paper_title": "Acoustic to articulatory mapping with deep neural network", "paper_id": "WOS:000364019400004"}