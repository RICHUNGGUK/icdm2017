{"auto_keywords": [{"score": 0.04931481962834531, "phrase": "soft_targets"}, {"score": 0.010604286071943898, "phrase": "gp"}, {"score": 0.00481495049065317, "phrase": "model_based_classifiers"}, {"score": 0.004637478829869904, "phrase": "machine_classifiers"}, {"score": 0.004539005582217309, "phrase": "hard_classification_targets"}, {"score": 0.004466519142879166, "phrase": "soft_versions"}, {"score": 0.004301834610818624, "phrase": "negative_effects"}, {"score": 0.004233119608341877, "phrase": "standard_cost_functions"}, {"score": 0.003947765701573287, "phrase": "sample_editing_methods"}, {"score": 0.003741371936431574, "phrase": "classifiers_performance"}, {"score": 0.003451766520526601, "phrase": "generative_models"}, {"score": 0.003378385493203297, "phrase": "gaussian_mixture_models"}, {"score": 0.0032712190037495975, "phrase": "gaussian_processes"}, {"score": 0.002969628818856786, "phrase": "easy_interpretation"}, {"score": 0.002937879003671346, "phrase": "straightforward_possibilities"}, {"score": 0.002875391177926809, "phrase": "missing_values"}, {"score": 0.0025822818714499795, "phrase": "complex_approximation"}, {"score": 0.0022941723937662927, "phrase": "simulation_results"}, {"score": 0.0022213218042340735, "phrase": "proposed_approach"}, {"score": 0.0021857667493036786, "phrase": "better_performance"}, {"score": 0.0021392418081444798, "phrase": "low_sensitivity"}, {"score": 0.0021049977753042253, "phrase": "parameters_selection"}], "paper_keywords": ["Smoothing target", " sample selection", " classification", " GMM", " GP"], "paper_abstract": "When training machine classifiers, to replace hard classification targets by emphasized soft versions of them helps to reduce the negative effects of using standard cost functions as approximations to misclassification rates. This emphasis has the same kind of effect as sample editing methods, that have proved to be effective for improving classifiers performance. In this paper, we explore the effectiveness of using emphasized soft targets with generative models, such as Gaussian Mixture Models (GMM), and Gaussian Processes (GP). The interest of using GMM is that they offer advantages such as an easy interpretation and straightforward possibilities to deal with missing values. With respect to GP, if we use soft targets, we do not need to resort to any complex approximation to get a Gaussian Process classifier and, simultaneously, we can obtain the advantages provided by the use of an emphasis. Simulation results support the usefulness of the proposed approach to get better performance and show a low sensitivity to design parameters selection.", "paper_title": "Designing Model Based Classifiers by Emphasizing Soft Targets", "paper_id": "WOS:000273197700003"}