{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "large_anonymous_games"}, {"score": 0.004671588539217021, "phrase": "large_systems"}, {"score": 0.004056769841308405, "phrase": "sophisticated_multi-agent_learning_algorithms"}, {"score": 0.003780286517897356, "phrase": "alternative_approach"}, {"score": 0.00363080961099728, "phrase": "restricted_classes"}, {"score": 0.003417565253539315, "phrase": "efficient_algorithms"}, {"score": 0.0030278017562213265, "phrase": "nash_equilibria"}, {"score": 0.0021049977753042253, "phrase": "statistical_information"}], "paper_keywords": [""], "paper_abstract": "In large systems, it is important for agents to learn to act effectively, but sophisticated multi-agent learning algorithms generally do not scale. An alternative approach is to find restricted classes of games where simple, efficient algorithms converge. It is shown that stage learning efficiently converges to Nash equilibria in large anonymous games if best-reply dynamics converge. Two features are identified that improve convergence. First, rather than making learning more difficult, more agents are actually beneficial in many settings. Second, providing agents with statistical information about the behavior of others can significantly reduce the number of observations needed.", "paper_title": "Multiagent Learning in Large Anonymous Games", "paper_id": "WOS:000288653600001"}