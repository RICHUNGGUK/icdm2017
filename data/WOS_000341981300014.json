{"auto_keywords": [{"score": 0.04016938422382131, "phrase": "structboost"}, {"score": 0.011640691292041136, "phrase": "ssvm"}, {"score": 0.00790487522391911, "phrase": "structured_learning"}, {"score": 0.00481495049065317, "phrase": "structured_output_variables"}, {"score": 0.004607686390487483, "phrase": "single_accurate_predictor"}, {"score": 0.004260906498835763, "phrase": "computer_vision"}, {"score": 0.004178351419209898, "phrase": "structured_support_vector_machines"}, {"score": 0.003998380230709541, "phrase": "new_boosting_algorithm"}, {"score": 0.003959447096055027, "phrase": "structured_output_prediction"}, {"score": 0.0036079110889031874, "phrase": "weak_structured_learners"}, {"score": 0.0034355662264234864, "phrase": "standard_boosting_approaches"}, {"score": 0.003385490833580421, "phrase": "adaboost"}, {"score": 0.0033361238953114707, "phrase": "lpboost"}, {"score": 0.0032554492909625653, "phrase": "resulting_optimization_problem"}, {"score": 0.0028244513779243107, "phrase": "exponential_number"}, {"score": 0.0027561164046279413, "phrase": "cutting-plane_method"}, {"score": 0.0024383967028975616, "phrase": "column_generation"}, {"score": 0.0022216045996270974, "phrase": "tree_loss"}, {"score": 0.0021999341184897217, "phrase": "hierarchical_multi-class_classification"}, {"score": 0.002157223877108711, "phrase": "pascal_overlap_criterion"}, {"score": 0.0021361800485636823, "phrase": "robust_visual_tracking"}, {"score": 0.0021049977753042253, "phrase": "conditional_random_field_parameters"}], "paper_keywords": ["Boosting", " ensemble learning", " AdaBoost", " structured learning", " conditional random field"], "paper_abstract": "Boosting is a method for learning a single accurate predictor by linearly combining a set of less accurate weak learners. Recently, structured learning has found many applications in computer vision. Inspired by structured support vector machines (SSVM), here we propose a new boosting algorithm for structured output prediction, which we refer to as StructBoost. StructBoost supports nonlinear structured learning by combining a set of weak structured learners. As SSVM generalizes SVM, our StructBoost generalizes standard boosting approaches such as AdaBoost, or LPBoost to structured learning. The resulting optimization problem of StructBoost is more challenging than SSVM in the sense that it may involve exponentially many variables and constraints. In contrast, for SSVM one usually has an exponential number of constraints and a cutting-plane method is used. In order to efficiently solve StructBoost, we formulate an equivalent 1-slack formulation and solve it using a combination of cutting planes and column generation. We show the versatility and usefulness of StructBoost on a range of problems such as optimizing the tree loss for hierarchical multi-class classification, optimizing the Pascal overlap criterion for robust visual tracking and learning conditional random field parameters for image segmentation.", "paper_title": "StructBoost: Boosting Methods for Predicting Structured Output Variables", "paper_id": "WOS:000341981300014"}