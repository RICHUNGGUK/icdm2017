{"auto_keywords": [{"score": 0.04847167377939251, "phrase": "competing_parties"}, {"score": 0.0363002347977913, "phrase": "participating_parties"}, {"score": 0.00481495049065317, "phrase": "incentive_compatible_privacy-preserving_data_analysis"}, {"score": 0.004558977045730675, "phrase": "private_data"}, {"score": 0.004436116555817464, "phrase": "privacy-preserving_distributed_data_analysis"}, {"score": 0.004375930681846676, "phrase": "ppda"}, {"score": 0.00422899036681456, "phrase": "beneficial_data_models"}, {"score": 0.00417160036938041, "phrase": "analysis_results"}, {"score": 0.003949693102823493, "phrase": "different_incentives"}, {"score": 0.003688773272422118, "phrase": "final_analysis_result"}, {"score": 0.003284026247389735, "phrase": "proper_incentives"}, {"score": 0.003195414285736136, "phrase": "current_ppda_techniques"}, {"score": 0.002825251837733693, "phrase": "compatible_privacy-preserving_data_analysis_techniques"}, {"score": 0.002693134880651768, "phrase": "truthful_inputs"}, {"score": 0.002532284627202572, "phrase": "key_theorems"}, {"score": 0.002148677187261496, "phrase": "best_choice"}, {"score": 0.0021049977753042253, "phrase": "participating_party"}], "paper_keywords": ["Privacy", " secure multiparty computation", " noncooperative computation"], "paper_abstract": "In many cases, competing parties who have private data may collaboratively conduct privacy-preserving distributed data analysis (PPDA) tasks to learn beneficial data models or analysis results. Most often, the competing parties have different incentives. Although certain PPDA techniques guarantee that nothing other than the final analysis result is revealed, it is impossible to verify whether participating parties are truthful about their private input data. Unless proper incentives are set, current PPDA techniques cannot prevent participating parties from modifying their private inputs. This raises the question of how to design incentive compatible privacy-preserving data analysis techniques that motivate participating parties to provide truthful inputs. In this paper, we first develop key theorems, then base on these theorems, we analyze certain important privacy-preserving data analysis tasks that could be conducted in a way that telling the truth is the best choice for any participating party.", "paper_title": "Incentive Compatible Privacy-Preserving Data Analysis", "paper_id": "WOS:000317860300010"}