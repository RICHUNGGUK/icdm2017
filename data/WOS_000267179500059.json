{"auto_keywords": [{"score": 0.048992899974696226, "phrase": "kpca"}, {"score": 0.029288846366301528, "phrase": "training_samples"}, {"score": 0.015719693992243013, "phrase": "maximum_variance_unfolding_projections"}, {"score": 0.014031877306297907, "phrase": "kpca-based_monitoring_method"}, {"score": 0.010387877239976879, "phrase": "mvup"}, {"score": 0.004749106104067268, "phrase": "principal_component_analysis"}, {"score": 0.004536029676655286, "phrase": "powerful_dimensionality_reduction_tool"}, {"score": 0.004473982381245469, "phrase": "nonlinear_processes"}, {"score": 0.00443308765153716, "phrase": "numerous_mutually_correlated_measured_variables"}, {"score": 0.004062682236016889, "phrase": "finite_candidates"}, {"score": 0.003988719758707836, "phrase": "faulty_process_samples"}, {"score": 0.0038981499110532307, "phrase": "off-line_modeling_phase"}, {"score": 0.0037747835341722636, "phrase": "high_computational_cost"}, {"score": 0.0037231102027070724, "phrase": "on-line_monitoring_phase"}, {"score": 0.0036052633308076933, "phrase": "kernel_functions"}, {"score": 0.003427540517249369, "phrase": "new_process"}, {"score": 0.0033651019362620866, "phrase": "fault_detection"}, {"score": 0.00327356326590461, "phrase": "novel_dimensionality_reduction_method"}, {"score": 0.0031121406603482112, "phrase": "recently_proposed_manifold_learning_method_maximum_variance_unfolding"}, {"score": 0.0030836572116179494, "phrase": "mvu"}, {"score": 0.0029181203386806683, "phrase": "special_variation"}, {"score": 0.002786964045867666, "phrase": "underlying_manifold_structure"}, {"score": 0.002673957615079041, "phrase": "reduced_space"}, {"score": 0.0026252106881752067, "phrase": "distribution_region"}, {"score": 0.002518746501941657, "phrase": "linear_regression"}, {"score": 0.00241658945942583, "phrase": "implicit_mapping"}, {"score": 0.002255431275670053, "phrase": "benchmark_tennessee_eastman_process"}, {"score": 0.002224510044064184, "phrase": "mvup-based_process_monitoring_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Process monitoring", " Dimensionality reduction", " Kernel matrix learning", " Linear regression", " Maximum variance unfolding projections"], "paper_abstract": "Kernel principal component analysis (KPCA) has recently proven to be a powerful dimensionality reduction tool for monitoring nonlinear processes with numerous mutually correlated measured variables. However, the performance of KPCA-based monitoring method largely depends on its kernel function which can only be empirically selected from finite candidates assuming that some faulty process samples are available in the off-line modeling phase. Moreover, KPCA works at high computational cost in the on-line monitoring phase due to its dense expansions in terms of kernel functions. To overcome these deficiencies, this paper proposes a new process monitoring technique comprising fault detection and identification based on a novel dimensionality reduction method named maximum variance unfolding projections (MVUP). MVUP firstly applies the recently proposed manifold learning method maximum variance unfolding (MVU) on training samples, which can be seen as a special variation of KPCA whose kernel matrix is automatically learned such that the underlying manifold structure of training samples is \"unfolded\" in the reduced space and hence the boundary of distribution region of training samples is preserved. Then MVUP uses linear regression to find the projection that best approximates the implicit mapping from training samples to their lower dimensional embedding learned by MVU. Simulation results on the benchmark Tennessee Eastman process show that MVUP-based process monitoring method is a good alternative to KPCA-based monitoring method. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Nonlinear process monitoring based on maximum variance unfolding projections", "paper_id": "WOS:000267179500059"}