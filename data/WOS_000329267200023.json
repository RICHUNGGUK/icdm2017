{"auto_keywords": [{"score": 0.04954397446159369, "phrase": "content_centric_networking"}, {"score": 0.02440616809826358, "phrase": "proposed_scheme"}, {"score": 0.00481495049065317, "phrase": "manifold_learning"}, {"score": 0.004551781491498328, "phrase": "emerging_network_architecture"}, {"score": 0.004425616928975799, "phrase": "end-to-end_connection"}, {"score": 0.004351595642056769, "phrase": "content_centric_communication_model"}, {"score": 0.004230973777221294, "phrase": "ccn"}, {"score": 0.004160177106153782, "phrase": "content_store_module"}, {"score": 0.0038668462001710314, "phrase": "arbitrary_network_topology"}, {"score": 0.0036966717141736355, "phrase": "appropriate_cache_size"}, {"score": 0.0034944094552943, "phrase": "network_performance"}, {"score": 0.0034166271604770576, "phrase": "economic_investment"}, {"score": 0.003378385493203297, "phrase": "previous_works"}, {"score": 0.0029681091946289757, "phrase": "data_mining_method"}, {"score": 0.002918394200972564, "phrase": "cache_size_allocation"}, {"score": 0.0028695095228791724, "phrase": "proposed_algorithm"}, {"score": 0.002727700630869639, "phrase": "network_traffic"}, {"score": 0.0026971491199975083, "phrase": "user_behaviors"}, {"score": 0.0025494354909453847, "phrase": "content_delivery"}, {"score": 0.0024786330057813204, "phrase": "manifold_learning_embedding_results"}, {"score": 0.0024370965602952496, "phrase": "novel_cache_size_optimization_scheme"}, {"score": 0.0023827927890399357, "phrase": "extensive_experiments"}, {"score": 0.002264982416465872, "phrase": "simulation_results"}, {"score": 0.0021773853011112882, "phrase": "existing_cache_allocation_schemes"}, {"score": 0.002152985231951416, "phrase": "ccn."}], "paper_keywords": ["Content Centric Networking", " Cache size allocation", " Manifold learning"], "paper_abstract": "Content Centric Networking (CCN) is an emerging network architecture, shifting from an end-to-end connection to a content centric communication model. Each router in CCN has a content store module to cache the chunks passed by, and is arranged in an arbitrary network topology. It is important to allocate an appropriate cache size to each router in order to both improve the network performance and reduce the economic investment. Previous works have proposed several heterogeneous cache allocation schemes, but the gain brought by these schemes is not obvious. In this paper, we introduce a data mining method into the cache size allocation. The proposed algorithm uses manifold learning to analyze the regularity of network traffic and user behaviors, and classify routers based on their roles in the content delivery. Guided by the manifold learning embedding results, a novel cache size optimization scheme is developed. Extensive experiments have been performed to evaluate the proposed scheme. Simulation results show that the proposed scheme outperforms the existing cache allocation schemes in CCN. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "A novel cache size optimization scheme based on manifold learning in Content Centric Networking", "paper_id": "WOS:000329267200023"}