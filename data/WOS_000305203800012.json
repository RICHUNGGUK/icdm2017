{"auto_keywords": [{"score": 0.029940041712803473, "phrase": "tcs"}, {"score": 0.01571960220654954, "phrase": "life_time"}, {"score": 0.004757643419056999, "phrase": "reuse_time_prediction"}, {"score": 0.004645057834614705, "phrase": "chip_mulltiprocessors"}, {"score": 0.004562362497952548, "phrase": "chip_multi-processors"}, {"score": 0.004375061788023814, "phrase": "potential_benefits"}, {"score": 0.004322967486451877, "phrase": "future_cmps"}, {"score": 0.0037216229812089686, "phrase": "major_weakness"}, {"score": 0.003677280504320636, "phrase": "private_cache"}, {"score": 0.003611751858608048, "phrase": "higher_cache"}, {"score": 0.0035051129798529, "phrase": "small_private_cache_capacity"}, {"score": 0.0033409791799749434, "phrase": "private_caches"}, {"score": 0.0032229262928681304, "phrase": "replaced_blocks"}, {"score": 0.003109031770476385, "phrase": "indiscriminate_spilling"}, {"score": 0.003053598205821532, "phrase": "capacity_problem"}, {"score": 0.0028586409810976367, "phrase": "capacity_sharing"}, {"score": 0.0027741761880779535, "phrase": "effective_capacity"}, {"score": 0.002597012212823168, "phrase": "replaced_block"}, {"score": 0.00255068452076921, "phrase": "reuse_possibility"}, {"score": 0.0024604876113911173, "phrase": "reuse_time"}, {"score": 0.0023592715993204796, "phrase": "weighted_speedup"}, {"score": 0.002169132543304098, "phrase": "best_spill_probability"}, {"score": 0.0021049977753042253, "phrase": "dynamic_spill-receive"}], "paper_keywords": ["Chip Multi-Processors", " private L2 cache", " capacity sharing", " cooperative caching"], "paper_abstract": "In Chip Multi-Processors (CMPs), private L2 caches have potential benefits in future CMPs, e.g. small access latency, performance isolation, tile-friendly architecture and simple low bandwidth on-chip interconnect. But the major weakness of private cache is the higher cache miss rate caused by small private cache capacity. To deal with this problem, private caches can share capacity through spilling replaced blocks to other private caches. However, indiscriminate spilling can make capacity problem worse and influence performance negatively. This letter proposes throttling capacity sharing (TCS) for effective capacity sharing in private L2 caches. TCS determines whether to spill a replaced block by predicting reuse possibility, based on life time and reuse time. In our performance evaluation, TCS improves weighted speedup by 48.79%, 6.37% and 5.44% compared to non-spilling, Cooperative Caching with best spill probability (CC) and Dynamic Spill-Receive (DSR), respectively.", "paper_title": "Throttling Capacity Sharing Using Life Time and Reuse Time Prediction in Private L2 Caches of Chip Mulltiprocessors", "paper_id": "WOS:000305203800012"}