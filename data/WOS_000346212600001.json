{"auto_keywords": [{"score": 0.04835227522307675, "phrase": "batch_computations"}, {"score": 0.026230022403717274, "phrase": "input_data"}, {"score": 0.00481495049065317, "phrase": "batch-oriented_computations"}, {"score": 0.0047797212183363835, "phrase": "large_sliding_time_windows"}, {"score": 0.004744748477093856, "phrase": "today's_business_workflows"}, {"score": 0.004506968388996092, "phrase": "specific_time"}, {"score": 0.004441236717408874, "phrase": "strategic_information"}, {"score": 0.004234129588974058, "phrase": "effective_measure"}, {"score": 0.0042031320273645065, "phrase": "data_analytics_freshness"}, {"score": 0.004157058883925715, "phrase": "decision_makers"}, {"score": 0.004081385289516914, "phrase": "typical_amounts"}, {"score": 0.0037505809981715024, "phrase": "new_batch"}, {"score": 0.0036958398682001015, "phrase": "previous_one"}, {"score": 0.003408688677676014, "phrase": "batch_processing"}, {"score": 0.0033712944392793195, "phrase": "overlapping_sliding_time_windows"}, {"score": 0.0030414140732789186, "phrase": "large_data_volumes"}, {"score": 0.003019121766552419, "phrase": "observation_windows"}, {"score": 0.0027844017803674444, "phrase": "multiple_metrics"}, {"score": 0.002673957615079041, "phrase": "computation_time_window"}, {"score": 0.0023421547766273015, "phrase": "well-known_hadoop_platform"}, {"score": 0.002265833357217618, "phrase": "mapreduce_paradigm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Event processing", " Batch processing", " Time window based computations", " Data analytics", " Big data"], "paper_abstract": "Today's business workflows are very likely to include batch computations that periodically analyze subsets of data within specific time ranges to provide strategic information for stakeholders and other interested parties. The frequency of these batch computations provides an effective measure of data analytics freshness available to decision makers. Nevertheless, the typical amounts of data to elaborate in a batch are so large that a computation can take very long. Considering that usually a new batch starts when the previous one has completed, the frequency of such batches can thus be very low. In this paper we propose a model for batch processing based on overlapping sliding time windows that allows to increase the frequency of batches. The model is well suited to scenarios (e.g., financial, security etc.) characterized by large data volumes, observation windows in the order of hours (or days) and frequent updates (order of seconds). The model introduces multiple metrics whose aim is reducing the latency between the end of a computation time window and the availability of results, increasing thus the frequency of the batches. These metrics specifically take into account the organization of input data to minimize its impact on such latency. The model is then instantiated on the well-known Hadoop platform, a batch processing engine based on the MapReduce paradigm, and a set of strategies for efficiently arranging input data is described and evaluated. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "High frequency batch-oriented computations over large sliding time windows", "paper_id": "WOS:000346212600001"}