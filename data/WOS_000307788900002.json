{"auto_keywords": [{"score": 0.047844536713056565, "phrase": "peak_power_consumption"}, {"score": 0.00481495049065317, "phrase": "cache_latency_control"}, {"score": 0.004769182299692333, "phrase": "application_fairness"}, {"score": 0.004678940805063634, "phrase": "power-constrained_chip_multiprocessors"}, {"score": 0.004546755482549647, "phrase": "chip_multiprocessors"}, {"score": 0.004212157020917929, "phrase": "chip-level_power_capping"}, {"score": 0.004015618451418077, "phrase": "cmp"}, {"score": 0.0038465304237380125, "phrase": "selected_cache_banks"}, {"score": 0.003809932244103758, "phrase": "low-power_modes"}, {"score": 0.0036669760226536977, "phrase": "power_capping"}, {"score": 0.0036147562669032957, "phrase": "undesired_long_cache_access_latencies"}, {"score": 0.003364566299071383, "phrase": "cmp."}, {"score": 0.0032382660477699695, "phrase": "novel_cache_management_strategy"}, {"score": 0.003087017178815267, "phrase": "fairness_guarantees"}, {"score": 0.0030140547908298404, "phrase": "cache_access_latencies"}, {"score": 0.0029711052657054463, "phrase": "application_threads"}, {"score": 0.002752139271586703, "phrase": "differentiated_cache_latency_guarantees"}, {"score": 0.00263612191603326, "phrase": "desired_thread_priorities"}, {"score": 0.002598543802992702, "phrase": "architectural_level"}, {"score": 0.0025614999929672, "phrase": "desired_rates"}, {"score": 0.002537097217899195, "phrase": "thread_progress"}, {"score": 0.002512926336312949, "phrase": "coscheduled_applications"}, {"score": 0.0024534993283766332, "phrase": "two-tier_control_architecture"}, {"score": 0.0023954743066925714, "phrase": "advanced_feedback_control_theory"}, {"score": 0.002372649454733251, "phrase": "guaranteed_control_accuracy"}, {"score": 0.002350041573006264, "phrase": "system_stability"}, {"score": 0.002327648608736437, "phrase": "extensive_experimental_results"}, {"score": 0.0022509365210787993, "phrase": "desired_cache_power_capping"}], "paper_keywords": ["Power capping", " cache latency", " fairness", " performance differentiation", " control theory", " chip multiprocessors"], "paper_abstract": "Limiting the peak power consumption of chip multiprocessors (CMPs) has recently received a lot of attention. In order to enable chip-level power capping, the peak power consumption of last-level (e. g., L2) on-chip caches in a CMP often needs to be constrained by dynamically transitioning selected cache banks into low-power modes. However, dynamic cache resizing for power capping may cause undesired long cache access latencies, and even thread starving and thrashing, for the applications running on the CMP. In this paper, we propose a novel cache management strategy that can limit the peak power consumption of L2 caches and provide fairness guarantees, such that the cache access latencies of the application threads coscheduled on the CMP are impacted more uniformly. Our strategy is also extended to provide differentiated cache latency guarantees that can help the OS to enforce the desired thread priorities at the architectural level and achieve desired rates of thread progress for coscheduled applications. Our solution features a two-tier control architecture rigorously designed based on advanced feedback control theory for guaranteed control accuracy and system stability. Extensive experimental results demonstrate that our solution can achieve the desired cache power capping, fair or differentiated cache sharing, and power-performance tradeoffs for many applications.", "paper_title": "Cache Latency Control for Application Fairness or Differentiation in Power-Constrained Chip Multiprocessors", "paper_id": "WOS:000307788900002"}