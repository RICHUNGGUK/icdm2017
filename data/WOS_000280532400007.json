{"auto_keywords": [{"score": 0.04204790475185293, "phrase": "training_samples"}, {"score": 0.013422677863357003, "phrase": "relative_neighborhood_graph"}, {"score": 0.00481495049065317, "phrase": "nearest_neighbor_rule"}, {"score": 0.0044967055264893184, "phrase": "novel_semi-supervised_learning_approach"}, {"score": 0.004223415145617665, "phrase": "first_step"}, {"score": 0.003899385109646589, "phrase": "unlabeled_sample"}, {"score": 0.0038114397487574838, "phrase": "unlabeled_samples"}, {"score": 0.0035189057079817285, "phrase": "newly_labeled_samples"}, {"score": 0.0033427754823819157, "phrase": "second_step"}, {"score": 0.0033048445033866795, "phrase": "standard_self-training_algorithm"}, {"score": 0.0031037644581516973, "phrase": "predetermined_stopping_criterion"}, {"score": 0.002999274091205852, "phrase": "third_step"}, {"score": 0.0029483516334882862, "phrase": "statistical_test"}, {"score": 0.002881793492919646, "phrase": "label_modification"}, {"score": 0.0028006988338192375, "phrase": "last_step"}, {"score": 0.002753138528582461, "phrase": "remaining_unlabeled_samples"}, {"score": 0.002690975370565776, "phrase": "standard_nearest_neighbor_rule"}, {"score": 0.0026003455833291124, "phrase": "proposed_method"}, {"score": 0.0024700776739384977, "phrase": "error_reinforcement"}, {"score": 0.002359759876402679, "phrase": "initial_stages"}, {"score": 0.0023329572140896237, "phrase": "semi-supervised_learning"}, {"score": 0.0022287497627555895, "phrase": "label_modification_mechanism"}, {"score": 0.0022034318550547866, "phrase": "better_classification_performance"}, {"score": 0.0021784009230363627, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Semi-supervised learning", " Nearest neighbor rule", " Cut edges"], "paper_abstract": "In this paper, we propose a novel semi-supervised learning approach based on nearest neighbor rule and cut edges In the first step of our approach, a relative neighborhood graph based on all training samples is constructed for each unlabeled sample, and the unlabeled samples whose edges are all connected to training samples from the same class are labeled. These newly labeled samples are then added into the training samples In the second step, standard self-training algorithm using nearest neighbor rule is applied for classification until a predetermined stopping criterion is met. In the third step, a statistical test is applied for label modification, and in the last step, the remaining unlabeled samples are classified using standard nearest neighbor rule The main advantages of the proposed method are: (1) it reduces the error reinforcement by using relative neighborhood graph for classification in the initial stages of semi-supervised learning: (2) it introduces a label modification mechanism for better classification performance. Experimental results show the effectiveness of the proposed approach (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Semi-supervised learning based on nearest neighbor rule and cut edges", "paper_id": "WOS:000280532400007"}