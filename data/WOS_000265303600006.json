{"auto_keywords": [{"score": 0.04866188206860211, "phrase": "generalization_performance"}, {"score": 0.03463419078974214, "phrase": "erm_algorithm"}, {"score": 0.00481495049065317, "phrase": "uniformly_ergodic_markov_chains"}, {"score": 0.00443308765153716, "phrase": "main_thread"}, {"score": 0.004301834610818624, "phrase": "theoretical_research"}, {"score": 0.004205940624913343, "phrase": "previous_bounds"}, {"score": 0.004020492138367616, "phrase": "empirical_risk_minimization"}, {"score": 0.003459191419478298, "phrase": "classical_framework"}, {"score": 0.003356675879109443, "phrase": "generalization_bounds"}, {"score": 0.003232779373179631, "phrase": "uniformly_ergodic_markov_chain"}, {"score": 0.0025409813087197528, "phrase": "erm"}, {"score": 0.0023214774334744713, "phrase": "established_theory"}, {"score": 0.002252602622785975, "phrase": "erm_type"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["ERM algorithms", " Uniform ergodic Markov chain samples", " Generalization bound", " Uniform convergence", " Relative uniform convergence"], "paper_abstract": "Evaluation for generalization performance of learning algorithms has been the main thread of machine learning theoretical research. The previous bounds describing the generalization performance of the empirical risk minimization (ERM) algorithm are usually established based on independent and identically distributed (i.i.d.) samples. In this paper we go far beyond this classical framework by establishing the generalization bounds of the ERM algorithm with uniformly ergodic Markov chain (u.e.M.c.) samples. We prove the bounds on the rate of uniform convergence/relative uniform convergence of the ERM algorithm with u.e.M.c. samples, and show that the ERM algorithm with u.e.M.c. samples is consistent. The established theory underlies application of ERM type of learning algorithms. (C) 2009 Elsevier Inc. All rights reserved.", "paper_title": "Learning from uniformly ergodic Markov chains", "paper_id": "WOS:000265303600006"}