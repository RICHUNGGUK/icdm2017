{"auto_keywords": [{"score": 0.0245479846192286, "phrase": "lidar"}, {"score": 0.00481495049065317, "phrase": "urban_scene"}, {"score": 0.0046797114400479135, "phrase": "lidar_data"}, {"score": 0.0045052562941109734, "phrase": "cultural_and_natural_features"}, {"score": 0.0043786774510943625, "phrase": "large_urban_area"}, {"score": 0.004019797503157808, "phrase": "primary_step"}, {"score": 0.003944112858235306, "phrase": "ultimate_goal"}, {"score": 0.003815064377019477, "phrase": "large_number"}, {"score": 0.0037789720824759503, "phrase": "varied_categories"}, {"score": 0.00369022262431101, "phrase": "power_plants"}, {"score": 0.003603549914861701, "phrase": "local_patches"}, {"score": 0.0035525230119401153, "phrase": "ground_surface"}, {"score": 0.0033875770020590796, "phrase": "tensor_voting"}, {"score": 0.0033395980635636644, "phrase": "surface_orientation"}, {"score": 0.003307988966112615, "phrase": "neighboring_regions"}, {"score": 0.0031693980719538287, "phrase": "adjacent_planar_surfaces"}, {"score": 0.0031393948330209224, "phrase": "consistent_pose"}, {"score": 0.003094920033010818, "phrase": "surface_segments"}, {"score": 0.0028409576481842457, "phrase": "vertical_faces"}, {"score": 0.0027479040199262393, "phrase": "free-standing_vertical_structures"}, {"score": 0.0026705669656375197, "phrase": "inferred_large_structures"}, {"score": 0.0026077803487003, "phrase": "geometric_context"}, {"score": 0.00258307991054107, "phrase": "segment_linear_structures"}, {"score": 0.0025343769150179764, "phrase": "power_lines"}, {"score": 0.0022608057001451414, "phrase": "typical_urban_regions"}, {"score": 0.0021454671611847507, "phrase": "quantitative_analysis"}, {"score": 0.0021049977753042253, "phrase": "externally_provided_ground_truth"}], "paper_keywords": ["Large scale range image processing", " Segmentation"], "paper_abstract": "We present a framework to segment cultural and natural features, given 3D aerial scans of a large urban area, and (optionally) registered ground level scans of the same area. This system provides a primary step to achieve the ultimate goal of detecting every object from a large number of varied categories, from antenna to power plants. Our framework first identifies local patches of the ground surface and roofs of buildings. This is accomplished by tensor voting that infers surface orientation from neighboring regions as well as local 3D points. We then group adjacent planar surfaces with consistent pose to find surface segments and classify them as either the terrain or roofs of buildings. The same approach is also applied to delineate vertical faces of buildings, as well as free-standing vertical structures such as fences. The inferred large structures are then used as geometric context to segment linear structures, such as power lines, and structures attached to walls and roofs from remaining unclassified 3D points in the scene. We demonstrate our system on real LIDAR datasets acquired from typical urban regions with areas of a few square kilometers each, and provide a quantitative analysis of performance using externally provided ground truth.", "paper_title": "Urban scene understanding from aerial and ground LIDAR data", "paper_id": "WOS:000291703700007"}