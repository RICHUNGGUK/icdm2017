{"auto_keywords": [{"score": 0.027029331462353194, "phrase": "basis_images"}, {"score": 0.00481495049065317, "phrase": "outdoor_time-lapse_videos"}, {"score": 0.004582897918101983, "phrase": "rendered_virtual_objects"}, {"score": 0.004401342842183475, "phrase": "background_scenes"}, {"score": 0.004284302478991387, "phrase": "changing_lighting_condition"}, {"score": 0.004226949670141375, "phrase": "real_scene"}, {"score": 0.0041703614123283165, "phrase": "illumination_consistency"}, {"score": 0.004005083535629333, "phrase": "novel_method"}, {"score": 0.0038810583785936505, "phrase": "skylight_basis_images"}, {"score": 0.00384633057714983, "phrase": "static_outdoor_scenes"}, {"score": 0.0037948184359488284, "phrase": "time-lapse_image_sequence"}, {"score": 0.003677280504320636, "phrase": "resulted_basis_images"}, {"score": 0.003595552309967789, "phrase": "material_reflectivity"}, {"score": 0.0034685354330506605, "phrase": "global_illumination_effects"}, {"score": 0.0034220655476652683, "phrase": "outdoor_scene"}, {"score": 0.003376216135716629, "phrase": "unit_intensity"}, {"score": 0.0031845067058084583, "phrase": "previous_methods"}, {"score": 0.002936849401568391, "phrase": "ideal_diffuse"}, {"score": 0.0028844769395018595, "phrase": "weather_condition"}, {"score": 0.0027206133859493725, "phrase": "shadowed_pixels"}, {"score": 0.0026720866990543744, "phrase": "time-lapse_curve"}, {"score": 0.0024311346712789553, "phrase": "iterative_procedure"}, {"score": 0.002398529964696261, "phrase": "decomposition_equation"}, {"score": 0.002262209824105154, "phrase": "experimental_results"}, {"score": 0.0021821915946356168, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "image_understanding"}], "paper_keywords": ["Basis image decomposition", " Outdoor scenes", " Global illumination", " Augmented reality"], "paper_abstract": "In augmented reality, it is essential that the rendered virtual objects are embedded harmonically into the view of the background scenes and their appearance should reflect the changing lighting condition of the real scene to ensure illumination consistency. In this paper, we propose a novel method to solve for the sunlight and skylight basis images of static outdoor scenes from a time-lapse image sequence. It is proved that the resulted basis images encapsulate the geometry and material reflectivity of the scene, correspond to the global illumination effects of the outdoor scene under a unit intensity of the sunlight and skylight. Our method is fully automatic. Unlike previous methods, it gets rid of the constraints that the reflectance of all objects in scenes should be ideal diffuse, or the weather condition should be overcast or sunshine. During decomposition, we first detect shadowed pixels by analyzing the time-lapse curve of each pixel through k-means clustering, the basis images of sunlight and skylight are then solved by an iterative procedure with the decomposition equation. The basis images are further optimized by exploiting their constraints and priors. Experimental results demonstrate the effectiveness and flexibility of the proposed method. Our method can also be applied in image understanding and compressing.", "paper_title": "Basis image decomposition of outdoor time-lapse videos", "paper_id": "WOS:000325811300008"}