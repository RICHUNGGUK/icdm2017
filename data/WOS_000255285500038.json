{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "real_video"}, {"score": 0.04598947580092755, "phrase": "binocular_video_sequence"}, {"score": 0.03693643766382271, "phrase": "one-way_coupling"}, {"score": 0.004767546015485477, "phrase": "simulated_fluids"}, {"score": 0.004582528208024817, "phrase": "simulated_fluid_phenomena"}, {"score": 0.004492717291734985, "phrase": "real_dynamic_scenes"}, {"score": 0.004069280130346136, "phrase": "velocity_information"}, {"score": 0.00393066798511457, "phrase": "visible_parts"}, {"score": 0.003853583126988071, "phrase": "surface_completion"}, {"score": 0.003778004256546193, "phrase": "missing_regions"}, {"score": 0.003685604033479918, "phrase": "fluid_simulation"}, {"score": 0.0033050703534275717, "phrase": "temporal_consistency"}, {"score": 0.0032563083791198534, "phrase": "reconstructed_scene"}, {"score": 0.00320826350799124, "phrase": "animated_fluid"}, {"score": 0.0030988889679192965, "phrase": "geometry_tracking_algorithm"}, {"score": 0.003053159610975692, "phrase": "optic_flow_and_depth_information"}, {"score": 0.0029637093924781825, "phrase": "\"velocity_completion"}, {"score": 0.0029055323737809825, "phrase": "velocity_completion_technique"}, {"score": 0.0028768722873689432, "phrase": "local_rigidity_constraints"}, {"score": 0.0028203950416405563, "phrase": "motion_field"}, {"score": 0.00263129148531588, "phrase": "reconstructed_shape"}, {"score": 0.002516457934208144, "phrase": "smoothly_varying_geometry"}, {"score": 0.00240662380079115, "phrase": "necessary_boundary_conditions"}, {"score": 0.0023476849595393872, "phrase": "dynamic_geometry"}, {"score": 0.0023130151703068444, "phrase": "simulated_fluid"}, {"score": 0.002234092591045251, "phrase": "gpu_based_scheme"}, {"score": 0.0021902063413831545, "phrase": "synthetic_fluid"}, {"score": 0.0021049977753042253, "phrase": "scene_texture"}], "paper_keywords": [""], "paper_abstract": "We present a technique for coupling simulated fluid phenomena that interact with real dynamic scenes captured as a binocular video sequence. We first process the binocular video sequence to obtain a complete 3D reconstruction of the scene, including velocity information. We use stereo for the visible parts of 3D geometry and surface completion to fill the missing regions. We then perform fluid simulation within a 3D domain that contains the object, enabling one-way coupling from the video to the fluid. In order to maintain temporal consistency of the reconstructed scene and the animated fluid across frames, we develop a geometry tracking algorithm that combines optic flow and depth information with a novel technique for \"velocity completion\". The velocity completion technique uses local rigidity constraints to hypothesize a motion field for the entire 3D shape, which is then used to propagate and filter the reconstructed shape over time. This approach not only generates smoothly varying geometry across time, but also simultaneously provides the necessary boundary conditions for one-way coupling between the dynamic geometry and the simulated fluid. Finally, we employ a GPU based scheme for rendering the synthetic fluid in the real video, taking refraction and scene texture into account.", "paper_title": "Fluid in video: Augmenting real video with simulated fluids", "paper_id": "WOS:000255285500038"}