{"auto_keywords": [{"score": 0.04813254873980984, "phrase": "psl"}, {"score": 0.027717771597026583, "phrase": "inference_time"}, {"score": 0.00481495049065317, "phrase": "foxpsl"}, {"score": 0.004651346011959237, "phrase": "probabilistic_soft_logic"}, {"score": 0.004540126719762935, "phrase": "distributed_graph_processing_framework"}, {"score": 0.004431554974667461, "phrase": "leading_formalisms"}, {"score": 0.004401011982385274, "phrase": "statistical_relational_learning"}, {"score": 0.004295752645085445, "phrase": "machine_learning"}, {"score": 0.004178522455099832, "phrase": "rich_relational_structures"}, {"score": 0.004106877044437756, "phrase": "logical_representations"}, {"score": 0.004078562617505643, "phrase": "probabilistic_graphical_models"}, {"score": 0.003926273177600597, "phrase": "template_language"}, {"score": 0.003899199029692063, "phrase": "hinge-loss_markov_random_fields"}, {"score": 0.0038323244983352587, "phrase": "continuous_markov_random_fields"}, {"score": 0.0037535816047183845, "phrase": "maximum_a_posteriori_inference"}, {"score": 0.0036008989464331835, "phrase": "constrained_convex_minimization_problem"}, {"score": 0.0035268943257252224, "phrase": "discrete_optimization_problem"}, {"score": 0.0035025644647418983, "phrase": "standard_mrfs"}, {"score": 0.0034544053534458093, "phrase": "logical_perspective"}, {"score": 0.003418719577853084, "phrase": "key_feature"}, {"score": 0.003325343504284345, "phrase": "soft_truth_values"}, {"score": 0.0032569835069392924, "phrase": "complex_domain_knowledge"}, {"score": 0.003092149768415082, "phrase": "full_psl_pipeline"}, {"score": 0.0030708096989903945, "phrase": "problem_definition"}, {"score": 0.0030390745780621503, "phrase": "distributed_solver"}, {"score": 0.0029458177077921043, "phrase": "domain_specific_language"}, {"score": 0.002875261849352716, "phrase": "class_system"}, {"score": 0.0028554143163813947, "phrase": "existential_quantifiers"}, {"score": 0.0028161281608563267, "phrase": "efficient_grounding"}, {"score": 0.0027296938800704484, "phrase": "configurable_optimizations"}, {"score": 0.002701474449898187, "phrase": "optimized_grounding"}, {"score": 0.0026643006135750025, "phrase": "lazy_inference"}, {"score": 0.002564682311144514, "phrase": "extensive_evaluation"}, {"score": 0.0024859463164240603, "phrase": "stateof-the-art_implementation"}, {"score": 0.0024688585353866556, "phrase": "admm"}, {"score": 0.002434805319963885, "phrase": "graphlab"}, {"score": 0.0023518780693181796, "phrase": "solution_quality"}, {"score": 0.002248277737254846, "phrase": "execution_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["PSL", " ADMM", " Large-scale graph processing"], "paper_abstract": "In this paper, we describe foxPSL, a fast, optimized and extended implementation of Probabilistic Soft Logic (PSL) based on the distributed graph processing framework SIGNAL/COLLECT. PSL is one of the leading formalisms of statistical relational learning, a recently developed field of machine learning that aims at representing both uncertainty and rich relational structures, usually by combining logical representations with probabilistic graphical models. PSL can be seen as both a probabilistic logic and a template language for hinge-loss Markov Random Fields, a type of continuous Markov Random fields (MRF) in which Maximum a Posteriori inference is very efficient, since it can be formulated as a constrained convex minimization problem, as opposed to a discrete optimization problem for standard MRFs. From the logical perspective, a key feature of PSL is the capability to represent soft truth values, allowing the expression of complex domain knowledge, like degrees of truth, in parallel with uncertainty. foxPSL supports the full PSL pipeline from problem definition to a distributed solver that implements the Alternating Direction Method of Multipliers (ADMM) consensus optimization. It provides a Domain Specific Language that extends standard PSL with a class system and existential quantifiers, allowing for efficient grounding. Moreover, it implements a series of configurable optimizations, like optimized grounding of constraints and lazy inference, that improve grounding and inference time. We perform an extensive evaluation, comparing the performance of foxPSL to a stateof-the-art implementation of ADMM consensus optimization in GraphLab, and show an improvement in both inference time and solution quality. Moreover, we evaluate the impact of the optimizations on the execution time and discuss the trade-offs related to each optimization. (C) 2015 The Authors. Published by Elsevier Inc.", "paper_title": "foxPSL: A Fast, Optimized and eXtended PSL implementation", "paper_id": "WOS:000364725300006"}