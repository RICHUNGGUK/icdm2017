{"auto_keywords": [{"score": 0.034804455095609727, "phrase": "sift_method"}, {"score": 0.00481495049065317, "phrase": "fully_affine_invariant_image_comparison"}, {"score": 0.00476323161560059, "phrase": "physical_object"}, {"score": 0.004724805619908213, "phrase": "smooth_or_piecewise_smooth_boundary"}, {"score": 0.0046238380150870435, "phrase": "varying_positions"}, {"score": 0.004598933498016774, "phrase": "smooth_apparent_deformations"}, {"score": 0.004488505301335364, "phrase": "affine_transforms"}, {"score": 0.004452285666140591, "phrase": "image_plane"}, {"score": 0.004392565073466714, "phrase": "solid_object_recognition_problem"}, {"score": 0.00427550604912774, "phrase": "affine_invariant_image_local_features"}, {"score": 0.0041728113383304125, "phrase": "normalization_methods"}, {"score": 0.00412796126884884, "phrase": "fully_affine_normalization_method"}, {"score": 0.00394264312173188, "phrase": "scale-invariant_feature_transform"}, {"score": 0.0037758453878187323, "phrase": "sift"}, {"score": 0.003695040819303525, "phrase": "six_parameters"}, {"score": 0.003665200409053223, "phrase": "affine_transform"}, {"score": 0.0031759067385562553, "phrase": "resulting_method"}, {"score": 0.003116351738760937, "phrase": "fully_affine_invariant"}, {"score": 0.0029763124376934787, "phrase": "dramatic_computational_load"}, {"score": 0.002952259134660412, "phrase": "two-resolution_scheme"}, {"score": 0.0029204892894712535, "phrase": "asift_complexity"}, {"score": 0.002873475119977635, "phrase": "sift."}, {"score": 0.00285796863539838, "phrase": "new_notion"}, {"score": 0.0028348690177346448, "phrase": "transition_tilt"}, {"score": 0.002707444334463544, "phrase": "absolute_tilt"}, {"score": 0.0026638482306228575, "phrase": "slanted_view"}, {"score": 0.0024963543716522087, "phrase": "attainable_transition_tilt"}, {"score": 0.0024628046987344846, "phrase": "affine_image_comparison_method"}, {"score": 0.0024428911807302988, "phrase": "new_method"}, {"score": 0.0023776656246300063, "phrase": "transition_tilts"}, {"score": 0.0023648305043900662, "phrase": "large_magnitude"}, {"score": 0.00225848609192748, "phrase": "asift"}, {"score": 0.002104998402294158, "phrase": "hessian-affine"}], "paper_keywords": ["image matching", " descriptors", " affine invariance", " scale invariance", " affine normalization", " scale-invariant feature transform (SIFT)"], "paper_abstract": "If a physical object has a smooth or piecewise smooth boundary, its images obtained by cameras in varying positions undergo smooth apparent deformations. These deformations are locally well approximated by affine transforms of the image plane. In consequence the solid object recognition problem has often been led back to the computation of affine invariant image local features. Such invariant features could be obtained by normalization methods, but no fully affine normalization method exists for the time being. Even scale invariance is dealt with rigorously only by the scale-invariant feature transform (SIFT) method. By simulating zooms out and normalizing translation and rotation, SIFT is invariant to four out of the six parameters of an affine transform. The method proposed in this paper, affine-SIFT (ASIFT), simulates all image views obtainable by varying the two camera axis orientation parameters, namely, the latitude and the longitude angles, left over by the SIFT method. Then it covers the other four parameters by using the SIFT method itself. The resulting method will be mathematically proved to be fully affine invariant. Against any prognosis, simulating all views depending on the two camera orientation parameters is feasible with no dramatic computational load. A two-resolution scheme further reduces the ASIFT complexity to about twice that of SIFT. A new notion, the transition tilt, measuring the amount of distortion from one view to another, is introduced. While an absolute tilt from a frontal to a slanted view exceeding 6 is rare, much higher transition tilts are common when two slanted views of an object are compared (see Figure 1). The attainable transition tilt is measured for each affine image comparison method. The new method permits one to reliably identify features that have undergone transition tilts of large magnitude, up to 36 and higher. This fact is substantiated by many experiments which show that ASIFT significantly outperforms the state-of-the-art methods SIFT, maximally stable extremal region (MSER), Harris-affine, and Hessian-affine.", "paper_title": "ASIFT: A New Framework for Fully Affine Invariant Image Comparison", "paper_id": "WOS:000278101100006"}