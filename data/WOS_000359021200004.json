{"auto_keywords": [{"score": 0.05007537788564748, "phrase": "image_descriptions"}, {"score": 0.049786882302876256, "phrase": "user_tagging_behavior"}, {"score": 0.026528873866425513, "phrase": "tags"}, {"score": 0.026214872006293348, "phrase": "description_condition"}, {"score": 0.0046432244185370605, "phrase": "crowdsourced_tags"}, {"score": 0.004504786051750715, "phrase": "social_wisdom"}, {"score": 0.004076444306787255, "phrase": "crowdsourcing_interface_design"}, {"score": 0.004015182362035361, "phrase": "images'_titles"}, {"score": 0.003930953151925098, "phrase": "image_digital_libraries"}, {"score": 0.0036222340564869625, "phrase": "digital_image_libraries"}, {"score": 0.0031223774204093713, "phrase": "tagging_system"}, {"score": 0.003056819704624705, "phrase": "image_tags"}, {"score": 0.0030383422480050573, "phrase": "amazon's_mechanical_turk's_crowdworkerswith"}, {"score": 0.00297454367746853, "phrase": "generated_tags"}, {"score": 0.002938688858078236, "phrase": "different_perspectives"}, {"score": 0.002675039053570178, "phrase": "image_description"}, {"score": 0.0026508118618120114, "phrase": "users'_information"}, {"score": 0.0026188490199688013, "phrase": "tag_cloud_interface"}, {"score": 0.002509976179108431, "phrase": "crowdsourcing_approach"}, {"score": 0.002326669201839705, "phrase": "higher_tag_reuse_rate"}, {"score": 0.002305589818994465, "phrase": "user_study"}, {"score": 0.0022777800735119405, "phrase": "different_tag_sets"}, {"score": 0.0022640009579466924, "phrase": "different_support"}, {"score": 0.0021764417172328307, "phrase": "target_results"}, {"score": 0.002124247104243502, "phrase": "user_success"}, {"score": 0.0021049977753042253, "phrase": "search_task"}], "paper_keywords": ["information access", " information use", " shared cataloging"], "paper_abstract": "Crowdsourcing has emerged as a way to harvest social wisdom from thousands of volunteers to perform a series of tasks online. However, little research has been devoted to exploring the impact of various factors such as the content of a resource or crowdsourcing interface design on user tagging behavior. Although images' titles and descriptions are frequently available in image digital libraries, it is not clear whether they should be displayed to crowdworkers engaged in tagging. This paper focuses on offering insight to the curators of digital image libraries who face this dilemma by examining (i) how descriptions influence the user in his/her tagging behavior and (ii) how this relates to the (a) nature of the tags, (b) the emergent folksonomy, and (c) the findability of the images in the tagging system. We compared two different methods for collecting image tags from Amazon's Mechanical Turk's crowdworkerswith and without image descriptions. Several properties of generated tags were examined from different perspectives: diversity, specificity, reusability, quality, similarity, descriptiveness, and so on. In addition, the study was carried out to examine the impact of image description on supporting users' information seeking with a tag cloud interface. The results showed that the properties of tags are affected by the crowdsourcing approach. Tags from the with description condition are more diverse and more specific than tags from the without description condition, while the latter has a higher tag reuse rate. A user study also revealed that different tag sets provided different support for search. Tags produced with description shortened the path to the target results, whereas tags produced without description increased user success in the search task.", "paper_title": "The Impact of Image Descriptions on User Tagging Behavior: A Study of the Nature and Functionality of Crowdsourced Tags", "paper_id": "WOS:000359021200004"}