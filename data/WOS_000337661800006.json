{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "generative_classifier"}, {"score": 0.004736045157669388, "phrase": "label_proportions"}, {"score": 0.004324521292490181, "phrase": "marginal_distribution"}, {"score": 0.004253618550301311, "phrase": "class_labels"}, {"score": 0.004081385289516914, "phrase": "data_groups"}, {"score": 0.0033743949483348626, "phrase": "data_instances"}, {"score": 0.0027211030647461324, "phrase": "existing_algorithms"}, {"score": 0.0025257081555100556, "phrase": "density_estimation_framework"}, {"score": 0.0023249757987087055, "phrase": "practical_rbm-based_algorithm"}, {"score": 0.0022122603123901114, "phrase": "benchmark_datasets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Proportion learning", " Bayesian model", " Restricted Boltzmann machine"], "paper_abstract": "Learning a classifier when only knowing the features and marginal distribution of class labels in each of the data groups is both theoretically interesting and practically useful. Specifically, we consider the case in which the ratio of the number of data instances to the number of classes is large. We prove sample complexity upper bound in this setting, which is inspired by an analysis of existing algorithms. We further formulate the problem in a density estimation framework to learn a generative classifier. We also develop a practical RBM-based algorithm which shows promising performance on benchmark datasets. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Learning a generative classifier from label proportions", "paper_id": "WOS:000337661800006"}