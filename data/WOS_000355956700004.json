{"auto_keywords": [{"score": 0.03459313900284793, "phrase": "mtd"}, {"score": 0.00481495049065317, "phrase": "non-dedicated_heterogeneous_multicluster"}, {"score": 0.0046632033374901715, "phrase": "scientific_workflow"}, {"score": 0.004574449773348889, "phrase": "parallel_task_graphs"}, {"score": 0.004516217589503588, "phrase": "ptg"}, {"score": 0.004345909305473054, "phrase": "task_parallelism"}, {"score": 0.004076157223660074, "phrase": "industrial_domains"}, {"score": 0.004024242000713225, "phrase": "efficient_scheduling"}, {"score": 0.0038973170902076707, "phrase": "multicluster_platform"}, {"score": 0.003798654583736764, "phrase": "long-standing_challenge"}, {"score": 0.0037024804835018373, "phrase": "previous_work"}, {"score": 0.0035399770257915466, "phrase": "dedicated_multicluster"}, {"score": 0.0033845816848753073, "phrase": "novel_scheduling_algorithm"}, {"score": 0.0031743093007496736, "phrase": "non-dedicated_heterogeneous_multicluster_platform"}, {"score": 0.003054450075234415, "phrase": "novel_method"}, {"score": 0.002958021635132416, "phrase": "dynamic_critical_path"}, {"score": 0.0028830690329478465, "phrase": "availability_fluctuation"}, {"score": 0.0027564303939865476, "phrase": "scientific_workflow's_data-parallel_tasks"}, {"score": 0.0026693851900137953, "phrase": "moldable_task_duplication_strategy"}, {"score": 0.002601727192945944, "phrase": "pre-duplicated_predecessor_tasks"}, {"score": 0.0024556852466581527, "phrase": "data-parallel_tasks"}, {"score": 0.002378114613631841, "phrase": "broad_range"}, {"score": 0.002347775213789611, "phrase": "scientific_workflow_and_multicluster_platform_settings"}, {"score": 0.0022302306304023602, "phrase": "proposed_approach"}, {"score": 0.0021876814398268775, "phrase": "numerical_results"}, {"score": 0.0021049977753042253, "phrase": "better_average_ptg_makespan"}], "paper_keywords": ["Scientific workflow", " heterogeneous multicluster", " scheduling", " advance reservation", " task duplication", " task migration"], "paper_abstract": "Scientific workflow structured as Parallel Task Graphs (PTG) exhibits both data and task parallelism, and arises in scientific as well as in industrial domains. Efficient scheduling of such workflow on a multicluster platform has been a long-standing challenge. Most of previous work on PTG scheduling primarily focused on dedicated multicluster. In this paper, a novel scheduling algorithm known as the Moldable Task Duplication (MTD) is applied to non-dedicated heterogeneous multicluster platform with advance reservations. A novel method for the calculation of dynamic critical path that handles the availability fluctuation of multicluster and the moldability of scientific workflow's data-parallel tasks is proposed. A moldable task duplication strategy with migration of pre-duplicated predecessor tasks is developed to fully exploit the flexibility of data-parallel tasks. Simulations spanning a broad range of scientific workflow and multicluster platform settings are performed in order to verify the proposed approach. The numerical results show that MTD can achieve better average PTG makespan than previous methods in the literature.", "paper_title": "Scientific workflow scheduling in non-dedicated heterogeneous multicluster with advance reservations", "paper_id": "WOS:000355956700004"}