{"auto_keywords": [{"score": 0.038719753539566616, "phrase": "mcssvm"}, {"score": 0.010533081822550819, "phrase": "support_vector_machine"}, {"score": 0.00481495049065317, "phrase": "minimum_class_spread"}, {"score": 0.004724980378009193, "phrase": "classical_classification_methods"}, {"score": 0.004550029253278477, "phrase": "strong_generalization_capability"}, {"score": 0.004481868017991508, "phrase": "separation_margin"}, {"score": 0.004448169552315403, "phrase": "binary_classes"}, {"score": 0.004171730509424374, "phrase": "optimal_solutions"}, {"score": 0.0039869632444468036, "phrase": "preferentially_separate_classes"}, {"score": 0.003956971099850658, "phrase": "large_margin_directions"}, {"score": 0.0037674258625824113, "phrase": "novel_minimum_class_spread"}, {"score": 0.003641528016135388, "phrase": "pattern_classification_problems"}, {"score": 0.003546513036085932, "phrase": "interclass_separation_margin"}, {"score": 0.0033511469200347907, "phrase": "distribution-dependent_regularization"}, {"score": 0.003313380246267812, "phrase": "classification_function"}, {"score": 0.003214730261140886, "phrase": "input_data"}, {"score": 0.0031784960695034645, "phrase": "basic_idea"}, {"score": 0.0030955250132409964, "phrase": "class_distribution"}, {"score": 0.003083849594367653, "phrase": "constrained_hyperplane"}, {"score": 0.003014713272570927, "phrase": "normal_class"}, {"score": 0.0029360049890445944, "phrase": "minimum_q-spread_tube"}, {"score": 0.002859345731792013, "phrase": "abnormal_class"}, {"score": 0.002722234804904997, "phrase": "maximum_interclass_margin"}, {"score": 0.0026014984513015368, "phrase": "generalization_capability"}, {"score": 0.002572158343938064, "phrase": "proposed_classifier"}, {"score": 0.0025239898026543964, "phrase": "proposed_method"}, {"score": 0.002495521662819317, "phrase": "simple_extensions"}, {"score": 0.002476721068743341, "phrase": "existing_maximum_margin_formulations"}, {"score": 0.0022447938263410023, "phrase": "toy_and_real-world_classification_problems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Pattern classification", " Novelty detection", " Within-class spread", " Support vector machines (SVMs)", " Kernel trick"], "paper_abstract": "While classical classification methods such as support vector machine and its extensions (SVMs) obtain strong generalization capability by maximizing the separation margin between binary classes, they are usually sensitive to affine (or scaling) transformation of data. The optimal solutions of SVMs may be misled by the spread of data and preferentially separate classes along large margin directions. To this end, in this paper, we propose a novel minimum class spread constrained support vector machine (MCSSVM) for pattern classification problems by simultaneously considering the maximization of interclass separation margin and the minimization of within-class spread of data, which corresponds to a distribution-dependent regularization on the classification function by constraining the within-class spread of input data. The basic idea of MCSSVM is to find a class distribution constrained hyperplane such that one class (or normal class) can be enclosed in a minimum q-spread tube, while the other class (or abnormal class) is farthest from this tube. MCSSVM can simultaneously achieve both maximum interclass margin and minimum within-class spread so as to enhance the generalization capability of the proposed classifier. Moreover, the proposed method only requires simple extensions to existing maximum margin formulations such as SVMs and still preserves their computational efficiency. Generalization bound for MCSSVM is theoretically derived and the validity of MCSSVM is examined by classification of toy and real-world classification problems, which demonstrate the superiority of our method in comparison to other related state-of-the-art algorithms. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Minimum class spread constrained support vector machine", "paper_id": "WOS:000347753400052"}