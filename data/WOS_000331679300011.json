{"auto_keywords": [{"score": 0.027140291257134692, "phrase": "strictly_local_features"}, {"score": 0.00481495049065317, "phrase": "local_image_features"}, {"score": 0.004588389551682397, "phrase": "image_content"}, {"score": 0.004494570360108983, "phrase": "limited_number"}, {"score": 0.004283019592801715, "phrase": "local_feature_extractor"}, {"score": 0.004025531820226182, "phrase": "robust_image_representation"}, {"score": 0.003757480190200645, "phrase": "context-aware_feature_extraction"}, {"score": 0.0036553070575015344, "phrase": "information_theoretic_framework"}, {"score": 0.003435426082776884, "phrase": "specific_type"}, {"score": 0.0032287289440915187, "phrase": "complementary_features"}, {"score": 0.003097865379563127, "phrase": "image_context"}, {"score": 0.00271735110571002, "phrase": "context-aware_features"}, {"score": 0.002255431275670053, "phrase": "context-aware_ones"}, {"score": 0.0021940118003312397, "phrase": "even_more_robust_representation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Local features", " Keypoint extraction", " Image content descriptors", " Image representation", " Visual saliency", " Information theory", " Kernel estimators", " Complementarity"], "paper_abstract": "Local image features are often used to efficiently represent image content. The limited number of types of features that a local feature extractor responds to might be insufficient to provide a robust image representation. To overcome this limitation, we propose a context-aware feature extraction formulated under an information theoretic framework. The algorithm does not respond to a specific type of features; the idea is to retrieve complementary features which are relevant within the image context. We empirically validate the method by investigating the repeatability, the completeness, and the complementarity of context-aware features on standard benchmarks. In a comparison with strictly local features, we show that our context-aware features produce more robust image representations. Furthermore, we study the complementarity between strictly local features and context-aware ones to produce an even more robust representation. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Context-aware features and robust image representations", "paper_id": "WOS:000331679300011"}