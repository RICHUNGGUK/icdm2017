{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "video_alignment"}, {"score": 0.030514940731389485, "phrase": "different_times"}, {"score": 0.004721711709176679, "phrase": "different_areas"}, {"score": 0.004675768396728975, "phrase": "computer_vision"}, {"score": 0.004607686390487483, "phrase": "wide_baseline_matching"}, {"score": 0.004562847483469705, "phrase": "action_recognition"}, {"score": 0.004452641437293878, "phrase": "video_copy_detection"}, {"score": 0.004387793971765289, "phrase": "dropping_prevention"}, {"score": 0.004345085569121329, "phrase": "current_video_alignment_methods"}, {"score": 0.004240116703465252, "phrase": "relatively_simple_case"}, {"score": 0.004077394032903726, "phrase": "simultaneous_acquisition"}, {"score": 0.0038827100184187805, "phrase": "joint_video_alignment"}, {"score": 0.003770373393393271, "phrase": "spatio-temporal_alignment"}, {"score": 0.0034693659976716197, "phrase": "spatial_and_temporal_alignment"}, {"score": 0.0034187896011435245, "phrase": "single_alignment_framework"}, {"score": 0.0031767199435197243, "phrase": "neighbor_frames"}, {"score": 0.003130396338031522, "phrase": "standard_pairwise_markov_random_field"}, {"score": 0.0030397596289795143, "phrase": "new_formulation"}, {"score": 0.002852256089630964, "phrase": "independent_moving_cameras"}, {"score": 0.0027969169552386, "phrase": "similar_trajectory"}, {"score": 0.0027159094186967247, "phrase": "particular_cases"}, {"score": 0.0026762874092443197, "phrase": "fixed_geometric_transformation"}, {"score": 0.0026501935378083663, "phrase": "linear_temporal_mapping"}, {"score": 0.002573424607574822, "phrase": "different_scenarios"}, {"score": 0.002379379676378223, "phrase": "proposed_approach"}, {"score": 0.002344655708000408, "phrase": "proposed_method"}, {"score": 0.0023104373174118458, "phrase": "highest_video_alignment_accuracy"}], "paper_keywords": ["Direct-based", " feature-based", " image registration", " Markov random fields", " synchronization", " video alignment", " video retrieval"], "paper_abstract": "Video alignment is important in different areas of computer vision such as wide baseline matching, action recognition, change detection, video copy detection and frame dropping prevention. Current video alignment methods usually deal with a relatively simple case of fixed or rigidly attached cameras or simultaneous acquisition. Therefore, in this paper we propose a joint video alignment for bringing two video sequences into a spatio-temporal alignment. Specifically, the novelty of the paper is to formulate the video alignment to fold the spatial and temporal alignment into a single alignment framework. This simultaneously satisfies a frame-correspondence and frame-alignment similarity; exploiting the knowledge among neighbor frames by a standard pairwise Markov random field (MRF). This new formulation is able to handle the alignment of sequences recorded at different times by independent moving cameras that follows a similar trajectory, and also generalizes the particular cases that of fixed geometric transformation and/or linear temporal mapping. We conduct experiments on different scenarios such as sequences recorded simultaneously or by moving cameras to validate the robustness of the proposed approach. The proposed method provides the highest video alignment accuracy compared to the state-of-the-art methods on sequences recorded from vehicles driving along the same track at different times.", "paper_title": "Joint Spatio-Temporal Alignment of Sequences", "paper_id": "WOS:000324765400014"}