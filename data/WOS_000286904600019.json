{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "chi-square_statistics"}, {"score": 0.04829779156277875, "phrase": "text_categorization"}, {"score": 0.043626296647104795, "phrase": "chi-square_tests"}, {"score": 0.007290872219550176, "phrase": "combined_usage"}, {"score": 0.003923532450854754, "phrase": "term_vectors"}, {"score": 0.003371066990851953, "phrase": "chi-square_test"}, {"score": 0.0031724417545242315, "phrase": "miss_rate"}, {"score": 0.0030311679447397725, "phrase": "theoretical_performance"}, {"score": 0.0027671619871474764, "phrase": "cosine_similarities"}, {"score": 0.0026640466056415298, "phrase": "idf_performs"}, {"score": 0.0023952639120005193, "phrase": "optimal_threshold_value"}, {"score": 0.0021049977753042253, "phrase": "extensive_experiment_results"}], "paper_keywords": ["Nonparametric statistics", " Text mining", " Machine learning"], "paper_abstract": "In this paper, we propose using chi-square statistics to measure similarities and chi-square tests to determine the homogeneity of two random samples of term vectors for text categorization. The properties of chi-square tests for text categorization are studied first. One of the advantages of chi-square test is that its significance level is similar to the miss rate that provides a foundation for theoretical performance (i.e. miss rate) guarantee. Generally a classifier using cosine similarities with IF I* IDF performs reasonably well in text categorization. However, its performance may fluctuate even near the optimal threshold value. To improve the limitation, we propose the combined usage of chi-square statistics and cosine similarities. Extensive experiment results verify properties of chi-square tests and performance of the combined usage. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Using chi-square statistics to measure similarities for text categorization", "paper_id": "WOS:000286904600019"}