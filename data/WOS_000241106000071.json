{"auto_keywords": [{"score": 0.04455074562181148, "phrase": "mlcof"}, {"score": 0.03125414807245528, "phrase": "ontological_elements"}, {"score": 0.00481495049065317, "phrase": "robot_context_modeling"}, {"score": 0.004704187604192605, "phrase": "object_recognition"}, {"score": 0.004569293780076254, "phrase": "multi-layered_context_ontology_framework"}, {"score": 0.004187284711626886, "phrase": "six_knowledge_layers"}, {"score": 0.003973523379376352, "phrase": "image_layer"}, {"score": 0.003662410853488772, "phrase": "object_layer"}, {"score": 0.00357806560856829, "phrase": "space_layer"}, {"score": 0.0032786537599187125, "phrase": "relational_functions"}, {"score": 0.0032406665327678616, "phrase": "concept_hierarchies"}, {"score": 0.0032031180198375283, "phrase": "relation_hierarchies"}, {"score": 0.0029867619862229853, "phrase": "relational_constraints"}, {"score": 0.002658068304632523, "phrase": "different_klayers"}, {"score": 0.002536926192232391, "phrase": "integrated_robot_context_information"}, {"score": 0.00249293148301837, "phrase": "low_level_image"}, {"score": 0.0024640253074497114, "phrase": "high_level_object"}, {"score": 0.002435453488008121, "phrase": "space_semantics"}, {"score": 0.0023792975669318615, "phrase": "integrated_context_knowledge"}, {"score": 0.002244494905883452, "phrase": "unidirectional_reasoning"}, {"score": 0.0021672995161145276, "phrase": "bidirectional_reasoning"}, {"score": 0.0021049977753042253, "phrase": "partial_information"}], "paper_keywords": [""], "paper_abstract": "This paper introduces Multi-layered Context Ontology Framework (MLCOF) for comprehensive, integrated robot context modeling and reasoning for object recognition. MLCOF consists of six knowledge layers (KLayer) including rules such as an image layer, three geometry (1D, 2D and 3D geometry) layers, an object layer, and a space layer. For each KLayer, we use a 6-tuple ontology structure including concepts, relations, relational functions, concept hierarchies, relation hierarchies and axioms. The axioms specify the semantics of concepts and relational constraints between ontological elements at each KLayer. The rules are used to specify or infer the relationships between ontological elements at different KLayers. Thus, MLCOF enables to model integrated robot context information from a low level image to high level object and space semantics. With the integrated context knowledge, a robot can understand objects not only through unidirectional reasoning between two adjacent layers but also through bidirectional reasoning among several layers even with partial information.", "paper_title": "Ontology-based framework of robot context modeling and reasoning for object recognition", "paper_id": "WOS:000241106000071"}