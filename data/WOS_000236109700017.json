{"auto_keywords": [{"score": 0.02894162358044572, "phrase": "f_rate"}, {"score": 0.014225591742458042, "phrase": "better_performance"}, {"score": 0.013280479325587511, "phrase": "multiple_learners"}, {"score": 0.008726195921702491, "phrase": "base-chunking_task"}, {"score": 0.004271100220705305, "phrase": "external_resources"}, {"score": 0.004164644263639545, "phrase": "additional_training_data"}, {"score": 0.0032556926399045635, "phrase": "mask_method"}, {"score": 0.003174464741377186, "phrase": "chunking_accuracy"}, {"score": 0.0031148723927633955, "phrase": "experimental_results"}, {"score": 0.0024654846995380347, "phrase": "chinese"}, {"score": 0.0021726139494880653, "phrase": "complete_chunking_time"}], "paper_keywords": [""], "paper_abstract": "Several phrase chunkers have been proposed over the past few years. Some state-of-the-art chunkers achieved better performance via integrating external resources, e.g., parsers and additional training data, or combining multiple learners. However, in many languages and domains, such external materials are not easily available and the combination of multiple learners will increase the cost of training and testing. In this paper, we propose a mask method to improve the chunking accuracy. The experimental results show that our chunker achieves better performance in comparison with other deep parsers and chunkers. For CoNLL-2000 data set, our system achieves 94.12 in F rate. For the base-chunking task, our system reaches 92.95 in F rate. When porting to Chinese, the performance of the base-chunking task is 92.36 in F rate. Also, our chunker is quite efficient. The complete chunking time of a 50K words document is about 50 seconds.", "paper_title": "A general and multi-lingual phrase chunking model based on masking method", "paper_id": "WOS:000236109700017"}