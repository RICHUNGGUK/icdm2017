{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "diagonal_discriminant_analysis"}, {"score": 0.004706453355638515, "phrase": "high-dimensional_data"}, {"score": 0.004548253531664032, "phrase": "new_challenges"}, {"score": 0.0044967055264893184, "phrase": "traditional_statistical_methods"}, {"score": 0.0043703658695579085, "phrase": "class_prediction"}, {"score": 0.0043208252177835815, "phrase": "high-_dimension"}, {"score": 0.004058180509184539, "phrase": "small_sample_size"}, {"score": 0.0036622637391432143, "phrase": "class_prediction_methods"}, {"score": 0.0033427754823819157, "phrase": "statistical_methods"}, {"score": 0.002931569771634119, "phrase": "shrinkage_estimators"}, {"score": 0.002881793492919646, "phrase": "mean_value"}, {"score": 0.0028328599839713866, "phrase": "quadratic_loss_function"}, {"score": 0.002784755056588371, "phrase": "optimal_shrinkage_parameter"}, {"score": 0.0026604207233593973, "phrase": "sample_size"}, {"score": 0.0024700776739384977, "phrase": "shrinkage-based_diagonal_discriminant_rule"}, {"score": 0.002359759876402679, "phrase": "proposed_shrinkage_mean"}, {"score": 0.0022672718785099666, "phrase": "simulation_studies"}, {"score": 0.00224151735457093, "phrase": "real_data"}, {"score": 0.0021908807203548345, "phrase": "proposed_shrinkage-based_rule"}, {"score": 0.0021049977753042253, "phrase": "wide_range"}], "paper_keywords": [""], "paper_abstract": "Motivation: High-dimensional data such as microarrays have created new challenges to traditional statistical methods. One such example is on class prediction with high- dimension, low-sample size data. Due to the small sample size, the sample mean estimates are usually unreliable. As a consequence, the performance of the class prediction methods using the sample mean may also be unsatisfactory. To obtain more accurate estimation of parameters some statistical methods, such as regularizations through shrinkage, are often desired. Results: In this article, we investigate the family of shrinkage estimators for the mean value under the quadratic loss function. The optimal shrinkage parameter is proposed under the scenario when the sample size is fixed and the dimension is large. We then construct a shrinkage-based diagonal discriminant rule by replacing the sample mean by the proposed shrinkage mean. Finally, we demonstrate via simulation studies and real data analysis that the proposed shrinkage-based rule outperforms its original competitor in a wide range of settings.", "paper_title": "Improved mean estimation and its application to diagonal discriminant analysis", "paper_id": "WOS:000300490500012"}