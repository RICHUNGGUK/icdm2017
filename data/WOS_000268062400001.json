{"auto_keywords": [{"score": 0.039133422014451295, "phrase": "classification_model"}, {"score": 0.015719716506582538, "phrase": "batch_mode_active_learning"}, {"score": 0.01413974721604038, "phrase": "active_learning"}, {"score": 0.013726124059438871, "phrase": "manual_labeling"}, {"score": 0.008132830049320436, "phrase": "unlabeled_examples"}, {"score": 0.00473320761888448, "phrase": "text_categorization"}, {"score": 0.004476963405985556, "phrase": "manually_labeled_data_examples"}, {"score": 0.004419819325202464, "phrase": "training_stage"}, {"score": 0.004144810537437608, "phrase": "learning_tasks"}, {"score": 0.004056981775766067, "phrase": "previous_studies"}, {"score": 0.003920295222165263, "phrase": "single_unlabeled_example"}, {"score": 0.0036137713873827374, "phrase": "acquired_labeled_example"}, {"score": 0.0034621581245372138, "phrase": "information_retrieval_tasks"}, {"score": 0.0034179225740833055, "phrase": "user's_relevance_feedback"}, {"score": 0.003331134183901191, "phrase": "top_k"}, {"score": 0.0030573959252626695, "phrase": "informative_examples"}, {"score": 0.002954287204671032, "phrase": "key_feature"}, {"score": 0.002929056388593134, "phrase": "batch_mode"}, {"score": 0.0028060889647071787, "phrase": "selected_examples"}, {"score": 0.0027347937102326285, "phrase": "unique_information"}, {"score": 0.0027114323601885666, "phrase": "model_updating"}, {"score": 0.002608744950946475, "phrase": "fisher_information_matrix"}, {"score": 0.002553382046204689, "phrase": "model_uncertainty"}, {"score": 0.002414861891567233, "phrase": "fisher_information"}, {"score": 0.002283839204519042, "phrase": "image_retrieval"}, {"score": 0.002264321283759897, "phrase": "promising_results"}, {"score": 0.0021692000054033956, "phrase": "active_learning_approaches"}], "paper_keywords": ["Batch mode active learning", " logistic regressions", " kernel logistic regressions", " convex optimization", " text categorization", " image retrieval"], "paper_abstract": "Most machine learning tasks in data classification and information retrieval require manually labeled data examples in the training stage. The goal of active learning is to select the most informative examples for manual labeling in these learning tasks. Most of the previous studies in active learning have focused on selecting a single unlabeled example in each iteration. This could be inefficient, since the classification model has to be retrained for every acquired labeled example. It is also inappropriate for the setup of information retrieval tasks where the user's relevance feedback is often provided for the top K retrieved items. In this paper, we present a framework for batch mode active learning, which selects a number of informative examples for manual labeling in each iteration. The key feature of batch mode active learning is to reduce the redundancy among the selected examples such that each example provides unique information for model updating. To this end, we employ the Fisher information matrix as the measurement of model uncertainty, and choose the set of unlabeled examples that can efficiently reduce the Fisher information of the classification model. We apply our batch mode active learning framework to both text categorization and image retrieval. Promising results show that our algorithms are significantly more effective than the active learning approaches that select unlabeled examples based only on their informativeness for the classification model.", "paper_title": "Batch Mode Active Learning with Applications to Text Categorization and Image Retrieval", "paper_id": "WOS:000268062400001"}