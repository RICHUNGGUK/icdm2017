{"auto_keywords": [{"score": 0.028504862533703615, "phrase": "local_critics"}, {"score": 0.00481495049065317, "phrase": "multiple_local_critics"}, {"score": 0.00478579024367007, "phrase": "decision_making"}, {"score": 0.004517387079319428, "phrase": "perpetual_difficulty"}, {"score": 0.004435782384431224, "phrase": "action_values"}, {"score": 0.004395532072377065, "phrase": "time_steps"}, {"score": 0.004174220694700258, "phrase": "reinforcement_rewards"}, {"score": 0.0041112665381266315, "phrase": "complicated_or_blurred_environments"}, {"score": 0.0039280214778273925, "phrase": "concurrent_learning"}, {"score": 0.0038453138708790385, "phrase": "sensory_space"}, {"score": 0.0037415196765275376, "phrase": "selected_motor_actions"}, {"score": 0.003651603914126771, "phrase": "previous_works"}, {"score": 0.00342568771304873, "phrase": "input_space"}, {"score": 0.0033129660760880383, "phrase": "objective_sensory_data"}, {"score": 0.0032629585038738856, "phrase": "mental_states"}, {"score": 0.0032431667821391044, "phrase": "subjective_inputs"}, {"score": 0.003117405395602633, "phrase": "selected_action"}, {"score": 0.0030147970456037274, "phrase": "local_critic"}, {"score": 0.0029874020705125356, "phrase": "agent's_actions"}, {"score": 0.0029422942175866057, "phrase": "task_domain"}, {"score": 0.0028367868542874737, "phrase": "local_critic's_assessment"}, {"score": 0.0028110048684383167, "phrase": "sparse_super-critic_punishing_revisions"}, {"score": 0.0026209522797963447, "phrase": "appropriate_subset"}, {"score": 0.0025735173163957993, "phrase": "physical_actions"}, {"score": 0.002526938673434697, "phrase": "effective_combination"}, {"score": 0.0024511688853030168, "phrase": "prior_accurately_designed_critic"}, {"score": 0.0024288830311280573, "phrase": "mathematical_formulation"}, {"score": 0.002414138203828421, "phrase": "proposed_learning_method"}, {"score": 0.0023346234464901978, "phrase": "proposed_method"}, {"score": 0.002264607102799332, "phrase": "attention_control"}, {"score": 0.0022236070278432575, "phrase": "monte_carlo_analysis"}, {"score": 0.002203385580030364, "phrase": "experimental_results"}, {"score": 0.0021700901058417602, "phrase": "proposed_formulation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Attention control", " Reinforcement learning", " Q-learning", " Brain emotional learning controller", " Multi objective problems", " Model free control"], "paper_abstract": "Dealing with uncertainties and lack of knowledge about problems and situations, there is a perpetual difficulty to evaluate the situations and action values in all time steps. On the other hand, the design of critics which delicately guide the agent even with reinforcement rewards and punishments in these complicated or blurred environments is laborious and cumbersome. In this study, we propose a framework for concurrent learning of control of attention to the sensory space, attention to the various critics to evaluate the selected motor actions, and the motor actions themselves. Previous works include the implementation of the control of attention for selecting the most important parts of data and/or reducing the dimensionality of the input space. However, decision making can depend not only on objective sensory data, but also upon mental states or subjective inputs as well. Specifically, we examine attention for the evaluations of selected action by various local critics, as well as sensory inputs. Each local critic evaluates the agent's actions regarding to its standpoints on task domain. Our agent tries to learn the degree of importance of each local critic's assessment, using sparse super-critic punishing revisions. So the agent learns the way of combining or even disregarding some of local critics while it learns to focus on the appropriate subset of features, and learns physical actions concurrently. By discovering the effective combination of local critics, the agent does not need any prior accurately designed critic. The mathematical formulation of proposed learning method is developed. Also, in order to evaluate the proposed method, two benchmarks are discussed. The effect of using attention control on robustness is analyzed via Monte Carlo analysis. The experimental results show the efficiency of proposed formulation in presence of uncertainties. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Attention to multiple local critics in decision making and control", "paper_id": "WOS:000279408200022"}