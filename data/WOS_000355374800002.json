{"auto_keywords": [{"score": 0.04900554137256695, "phrase": "data_mapping"}, {"score": 0.04328118820753266, "phrase": "parallel_applications"}, {"score": 0.041692141960465806, "phrase": "memory_hierarchy"}, {"score": 0.03264800298277407, "phrase": "improved_mappings"}, {"score": 0.00481495049065317, "phrase": "communication_and_page_usage"}, {"score": 0.004631335513513859, "phrase": "shared-memory_systems"}, {"score": 0.004483659121004398, "phrase": "multicore_processors"}, {"score": 0.004454691230204595, "phrase": "current_systems"}, {"score": 0.004397313229350093, "phrase": "multithreaded_processors"}, {"score": 0.00436890075128947, "phrase": "non-uniform_memory_access"}, {"score": 0.0043406794401518265, "phrase": "numa"}, {"score": 0.004161553532799662, "phrase": "efficient_execution"}, {"score": 0.003912925129722523, "phrase": "shared_caches"}, {"score": 0.003691048155818806, "phrase": "numa_node"}, {"score": 0.0034145918296403874, "phrase": "application's_memory_access_behavior"}, {"score": 0.0032629585038738856, "phrase": "memory_pages"}, {"score": 0.0031690434364310435, "phrase": "profiling_method"}, {"score": 0.0029795342727066696, "phrase": "mathematical_description"}, {"score": 0.0029126002350975634, "phrase": "large_set"}, {"score": 0.002893753089970741, "phrase": "parallel_workloads"}, {"score": 0.0028195727965553367, "phrase": "parallel_apis"}, {"score": 0.0028014226458745535, "phrase": "mpi"}, {"score": 0.0027832320287009276, "phrase": "openmp"}, {"score": 0.0027651880029056454, "phrase": "pthreads"}, {"score": 0.002599763359352916, "phrase": "optimized_thread"}, {"score": 0.0025829353063908256, "phrase": "data_mappings"}, {"score": 0.002566215899764421, "phrase": "experimental_results"}, {"score": 0.0025248881422983553, "phrase": "performance_improvements"}, {"score": 0.0024048460326284416, "phrase": "energy_consumption"}, {"score": 0.002312925203110055, "phrase": "default_mapping"}, {"score": 0.0022904980438110613, "phrase": "operating_system"}, {"score": 0.0021464286727045623, "phrase": "optimal_improvements"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Shared memory", " Thread mapping", " Data mapping", " Multicore", " NUMA"], "paper_abstract": "The parallelism in shared-memory systems has increased significantly with the advent and evolution of multicore processors. Current systems include several multicore and multithreaded processors with Non-Uniform Memory Access (NUMA) characteristics. These architectures require the adoption of two strategies for the efficient execution of parallel applications: (i) threads sharing data should be placed in such a way in the memory hierarchy that they execute on shared caches; and (ii) a thread should have the data that it accesses placed on the NUMA node where it is executing. We refer to these techniques as thread and data mapping, respectively. Both strategies require knowledge of the application's memory access behavior to identify the communication between threads and processes as well as their usage of memory pages. In this paper, we introduce a profiling method to establish the suitability of parallel applications for improved mappings that take the memory hierarchy into account, based on a mathematical description of their memory access behaviors. Experiments with a large set of parallel workloads that are based on a variety of parallel APIs (MPI, OpenMP, Pthreads, and MPI+OpenMP) show that most applications can benefit from improved mappings. We provide a mechanism to compute optimized thread and data mappings. Experimental results with this mechanism showed performance improvements of up to 54% (20% on average), as well as reductions of the energy consumption of up to 37% (11% on average), compared to the default mapping by the operating system. Furthermore, our results show that thread and data mapping have to be performed jointly in order to achieve optimal improvements. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Characterizing communication and page usage of parallel applications for thread and data mapping", "paper_id": "WOS:000355374800002"}