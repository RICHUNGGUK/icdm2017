{"auto_keywords": [{"score": 0.04968510255692421, "phrase": "censored_data"}, {"score": 0.00481495049065317, "phrase": "intrinsic_bayes_factors"}, {"score": 0.004677711903652145, "phrase": "covariate_selection"}, {"score": 0.0046392209103157936, "phrase": "regression_models"}, {"score": 0.004601045179623499, "phrase": "right_censored_data"}, {"score": 0.00443308765153716, "phrase": "default_bayesian_point"}, {"score": 0.004360412703519539, "phrase": "bayes_factors"}, {"score": 0.004218602458288531, "phrase": "intrinsic_bf"}, {"score": 0.004081385289516914, "phrase": "minimal_training_samples"}, {"score": 0.0038518661517315533, "phrase": "possible_mtss_increases"}, {"score": 0.0037419747525425586, "phrase": "uncensored_data"}, {"score": 0.003590383760209319, "phrase": "proper_posterior"}, {"score": 0.0034024277222012597, "phrase": "sequential_minimal_training_sample_scheme"}, {"score": 0.0033743954502404197, "phrase": "smts"}, {"score": 0.0032510690712452147, "phrase": "ibf_correction_factors"}, {"score": 0.003171358146412577, "phrase": "analytical_form"}, {"score": 0.0031193028729331667, "phrase": "numerical_approximation"}, {"score": 0.003030247482854539, "phrase": "analytical_expression"}, {"score": 0.0029928611380840757, "phrase": "correction_terms"}, {"score": 0.0029559346879594254, "phrase": "different_ts_scheme"}, {"score": 0.0028360962841331634, "phrase": "km_minimal_training_sample_scheme"}, {"score": 0.0027211030647461324, "phrase": "analyzed_simulation_setting"}, {"score": 0.002504881868215954, "phrase": "ibf"}, {"score": 0.0024434201175883674, "phrase": "resulting_new_ibf"}, {"score": 0.002393353846080347, "phrase": "analytical_expressions"}, {"score": 0.0022492129111567824, "phrase": "large_simulation_study"}, {"score": 0.0021579641460002523, "phrase": "real_data_set"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Improper priors", " Intrinsic Bayes factor", " Kaplan-Meier estimator", " Model selection", " Survival analysis"], "paper_abstract": "The problem of covariate selection for regression models with right censored data is considered. It is approached from a default Bayesian point of view with Bayes factors (BFs) and in particular with Intrinsic BF (IBF) that depends on the minimal training samples (MTSs). In the presence of censored data, the number of possible MTSs increases, due to the fact that uncensored data, relevant for training the improper prior into a proper posterior, must be combined with censored data. For this purpose, the sequential minimal training sample scheme (SMTS) accounts for such requirements but generally leads to IBF correction factors that do not have an analytical form and thus require numerical approximation. In order to obtain an analytical expression of the correction terms, a different TS scheme is introduced based on the Kaplan-Meier (KM) estimator, termed the KM minimal training sample scheme. This new tool works extremely well in the analyzed simulation setting and also in the applications; it produces results which are similar, if not better, than the IBF calculated using MTSs. The resulting new IBF, being based on analytical expressions, is much faster to compute. Evidence of these results comes from a large simulation study, theoretical arguments, and an application to a real data set. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A new minimal training sample scheme for intrinsic Bayes factors in censored data", "paper_id": "WOS:000343347500005"}