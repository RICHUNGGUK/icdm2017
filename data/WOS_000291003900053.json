{"auto_keywords": [{"score": 0.03807495921495178, "phrase": "hypothetical_context_trees"}, {"score": 0.014054703109939047, "phrase": "context_tree"}, {"score": 0.011339497880963981, "phrase": "strong_consistency"}, {"score": 0.008496290932156838, "phrase": "true_context_tree"}, {"score": 0.00481495049065317, "phrase": "bic_context_tree"}, {"score": 0.004744437370338926, "phrase": "stationary_ergodic_processes"}, {"score": 0.004698000536608171, "phrase": "context_trees"}, {"score": 0.004652016085325825, "phrase": "arbitrary_stationary_ergodic_processes"}, {"score": 0.004385367803204002, "phrase": "markov_chain"}, {"score": 0.004216112320418982, "phrase": "infinite_depth"}, {"score": 0.003993958025223994, "phrase": "bayesian_information_criterion"}, {"score": 0.003954883863970129, "phrase": "bic"}, {"score": 0.003820896867623235, "phrase": "strongly_consistent_estimator"}, {"score": 0.0033950634506367235, "phrase": "estimated_context_tree"}, {"score": 0.0033452741392850523, "phrase": "true_one"}, {"score": 0.002914288956035066, "phrase": "recovery_level"}, {"score": 0.0028016507334576216, "phrase": "specific_rate"}, {"score": 0.002640781900605126, "phrase": "bic_estimator"}, {"score": 0.0025638362414466278, "phrase": "larger_and_larger_depths"}, {"score": 0.0024768883044869023, "phrase": "special_case"}, {"score": 0.002455839183645046, "phrase": "k"}, {"score": 0.002416589459425828, "phrase": "arbitrary_constant"}, {"score": 0.0022890371899188466, "phrase": "stationary_ergodic_process"}, {"score": 0.0022223176391038785, "phrase": "existing_results"}, {"score": 0.0021049977753042253, "phrase": "finite_depth"}], "paper_keywords": ["Bayesian information criterion (BIC)", " consistent estimation", " context tree", " ergodic processes", " infinite memory", " model selection", " suffix tree"], "paper_abstract": "Context trees of arbitrary stationary ergodic processes with finite alphabets are considered. Such a process is not necessarily a Markov chain, so the context tree may be of infinite depth. Calculated from a sample of size n, the Bayesian information criterion (BIC) is shown to provide a strongly consistent estimator of the context tree of the process, via minimization over hypothetical context trees, without any restriction on the hypothetical context trees. Strong consistency means that the estimated context tree recovers the true one up to a level K, eventually almost surely as n tends to infinity. Under some conditions on the process, it is shown that the recovery level K can grow with n at a specific rate determined by the distribution of the process; thus, the BIC estimator can recover the true context tree to larger and larger depths. The results include for the special case of K being an arbitrary constant that the strong consistency is satisfied without any assumption on the stationary ergodic process, which itself improves the existing results, where either the true context tree was assumed to be of finite depth or the depth of the hypothetical context trees was bounded by o(log n).", "paper_title": "BIC Context Tree Estimation for Stationary Ergodic Processes", "paper_id": "WOS:000291003900053"}