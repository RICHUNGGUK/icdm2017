{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "coreference_resolution"}, {"score": 0.004470539706227421, "phrase": "empirical_evaluation"}, {"score": 0.004296998284839309, "phrase": "main_goal"}, {"score": 0.00419195822011581, "phrase": "comparative_analysis"}, {"score": 0.0040491842732233154, "phrase": "multiple_languages"}, {"score": 0.003577691211998842, "phrase": "system_outputs"}, {"score": 0.0033380605690230655, "phrase": "english"}, {"score": 0.00330509444178479, "phrase": "catalan"}, {"score": 0.0032724970984821127, "phrase": "spanish"}, {"score": 0.0029784342137867776, "phrase": "resolution_algorithms"}, {"score": 0.0027925723953701083, "phrase": "different_conditions"}, {"score": 0.0025289662786567896, "phrase": "general_principles"}, {"score": 0.0024306105794630246, "phrase": "interesting_issues"}, {"score": 0.0021793698531006197, "phrase": "input_annotations"}, {"score": 0.0021049977753042253, "phrase": "scoring_measures"}], "paper_keywords": ["Coreference resolution and evaluation", " NLP system analysis", " Machine learning based NLP tools", " SemEval-2010 (Task 1)", " Discourse entities"], "paper_abstract": "This paper presents an empirical evaluation of coreference resolution that covers several interrelated dimensions. The main goal is to complete the comparative analysis from the SemEval-2010 task on Coreference Resolution in Multiple Languages. To do so, the study restricts the number of languages and systems involved, but extends and deepens the analysis of the system outputs, including a more qualitative discussion. The paper compares three automatic coreference resolution systems for three languages (English, Catalan and Spanish) in four evaluation settings, and using four evaluation measures. Given that our main goal is not to provide a comparison between resolution algorithms, these are merely used as tools to shed light on the different conditions under which coreference resolution is evaluated. Although the dimensions are strongly interdependent, making it very difficult to extract general principles, the study reveals a series of interesting issues in relation to coreference resolution: the portability of systems across languages, the influence of the type and quality of input annotations, and the behavior of the scoring measures.", "paper_title": "Coreference resolution: an empirical study based on SemEval-2010 shared Task 1", "paper_id": "WOS:000323754700005"}