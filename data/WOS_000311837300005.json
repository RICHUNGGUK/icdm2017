{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "neural_networks"}, {"score": 0.004677372885331908, "phrase": "gpu._modern_graphics_cards"}, {"score": 0.004046020290832207, "phrase": "intensive_calculations"}, {"score": 0.0034995881411519925, "phrase": "neural_network_simulations"}, {"score": 0.003161474881435185, "phrase": "parallel_simulation"}, {"score": 0.002855934865505357, "phrase": "large_audience"}, {"score": 0.0023990982005125763, "phrase": "ongoing_efforts"}, {"score": 0.0021049977753042253, "phrase": "main_difficulties"}], "paper_keywords": ["Simulation", " graphics cards", " GPU", " spiking neural networks", " algorithms", " parallel computing"], "paper_abstract": "Modern graphics cards contain hundreds of cores that can be programmed for intensive calculations. They are beginning to be used for spiking neural network simulations. The goal is to make parallel simulation of spiking neural networks available to a large audience, without the requirements of a cluster. We review the ongoing efforts towards this goal, and we outline the main difficulties.", "paper_title": "Simulating spiking neural networks on GPU", "paper_id": "WOS:000311837300005"}