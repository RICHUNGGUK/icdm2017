{"auto_keywords": [{"score": 0.028603173928663867, "phrase": "ica-based_features"}, {"score": 0.00481495049065317, "phrase": "lip_motion_video"}, {"score": 0.004719664411221952, "phrase": "lip-reading_recognition"}, {"score": 0.004595529592539951, "phrase": "lip-motion_features"}, {"score": 0.00450456611645112, "phrase": "multiple_video_frames"}, {"score": 0.004327981760540394, "phrase": "principle_component_analysis"}, {"score": 0.004271133811401192, "phrase": "pca"}, {"score": 0.004186105377259855, "phrase": "independent_component_analysis"}, {"score": 0.003813017794036879, "phrase": "human_perception"}, {"score": 0.0037624955853577786, "phrase": "facial_motion"}, {"score": 0.003449972561293443, "phrase": "invariant_aspects"}, {"score": 0.0032706520949775065, "phrase": "changeable_aspects"}, {"score": 0.00312138530097218, "phrase": "dynamic_video_features"}, {"score": 0.0030799988391729464, "phrase": "multiple_consecutive_frames"}, {"score": 0.0029590932194209826, "phrase": "multiple-frame_features"}, {"score": 0.0027495914857929584, "phrase": "single-frame_static_features"}, {"score": 0.002572001496778222, "phrase": "corresponding_coefficients"}, {"score": 0.002520990102833368, "phrase": "video_representation"}, {"score": 0.002421975107313603, "phrase": "pca-based_features"}, {"score": 0.002265497060260791, "phrase": "nmf-based_features"}], "paper_keywords": [""], "paper_abstract": "The lip-reading recognition is reported with lip-motion features extracted from multiple video frames by three unsupervised learning algorithms, i.e., Principle Component Analysis (PCA), Independent Component Analysis (ICA), and Non-negative Matrix Factorization (NMF). Since the human perception of facial motion goes through two different pathways, i.e., the lateral fusifom gyrus for the invariant aspects and the superior temporal sulcus for the changeable aspects of faces, we extracted the dynamic video features from multiple consecutive frames for the latter. The multiple-frame features require less number of coefficients for the same frame length than the single-frame static features. The ICA-based features are most sparse, while the corresponding coefficients for the video representation are the least sparse. PCA-based features have the opposite characteristics, while the characteristics of the NMF-based features are in the middle. Also the ICA-based features result in much better recognition performance than the others.", "paper_title": "Unsupervised feature extraction for the representation and recognition of lip motion video", "paper_id": "WOS:000240085400078"}