{"auto_keywords": [{"score": 0.025893528386211905, "phrase": "object_predictions"}, {"score": 0.025424528646536156, "phrase": "pixel_labels"}, {"score": 0.00481495049065317, "phrase": "object_instance_inference"}, {"score": 0.004725886853744007, "phrase": "per-exemplar_detectors"}, {"score": 0.004426882270402403, "phrase": "semantic_label"}, {"score": 0.00428451995524549, "phrase": "spatial_extent"}, {"score": 0.0042446888127531945, "phrase": "individual_object_instances"}, {"score": 0.003920674807745575, "phrase": "broad_coverage"}, {"score": 0.003848088904418221, "phrase": "object_categories"}, {"score": 0.0036553070575015344, "phrase": "region-level_features"}, {"score": 0.0036213041338584756, "phrase": "per-exemplar_sliding_window_detectors"}, {"score": 0.003570889780957037, "phrase": "traditional_bounding_box_detectors"}, {"score": 0.0033603864623013733, "phrase": "high_intra-class_variation"}, {"score": 0.0032827577713351336, "phrase": "object_masks"}, {"score": 0.0031919592786945126, "phrase": "test_image"}, {"score": 0.003162252895465901, "phrase": "pixel-level_segmentation"}, {"score": 0.0030747771905143273, "phrase": "per-exemplar_detections"}, {"score": 0.002989714021608139, "phrase": "candidate_object"}, {"score": 0.002722758109991685, "phrase": "valid_overlap_relationships"}, {"score": 0.0026974065918918275, "phrase": "occlusion_ordering"}, {"score": 0.002598333022293788, "phrase": "integer_quadratic_program"}, {"score": 0.002550165781755603, "phrase": "greedy_method"}, {"score": 0.002514625755809045, "phrase": "standard_solver"}, {"score": 0.0022686625017583387, "phrase": "proposed_system"}, {"score": 0.0022475295254231714, "phrase": "promising_results"}, {"score": 0.002195552442011313, "phrase": "labelme_dataset"}], "paper_keywords": ["Image parsing", " Semantic segmentation", " Scene understanding", " Object segmentation"], "paper_abstract": "This paper describes a system for interpreting a scene by assigning a semantic label at every pixel and inferring the spatial extent of individual object instances together with their occlusion relationships. First we present a method for labeling each pixel aimed at achieving broad coverage across hundreds of object categories, many of them sparsely sampled. This method combines region-level features with per-exemplar sliding window detectors. Unlike traditional bounding box detectors, per-exemplar detectors perform well on classes with little training data and high intra-class variation, and they allow object masks to be transferred into the test image for pixel-level segmentation. Next, we use per-exemplar detections to generate a set of candidate object masks for a given test image. We then select a subset of objects that explain the image well and have valid overlap relationships and occlusion ordering. This is done by minimizing an integer quadratic program either using a greedy method or a standard solver. We alternate between using the object predictions to refine the pixel labels and using the pixel labels to improve the object predictions. The proposed system obtains promising results on two challenging subsets of the LabelMe dataset, the largest of which contains 45,676 images and 232 classes.", "paper_title": "Scene Parsing with Object Instance Inference Using Regions and Per-exemplar Detectors", "paper_id": "WOS:000351518500003"}