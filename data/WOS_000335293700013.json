{"auto_keywords": [{"score": 0.02990597071050919, "phrase": "io"}, {"score": 0.014708731686627152, "phrase": "correlated_seismograms"}, {"score": 0.010575609542463168, "phrase": "mapreduce_jobs"}, {"score": 0.004814985888284645, "phrase": "hadoop"}, {"score": 0.00473477283457869, "phrase": "waveform_cross_correlation"}, {"score": 0.0046092435167207095, "phrase": "high-precision_hypocenter_locations"}, {"score": 0.004412285905508977, "phrase": "small_hypocenter_separation_distances"}, {"score": 0.004280861452668641, "phrase": "spotlight_purposes"}, {"score": 0.004139401327448807, "phrase": "large_numbers"}, {"score": 0.00398916666053909, "phrase": "next-generation_pipelines"}, {"score": 0.003909522412849035, "phrase": "core_part"}, {"score": 0.003717273538121102, "phrase": "correlated_seismic_events"}, {"score": 0.00363080961099728, "phrase": "global_dataset"}, {"score": 0.003510754567808717, "phrase": "conventional_distributed_cluster"}, {"score": 0.003195236629209403, "phrase": "hadoop_cluster"}, {"score": 0.003058515297281172, "phrase": "test_dataset"}, {"score": 0.00300749708357049, "phrase": "fundamental_algorithmic_transformations"}, {"score": 0.0029473940028924748, "phrase": "maximum_performance_increase"}, {"score": 0.0028982239829450198, "phrase": "original_io-bound_implementation"}, {"score": 0.0028498718992429825, "phrase": "great_lengths"}, {"score": 0.002783527398566117, "phrase": "hadoop_implementation"}, {"score": 0.0026111116934081284, "phrase": "tiered_series"}, {"score": 0.0022898630573629144, "phrase": "fine-grained_computations"}, {"score": 0.0021844290159501313, "phrase": "large_performance_gain"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Correlation", " Hadoop", " MapReduce", " Seismology"], "paper_abstract": "In seismology, waveform cross correlation has been used for years to produce high-precision hypocenter locations and for sensitive detectors. Because correlated seismograms generally are found only at small hypocenter separation distances, correlation detectors have historically been reserved for spotlight purposes. However, many regions have been found to produce large numbers of correlated seismograms, and there is growing interest in building next-generation pipelines that employ correlation as a core part of their operation. In an effort to better understand the distribution and behavior of correlated seismic events, we have cross correlated a global dataset consisting of over 300 million seismograms. This was done using a conventional distributed cluster, and required 42 days. In anticipation of processing much larger datasets, we have re-architected the system to run as a series of MapReduce jobs on a Hadoop cluster. In doing so we achieved a factor of 19 performance increase on a test dataset. We found that fundamental algorithmic transformations were required to achieve the maximum performance increase. Whereas in the original IO-bound implementation, we went to great lengths to minimize IO, in the Hadoop implementation where IO is cheap, we were able to greatly increase the parallelism of our algorithms by performing a tiered series of very fine-grained (highly parallelizable) transformations on the data. Each of these MapReduce jobs required reading and writing large amounts of data. But, because IO is very fast, and because the fine-grained computations could be handled extremely quickly by the mappers, the net was a large performance gain. (C) 2014 The Authors. Published by Elsevier Ltd.", "paper_title": "Large-scale seismic signal analysis with Hadoop", "paper_id": "WOS:000335293700013"}