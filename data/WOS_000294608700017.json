{"auto_keywords": [{"score": 0.04478831236984077, "phrase": "'narrow'_computations"}, {"score": 0.030604822686408243, "phrase": "gpp"}, {"score": 0.00481495049065317, "phrase": "speculatively_prune_useless_narrow_computations"}, {"score": 0.004676575291629554, "phrase": "unique_hardware-software_collaborative_strategy"}, {"score": 0.0043477114072437316, "phrase": "low_power_execution_platform"}, {"score": 0.004161553532799662, "phrase": "strictly_narrow_bit-wide_microarchitecture"}, {"score": 0.003906586074865932, "phrase": "low_cost"}, {"score": 0.00386876598761639, "phrase": "low_hardware_complexity"}, {"score": 0.003831310632470526, "phrase": "low_power_execution_engine"}, {"score": 0.003409057326528229, "phrase": "optimization_technique"}, {"score": 0.003359647377874098, "phrase": "global_productiveness_propagation"}, {"score": 0.003092842645798083, "phrase": "narrow_computations"}, {"score": 0.0028333356794133053, "phrase": "static_backward_slices"}, {"score": 0.0028058765785670546, "phrase": "selected_narrow_computations"}, {"score": 0.0025207920578878894, "phrase": "speculative_optimization_technique"}, {"score": 0.002366110899738696, "phrase": "finer_granularity"}, {"score": 0.0022101055924375725, "phrase": "narrow_bit-wide_execution_core"}, {"score": 0.0021674482571326283, "phrase": "average_dynamic_instruction_stream_reduction"}, {"score": 0.0021049977753042253, "phrase": "overall_performance"}], "paper_keywords": ["Algorithms", " Performance", " Narrow Bitwide Computations", " Profile-guided Optimizations"], "paper_abstract": "This paper proposes a unique hardware-software collaborative strategy to remove useless work at 16-bit data-width granularity. The underlying motivation is to design a low power execution platform by exploiting 'narrow' computations. The proposal uses a strictly narrow bit-wide microarchitecture (16-bit integer datapath), which realizes the goal of a low cost, low hardware complexity, low power execution engine. Software dynamically maps the 64-bit computations by translating them into an equivalent 16-bit instruction stream and optimizing them. In this paper, we propose an optimization technique, called Global Productiveness Propagation (GPP), which is a dynamic, profile-based optimization technique that infers the minimum required dataflow by pruning narrow computations that are mostprobably useless (non-productive). More precisely, GPP speculatively prunes the static backward slices of selected narrow computations: computations that result in the same value (in their respective storage location) as that at the input of the region. This speculative optimization technique is formulated around the concept of 'narrow' computations because the same allow a finer granularity to distinguish between useful (productive) and useless (nonproductive) work. GPP has been evaluated on an in-order narrow bit-wide execution core, achieving an average dynamic instruction stream reduction of 6.6%, while improving overall performance by 4.2%", "paper_title": "Global Productiveness Propagation: A Code Optimization Technique to Speculatively Prune Useless Narrow Computations", "paper_id": "WOS:000294608700017"}