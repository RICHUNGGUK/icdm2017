{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "hidden_markov_models"}, {"score": 0.004658426838467567, "phrase": "logical_hidden_markov_models"}, {"score": 0.00428892403807229, "phrase": "traditional_hidden_markov_models"}, {"score": 0.0038838500580958744, "phrase": "structured_symbols"}, {"score": 0.0035755653799043, "phrase": "logical_atoms"}, {"score": 0.0033465923623290034, "phrase": "flat_characters"}, {"score": 0.0021049977753042253, "phrase": "resulting_representation"}], "paper_keywords": [""], "paper_abstract": "Logical hidden Markov models (LOHMMs) upgrade traditional hidden Markov models to deal with sequences of structured symbols in the form of logical atoms, rather than flat characters. This note formally introduces LOHMMs and presents solutions to the three central inference problems for LOHMMs: evaluation, most likely hidden state sequence and parameter estimation. The resulting representation and algorithms are experimentally evaluated on problems from the domain of bioinformatics.", "paper_title": "Logical hidden Markov models", "paper_id": "WOS:000236920600001"}