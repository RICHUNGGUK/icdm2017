{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "parallel_mcmc_sampling"}, {"score": 0.004757017456572827, "phrase": "big-data_bayesian_analytics"}, {"score": 0.004685575787741084, "phrase": "sequential_nature"}, {"score": 0.004657299036322549, "phrase": "estimation_techniques"}, {"score": 0.00462919213721188, "phrase": "bayesian_methods"}, {"score": 0.004573483858954342, "phrase": "machine_learning"}, {"score": 0.004491170257043608, "phrase": "big_data_analytics"}, {"score": 0.004410331572207815, "phrase": "potential_opportunities"}, {"score": 0.00438370856272802, "phrase": "parallelize_techniques"}, {"score": 0.004344073762982718, "phrase": "monte_carlo_markov_chain"}, {"score": 0.004214516848083075, "phrase": "general_strategies"}, {"score": 0.004151188559520802, "phrase": "modern_cpus"}, {"score": 0.003978866233891427, "phrase": "single-instruction_multiple-data"}, {"score": 0.003907212558276185, "phrase": "mcmc_sampling"}, {"score": 0.003883614784513501, "phrase": "probabilistic_graphical_models"}, {"score": 0.0038252396052150354, "phrase": "exchangeable_models"}, {"score": 0.003767738552860633, "phrase": "bayesian_generalized_linear_models"}, {"score": 0.003711098637056057, "phrase": "child-node_contributions"}, {"score": 0.003677522700365517, "phrase": "conditional_posterior"}, {"score": 0.0035677736570659813, "phrase": "undirected_graphs"}, {"score": 0.003546218640291191, "phrase": "discrete-value_nodes"}, {"score": 0.003492897128445075, "phrase": "conditionally-independent_nodes"}, {"score": 0.0034299649219748513, "phrase": "simd_form"}, {"score": 0.0034092396400930446, "phrase": "high-performance_libraries"}, {"score": 0.0033681627448832996, "phrase": "vectorization_capabilities"}, {"score": 0.0032775342939895358, "phrase": "decent_speedup"}, {"score": 0.0032184697893776052, "phrase": "high-level_source-code"}, {"score": 0.003141364320497748, "phrase": "parallelization_overhead"}, {"score": 0.0031129269142224194, "phrase": "data_locality"}, {"score": 0.0030941113607985205, "phrase": "non-uniform_memory_access_architectures"}, {"score": 0.0030661003993462665, "phrase": "big-data_bayesian_glm_graphs"}, {"score": 0.002876976753279887, "phrase": "naive_implementation"}, {"score": 0.002816556934231128, "phrase": "multi-threaded_intel_mkl_blas"}, {"score": 0.002765776659294382, "phrase": "striking_distance"}, {"score": 0.0027407299369891502, "phrase": "memory-bandwidth-induced_hardware_limit"}, {"score": 0.002532919466975052, "phrase": "modern_predictive_analytics"}, {"score": 0.002502374576203785, "phrase": "hierarchical_bayesian_glm"}, {"score": 0.002487240194265389, "phrase": "variable_selection"}, {"score": 0.002464709648714996, "phrase": "ensemble_regression"}, {"score": 0.002427610261739265, "phrase": "proposed_optimization_strategies"}, {"score": 0.002333738303480471, "phrase": "vector_units"}, {"score": 0.002305589818994465, "phrase": "many-core_simd_processors"}, {"score": 0.0022847009758393405, "phrase": "intel_xeon_phi"}, {"score": 0.002270880088524628, "phrase": "graphic_processing_units"}, {"score": 0.0022231606165229235, "phrase": "energy_efficiency"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["GPU", " Hierarchical Bayesian", " Intel Xeon Phi", " Logistic regression", " OpenMP", " Vectorization"], "paper_abstract": "Computational intensity and sequential nature of estimation techniques for Bayesian methods in statistics and machine learning, combined with their increasing applications for big data analytics, necessitate both the identification of potential opportunities to parallelize techniques such as Monte Carlo Markov Chain (MCMC) sampling, and the development of general strategies for mapping such parallel algorithms to modern CPUs in order to elicit the performance up the compute-based and/or memory-based hardware limits. Two opportunities for Single-Instruction Multiple-Data (SIMD) parallelization of MCMC sampling for probabilistic graphical models are presented. In exchangeable models with many observations such as Bayesian Generalized Linear Models (GLMs), child-node contributions to the conditional posterior of each node can be calculated concurrently. In undirected graphs with discrete-value nodes, concurrent sampling of conditionally-independent nodes can be transformed into a SIMD form. High-performance libraries with multi-threading and vectorization capabilities can be readily applied to such SIMD opportunities to gain decent speedup, while a series of high-level source-code and runtime modifications provide further performance boost by reducing parallelization overhead and increasing data locality for Non-Uniform Memory Access architectures. For big-data Bayesian GLM graphs, the end-result is a routine for evaluating the conditional posterior and its gradient vector that is 5 times faster than a naive implementation using (built-in) multi-threaded Intel MKL BLAS, and reaches within the striking distance of the memory-bandwidth-induced hardware limit. Using multi-threading for cache-friendly, fine-grained parallelization can outperform coarse-grained alternatives which are often less cache-friendly, a likely scenario in modern predictive analytics workflow such as Hierarchical Bayesian GLM, variable selection, and ensemble regression and classification. The proposed optimization strategies improve the scaling of performance with number of cores and width of vector units (applicable to many-core SIMD processors such as Intel Xeon Phi and Graphic Processing Units), resulting in cost-effectiveness, energy efficiency ('green computing'), and higher speed on multi-core x86 processors. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "SIMD parallel MCMC sampling with applications for big-data Bayesian analytics", "paper_id": "WOS:000353734300006"}