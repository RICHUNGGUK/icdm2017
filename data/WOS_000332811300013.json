{"auto_keywords": [{"score": 0.04015238390925852, "phrase": "ann"}, {"score": 0.03916484252588739, "phrase": "fsm"}, {"score": 0.033589423986078615, "phrase": "state_changes"}, {"score": 0.03325731973057104, "phrase": "afsm"}, {"score": 0.02591531381035994, "phrase": "proposed_approach"}, {"score": 0.02578587361337967, "phrase": "different_situations"}, {"score": 0.00481495049065317, "phrase": "original_approach"}, {"score": 0.004778145748896516, "phrase": "autonomous_mobile_robots"}, {"score": 0.0046813628851623676, "phrase": "topological_map"}, {"score": 0.004633705657623413, "phrase": "proposed_afsm"}, {"score": 0.00436890075128947, "phrase": "possible_path"}, {"score": 0.004247635679434271, "phrase": "fsm-finite_state_machine"}, {"score": 0.004087658051566714, "phrase": "input_data"}, {"score": 0.004004804955715663, "phrase": "specific_environment_features"}, {"score": 0.0039035886767440453, "phrase": "fsm."}, {"score": 0.0038737214010638745, "phrase": "new_input_pattern"}, {"score": 0.0037854836033989403, "phrase": "current_context"}, {"score": 0.003680352247048994, "phrase": "next_state"}, {"score": 0.0036149702980441054, "phrase": "input_features"}, {"score": 0.0035781301369981573, "phrase": "specific_local_properties"}, {"score": 0.0035145577714492024, "phrase": "sensors_data"}, {"score": 0.0032965644170009425, "phrase": "previously_trained_ann"}, {"score": 0.003246283817099847, "phrase": "key_component"}, {"score": 0.003204967757638859, "phrase": "present_state"}, {"score": 0.0030061190511899475, "phrase": "mobile_robot"}, {"score": 0.002870610281308612, "phrase": "adequate_local_reactive_behavior"}, {"score": 0.0028486252355914084, "phrase": "current_state"}, {"score": 0.0025253196950911177, "phrase": "complex_set"}, {"score": 0.002411431807017313, "phrase": "sensors_configurations"}, {"score": 0.0023624736905605535, "phrase": "indoor_and_outdoor_environments"}, {"score": 0.002320449502337321, "phrase": "kinect_sensor"}, {"score": 0.0023085801607267897, "phrase": "indoor_environments"}, {"score": 0.0022559132878182155, "phrase": "standard_rgb_camera"}, {"score": 0.0022443733130746305, "phrase": "urban_roads_environments"}, {"score": 0.0022271736946235703, "phrase": "proposed_method"}, {"score": 0.002159680409416879, "phrase": "promising_approach"}, {"score": 0.002148631647473042, "phrase": "autonomous_mobile_robots_control"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Mobile robotics", " Autonomous navigation", " Kinect", " Artificial neural networks", " Finite state machines"], "paper_abstract": "In this paper we present an original approach applied to autonomous mobile robots navigation integrating localization and navigation using a topological map based on the proposed AFSM (adaptive finite state machine) technique. In this approach, the environment is mapped as a graph, and each possible path is represented by a sequence of states controlled by a FSM-finite state machine. An ANN (artificial neural network) is trained to recognize patterns on input data, where each pattern is associated to specific environment features or properties, consequently representing the present context/state of the FSM. When a new input pattern is recognized by the ANN (changing the current context), this allows the FSM to change to the next state and its associated action/behavior. The input features are related to specific local properties of the environment (obtained from sensors data), as for example, straight path, right and left turns, and intersections. This way, the FSM is integrated to a previously trained ANN, which acts as a key component recognizing and indicating the present state and the state changes, allowing the AFSM to select the current/correct action (local reactive behaviors) for each situation. The AFSM allows the mobile robot to autonomously follow a sequence of states/behaviors in order to reach a destination, first choosing an adequate local reactive behavior for each current state, and second detecting the changes in the current context/state, following a sequence of states/actions that codes the topological (global) path into the FSM (sequence of states/actions). The ANN is also a very important component of this system, since it can be trained/adapted to recognize a complex set of situations and state changes. In order to demonstrate the robustness of the proposed approach to different situations and sensors configurations, we evaluated the proposed approach for both indoor and outdoor environments, using a Pioneer P3-AT robot equipped with Kinect sensor for indoor environments, and an automated vehicle equipped with a standard RGB camera for urban roads environments. The proposed method was tested in different situations with success and demonstrated to be a promising approach to autonomous mobile robots control and navigation. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Adaptive finite state machine based visual autonomous navigation system", "paper_id": "WOS:000332811300013"}