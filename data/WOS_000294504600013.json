{"auto_keywords": [{"score": 0.041943707584810794, "phrase": "human_body"}, {"score": 0.00481495049065317, "phrase": "global_motion_features"}, {"score": 0.0047026237903774895, "phrase": "novel_computer_vision_approach"}, {"score": 0.004647442352794694, "phrase": "video_sequences"}, {"score": 0.00443308765153716, "phrase": "human_motion"}, {"score": 0.004398331355940011, "phrase": "different_information"}, {"score": 0.0042119653427658025, "phrase": "motion_information"}, {"score": 0.004178935413340453, "phrase": "human_joints"}, {"score": 0.00404937519538515, "phrase": "boundary_motion"}, {"score": 0.003939296259436904, "phrase": "binary_and_gray-level_images"}, {"score": 0.0038624981944755813, "phrase": "human_movements"}, {"score": 0.003742711659195878, "phrase": "different_kinds"}, {"score": 0.0036553070575015344, "phrase": "global_motion"}, {"score": 0.0035141291835319682, "phrase": "fusion_model"}, {"score": 0.0033651019362620866, "phrase": "segmented_frames"}, {"score": 0.003286486670483032, "phrase": "distinct_class"}, {"score": 0.0031100973266506163, "phrase": "background_extraction"}, {"score": 0.003073545175760353, "phrase": "gaussian_mixture_model"}, {"score": 0.002943147037670826, "phrase": "wavelet_transform"}, {"score": 0.002851790448644913, "phrase": "principal_component_analysis"}, {"score": 0.0028297072750103356, "phrase": "pca"}, {"score": 0.002752390133272192, "phrase": "motion_information_capture"}, {"score": 0.0027200443140323032, "phrase": "silhouette"}, {"score": 0.0025841336988141235, "phrase": "grey_level_variations"}, {"score": 0.0025537472239953807, "phrase": "silhouette-binary-wavelet_model"}, {"score": 0.002474447780553576, "phrase": "binary_information"}, {"score": 0.002445347925313158, "phrase": "silhouette-edge-binary_model"}, {"score": 0.0023694065215394593, "phrase": "edge_information"}, {"score": 0.0023415390666563177, "phrase": "silhouette_skeleton_wavelet_model"}, {"score": 0.0022688141624966967, "phrase": "skeleton_movement"}, {"score": 0.002242127152093798, "phrase": "classification_rates"}, {"score": 0.002146926767291475, "phrase": "new_proposed_fusion_technique"}, {"score": 0.0021049977753042253, "phrase": "excellent_performance"}], "paper_keywords": ["Human gait", " Gait recognition", " Gait analysis", " Biometry", " Fusion of characteristics", " Global motion"], "paper_abstract": "This paper proposes a novel computer vision approach that processes video sequences of people walking and then recognises those people by their gait. Human motion carries different information that can be analysed in various ways. The skeleton carries motion information about human joints, and the silhouette carries information about boundary motion of the human body. Moreover, binary and gray-level images contain different information about human movements. This work proposes to recover these different kinds of information to interpret the global motion of the human body based on four different segmented image models, using a fusion model to improve classification. Our proposed method considers the set of the segmented frames of each individual as a distinct class and each frame as an object of this class. The methodology applies background extraction using the Gaussian Mixture Model (GMM), a scale reduction based on the Wavelet Transform (WT) and feature extraction by Principal Component Analysis (PCA). We propose four new schemas for motion information capture: the Silhouette-Gray-Wavelet model (SGW) captures motion based on grey level variations; the Silhouette-Binary-Wavelet model (SBW) captures motion based on binary information; the Silhouette-Edge-Binary model (SEW) captures motion based on edge information and the Silhouette Skeleton Wavelet model (SSW) captures motion based on skeleton movement. The classification rates obtained separately from these four different models are then merged using a new proposed fusion technique. The results suggest excellent performance in terms of recognising people by their gait.", "paper_title": "Human gait recognition using extraction and fusion of global motion features", "paper_id": "WOS:000294504600013"}