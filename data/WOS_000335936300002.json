{"auto_keywords": [{"score": 0.049512022618515686, "phrase": "bipartite_heterogeneous_network"}, {"score": 0.046238615936730884, "phrase": "text_collections"}, {"score": 0.018444082716038354, "phrase": "text_collection"}, {"score": 0.010612387000973441, "phrase": "text_classification"}, {"score": 0.005977477738603898, "phrase": "classification_model"}, {"score": 0.004682917599491709, "phrase": "numeric_data_classification"}, {"score": 0.004518442937844318, "phrase": "vector_space_model"}, {"score": 0.004240116703465252, "phrase": "high_dimensionality"}, {"score": 0.004140203942496321, "phrase": "general-purpose_classifiers"}, {"score": 0.003947358102140903, "phrase": "high_sparsity"}, {"score": 0.0038696708318671446, "phrase": "different_objects"}, {"score": 0.003674738405118697, "phrase": "classification_results"}, {"score": 0.0036023971109946946, "phrase": "simplest_ways"}, {"score": 0.003559675269411366, "phrase": "textual_collections"}, {"score": 0.0032099453192629976, "phrase": "heterogeneous_bipartite_networks"}, {"score": 0.002837451022172113, "phrase": "bipartite_heterogeneous_networks"}, {"score": 0.0027485326424697095, "phrase": "text_classifier"}, {"score": 0.0022977342663599042, "phrase": "empirical_evaluation"}, {"score": 0.002270449532546444, "phrase": "large_amount"}, {"score": 0.0022345720876241044, "phrase": "different_domains"}, {"score": 0.0021992603252793995, "phrase": "proposed_imbhn_algorithm"}, {"score": 0.002181813794658713, "phrase": "significantly_better_results"}, {"score": 0.0021049977753042253, "phrase": "naive_bayes_algorithms"}], "paper_keywords": ["heterogeneous network", " text classification", " inductive model generation"], "paper_abstract": "Algorithms for numeric data classification have been applied for text classification. Usually the vector space model is used to represent text collections. The characteristics of this representation such as sparsity and high dimensionality sometimes impair the quality of general-purpose classifiers. Networks can be used to represent text collections, avoiding the high sparsity and allowing to model relationships among different objects that compose a text collection. Such network-based representations can improve the quality of the classification results. One of the simplest ways to represent textual collections by a network is through a bipartite heterogeneous network, which is composed of objects that represent the documents connected to objects that represent the terms. Heterogeneous bipartite networks do not require computation of similarities or relations among the objects and can be used to model any type of text collection. Due to the advantages of representing text collections through bipartite heterogeneous networks, in this article we present a text classifier which builds a classification model using the structure of a bipartite heterogeneous network. Such an algorithm, referred to as IMBHN (Inductive Model Based on Bipartite Heterogeneous Network), induces a classification model assigning weights to objects that represent the terms for each class of the text collection. An empirical evaluation using a large amount of text collections from different domains shows that the proposed IMBHN algorithm produces significantly better results than k-NN, C4.5, SVM, and Naive Bayes algorithms.", "paper_title": "Inductive Model Generation for Text Classification Using a Bipartite Heterogeneous Network", "paper_id": "WOS:000335936300002"}