{"auto_keywords": [{"score": 0.04929460594219637, "phrase": "conflict_misses"}, {"score": 0.00481495049065317, "phrase": "adaptive_selection_of"}, {"score": 0.004795102350075197, "phrase": "cache_indexing_bits"}, {"score": 0.0046392209103157936, "phrase": "cache_memories"}, {"score": 0.0045820747375409435, "phrase": "crucial_part"}, {"score": 0.004525629293824217, "phrase": "design_cycle"}, {"score": 0.00446987606516801, "phrase": "modern_processor"}, {"score": 0.0043066860455264, "phrase": "performance_gap"}, {"score": 0.004098291340525772, "phrase": "low_degrees"}, {"score": 0.004014452814186653, "phrase": "large_amount"}, {"score": 0.0038678251731669865, "phrase": "significant_fraction"}, {"score": 0.003680587852807675, "phrase": "high_cost"}, {"score": 0.0033883824438527316, "phrase": "high_number"}, {"score": 0.0033190180867511605, "phrase": "low-associative_caches"}, {"score": 0.0032510690712452147, "phrase": "indexing_policy"}, {"score": 0.0031452231581533814, "phrase": "block_address"}, {"score": 0.003042812778470762, "phrase": "basic_premise"}, {"score": 0.0029194625087935345, "phrase": "set_usage"}, {"score": 0.0028596699752849682, "phrase": "poor_selection"}, {"score": 0.0028243822059448266, "phrase": "indexing_bits"}, {"score": 0.0027437235598539904, "phrase": "run_time"}, {"score": 0.0026107601878587816, "phrase": "available_sets"}, {"score": 0.0025785359740308337, "phrase": "large_fraction"}, {"score": 0.002393353846080347, "phrase": "ipc_improvements"}, {"score": 0.0022122603123901114, "phrase": "energy_consumption"}, {"score": 0.002184943946549964, "phrase": "cache_hierarchy"}, {"score": 0.0021049977753042253, "phrase": "negligible_area"}], "paper_keywords": ["Cache memories", " conflict misses", " adaptive indexing", " working set variations"], "paper_abstract": "The design of cache memories is a crucial part of the design cycle of a modern processor, since they are able to bridge the performance gap between the processor and the memory. Unfortunately, caches with low degrees of associativity suffer a large amount of conflict misses. Although by increasing their associativity a significant fraction of these misses can be removed, this comes at a high cost in both power, area, and access time. In this work, we address the problem of high number of conflict misses in low-associative caches, by proposing an indexing policy that adaptively selects the bits from the block address used to index the cache. The basic premise of this work is that the non-uniformity in the set usage is caused by a poor selection of the indexing bits. Instead, by selecting at run time those bits that disperse the working set more evenly across the available sets, a large fraction of the conflict misses (85 percent, on average) can be removed. This leads to IPC improvements of 10.9 percent for the SPEC CPU2006 benchmark suite. By having less accesses in the L2 cache, our proposal also reduces the energy consumption of the cache hierarchy by 13.2 percent. These benefits come with a negligible area overhead.", "paper_title": "Adaptive Selection of Cache Indexing Bits for Removing Conflict Misses", "paper_id": "WOS:000354414500003"}