{"auto_keywords": [{"score": 0.04022673782342742, "phrase": "large_scale-change"}, {"score": 0.00481495049065317, "phrase": "invariant_auto-context"}, {"score": 0.0046860651740695996, "phrase": "labeling"}, {"score": 0.004610058444728656, "phrase": "complicated_environment"}, {"score": 0.00456020621016909, "phrase": "context_information"}, {"score": 0.004486432283770142, "phrase": "important_role"}, {"score": 0.004342430078306461, "phrase": "recently_proposed_auto-context_algorithm"}, {"score": 0.004225950334493496, "phrase": "effective_context-based_methods"}, {"score": 0.004112582094962078, "phrase": "standard_auto-context_approach"}, {"score": 0.003958937342925219, "phrase": "fixed_radius_sequence"}, {"score": 0.0036091892088392775, "phrase": "scale_invariant_auto-context"}, {"score": 0.003570121882499456, "phrase": "siac"}, {"score": 0.0034554281349858836, "phrase": "improved_version"}, {"score": 0.003399466007862412, "phrase": "auto-context_algorithm"}, {"score": 0.003167217223469026, "phrase": "optimal_scale"}, {"score": 0.0030654278282822027, "phrase": "iterative_way"}, {"score": 0.002999386721353559, "phrase": "corresponding_optimal_radius_sequence"}, {"score": 0.002966900048034132, "phrase": "context_location_sampling"}, {"score": 0.0027641218567092665, "phrase": "proposed_siac_algorithm"}, {"score": 0.0026898636962522505, "phrase": "current_classification_map"}, {"score": 0.002631892325004253, "phrase": "image_scale"}, {"score": 0.002575167114383286, "phrase": "corresponding_radius_sequence"}, {"score": 0.0024923577071656014, "phrase": "context_locations"}, {"score": 0.0023990982005125763, "phrase": "classification_maps"}, {"score": 0.0023219374444738723, "phrase": "image_scales"}, {"score": 0.0022228943786652914, "phrase": "siac_algorithm"}, {"score": 0.0021049977753042253, "phrase": "standard_auto-context_algorithm"}], "paper_keywords": ["Image segmentation", " image labeling", " context information", " auto-context", " scale invariance"], "paper_abstract": "In complicated environment, context information plays an important role in image segmentation/labeling. The recently proposed auto-context algorithm is one of the effective context-based methods. However, the standard auto-context approach samples the context locations utilizing a fixed radius sequence, which is sensitive to large scale-change of objects. In this paper, we present a scale invariant auto-context (SIAC) algorithm which is an improved version of the auto-context algorithm. In order to achieve scale-invariance, we try to approximate the optimal scale for the image in an iterative way and adopt the corresponding optimal radius sequence for context location sampling, both in training and testing. In each iteration of the proposed SIAC algorithm, we use the current classification map to estimate the image scale, and the corresponding radius sequence is then used for choosing context locations. The algorithm iteratively updates the classification maps, as well as the image scales, until convergence. We demonstrate the SIAC algorithm on several image segmentation/labeling tasks. The results demonstrate improvement over the standard auto-context algorithm when large scale-change of objects exists.", "paper_title": "Scale Invariant Auto-context for Object Segmentation and Labeling", "paper_id": "WOS:000345333200018"}