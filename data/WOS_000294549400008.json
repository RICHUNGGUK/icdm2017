{"auto_keywords": [{"score": 0.03644451033122438, "phrase": "gaussian"}, {"score": 0.00481495049065317, "phrase": "echo_state_gaussian_process"}, {"score": 0.00476697427418509, "phrase": "echo_state_networks"}, {"score": 0.004625881588444304, "phrase": "novel_approach"}, {"score": 0.004579780586951551, "phrase": "recurrent_neural_network"}, {"score": 0.004534206940036242, "phrase": "rnn"}, {"score": 0.004081385289516914, "phrase": "simple_computationally_efficient_algorithm"}, {"score": 0.003940706575253453, "phrase": "practical_application"}, {"score": 0.0038431888954930083, "phrase": "classical_approaches"}, {"score": 0.0037480753312398754, "phrase": "benchmark_tasks"}, {"score": 0.0035827424231607784, "phrase": "novel_bayesian_approach"}, {"score": 0.003339886795391701, "phrase": "esgp"}, {"score": 0.003113441660343867, "phrase": "conventional_reservoir_computing_networks"}, {"score": 0.0029611289031152856, "phrase": "generated_predictions"}, {"score": 0.002858952758523772, "phrase": "predictive_distribution"}, {"score": 0.0026252106881752067, "phrase": "benchmark_datasets"}, {"score": 0.0025989960809479104, "phrase": "real-world_applications"}, {"score": 0.0024842242921857705, "phrase": "significant_enhancement"}, {"score": 0.002447101794397243, "phrase": "dynamical_data_modeling_capabilities"}, {"score": 0.0022133711375320244, "phrase": "existing_gaussian_process-based_methods"}, {"score": 0.0021049977753042253, "phrase": "obtained_predictive_performance"}], "paper_keywords": ["Bayesian inference", " Gaussian process", " reservoir computing", " sequential data modeling"], "paper_abstract": "Echo state networks (ESNs) constitute a novel approach to recurrent neural network (RNN) training, with an RNN (the reservoir) being generated randomly, and only a readout being trained using a simple computationally efficient algorithm. ESNs have greatly facilitated the practical application of RNNs, outperforming classical approaches on a number of benchmark tasks. In this paper, we introduce a novel Bayesian approach toward ESNs, the echo state Gaussian process (ESGP). The ESGP combines the merits of ESNs and Gaussian processes to provide a more robust alternative to conventional reservoir computing networks while also offering a measure of confidence on the generated predictions (in the form of a predictive distribution). We exhibit the merits of our approach in a number of applications, considering both benchmark datasets and real-world applications, where we show that our method offers a significant enhancement in the dynamical data modeling capabilities of ESNs. Additionally, we also show that our method is orders of magnitude more computationally efficient compared to existing Gaussian process-based methods for dynamical data modeling, without compromises in the obtained predictive performance.", "paper_title": "Echo State Gaussian Process", "paper_id": "WOS:000294549400008"}