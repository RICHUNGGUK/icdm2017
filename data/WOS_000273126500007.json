{"auto_keywords": [{"score": 0.028906609734183148, "phrase": "support_vectors"}, {"score": 0.0045302298105691615, "phrase": "nu-support_vector_machines"}, {"score": 0.003929391999210588, "phrase": "arbitrary_shape"}, {"score": 0.003272083495778595, "phrase": "input_value"}, {"score": 0.0031845067058084583, "phrase": "previous_nu-svm"}, {"score": 0.0031203609829058587, "phrase": "proposed_support_vector_algorithms"}, {"score": 0.0025456716198597627, "phrase": "upper_bound"}, {"score": 0.0024607296642187846, "phrase": "training_errors"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Support vector machines (SVMs)", " Regression estimation", " Classification", " Heteroscedastic noise model", " Parametric-insensitive model", " Parametric-margin model"], "paper_abstract": "In this paper, a modification of nu-support vector machines (nu-SVM) for regression and classification is described, and the use of a parametric insensitive/margin model with an arbitrary shape is demonstrated. This can be useful in many cases, especially when the noise is heteroscedastic, that is, the noise strongly depends on the input value x. Like the previous nu-SVM, the proposed support vector algorithms have the advantage of using the parameter 0 <= nu <= 1 for controlling the number of support vectors. To be more precise, v is an upper bound on the fraction of training errors and a lower bound on the fraction of support vectors. The algorithms are analyzed theoretically and experimentally. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "New support vector algorithms with parametric insensitive/margin model", "paper_id": "WOS:000273126500007"}