{"auto_keywords": [{"score": 0.02722899152521005, "phrase": "d-tlb_misses"}, {"score": 0.00481495049065317, "phrase": "tlb_improvements_for_chip_multiprocessors"}, {"score": 0.004774937143916685, "phrase": "inter-core_cooperative_prefetchers"}, {"score": 0.004618166136069052, "phrase": "translation_lookaside_buffers"}, {"score": 0.004485200522202792, "phrase": "overall_system_performance"}, {"score": 0.004392565073466714, "phrase": "uniprocessor_tlbs"}, {"score": 0.0039737570920809215, "phrase": "thorough_tlb_performance_evaluation"}, {"score": 0.003940706575253453, "phrase": "sequential_and_parallel_benchmarks"}, {"score": 0.0038271712887391015, "phrase": "hardware_performance_counters"}, {"score": 0.003670608022642996, "phrase": "tlb_hit_rates"}, {"score": 0.003447649979671398, "phrase": "tlb"}, {"score": 0.003404703106153948, "phrase": "significantly_higher_miss_rate"}, {"score": 0.0032246835734680377, "phrase": "characterization_data"}, {"score": 0.0031317126905234145, "phrase": "inter-core_cooperative"}, {"score": 0.003105659032769289, "phrase": "icc"}, {"score": 0.0030797912111959137, "phrase": "tlb_prefetchers"}, {"score": 0.0028446460307503343, "phrase": "icc_prefetchers"}, {"score": 0.0027741761880779535, "phrase": "data_tlb"}, {"score": 0.002682917193736698, "phrase": "parallel_workloads"}, {"score": 0.0026055251533586804, "phrase": "sll_tlbs"}, {"score": 0.002447101794397243, "phrase": "multiprogrammed_sequential_workloads"}, {"score": 0.0023566987138026285, "phrase": "hit_rates"}, {"score": 0.0021766418372878835, "phrase": "even_more_modest_hardware_requirements"}, {"score": 0.00212268510072928, "phrase": "parallel_applications"}], "paper_keywords": ["Design", " Experimentation", " Measurement", " Performance", " Translation lookaside buffer", " shared last-level TLB", " TLB prefetching", " simulation", " performance evaluation"], "paper_abstract": "Translation Lookaside Buffers (TLBs) are critical to overall system performance. Much past research has addressed uniprocessor TLBs, lowering access times and miss rates. However, as Chip MultiProcessors (CMPs) become ubiquitous, TLB design and performance must be reevaluated. Our article begins by performing a thorough TLB performance evaluation of sequential and parallel benchmarks running on a real-world, modern CMP system using hardware performance counters. This analysis demonstrates the need for further improvement of TLB hit rates for both classes of application, and it also points out that the data TLB has a significantly higher miss rate than the instruction TLB in both cases. In response to the characterization data, we propose and evaluate both Inter-Core Cooperative (ICC) TLB prefetchers and Shared Last-Level (SLL) TLBs as alternatives to the commercial norm of private, per-core L2 TLBs. ICC prefetchers eliminate 19% to 90% of Data TLB (D-TLB) misses across parallel workloads while requiring only modest changes in hardware. SLL TLBs eliminate 7% to 79% of D-TLB misses for parallel workloads and 35% to 95% of D-TLB misses for multiprogrammed sequential workloads. This corresponds to 27% and 21% increases in hit rates as compared to private, per-core L2 TLBs, respectively, and is achieved this using even more modest hardware requirements. Because of their benefits for parallel applications, their applicability to sequential workloads, and their readily implementable hardware, SLL TLBs and ICC TLB prefetchers hold great promise for CMPs.", "paper_title": "TLB Improvements for Chip Multiprocessors: Inter-Core Cooperative Prefetchers and Shared Last-Level TLBs", "paper_id": "WOS:000317426900002"}