{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "reward_function_search"}, {"score": 0.04930986456658361, "phrase": "reward_functions"}, {"score": 0.038138884121205564, "phrase": "alternate_reward_functions"}, {"score": 0.004661446705304497, "phrase": "reinforcement_learning"}, {"score": 0.003964007795174772, "phrase": "psychological_notion"}, {"score": 0.003900257249255497, "phrase": "intrinsic_motivation"}, {"score": 0.0032629585038738856, "phrase": "natural_task-based_reward_function"}, {"score": 0.0030828215204304473, "phrase": "genetic_programming_algorithm"}, {"score": 0.0029126002350975634, "phrase": "agent_learning_performance"}, {"score": 0.002578745296475411, "phrase": "possible_scalability"}, {"score": 0.0021922308351126746, "phrase": "nonstationary_environments"}, {"score": 0.0021049977753042253, "phrase": "short_agent_lifetimes"}], "paper_keywords": ["Genetic programming", " intrinsic motivation", " reinforcement learning"], "paper_abstract": "Reward functions in reinforcement learning have largely been assumed given as part of the problem being solved by the agent. However, the psychological notion of intrinsic motivation has recently inspired inquiry into whether there exist alternate reward functions that enable an agent to learn a task more easily than the natural task-based reward function allows. This paper presents a genetic programming algorithm to search for alternate reward functions that improve agent learning performance. We present experiments that show the superiority of these reward functions, demonstrate the possible scalability of our method, and define three classes of problems where reward function search might be particularly useful: distributions of environments, nonstationary environments, and problems with short agent lifetimes.", "paper_title": "Genetic Programming for Reward Function Search", "paper_id": "WOS:000294902000003"}