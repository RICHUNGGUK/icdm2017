{"auto_keywords": [{"score": 0.050067233313081425, "phrase": "genetic_programming"}, {"score": 0.049109137702429556, "phrase": "unbalanced_data"}, {"score": 0.043438310303989036, "phrase": "gp"}, {"score": 0.03380457797284273, "phrase": "ga"}, {"score": 0.032493979223724045, "phrase": "composite_solution_trees"}, {"score": 0.004782587436296574, "phrase": "ensemble_selection"}, {"score": 0.004686791459644141, "phrase": "classification_algorithms"}, {"score": 0.004623990904432388, "phrase": "performance_degradation"}, {"score": 0.004577440795549049, "phrase": "class_distribution"}, {"score": 0.004455575231721042, "phrase": "two-step_approach"}, {"score": 0.004264395507931215, "phrase": "first_step"}, {"score": 0.004178935413340453, "phrase": "pareto-approximated_front"}, {"score": 0.003959288961559545, "phrase": "majority_class"}, {"score": 0.0038538167879752137, "phrase": "mo_component"}, {"score": 0.0036883616416213206, "phrase": "second_step"}, {"score": 0.0035539019235553897, "phrase": "novel_ensemble_selection_approach"}, {"score": 0.0034708912871162464, "phrase": "best_individuals"}, {"score": 0.003401278997237025, "phrase": "new_gp_approach"}, {"score": 0.003378385493203297, "phrase": "multiple_pareto-approximated_front_members"}, {"score": 0.003344332868248692, "phrase": "single_composite_genetic_program_solution"}, {"score": 0.003266201217790818, "phrase": "ensemble_representation"}, {"score": 0.0032223742018434856, "phrase": "traditional_genetic_algorithm"}, {"score": 0.003032295420569351, "phrase": "selection_pressure"}, {"score": 0.0029815085406590426, "phrase": "small_highly-cooperative_groups"}, {"score": 0.0028824650336365465, "phrase": "ensemble_sizes"}, {"score": 0.002694112801983161, "phrase": "base_learners"}, {"score": 0.002640038329840458, "phrase": "different_function"}, {"score": 0.0025696192337207155, "phrase": "new_ways"}, {"score": 0.002535115422089855, "phrase": "member_outputs"}, {"score": 0.0024097920845706795, "phrase": "proposed_gp_approach"}, {"score": 0.0023935561037315375, "phrase": "smaller_more_diverse_ensembles"}, {"score": 0.002361410799860054, "phrase": "established_ensemble_selection_algorithm"}, {"score": 0.002259883463607508, "phrase": "established_approach"}, {"score": 0.0022370795358896784, "phrase": "evolved_gp_ensembles"}, {"score": 0.0021192805640815817, "phrase": "high_levels"}, {"score": 0.0021049977753042253, "phrase": "class_imbalance"}], "paper_keywords": ["Classification", " ensemble machine learning", " genetic programming", " unbalanced data"], "paper_abstract": "Classification algorithms can suffer from performance degradation when the class distribution is unbalanced. This paper develops a two-step approach to evolving ensembles using genetic programming (GP) for unbalanced data. The first step uses multiobjective (MO) GP to evolve a Pareto-approximated front of GP classifiers to form the ensemble by trading-off the minority and the majority class against each other during learning. The MO component alleviates the reliance on sampling to artificially rebalance the data. The second step, which is the focus this paper, proposes a novel ensemble selection approach using GP to automatically find/choose the best individuals for the ensemble. This new GP approach combines multiple Pareto-approximated front members into a single composite genetic program solution to represent the (optimized) ensemble. This ensemble representation has two main advantages/novelties over traditional genetic algorithm (GA) approaches. First, by limiting the depth of the composite solution trees, we use selection pressure during evolution to find small highly-cooperative groups of individuals for the ensemble. This means that ensemble sizes are not fixed a priori (as in GA), but vary depending on the strength of the base learners. Second, we compare different function set operators in the composite solution trees to explore new ways to aggregate the member outputs and thus, control how the ensemble computes its output. We show that the proposed GP approach evolves smaller more diverse ensembles compared to an established ensemble selection algorithm, while still performing as well as, or better than the established approach. The evolved GP ensembles also perform well compared to other bagging and boosting approaches, particularly on tasks with high levels of class imbalance.", "paper_title": "Reusing Genetic Programming for Ensemble Selection in Classification of Unbalanced Data", "paper_id": "WOS:000345907800008"}