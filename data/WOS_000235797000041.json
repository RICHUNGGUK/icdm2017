{"auto_keywords": [{"score": 0.004606479650820579, "phrase": "present_paper"}, {"score": 0.004406994912939125, "phrase": "adaptive_algorithm"}, {"score": 0.004278807087784626, "phrase": "competitive_training"}, {"score": 0.004093453936415085, "phrase": "nearest_neighbor"}, {"score": 0.003479692058963528, "phrase": "new_learning_rule"}, {"score": 0.0032319109979344184, "phrase": "well-known_lvq_method"}, {"score": 0.0030017207229983385, "phrase": "alternative_neighborhood_concept"}, {"score": 0.0028715299874549245, "phrase": "optimal_locations"}, {"score": 0.0027469703311742647, "phrase": "codebook_vectors"}, {"score": 0.0025892330566358503, "phrase": "synthetic_and_real_databases"}, {"score": 0.0023694065215394593, "phrase": "learning_technique"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["learning", " LVQ", " nearest centroid neighbor", " nearest neighbor"], "paper_abstract": "The present paper introduces an adaptive algorithm for competitive training of a nearest neighbor (NN) classifier when using a very small codebook. The new learning rule is based on the well-known LVQ method, and uses an alternative neighborhood concept to estimate optimal locations of the codebook vectors. Experiments over synthetic and real databases suggest the advantages of the learning technique here introduced. (c) 2005 Elsevier B.V. All rights reserved.", "paper_title": "An LVQ-based adaptive algorithm for learning from very small codebooks", "paper_id": "WOS:000235797000041"}