{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "selectional_preference_induction"}, {"score": 0.039790440365883084, "phrase": "co-occurrence_frequencies"}, {"score": 0.0046970764288494764, "phrase": "distributional_similarity_methods"}, {"score": 0.00446987606516801, "phrase": "valuable_tool"}, {"score": 0.00428892403807229, "phrase": "semantic_similarity"}, {"score": 0.004047781270412204, "phrase": "two-way_co-occurrence_data"}, {"score": 0.002931569771634119, "phrase": "tensor_factorization_methods"}, {"score": 0.002789528662623221, "phrase": "three-way_co-occurrences"}, {"score": 0.0024232694434408093, "phrase": "pseudo-disambiguation_task"}, {"score": 0.002305799666781492, "phrase": "tensor_factorization"}, {"score": 0.0022492129111567824, "phrase": "non-negative_tensor_factorization"}, {"score": 0.0021401625519713577, "phrase": "promising_tool"}], "paper_keywords": [""], "paper_abstract": "The distributional similarity methods have proven to be a valuable tool for the induction of semantic similarity. Until now, most algorithms use two-way co-occurrence data to compute the meaning of words. Co-occurrence frequencies, however, need not be pairwise. One can easily imagine situations where it is desirable to investigate co-occurrence frequencies of three modes and beyond. This paper will investigate tensor factorization methods to build a model of three-way co-occurrences. The approach is applied to the problem of selectional preference induction, and automatically evaluated in a pseudo-disambiguation task. The results show that tensor factorization, and non-negative tensor factorization in particular, is a promising tool for Natural Language Processing (NLP).", "paper_title": "A non-negative tensor factorization model for selectional preference induction", "paper_id": "WOS:000283836700004"}