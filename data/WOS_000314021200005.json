{"auto_keywords": [{"score": 0.0048198534512871975, "phrase": "angle"}, {"score": 0.004672444473700524, "phrase": "reference_image"}, {"score": 0.004444203710097833, "phrase": "visual_homing_method"}, {"score": 0.004291073117901643, "phrase": "ground_plane"}, {"score": 0.004122490120202936, "phrase": "omnidirectional_images"}, {"score": 0.004040688646993605, "phrase": "different_locations"}, {"score": 0.00396050388346298, "phrase": "goal_position"}, {"score": 0.003511613254403125, "phrase": "relative_angles"}, {"score": 0.00327356326590461, "phrase": "indirect_angle_estimation_procedure"}, {"score": 0.003129096013910623, "phrase": "planar_motion"}, {"score": 0.0030823667846259836, "phrase": "important_robustness_properties"}, {"score": 0.002931569771634119, "phrase": "new_control_law"}, {"score": 0.002873331232538783, "phrase": "available_angles"}, {"score": 0.002816246391862638, "phrase": "range_information"}, {"score": 0.0025473475682739784, "phrase": "omnidirectional_vision"}, {"score": 0.0024842242921857705, "phrase": "wide_field"}, {"score": 0.0023390219342052623, "phrase": "formal_proof"}, {"score": 0.0022696277881969896, "phrase": "proposed_control_law"}, {"score": 0.0021476967767071233, "phrase": "different_sets"}, {"score": 0.0021049977753042253, "phrase": "real_images"}], "paper_keywords": ["Visual control", " Mobile robots", " Omnidirectional vision", " Navigation"], "paper_abstract": "This paper presents a visual homing method for a robot moving on the ground plane. The approach employs a set of omnidirectional images acquired previously at different locations (including the goal position) in the environment, and the current image taken by the robot. We present as contribution a method to obtain the relative angles between all these locations, using the computation of the 1D trifocal tensor between views and an indirect angle estimation procedure. The tensor is particularly well suited for planar motion and provides important robustness properties to our technique. Another contribution of our paper is a new control law that uses the available angles, with no range information involved, to drive the robot to the goal. Therefore, our method takes advantage of the strengths of omnidirectional vision, which provides a wide field of view and very precise angular information. We present a formal proof of the stability of the proposed control law. The performance of our approach is illustrated through simulations and different sets of experiments with real images.", "paper_title": "Angle-based homing from a reference image set using the 1D trifocal tensor", "paper_id": "WOS:000314021200005"}