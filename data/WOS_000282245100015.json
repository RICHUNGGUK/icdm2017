{"auto_keywords": [{"score": 0.024677663705734126, "phrase": "parallel_speech_data"}, {"score": 0.004653339900995785, "phrase": "segment-based_voice_conversion_technique"}, {"score": 0.004560248816733711, "phrase": "markov"}, {"score": 0.004346139434813299, "phrase": "nonparallel_training_data"}, {"score": 0.00422899036681456, "phrase": "proposed_technique"}, {"score": 0.004143196873246147, "phrase": "phoneme_information"}, {"score": 0.0038695436922618876, "phrase": "input_speech"}, {"score": 0.0037910145286595386, "phrase": "source_speaker"}, {"score": 0.0034924598001567944, "phrase": "synthesis_part"}, {"score": 0.00332924643541238, "phrase": "prosodic_context"}, {"score": 0.0032616462517547477, "phrase": "phonetically_and_prosodically_context-dependent_label_sequence"}, {"score": 0.002984173420996039, "phrase": "converted_speech"}, {"score": 0.0028838335724864547, "phrase": "label_sequence"}, {"score": 0.002786858120570499, "phrase": "target_speaker's_pre-trained_context-dependent_hmms"}, {"score": 0.0021932609696277937, "phrase": "objective_and_subjective_experimental_results"}, {"score": 0.0021340178074057245, "phrase": "segment-based_voice_conversion"}, {"score": 0.0021049977753042253, "phrase": "phonetic_and_prosodic_contexts"}], "paper_keywords": ["voice conversion", " HMM-based speech synthesis", " F0 quantization", " prosodic context", " nonparallel data"], "paper_abstract": "We propose a segment-based voice conversion technique using hidden Markov model (HMM)-based speech synthesis with nonparallel training data. In the proposed technique, the phoneme information with durations and a quantized F0 contour are extracted from the input speech of a source speaker, and are transmitted to a synthesis part. In the synthesis part, the quantized F0 symbols are used as prosodic context. A phonetically and prosodically context-dependent label sequence is generated from the transmitted phoneme and the F0 symbols. Then, converted speech is generated from the label sequence with durations using the target speaker's pre-trained context-dependent HMMs. In the model training, the models of the source and target speakers can be trained separately, hence there is no need to prepare parallel speech data of the source and target speakers. Objective and subjective experimental results show that the segment-based voice conversion with phonetic and prosodic contexts works effectively even if the parallel speech data is not available.", "paper_title": "HMM-Based Voice Conversion Using Quantized F0 Context", "paper_id": "WOS:000282245100015"}