{"auto_keywords": [{"score": 0.0500781746464475, "phrase": "approximate_mdp"}, {"score": 0.03982161900229302, "phrase": "qsi"}, {"score": 0.00459039896577789, "phrase": "low-complexity_delay-aware_cross-layer_scheduling_algorithm"}, {"score": 0.004334657104697421, "phrase": "complex_interactions"}, {"score": 0.003977403701783668, "phrase": "infinite_horizon_average_reward_markov_decision_process"}, {"score": 0.003828187766572941, "phrase": "joint_queue_state_information"}, {"score": 0.00349577373145384, "phrase": "joint_channel_state_information"}, {"score": 0.0034628348779557148, "phrase": "csi"}, {"score": 0.0033645655483989746, "phrase": "r-d_links"}, {"score": 0.0032074366230426727, "phrase": "equivalent_mdp_formulation"}, {"score": 0.0031018195951638882, "phrase": "system_state"}, {"score": 0.003043031131345537, "phrase": "global_qsi."}, {"score": 0.0029569247903654477, "phrase": "stochastic_learning"}, {"score": 0.0026999603129904902, "phrase": "per-node_value_function"}, {"score": 0.002661474607275484, "phrase": "real-time_observations"}, {"score": 0.002623536040408411, "phrase": "local_csi"}, {"score": 0.0024771000236931836, "phrase": "combined_distributed_learning"}, {"score": 0.002406968743305622, "phrase": "global_optimal_solution"}, {"score": 0.0023840346303791032, "phrase": "large_arrivals"}, {"score": 0.0022617389804167943, "phrase": "proposed_scheme"}, {"score": 0.0022401855403251653, "phrase": "significant_gain"}, {"score": 0.002166349705365602, "phrase": "conventional_csit-only_control"}, {"score": 0.0021354538918029286, "phrase": "throughput_optimal_control"}, {"score": 0.0021049977753042253, "phrase": "stability_sense"}], "paper_keywords": ["Cooperative communications", " delay-aware resource allocation", " distributive algorithm", " stochastic optimization"], "paper_abstract": "In this paper, a low-complexity delay-aware cross-layer scheduling algorithm for two-hop relay communication systems is proposed. The complex interactions of the queues at the source node and the M relay nodes (RSs) are modeled as an infinite horizon average reward Markov decision process (MDP), whose state space involves the joint queue state information (QSI) of the queues at the source node and the M RSs as well as the joint channel state information (CSI) of all S-R and R-D links. To address the curse of dimensionality, an equivalent MDP formulation is first proposed, where the system state depends only on global QSI. Furthermore, using approximate MDP and stochastic learning, an auction-based distributed online learning algorithm is derived, where each node iteratively estimates a per-node value function based on real-time observations of the local CSI and local QSI as well as signaling between relays. The combined distributed learning converges almost surely to a global optimal solution for large arrivals. Finally, it is showed by simulations that the proposed scheme achieves significant gain compared with various baselines such as the conventional CSIT-only control and the throughput optimal control (in stability sense).", "paper_title": "Delay-Aware Two-Hop Cooperative Relay Communications via Approximate MDP and Stochastic Learning", "paper_id": "WOS:000325981100042"}