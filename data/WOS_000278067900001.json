{"auto_keywords": [{"score": 0.046738427830692486, "phrase": "unknown_matrix"}, {"score": 0.00481495049065317, "phrase": "convex_relaxation"}, {"score": 0.004425979295788883, "phrase": "small_fraction"}, {"score": 0.00426900754050533, "phrase": "matrix_completion_problem"}, {"score": 0.004150761431291174, "phrase": "great_number"}, {"score": 0.004052007312730483, "phrase": "famous_netflix_prize"}, {"score": 0.003987474771008829, "phrase": "collaborative_filtering"}, {"score": 0.0038305869305614504, "phrase": "small_number"}, {"score": 0.003635790924434452, "phrase": "low_rank"}, {"score": 0.00340954056723008, "phrase": "optimality_results"}, {"score": 0.003368707839819003, "phrase": "minimum_number"}, {"score": 0.0032491108935498794, "phrase": "rank_r"}, {"score": 0.0029386456078004863, "phrase": "singular_vectors"}, {"score": 0.0028115863316685937, "phrase": "convenient_convex_program"}, {"score": 0.0026577673946415583, "phrase": "information_theoretic_limit"}, {"score": 0.002615381301695394, "phrase": "logarithmic_factors"}, {"score": 0.0025736694380861604, "phrase": "convex_program"}, {"score": 0.002472269923319476, "phrase": "observed_entries"}, {"score": 0.002432834929068545, "phrase": "minimum_nuclear_norm"}, {"score": 0.0022268964676199292, "phrase": "random_n_x"}, {"score": 0.0021049977753042253, "phrase": "nuclear_norm_minimization"}], "paper_keywords": ["Duality in optimization", " free probability", " low-rank matrices", " matrix completion", " nuclear norm minimization", " random matrices and techniques from random matrix theory", " semidefinite programming"], "paper_abstract": "This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible, but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr log(n).", "paper_title": "The Power of Convex Relaxation: Near-Optimal Matrix Completion", "paper_id": "WOS:000278067900001"}