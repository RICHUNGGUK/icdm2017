{"auto_keywords": [{"score": 0.04660802533264657, "phrase": "goms"}, {"score": 0.00481495049065317, "phrase": "herbal_compiler"}, {"score": 0.004375928080972614, "phrase": "cognitive_user_models"}, {"score": 0.00417160036938041, "phrase": "different_stages"}, {"score": 0.003976775340098895, "phrase": "spreadsheet_task"}, {"score": 0.003922794571908569, "phrase": "multiple_sessions"}, {"score": 0.0038431888954930083, "phrase": "example_task"}, {"score": 0.003352088714126572, "phrase": "novice_model"}, {"score": 0.0030879936732269293, "phrase": "procedural_knowledge"}, {"score": 0.0029436264166293317, "phrase": "expert_model"}, {"score": 0.0025848074189353397, "phrase": "limited_declarative_learning"}, {"score": 0.002532284627202572, "phrase": "command_strings"}, {"score": 0.002364777610365689, "phrase": "intermediate_models"}, {"score": 0.002254145085288829, "phrase": "aggregate_and_individual_human_learning_data"}, {"score": 0.0021932609696277937, "phrase": "models'_predictions"}, {"score": 0.0021049977753042253, "phrase": "user_models"}], "paper_keywords": ["Computational cognitive modeling", " user modeling", " expertise", " ACT-R", " GOMS", " KLM", " evaluating user interfaces", " Interaction", " Simulation", " Usability", " Learning", " Human Factors", " Design", " Theory"], "paper_abstract": "We report a way to build a series of GOMS-like cognitive user models representing a range of performance at different stages of learning. We use a spreadsheet task across multiple sessions as an example task; it takes about 20-30 min. to perform. The models were created in ACT-R using a compiler. The novice model has 29 rules and 1,152 declarative memory task elements (chunks) it learns to create procedural knowledge to perform the task. The expert model has 617 rules and 614 task chunks (that it does not use) and 538 command string chunks it gets slightly faster through limited declarative learning of the command strings and some further production compilation; there are a range of intermediate models. These models were tested against aggregate and individual human learning data, confirming the models' predictions. This work suggests that user models can be created that learn like users while doing the task.", "paper_title": "Predicting User Performance and Learning in Human-Computer Interaction with the Herbal Compiler", "paper_id": "WOS:000364272700005"}