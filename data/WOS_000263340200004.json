{"auto_keywords": [{"score": 0.04208729377636017, "phrase": "trifocal_tensors"}, {"score": 0.00481495049065317, "phrase": "robust_estimation"}, {"score": 0.004776297980616768, "phrase": "trifocal_tensors_using_natural_features"}, {"score": 0.004681012408089219, "phrase": "augmented_reality_deals"}, {"score": 0.004496080495247288, "phrase": "real_world"}, {"score": 0.004424160689087029, "phrase": "virtual_scenes"}, {"score": 0.004249332848326785, "phrase": "ar_applications"}, {"score": 0.004131063310728304, "phrase": "novel_registration_method"}, {"score": 0.0040978781692373005, "phrase": "natural_features"}, {"score": 0.0040485975929323, "phrase": "online_estimation"}, {"score": 0.0035296940954990964, "phrase": "virtual_object"}, {"score": 0.0034452601929727752, "phrase": "online_registration"}, {"score": 0.003403801095792972, "phrase": "natural_feature_correspondences"}, {"score": 0.0033492947290751996, "phrase": "reference_views"}, {"score": 0.003282383509542342, "phrase": "current_frame"}, {"score": 0.003229815147800001, "phrase": "feature_triples"}, {"score": 0.0031020367403802773, "phrase": "corresponding_trifocal_tensors"}, {"score": 0.0030646951765987414, "phrase": "image_sequence"}, {"score": 0.0029434299787644445, "phrase": "registration_matrix"}, {"score": 0.002884603537502399, "phrase": "estimated_registration_matrix"}, {"score": 0.0028155572612699976, "phrase": "initial_estimate"}, {"score": 0.0027816546451972725, "phrase": "nonlinear_optimization_method"}, {"score": 0.0027370835853738626, "phrase": "actual_residual_errors"}, {"score": 0.002524688179363081, "phrase": "robust_method"}, {"score": 0.0024444073418288703, "phrase": "modified_ransac_algorithm"}, {"score": 0.002357131515622894, "phrase": "standard_ransac"}, {"score": 0.0022914054720704546, "phrase": "computation_complexity"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Augmented reality", " registration", " trifocal tensors", " projective reconstruction"], "paper_abstract": "Augmented reality deals with the problem of dynamically augmenting or enhancing the real world with computer generated virtual scenes. Registration is one of the most pivotal problems currently limiting AR applications. In this paper, a novel registration method using natural features based on online estimation of trifocal tensors is proposed. This method consists of two stages: offline initialization and online registration. Initialization involves specifying four points in two reference images respectively to build the world coordinate system on which a virtual object will be augmented. In online registration, the natural feature correspondences detected From the reference views are tracked in the current frame to build the feature triples. Then these triples are Used to estimate the corresponding trifocal tensors in the image sequence by which the four specified points are transferred to compute the registration matrix for augmentation. The estimated registration matrix will be used as an initial estimate for a nonlinear optimization method that minimizes the actual residual errors based on the Levenberg-Marquardt (LM) minimization method, thus making the results more robust and stable. This paper also proposes a robust method for estimating the trifocal tensors, where a modified RANSAC algorithm is used to remove outliers. Compared with standard RANSAC, our method can significantly reduce, computation complexity, while overcoming the disturbance of mismatches. Some experiments have been carried out to demonstrate the validity of the proposed approach.", "paper_title": "ROBUST ESTIMATION OF TRIFOCAL TENSORS USING NATURAL FEATURES FOR AUGMENTED REALITY SYSTEMS", "paper_id": "WOS:000263340200004"}