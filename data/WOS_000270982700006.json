{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "radial_outflow"}, {"score": 0.03843856552198327, "phrase": "depth_perception"}, {"score": 0.004760017604908536, "phrase": "depth_information"}, {"score": 0.004687742829233727, "phrase": "practical_experience"}, {"score": 0.004511799033574768, "phrase": "remotely_operated_robots"}, {"score": 0.004325851128896925, "phrase": "smets"}, {"score": 0.004260135332570871, "phrase": "tittle"}, {"score": 0.004227653675675524, "phrase": "roesler"}, {"score": 0.0041001740903338834, "phrase": "previous_research"}, {"score": 0.004037877545494505, "phrase": "head_motions"}, {"score": 0.003991774582021095, "phrase": "effective_information"}, {"score": 0.003931130790523288, "phrase": "bingham"}, {"score": 0.0035586268203884673, "phrase": "remote_targets"}, {"score": 0.0035179764329354877, "phrase": "moving_camera"}, {"score": 0.0034118234596993836, "phrase": "teleoperated_robotic_arm"}, {"score": 0.0033215617190376565, "phrase": "white_squares"}, {"score": 0.003296212583539166, "phrase": "black_space"}, {"score": 0.0031723302551782324, "phrase": "video_monitor"}, {"score": 0.0029951555610569225, "phrase": "remote_camera"}, {"score": 0.0029270797740550973, "phrase": "different_experimental_conditions"}, {"score": 0.0028715299874549245, "phrase": "remote_camera_arm"}, {"score": 0.0028170314398963704, "phrase": "participants'_head_movements"}, {"score": 0.002680114113899346, "phrase": "preprogrammed_oscillatory_motions"}, {"score": 0.002599177223533834, "phrase": "participants'_distance_judgments"}, {"score": 0.0025596276616952516, "phrase": "actual_target_distances"}, {"score": 0.0025014259919355453, "phrase": "third_experiment"}, {"score": 0.0024633601573822114, "phrase": "familiar_objects"}, {"score": 0.0023981301755351607, "phrase": "successful_method"}, {"score": 0.0022640963589007457, "phrase": "distance_feedback"}, {"score": 0.0022211005680689666, "phrase": "unfamiliar_targets"}, {"score": 0.0021049977753042253, "phrase": "active_or_passive_front-to-back_camera_motions"}], "paper_keywords": [""], "paper_abstract": "Practical experience has shown that teleoperators have difficulty perceiving aspects of remotely operated robots and their environments (e. g., Casper & Murphy, 2003; Smets, 1995; Tittle, Roesler, & Woods, 2002). Previous research has shown that head motions can provide effective information about depth (Bingham, & Pagano, 1998; Pagano & Bingham, 1998). In three experiments, a method for improving depth perception was investigated, where participants viewed remote targets with a moving camera. The camera was mounted on a teleoperated robotic arm that oscillated toward and away from white squares against black space, producing expansion and contraction of targets on a video monitor. Participants viewed this expansion and contraction and then reported the distance between the remote camera and the targets. Under different experimental conditions, motions of the remote camera arm were coupled with the participants' head movements, were controlled by a joystick, or followed a set of preprogrammed oscillatory motions. Under each of these conditions, participants' distance judgments varied semantically with actual target distances. In addition, the third experiment demonstrated that using familiar objects and providing feedback could be a successful method of training. This was also the case when applied to a condition where distance feedback was not provided and unfamiliar targets were used. The results indicate that the use of radial outflow produced by active or passive front-to-back camera motions and training with familiar objects may be effective strategies for improving depth perception in teleoperation.", "paper_title": "Using Radial Outflow to Provide Depth Information During Teleoperation", "paper_id": "WOS:000270982700006"}