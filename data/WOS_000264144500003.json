{"auto_keywords": [{"score": 0.025176482524659347, "phrase": "low-dimensional_embedding"}, {"score": 0.00481495049065317, "phrase": "articulated_motion_recognition"}, {"score": 0.004747714939490445, "phrase": "motion_representations"}, {"score": 0.004697902218671618, "phrase": "frame-wise_abstractions"}, {"score": 0.004648609688625397, "phrase": "statistical_distribution"}, {"score": 0.004616034337089482, "phrase": "low-level_features"}, {"score": 0.004487989502479992, "phrase": "relational_distributions"}, {"score": 0.00440976345264104, "phrase": "parts_changes"}, {"score": 0.004378854464130883, "phrase": "articulated_motion"}, {"score": 0.004332894955218135, "phrase": "distribution_changes"}, {"score": 0.004227515355865597, "phrase": "latent_space"}, {"score": 0.003940286428597882, "phrase": "standard_techniques"}, {"score": 0.0038989120088094185, "phrase": "dynamic_time"}, {"score": 0.0037906837773782, "phrase": "paper_concerns"}, {"score": 0.0037508743235608872, "phrase": "frame-wise_distributions"}, {"score": 0.0036467403626789666, "phrase": "probability_functions"}, {"score": 0.0035957586558176932, "phrase": "low-dimensional_space"}, {"score": 0.003447050909511877, "phrase": "bhattacharya"}, {"score": 0.0034228518192925134, "phrase": "matusita"}, {"score": 0.0033988655074984977, "phrase": "kullback-leibler"}, {"score": 0.0033395304916220086, "phrase": "symmetric-kl_distances"}, {"score": 0.0033044432971036652, "phrase": "dot_products"}, {"score": 0.0032013710938940424, "phrase": "computational_advantages"}, {"score": 0.0031344430376015033, "phrase": "speed-normalized_matching"}, {"score": 0.003079736435077217, "phrase": "speed_normalized_representations"}, {"score": 0.0030047427137652218, "phrase": "configuration_trajectories"}, {"score": 0.002900756392266265, "phrase": "temporal_scale_variations"}, {"score": 0.0028201570908224166, "phrase": "five_different_probabilistic_distance_measures"}, {"score": 0.0026750045328382743, "phrase": "large_number"}, {"score": 0.0026562224049977213, "phrase": "possible_classes"}, {"score": 0.0025915147359879616, "phrase": "person_variations"}, {"score": 0.002537303919584199, "phrase": "human-human_interaction_sequences"}, {"score": 0.002415170557932468, "phrase": "right_distance_measure"}, {"score": 0.002290814637620121, "phrase": "recognition_accuracies"}, {"score": 0.0021049977753042253, "phrase": "low-level_parameters"}], "paper_keywords": ["Human motion classification", " embedding probability density functions", " gesture recognition", " sign language recognition"], "paper_abstract": "Some articulated motion representations rely on frame-wise abstractions of the statistical distribution of low-level features such as orientation, color, or relational distributions. As configuration among parts changes with articulated motion, the distribution changes, tracing a trajectory in the latent space of distributions, which we call the configuration space. These trajectories can then be used for recognition using standard techniques such as dynamic time warping. The core theory in this paper concerns embedding the frame-wise distributions, which can be looked upon as probability functions, into a low-dimensional space so that we can estimate various meaningful probabilistic distances such as the Chernoff, Bhattacharya, Matusita, Kullback-Leibler (KL) or symmetric-KL distances based on dot products between points in this space. Apart from computational advantages, this representation also affords speed-normalized matching of motion signatures. Speed normalized representations can be formed by interpolating the configuration trajectories along their arc lengths, without using any knowledge of the temporal scale variations between the sequences. We experiment with five different probabilistic distance measures and show the usefulness of the representation in three different contexts-sign recognition (with large number of possible classes), gesture recognition (with person variations), and classification of human-human interaction sequences (with segmentation problems). We find the importance of using the right distance measure for each situation. The low-dimensional embedding makes matching two to three times faster, while achieving recognition accuracies that are close to those obtained without using a low-dimensional embedding. We also empirically establish the robustness of the representation with respect to low-level parameters, embedding parameters, and temporal-scale parameters.", "paper_title": "Distribution-Based Dimensionality Reduction Applied to Articulated Motion Recognition", "paper_id": "WOS:000264144500003"}