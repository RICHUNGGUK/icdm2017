{"auto_keywords": [{"score": 0.039590301519126646, "phrase": "insignificant_hidden_nodes"}, {"score": 0.03587220612412254, "phrase": "input_parameters"}, {"score": 0.032815198594099704, "phrase": "energy_error"}, {"score": 0.02483307094281365, "phrase": "elm"}, {"score": 0.00481495049065317, "phrase": "dynamic_adjustment_of_hidden_node_parameters"}, {"score": 0.004766090327062509, "phrase": "extreme_learning_machine"}, {"score": 0.004506048850130758, "phrase": "huang_et_al"}, {"score": 0.00437021209960886, "phrase": "generalized_single_hidden_layer_feedforward_networks"}, {"score": 0.004238452771031322, "phrase": "hidden_nodes"}, {"score": 0.003966388754366831, "phrase": "function_approximation_problems"}, {"score": 0.003906116922372891, "phrase": "predetermined_network_structure"}, {"score": 0.0036181717017041387, "phrase": "dynamic_adjustment"}, {"score": 0.0032668821950788533, "phrase": "residual_error"}, {"score": 0.0029951555610569225, "phrase": "recursive_expectation-minimization_theorem"}, {"score": 0.002875200380397413, "phrase": "insignificant_hidden_node"}, {"score": 0.0028026735035370206, "phrase": "decreasing_direction"}, {"score": 0.002676692093594358, "phrase": "detailed_theoretical_foundation"}, {"score": 0.002556359086441866, "phrase": "experimental_results"}, {"score": 0.0025046245057922557, "phrase": "proposed_da-elm"}, {"score": 0.0024289743270061157, "phrase": "state-of-art_algorithms"}, {"score": 0.002392008392892289, "phrase": "bayesian_elm"}, {"score": 0.0022496789733258533, "phrase": "levenberg-marquardt"}, {"score": 0.002104999656252259, "phrase": "elm."}], "paper_keywords": ["Adjustment of hidden node parameters", " error minimized approximation", " extreme learning machine", " least squares method"], "paper_abstract": "Extreme learning machine (ELM), proposed by Huang et al., was developed for generalized single hidden layer feedforward networks with a wide variety of hidden nodes. ELMs have been proved very fast and effective especially for solving function approximation problems with a predetermined network structure. However, it may contain insignificant hidden nodes. In this paper, we propose dynamic adjustment ELM (DA-ELM) that can further tune the input parameters of insignificant hidden nodes in order to reduce the residual error. It is proved in this paper that the energy error can be effectively reduced by applying recursive expectation-minimization theorem. In DA-ELM, the input parameters of insignificant hidden node are updated in the decreasing direction of the energy error in each step. The detailed theoretical foundation of DA-ELM is presented in this paper. Experimental results show that the proposed DA-ELM is more efficient than the state-of-art algorithms such as Bayesian ELM, optimally-pruned ELM, two-stage ELM, Levenberg-Marquardt, sensitivity-based linear learning method as well as the preliminary ELM.", "paper_title": "Dynamic Adjustment of Hidden Node Parameters for Extreme Learning Machine", "paper_id": "WOS:000348071500011"}