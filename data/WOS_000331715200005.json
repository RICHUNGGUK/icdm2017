{"auto_keywords": [{"score": 0.04970018005584556, "phrase": "latent_space"}, {"score": 0.008980142700324085, "phrase": "motion_tracking"}, {"score": 0.004739056045644449, "phrase": "sequential_clonal_selection_algorithm"}, {"score": 0.004701556483912018, "phrase": "high_dimensional_pose_state_space"}, {"score": 0.004590820632326585, "phrase": "articulated_human_pose_tracking"}, {"score": 0.00453643016617164, "phrase": "pose_analysis"}, {"score": 0.004290969772225093, "phrase": "novel_generative_approach"}, {"score": 0.004206548500039536, "phrase": "evolutionary_computation"}, {"score": 0.004026598712747509, "phrase": "effective_search_strategy"}, {"score": 0.00396308097989371, "phrase": "extracted_state_subspace"}, {"score": 0.003869673995931933, "phrase": "isomap"}, {"score": 0.003808619097554076, "phrase": "low-dimensional_latent_space"}, {"score": 0.0036023971109946946, "phrase": "prior_knowledge"}, {"score": 0.003573859492987647, "phrase": "human_motion"}, {"score": 0.0034619440946558186, "phrase": "manifold_reconstruction_method"}, {"score": 0.0034208822062692127, "phrase": "smooth_mappings"}, {"score": 0.003353521531649663, "phrase": "original_space"}, {"score": 0.0031592690527974285, "phrase": "search_strategy"}, {"score": 0.003097043800165555, "phrase": "new_evolutionary_approach"}, {"score": 0.0028944757265206332, "phrase": "based_method"}, {"score": 0.0028601252251285, "phrase": "human_pose"}, {"score": 0.002837451022172113, "phrase": "static_image"}, {"score": 0.0025892330566358503, "phrase": "sequential_csa"}, {"score": 0.002488183412451029, "phrase": "temporal_continuity_information"}, {"score": 0.0024586427394152196, "phrase": "traditional_csa."}, {"score": 0.0024101837218440834, "phrase": "bayesian_inference_view"}, {"score": 0.002381566880282456, "phrase": "sequential_csa_algorithm"}, {"score": 0.0023346234464901978, "phrase": "multilayer_importance_sampling_based_particle_filter"}, {"score": 0.002270449532546444, "phrase": "different_motion_types"}, {"score": 0.0022168460543913787, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "s-csa_based_motion_tracking_method"}], "paper_keywords": ["Human motion analysis", " Pose estimation", " Human motion tracking", " Manifold learning", " Clonal selection algorithm"], "paper_abstract": "High dimensional pose state space is the main challenge in articulated human pose tracking which makes pose analysis computationally expensive or even infeasible. In this paper, we propose a novel generative approach in the framework of evolutionary computation, by which we try to widen the bottleneck with effective search strategy embedded in the extracted state subspace. Firstly, we use ISOMAP to learn the low-dimensional latent space of pose state in the aim of both reducing dimensionality and extracting the prior knowledge of human motion simultaneously. Then, we propose a manifold reconstruction method to establish smooth mappings between the latent space and original space, which enables us to perform pose analysis in the latent space. In the search strategy, we adopt a new evolutionary approach, clonal selection algorithm (CSA), for pose optimization. We design a CSA based method to estimate human pose from static image, which can be used for initialization of motion tracking. In order to make CSA suitable for motion tracking, we propose a sequential CSA (S-CSA) algorithm by incorporating the temporal continuity information into the traditional CSA. Actually, in a Bayesian inference view, the sequential CSA algorithm is in essence a multilayer importance sampling based particle filter. Our methods are demonstrated in different motion types and different image sequences. Experimental results show that our CSA based pose estimation method can achieve viewpoint invariant 3D pose reconstruction and the S-CSA based motion tracking method can achieve accurate and stable tracking of 3D human motion.", "paper_title": "Generative tracking of 3D human motion in latent space by sequential clonal selection algorithm", "paper_id": "WOS:000331715200005"}