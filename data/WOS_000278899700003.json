{"auto_keywords": [{"score": 0.048564928403357514, "phrase": "decision_rules"}, {"score": 0.010612387000973441, "phrase": "ender"}, {"score": 0.006387665774420241, "phrase": "minimization_techniques"}, {"score": 0.004515252649226697, "phrase": "important_role"}, {"score": 0.004473982381245469, "phrase": "machine_learning"}, {"score": 0.004412780054037622, "phrase": "main_advantage"}, {"score": 0.0042928648367867835, "phrase": "human-interpretable_form"}, {"score": 0.004119049028319832, "phrase": "complex_interactions"}, {"score": 0.0038981499110532273, "phrase": "learning_algorithm"}, {"score": 0.0035722806911457545, "phrase": "binary_classification_problems"}, {"score": 0.0034911335714333507, "phrase": "boosting_approach"}, {"score": 0.0033190180867511605, "phrase": "sequential_covering"}, {"score": 0.00327356326590461, "phrase": "new_rule"}, {"score": 0.0029181203386806683, "phrase": "different_loss_functions"}, {"score": 0.002825681384008326, "phrase": "boosting_framework"}, {"score": 0.002723607240517261, "phrase": "impurity_measures"}, {"score": 0.0026616868981501006, "phrase": "single_decision_rules"}, {"score": 0.002194011800331242, "phrase": "ender_algorithm"}, {"score": 0.0021049977753042253, "phrase": "rulefit"}], "paper_keywords": ["Decision rules", " Impurity measures", " Ensemble", " Boosting", " Forward stagewise additive modeling"], "paper_abstract": "Induction of decision rules plays an important role in machine learning. The main advantage of decision rules is their simplicity and human-interpretable form. Moreover, they are capable of modeling complex interactions between attributes. In this paper, we thoroughly analyze a learning algorithm, called ENDER, which constructs an ensemble of decision rules. This algorithm is tailored for regression and binary classification problems. It uses the boosting approach for learning, which can be treated as generalization of sequential covering. Each new rule is fitted by focusing on examples which were the hardest to classify correctly by the rules already present in the ensemble. We consider different loss functions and minimization techniques often encountered in the boosting framework. The minimization techniques are used to derive impurity measures which control construction of single decision rules. Properties of four different impurity measures are analyzed with respect to the trade-off between misclassification (discrimination) and coverage (completeness) of the rule. Moreover, we consider regularization consisting of shrinking and sampling. Finally, we compare the ENDER algorithm with other well-known decision rule learners such as SLIPPER, LRI and RuleFit.", "paper_title": "ENDER: a statistical framework for boosting decision rules", "paper_id": "WOS:000278899700003"}