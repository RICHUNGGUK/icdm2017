{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "online_dynamic_gesture_recognition_for_human_robot_interaction"}, {"score": 0.004643839937761046, "phrase": "online_dynamic_hand_gesture_recognition_system"}, {"score": 0.004560568143816105, "phrase": "rgb-d_camera"}, {"score": 0.004398457709182882, "phrase": "hand_gestures"}, {"score": 0.004345706062641742, "phrase": "complicated_background"}, {"score": 0.004267757384195032, "phrase": "background_subtraction"}, {"score": 0.004140924670517666, "phrase": "model-based_method"}, {"score": 0.00406663414150229, "phrase": "human_detection"}, {"score": 0.003945754887845885, "phrase": "depth_map"}, {"score": 0.0038516336597530614, "phrase": "robust_hand_tracking_approach"}, {"score": 0.003692271726952282, "phrase": "hand_gesture_recognition"}, {"score": 0.0035824802350703376, "phrase": "color_information"}, {"score": 0.0034135407979996673, "phrase": "hand_tracking"}, {"score": 0.003332072426367186, "phrase": "spatio-temporal_hand_gesture_sequences"}, {"score": 0.003213489259323924, "phrase": "reliable_gesture"}, {"score": 0.00306189690236109, "phrase": "static_postures"}, {"score": 0.00291743479583421, "phrase": "left-right_banded"}, {"score": 0.002680789041160613, "phrase": "multi-feature_representation"}, {"score": 0.002600995957987461, "phrase": "hand_gesture_sequences"}, {"score": 0.0025697460140513932, "phrase": "experimental_evaluations"}, {"score": 0.002389956401870098, "phrase": "proposed_system"}, {"score": 0.0022909325048608054, "phrase": "human-robot_interactive_system"}, {"score": 0.002143529653780496, "phrase": "interactive_experiments"}, {"score": 0.0021049977753042253, "phrase": "dynamic_environment"}], "paper_keywords": ["Hand gesture recognition", " Dynamic gesture spotting", " Human-robot interaction"], "paper_abstract": "This paper presents an online dynamic hand gesture recognition system with an RGB-D camera, which can automatically recognize hand gestures against complicated background. For background subtraction, we use a model-based method to perform human detection and segmentation in the depth map. Since a robust hand tracking approach is crucial for the performance of hand gesture recognition, our system uses both color information and depth information in the process of hand tracking. To extract spatio-temporal hand gesture sequences in the trajectory, a reliable gesture spotting scheme with detection on change of static postures is proposed. Then discrete HMMs with Left-Right Banded (LRB) topology are utilized to model and classify gestures based on multi-feature representation and quantization of the hand gesture sequences. Experimental evaluations on two self-built databases of dynamic hand gestures show the effectiveness of the proposed system. Furthermore, we develop a human-robot interactive system, and the performance of this system is demonstrated through interactive experiments in the dynamic environment.", "paper_title": "Online Dynamic Gesture Recognition for Human Robot Interaction", "paper_id": "WOS:000350657800012"}