{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "cognitive_vision"}, {"score": 0.004723847090183984, "phrase": "cognitive_systems"}, {"score": 0.004678940805063634, "phrase": "cognitive_robots"}, {"score": 0.004568525347438891, "phrase": "different_tasks"}, {"score": 0.004334657104697421, "phrase": "new_situations"}, {"score": 0.004212157020917929, "phrase": "real-world_settings"}, {"score": 0.004132411680987228, "phrase": "visual_perception"}, {"score": 0.003958439439112026, "phrase": "essential_function"}, {"score": 0.0037199473428123175, "phrase": "dominant_cue"}, {"score": 0.0036494864560524735, "phrase": "simple_objects"}, {"score": 0.003529364798514874, "phrase": "advanced_computer_vision_methods"}, {"score": 0.0034625012596827334, "phrase": "large_data"}, {"score": 0.0032382660477699695, "phrase": "higher_level_semantics"}, {"score": 0.003072285184441679, "phrase": "specific_requirement"}, {"score": 0.0030285084113651035, "phrase": "vision_system"}, {"score": 0.0029569247903654477, "phrase": "cognitive_robotics"}, {"score": 0.002873247913129334, "phrase": "new_approach"}, {"score": 0.002845883666777154, "phrase": "robot_vision"}, {"score": 0.002687070469080394, "phrase": "situated_and_embodied_aspects"}, {"score": 0.0024771000236931836, "phrase": "cognitive_functions"}, {"score": 0.0022401855403251653, "phrase": "visual_input"}, {"score": 0.0021049977753042253, "phrase": "common_ontology"}], "paper_keywords": ["cognitive robotics", " perception", " vision", " ontology", " functions"], "paper_abstract": "Cognitive robots are supposed to execute different tasks, adapt to changes in the environment and cope with new situations. They shall operate in real-world settings. Hence, visual perception of the objects in the environment is an essential function. However, on the one hand there are robots using colour as dominant cue to cope with simple objects and on the other hand there are advanced computer vision methods that search through large data bases of images. What is usually missing to a robot are the higher level semantics of its world. To overcome this gap we analyse the specific requirement to the vision system given the context of cognitive robotics. We then propose a new approach to robot vision, which we termed situated vision in order to emphasise the situated and embodied aspects inherent in this domain. We are discussing requirements for such a situated vision system and provide a theory of cognitive functions that seem important to overcome limitations that appear when fixating only on the information that can be found in the visual input. Finally, we are explaining our understanding for the need of a common ontology on which these functions operate.", "paper_title": "Theoretic foundations of situating cognitive vision in robots and cognitive systems", "paper_id": "WOS:000299541900006"}