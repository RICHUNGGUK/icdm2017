{"auto_keywords": [{"score": 0.036091624165644744, "phrase": "cholesky"}, {"score": 0.00481495049065317, "phrase": "parallel_tiled_linear_algebra_algorithms"}, {"score": 0.00465634671242413, "phrase": "multicore_systems"}, {"score": 0.004477870190590885, "phrase": "high_performance_computing_world"}, {"score": 0.004428139418750855, "phrase": "linear_algebra_algorithms"}, {"score": 0.00428222231579898, "phrase": "new_algorithms"}, {"score": 0.00400459716272594, "phrase": "architectural_features"}, {"score": 0.0039380388343479384, "phrase": "new_processors"}, {"score": 0.00389427992231721, "phrase": "fine_grain_parallelism"}, {"score": 0.003829548069657859, "phrase": "major_requirement"}, {"score": 0.003703282519292336, "phrase": "loose_synchronization"}, {"score": 0.003641713874009232, "phrase": "parallel_execution"}, {"score": 0.003348838095597268, "phrase": "qr_factorization"}, {"score": 0.0031490944606172152, "phrase": "small_tasks"}, {"score": 0.0030794433253250476, "phrase": "square_blocks"}, {"score": 0.002707741309851526, "phrase": "computational_resources"}, {"score": 0.0025892330566358503, "phrase": "order_execution"}, {"score": 0.00244834685428352, "phrase": "intrinsically_sequential_tasks"}, {"score": 0.0023807981747706376, "phrase": "performance_comparisons"}, {"score": 0.0023281003994670714, "phrase": "lapack_algorithms"}, {"score": 0.002176887956041267, "phrase": "blas_operations"}, {"score": 0.0021526564019119466, "phrase": "vendor_implementations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Linear algebra", " Mathematical software", " High performance computing", " Multicore"], "paper_abstract": "As multicore systems continue to gain ground in the high performance computing world, linear algebra algorithms have to be reformulated or new algorithms have to be developed in order to take advantage of the architectural features on these new processors. Fine grain parallelism becomes a major requirement and introduces the necessity of loose synchronization in the parallel execution of an operation. This paper presents algorithms for the Cholesky, LU and QR factorization where the operations can be represented as a sequence of small tasks that operate on square blocks of data. These tasks can be dynamically scheduled for execution based on the dependencies among them and on the availability of computational resources. This may result in out of order execution of tasks which will completely hide the presence of intrinsically sequential tasks in the factorization. Performance comparisons are presented with LAPACK algorithms where parallelism can only be exploited at the level of the BLAS operations and vendor implementations. Published by Elsevier B.V.", "paper_title": "A class of parallel tiled linear algebra algorithms for multicore architectures", "paper_id": "WOS:000263480200004"}