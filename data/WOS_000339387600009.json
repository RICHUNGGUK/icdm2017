{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "document_clustering"}, {"score": 0.029223440443155526, "phrase": "subspace_learning"}, {"score": 0.004677711903652145, "phrase": "document_space"}, {"score": 0.004563182153397349, "phrase": "high_dimension"}, {"score": 0.004396600680348434, "phrase": "great_deal"}, {"score": 0.004360412703519539, "phrase": "redundant_information"}, {"score": 0.0043066860455264, "phrase": "high-dimensional_vectors"}, {"score": 0.0039649719120779066, "phrase": "low-dimensional_subspace"}, {"score": 0.0038518661517315533, "phrase": "document_vectors"}, {"score": 0.0036352070472201086, "phrase": "clustering_vectors"}, {"score": 0.0032780806856932423, "phrase": "vice_versa"}, {"score": 0.0030680994147125364, "phrase": "iterative_procedure"}, {"score": 0.0028127163745564777, "phrase": "initial_cluster_indicators"}, {"score": 0.002709862658377861, "phrase": "affinity_propagation"}, {"score": 0.0026107601878587816, "phrase": "specific_number"}, {"score": 0.002515272856011004, "phrase": "cluster_indicators"}, {"score": 0.0024535690077712034, "phrase": "asl"}, {"score": 0.0024232694434408093, "phrase": "obtained_subspace"}, {"score": 0.0023249757987087055, "phrase": "iterative_optimization"}, {"score": 0.0022962708568492734, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "conventional_methods"}], "paper_keywords": ["Document clustering", " Subspace learning", " K-affinity propagation"], "paper_abstract": "The performance of clustering in document space can be influenced by the high dimension of the vectors, because there exists a great deal of redundant information in the high-dimensional vectors, which may make the similarity between vectors inaccurate. Hence, it is very considerable to derive a low-dimensional subspace that contains less redundant information, so that document vectors can be grouped more reasonably. In general, learning a subspace and clustering vectors are treated as two independent steps; in this case, we cannot estimate whether the subspace is appropriate for the method of clustering or vice versa. To overcome this drawback, this paper combines subspace learning and clustering into an iterative procedure named adaptive subspace learning (ASL). Firstly, the intracluster similarity and the intercluster separability of vectors can be increased via the initial cluster indicators in the step of subspace learning, and then affinity propagation is adopted to partition the vectors into a specific number of clusters, so as to update the cluster indicators and repeat subspace learning. In ASL, the obtained subspace can become more suitable for the clustering with the iterative optimization. The proposed method is evaluated using NG20, Classic3 and K1b datasets, and the results are shown to be superior to the conventional methods of document clustering.", "paper_title": "Adaptive subspace learning: an iterative approach for document clustering", "paper_id": "WOS:000339387600009"}