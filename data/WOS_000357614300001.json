{"auto_keywords": [{"score": 0.03926714714893431, "phrase": "single_cell"}, {"score": 0.015719716506582538, "phrase": "cell_detection"}, {"score": 0.015599002431466464, "phrase": "redundant_candidate_regions"}, {"score": 0.015479200759850795, "phrase": "nonoverlapping_constraints"}, {"score": 0.015242307979733449, "phrase": "microscopy_images"}, {"score": 0.004594951819987416, "phrase": "automated_cell_behavior_analysis"}, {"score": 0.004559270778306828, "phrase": "cell_shape_analysis"}, {"score": 0.004523865550323285, "phrase": "cell_tracking"}, {"score": 0.004488734023485018, "phrase": "robust_cell_detection"}, {"score": 0.004453874101119545, "phrase": "high-density_and_low-contrast_images"}, {"score": 0.004217286731331736, "phrase": "cell_cluster"}, {"score": 0.004184526032558792, "phrase": "blurry_intercellular_boundaries"}, {"score": 0.004103728794623367, "phrase": "current_methods"}, {"score": 0.004040211152784802, "phrase": "multiple_cells"}, {"score": 0.003931402465972151, "phrase": "control_parameters"}, {"score": 0.0038404642251010797, "phrase": "touching_cells"}, {"score": 0.0035940277928341265, "phrase": "low-intensity_regions"}, {"score": 0.0032472646337850042, "phrase": "candidate_regions"}, {"score": 0.0030625949549620475, "phrase": "candidate_region"}, {"score": 0.0030269369940823902, "phrase": "main_part"}, {"score": 0.0029338597685088603, "phrase": "cell_candidate"}, {"score": 0.002911039832825817, "phrase": "supervised_learning"}, {"score": 0.0028436364707396613, "phrase": "optimal_set"}, {"score": 0.002821516317503421, "phrase": "cell_regions"}, {"score": 0.0027886573969044042, "phrase": "redundant_regions"}, {"score": 0.0027240799841720957, "phrase": "selected_region"}, {"score": 0.0026506222660465104, "phrase": "selected_regions"}, {"score": 0.002549096826249, "phrase": "optimal_region_selection"}, {"score": 0.002519402443228795, "phrase": "binary_linear_programming_problem"}, {"score": 0.002311933249234786, "phrase": "five_representative_methods"}, {"score": 0.002223351523626989, "phrase": "data_sets"}, {"score": 0.002206045784326466, "phrase": "experimental_application"}, {"score": 0.0021803388613879896, "phrase": "proposed_method"}], "paper_keywords": ["Bioimage informatics", " cell detection", " microscopy image"], "paper_abstract": "Cell detection in microscopy images is essential for automated cell behavior analysis including cell shape analysis and cell tracking. Robust cell detection in high-density and low-contrast images is still challenging since cells often touch and partially overlap, forming a cell cluster with blurry intercellular boundaries. In such cases, current methods tend to detect multiple cells as a cluster. If the control parameters are adjusted to separate the touching cells, other problems often occur: a single cell may be segmented into several regions, and cells in low-intensity regions may not be detected. To solve these problems, we first detect redundant candidate regions, which include many false positives but in turn very few false negatives, by allowing candidate regions to overlap with each other. Next, the score for how likely the candidate region contains the main part of a single cell is computed for each cell candidate using supervised learning. Then we select an optimal set of cell regions from the redundant regions under nonoverlapping constraints, where each selected region looks like a single cell and the selected regions do not overlap. We formulate this problem of optimal region selection as a binary linear programming problem under nonoverlapping constraints. We demonstrated the effectiveness of our method for several types of cells in microscopy images. Our method performed better than five representative methods, achieving an F-measure of over 0.9 for all data sets. Experimental application of the proposed method to 3-D images demonstrated that also works well for 3-D cell detection.", "paper_title": "Cell Detection From Redundant Candidate Regions Under Nonoverlapping Constraints", "paper_id": "WOS:000357614300001"}