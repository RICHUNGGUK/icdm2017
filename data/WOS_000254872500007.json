{"auto_keywords": [{"score": 0.03432017230737596, "phrase": "photometry_invariance"}, {"score": 0.00481495049065317, "phrase": "low_photon_counts"}, {"score": 0.004716520738331953, "phrase": "edge-preserving_filters"}, {"score": 0.0045726187330434025, "phrase": "local_m-smoothers"}, {"score": 0.004209893377338457, "phrase": "gaussian_noise"}, {"score": 0.003531474887552889, "phrase": "poissonian_noise"}, {"score": 0.0030239842475439814, "phrase": "filter_coefficients"}, {"score": 0.0028715299874549245, "phrase": "proposed_normalization"}, {"score": 0.0025100713447593773, "phrase": "strong_connection"}, {"score": 0.0024586427394152196, "phrase": "anisotropic_diffusion"}, {"score": 0.0022168460543913787, "phrase": "comparable_denoising_performances"}, {"score": 0.0021049977753042253, "phrase": "root_mean_square_error"}], "paper_keywords": ["edge-preserving filter", " local M-smoothers", " bilateral filtering", " anisotropic diffusion", " photometry invariance", " Poissonian noise"], "paper_abstract": "Edge-preserving filters such as local M-smoothers or bilateral filtering are usually designed for Gaussian noise. This paper investigates how these filters can be adapted in order to efficiently deal with Poissonian noise. In addition, the issue of photometry invariance is addressed by changing the way filter coefficients are normalized. The proposed normalization is additive, instead of being multiplicative, and leads to a strong connection with anisotropic diffusion. Experiments show that ensuring the photometry invariance leads to comparable denoising performances in terms of the root mean square error computed on the signal.", "paper_title": "Edge-preserving filtering of images with low photon counts", "paper_id": "WOS:000254872500007"}