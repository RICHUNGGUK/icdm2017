{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "unified_framework"}, {"score": 0.004760394308239882, "phrase": "joint_video_pedestrian_segmentation"}, {"score": 0.004706453355638515, "phrase": "pose_tracking._pedestrian_segmentation"}, {"score": 0.004653120760786245, "phrase": "pose_tracking"}, {"score": 0.004522406417999492, "phrase": "human_silhouettes"}, {"score": 0.0038332390893263844, "phrase": "related_methods"}, {"score": 0.003746779951069909, "phrase": "still_images"}, {"score": 0.0034395119150793787, "phrase": "monocular_videos"}, {"score": 0.003211883390828745, "phrase": "em-based_maximum_likelihood_estimation"}, {"score": 0.003051073364818384, "phrase": "bayesian_filtering"}, {"score": 0.0030164423559955896, "phrase": "body_silhouette"}, {"score": 0.002965229277927781, "phrase": "observation_cue"}, {"score": 0.0029148831519944358, "phrase": "pedestrian_segmentation"}, {"score": 0.0028490783932465288, "phrase": "guided_filtering"}, {"score": 0.002784755056588371, "phrase": "body_skeleton"}, {"score": 0.002442025065383455, "phrase": "hierarchical_shape"}, {"score": 0.0022933216359142736, "phrase": "first_frame"}, {"score": 0.0022287497627555895, "phrase": "pedestrian_datasets"}, {"score": 0.0021908807203548345, "phrase": "approach's_effectiveness"}, {"score": 0.0021659920594094407, "phrase": "cluttered_backgrounds"}], "paper_keywords": ["Pedestrian segmentation", " pose tracking", " hierarchical shape matching", " particle filtering", " guided filtering"], "paper_abstract": "Pedestrian segmentation and pose tracking are performed to infer human silhouettes and skeletons, respectively. Although the two tasks are complementary in nature, few works have been done on combining them together to improve each other, and some related methods are limited to still images. In this paper, we propose an approach to jointly solving them in monocular videos via a unified framework. Basically, the framework is built on EM-based maximum likelihood estimation, in which pose tracking is fulfilled through Bayesian filtering using body silhouette as an observation cue, and pedestrian segmentation is inferred by guided filtering with constraint of body skeleton. The two sets of parameters are alternatively updated along the video. In the initialization of the framework, we utilize a hierarchical shape matching scheme to obtain the silhouette and skeleton in the first frame. Experiments on challenging pedestrian datasets verify the approach's effectiveness to cluttered backgrounds, moving camera and various articulated bodies, and the performance is improved significantly by solving the two tasks together.", "paper_title": "A UNIFIED FRAMEWORK FOR JOINT VIDEO PEDESTRIAN SEGMENTATION AND POSE TRACKING", "paper_id": "WOS:000327353700009"}