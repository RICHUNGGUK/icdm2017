{"auto_keywords": [{"score": 0.04774398175413618, "phrase": "synthetic_data"}, {"score": 0.035507204238393285, "phrase": "matrix_mechanism"}, {"score": 0.00481495049065317, "phrase": "query_sets"}, {"score": 0.0047597635659244655, "phrase": "differentially-private_matrix_mechanism"}, {"score": 0.004651271219032404, "phrase": "privacy_research"}, {"score": 0.00451043437607004, "phrase": "formal_privacy_guarantee"}, {"score": 0.004307099985737249, "phrase": "original_data"}, {"score": 0.004241370886886689, "phrase": "reasonable_accuracy"}, {"score": 0.004192730391924712, "phrase": "synthetic_data_set"}, {"score": 0.004081385289516914, "phrase": "specified_set"}, {"score": 0.003808407814695708, "phrase": "differential_privacy"}, {"score": 0.003459191419478298, "phrase": "particular_case"}, {"score": 0.0034326732528567826, "phrase": "answering_sets"}, {"score": 0.0034063576796640603, "phrase": "linear_counting_queries"}, {"score": 0.003105824909705158, "phrase": "complex_correlated_noise"}, {"score": 0.0030583717270715556, "phrase": "specified_workload"}, {"score": 0.0029428772818833166, "phrase": "minimum_total_error"}, {"score": 0.0028317319086202217, "phrase": "workload_queries"}, {"score": 0.002683125911877974, "phrase": "query_workload"}, {"score": 0.002631959004685823, "phrase": "spectral_properties"}, {"score": 0.002542298702137655, "phrase": "matrix_form"}, {"score": 0.0023178219772486868, "phrase": "predicate_queries"}, {"score": 0.0022648637058989463, "phrase": "k-way_marginals"}, {"score": 0.002121281184742656, "phrase": "random_interval_queries"}, {"score": 0.0021049977753042253, "phrase": "random_marginals"}], "paper_keywords": ["Differential privacy", " Linear query", " Minimal error", " Spectral decomposition", " Lower bound"], "paper_abstract": "A common goal of privacy research is to release synthetic data that satisfies a formal privacy guarantee and can be used by an analyst in place of the original data. To achieve reasonable accuracy, a synthetic data set must be tuned to support a specified set of queries accurately, sacrificing fidelity for other queries. This work considers methods for producing synthetic data under differential privacy and investigates what makes a set of queries \"easy\" or \"hard\" to answer. We consider this issue in the particular case of answering sets of linear counting queries using the matrix mechanism (Li et al. 2010), a recent differentially-private mechanism that can reduce error by adding complex correlated noise adapted to a specified workload. Our main result is a novel lower bound on the minimum total error required to simultaneously release answers to a set of workload queries when using the matrix mechanism. The bound reveals that the hardness of a query workload is related to the spectral properties of the workload when it is represented in matrix form. Under (oee-, delta)-differential privacy, we prove that this bound is tight for many common workloads such as the set of all predicate queries and the set of all k-way marginals. Our empirical study also indicates this bound is close-to-tight on workloads consisting of random interval queries or random marginals.", "paper_title": "Lower Bounds on the Error of Query Sets Under the Differentially-Private Matrix Mechanism", "paper_id": "WOS:000365792200011"}