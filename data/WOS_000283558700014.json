{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "hidden_markov_models"}, {"score": 0.004762550320451225, "phrase": "nonelliptically_contoured_state_densities"}, {"score": 0.004558564684763264, "phrase": "popular_approach"}, {"score": 0.004484332781147261, "phrase": "sequential_data"}, {"score": 0.004435514622798228, "phrase": "continuous_attributes"}, {"score": 0.004292212137716459, "phrase": "observation_emission_densities"}, {"score": 0.004222299135545249, "phrase": "hmm_hidden_states"}, {"score": 0.004063547375196532, "phrase": "elliptically_contoured_distributions"}, {"score": 0.0040192915527630995, "phrase": "usually_multivariate_gaussian"}, {"score": 0.003975515793563275, "phrase": "student's-t_densities"}, {"score": 0.0038893838564184107, "phrase": "elliptically_contoured_distributions_cannot_sufficiently_model_heavy-tailed_or_skewed_populations"}, {"score": 0.003602302241898501, "phrase": "communication_signal_processing_domain"}, {"score": 0.0035435867326548665, "phrase": "finite_mixtures"}, {"score": 0.003429001377800258, "phrase": "hmm_state_densities"}, {"score": 0.003373101013123386, "phrase": "common_approach"}, {"score": 0.0031240075437664314, "phrase": "modeled_data"}, {"score": 0.0030229485340586473, "phrase": "large_number"}, {"score": 0.002989991779830814, "phrase": "mixture_components"}, {"score": 0.0029412271277166873, "phrase": "hmm_state"}, {"score": 0.0028460640294160383, "phrase": "negative_effect"}, {"score": 0.0027996401456881806, "phrase": "model_efficiency"}, {"score": 0.0027539714188091866, "phrase": "training_data"}, {"score": 0.0027389142053945246, "phrase": "set's_size"}, {"score": 0.0024276590297034064, "phrase": "nonelliptically_contoured_distribution"}, {"score": 0.0021399277552314067, "phrase": "skewed_and_heavy-tailed_populations"}, {"score": 0.0021049977753042253, "phrase": "simple_and_computationally_efficient_manner"}], "paper_keywords": ["Hidden Markov models", " multivariate normal inverse Gaussian (MNIG) distribution", " expectation-maximization", " sequential data modeling"], "paper_abstract": "Hidden Markov models (HMMs) are a popular approach for modeling sequential data comprising continuous attributes. In such applications, the observation emission densities of the HMM hidden states are typically modeled by means of elliptically contoured distributions, usually multivariate Gaussian or Student's-t densities. However, elliptically contoured distributions cannot sufficiently model heavy-tailed or skewed populations which are typical in many fields, such as the financial and the communication signal processing domain. Employing finite mixtures of such elliptically contoured distributions to model the HMM state densities is a common approach for the amelioration of these issues. Nevertheless, the nature of the modeled data often requires postulation of a large number of mixture components for each HMM state, which might have a negative effect on both model efficiency and the training data set's size required to avoid overfitting. To resolve these issues, in this paper, we advocate for the utilization of a nonelliptically contoured distribution, the multivariate normal inverse Gaussian (MNIG) distribution, for modeling the observation densities of HMMs. As we experimentally demonstrate, our selection allows for more effective modeling of skewed and heavy-tailed populations in a simple and computationally efficient manner.", "paper_title": "Hidden Markov Models with Nonelliptically Contoured State Densities", "paper_id": "WOS:000283558700014"}