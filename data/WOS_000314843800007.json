{"auto_keywords": [{"score": 0.03259375215011238, "phrase": "maximum_margin_classification_constraints"}, {"score": 0.010612387000973441, "phrase": "multiplicative_update_rules"}, {"score": 0.009856984170001828, "phrase": "nmf"}, {"score": 0.004770461993586338, "phrase": "concurrent_nonnegative_matrix_factorization"}, {"score": 0.004617949594931096, "phrase": "state-of-the-art_classification_methods"}, {"score": 0.004347473906950474, "phrase": "first_one"}, {"score": 0.004307286039184164, "phrase": "data_transformation"}, {"score": 0.004169519409162853, "phrase": "second_one"}, {"score": 0.00411182818527434, "phrase": "transformed_data"}, {"score": 0.004073809704022463, "phrase": "classification_methods"}, {"score": 0.003764469758319617, "phrase": "nmf_factorization"}, {"score": 0.003712362078915926, "phrase": "svm_classification"}, {"score": 0.0034303736977646135, "phrase": "support_vectors"}, {"score": 0.0032898346872897383, "phrase": "suboptimal_classification_performance"}, {"score": 0.0030398432591176357, "phrase": "standard_nmf_optimization"}, {"score": 0.002956209594959227, "phrase": "proposed_framework"}, {"score": 0.0027827907725673845, "phrase": "projected_data"}, {"score": 0.0026811531172346676, "phrase": "concurrent_nmf_factorization"}, {"score": 0.002656327554326748, "phrase": "support_vector_optimization"}, {"score": 0.002431626477893495, "phrase": "nmf_problem"}, {"score": 0.0024091057723923857, "phrase": "additional_discriminant_constraints"}, {"score": 0.0023867931451842087, "phrase": "respective_multiplicative_update_rules"}, {"score": 0.002267708463966758, "phrase": "nmf_factorization_problem"}, {"score": 0.0022258906408344973, "phrase": "section_vi._experimental_results"}, {"score": 0.0021049977753042253, "phrase": "nmf_and_discriminant_nmf_objective_functions"}], "paper_keywords": ["Joint optimization", " maximum margin classification", " nonnegative matrix factorization (NMF)", " support vector machines (SVMs)"], "paper_abstract": "The state-of-the-art classification methods which employ nonnegative matrix factorization (NMF) employ two consecutive independent steps. The first one performs data transformation (dimensionality reduction) and the second one classifies the transformed data using classification methods, such as nearest neighbor/centroid or support vector machines (SVMs). In the following, we focus on using NMF factorization followed by SVM classification. Typically, the parameters of these two steps, e. g., the NMF bases/coefficients and the support vectors, are optimized independently, thus leading to suboptimal classification performance. In this paper, we merge these two steps into one by incorporating maximum margin classification constraints into the standard NMF optimization. The notion behind the proposed framework is to perform NMF, while ensuring that the margin between the projected data of the two classes is maximal. The concurrent NMF factorization and support vector optimization are performed through a set of multiplicative update rules. In the same context, the maximum margin classification constraints are imposed on the NMF problem with additional discriminant constraints and respective multiplicative update rules are extracted. The impact of the maximum margin classification constraints on the NMF factorization problem is addressed in Section VI. Experimental results in several databases indicate that the incorporation of the maximum margin classification constraints into the NMF and discriminant NMF objective functions improves the accuracy of the classification.", "paper_title": "Multiplicative Update Rules for Concurrent Nonnegative Matrix Factorization and Maximum Margin Classification", "paper_id": "WOS:000314843800007"}