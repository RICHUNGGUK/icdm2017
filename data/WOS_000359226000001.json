{"auto_keywords": [{"score": 0.043078709258480896, "phrase": "deduplication_process"}, {"score": 0.03192280240290009, "phrase": "first_stage"}, {"score": 0.004814986962035431, "phrase": "practical"}, {"score": 0.0046659637258752535, "phrase": "large_scale_deduplication"}, {"score": 0.004603525341738782, "phrase": "data_deduplication_task"}, {"score": 0.004521566043596533, "phrase": "considerable_amount"}, {"score": 0.004421156723819163, "phrase": "research_community"}, {"score": 0.004322967486451877, "phrase": "effective_and_efficient_solutions"}, {"score": 0.003969250376327401, "phrase": "manually_labeled_pairs"}, {"score": 0.0038119123317396954, "phrase": "labeled_set"}, {"score": 0.0037608593980593035, "phrase": "daunting_task"}, {"score": 0.0035794251590584563, "phrase": "large_number"}, {"score": 0.0035473867669654174, "phrase": "informative_pairs"}, {"score": 0.003406713877432236, "phrase": "two-stage_sampling_selection_strategy"}, {"score": 0.0033011569787033297, "phrase": "reduced_set"}, {"score": 0.0031845067058084583, "phrase": "large_datasets"}, {"score": 0.002910545717767559, "phrase": "balanced_subsets"}, {"score": 0.0028844769395018595, "phrase": "candidate_pairs"}, {"score": 0.0028076592725295646, "phrase": "second_stage"}, {"score": 0.00277001889871322, "phrase": "active_selection"}, {"score": 0.0026841368358805433, "phrase": "redundant_pairs"}, {"score": 0.0025316254589087973, "phrase": "even_smaller_and_more_informative_training"}, {"score": 0.0021920373388760314, "phrase": "labeling_effort"}, {"score": 0.002143247921132179, "phrase": "competitive_or_superior_matching_quality"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_deduplication_methods"}], "paper_keywords": ["Deduplication", " signature-based deduplication"], "paper_abstract": "The data deduplication task has attracted a considerable amount of attention from the research community in order to provide effective and efficient solutions. The information provided by the user to tune the deduplication process is usually represented by a set of manually labeled pairs. In very large datasets, producing this kind of labeled set is a daunting task since it requires an expert to select and label a large number of informative pairs. In this article, we propose a two-stage sampling selection strategy (T3S) that selects a reduced set of pairs to tune the deduplication process in large datasets. T3S selects the most representative pairs by following two stages. In the first stage, we propose a strategy to produce balanced subsets of candidate pairs for labeling. In the second stage, an active selection is incrementally invoked to remove the redundant pairs in the subsets created in the first stage in order to produce an even smaller and more informative training set. This training set is effectively used both to identify where the most ambiguous pairs lie and to configure the classification approaches. Our evaluation shows that T3S is able to reduce the labeling effort substantially while achieving a competitive or superior matching quality when compared with state-of-the-art deduplication methods in large datasets.", "paper_title": "A Practical and Effective Sampling Selection Strategy for Large Scale Deduplication", "paper_id": "WOS:000359226000001"}