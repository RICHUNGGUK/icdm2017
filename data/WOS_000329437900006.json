{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "web_queries"}, {"score": 0.004665296491645837, "phrase": "increasing_amount"}, {"score": 0.0046164478775379105, "phrase": "biased_and_opinionated_documents"}, {"score": 0.004449452743965974, "phrase": "polarizing_events"}, {"score": 0.004243552607799184, "phrase": "indepth_analysis"}, {"score": 0.004199101289890982, "phrase": "web_search_queries"}, {"score": 0.004155113657645735, "phrase": "controversial_topics"}, {"score": 0.004068510313497539, "phrase": "query_sentiment"}, {"score": 0.0039006600544599537, "phrase": "extensive_user_assessments"}, {"score": 0.0038597866217852353, "phrase": "discriminative_term_analyses"}, {"score": 0.0037397086147485897, "phrase": "sentiment_analysis"}, {"score": 0.0036810726176482278, "phrase": "sentiwordnet_thesaurus"}, {"score": 0.0035665344993417603, "phrase": "sentiment_annotations"}, {"score": 0.003278167066287366, "phrase": "different_classifiers"}, {"score": 0.003226744277130179, "phrase": "query_texts"}, {"score": 0.0031929098985796814, "phrase": "query_result_titles"}, {"score": 0.003028969851366049, "phrase": "query_sentiment_detection"}, {"score": 0.0028886123801902517, "phrase": "query_recommendation_scenario"}, {"score": 0.0028432828877281388, "phrase": "sentiment_detection"}, {"score": 0.002769304577201566, "phrase": "additional_queries"}, {"score": 0.002740253546178098, "phrase": "polarized_queries"}, {"score": 0.002697245874076643, "phrase": "search_engine_users"}, {"score": 0.002654911400878851, "phrase": "second_application_scenario"}, {"score": 0.0026270572353632297, "phrase": "controversial_topic_discovery"}, {"score": 0.0025858215477025117, "phrase": "query_sentiment_classifiers"}, {"score": 0.002518525107994039, "phrase": "previously_unknown_topics"}, {"score": 0.0024659480471085405, "phrase": "highly_positive_and_negative_opinions"}, {"score": 0.0023891283748647416, "phrase": "search_engine"}, {"score": 0.002242577809454225, "phrase": "real-world_data"}, {"score": 0.0021273284545701896, "phrase": "query_sentiment_analysis"}, {"score": 0.0021049977753042253, "phrase": "practical_scenarios"}], "paper_keywords": ["Algorithms", " Experimentation", " Opinionated queries", " sentiment analysis", " Web search"], "paper_abstract": "The Web contains an increasing amount of biased and opinionated documents on politics, products, and polarizing events. In this article, we present an indepth analysis of Web search queries for controversial topics, focusing on query sentiment. To this end, we conduct extensive user assessments and discriminative term analyses, as well as a sentiment analysis using the SentiWordNet thesaurus, a lexical resource containing sentiment annotations. Furthermore, in order to detect the sentiment expressed in queries, we build different classifiers based on query texts, query result titles, and snippets. We demonstrate the virtue of query sentiment detection in two different use cases. First, we define a query recommendation scenario that employs sentiment detection of results to recommend additional queries for polarized queries issued by search engine users. The second application scenario is controversial topic discovery, where query sentiment classifiers are employed to discover previously unknown topics that trigger both highly positive and negative opinions among the users of a search engine. For both use cases, the results of our evaluations on real-world data are promising and show the viability and potential of query sentiment analysis in practical scenarios.", "paper_title": "Analyzing, Detecting, and Exploiting Sentiment in Web Queries", "paper_id": "WOS:000329437900006"}