{"auto_keywords": [{"score": 0.04224478442118721, "phrase": "dance_performance"}, {"score": 0.00481495049065317, "phrase": "computer_graphics"}, {"score": 0.0047563776685277314, "phrase": "considerable_research"}, {"score": 0.00461302961851157, "phrase": "realistic_human_motion_synthesis"}, {"score": 0.004419538941706716, "phrase": "human_emotional_aspects"}, {"score": 0.004260134699483774, "phrase": "human_motion"}, {"score": 0.00410645614623058, "phrase": "new_approach"}, {"score": 0.003958299299658418, "phrase": "input_music"}, {"score": 0.0038389110156920926, "phrase": "emotional_aspects"}, {"score": 0.0036553070575015344, "phrase": "motion_analysis"}, {"score": 0.0035887342563437935, "phrase": "music_analysis"}, {"score": 0.003501846136829077, "phrase": "motion_synthesis"}, {"score": 0.003417054482155433, "phrase": "extracted_features"}, {"score": 0.003334309053314909, "phrase": "analysis_steps"}, {"score": 0.003293688299319582, "phrase": "motion_and_music_feature_vectors"}, {"score": 0.003213920601037463, "phrase": "motion_vectors"}, {"score": 0.0031360786664165093, "phrase": "motion_rhythm"}, {"score": 0.0030414140732789186, "phrase": "music_vectors"}, {"score": 0.0029677378488677983, "phrase": "musical_rhythm"}, {"score": 0.002723607240517261, "phrase": "candidate_motion_segments"}, {"score": 0.00259320616168125, "phrase": "music_segment"}, {"score": 0.0024842242921857705, "phrase": "motion_segment"}, {"score": 0.0023652572260178637, "phrase": "music_segments"}, {"score": 0.002224510044064184, "phrase": "synthesis_process"}, {"score": 0.002183938718432764, "phrase": "desired_motion_segments"}, {"score": 0.0021441057555396013, "phrase": "specified_music_segments"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": [""], "paper_abstract": "In computer graphics, considerable research has been conducted on realistic human motion synthesis. However most research does not consider human emotional aspects, which often strongly affect human motion. This paper presents a new approach for synthesizing dance performance matched to input music, based on the emotional aspects of dance performance. Our method consists of a motion analysis, a music analysis, and a motion synthesis based on the extracted features. In the analysis steps, motion and music feature vectors are acquired. Motion vectors are derived from motion rhythm and intensity, while music vectors are derived from musical rhythm, structure, and intensity. For synthesizing dance performance, we first find candidate motion segments whose rhythm features are matched to those of each music segment, and then we find the motion segment set whose intensity is similar to that of music segments. Additionally, our system supports having animators control the synthesis process by assigning desired motion segments to the specified music segments. The experimental results indicate that our method actually creates dance performance as if a character was listening and expressively dancing to the music.", "paper_title": "Dancing-to-music character animation", "paper_id": "WOS:000240736800024"}