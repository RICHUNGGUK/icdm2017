{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "emotional_impact"}, {"score": 0.004737579882204798, "phrase": "bayesian_multiple_kernel_learning"}, {"score": 0.004404445045826858, "phrase": "emerging_research_areas"}, {"score": 0.0043161190928529755, "phrase": "previous_research"}, {"score": 0.004195418010131832, "phrase": "feature_extraction_methods"}, {"score": 0.0041112665381266315, "phrase": "multimedia_content"}, {"score": 0.004028796143006953, "phrase": "different_feature_representations"}, {"score": 0.003822003373331997, "phrase": "people's_emotions"}, {"score": 0.003640516896245813, "phrase": "novel_bayesian_multiple_kernel"}, {"score": 0.0035819501337406596, "phrase": "affective_classification"}, {"score": 0.0035530197642369464, "phrase": "retrieval_tasks"}, {"score": 0.0035100601949451028, "phrase": "proposed_method"}, {"score": 0.003439608110599787, "phrase": "different_representations"}, {"score": 0.003289534854212415, "phrase": "better_prediction_performance"}, {"score": 0.003236596168242036, "phrase": "single_feature_representation"}, {"score": 0.0029965060407413898, "phrase": "automatic_feature_selections"}, {"score": 0.002865710140187219, "phrase": "multilabel_setup"}, {"score": 0.002751751956416832, "phrase": "bayesian_formulation"}, {"score": 0.002696479050724968, "phrase": "probabilistic_outputs"}, {"score": 0.0025892330566358503, "phrase": "single_image"}, {"score": 0.002547535564922075, "phrase": "case_study"}, {"score": 0.002506507889886399, "phrase": "classification_and_retrieval_experiments"}, {"score": 0.0024461989110005447, "phrase": "people's_emotional_states"}, {"score": 0.002387337550919433, "phrase": "generic_low-level_image_features"}, {"score": 0.0023016843709107297, "phrase": "widely-used_international_affective_picture_system"}, {"score": 0.002183347623351868, "phrase": "classification_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Image emotions", " Multiple kernel learning", " Multiview learning", " Variational approximation", " Low-level image features"], "paper_abstract": "Affective classification and retrieval of multimedia such as audio, image, and video have become emerging research areas in recent years. The previous research focused on designing features and developing feature extraction methods. Generally, a multimedia content can be represented with different feature representations (i.e., views). However, the most suitable feature representation related to people's emotions is usually not known a priori. We propose here a novel Bayesian multiple kernel learning algorithm for affective classification and retrieval tasks. The proposed method can make use of different representations simultaneously (i.e., multiview learning) to obtain a better prediction performance than using a single feature representation (i.e., single-view learning) or a subset of features, with the advantage of automatic feature selections. In particular, our algorithm has been implemented within a multilabel setup to capture the correlation between emotions, and the Bayesian formulation enables our method to produce probabilistic outputs for measuring a set of emotions triggered by a single image. As a case study, we perform classification and retrieval experiments with our algorithm for predicting people's emotional states evoked by images, using generic low-level image features. The empirical results with our approach on the widely-used International Affective Picture System (IAPS) data set outperform several existing methods in terms of classification performance and results interpretability. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Understanding emotional impact of images using Bayesian multiple kernel learning", "paper_id": "WOS:000356747700002"}