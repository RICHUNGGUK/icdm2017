{"auto_keywords": [{"score": 0.044619395217733046, "phrase": "shared_memory_systems"}, {"score": 0.00481495049065317, "phrase": "scalable_java_communications"}, {"score": 0.004687645903373103, "phrase": "java_implementation"}, {"score": 0.004230160649921963, "phrase": "java"}, {"score": 0.00419229472352669, "phrase": "nonblocking_collectives"}, {"score": 0.003991196463806465, "phrase": "collective_operations"}, {"score": 0.003902992784453769, "phrase": "message_passing_codes"}, {"score": 0.003732368382223596, "phrase": "point-to-point_primitives"}, {"score": 0.0034437574674180365, "phrase": "current_trend"}, {"score": 0.003191636645925296, "phrase": "multi-core_and_many-core_processors"}, {"score": 0.0030932495918679285, "phrase": "remote_direct_memory_access"}, {"score": 0.0030656984915295275, "phrase": "thread-based_progression"}, {"score": 0.0030113280682863234, "phrase": "pure_multi"}, {"score": 0.002971182100871581, "phrase": "shared_memory_support"}, {"score": 0.0028667159745494933, "phrase": "imposed_synchronization"}, {"score": 0.0027535633837592597, "phrase": "distributed_memory_scenario"}, {"score": 0.0026686444508167875, "phrase": "shared_memory"}, {"score": 0.002473129577319634, "phrase": "fastmpj"}, {"score": 0.0023437863565921053, "phrase": "representative_shared_memory_system"}, {"score": 0.0023125191783901367, "phrase": "significant_improvements"}, {"score": 0.002241171326888997, "phrase": "implicit_synchronization"}, {"score": 0.0022013916728990564, "phrase": "barely_any_overhead"}, {"score": 0.0021720199689914464, "phrase": "common_blocking_operations"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["collective operations", " Java multi-threading", " Message Passing in Java (MPJ)", " MPI 3.0", " nonblocking collectives", " shared memory architectures"], "paper_abstract": "This paper presents a Java implementation of the recently published MPI 3.0 nonblocking message passing collectives in order to analyze and assess the feasibility of taking advantage of these operations in shared memory systems using Java. Nonblocking collectives aim to exploit the overlapping between computation and communication for collective operations to increase scalability of message passing codes, as it has been carried out for nonblocking point-to-point primitives. This scalability has become crucial not only for clusters but also for shared memory systems because of the current trend of increasing the number of cores per chip, which is leading to the generalization of multi-core and many-core processors. Message passing libraries based on remote direct memory access, thread-based progression, or implementing pure multi-threading shared memory support could potentially benefit from the lack of imposed synchronization by nonblocking collectives. But, although the distributed memory scenario has been well studied, the shared memory one has not been tackled yet. Hence, nonblocking collectives support has been included in FastMPJ, a Message Passing in Java (MPJ) implementation, and evaluated on a representative shared memory system, obtaining significant improvements because of overlapping and lack of implicit synchronization, and with barely any overhead imposed over common blocking operations. Copyright (C) 2014 John Wiley & Sons, Ltd.", "paper_title": "Nonblocking collectives for scalable Java communications", "paper_id": "WOS:000351682800006"}