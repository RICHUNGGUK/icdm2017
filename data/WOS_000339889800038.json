{"auto_keywords": [{"score": 0.046429977017780094, "phrase": "training_samples"}, {"score": 0.007744584865282426, "phrase": "underlining_space"}, {"score": 0.00481495049065317, "phrase": "hand_gesture_recognition"}, {"score": 0.004710306419574744, "phrase": "previous_research"}, {"score": 0.004669085371587273, "phrase": "human_machine_interaction"}, {"score": 0.004201571673071299, "phrase": "training-required_methods"}, {"score": 0.004146510711518748, "phrase": "small_number"}, {"score": 0.00403853528823342, "phrase": "poor_or_user-independent_performance"}, {"score": 0.0038647641000798135, "phrase": "time-consuming_and_laborious_sample_collection_processes"}, {"score": 0.003747575730190958, "phrase": "high-performance_training-free_approach"}, {"score": 0.003477505397536663, "phrase": "gesture_generation"}, {"score": 0.0034319005131102495, "phrase": "physical_meaning"}, {"score": 0.0034018288705284427, "phrase": "acceleration_direction"}, {"score": 0.0031565959573536194, "phrase": "gesture_trails"}, {"score": 0.0030206579994328975, "phrase": "gesture_recognition_devices"}, {"score": 0.002941913249957503, "phrase": "gesture_template_generation_process"}, {"score": 0.002790511479398411, "phrase": "training-free_gesture_recognition"}, {"score": 0.002682081928174864, "phrase": "original_acceleration_sequence"}, {"score": 0.0024667783849055634, "phrase": "dynamic_programming"}, {"score": 0.0023918783117166326, "phrase": "gesture_recognition_process"}, {"score": 0.0023501014144112443, "phrase": "system_performance"}, {"score": 0.0022290883852844057, "phrase": "training-free_algorithm"}, {"score": 0.0021709339252206825, "phrase": "traditional_training-required_algorithms"}, {"score": 0.0021518875024104244, "phrase": "hidden_markov_model"}, {"score": 0.002133029105165795, "phrase": "hmm"}, {"score": 0.0021049977753042253, "phrase": "dynamic_time_warping"}], "paper_keywords": ["Training-free", " Gesture recognition", " Accelerometer"], "paper_abstract": "In previous research on human machine interaction, parameters or templates of gestures are always learnt from training samples first and then a certain kind of matching is conducted. For these training-required methods, a small number of training samples always result in poor or user-independent performance, while a large quantity of training samples lead to time-consuming and laborious sample collection processes. In this paper, a high-performance training-free approach for hand gesture recognition with accelerometer is proposed. First, we determine the underlining space for gesture generation with the physical meaning of acceleration direction. Then, the template of each gesture in the underlining space can be generated from the gesture trails, which are frequently provided in the instructions of gesture recognition devices. Thus, during the gesture template generation process, the algorithm does not require training samples any more and fulfills training-free gesture recognition. After that, a feature extraction method, which transforms the original acceleration sequence into a sequence of more user-invariant features in the underlining space, and a more robust template matching method, which is based on dynamic programming, are presented to finish the gesture recognition process and enhance the system performance. Our algorithm is tested in a 28-user experiment with 2,240 gesture samples and this training-free algorithm shows better performance than the traditional training-required algorithms of Hidden Markov Model (HMM) and Dynamic Time Warping (DTW).", "paper_title": "A high-performance training-free approach for hand gesture recognition with accelerometer", "paper_id": "WOS:000339889800038"}