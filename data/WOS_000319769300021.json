{"auto_keywords": [{"score": 0.048636009815037955, "phrase": "training_algorithm"}, {"score": 0.00481495049065317, "phrase": "standard_autoassociative_neural_network"}, {"score": 0.004563880494020726, "phrase": "near-optimal_number"}, {"score": 0.004494570360108983, "phrase": "nonlinear_principal_components"}, {"score": 0.0042928648367867835, "phrase": "meaningful_nlpcs"}, {"score": 0.0035722806911457545, "phrase": "new_refinements"}, {"score": 0.0034911335714333507, "phrase": "network_structure"}, {"score": 0.0029722900280316216, "phrase": "local_nonlinear_principal_component_analysis"}, {"score": 0.0027529929913806066, "phrase": "stock_price_database"}, {"score": 0.002649472341607234, "phrase": "different_situations"}, {"score": 0.002435190484324197, "phrase": "last_section"}, {"score": 0.0023798115577749225, "phrase": "proposed_structures"}, {"score": 0.0021872912745910127, "phrase": "efficient_tools"}, {"score": 0.0021375377706211686, "phrase": "wide_range"}, {"score": 0.0021049977753042253, "phrase": "signal_processing_applications"}], "paper_keywords": ["Autoassociative neural network", " Nonlinear principal component analysis", " Constructive and destructive neural networks", " Reinforcement learning", " Genetic algorithm", " Recurrent neural networks"], "paper_abstract": "Improving the training algorithm, determining near-optimal number of nonlinear principal components (NLPCs), extracting meaningful NLPCs, and increasing the nonlinear, dynamic, and selective processing capability of the standard autoassociative neural network are the objectives of this article that are achieved independently by some new refinements of the network structure and the training algorithm. In addition, three different topologies of the network are presented, which make it possible to perform local nonlinear principal component analysis. Performances of all methods are evaluated by a stock price database that demonstrates their efficiency in different situations. Finally, as it will be illustrated in the last section, the proposed structures can be easily combined together, which introduce them as efficient tools in a wide range of signal processing applications.", "paper_title": "Some refinements of the standard autoassociative neural network", "paper_id": "WOS:000319769300021"}