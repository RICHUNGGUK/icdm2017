{"auto_keywords": [{"score": 0.032743607062757925, "phrase": "verbal_descriptions"}, {"score": 0.00481495049065317, "phrase": "unconstrained_face_recognition"}, {"score": 0.00466684417181804, "phrase": "media_collection"}, {"score": 0.004602483094756597, "phrase": "recognition_applications_progress"}, {"score": 0.0045547927862194856, "phrase": "sensing_and_cooperative_subjects_scenarios"}, {"score": 0.00436890075128947, "phrase": "unconstrained_scenarios"}, {"score": 0.004338661611644755, "phrase": "uncooperative_subjects"}, {"score": 0.004219774794569897, "phrase": "new_challenges"}, {"score": 0.004061584718427419, "phrase": "ambient_illumination"}, {"score": 0.0040334640350288, "phrase": "image_resolution"}, {"score": 0.004005537264228818, "phrase": "background_clutter"}, {"score": 0.0039778030796649416, "phrase": "facial_pose"}, {"score": 0.00386876598761639, "phrase": "forensic_investigations"}, {"score": 0.00367228341822469, "phrase": "low_quality_face_images"}, {"score": 0.0029295314433077134, "phrase": "face_sketch"}, {"score": 0.002899125545529459, "phrase": "ancillary_information"}, {"score": 0.002723186210025975, "phrase": "traditional_face_matching_methods"}, {"score": 0.002685558057339722, "phrase": "single_media"}, {"score": 0.0024704333220467393, "phrase": "entire_gamut"}, {"score": 0.0023942700905678735, "phrase": "single_candidate_list"}, {"score": 0.0023043558058824572, "phrase": "proposed_approach"}, {"score": 0.0021871503075921537, "phrase": "different_fusion_schemes"}, {"score": 0.002134508934917511, "phrase": "quality_measures"}, {"score": 0.0021049977753042253, "phrase": "video_frame_selection"}], "paper_keywords": ["Unconstrained face recognition", " uncooperative subjects", " media collection", " quality-based fusion", " still face image", " video track", " 3D face model", " face sketch", " demographics"], "paper_abstract": "As face recognition applications progress from constrained sensing and cooperative subjects scenarios (e.g., driver's license and passport photos) to unconstrained scenarios with uncooperative subjects (e.g., video surveillance), new challenges are encountered. These challenges are due to variations in ambient illumination, image resolution, background clutter, facial pose, expression, and occlusion. In forensic investigations where the goal is to identify a person of interest, often based on low quality face images and videos, we need to utilize whatever source of information is available about the person. This could include one or more video tracks, multiple still images captured by bystanders (using, for example, their mobile phones), 3-D face models constructed from image(s) and video(s), and verbal descriptions of the subject provided by witnesses. These verbal descriptions can be used to generate a face sketch and provide ancillary information about the person of interest (e.g., gender, race, and age). While traditional face matching methods generally take a single media (i.e., a still face image, video track, or face sketch) as input, this paper considers using the entire gamut of media as a probe to generate a single candidate list for the person of interest. We show that the proposed approach boosts the likelihood of correctly identifying the person of interest through the use of different fusion schemes, 3-D face models, and incorporation of quality measures for fusion and video frame selection.", "paper_title": "Unconstrained Face Recognition: Identifying a Person of Interest From a Media Collection", "paper_id": "WOS:000353289900012"}