{"auto_keywords": [{"score": 0.04177709856406242, "phrase": "optimal_policy"}, {"score": 0.004815011990636194, "phrase": "pomdps"}, {"score": 0.004650599164288254, "phrase": "markov"}, {"score": 0.004395984840790689, "phrase": "complex_task"}, {"score": 0.0033682492486884364, "phrase": "good_low-dimensional_spaces"}, {"score": 0.0033213460816510685, "phrase": "multi-agent_co-operative_learning_domains"}, {"score": 0.0030319482153908037, "phrase": "online_algorithm"}, {"score": 0.003010757286626405, "phrase": "cmeas"}, {"score": 0.0028866770996648057, "phrase": "pomdp_model"}, {"score": 0.002729133029776093, "phrase": "look-ahead_search"}, {"score": 0.002653606593103781, "phrase": "best_action"}, {"score": 0.0024912073108138613, "phrase": "overwhelming_complexity"}, {"score": 0.002371783323468861, "phrase": "possible_situation"}, {"score": 0.0022110183535859374, "phrase": "good_strategy"}, {"score": 0.0021347607855562102, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "multiple_agents"}], "paper_keywords": ["online algorithm", " multi-agent", " co-operative learning", " POMDPs"], "paper_abstract": "Solving partially observable Markov decision processes (POMDPs) is a complex task that is often intractable. This paper examines the problem of finding an optimal policy for POMDPs. While a lot of effort has been made to develop algorithms to solve POMDPs, the question of automatically finding good low-dimensional spaces in multi-agent co-operative learning domains has not been explored thoroughly. To identify this question, an online algorithm CMEAS is presented to improve the POMDP model. This algorithm is based on a look-ahead search to find the best action to execute at each cycle. Thus the overwhelming complexity of computing a policy for each possible situation is avoided. A series of simulations demonstrate this good strategy and performance of the proposed algorithm when multiple agents co-operate to find all optimal policy for POMDPs.", "paper_title": "An online multi-agent co-operative learning algorithm in POMDPs", "paper_id": "WOS:000262848800004"}