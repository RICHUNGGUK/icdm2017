{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "corrupted_silhouettes"}, {"score": 0.049593242225692294, "phrase": "sub-manifold_voting_strategy"}, {"score": 0.028745127034287252, "phrase": "human_poses"}, {"score": 0.004591120854640081, "phrase": "learning-based_framework"}, {"score": 0.004529093447865156, "phrase": "human_pose_estimation"}, {"score": 0.004498393285602365, "phrase": "complicated_environments"}, {"score": 0.004467900288375827, "phrase": "human_silhouettes"}, {"score": 0.0044225461990535855, "phrase": "input_images"}, {"score": 0.004245667843980468, "phrase": "motion_blur"}, {"score": 0.004145760434798249, "phrase": "corrupted_body_silhouette"}, {"score": 0.004048194450210347, "phrase": "corresponding_pose_structure"}, {"score": 0.00395291546135423, "phrase": "input_silhouette"}, {"score": 0.0038862297330905836, "phrase": "basic_assumption"}, {"score": 0.0035571129372263532, "phrase": "training_data"}, {"score": 0.0034497831301482144, "phrase": "robust_statistical_method"}, {"score": 0.003357091486708983, "phrase": "uncorrupted_components"}, {"score": 0.0031899334050985175, "phrase": "gaussian_process"}, {"score": 0.0031254169757175257, "phrase": "low-dimensional_manifold"}, {"score": 0.003104201872147936, "phrase": "visual_input_data"}, {"score": 0.0030414140732789186, "phrase": "sub-manifold_corresponding"}, {"score": 0.002939568952175845, "phrase": "traditional_methods"}, {"score": 0.0029096837584084182, "phrase": "likelihood_probability"}, {"score": 0.0028026735035370206, "phrase": "learned_sub-manifolds"}, {"score": 0.002681255756642227, "phrase": "proposed_learning-based_framework"}, {"score": 0.002618064695883914, "phrase": "input_human_pose"}, {"score": 0.0025914395870574787, "phrase": "latent_space"}, {"score": 0.002565084553019013, "phrase": "intrinsic_pose"}, {"score": 0.0024372660612788184, "phrase": "outlier_rejection"}, {"score": 0.0023717148226629105, "phrase": "great_ability"}, {"score": 0.0023158019935841235, "phrase": "small_computational_burden"}, {"score": 0.0021484955960643167, "phrase": "shadowed_and_noisy_environments"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Gaussian Processes", " Manifold", " Human pose estimation", " Robust statistics", " Voting"], "paper_abstract": "In this paper, a learning-based framework is proposed for human pose estimation in complicated environments. Human silhouettes extracted from input images are always incomplete and corrupted due to shadows, occlusions, motion blur, or foreground/background color similarity. Given a corrupted body silhouette, our goal is to infer the corresponding pose structure robustly, and to reconstruct the input silhouette as well. The basic assumption of our method is that the body pose (and configuration) can be indicated by some parts (components) of the silhouette given a training data set. Based on this assumption, a robust statistical method is applied to gather the information from uncorrupted components, and to ignore the effects from the outliers. In this method, Gaussian Process is used to learn the low-dimensional manifold of visual input data, and to create the sub-manifold corresponding to each component of the silhouette. Different from traditional methods, the likelihood probability is computed by means of a sub-manifold voting strategy based on the learned sub-manifolds. By fusing the likelihood and the prior of human poses, the proposed learning-based framework can specify the location of the input human pose in the latent space. The intrinsic pose and configuration can then be deduced from this location, or be refined after outlier rejection. Experiments show that our approach has a great ability to estimate human poses from corrupted Silhouettes with small computational burden. Therefore, it can be applied for tracking initialization, 3D pose estimation, 2D configuration reconstruction in occluded, shadowed and noisy environments. (c) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Human pose estimation from corrupted silhouettes using a sub-manifold voting strategy in latent variable space", "paper_id": "WOS:000263634500010"}