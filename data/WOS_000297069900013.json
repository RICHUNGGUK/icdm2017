{"auto_keywords": [{"score": 0.025325674119790528, "phrase": "lasso"}, {"score": 0.00481495049065317, "phrase": "sparse_algorithms"}, {"score": 0.004551199992546761, "phrase": "no-free-lunch_theorem"}, {"score": 0.0037363522297378777, "phrase": "good_generalization_ability"}, {"score": 0.0032145922365231093, "phrase": "sparse_algorithm"}, {"score": 0.002613709503583786, "phrase": "learning_algorithm"}, {"score": 0.0021049977753042253, "phrase": "strong_stability_properties"}], "paper_keywords": ["Stability", " sparsity", " Lasso", " regularization"], "paper_abstract": "We consider two desired properties of learning algorithms: sparsity and algorithmic stability. Both properties are believed to lead to good generalization ability. We show that these two properties are fundamentally at odds with each other: A sparse algorithm cannot be stable and vice versa. Thus, one has to trade off sparsity and stability in designing a learning algorithm. In particular, our general result implies that l(1)-regularized regression (Lasso) cannot be stable, while l(2)-regularized regression is known to have strong stability properties and is therefore not sparse.", "paper_title": "Sparse Algorithms Are Not Stable: A No-Free-Lunch Theorem", "paper_id": "WOS:000297069900013"}