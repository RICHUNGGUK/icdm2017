{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "inverted_dirichlet_finite_mixture_models"}, {"score": 0.004570759604335229, "phrase": "unsupervised_algorithm"}, {"score": 0.004482400730101345, "phrase": "finite_mixture_models"}, {"score": 0.004424441580112395, "phrase": "multivariate_positive_data"}, {"score": 0.0037599278182081056, "phrase": "mixture_model"}, {"score": 0.003639471039860495, "phrase": "inverted_dirichlet_distribution"}, {"score": 0.0035228596881051763, "phrase": "good_representation"}, {"score": 0.0034322572683276654, "phrase": "positive_non-gaussian_data"}, {"score": 0.003194898129853895, "phrase": "inverted_dirichlet_mixture"}, {"score": 0.0030924870122337905, "phrase": "maximum_likelihood"}, {"score": 0.0029933487820771217, "phrase": "newton_raphson_method"}, {"score": 0.0027862576750944277, "phrase": "minimum_message_length"}, {"score": 0.0026274936167233515, "phrase": "optimal_number"}, {"score": 0.0024616504443079512, "phrase": "experimental_results"}, {"score": 0.002398274973378986, "phrase": "artificial_histograms"}, {"score": 0.0023672002840029517, "phrase": "real_data_sets"}, {"score": 0.0023213398100616132, "phrase": "challenging_problem"}, {"score": 0.0022912596877648723, "phrase": "software_modules_classification"}, {"score": 0.0022177498761722773, "phrase": "proposed_statistical_framework"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Data clustering", " Mixture models", " Inverted Dirichlet distribution", " Maximum likelihood", " Unsupervised learning", " MML"], "paper_abstract": "In this work we present an unsupervised algorithm for learning finite mixture models from multivariate positive data. Indeed, this kind of data appears naturally in many applications, yet it has not been adequately addressed in the past. This mixture model is based on the inverted Dirichlet distribution, which offers a good representation and modeling of positive non-Gaussian data. The proposed approach for estimating the parameters of an inverted Dirichlet mixture is based on the maximum likelihood (ML) using Newton Raphson method. We also develop an approach, based on the minimum message length (MML) criterion, to select the optimal number of clusters to represent the data using such a mixture. Experimental results are presented using artificial histograms and real data sets. The challenging problem of software modules classification is investigated within the proposed statistical framework, also. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Positive vectors clustering using inverted Dirichlet finite mixture models", "paper_id": "WOS:000298027300030"}