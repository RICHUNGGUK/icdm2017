{"auto_keywords": [{"score": 0.04472882712454684, "phrase": "hardware_failures"}, {"score": 0.02581590435353388, "phrase": "low_overhead"}, {"score": 0.00481495049065317, "phrase": "mpi_applications"}, {"score": 0.0047472380621488616, "phrase": "application-level_approach"}, {"score": 0.0046364836476864325, "phrase": "large-scale_computational_science_and_engineering_parallel_applications"}, {"score": 0.003948613642680196, "phrase": "machine_failures"}, {"score": 0.0038746849003761024, "phrase": "rollback_recovery"}, {"score": 0.0037309384824565695, "phrase": "fault_tolerance_support"}, {"score": 0.0036958398682001015, "phrase": "parallel_applications"}, {"score": 0.0034920505103165403, "phrase": "complete_restart"}, {"score": 0.0034428776029411944, "phrase": "parallel_application"}, {"score": 0.0033943947596098583, "phrase": "last_checkpoint"}, {"score": 0.0033624514778823763, "phrase": "new_advances"}, {"score": 0.0031769866037536045, "phrase": "proactive_process_migration_approaches"}, {"score": 0.0030590445140753187, "phrase": "preventive_way"}, {"score": 0.003030247482854539, "phrase": "node_failures"}, {"score": 0.0029039692582303904, "phrase": "whole_application"}, {"score": 0.002769805263310232, "phrase": "application-level_checkpointing_framework"}, {"score": 0.0027178867838199734, "phrase": "message_passing_interface"}, {"score": 0.0026923856079681028, "phrase": "mpi"}, {"score": 0.002641823250595624, "phrase": "impending_failures"}, {"score": 0.0025316905609748135, "phrase": "entire_application"}, {"score": 0.0024960069794216977, "phrase": "main_features"}, {"score": 0.002460825108719896, "phrase": "proposed_solution"}, {"score": 0.00240328454980006, "phrase": "failure-free_executions"}, {"score": 0.0022492129111567824, "phrase": "migration_time"}, {"score": 0.002155412043665635, "phrase": "light_and_asynchronous_protocol"}, {"score": 0.0021149856030692462, "phrase": "consistent_global_state"}], "paper_keywords": ["failure avoidance", " proactive migration", " checkpointing", " message-passing"], "paper_abstract": "Execution times of large-scale computational science and engineering parallel applications are usually longer than the mean-time-between-failures. For this reason, hardware failures must be tolerated by the applications to ensure that not all computation done is lost on machine failures. Checkpointing and rollback recovery is one of the most popular techniques to provide fault tolerance support to parallel applications. However, when a failure occurs, most checkpointing mechanisms require a complete restart of the parallel application from the last checkpoint. New advances in the prediction of hardware failures have led to the development of proactive process migration approaches, where tasks are migrated in a preventive way when node failures are anticipated, avoiding the restart of the whole application. The work presented in this paper extends an application-level checkpointing framework to proactively migrate message passing interface (MPI) processes when impending failures are notified, without having to restart the entire application. The main features of the proposed solution are: low overhead in failure-free executions, avoiding the checkpoint dumping associated to rolling back strategies; low overhead at migration time, by means of the design of a light and asynchronous protocol to achieve a consistent global state; transparency for the user, thanks to the use of a compiler tool and a runtime library and portability, as it is not locked into a particular architecture, operating system or MPI implementation.", "paper_title": "Failure Avoidance in MPI Applications Using an Application-Level Approach", "paper_id": "WOS:000329132400007"}