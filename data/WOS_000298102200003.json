{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "natural_language_processing"}, {"score": 0.0043738432231020885, "phrase": "unified_neural_network_architecture"}, {"score": 0.003934970057482768, "phrase": "part-of-speech_tagging"}, {"score": 0.003608732492631878, "phrase": "semantic_role_labeling"}, {"score": 0.0032777653153451265, "phrase": "task-specific_engineering"}, {"score": 0.0030642636185693054, "phrase": "prior_knowledge"}, {"score": 0.0029203055813347874, "phrase": "man-made_input_features"}, {"score": 0.002677964894127131, "phrase": "internal_representations"}, {"score": 0.0025521085778978042, "phrase": "vast_amounts"}, {"score": 0.0025034338848015166, "phrase": "mostly_unlabeled_training_data"}, {"score": 0.002208853811052348, "phrase": "freely_available_tagging_system"}, {"score": 0.0021049977753042253, "phrase": "minimal_computational_requirements"}], "paper_keywords": ["natural language processing", " neural networks"], "paper_abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.", "paper_title": "Natural Language Processing (Almost) from Scratch", "paper_id": "WOS:000298102200003"}