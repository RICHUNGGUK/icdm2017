{"auto_keywords": [{"score": 0.02872515980242424, "phrase": "mse"}, {"score": 0.014804969922366707, "phrase": "different_views"}, {"score": 0.008765589671862013, "phrase": "low-dimensional_embedding"}, {"score": 0.00481495049065317, "phrase": "multiview_spectral_embedding"}, {"score": 0.004752873752686246, "phrase": "computer_vision"}, {"score": 0.00471193241675062, "phrase": "multimedia_search"}, {"score": 0.00457138247462329, "phrase": "multiple_features"}, {"score": 0.004284100953217494, "phrase": "natural_scene_image"}, {"score": 0.004102639724186862, "phrase": "visual_features"}, {"score": 0.0036500346000495317, "phrase": "different_spaces"}, {"score": 0.0035564156572789473, "phrase": "conventional_spectral-embedding_algorithms"}, {"score": 0.0032896745636186824, "phrase": "new_vector"}, {"score": 0.003109519872758431, "phrase": "specific_statistical_property"}, {"score": 0.0030166226457616616, "phrase": "new_spectral-embedding_algorithm"}, {"score": 0.0029519664912853938, "phrase": "spectral_embedding"}, {"score": 0.0028513785049061767, "phrase": "different_features"}, {"score": 0.0028267701593809877, "phrase": "different_ways"}, {"score": 0.002766171878646582, "phrase": "physically_meaningful_embedding"}, {"score": 0.0025036862991477437, "phrase": "complementary_property"}, {"score": 0.0024183363693242943, "phrase": "closed-form_solution"}, {"score": 0.0023460397258997525, "phrase": "alternating_optimization-based_iterative_algorithm"}, {"score": 0.0022174469839432013, "phrase": "image_retrieval"}, {"score": 0.0021982976170703884, "phrase": "video_annotation"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Dimensionality reduction", " multiple views", " spectral embedding"], "paper_abstract": "In computer vision and multimedia search, it is common to use multiple features from different views to represent an object. For example, to well characterize a natural scene image, it is essential to find a set of visual features to represent its color, texture, and shape information and encode each feature into a vector. Therefore, we have a set of vectors in different spaces to represent the image. Conventional spectral-embedding algorithms cannot deal with such datum directly, so we have to concatenate these vectors together as a new vector. This concatenation is not physically meaningful because each feature has a specific statistical property. Therefore, we develop a new spectral-embedding algorithm, namely, multiview spectral embedding (MSE), which can encode different features in different ways, to achieve a physically meaningful embedding. In particular, MSE finds a low-dimensional embedding wherein the distribution of each view is sufficiently smooth, and MSE explores the complementary property of different views. Because there is no closed-form solution for MSE, we derive an alternating optimization-based iterative algorithm to obtain the low-dimensional embedding. Empirical evaluations based on the applications of image retrieval, video annotation, and document clustering demonstrate the effectiveness of the proposed approach.", "paper_title": "Multiview Spectral Embedding", "paper_id": "WOS:000284364400002"}