{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "robust_dialog_management"}, {"score": 0.04818042291546326, "phrase": "spoken_dialog_systems"}, {"score": 0.03967305438082863, "phrase": "dialog_manager"}, {"score": 0.0333570523443284, "phrase": "agenda_graph"}, {"score": 0.004339293854115301, "phrase": "recognition_and_understanding_errors"}, {"score": 0.004167218012926657, "phrase": "unexpected_inputs"}, {"score": 0.003910441483033426, "phrase": "hybrid_approach"}, {"score": 0.0037121208432871118, "phrase": "agenda-based_and_example-based_dialog_modeling"}, {"score": 0.0035442655396704724, "phrase": "best_hypotheses"}, {"score": 0.003463196032143783, "phrase": "current_dialog_state"}, {"score": 0.003287482882222731, "phrase": "dialog_state"}, {"score": 0.0032309093154028663, "phrase": "discourse_interpretation_algorithm"}, {"score": 0.0031026497891826726, "phrase": "focus_stack"}, {"score": 0.0029967610945411593, "phrase": "multiple_recognition_hypotheses"}, {"score": 0.002877769867854964, "phrase": "next_action"}, {"score": 0.00282822695516646, "phrase": "multi-level_score_functions"}, {"score": 0.002795671770303977, "phrase": "trigger_error_recovery_strategies"}, {"score": 0.0027475383418803724, "phrase": "exceptional_cases"}, {"score": 0.0026691455928407022, "phrase": "unexpected_focus_shifts"}, {"score": 0.002623184850933423, "phrase": "proposed_method"}, {"score": 0.0025336179740814905, "phrase": "spoken_dialog_system"}, {"score": 0.0024899850926034567, "phrase": "building_guidance_domain"}, {"score": 0.002447101794397243, "phrase": "intelligent_service_robot"}, {"score": 0.0023363141951290526, "phrase": "simulated_and_real_users"}, {"score": 0.0022960713730673494, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Example-based dialog modeling", " Agenda-based dialog management", " Robust dialog management", " Error handling"], "paper_abstract": "Spoken dialog systems have difficulty selecting which action to take in a given situation because recognition and understanding errors are prevalent due to noise and unexpected inputs. To solve this problem, this paper presents a hybrid approach to improving robustness of the dialog manager by using agenda-based and example-based dialog modeling. This approach can exploit it-best hypotheses to determine the current dialog state in the dialog manager and keep track of the dialog state using a discourse interpretation algorithm based on an agenda graph and a focus stack. Given the agenda graph and multiple recognition hypotheses, the system can predict the next action to maximize multi-level score functions and trigger error recovery strategies to handle exceptional cases due to misunderstandings or unexpected focus shifts. The proposed method was tested by developing a spoken dialog system for a building guidance domain in an intelligent service robot. This system was then evaluated by simulated and real users. The experimental results show that our approach can effectively develop robust dialog management for spoken dialog systems. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Hybrid approach to robust dialog management using agenda and dialog examples", "paper_id": "WOS:000277841900004"}