{"auto_keywords": [{"score": 0.03423057083405171, "phrase": "global_shape"}, {"score": 0.03069155049113217, "phrase": "neighbor_reconstruction_framework"}, {"score": 0.00481495049065317, "phrase": "facial_expression_synthesis"}, {"score": 0.00450130420152996, "phrase": "facial_expressions"}, {"score": 0.004133055661437163, "phrase": "training_set"}, {"score": 0.0040777192615062815, "phrase": "unresolved_problem"}, {"score": 0.004041238873048836, "phrase": "statistical_model"}, {"score": 0.00384633057714983, "phrase": "two-step_method"}, {"score": 0.0037104876694493815, "phrase": "statistical_appearance_model"}, {"score": 0.003437486158494063, "phrase": "seven_components"}, {"score": 0.0033459905006404207, "phrase": "seven_local_texture_models"}, {"score": 0.0032132782979796895, "phrase": "local_texture_strategy"}, {"score": 0.003141830113006653, "phrase": "different_components"}, {"score": 0.0030307927228223883, "phrase": "training_sets"}, {"score": 0.00295008998986066, "phrase": "\"legal\"_result"}, {"score": 0.0027575842698911173, "phrase": "target_expression_vector"}, {"score": 0.0027206133859493725, "phrase": "linear_combination"}, {"score": 0.0026962411675196213, "phrase": "neighbor_subject's_expression_vectors"}, {"score": 0.0025660347613972573, "phrase": "proposed_method"}, {"score": 0.0025202582748972122, "phrase": "wider_range"}, {"score": 0.0023663794611266426, "phrase": "fcm"}, {"score": 0.0023241387549221408, "phrase": "standard_aam"}, {"score": 0.0023033100935570755, "phrase": "face_representation"}, {"score": 0.0021049977753042253, "phrase": "single-target_applications"}], "paper_keywords": ["Computer vision", " face representation", " facial expression synthesis", " statistical appearance models"], "paper_abstract": "Statistical model based facial expression synthesis methods are robust and can be easily used in real environment. But facial expressions of humans are varied. How to represent and synthesize expressions that are is not included in the training set is an unresolved problem in statistical model based researches. In this paper, we propose a two-step method. At first, we propose a statistical appearance model, the facial component model, to represent faces. The model divides the face into seven components, and constructs one global shape model and seven local texture models separately. The motivation to use global shape + local texture strategy is the combination of different components that can generate more types of expression than training sets and the global shape guarantees a \"legal\" result. Then a neighbor reconstruction framework is proposed to synthesize expressions. The framework estimates the target expression vector by a linear combination of neighbor subject's expression vectors. This paper primarily contributes three things: first, the proposed method can synthesize a wider range of expressions than with the training set. Second, experiments demonstrate that FCM is better than standard AAM in face representation. Third, neighbor reconstruction framework is very flexible. It can be used in multisamples with multitargets and single-sample with single-target applications.", "paper_title": "FACIAL EXPRESSION SYNTHESIS BASED ON FACIAL COMPONENT MODEL", "paper_id": "WOS:000267114600013"}