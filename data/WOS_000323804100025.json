{"auto_keywords": [{"score": 0.04355159126538614, "phrase": "minority_class"}, {"score": 0.00481495049065317, "phrase": "highly_imbalanced_data-sets"}, {"score": 0.0046683172874085015, "phrase": "imbalanced_data-sets"}, {"score": 0.004506171772318298, "phrase": "data_mining"}, {"score": 0.004292337783332826, "phrase": "undesirable_effects"}, {"score": 0.0040886093072615, "phrase": "accurate_tools"}, {"score": 0.0038431888954930083, "phrase": "possible_solution"}, {"score": 0.0037925389501636975, "phrase": "ensemble_proposals"}, {"score": 0.0037096052787890326, "phrase": "bagging"}, {"score": 0.003676988184753843, "phrase": "boosting"}, {"score": 0.0036445446531633368, "phrase": "preprocessing_techniques"}, {"score": 0.003350740737336966, "phrase": "new_ensemble_construction_algorithm"}, {"score": 0.003191560305761507, "phrase": "simplest_and_most_accurate_ensemble"}, {"score": 0.003135564707433078, "phrase": "random_undersampling"}, {"score": 0.003107935254560724, "phrase": "boosting_algorithm"}, {"score": 0.003013129637451091, "phrase": "existing_proposals"}, {"score": 0.002934166052954463, "phrase": "base_classifiers"}, {"score": 0.0028572658971252616, "phrase": "evolutionary_undersampling_approach"}, {"score": 0.002721464488351771, "phrase": "different_subsets"}, {"score": 0.002697474061842142, "phrase": "majority_class_instances"}, {"score": 0.0026501241093379786, "phrase": "base_classifier"}, {"score": 0.0026036031415940563, "phrase": "two-class_highly_imbalanced_problems"}, {"score": 0.0025018875576502606, "phrase": "proper_statistical_analysis"}, {"score": 0.0022297712188622293, "phrase": "kappa-error_diagrams"}, {"score": 0.002161695357601592, "phrase": "imbalanced_scenario"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Classification", " Imbalanced data-sets", " Ensembles", " Class distribution", " Kappa-error diagrams", " Boosting"], "paper_abstract": "Classification with imbalanced data-sets has become one of the most challenging problems in Data Mining. Being one class much more represented than the other produces undesirable effects in both the learning and classification processes, mainly regarding the minority class. Such a problem needs accurate tools to be undertaken; lately, ensembles of classifiers have emerged as a possible solution. Among ensemble proposals, the combination of Bagging and Boosting with preprocessing techniques has proved its ability to enhance the classification of the minority class. In this paper, we develop a new ensemble construction algorithm (EUSBoost) based on RUSBoost, one of the simplest and most accurate ensemble, which combines random undersampling with Boosting algorithm. Our methodology aims to improve the existing proposals enhancing the performance of the base classifiers by the usage of the evolutionary undersampling approach. Besides, we promote diversity favoring the usage of different subsets of majority class instances to train each base classifier. Centered on two-class highly imbalanced problems, we will prove, supported by the proper statistical analysis, that EUSBoost is able to outperform the state-of-the-art methods based on ensembles. We will also analyze its advantages using kappa-error diagrams, which we adapt to the imbalanced scenario. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "EUSBoost: Enhancing ensembles for highly imbalanced data-sets by evolutionary undersampling", "paper_id": "WOS:000323804100025"}