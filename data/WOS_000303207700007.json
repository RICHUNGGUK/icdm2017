{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "cache_organization"}, {"score": 0.01540798788623252, "phrase": "chip_multiprocessors"}, {"score": 0.015223879821119867, "phrase": "data_access_latency"}, {"score": 0.013071327795822128, "phrase": "noc"}, {"score": 0.012862942935608556, "phrase": "communication_locality"}, {"score": 0.0127088527556333, "phrase": "communication_latency"}, {"score": 0.004756805752518494, "phrase": "access_latency"}, {"score": 0.004567990533989851, "phrase": "performance_improvements"}, {"score": 0.004263972370406983, "phrase": "memory_hierarchy"}, {"score": 0.004212453011596424, "phrase": "on-chip_interconnect"}, {"score": 0.004144723510171449, "phrase": "running_workload"}, {"score": 0.0038375280115736958, "phrase": "special_fast_paths"}, {"score": 0.0035965032173588753, "phrase": "communication_patterns"}, {"score": 0.003384262486955773, "phrase": "underlying_noc"}, {"score": 0.003329804436286295, "phrase": "simple_noc_design"}, {"score": 0.0032629585038738856, "phrase": "optimization_opportunities"}, {"score": 0.0031459887611258765, "phrase": "codesign_approach"}, {"score": 0.0029244418026475832, "phrase": "periodic_configuration"}, {"score": 0.0026530590435527527, "phrase": "unique_private"}, {"score": 0.002537216271965659, "phrase": "processor_core"}, {"score": 0.002506507889886399, "phrase": "core's_locally_accessible_cache_bank"}, {"score": 0.002466139325703204, "phrase": "dedicated_high-speed_circuits"}, {"score": 0.002406799309495983, "phrase": "remote_cores"}, {"score": 0.002387337550919433, "phrase": "fast_access"}, {"score": 0.0023680327896318915, "phrase": "shared_data"}, {"score": 0.0023016843709107297, "phrase": "scientific_and_commercial_workloads"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_noc-cache_codesigned_system"}], "paper_keywords": ["Multicore/single-chip multiprocessors", " circuit-switching networks", " cache memories"], "paper_abstract": "Reducing data access latency is vital to achieving performance improvements in computing. For chip multiprocessors (CMPs), data access latency depends on the organization of the memory hierarchy, the on-chip interconnect, and the running workload. Several network-on-chip (NoC) designs exploit communication locality to reduce communication latency by configuring special fast paths or circuits on which communication is faster than the rest of the NoC. However, communication patterns are directly affected by the cache organization and many cache organizations are designed in isolation of the underlying NoC or assume a simple NoC design, thus possibly missing optimization opportunities. In this work, we take a codesign approach of the NoC and cache organization. First, we propose a hybrid circuit/packet-switched NoC that exploits communication locality through periodic configuration of the most beneficial circuits. Second, we design a Unique Private (UP) caching scheme targeting the class of interconnects which exploit communication locality to improve communication latency. The Unique Private cache stores the data that are mostly accessed by each processor core in the core's locally accessible cache bank, while leveraging dedicated high-speed circuits in the interconnect to provide remote cores with fast access to shared data. Simulations of a suite of scientific and commercial workloads show that our proposed design achieves a speedup of 15.2 and 14 percent on a 16-core and a 64-core CMP, respectively, over the state-of-the-art NoC-Cache codesigned system that also exploits communication locality in multithreaded applications.", "paper_title": "Codesign of NoC and Cache Organization for Reducing Access Latency in Chip Multiprocessors", "paper_id": "WOS:000303207700007"}