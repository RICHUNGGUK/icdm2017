{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "mixture_models"}, {"score": 0.04550863708222468, "phrase": "data_space"}, {"score": 0.00475254914916922, "phrase": "binary_tree_search"}, {"score": 0.0047113960612140335, "phrase": "unsupervised_data_clustering"}, {"score": 0.0044718206943536514, "phrase": "mixture_components"}, {"score": 0.004063664475797303, "phrase": "simultaneous_estimation"}, {"score": 0.004010960493946656, "phrase": "mixture's_parameters"}, {"score": 0.003644714340300824, "phrase": "single_component"}, {"score": 0.003581797255879607, "phrase": "iteratively_splits_components"}, {"score": 0.003459191419478298, "phrase": "binary_tree_structure"}, {"score": 0.003399466007862412, "phrase": "efficient_exploration"}, {"score": 0.0033553473725594003, "phrase": "possible_solutions"}, {"score": 0.003311799410921826, "phrase": "proposed_scheme"}, {"score": 0.0032830808525570903, "phrase": "important_computational_savings"}, {"score": 0.0029961221584602405, "phrase": "performance_time"}, {"score": 0.002893505913503472, "phrase": "computer_and_robot_vision_applications"}, {"score": 0.002770150086489194, "phrase": "deterministic_evolution"}, {"score": 0.002686935113435739, "phrase": "parameter_estimation"}, {"score": 0.002594880866651459, "phrase": "expectation_maximization_algorithm"}, {"score": 0.0025279105573394727, "phrase": "different_complexity"}, {"score": 0.0024842242921857705, "phrase": "minimum_message_length_information_criteria"}, {"score": 0.002357632753637638, "phrase": "fit_log-likelihood"}, {"score": 0.0022768346311104735, "phrase": "synthetic_data"}, {"score": 0.0021607883988873492, "phrase": "data-intensive_image_segmentation_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Unsupervised clustering", " Expectation Maximization", " Image processing", " Robotics", " Machine vision"], "paper_abstract": "Unsupervised data clustering can be addressed by the estimation of mixture models, where the mixture components are associated to clusters in data space. In this paper we present a novel, unsupervised classification algorithm based on the simultaneous estimation of the mixture's parameters and the number of components (complexity). Its distinguishing aspect is the way the data space is searched. Our algorithm starts from a single component covering all the input space and iteratively splits components according to breadth first search on a binary tree structure that provides an efficient exploration of the possible solutions. The proposed scheme demonstrates important computational savings with respect to other state-of-the-art algorithms, making it particularly suited to scenarios where the performance time is an issue, such as in computer and robot vision applications. The initialization procedure is unique, allowing a deterministic evolution of the algorithm, while the parameter estimation is performed with a modification of the Expectation Maximization algorithm. To compare models with different complexity we use the Minimum Message Length information criteria that implement the trade-off between the number of components and data fit log-likelihood. We validate our new approach with experiments on synthetic data, and we test and compare to related approaches its computational efficiency in data-intensive image segmentation applications. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Efficient greedy estimation of mixture models through a binary tree search", "paper_id": "WOS:000341464300009"}