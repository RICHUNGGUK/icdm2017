{"auto_keywords": [{"score": 0.04453308932307293, "phrase": "motion_database"}, {"score": 0.00481495049065317, "phrase": "occluded_monocular_observations"}, {"score": 0.00458940888106061, "phrase": "whole-body_motion_recovery"}, {"score": 0.00439777299939725, "phrase": "occluded_monocular_camera_images"}, {"score": 0.004327981760540394, "phrase": "statistical_inference"}, {"score": 0.003767517649628532, "phrase": "abstract_statistical_form"}, {"score": 0.003668333531296882, "phrase": "rich_information"}, {"score": 0.003629392214109574, "phrase": "expensive_computation"}, {"score": 0.0035908627899097407, "phrase": "image_processing"}, {"score": 0.0034963129868796033, "phrase": "inference_mechanism"}, {"score": 0.003459191419478298, "phrase": "low_level_image_features"}, {"score": 0.0032793933580835574, "phrase": "psychological_research"}, {"score": 0.0031422859551159506, "phrase": "proposed_inference_mechanism"}, {"score": 0.0030270132320276096, "phrase": "closest_motion"}, {"score": 0.002720376476146181, "phrase": "different_space"}, {"score": 0.002662871928330334, "phrase": "joint_space"}, {"score": 0.0026205405415623525, "phrase": "coordinate_transformation"}, {"score": 0.002578880352208335, "phrase": "statistical_motion_representation"}, {"score": 0.0025109095718850376, "phrase": "view_invariant"}, {"score": 0.002470987929071079, "phrase": "demonstrator's_baselink_position"}, {"score": 0.002393034183276193, "phrase": "camera_coordinates"}, {"score": 0.00232995025271599, "phrase": "extended_particle_filter"}, {"score": 0.0022685255265595624, "phrase": "experimental_evaluation"}, {"score": 0.0022324489895237504, "phrase": "presented_concepts"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Statistical inference", " Motion recognition", " Motion recovery", " Motion capturing", " Optical flow", " Particle filter", " Monocular vision"], "paper_abstract": "This paper proposes a method for 3D whole-body motion recovery and motion recognition from a sequence of occluded monocular camera images based on statistical inference using a motion database. In the motion database, each motion primitive (e.g., walk, kick, etc.) is represented in an abstract statistical form. Instead of extracting rich information by expensive computation of image processing, we propose an inference mechanism from low level image features (e.g., optical flow), inspired by psychological research on how humans perceive motion. The proposed inference mechanism recovers the 3D body configuration and finds the closest motion primitive in the motion database. Observations in 2D camera image space can be recognized even though the motion database is prepared in a different space (such as joint space) by coordinate transformation of the statistical motion representation. The approach is view invariant since the demonstrator's baselink position and orientation with respect to camera coordinates are tracked using an extended particle filter. Finally, an experimental evaluation of the presented concepts using a 56-degree-of-freedom articulated human model is discussed. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Motion recognition and recovery from occluded monocular observations", "paper_id": "WOS:000336468400008"}