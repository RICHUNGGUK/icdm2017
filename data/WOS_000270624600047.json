{"auto_keywords": [{"score": 0.03293601710642665, "phrase": "lda"}, {"score": 0.00481495049065317, "phrase": "markov_chain_monte_carlo_simulations"}, {"score": 0.004610058444728656, "phrase": "posterior_distribution"}, {"score": 0.00456020621016909, "phrase": "markov_chain_monte_carlo_sampling"}, {"score": 0.004389912080394437, "phrase": "true_distribution"}, {"score": 0.004090274535243564, "phrase": "central_problem"}, {"score": 0.003916098498242888, "phrase": "different_points"}, {"score": 0.003668591097652231, "phrase": "convergence_measures"}, {"score": 0.00349324530379071, "phrase": "convergence_problems"}, {"score": 0.0033262524445013303, "phrase": "proper_visualization"}, {"score": 0.003236941658990869, "phrase": "novel_connection"}, {"score": 0.0031500213134140953, "phrase": "linear_discriminant_analysis"}, {"score": 0.002999386721353559, "phrase": "simulation_chains"}, {"score": 0.002934764205541183, "phrase": "common_multivariate_convergence_measure"}, {"score": 0.002719325177422626, "phrase": "restrictive_assumptions"}, {"score": 0.0025611773887867255, "phrase": "recent_extension"}, {"score": 0.0023602032679095955, "phrase": "unidentifiable_models"}, {"score": 0.0023346234464901978, "phrase": "model_families"}, {"score": 0.00230932021677234, "phrase": "variable_number"}, {"score": 0.0022472527731744974, "phrase": "straightforward_visualization"}, {"score": 0.002210814150677161, "phrase": "parameter_space"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": [""], "paper_abstract": "Bayesian inference often requires approximating the posterior distribution by Markov chain Monte Carlo sampling. The samples come from the true distribution only after the simulation has converged, which makes detecting convergence a central problem. Commonly, several simulation chains are started from different points, and their overlap is used as a measure of convergence. Convergence measures cannot tell the analyst the cause of convergence problems; it is suggested that complementing them with proper visualization will help. A novel connection is pointed out: linear discriminant analysis (LDA) minimizes the overlap of the simulation chains measured by a common multivariate convergence measure. LDA is thus justified for visualizing convergence. However, LDA makes restrictive assumptions about the chains, which can be relaxed by a recent extension called discriminative component analysis (DCA). Lastly, methods are introduced for unidentifiable models and model families with variable number of parameters, where straightforward visualization in the parameter space is not feasible. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Visualizations for assessing convergence and mixing of Markov chain Monte Carlo simulations", "paper_id": "WOS:000270624600047"}