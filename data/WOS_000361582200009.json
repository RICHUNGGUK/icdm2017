{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "global_exponential_stability"}, {"score": 0.04931727328027495, "phrase": "complex-valued_recurrent_neural_networks"}, {"score": 0.027997284734999024, "phrase": "obtained_results"}, {"score": 0.004234884779773412, "phrase": "matrix_measure_method"}, {"score": 0.004134137523409649, "phrase": "halanay_inequality"}, {"score": 0.004068302313449334, "phrase": "global_exponential_stability_problem"}, {"score": 0.003606711217432998, "phrase": "lyapunov_functions"}, {"score": 0.003301733505307784, "phrase": "addressed_complex-valued_neural_networks"}, {"score": 0.003071429173571846, "phrase": "activation_functions"}, {"score": 0.0027667539384678814, "phrase": "relating_references"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Complex-valued recurrent neural networks", " Matrix measure", " Halanay inequality", " Exponential stability", " Time-varying delay"], "paper_abstract": "In this paper, based on the matrix measure method and the Halanay inequality, global exponential stability problem is investigated for the complex-valued recurrent neural networks with time-varying delays. Without constructing any Lyapunov functions, several sufficient criteria are obtained to ascertain the global exponential stability of the addressed complex-valued neural networks under different activation functions. Here, the activation functions are no longer assumed to be derivative which is always demanded in relating references. In addition, the obtained results are easy to be verified and implemented in practice. Finally, two examples are given to illustrate the effectiveness of the obtained results. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Matrix measure method for global exponential stability of complex-valued recurrent neural networks with time-varying delays", "paper_id": "WOS:000361582200009"}