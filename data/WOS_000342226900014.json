{"auto_keywords": [{"score": 0.046784838505979066, "phrase": "multimodal_features"}, {"score": 0.033574470598394766, "phrase": "high-order_correlation"}, {"score": 0.00481495049065317, "phrase": "high-order_potentials"}, {"score": 0.004702092660370367, "phrase": "computer_vision"}, {"score": 0.0046650615456476155, "phrase": "multimedia_analysis"}, {"score": 0.00453772385360173, "phrase": "multiple_features"}, {"score": 0.0042426974826585695, "phrase": "natural_scene_image"}, {"score": 0.004110549138321181, "phrase": "visual_features"}, {"score": 0.0034674164050273568, "phrase": "scale_invariant_feature_transform_descriptors"}, {"score": 0.003306559295382181, "phrase": "image_texture"}, {"score": 0.003241750934419473, "phrase": "existing_algorithms"}, {"score": 0.0030187498405804315, "phrase": "new_multimodal_feature_integration_framework"}, {"score": 0.0029246121262946384, "phrase": "new_measure"}, {"score": 0.0027559226203857316, "phrase": "direct_extension"}, {"score": 0.002723367507064405, "phrase": "previous_binary_correlation"}, {"score": 0.002648889316519512, "phrase": "feature_correlation_hypergraph"}, {"score": 0.002576442680766742, "phrase": "high-order_relations"}, {"score": 0.0024960634897058394, "phrase": "clustering_algorithm"}, {"score": 0.002418185868191525, "phrase": "original_multimodal"}, {"score": 0.0023150468182777813, "phrase": "multiclass_boosting_strategy"}, {"score": 0.0022606512324475584, "phrase": "strong_classifier"}, {"score": 0.0022250978492127163, "phrase": "weak_classifiers"}, {"score": 0.002164216680934624, "phrase": "experimental_results"}, {"score": 0.0021471293746360026, "phrase": "seven_popular_datasets"}], "paper_keywords": ["Feature correlation hypergraph", " high-order relations", " multimodal features"], "paper_abstract": "In computer vision and multimedia analysis, it is common to use multiple features (or multimodal features) to represent an object. For example, to well characterize a natural scene image, we typically extract a set of visual features to represent its color, texture, and shape. However, it is challenging to integrate multimodal features optimally. Since they are usually high-order correlated, e. g., the histogram of gradient (HOG), bag of scale invariant feature transform descriptors, and wavelets are closely related because they collaboratively reflect the image texture. Nevertheless, the existing algorithms fail to capture the high-order correlation among multimodal features. To solve this problem, we present a new multimodal feature integration framework. Particularly, we first define a new measure to capture the high-order correlation among the multimodal features, which can be deemed as a direct extension of the previous binary correlation. Therefore, we construct a feature correlation hypergraph (FCH) to model the high-order relations among multimodal features. Finally, a clustering algorithm is performed on FCH to group the original multimodal features into a set of partitions. Moreover, a multiclass boosting strategy is developed to obtain a strong classifier by combining the weak classifiers learned from each partition. The experimental results on seven popular datasets show the effectiveness of our approach.", "paper_title": "Feature Correlation Hypergraph: Exploiting High-order Potentials for Multimodal Recognition", "paper_id": "WOS:000342226900014"}