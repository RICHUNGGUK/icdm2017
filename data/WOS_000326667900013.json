{"auto_keywords": [{"score": 0.04747282423410841, "phrase": "mi"}, {"score": 0.015337551174005518, "phrase": "dependence-maximization_clustering"}, {"score": 0.011482877976631395, "phrase": "qmi"}, {"score": 0.008173619836503644, "phrase": "lsqmi"}, {"score": 0.00481495049065317, "phrase": "quadratic_mutual_information"}, {"score": 0.004441359373498799, "phrase": "standard_measure"}, {"score": 0.004386503433248535, "phrase": "statistical_dependence"}, {"score": 0.004332322079100859, "phrase": "random_variables"}, {"score": 0.0041478818670853115, "phrase": "log_function"}, {"score": 0.00402094658848301, "phrase": "probability_densities"}, {"score": 0.0035507457285983268, "phrase": "quadratic_mi"}, {"score": 0.0031746155143471725, "phrase": "squared_difference"}, {"score": 0.0031159081999910694, "phrase": "joint_density"}, {"score": 0.002855934865505357, "phrase": "kernel_least-squares_qmi_estimator"}, {"score": 0.002633941112839883, "phrase": "density_difference"}, {"score": 0.002521623057264411, "phrase": "notable_advantage"}, {"score": 0.0022542611024997474, "phrase": "linear_equations"}], "paper_keywords": ["quadratic mutual information", " least-square density-difference estimation", " information theoretic clustering"], "paper_abstract": "Mutual information (MI) is a standard measure of statistical dependence of random variables. However, due to the log function and the ratio of probability densities included in MI, it is sensitive to outliers. On the other hand, the L-2-distance variant of MI called quadratic MI (QMI) tends to be robust against outliers because QMI is just the integral of the squared difference between the joint density and the product of marginals. In this paper, we propose a kernel least-squares QMI estimator called least-squares QMI (LSQMI) that directly estimates the density difference without estimating each density. A notable advantage of LSQMI is that its solution can be analytically and efficiently computed just by solving a system of linear equations. We then apply LSQMI to dependence-maximization clustering, and demonstrate its usefulness experimentally.", "paper_title": "Direct Approximation of Quadratic Mutual Information and Its Application to Dependence-Maximization Clustering", "paper_id": "WOS:000326667900013"}