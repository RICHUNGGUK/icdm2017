{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "many-core_graphics_processors"}, {"score": 0.004740476936977635, "phrase": "high-performance_applications"}, {"score": 0.004618893461411858, "phrase": "many-core_architectures"}, {"score": 0.004571133708117498, "phrase": "efficient_mapping_techniques"}, {"score": 0.004523865550323285, "phrase": "architecture-specific_tuning_methodologies"}, {"score": 0.004141238989360548, "phrase": "architecture-aware_methods"}, {"score": 0.004055998173160551, "phrase": "-pairs_computations"}, {"score": 0.003870541730075597, "phrase": "numerous_application_areas"}, {"score": 0.0038304902197108643, "phrase": "scientific_computing"}, {"score": 0.003542976343910816, "phrase": "pairwise_interaction"}, {"score": 0.0033633514001658086, "phrase": "multi-layered_memory_hierarchies"}, {"score": 0.0032094634756436595, "phrase": "small_and_low-latency_on-chip_memories"}, {"score": 0.0030308784612749647, "phrase": "memory_traffic"}, {"score": 0.0028325548627901004, "phrase": "hierarchical_decomposition_scheme"}, {"score": 0.0027169974137406148, "phrase": "output_matrix"}, {"score": 0.0026888503045081505, "phrase": "input_data"}, {"score": 0.0026061419474030633, "phrase": "careful_tuning"}, {"score": 0.0025657442830956017, "phrase": "involved_set"}, {"score": 0.00253916011199984, "phrase": "decomposition_parameters"}, {"score": 0.002473895542219933, "phrase": "high_efficiency"}, {"score": 0.0022642601698943687, "phrase": "sti_cell_processor"}, {"score": 0.0022175679453857473, "phrase": "multi-core_cpu_parallelizations"}, {"score": 0.002194611136871074, "phrase": "openmp"}, {"score": 0.002171836484200008, "phrase": "intel_threading_building_blocks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Parallelization", " High-performance", " GPU", " GPGPU", " Multicores"], "paper_abstract": "Developing high-performance applications on emerging multi- and many-core architectures requires efficient mapping techniques and architecture-specific tuning methodologies to realize performance closer to their peak compute capability and memory bandwidth. In this paper, we develop architecture-aware methods to accelerate all-pairs computations on many-core graphics processors. Pairwise computations occur frequently in numerous application areas in scientific computing. While they appear easy to parallelize due to the independence of computing each pairwise interaction from all others, development of techniques to address multi-layered memory hierarchies, mapping within the restrictions imposed by the small and low-latency on-chip memories, striking the right balanced between concurrency, reuse and memory traffic etc., are crucial to obtain high-performance. We present a hierarchical decomposition scheme for CPUs based on decomposition of the output matrix and input data. We demonstrate that a careful tuning of the involved set of decomposition parameters is essential to achieve high efficiency on the CPUs. We also compare the performance of our strategies with an implementation on the STI Cell processor as well as multi-core CPU parallelizations using OpenMP and Intel Threading Building Blocks. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "All-pairs computations on many-core graphics processors", "paper_id": "WOS:000317706500001"}