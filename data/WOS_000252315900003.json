{"auto_keywords": [{"score": 0.04973625252864221, "phrase": "topographic_manifold"}, {"score": 0.00481495049065317, "phrase": "geometric_properties"}, {"score": 0.004661775069083667, "phrase": "human-computer_interaction"}, {"score": 0.004628400269774981, "phrase": "automatic_eye_detection"}, {"score": 0.004546000131069232, "phrase": "important_component"}, {"score": 0.004513450434595191, "phrase": "advanced_human-computer_interface_design"}, {"score": 0.004369824355829779, "phrase": "successful_system"}, {"score": 0.004338530593157634, "phrase": "face_recognition"}, {"score": 0.004307459965946991, "phrase": "emotion_identification"}, {"score": 0.0041703614123283165, "phrase": "novel_approach"}, {"score": 0.004066740842661956, "phrase": "geometric_surface_features"}, {"score": 0.0040086845241492424, "phrase": "eye_images"}, {"score": 0.003923144245133288, "phrase": "joint_spatial-intensity_domain"}, {"score": 0.0034220655476652683, "phrase": "terrain_classification_procedure"}, {"score": 0.003361069456060196, "phrase": "facial_images"}, {"score": 0.0032075033252058835, "phrase": "terrain_map"}, {"score": 0.0031277316566463978, "phrase": "terrain_labels"}, {"score": 0.0030830390264125923, "phrase": "eye_terrain_pattern"}, {"score": 0.0030499378654797143, "phrase": "bhattacharyya_affinity"}, {"score": 0.002984794722633428, "phrase": "distribution_similarity"}, {"score": 0.002910545717767559, "phrase": "bhattacharyya_kernel"}, {"score": 0.0028792911886505526, "phrase": "support_vector_machine"}, {"score": 0.0028279422436488116, "phrase": "proper_eye_pairs"}, {"score": 0.002797572252783356, "phrase": "pit-labeled_candidates"}, {"score": 0.002747676657869163, "phrase": "detected_eyes"}, {"score": 0.0027181663098561066, "phrase": "first_frame"}, {"score": 0.0026889720516076205, "phrase": "video_sequence"}, {"score": 0.0026600905156986317, "phrase": "mutual-information-based_fitting_function"}, {"score": 0.0025660347613972573, "phrase": "neighboring_frames"}, {"score": 0.0025202582748972122, "phrase": "fitting_function"}, {"score": 0.0025021765811679446, "phrase": "eye_locations"}, {"score": 0.0024664004864629724, "phrase": "subsequent_frames"}, {"score": 0.0024136908511423875, "phrase": "proposed_approach"}, {"score": 0.002370625627299064, "phrase": "eye_detection"}, {"score": 0.0023536149458842992, "phrase": "eye_tracking"}, {"score": 0.0023116191163488824, "phrase": "derived_topographic_manifold"}, {"score": 0.002262209824105154, "phrase": "original-intensity_image_domain"}, {"score": 0.0021587414711262904, "phrase": "different_facial_appearances"}, {"score": 0.0021202154023229123, "phrase": "video_sequences"}, {"score": 0.0021049977753042253, "phrase": "background_constraints"}], "paper_keywords": ["algorithms", " eye detection", " eye tracking", " topographic manifold", " Bhattacharyya affinity", " mutual information"], "paper_abstract": "Automatic eye detection and tracking is an important component for advanced human-computer interface design. Accurate eye localization can help develop a successful system for face recognition and emotion identification. In this article, we propose a novel approach to detect and track eyes using geometric surface features on topographic manifold of eye images. First, in the joint spatial-intensity domain, a facial image is treated as a 3D terrain surface or image topographic manifold. In particular, eye regions exhibit certain intrinsic geometric traits on this topographic manifold, namely, the pit-labeled center and hillside-like surround regions. Applying a terrain classification procedure on the topographic manifold of facial images, each location of the manifold can be labeled to generate a terrain map. We use the distribution of terrain labels to represent the eye terrain pattern. The Bhattacharyya affinity is employed to measure the distribution similarity between two topographic manifolds. Based on the Bhattacharyya kernel, a support vector machine is applied for selecting proper eye pairs from the pit-labeled candidates. Second, given detected eyes on the first frame of a video sequence, a mutual-information-based fitting function is defined to describe the similarity between two terrain surfaces of neighboring frames. By optimizing the fitting function, eye locations are updated for subsequent frames. The distinction of the proposed approach lies in that both eye detection and eye tracking are performed on the derived topographic manifold, rather than on an original-intensity image domain. The robustness of the approach is demonstrated under various imaging conditions and with different facial appearances, using both static images and video sequences without background constraints.", "paper_title": "Using geometric properties of topographic manifold to detect and track eyes for human-computer interaction", "paper_id": "WOS:000252315900003"}