{"auto_keywords": [{"score": 0.037498392220758944, "phrase": "score_regularization"}, {"score": 0.014384903088612988, "phrase": "similar_scores"}, {"score": 0.012669727909466447, "phrase": "retrieval_scores"}, {"score": 0.00481495049065317, "phrase": "query-based_retrieval_scores"}, {"score": 0.0046632033374901715, "phrase": "cluster_hypothesis"}, {"score": 0.0046038458731764926, "phrase": "score-based_information_retrieval"}, {"score": 0.0044873778175404475, "phrase": "closely_related_documents"}, {"score": 0.004208881856146758, "phrase": "arbitrary_system"}, {"score": 0.003798654583736764, "phrase": "topically_related_documents"}, {"score": 0.0031743093007496736, "phrase": "arbitrary_initial_retrieval_rankings"}, {"score": 0.003054450075234415, "phrase": "regularized_scores"}, {"score": 0.002901627749562029, "phrase": "un-regularized_scores"}, {"score": 0.0027741761880779535, "phrase": "improved_performance"}, {"score": 0.0026865721000905235, "phrase": "baseline_retrieval_algorithms"}, {"score": 0.0024714996534331668, "phrase": "pseudo-relevance_feedback"}, {"score": 0.002378114613631841, "phrase": "cluster-based_retrieval"}, {"score": 0.0023029886389559122, "phrase": "strong_empirical_and_theoretical_results"}, {"score": 0.0021597662797996843, "phrase": "general_design_principle"}, {"score": 0.0021322065604537617, "phrase": "post-processing_step"}, {"score": 0.0021049977753042253, "phrase": "information_retrieval_systems"}], "paper_keywords": ["regularization", " cluster hypothesis", " cluster-based retrieval", " pseudo-relevance feedback", " query expansion", " document expansion"], "paper_abstract": "We adapt the cluster hypothesis for score-based information retrieval by claiming that closely related documents should have similar scores. Given a retrieval from an arbitrary system, we describe an algorithm which directly optimizes this objective by adjusting retrieval scores so that topically related documents receive similar scores. We refer to this process as score regularization. Because score regularization operates on retrieval scores, regardless of their origin, we can apply the technique to arbitrary initial retrieval rankings. Document rankings derived from regularized scores, when compared to rankings derived from un-regularized scores, consistently and significantly result in improved performance given a variety of baseline retrieval algorithms. We also present several proofs demonstrating that regularization generalizes methods such as pseudo-relevance feedback, document expansion, and cluster-based retrieval. Because of these strong empirical and theoretical results, we argue for the adoption of score regularization as general design principle or post-processing step for information retrieval systems.", "paper_title": "Regularizing query-based retrieval scores", "paper_id": "WOS:000250465600003"}