{"auto_keywords": [{"score": 0.04879536524099014, "phrase": "skull_base"}, {"score": 0.027507999683207576, "phrase": "image_features"}, {"score": 0.00481495049065317, "phrase": "video-based_navigation_for_endoscopic_endonasal_skull_base_surgery"}, {"score": 0.0045108906244892165, "phrase": "critical_anatomy"}, {"score": 0.004318881178805575, "phrase": "endoscopic_endonasal_skull_base_surgery"}, {"score": 0.004068087482412997, "phrase": "neurovascular_structures"}, {"score": 0.003958937342925219, "phrase": "today's_navigation_systems"}, {"score": 0.0037697665240643066, "phrase": "indirect_relationship"}, {"score": 0.0037087324991876727, "phrase": "navigation_system"}, {"score": 0.003308195943172624, "phrase": "video_data"}, {"score": 0.003236941658990869, "phrase": "endoscope_camera"}, {"score": 0.0031500213134140953, "phrase": "image_feature_points"}, {"score": 0.003032228032253871, "phrase": "image_feature"}, {"score": 0.0028715299874549245, "phrase": "reconstructed_point_cloud"}, {"score": 0.002779217021776702, "phrase": "preoperative_computed_tomography"}, {"score": 0.0026607205525625995, "phrase": "initial_registration"}, {"score": 0.002347378595930709, "phrase": "current_camera_pose"}, {"score": 0.002128067018576581, "phrase": "target_registration_error"}, {"score": 0.00210500153723021, "phrase": "tre"}], "paper_keywords": ["Endoscopy", " image-guided treatment", " registration", " surgical guidance/navigation"], "paper_abstract": "Surgeries of the skull base require accuracy to safely navigate the critical anatomy. This is particularly the case for endoscopic endonasal skull base surgery (ESBS) where the surgeons work within millimeters of neurovascular structures at the skull base. Today's navigation systems provide approximately 2 mm accuracy. Accuracy is limited by the indirect relationship of the navigation system, the image and the patient. We propose a method to directly track the position of the endoscope using video data acquired from the endoscope camera. Our method first tracks image feature points in the video and reconstructs the image feature points to produce 3D points, and then registers the reconstructed point cloud to a surface segmented from preoperative computed tomography (CT) data. After the initial registration, the system tracks image features and maintains the 2D-3D correspondence of image features and 3D locations. These data are then used to update the current camera pose. We present a method for validation of our system, which achieves submillimeter (0.70 mm mean) target registration error (TRE) results.", "paper_title": "A System for Video-Based Navigation for Endoscopic Endonasal Skull Base Surgery", "paper_id": "WOS:000302547400010"}