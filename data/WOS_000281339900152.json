{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multi-valued_attribute_decomposition"}, {"score": 0.04928674718599398, "phrase": "multi-label_learning"}, {"score": 0.004466519142879166, "phrase": "-labeled_learning"}, {"score": 0.0037480753312398754, "phrase": "new_learning_framework"}, {"score": 0.003418958653159371, "phrase": "multi-valued_attribute"}, {"score": 0.003306559295382181, "phrase": "five_methods"}, {"score": 0.003066945490483524, "phrase": "multi_values"}, {"score": 0.0029909851863915283, "phrase": "data_transformation"}, {"score": 0.0027974705482714884, "phrase": "experimental_results"}, {"score": 0.0026384167183586015, "phrase": "existing_decision_tree_based_algorithms"}, {"score": 0.0024065032567542107, "phrase": "combined_method"}, {"score": 0.0023079225317714793, "phrase": "optimal_combination"}, {"score": 0.0022507188208913394, "phrase": "different_types"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Classification", " Decision tree", " Multi-valued attribute decomposition", " Multi-label learning", " Data transformation"], "paper_abstract": "Multi-valued and multi-labeled learning is concerned with samples associated with a set of values both with label and attribute. This paper proposes a new learning framework, which combines multi-valued attribute decomposition with multi-label learning. To deal with multi-valued attribute, we present five methods which differ in strategies with the correlations of multi values. After data transformation, three classic multi-label algorithms are employed for learning. Experimental results demonstrate that most combined methods significantly outperform the existing decision tree based algorithms. Furthermore, exploring the advantages and limitations of each combined method, we find the optimal combination corresponding to different types of datasets. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Combine multi-valued attribute decomposition with multi-label learning", "paper_id": "WOS:000281339900152"}