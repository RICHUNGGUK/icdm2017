{"auto_keywords": [{"score": 0.03638002405234209, "phrase": "hyb"}, {"score": 0.017101043809602406, "phrase": "coo"}, {"score": 0.016998470995151168, "phrase": "csr"}, {"score": 0.016896368979494602, "phrase": "ell"}, {"score": 0.010612382822272996, "phrase": "performance_analysis"}, {"score": 0.010485027649418183, "phrase": "gpu"}, {"score": 0.008174716014317459, "phrase": "sparse_matrix"}, {"score": 0.008100625531969025, "phrase": "pmf"}, {"score": 0.007173101841490425, "phrase": "spmv"}, {"score": 0.0066276012319205005, "phrase": "estimated_value"}, {"score": 0.004785682967399109, "phrase": "optimization_for_spmv"}, {"score": 0.004727678014364335, "phrase": "probabilistic_modeling"}, {"score": 0.004641980000471692, "phrase": "unique_method"}, {"score": 0.004557828309570373, "phrase": "sparse_matrix-vector_multiplication"}, {"score": 0.004434439786037454, "phrase": "wide_adaptability"}, {"score": 0.004407474941517865, "phrase": "different_types"}, {"score": 0.004380673342749118, "phrase": "sparse_matrices"}, {"score": 0.004314377131918679, "phrase": "existing_methods"}, {"score": 0.004236139082910124, "phrase": "particular_sparse_matrices"}, {"score": 0.004121423202649493, "phrase": "additional_benchmarks"}, {"score": 0.004083876271505206, "phrase": "optimized_parameters"}, {"score": 0.0039854083031404764, "phrase": "probability_mass_function"}, {"score": 0.0037609217735040715, "phrase": "precisely_the_distribution_pattern"}, {"score": 0.003738037065221128, "phrase": "non-zero_elements"}, {"score": 0.0036367606686493227, "phrase": "theoretical_basis"}, {"score": 0.0033185114695278226, "phrase": "hardware_parameters"}, {"score": 0.0029190612790772675, "phrase": "theoretical_estimated_values"}, {"score": 0.0028924362743419523, "phrase": "tested_values"}, {"score": 0.0028748209350107743, "phrase": "high_consistency"}, {"score": 0.0027968664019097393, "phrase": "optimal_segmentation_threshold"}, {"score": 0.0027127202051739608, "phrase": "optimal_performance"}, {"score": 0.002567569159450693, "phrase": "estimated_speedup"}, {"score": 0.0025286424059485745, "phrase": "tested_speedup"}, {"score": 0.0024903043450159594, "phrase": "ten_tested_sparse_matrices"}, {"score": 0.0023570261027098293, "phrase": "relative_difference"}, {"score": 0.0023142006730269386, "phrase": "tested_value"}, {"score": 0.002265217884758413, "phrase": "performance_improvement"}, {"score": 0.002210502984649107, "phrase": "average_performance_improvement"}, {"score": 0.002190326602897302, "phrase": "optimal_solution"}, {"score": 0.0021243898166922177, "phrase": "automatic_solution"}, {"score": 0.0021049977753042253, "phrase": "cusparse_lib"}], "paper_keywords": ["GPU", " performance modeling", " probability mass function", " sparse matrix-vector multiplication"], "paper_abstract": "This paper presents a unique method of performance analysis and optimization for sparse matrix-vector multiplication (SpMV) on GPU. This method has wide adaptability for different types of sparse matrices and is different from existing methods which only adapt to some particular sparse matrices. In addition, our method does not need additional benchmarks to get optimized parameters, which are calculated directly through the probability mass function (PMF). We make the following contributions. (1) We present a PMF to analyze precisely the distribution pattern of non-zero elements in a sparse matrix. The PMF can provide theoretical basis for the compression of a sparse matrix. (2) Compression efficiency of COO, CSR, ELL, and HYB can be analyzed precisely through the PMF, and combined with the hardware parameters of GPU, the performance of SpMV based on COO, CSR, ELL, and HYB can be estimated. Furthermore, the most appropriate format for SpMV can be selected according to estimated value of the performance. Experiments prove that the theoretical estimated values and the tested values have high consistency. (3) For HYB, the optimal segmentation threshold can be found through the PMF to achieve the optimal performance for SpMV. Our performance modeling and analysis are very accurate. The order of magnitude of the estimated speedup and that of the tested speedup for each of the ten tested sparse matrices based on the three formats COO, CSR, and ELL are the same. The percentage of relative difference between an estimated value and a tested value is less than 20 percent for over 80 percent cases. The performance improvement of our algorithm is also effective. The average performance improvement of the optimal solution for HYB is over 15 percent compared with that of the automatic solution provided by CUSPARSE lib.", "paper_title": "Performance Analysis and Optimization for SpMV on GPU Using Probabilistic Modeling", "paper_id": "WOS:000348206700019"}