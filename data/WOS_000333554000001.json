{"auto_keywords": [{"score": 0.04496820109058902, "phrase": "multiple_views"}, {"score": 0.02909118388751685, "phrase": "imam"}, {"score": 0.0048208015580140234, "phrase": "domain"}, {"score": 0.004631099806015235, "phrase": "multi-view_learning"}, {"score": 0.004551647527068771, "phrase": "classification_performance"}, {"score": 0.004435006247087171, "phrase": "different_views"}, {"score": 0.004156259296367594, "phrase": "domain_adaptation"}, {"score": 0.004084920064588169, "phrase": "view_consistency"}, {"score": 0.00403221710768334, "phrase": "source_data"}, {"score": 0.003928834302530914, "phrase": "target_domain"}, {"score": 0.0038613835226952117, "phrase": "distribution_gap"}, {"score": 0.003828091961373454, "phrase": "different_domain_data"}, {"score": 0.003665874747419775, "phrase": "cross-domain_document_classification"}, {"score": 0.003525744120930142, "phrase": "views'_consistency"}, {"score": 0.0034953361767153285, "phrase": "target_data"}, {"score": 0.003405671497507337, "phrase": "domain-specific_features"}, {"score": 0.0032896745636186824, "phrase": "information-theoretic_multi-view"}, {"score": 0.003177615880037735, "phrase": "multi-way_clustering_scheme"}, {"score": 0.0031365819432206004, "phrase": "word_and_link_clusters"}, {"score": 0.002939202022371694, "phrase": "document_clusterings"}, {"score": 0.002863762666256937, "phrase": "respective_word"}, {"score": 0.002637377202509382, "phrase": "minimal_disagreement_rate"}, {"score": 0.0025808284847319528, "phrase": "view-based_clusterings"}, {"score": 0.002525489173110693, "phrase": "theoretical_and_empirical_justifications"}, {"score": 0.0024928553725344933, "phrase": "proposed_method"}, {"score": 0.0024078737745407614, "phrase": "traditional_multi-view_algorithm_co-training"}, {"score": 0.002305705177600838, "phrase": "coda"}, {"score": 0.0021049977753042253, "phrase": "mvtl-lm."}], "paper_keywords": [""], "paper_abstract": "Multi-view learning aims to improve classification performance by leveraging the consistency among different views of data. The incorporation of multiple views was paid little attention in the studies of domain adaptation, where the view consistency based on source data is largely violated in the target domain due to the distribution gap between different domain data. In this paper, we leverage multiple views for cross-domain document classification. The central idea is to strengthen the views' consistency on target data by identifying the associations of domain-specific features from different domains. We present an Information-theoretic Multi-view Adaptation Model (IMAM) using a multi-way clustering scheme, where word and link clusters can draw together seemingly unrelated features across domains, which boosts the consistency between document clusterings that are based on the respective word and link views. Moreover, we demonstrate that IMAM can always find the document clustering with the minimal disagreement rate to the overlap of view-based clusterings. We provide both theoretical and empirical justifications of the proposed method. Our experiments show that IMAM significantly outperforms traditional multi-view algorithm co-training, the co-training-based adaptation algorithm CODA, the single-view transfer model CoCC and the large-margin-based multi-view transfer model MVTL-LM.", "paper_title": "Information-Theoretic Multi-view Domain Adaptation: A Theoretical and Empirical Study", "paper_id": "WOS:000333554000001"}