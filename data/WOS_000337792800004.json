{"auto_keywords": [{"score": 0.038829551287483235, "phrase": "stationary_scenes"}, {"score": 0.03363896917055259, "phrase": "transformation_model"}, {"score": 0.01025069046710525, "phrase": "depth_information"}, {"score": 0.009332742460190523, "phrase": "non-stationary_regions"}, {"score": 0.0047292449487169345, "phrase": "recent_progress"}, {"score": 0.004686963264680882, "phrase": "multi-view_devices"}, {"score": 0.0046242451772036145, "phrase": "corresponding_signal_processing_techniques"}, {"score": 0.004582897918101983, "phrase": "stereoscopic_viewing_experience"}, {"score": 0.004421156723819163, "phrase": "growing_interest"}, {"score": 0.004342430078306461, "phrase": "depth_perception"}, {"score": 0.004303591748086452, "phrase": "human_vision"}, {"score": 0.00384633057714983, "phrase": "primary_contribution"}, {"score": 0.003660788124282824, "phrase": "non-stationary_objects"}, {"score": 0.003406713877432236, "phrase": "corresponding_stereoscopic_videos"}, {"score": 0.0032716011062067286, "phrase": "original_event"}, {"score": 0.0029901699209266435, "phrase": "vanishing_point"}, {"score": 0.0027575842698911173, "phrase": "motion_analysis"}, {"score": 0.0024202176034746337, "phrase": "synthesized_views"}, {"score": 0.002398529964696261, "phrase": "performance_comparison"}, {"score": 0.002366361492754389, "phrase": "ground_truth"}, {"score": 0.0023346234464901978, "phrase": "famous_multi-view_video_synthesis_algorithm"}, {"score": 0.002313701040445819, "phrase": "vsrs"}, {"score": 0.002272415777234064, "phrase": "six_views"}, {"score": 0.0021336208506092173, "phrase": "proposed_method"}], "paper_keywords": ["View synthesis", " 2D to 3D video conversion", " Vanishing point", " Motion analysis"], "paper_abstract": "With the recent progress of multi-view devices and the corresponding signal processing techniques, stereoscopic viewing experience has been introduced to the public with growing interest. To create depth perception in human vision, two different video sequences in binocular vision are required for viewers. Those videos can be either captured by 3D-enabled cameras or synthesized as needed. The primary contribution of this paper is to establish two transformation models for stationary scenes and non-stationary objects in a given view, respectively. The models can be used for the production of corresponding stereoscopic videos as a viewer would have seen at the original event of the scene. The transformation model to estimate the depth information for stationary scenes is based on the information of the vanishing point and vanishing lines of the given video. The transformation model for non-stationary regions is the result of combining the motion analysis of the non-stationary regions and the transformation model for stationary scenes to estimate the depth information. The performance of the models is evaluated using subjective 3D video quality evaluation and objective quality evaluation on the synthesized views. Performance comparison with the ground truth and a famous multi-view video synthesis algorithm, VSRS, which requires six views to complete synthesis, is also presented. It is shown that the proposed method can provide better perceptual 3D video quality with natural depth perception.", "paper_title": "Depth Estimation and Video Synthesis for 2D to 3D Video Conversion", "paper_id": "WOS:000337792800004"}