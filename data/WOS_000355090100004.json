{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "neighborhood_rank_difference"}, {"score": 0.03226147039959236, "phrase": "influence_space"}, {"score": 0.004195418010131832, "phrase": "novel_dynamic_outlier_detection_method"}, {"score": 0.003816197777388722, "phrase": "forward_nearest_neighbor_rank_difference"}, {"score": 0.003471135453226184, "phrase": "test_point"}, {"score": 0.0032398798149196432, "phrase": "first_step"}, {"score": 0.002726740692380339, "phrase": "second_step"}, {"score": 0.0026570998719084153, "phrase": "rank_difference"}, {"score": 0.0025449518236394103, "phrase": "absolute_density"}, {"score": 0.0023958326775913165, "phrase": "synthetic_and_some_uci_machine_learning_repository_datasets"}, {"score": 0.0022168460543913787, "phrase": "recently_published_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Outlier", " Rank-difference", " kNN", " RNN"], "paper_abstract": "Presence of outliers critically affects many pattern classification tasks. In this paper, we propose a novel dynamic outlier detection method based on neighborhood rank difference. In particular, reverse and the forward nearest neighbor rank difference is employed to capture the variations in densities of a test point with respect to various training points. In the first step of our method, we determine the influence space for a given dataset. A score for outlierness is proposed in the second step using the rank difference as well as the absolute density within this influence space. Experiments on synthetic and some UCI machine learning repository datasets clearly indicate the supremacy of our method over some recently published approaches. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Outlier detection using neighborhood rank difference", "paper_id": "WOS:000355090100004"}