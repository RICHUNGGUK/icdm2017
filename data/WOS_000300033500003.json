{"auto_keywords": [{"score": 0.037494894514464305, "phrase": "core_types"}, {"score": 0.015719716506582538, "phrase": "performance_heterogeneous_multicore_systems"}, {"score": 0.00816581599072906, "phrase": "eshmp"}, {"score": 0.0047910471257663805, "phrase": "performance_heterogeneous_multicore_processors"}, {"score": 0.004767267169056115, "phrase": "hmp"}, {"score": 0.004696608876994947, "phrase": "multiple_cores"}, {"score": 0.0046269981365987915, "phrase": "different_performance_characteristics"}, {"score": 0.004479678062285735, "phrase": "great_concern"}, {"score": 0.004402295697276237, "phrase": "higher_performance"}, {"score": 0.004315487055548749, "phrase": "diverse_architectural_requirements"}, {"score": 0.004294052530714228, "phrase": "comparable_homogeneous_ones"}, {"score": 0.003906357144047631, "phrase": "previous_work"}, {"score": 0.0037537380967196123, "phrase": "scheduling_algorithms"}, {"score": 0.0036250779580069455, "phrase": "previous_online_monitoring_approaches"}, {"score": 0.0035891316580885665, "phrase": "threads'_execution"}, {"score": 0.0034146585649631692, "phrase": "core_types_threads"}, {"score": 0.003322328254011141, "phrase": "load_imbalance"}, {"score": 0.003264872488939969, "phrase": "existing_offline"}, {"score": 0.00299958349498286, "phrase": "phase_changes"}, {"score": 0.0028608109787377255, "phrase": "offline_profiling_approaches"}, {"score": 0.002769568481822277, "phrase": "program_performance"}, {"score": 0.0027148677103585985, "phrase": "existing_approaches"}, {"score": 0.0026812282414768536, "phrase": "new_technique"}, {"score": 0.0025571463140118805, "phrase": "fast_cores"}, {"score": 0.002500386390058989, "phrase": "new_online_monitoring_approach"}, {"score": 0.002355095952113386, "phrase": "wide_variety"}, {"score": 0.0022970729721700604, "phrase": "hmp_systems"}, {"score": 0.0022799458141165587, "phrase": "heterogeneity-aware_schedulers"}, {"score": 0.002234893735225432, "phrase": "last_level"}, {"score": 0.002196202433718105, "phrase": "heterogeneous_cores"}, {"score": 0.002174393953583877, "phrase": "better_performance"}, {"score": 0.0021474369836979048, "phrase": "homogeneous_cores"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Performance heterogeneous multicore", " Scheduling", " Algorithm", " Operating systems"], "paper_abstract": "Performance heterogeneous multicore processors (HMP for brevity) consisting of multiple cores with the same instruction set but different performance characteristics (e.g., clock speed, issue width), are of great concern since they are able to deliver higher performance per watt and area for programs with diverse architectural requirements than comparable homogeneous ones. However, such power and area efficiencies of performance heterogeneous multicore systems can only be achieved when workloads are matched with cores according to both the properties of the workload and the features of the cores. Several heterogeneity-aware schedulers were proposed in the previous work. In terms of whether properties of workloads are obtained online or not, those scheduling algorithms can be categorized into two classes: online monitoring and offline profiling. The previous online monitoring approaches had to trace threads' execution on all core types, which is impractical as the number of core types grows. Besides, to trace all core types threads have to be migrated among cores, which may cause load imbalance and degrade the performance. The existing offline profiling approaches profile programs with a given input set before really executing them and thus remove the overhead associated with the number of core types. However, offline profiling approaches do not account for phase changes of threads. Moreover, since the properties they have collected are based on the given input set, those offline profiling approaches are hard to adapt to various input sets and therefore will drastically affect the program performance. To address the above problems in the existing approaches, we propose a new technique, ASTPI (Average Stall Time Per Instruction), to measure the efficiencies of threads in using fast cores. We design, implement and evaluate a new online monitoring approach called ESHMP, which is based on the metric. Our evaluation in the Linux 2.6.21 operating system shows that ESHMP delivers scalability while adapting to a wide variety of applications. Also, our experiment results show that among HMP systems in which heterogeneity-aware schedulers are adopted and there are more than one LLC (Last Level Cache), the architecture where heterogeneous cores share LLCs gain better performance than the ones where homogeneous cores share LLCs. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Efficient and scalable scheduling for performance heterogeneous multicore systems", "paper_id": "WOS:000300033500003"}