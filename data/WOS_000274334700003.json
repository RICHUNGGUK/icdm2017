{"auto_keywords": [{"score": 0.04963419481547922, "phrase": "search_effectiveness_metrics"}, {"score": 0.02875806215342705, "phrase": "static_distributions"}, {"score": 0.00481495049065317, "phrase": "decaying_weight_distributions"}, {"score": 0.00453144352814823, "phrase": "answer_lists"}, {"score": 0.004468415400599571, "phrase": "search_services"}, {"score": 0.004304574865291508, "phrase": "relevance_judgments"}, {"score": 0.004185632403886255, "phrase": "effectiveness_score"}, {"score": 0.004127394241838696, "phrase": "system_run"}, {"score": 0.003976007772514762, "phrase": "run's_relevance_vector"}, {"score": 0.003920674807745575, "phrase": "\"utility\"_vector"}, {"score": 0.003848088904418221, "phrase": "ith_element"}, {"score": 0.00379452936798156, "phrase": "utility_vector"}, {"score": 0.003741712498615481, "phrase": "relative_benefit"}, {"score": 0.0035376693476114733, "phrase": "relevant_document"}, {"score": 0.00329813918116714, "phrase": "user_behavior_patterns"}, {"score": 0.0032370412139943808, "phrase": "utility_weightings"}, {"score": 0.0031182092708983184, "phrase": "web_query_log"}, {"score": 0.003003726508522467, "phrase": "user_observations"}, {"score": 0.0029757667083164627, "phrase": "query_log_clickthroughs"}, {"score": 0.0029069972482610403, "phrase": "user_model"}, {"score": 0.0028133741785871867, "phrase": "weighting_distributions"}, {"score": 0.0025741370320813968, "phrase": "weight_vector"}, {"score": 0.002514625755809045, "phrase": "relevance_vector"}, {"score": 0.00246800641971897, "phrase": "geometric_weighting_model"}, {"score": 0.002422249273477746, "phrase": "rank-biased_precision_effectiveness"}, {"score": 0.00237733844863506, "phrase": "closest_fit"}, {"score": 0.0023442013458139497, "phrase": "user_observation_model"}, {"score": 0.0021049977753042253, "phrase": "bpref_and_mrr_metrics"}], "paper_keywords": ["Effectiveness metric", " Query log", " Clickthrough", " Rank-biased precision", " Average precision", " Reciprocal rank", " BPref"], "paper_abstract": "Search effectiveness metrics are used to evaluate the quality of the answer lists returned by search services, usually based on a set of relevance judgments. One plausible way of calculating an effectiveness score for a system run is to compute the inner-product of the run's relevance vector and a \"utility\" vector, where the ith element in the utility vector represents the relative benefit obtained by the user of the system if they encounter a relevant document at depth i in the ranking. This paper uses such a framework to examine the user behavior patterns-and hence utility weightings-that can be inferred from a web query log. We describe a process for extrapolating user observations from query log clickthroughs, and employ this user model to measure the quality of effectiveness weighting distributions. Our results show that for measures with static distributions (that is, utility weighting schemes for which the weight vector is independent of the relevance vector), the geometric weighting model employed in the rank-biased precision effectiveness metric offers the closest fit to the user observation model. In addition, using past TREC data as to indicate likelihood of relevance, we also show that the distributions employed in the BPref and MRR metrics are the best fit out of the measures for which static distributions do not exist.", "paper_title": "Click-based evidence for decaying weight distributions in search effectiveness metrics", "paper_id": "WOS:000274334700003"}