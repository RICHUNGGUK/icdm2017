{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "reward-punishment_editing"}, {"score": 0.004059438255358923, "phrase": "training_set"}, {"score": 0.003987126862293129, "phrase": "first_problem"}, {"score": 0.0038119123317396954, "phrase": "inexpensive_memory"}, {"score": 0.003777800904236079, "phrase": "high_processing_speeds"}, {"score": 0.0037272031155266556, "phrase": "second_one"}, {"score": 0.003499864176875713, "phrase": "proper_set"}, {"score": 0.0033011569787033297, "phrase": "editing_technique"}, {"score": 0.003071965703296204, "phrase": "correct_classification"}, {"score": 0.0029767499830258754, "phrase": "wrong_one"}, {"score": 0.002820319063320601, "phrase": "global_level"}, {"score": 0.0027206133859493725, "phrase": "different_scales"}, {"score": 0.0025089420019955232, "phrase": "predefined_threshold"}, {"score": 0.0024421008630165046, "phrase": "extensive_experimentation"}, {"score": 0.0023033100935570755, "phrase": "proposed_technique"}, {"score": 0.002143247921132179, "phrase": "condensing_techniques"}, {"score": 0.0021049977753042253, "phrase": "pre-processing_stage"}], "paper_keywords": ["Editing", " Nearest neighbor classifier"], "paper_abstract": "The nearest neighbor (NN) classifier represents one of the most popular non-parametric classification approaches and has been successfully applied in several pattern recognition problems. The two main limitations of this technique are its computational complexity and its sensitivity to the presence of outliers in the training set. Though the first problem has been partially overcome thanks to the availability of inexpensive memory and high processing speeds, the second one still persists, and several editing and condensing techniques have been proposed, aimed at selecting a proper set of prototypes from the training set. In this work, an editing technique is proposed, based on the idea of rewarding the patterns that contribute to a correct classification and punishing those that provide a wrong one. The analysis is carried out both at local and at global level, by analyzing the training set at different scales. A score is calculated for each pattern, and the patterns whose score is lower than a predefined threshold are edited out. An extensive experimentation has been conducted on several classification problems both to evaluate the efficacy of the proposed technique with respect to other editing approaches and to investigate the advantage of using reward-punishment editing in combination with condensing techniques or as a pre-processing stage when classifiers different from the NN are adopted.", "paper_title": "Data pre-processing through reward-punishment editing", "paper_id": "WOS:000283304500001"}