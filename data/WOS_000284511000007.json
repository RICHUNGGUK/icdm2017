{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "limited_user_environment"}, {"score": 0.03866447565465427, "phrase": "collaborative_filtering"}, {"score": 0.004780030485538593, "phrase": "search_engines"}, {"score": 0.004711156119191085, "phrase": "google"}, {"score": 0.004625983640628956, "phrase": "news_articles"}, {"score": 0.0040135756033094225, "phrase": "relevance_scores"}, {"score": 0.0035719191251314918, "phrase": "recommendation_systems"}, {"score": 0.003357343256340741, "phrase": "general_framework"}, {"score": 0.0029768089698126547, "phrase": "topic_relevance"}, {"score": 0.0029123920023263446, "phrase": "source_reputation"}, {"score": 0.002747328139245956, "phrase": "online_parameter_selection"}, {"score": 0.002727362288104992, "phrase": "language_models"}, {"score": 0.0026878636586288363, "phrase": "sentiment_analysis"}, {"score": 0.0025727581823022268, "phrase": "varying_reasons"}, {"score": 0.0024625698287060586, "phrase": "online_feature_selection_method"}, {"score": 0.002435902318721367, "phrase": "bayes"}, {"score": 0.0023830293456003765, "phrase": "recommendation_results"}, {"score": 0.002339953069296797, "phrase": "traditional_ir_techniques"}, {"score": 0.002247900207250435, "phrase": "news_recommendation_task"}, {"score": 0.0022153516654452345, "phrase": "yahoo"}, {"score": 0.002199348795227231, "phrase": "news"}, {"score": 0.002151604436222692, "phrase": "digg"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["News filtering", " Personalization", " News recommendation"], "paper_abstract": "Search engines, such as Google, assign scores to news articles based on their relevance to a query. However, not all relevant articles for the query may be interesting to a user. For example, if the article is old or yields little new information, the article would be uninteresting. Relevance scores do not take into account what makes an article interesting, which would vary from user to user. Although methods such as collaborative filtering have been shown to be effective in recommendation systems, in a limited user environment, there are not enough users that would make collaborative filtering effective. A general framework, called iScore, is presented for defining and measuring the \"interestingness\" of articles, incorporating user-feedback. iScore addresses the various aspects of what makes an article interesting, such as topic relevance, uniqueness, freshness, source reputation, and writing style. It employs various methods, such as multiple topic tracking, online parameter selection, language models, clustering, sentiment analysis, and phrase extraction to measure these features. Due to varying reasons that users hold about why an article is interesting, an online feature selection method in naive Bayes is also used to improve recommendation results. iScore can outperform traditional IR techniques by as much as 50.7%. iScore and its components are evaluated in the news recommendation task using three datasets from Yahoo! News, actual users, and Digg. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Measuring the interestingness of articles in a limited user environment", "paper_id": "WOS:000284511000007"}