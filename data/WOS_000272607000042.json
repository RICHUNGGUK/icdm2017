{"auto_keywords": [{"score": 0.045945050752891264, "phrase": "gepsvm"}, {"score": 0.03396016460032381, "phrase": "lipsvm"}, {"score": 0.015719714774698124, "phrase": "local_information"}, {"score": 0.004740126725341152, "phrase": "standard_support_vector_machines"}, {"score": 0.004487241576747549, "phrase": "quadratic_program"}, {"score": 0.004298006360831255, "phrase": "generalized_eigenvalues"}, {"score": 0.003989675045520656, "phrase": "simple_geometric_interpretation"}, {"score": 0.0035332058983966424, "phrase": "computation_time"}, {"score": 0.0035056109035307716, "phrase": "test_correctness"}, {"score": 0.003397362086358944, "phrase": "geometric_intuition"}, {"score": 0.0033314049082500794, "phrase": "new_supervised_learning_method"}, {"score": 0.00310435218261112, "phrase": "proximity_information"}, {"score": 0.003056029284235528, "phrase": "underlying_information"}, {"score": 0.002926973459215349, "phrase": "training_points"}, {"score": 0.0028588847851995533, "phrase": "aforementioned_characteristics"}, {"score": 0.0028365413717574544, "phrase": "cepsvm"}, {"score": 0.0025715131759585052, "phrase": "generalized_eigenvalue_problem"}, {"score": 0.002541417196444962, "phrase": "matrix_singularity"}, {"score": 0.0024436119167523156, "phrase": "eigenvalue-based_classifiers"}, {"score": 0.002206536029072657, "phrase": "artificial_and_benchmark_datasets"}, {"score": 0.0021636476333109144, "phrase": "lipsvm._crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Proximal classification", " Eigenvalue", " Manifold learning", " Outlier"], "paper_abstract": "Instead of standard support vector machines (SVMs) that classify points to one of two disjoint half-spaces by solving a quadratic program, the plane classifier GEPSVM (proximal SVM classification via generalized eigenvalues) classifies points by assigning them to the closest of two nonparallel planes which are generated by their corresponding generalized eigenvalue problems. A simple geometric interpretation of GEPSVM is that each plane is closest to the points of its own class and furthest to the points of the other class. Analysis and experiments have demonstrated its capability in both computation time and test correctness. In this paper, following the geometric intuition of GEPSVM, a new supervised learning method called proximal support vector machine using local information (LIPSVM) is proposed. With the introduction of proximity information (consideration of underlying information such as correlation or similarity between points) between the training points, LIPSVM not only keeps aforementioned characteristics of CEPSVM, but also has its additional advantages: (1) robustness to outliers; (2) each plane is generated from its corresponding standard rather than generalized eigenvalue problem to avoid matrix singularity; (3) comparable classification ability to the eigenvalue-based classifiers GEPSVM and LDA. Furthermore, the idea of LIPSVM can be easily extended to other classifiers, such as LDA. Finally, some experiments on the artificial and benchmark datasets show the effectiveness of LIPSVM. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.", "paper_title": "Proximal support vector machine using local information", "paper_id": "WOS:000272607000042"}