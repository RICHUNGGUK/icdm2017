{"auto_keywords": [{"score": 0.015274483805397329, "phrase": "salient_object_detection"}, {"score": 0.00481495049065317, "phrase": "salient_object"}, {"score": 0.004768901219709549, "phrase": "dataset"}, {"score": 0.004617112284856892, "phrase": "salient_region_detection_models"}, {"score": 0.00455788259881503, "phrase": "fixation_prediction_models"}, {"score": 0.004190904630161064, "phrase": "multiple_objects"}, {"score": 0.0041104856245548285, "phrase": "current_datasets"}, {"score": 0.004057728601458481, "phrase": "saliency_detection_approaches"}, {"score": 0.003816197777388722, "phrase": "in-depth_look"}, {"score": 0.0033971539563683174, "phrase": "saliency_judgments"}, {"score": 0.0032468685934998335, "phrase": "highest_fraction"}, {"score": 0.0030832123624449028, "phrase": "existing_saliency_models"}, {"score": 0.003014223770316234, "phrase": "severe_drop"}, {"score": 0.0029754949467239887, "phrase": "eight_state-of-the-art_models"}, {"score": 0.0027444334639134217, "phrase": "model_evaluation"}, {"score": 0.0026657070241024963, "phrase": "best_models"}, {"score": 0.002555950807368337, "phrase": "serious_drawback"}, {"score": 0.0025394700487126414, "phrase": "existing_models"}, {"score": 0.002380381895973937, "phrase": "statistical_analysis"}, {"score": 0.0022823466001223986, "phrase": "salient_object_detection_models"}, {"score": 0.0021601997088758957, "phrase": "existing_biased_data_sets"}, {"score": 0.0021393317071153844, "phrase": "new_venues"}, {"score": 0.0021255315818671963, "phrase": "future_research"}, {"score": 0.0021049977753042253, "phrase": "fast-evolving_field"}], "paper_keywords": ["Salient object detection", " explicit saliency", " bottom-up attention", " regions of interest", " eye movements"], "paper_abstract": "Salient object detection or salient region detection models, diverging from fixation prediction models, have traditionally been dealing with locating and segmenting the most salient object or region in a scene. While the notion of most salient object is sensible when multiple objects exist in a scene, current datasets for evaluation of saliency detection approaches often have scenes with only one single object. We introduce three main contributions in this paper. First, we take an in-depth look at the problem of salient object detection by studying the relationship between where people look in scenes and what they choose as the most salient object when they are explicitly asked. Based on the agreement between fixations and saliency judgments, we then suggest that the most salient object is the one that attracts the highest fraction of fixations. Second, we provide two new less biased benchmark data sets containing scenes with multiple objects that challenge existing saliency models. Indeed, we observed a severe drop in performance of eight state-of-the-art models on our data sets (40%-70%). Third, we propose a very simple yet powerful model based on superpixels to be used as a baseline for model evaluation and comparison. While on par with the best models on MSRA-5 K data set, our model wins over other models on our data highlighting a serious drawback of existing models, which is convoluting the processes of locating the most salient object and its segmentation. We also provide a review and statistical analysis of some labeled scene data sets that can be used for evaluating salient object detection models. We believe that our work can greatly help remedy the over-fitting of models to existing biased data sets and opens new venues for future research in this fast-evolving field.", "paper_title": "What is a Salient Object? A Dataset and a Baseline Model for Salient Object Detection", "paper_id": "WOS:000348375400002"}