{"auto_keywords": [{"score": 0.048602309644257866, "phrase": "linguistic_modifiers"}, {"score": 0.0437544826472625, "phrase": "fuzzy_sets"}, {"score": 0.03269286109052258, "phrase": "fuzzy_models"}, {"score": 0.032198834518680594, "phrase": "gm_performance"}, {"score": 0.02949532097507259, "phrase": "good_submodel_interpretability"}, {"score": 0.00481495049065317, "phrase": "extracting_takagi-sugeno"}, {"score": 0.004740126725341152, "phrase": "interpretable_submodels"}, {"score": 0.004348813532606792, "phrase": "ts_submodel_comprehensibility"}, {"score": 0.0041328796505374155, "phrase": "good_property"}, {"score": 0.004068611852912931, "phrase": "proposed_linguistic_modifiers"}, {"score": 0.0038363485899400285, "phrase": "adjoining_membership_functions"}, {"score": 0.003732526540522333, "phrase": "fuzzy_systems"}, {"score": 0.0036031440110534853, "phrase": "ts_submodels"}, {"score": 0.00351938145050947, "phrase": "system_behaviors"}, {"score": 0.0034510635632071978, "phrase": "global_model"}, {"score": 0.003424183788593921, "phrase": "gm"}, {"score": 0.0033840673522948592, "phrase": "corresponding_subareas"}, {"score": 0.0033183674218329904, "phrase": "good_ts_model_interpretability"}, {"score": 0.003279559293934528, "phrase": "distinguishable_input_space_partitioning"}, {"score": 0.0032158817866929563, "phrase": "gm_accuracy"}, {"score": 0.0028365413717574544, "phrase": "ts_fuzzy_model"}, {"score": 0.0027060907634889734, "phrase": "good_tradeoff"}, {"score": 0.0026639507068734907, "phrase": "submodel_interpretability"}, {"score": 0.0026327757304477665, "phrase": "regularization_learning_algorithm"}, {"score": 0.0025715131759585052, "phrase": "gm_objective_function"}, {"score": 0.0025215486544004134, "phrase": "local_model_objective_function"}, {"score": 0.002462867872567125, "phrase": "extended_index"}, {"score": 0.002424506147893058, "phrase": "identified_mfs"}, {"score": 0.0023773911659018825, "phrase": "parsimonious_rule_base"}, {"score": 0.0023220573674955776, "phrase": "qr_decomposition_method"}, {"score": 0.002285883886723896, "phrase": "important_fuzzy_rules"}, {"score": 0.002250272652754455, "phrase": "redundant_ones"}, {"score": 0.002232675154416128, "phrase": "experimental_studies"}, {"score": 0.0021892798077661956, "phrase": "ts_models"}, {"score": 0.0021551702945512494, "phrase": "suggested_method"}, {"score": 0.0021215910859085146, "phrase": "satisfactory_gm_performance"}, {"score": 0.0021049977753042253, "phrase": "parsimonious_rule_bases"}], "paper_keywords": ["Interpretability", " distinguishability", " knowledge extraction", " local models", " submodels", " Takagi-Sugeno fuzzy models", " regularization", " fuzziness"], "paper_abstract": "In this paper, a method for constructing Takagi-Sugeno (TS) fuzzy system from data is proposed with the objective of preserving TS submodel comprehensibility, in which linguistic modifiers are suggested to characterize the fuzzy sets. A good property held by the proposed linguistic modifiers is that they can broaden the cores of fuzzy sets while contracting the overlaps of adjoining membership functions (MFs) during identification of fuzzy systems from data. As a result, the TS submodels identified tend to dominate the system behaviors by automatically matching the global model (GM) in corresponding subareas, which leads to good TS model interpretability while producing distinguishable input space partitioning. However, the GM accuracy and model interpretability are two conflicting modeling objectives, improving interpretability of fuzzy models generally degrades the GM performance of fuzzy models, and vice versa. Hence, one challenging problem is how to construct a TS fuzzy model with not only good global performance but also good submodel interpretability. In order to achieve a good tradeoff between GM performance and submodel interpretability, a regularization learning algorithm is presented in which the GM objective function is combined with a local model objective function defined in terms of an extended index of fuzziness of identified MFs. Moreover, a parsimonious rule base is obtained by adopting a QR decomposition method to select the important fuzzy rules and reduce the redundant ones. Experimental studies have shown that the TS models identified by the suggested method possess good submodel interpretability and satisfactory GM performance with parsimonious rule bases.", "paper_title": "Extracting Takagi-Sugeno Fuzzy Rules with Interpretable Submodels via Regularization of Linguistic Modifiers", "paper_id": "WOS:000267122600008"}