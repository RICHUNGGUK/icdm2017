{"auto_keywords": [{"score": 0.03371796317805148, "phrase": "kinect"}, {"score": 0.00481495049065317, "phrase": "occluded_scenes"}, {"score": 0.00456571874088313, "phrase": "kinect_depth_data"}, {"score": 0.004392565073466714, "phrase": "frontal_gait_recognition"}, {"score": 0.003855034057431947, "phrase": "front_views"}, {"score": 0.0035852640843794252, "phrase": "back_view"}, {"score": 0.0034995881411519925, "phrase": "depth_information"}, {"score": 0.003350480663660326, "phrase": "periodic_variation"}, {"score": 0.0033021988455635403, "phrase": "skeleton_structure"}, {"score": 0.0032546105164772995, "phrase": "lower_body_region"}, {"score": 0.003115908199991072, "phrase": "front_view"}, {"score": 0.003070996252787868, "phrase": "feature_sets"}, {"score": 0.0030414140732789186, "phrase": "gait_dynamics"}, {"score": 0.002997572637726648, "phrase": "high_resolution"}, {"score": 0.002883718207958817, "phrase": "congested_places"}, {"score": 0.002828418443899226, "phrase": "railway_stations"}, {"score": 0.002801166393333128, "phrase": "shopping_malls"}, {"score": 0.0027741761880779535, "phrase": "multiple_persons"}, {"score": 0.0027209713296448296, "phrase": "surveillance_zone"}, {"score": 0.0025549840900344596, "phrase": "proposed_recognition_procedure"}, {"score": 0.0025181367444581993, "phrase": "unoccluded_frames"}, {"score": 0.0024818194799172263, "phrase": "cluttered_test_sequence"}, {"score": 0.002446024708601971, "phrase": "matching_frames"}, {"score": 0.0024107449502335583, "phrase": "training_sequence"}, {"score": 0.002387507583705495, "phrase": "dynamic_programming"}, {"score": 0.0023759728305710365, "phrase": "based_local_sequence_alignment"}, {"score": 0.0023079225317714815, "phrase": "frame_correspondence"}, {"score": 0.0022094759531152072, "phrase": "encouraging_results"}, {"score": 0.0021881743793875767, "phrase": "different_levels"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Frontal gait recognition", " Kinect", " Occlusion", " Sequence alignment"], "paper_abstract": "In this paper, we propose a method using Kinect depth data to address the problem of occlusion in frontal gait recognition. We consider situations where such depth cameras are mounted on top of entry and exit points of a zone under surveillance, respectively capturing the back and front views of each subject passing through the zone. A feature set corresponding to the back view is derived from the depth information along the contour of the silhouette, while periodic variation of the skeleton structure of the lower body region as estimated by Kinect is extracted from the front view. These feature sets preserve gait dynamics at a high resolution and can be extracted efficiently. In congested places like airports, railway stations and shopping malls, multiple persons move into the surveillance zone one after another, thereby causing occlusion of the target. The proposed recognition procedure compares the unoccluded frames of a cluttered test sequence with the matching frames of a training sequence. Dynamic programming based local sequence alignment is used to determine this frame correspondence. The method is computationally efficient and shows encouraging results under different levels of occlusion. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Frontal gait recognition from occluded scenes", "paper_id": "WOS:000359888900002"}