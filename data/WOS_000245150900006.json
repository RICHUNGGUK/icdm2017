{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "inertial_sensors"}, {"score": 0.0352477219827226, "phrase": "collaborative_process"}, {"score": 0.03473184552256374, "phrase": "vision-based_system"}, {"score": 0.004742290714667451, "phrase": "video_tracking"}, {"score": 0.004623608221548592, "phrase": "biggest_obstacles"}, {"score": 0.004553822674247401, "phrase": "effective_augmented_reality"}, {"score": 0.0043506951029334984, "phrase": "accurate_sensors"}, {"score": 0.00409382470158851, "phrase": "arbitrary_long_periods"}, {"score": 0.003871653343842317, "phrase": "effective_hybrid_approach"}, {"score": 0.0038131738052230254, "phrase": "inertial_and_vision-based_technologies"}, {"score": 0.0035337158050484474, "phrase": "relatively_poor_accuracy"}, {"score": 0.003393115177189967, "phrase": "efficient_strategy"}, {"score": 0.0029735479904284706, "phrase": "sensitivity_error"}, {"score": 0.002686360550456695, "phrase": "matching_stage"}, {"score": 0.002592523232809191, "phrase": "original_online_synchronization_process"}, {"score": 0.0023066199295447686, "phrase": "effective_ar_system"}, {"score": 0.002271725588755076, "phrase": "hybrid_tracking"}, {"score": 0.002214734873559146, "phrase": "e-commerce_application"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["augmented reality", " camera tracking", " sensor fusion"], "paper_abstract": "One of the biggest obstacles to building effective augmented reality (AR) systems is the lack Of accurate sensors that report the location of the user in an environment during arbitrary long periods of movements. In this paper, we present an effective hybrid approach that integrates inertial and vision-based technologies. This work is motivated by the need to explicitly take into account the relatively poor accuracy of inertial sensors and thus to define an efficient strategy for the collaborative process between the vision-based system and the sensor. The contributions of this papers are threefold: (i) our collaborative strategy fully integrates the sensitivity error of the sensor: the sensitivity is practically studied and is propagated into the collaborative process, especially in the matching stage (ii) we propose an original online synchronization process between the vision-based system and the sensor. This process allows us to use the sensor only when needed. (iii) an effective AR system using this hybrid tracking is demonstrated through an e-commerce application in unprepared environments. Copyright (c) 2007 John Wiley & Sons, Ltd.", "paper_title": "Use of inertial sensors to support video tracking", "paper_id": "WOS:000245150900006"}