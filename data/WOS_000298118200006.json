{"auto_keywords": [{"score": 0.04696168679298325, "phrase": "np_structure"}, {"score": 0.023036539527418493, "phrase": "penn_treebank"}, {"score": 0.010612387000973441, "phrase": "noun_phrases"}, {"score": 0.007121664754534445, "phrase": "parser's_f-score"}, {"score": 0.006585624604558238, "phrase": "lexical_information"}, {"score": 0.004668876693176078, "phrase": "crucial_part"}, {"score": 0.00464279568957307, "phrase": "natural_language"}, {"score": 0.004426882270402403, "phrase": "statistical_parsing_field"}, {"score": 0.004256599284336768, "phrase": "gold-standard_data"}, {"score": 0.004220967333660075, "phrase": "previous_efforts"}, {"score": 0.0041856539677897295, "phrase": "nps"}, {"score": 0.0040928394196673955, "phrase": "supervised_experiments"}, {"score": 0.004047214091981053, "phrase": "high_performance"}, {"score": 0.0038805854107176116, "phrase": "entire_wall_street_journal_section"}, {"score": 0.003815863485460754, "phrase": "inter-annotator_agreement"}, {"score": 0.003628079411881511, "phrase": "consistent_np_annotation"}, {"score": 0.0034495044604576385, "phrase": "new_data"}, {"score": 0.003126968800190193, "phrase": "deterministic_rules"}, {"score": 0.002732965124214202, "phrase": "supervised_model"}, {"score": 0.0027100527874262446, "phrase": "excellent_results"}, {"score": 0.0026498854775140854, "phrase": "simple_np_task"}, {"score": 0.002422249273477746, "phrase": "post-processing_module"}, {"score": 0.0023420086613415267, "phrase": "wide_variety"}, {"score": 0.002264420105254984, "phrase": "parser_experiments"}], "paper_keywords": [""], "paper_abstract": "Noun phrases (NPs) are a crucial part of natural language, and can have a very complex structure. However, this NP structure is largely ignored by the statistical parsing field, as the most widely used corpus is not annotated with it. This lack of gold-standard data has restricted previous efforts to parse NPs, making it impossible to perform the supervised experiments that have achieved high performance in so many Natural Language Processing (NLP) tasks. We comprehensively solve this problem by manually annotating NP structure for the entire Wall Street Journal section of the Penn Treebank. The inter-annotator agreement scores that we attain dispel the belief that the task is too difficult, and demonstrate that consistent NP annotation is possible. Our gold-standard NP data is now available for use in all parsers. We experiment with this new data, applying the Collins (2003) parsing model, and find that its recovery of NP structure is significantly worse than its overall performance. The parser's F-score is up to 5.69% lower than a baseline that uses deterministic rules. Through much experimentation, we determine that this result is primarily caused by a lack of lexical information. To solve this problem we construct a wide-coverage, large-scale NP Bracketing system. With our Penn Treebank data set, which is orders of magnitude larger than those used previously, we build a supervised model that achieves excellent results. Our model performs at 93.8% F-score on the simple NP task that most previous work has undertaken, and extends to bracket longer, more complex NPs that are rarely dealt with in the literature. We attain 89.14% F-score on this much more difficult task. Finally, we implement a post-processing module that brackets NPs identified by the Bikel (2004) parser. Our NP Bracketing model includes a wide variety of features that provide the lexical information that was missing during the parser experiments, and as a result, we outperform the parser's F-score by 9.04%. These experiments demonstrate the utility of the corpus, and show that many NLP applications can now make use of NP structure.", "paper_title": "Parsing Noun Phrases in the Penn Treebank", "paper_id": "WOS:000298118200006"}