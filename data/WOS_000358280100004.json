{"auto_keywords": [{"score": 0.04269803168773222, "phrase": "rgb_images"}, {"score": 0.00481495049065317, "phrase": "semi-automatic_image_labelling"}, {"score": 0.004760017604908536, "phrase": "depth_information"}, {"score": 0.0047057084749407485, "phrase": "image_labeling_tools"}, {"score": 0.004417848254181138, "phrase": "ground_truth"}, {"score": 0.004268293864953256, "phrase": "object_detection_processes"}, {"score": 0.0039841418890102925, "phrase": "new_widely_available_low-cost_sensors"}, {"score": 0.0039386951150582085, "phrase": "microsoft"}, {"score": 0.0037834649508375544, "phrase": "depth_images"}, {"score": 0.003431481042678356, "phrase": "rgb-depth_adapted_tools"}, {"score": 0.003334309053314909, "phrase": "new_interactive_labeling_tool"}, {"score": 0.0032585499655442404, "phrase": "image_labeling"}, {"score": 0.0030239842475439814, "phrase": "image_segmentation"}, {"score": 0.0029214769181390653, "phrase": "fuzzy_c-means_clustering"}, {"score": 0.0028880836335117297, "phrase": "connected_component_labeling"}, {"score": 0.002711109302199029, "phrase": "desired_objects"}, {"score": 0.0026041635822373265, "phrase": "interaction_time"}, {"score": 0.0025596276616952516, "phrase": "object_extraction"}, {"score": 0.0025014259919355453, "phrase": "efficient_segmentation"}, {"score": 0.002472822097373027, "phrase": "rgb-depth_space"}, {"score": 0.002375253757224999, "phrase": "entire_procedure"}, {"score": 0.0022815262950738814, "phrase": "desired_object"}, {"score": 0.0022424956516376073, "phrase": "closest_object"}, {"score": 0.0021049977753042253, "phrase": "robotics_applications"}], "paper_keywords": [""], "paper_abstract": "Image labeling tools help to extract objects within images to be used as ground truth for learning and testing in object detection processes. The inputs for such tools are usually RGB images. However with new widely available low-cost sensors like Microsoft Kinect it is possible to use depth images in addition to RGB images. Despite many existing powerful tools for image labeling, there is a need for RGB-depth adapted tools. We present a new interactive labeling tool that partially automates image labeling, with two major contributions. First, the method extends the concept of image segmentation from RGB to RGB-depth using Fuzzy C-Means clustering, connected component labeling and superpixels, and generates bounding pixels to extract the desired objects. Second, it minimizes the interaction time needed for object extraction by doing an efficient segmentation in RGB-depth space. Very few clicks are needed for the entire procedure compared to existing, tools. When the desired object is the closest object to the camera, which is often the case in robotics applications, no clicks at all are required to accurately extract the object.", "paper_title": "Semi-Automatic Image Labelling Using Depth Information", "paper_id": "WOS:000358280100004"}