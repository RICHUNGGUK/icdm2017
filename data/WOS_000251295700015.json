{"auto_keywords": [{"score": 0.03710249027424074, "phrase": "frame_saliency"}, {"score": 0.015719716506582538, "phrase": "salient_frames"}, {"score": 0.007626740161668764, "phrase": "proposed_method"}, {"score": 0.004759635663291431, "phrase": "spatiotemporal_video_modeling"}, {"score": 0.0045709675813472884, "phrase": "new_statistical_generative_model"}, {"score": 0.004518442937844318, "phrase": "spatiotemporal_video_segmentation"}, {"score": 0.004314285113050873, "phrase": "video_sequence"}, {"score": 0.004264697351852424, "phrase": "homogeneous_segments"}, {"score": 0.004119313626110943, "phrase": "\"building_blocks"}, {"score": 0.004048483412089098, "phrase": "semantic_video_segmentation"}, {"score": 0.003978866233891427, "phrase": "baseline_framework"}, {"score": 0.003910441483033426, "phrase": "gaussian_mixture_model"}, {"score": 0.0037121208432871118, "phrase": "six-dimensional_spatiotemporal_feature_space"}, {"score": 0.0033839745649214548, "phrase": "video_frame"}, {"score": 0.0033257460346754687, "phrase": "gmm-based_spatiotemporal_video_modeling"}, {"score": 0.0031937337757356526, "phrase": "small_set"}, {"score": 0.0030847461428168614, "phrase": "model_training"}, {"score": 0.003031650815900696, "phrase": "data_redundancy"}, {"score": 0.002945175711537758, "phrase": "modified_expectation_maximization_algorithm"}, {"score": 0.002877769867854964, "phrase": "simultaneous_gmm_training"}, {"score": 0.0027159094186967247, "phrase": "highest_saliency_values"}, {"score": 0.002623184850933423, "phrase": "gmm_estimation"}, {"score": 0.0025929837295811673, "phrase": "video_segmentation"}, {"score": 0.002391067964886602, "phrase": "object_behaviors"}, {"score": 0.0022176487309947266, "phrase": "key-frame_extraction"}, {"score": 0.0021049977753042253, "phrase": "real_videos"}], "paper_keywords": ["expectation maximization (EM)", " feature selection", " frame saliency", " Gaussian mixture models (GMMs)", " statistical video modeling", " video segmentation"], "paper_abstract": "We propose a new statistical generative model for spatiotemporal video segmentation. The objective is to partition a video sequence into homogeneous segments that can be used as \"building blocks\" for semantic video segmentation. The baseline framework is a Gaussian mixture model (GMM)-based video modeling approach that involves a six-dimensional spatiotemporal feature space. Specifically, we introduce the concept of frame saliency to quantify the relevancy of a video frame to the GMM-based spatiotemporal video modeling. This helps us use a small set of salient frames to facilitate the model training by reducing data redundancy and irrelevance. A modified expectation maximization algorithm is developed for simultaneous GMM training and frame saliency estimation, and the frames with the highest saliency values are extracted to refine the GMM estimation for video segmentation. Moreover, it is interesting to find that frame saliency can imply some object behaviors. This makes the proposed method also applicable to other frame-related video analysis tasks, such as key-frame extraction, video skimming, etc. Experiments on real videos demonstrate the effectiveness and efficiency of the proposed method.", "paper_title": "Selecting salient frames for spatiotemporal video modeling and segmentation", "paper_id": "WOS:000251295700015"}