{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "extreme_learning_machine"}, {"score": 0.004556901872357751, "phrase": "unifying_framework"}, {"score": 0.004521179256835894, "phrase": "different_families"}, {"score": 0.004415675459182871, "phrase": "classical_elm_model"}, {"score": 0.004346704947011699, "phrase": "linear_combination"}, {"score": 0.004295681900150244, "phrase": "fixed_number"}, {"score": 0.004261998281333649, "phrase": "nonlinear_expansions"}, {"score": 0.0042119653427658025, "phrase": "input_vector"}, {"score": 0.0040334640350288, "phrase": "optimal_weights"}, {"score": 0.003832198214757852, "phrase": "batch_mode"}, {"score": 0.003772306776343196, "phrase": "explicit_feature_mappings"}, {"score": 0.003728000957725218, "phrase": "implicit_mappings"}, {"score": 0.003626626504149897, "phrase": "online_version"}, {"score": 0.003299460925313939, "phrase": "efficient_learning_algorithm"}, {"score": 0.00327356326590461, "phrase": "online_kernel-based_elm"}, {"score": 0.0032223742018434856, "phrase": "open_problem"}, {"score": 0.003134705849154561, "phrase": "nonlinear_adaptive_filtering"}, {"score": 0.0031100973266506163, "phrase": "elm_theory"}, {"score": 0.0028743610212291727, "phrase": "straightforward_extension"}, {"score": 0.0028405715222684183, "phrase": "well-known_kernel"}, {"score": 0.0028293966058473476, "phrase": "recursive_least-squares"}, {"score": 0.0027741761880779535, "phrase": "kernel_adaptive_filtering"}, {"score": 0.002688050388891007, "phrase": "elm_framework"}, {"score": 0.0026355812883224203, "phrase": "resulting_algorithm"}, {"score": 0.0024357240356443653, "phrase": "kaf_field"}, {"score": 0.002407078478216306, "phrase": "sparse_filters"}, {"score": 0.0022333012657436307, "phrase": "highly_efficient_algorithm"}, {"score": 0.002181069180139225, "phrase": "obtained_generalization_error"}, {"score": 0.002163930783583212, "phrase": "training_time"}, {"score": 0.002146926767291475, "phrase": "empirical_evaluations"}, {"score": 0.002130056082139311, "phrase": "interesting_results"}, {"score": 0.0021049977753042253, "phrase": "benchmarking_datasets"}], "paper_keywords": ["Extreme learning machine (ELM)", " kernel", " online learning", " recursive least square (RLS)"], "paper_abstract": "The extreme learning machine (ELM) was recently proposed as a unifying framework for different families of learning algorithms. The classical ELM model consists of a linear combination of a fixed number of nonlinear expansions of the input vector. Learning in ELM is hence equivalent to finding the optimal weights that minimize the error on a dataset. The update works in batch mode, either with explicit feature mappings or with implicit mappings defined by kernels. Although an online version has been proposed for the former, no work has been done up to this point for the latter, and whether an efficient learning algorithm for online kernel-based ELM exists remains an open problem. By explicating some connections between nonlinear adaptive filtering and ELM theory, in this brief, we present an algorithm for this task. In particular, we propose a straightforward extension of the well-known kernel recursive least-squares, belonging to the kernel adaptive filtering (KAF) family, to the ELM framework. We call the resulting algorithm the kernel online sequential ELM (KOS-ELM). Moreover, we consider two different criteria used in the KAF field to obtain sparse filters and extend them to our context. We show that KOS-ELM, with their integration, can result in a highly efficient algorithm, both in terms of obtained generalization error and training time. Empirical evaluations demonstrate interesting results on some benchmarking datasets.", "paper_title": "Online Sequential Extreme Learning Machine With Kernels", "paper_id": "WOS:000360437300032"}