{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "localized_textured_surface_reconstruction"}, {"score": 0.004567596860086148, "phrase": "novel_scene_representation"}, {"score": 0.0044356867986444426, "phrase": "large-scale_point_clouds"}, {"score": 0.004282391936827106, "phrase": "high-resolution_photographs"}, {"score": 0.0039218440805789965, "phrase": "lighting_variations"}, {"score": 0.0037201996003549246, "phrase": "high-quality_representation"}, {"score": 0.0036553070575015344, "phrase": "captured_data"}, {"score": 0.0033868916699805224, "phrase": "challenging_and_time-consuming_task"}, {"score": 0.0032889671598112023, "phrase": "two-phase_approach"}, {"score": 0.0031565959573536194, "phrase": "multiple_overlapping_surface_patches"}, {"score": 0.00304737045343781, "phrase": "seamless_texture_generation"}, {"score": 0.0027579362569638945, "phrase": "high-quality_visualization"}, {"score": 0.002600661525224505, "phrase": "proposed_localization"}, {"score": 0.002555247330102505, "phrase": "global_texturing_problem"}, {"score": 0.002381365139274329, "phrase": "equivalent_mesh-based_texturing_techniques"}, {"score": 0.0022455164874830777, "phrase": "whole_data"}, {"score": 0.0021550502873107654, "phrase": "maximum_flexibility"}, {"score": 0.0021049977753042253, "phrase": "growing_data_sets"}], "paper_keywords": ["Image-based rendering", " surface representation", " color", " large-scale models", " segmentation"], "paper_abstract": "In this paper, we introduce a novel scene representation for the visualization of large-scale point clouds accompanied by a set of high-resolution photographs. Many real-world applications deal with very densely sampled point-cloud data, which are augmented with photographs that often reveal lighting variations and inaccuracies in registration. Consequently, the high-quality representation of the captured data, i.e., both point clouds and photographs together, is a challenging and time-consuming task. We propose a two-phase approach, in which the first (preprocessing) phase generates multiple overlapping surface patches and handles the problem of seamless texture generation locally for each patch. The second phase stitches these patches at render-time to produce a high-quality visualization of the data. As a result of the proposed localization of the global texturing problem, our algorithm is more than an order of magnitude faster than equivalent mesh-based texturing techniques. Furthermore, since our preprocessing phase requires only a minor fraction of the whole data set at once, we provide maximum flexibility when dealing with growing data sets.", "paper_title": "Large-Scale Point-Cloud Visualization through Localized Textured Surface Reconstruction", "paper_id": "WOS:000341566500006"}