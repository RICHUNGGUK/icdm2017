{"auto_keywords": [{"score": 0.049646024323540684, "phrase": "image_retrieval"}, {"score": 0.03363896917055258, "phrase": "mmp"}, {"score": 0.012782520943624186, "phrase": "positive_and_negative_examples"}, {"score": 0.00481495049065317, "phrase": "maximum_margin_subspace"}, {"score": 0.004664352260912174, "phrase": "fundamental_problems"}, {"score": 0.0046221918332842995, "phrase": "content-based_image_retrieval"}, {"score": 0.004437115547184535, "phrase": "low-level_visual_features"}, {"score": 0.004397000006837371, "phrase": "high-level_semantic_concepts"}, {"score": 0.004240116703465252, "phrase": "relevance_feedback"}, {"score": 0.004088807948906792, "phrase": "user-provided_information"}, {"score": 0.0038194503801108324, "phrase": "real-world_applications"}, {"score": 0.0037336520904376687, "phrase": "user_feedbacks"}, {"score": 0.0035515951985356374, "phrase": "image_space"}, {"score": 0.003424771860049617, "phrase": "high_dimensionality"}, {"score": 0.00334780964309978, "phrase": "novel_semisupervised_method"}, {"score": 0.0033175095965171674, "phrase": "dimensionality_reduction"}, {"score": 0.00304295114679455, "phrase": "local_neighborhood"}, {"score": 0.002988101395789399, "phrase": "traditional_dimensionality_reduction_algorithms"}, {"score": 0.002947611960613497, "phrase": "principal_component_analysis"}, {"score": 0.0029210837108012843, "phrase": "pca"}, {"score": 0.0028813415821988156, "phrase": "linear_discriminant_analysis"}, {"score": 0.0028553989215963477, "phrase": "lda"}, {"score": 0.0026790983342162887, "phrase": "local_manifold_structure"}, {"score": 0.002502374576203785, "phrase": "nearest_neighbor_search"}, {"score": 0.0023802126605244438, "phrase": "lower_dimensional_subspace"}, {"score": 0.0023479408542211875, "phrase": "relevant_images"}, {"score": 0.0022951216874671494, "phrase": "query_image"}, {"score": 0.0022434880661725493, "phrase": "retrieval_performance"}, {"score": 0.0021830553825770097, "phrase": "experimental_results"}, {"score": 0.0021632744659324434, "phrase": "corel"}, {"score": 0.002153450937601075, "phrase": "image_database"}], "paper_keywords": ["multimedia information systems", " image retrieval", " relevance feedback", " dimensionality reduction"], "paper_abstract": "One of the fundamental problems in Content-Based Image Retrieval (CBIR) has been the gap between low-level visual features and high-level semantic concepts. To narrow down this gap, relevance feedback is introduced into image retrieval. With the user-provided information, a classifier can be learned to distinguish between positive and negative examples. However, in real-world applications, the number of user feedbacks is usually too small compared to the dimensionality of the image space. In order to cope with the high dimensionality, we propose a novel semisupervised method for dimensionality reduction called Maximum Margin Projection (MMP). MMP aims at maximizing the margin between positive and negative examples at each local neighborhood. Different from traditional dimensionality reduction algorithms such as Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA), which effectively see only the global euclidean structure, MMP is designed for discovering the local manifold structure. Therefore, MMP is likely to be more suitable for image retrieval, where nearest neighbor search is usually involved. After projecting the images into a lower dimensional subspace, the relevant images get closer to the query image; thus, the retrieval performance can be enhanced. The experimental results on Corel image database demonstrate the effectiveness of our proposed algorithm.", "paper_title": "Learning a maximum margin subspace for image retrieval", "paper_id": "WOS:000251686000004"}