{"auto_keywords": [{"score": 0.03641062883629123, "phrase": "parallel_tasks"}, {"score": 0.008177126651420133, "phrase": "depspawn"}, {"score": 0.00481495049065317, "phrase": "argument-based_task_synchronization"}, {"score": 0.004611224230543916, "phrase": "parallel_applications"}, {"score": 0.004416079619543104, "phrase": "implicit_synchronization"}, {"score": 0.00433200902751133, "phrase": "programming_environments"}, {"score": 0.004050116768809519, "phrase": "data-parallel_libraries"}, {"score": 0.0039729853486821995, "phrase": "skeletal_operations"}, {"score": 0.0037683358267785435, "phrase": "arbitrary_task-level_parallel_computations"}, {"score": 0.003325410433297401, "phrase": "library-based_approach"}, {"score": 0.0032777653153451265, "phrase": "arbitrary_patterns"}, {"score": 0.003215295260684715, "phrase": "minimal_effort"}, {"score": 0.0030938932434437178, "phrase": "first_generic_approach"}, {"score": 0.0025767987652419054, "phrase": "function_arguments"}, {"score": 0.002443890721386284, "phrase": "parallel_task"}, {"score": 0.002125371638869951, "phrase": "widespread_high-level_approach"}], "paper_keywords": ["Parallel programming", " Synchronization", " Out-of-order execution", " Libraries", " Dependencies", " Programming models"], "paper_abstract": "Synchronization in parallel applications can be achieved either implicitly or explicitly. Implicit synchronization is typical of programming environments that provide predefined, and often simple, patterns of parallelism such as data-parallel libraries and languages and skeletal operations. Nevertheless, more flexible approaches that allow to express arbitrary task-level parallel computations without a predefined structure request in turn that the user explicitly specifies the synchronization needed among the parallel tasks. In this paper we present a library-based approach that enables arbitrary patterns of parallelism with minimal effort for the user. Our proposal is the first generic approach to express parallelism we know of that requires neither explicit synchronizations nor a detail of the dependencies of the parallel tasks. Our strategy relies on expressing the parallel tasks as functions that convey their dependencies implicitly by means of their arguments. These function arguments are analyzed by our library, called DepSpawn, when a parallel task is spawned in order to enforce its dependencies. Our experiments indicate that DepSpawn is very competitive, both in terms of performance and programmability, with respect to a widespread high-level approach like OpenMP. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A framework for argument-based task synchronization with automatic detection of dependencies", "paper_id": "WOS:000324960800009"}