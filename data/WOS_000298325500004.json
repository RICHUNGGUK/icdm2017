{"auto_keywords": [{"score": 0.03170834931407811, "phrase": "fedm"}, {"score": 0.013790727048131985, "phrase": "nfeqm"}, {"score": 0.007379297130506788, "phrase": "free_energy"}, {"score": 0.00481495049065317, "phrase": "psychovisual_quality_metric"}, {"score": 0.0047747348769918, "phrase": "free-energy_principle"}, {"score": 0.004597861947580946, "phrase": "new_psychovisual_quality_metric"}, {"score": 0.004502433187097914, "phrase": "recent_developments"}, {"score": 0.00446481608187988, "phrase": "brain_theory"}, {"score": 0.004071121244999291, "phrase": "active_inference_process"}, {"score": 0.0038549394272661356, "phrase": "internal_generative_model"}, {"score": 0.0038066979615349822, "phrase": "psychovisual_quality"}, {"score": 0.0036809741830924796, "phrase": "visual_sensory_data"}, {"score": 0.003589404014552974, "phrase": "generative_model"}, {"score": 0.0035296217979800463, "phrase": "upper_bound"}, {"score": 0.0034418037573506837, "phrase": "image_signal"}, {"score": 0.00330025288273863, "phrase": "cognition_process"}, {"score": 0.00323166859966514, "phrase": "perceptual_quality"}, {"score": 0.0030216031606457214, "phrase": "reduced-reference_free-energy-based_distortion_metric"}, {"score": 0.0029463874016490976, "phrase": "no-reference_free-energy-based_quality_metric"}, {"score": 0.0026862220320327613, "phrase": "visual_quality"}, {"score": 0.0026414426081951734, "phrase": "existing_image_quality_metrics"}, {"score": 0.0026083473154448326, "phrase": "severe_quality_degradation"}, {"score": 0.0024800509241747013, "phrase": "reference_image"}, {"score": 0.0023481578019624843, "phrase": "full-reference_ssim_image_quality_metric"}, {"score": 0.002299313860419974, "phrase": "popular_live_database"}, {"score": 0.0022139352210982398, "phrase": "correctly_the_visual_quality"}, {"score": 0.0021861845339709533, "phrase": "model-based_image_processing_algorithms"}, {"score": 0.0021407025628134586, "phrase": "competing_metrics"}, {"score": 0.0021049977753042253, "phrase": "viewers'_opinions"}], "paper_keywords": ["Brain theory", " free-energy principle", " image modeling", " image quality assessment"], "paper_abstract": "In this paper, we propose a new psychovisual quality metric of images based on recent developments in brain theory and neuroscience, particularly the free-energy principle. The perception and understanding of an image is modeled as an active inference process, in which the brain tries to explain the scene using an internal generative model. The psychovisual quality is thus closely related to how accurately visual sensory data can be explained by the generative model, and the upper bound of the discrepancy between the image signal and its best internal description is given by the free energy of the cognition process. Therefore, the perceptual quality of an image can be quantified using the free energy. Constructively, we develop a reduced-reference free-energy-based distortion metric (FEDM) and a no-reference free-energy-based quality metric (NFEQM). The FEDM and the NFEQM are nearly invariant to many global systematic deviations in geometry and illumination that hardly affect visual quality, for which existing image quality metrics wrongly predict severe quality degradation. Although with very limited or even without information on the reference image, the FEDM and the NFEQM are highly competitive compared with the full-reference SSIM image quality metric on images in the popular LIVE database. Moreover, FEDM and NFEQM can measure correctly the visual quality of some model-based image processing algorithms, for which the competing metrics often contradict with viewers' opinions.", "paper_title": "A Psychovisual Quality Metric in Free-Energy Principle", "paper_id": "WOS:000298325500004"}