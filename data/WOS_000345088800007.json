{"auto_keywords": [{"score": 0.029958935081844246, "phrase": "proposed_method"}, {"score": 0.015095804022463384, "phrase": "foreground_objects"}, {"score": 0.011921195444036414, "phrase": "observed_period"}, {"score": 0.009166992350156524, "phrase": "dual-mode_model"}, {"score": 0.00481495049065317, "phrase": "foreground_segmentation"}, {"score": 0.00477924690801092, "phrase": "low-contrast_video_images"}, {"score": 0.004570491683870396, "phrase": "image_sequence"}, {"score": 0.004519736937243476, "phrase": "still_camera"}, {"score": 0.00445293569103488, "phrase": "object_tracking"}, {"score": 0.004419904580451831, "phrase": "activity_recognition"}, {"score": 0.004370814742381778, "phrase": "behavior_understanding"}, {"score": 0.004322267755421529, "phrase": "widely_used_background"}, {"score": 0.004242546312843817, "phrase": "single_gaussian"}, {"score": 0.004179907635382014, "phrase": "gaussians"}, {"score": 0.004087469540575263, "phrase": "mean_gray_level"}, {"score": 0.003737934295442975, "phrase": "background_pixel_values"}, {"score": 0.0037101871762082153, "phrase": "foreground_pixel_values"}, {"score": 0.0036826452656927877, "phrase": "consecutive_image_frames"}, {"score": 0.0035744997458371335, "phrase": "true_background"}, {"score": 0.0034695189961509625, "phrase": "mean_background_models"}, {"score": 0.003418186564522323, "phrase": "low-contrast_objects"}, {"score": 0.0033550841271846065, "phrase": "sudden_light_changes"}, {"score": 0.0032686865485199806, "phrase": "dual-mode_scheme"}, {"score": 0.0030909442697163356, "phrase": "observed_consecutive_image_frames"}, {"score": 0.0028903278985330117, "phrase": "dynamic_changes"}, {"score": 0.002603758927691463, "phrase": "foreground_object"}, {"score": 0.002574788013427524, "phrase": "dynamic_background"}, {"score": 0.002499094513009327, "phrase": "exact_gray_level_mode"}, {"score": 0.0024529174827030787, "phrase": "image_sequences"}, {"score": 0.0024075916292945715, "phrase": "last_image_frame"}, {"score": 0.0023719332915829268, "phrase": "current_image"}, {"score": 0.002319431279824863, "phrase": "comparative_evaluation"}, {"score": 0.0023021895404322767, "phrase": "foreground_segmentation_methods"}, {"score": 0.002259642580775186, "phrase": "microsoft's_wallflower_dataset"}, {"score": 0.0021607035327962246, "phrase": "illumination_changes"}, {"score": 0.0021049977753042253, "phrase": "low-contrast_background"}], "paper_keywords": ["Background updating", " Foreground segmentation", " Mode estimation"], "paper_abstract": "In video surveillance, the detection of foreground objects in an image sequence from a still camera is critical for object tracking, activity recognition, and behavior understanding. The widely used background updating models such as single Gaussian and mixture of Gaussians are based mainly on the mean gray level of a given observation period, which could be inevitably affected by outliers and noise in the images. The mean from the average of background pixel values and foreground pixel values of consecutive image frames in an observed period will not represent the true background in the scene. Thus, the mean background models cannot detect low-contrast objects and promptly respond to sudden light changes. In this paper, a dual-mode scheme for foreground segmentation is proposed. The mode is based on the most frequently occurring gray level of observed consecutive image frames, and is used to represent the background in the scene. In order to accommodate the dynamic changes of a background, the proposed method uses a dual-mode model for background representation. The dual-mode model can represent two main states of the background and detect a more complete silhouette of the foreground object in the dynamic background. The proposed method can promptly calculate the exact gray level mode of individual pixels in image sequences by simply dropping the last image frame and adding the current image in an observed period. The comparative evaluation of foreground segmentation methods is performed on the Microsoft's Wallflower dataset. The results show that the proposed method can quickly respond to illumination changes and well extract foreground objects in a low-contrast background.", "paper_title": "Dual-mode detection for foreground segmentation in low-contrast video images", "paper_id": "WOS:000345088800007"}