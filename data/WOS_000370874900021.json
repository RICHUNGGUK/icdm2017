{"auto_keywords": [{"score": 0.04611756481428342, "phrase": "future_systems"}, {"score": 0.044584958941661715, "phrase": "sram"}, {"score": 0.00481495049065317, "phrase": "modern_systems"}, {"score": 0.004703149944841539, "phrase": "hardware_faults"}, {"score": 0.004648222388468414, "phrase": "memory_subsystem"}, {"score": 0.0041981583430961734, "phrase": "current_memory_subsystems"}, {"score": 0.004149103940568346, "phrase": "memory_subsystems"}, {"score": 0.004068611852912931, "phrase": "resilience_techniques"}, {"score": 0.003943047070755799, "phrase": "high-performance_computing_systems"}, {"score": 0.0036600862989330106, "phrase": "current_hardware_resilience_techniques"}, {"score": 0.003116551456858777, "phrase": "hardware_resilience_schemes"}, {"score": 0.003056029284235528, "phrase": "current_systems"}, {"score": 0.002748895580860912, "phrase": "methodological_study"}, {"score": 0.0026019646284747024, "phrase": "data_center_operators"}, {"score": 0.002551409948440577, "phrase": "incorrect_conclusions"}, {"score": 0.002531463482341473, "phrase": "system_reliability"}, {"score": 0.0024150092189446424, "phrase": "future_large-scale_systems"}, {"score": 0.0023680783509308525, "phrase": "sram_faults"}, {"score": 0.002312960805824996, "phrase": "significantly_larger_reliability_threat"}, {"score": 0.002259123228671651, "phrase": "dram_faults"}, {"score": 0.0022239279632673206, "phrase": "major_concern"}, {"score": 0.002206536029072657, "phrase": "stronger_dram_resilience_schemes"}, {"score": 0.0021551702945512494, "phrase": "acceptable_failure_rates"}, {"score": 0.0021049977753042253, "phrase": "today's_systems"}], "paper_keywords": ["Field studies", " Large-scale systems", " Reliability"], "paper_abstract": "Several recent publications have shown that hardware faults in the memory subsystem are commonplace. These faults are predicted to become more frequent in future systems that contain orders of magnitude more DRAM and SRAM than found in current memory subsystems. These memory subsystems will need to provide resilience techniques to tolerate these faults when deployed in high-performance computing systems and data centers containing tens of thousands of nodes. Therefore, it is critical to understand the efficacy of current hardware resilience techniques to determine whether they will be suitable for future systems. In this paper, we present a study of DRAM and SRAM faults and errors from the field. We use data from two leadership-class high-performance computer systems to analyze the reliability impact of hardware resilience schemes that are deployed in current systems. Our study has several key findings about the efficacy of many currently-deployed reliability techniques such as DRAM ECC, DDR address/command parity, and SRAM ECC and parity. We also perform a methodological study, and find that counting errors instead of faults, a common practice among researchers and data center operators, can lead to incorrect conclusions about system reliability. Finally, we use our data to project the needs of future large-scale systems. We find that SRAM faults are unlikely to pose a significantly larger reliability threat in the future, while DRAM faults will be a major concern and stronger DRAM resilience schemes will be needed to maintain acceptable failure rates similar to those found on today's systems.", "paper_title": "Memory Errors in Modern Systems", "paper_id": "WOS:000370874900021"}