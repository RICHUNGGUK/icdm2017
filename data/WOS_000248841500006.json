{"auto_keywords": [{"score": 0.04085427544088488, "phrase": "content_models"}, {"score": 0.04026157255412937, "phrase": "user_models"}, {"score": 0.010612387000973441, "phrase": "content-user_gap"}, {"score": 0.010219923583798394, "phrase": "hanging_basket_model"}, {"score": 0.0044634416051962545, "phrase": "leading_standard"}, {"score": 0.004396267325338022, "phrase": "multimedia_metadata_creation"}, {"score": 0.004264923517966271, "phrase": "vast_array"}, {"score": 0.004200724305692705, "phrase": "description_tools"}, {"score": 0.0031010029460927864, "phrase": "extremely_limited_range"}, {"score": 0.0030082398041055003, "phrase": "content_metadata"}], "paper_keywords": ["MPEG-7", " content metadata", " user metadata", " personalization", " multimedia standards"], "paper_abstract": "MPEG-7 is the leading standard for multimedia metadata creation, providing a vast array of description tools. Nevertheless, there exists a disparity between the content models and user models that may be created by the standard: metadata for content models is wide ranging and structured, but metadata for user models only support the specification of an extremely limited range of preferences where content metadata cannot be fully exploited. This results in a very incomplete mapping of user models to content models which we term the MPEG-7 content-user gap. We present a hanging basket model that closes the content-user gap by considering user models to be isomorphic to content models and thus enabling both models to be represented through MPEG-7 content description tools, specifically those concerned with events, objects and properties.", "paper_title": "Closing the content-user gap in MPEG-7: the hanging basket model", "paper_id": "WOS:000248841500006"}