{"auto_keywords": [{"score": 0.03239672932592519, "phrase": "base_register_name"}, {"score": 0.00481495049065317, "phrase": "guided_memory_reference"}, {"score": 0.004737879690862494, "phrase": "high-frequency_processors"}, {"score": 0.004528551999851654, "phrase": "multiple_small_single-ported_caches"}, {"score": 0.00447045328907701, "phrase": "monolithic_large_multi-ported_one"}, {"score": 0.004356472679444647, "phrase": "scalable_and_inexpensive_way"}, {"score": 0.0043144799365586375, "phrase": "higher_bandwidth"}, {"score": 0.004204459295724526, "phrase": "memory_references"}, {"score": 0.004084022274429013, "phrase": "close_match"}, {"score": 0.004005645977640982, "phrase": "ideal_multi-ported_cache"}, {"score": 0.003916098498242888, "phrase": "dynamic_data_access_patterns"}, {"score": 0.0038285451859508815, "phrase": "access_conflicts"}, {"score": 0.003779393063001438, "phrase": "unbalanced_loads"}, {"score": 0.003588991941539972, "phrase": "data_references"}, {"score": 0.003441352119167824, "phrase": "parallel_accesses"}, {"score": 0.0034081501761600067, "phrase": "separate_small_caches_-_access_region_cache"}, {"score": 0.0033211641484589775, "phrase": "better_performance"}, {"score": 0.003289117944111902, "phrase": "register-guided_memory_reference"}, {"score": 0.0031845067058084583, "phrase": "semantic_regions"}, {"score": 0.003133451532433272, "phrase": "multiple_caches"}, {"score": 0.003093195541269291, "phrase": "concurrent_accesses"}, {"score": 0.002985130390111069, "phrase": "memory_reference_instruction"}, {"score": 0.002937262271695137, "phrase": "basic_guide"}, {"score": 0.0029183300121987422, "phrase": "instruction_steering"}, {"score": 0.002880829737447174, "phrase": "initial_assignment"}, {"score": 0.0028530201960995896, "phrase": "specific_access_region_cache"}, {"score": 0.0027982016314450717, "phrase": "reassignment_mechanism"}, {"score": 0.0027444334639134217, "phrase": "access_pattern"}, {"score": 0.002639968630788011, "phrase": "distribution_mechanism"}, {"score": 0.0025892330566358503, "phrase": "access_regions"}, {"score": 0.0025312694615202786, "phrase": "physical_caches"}, {"score": 0.00250682585023182, "phrase": "potential_conflicts"}, {"score": 0.0024191966390855048, "phrase": "semantic-based_scheme"}, {"score": 0.0023497779149212737, "phrase": "considerable_performance_improvement"}, {"score": 0.0023195823738789228, "phrase": "ipc"}, {"score": 0.002253000188119187, "phrase": "integer_benchmark_programs"}, {"score": 0.0021742244283295986, "phrase": "floating-point_benchmark_programs"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Access region", " Access region cache", " Interleaving", " Memory partitionining", " Multibanked cache", " Register guide"], "paper_abstract": "Wide-issue and high-frequency processors require not only a low-latency but also high-bandwidth memory system to achieve high performance. Previous studies have shown that using multiple small single-ported caches instead of a monolithic large multi-ported one for L1 data cache can be a scalable and inexpensive way to provide higher bandwidth. Various schemes on how to direct the memory references have been proposed in order to achieve a close match to the performance of an ideal multi-ported cache. However, most existing designs seldom take dynamic data access patterns into consideration, thus suffer from access conflicts within one cache and unbalanced loads between the caches. It is observed in this paper that if one can group data references defined in a program into several regions (access regions) to allow parallel accesses, providing separate small caches - access region cache for these regions may prove to have better performance. A register-guided memory reference partitioning approach is proposed and it effectively identifies these semantic regions and organizes them into multiple caches adaptively to maximize concurrent accesses. The base register name, not its content, in the memory reference instruction is used as a basic guide for instruction steering. With the initial assignment to a specific access region cache per the base register name, a reassignment mechanism is applied to capture the access pattern when program is moving across its access regions. In addition, a distribution mechanism is introduced to adaptively enable access regions to extend or shrink among the physical caches to reduce potential conflicts further. The simulations of SPEC CPU2000 benchmarks have shown that the semantic-based scheme can reduce the conflicts effectively, and obtain considerable performance improvement in terms of IPC; with 8 access region caches, 25-33% higher IPC is achieved for integer benchmark programs than a comparable 8-banked cache, while the benefit is less for floating-point benchmark programs, 19% at most. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Access region cache with register guided memory reference partitioning", "paper_id": "WOS:000273154000002"}