{"auto_keywords": [{"score": 0.049474472243262034, "phrase": "multi-feature_fusion"}, {"score": 0.00481495049065317, "phrase": "multiple_non-overlapping_camera_views"}, {"score": 0.0046544807197808095, "phrase": "matching_objects"}, {"score": 0.004615202066192795, "phrase": "multiple_cameras"}, {"score": 0.004576253356889219, "phrase": "non-overlapping_views"}, {"score": 0.004518442937844318, "phrase": "necessary_but_difficult_task"}, {"score": 0.004461359547152617, "phrase": "wide_area_video_surveillance"}, {"score": 0.004330941610682453, "phrase": "spatio-temporal_information"}, {"score": 0.003945266418163835, "phrase": "novel_framework"}, {"score": 0.0037495207047193034, "phrase": "disjoint_views"}, {"score": 0.003670843919846253, "phrase": "space-time_cues"}, {"score": 0.003578600071301459, "phrase": "competitive_major_feature_histogram_fusion_representation"}, {"score": 0.0034738975998176323, "phrase": "appearance_model"}, {"score": 0.0034154440860550564, "phrase": "potentially_matching_objects"}, {"score": 0.0030847461428168614, "phrase": "improved_incremental_general_multicategory_support_vector_machine_algorithm"}, {"score": 0.0029817668105720924, "phrase": "appearance_models"}, {"score": 0.002870006736445581, "phrase": "classification_method"}, {"score": 0.002750721367040336, "phrase": "accurate_classification_model"}, {"score": 0.0024736973328071026, "phrase": "experimental_results"}, {"score": 0.0024114635128122783, "phrase": "proposed_methodology"}, {"score": 0.0023708445073819277, "phrase": "computational_efficiency"}, {"score": 0.0023507916951658455, "phrase": "computation_storage"}, {"score": 0.0021593396036472777, "phrase": "real-time_video_surveillance_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Video object matching", " Non-overlapping multi-camera views", " CMFH", " Incremental learning", " Video surveillance system"], "paper_abstract": "Matching objects across multiple cameras with non-overlapping views is a necessary but difficult task in the wide area video surveillance. Owing to the lack of spatio-temporal information, only the visual information can be used in some scenarios, especially when the cameras are widely separated. This paper proposes a novel framework based on multi-feature fusion and incremental learning to match the objects across disjoint views in the absence of space-time cues. We first develop a competitive major feature histogram fusion representation (CMFH1) to formulate the appearance model for characterizing the potentially matching objects. The appearances of the objects can change over time and hence the models should be continuously updated. We then adopt an improved incremental general multicategory support vector machine algorithm (IGMSVM(2)) to update the appearance models online and match the objects based on a classification method. Only a small amount of samples are needed for building an accurate classification model in our method. Several tests are performed on CAVIAR, ISCAPS and VIPeR databases where the objects change significantly due to variations in the viewpoint, illumination and poses. Experimental results demonstrate the advantages of the proposed methodology in terms of computational efficiency, computation storage, and matching accuracy over that of other state-of-the-art classification-based matching approaches. The system developed in this research can be used in real-time video surveillance applications. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Video object matching across multiple non-overlapping camera views based on multi-feature fusion and incremental learning", "paper_id": "WOS:000342870900009"}