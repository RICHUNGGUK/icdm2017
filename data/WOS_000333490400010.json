{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "negative_effect"}, {"score": 0.04909435677365326, "phrase": "goal-driven_self-optimization"}, {"score": 0.004500414250942443, "phrase": "oscillating_utilities"}, {"score": 0.004407813106104401, "phrase": "large_number"}, {"score": 0.004362226376603478, "phrase": "uncertain_factors"}, {"score": 0.004294724955301414, "phrase": "runtime_environments"}, {"score": 0.003993216345115755, "phrase": "predefined_requirements_goal_models"}, {"score": 0.003911010373894104, "phrase": "imprecise_contributions"}, {"score": 0.003870541730075597, "phrase": "unknown_quality_preferences"}, {"score": 0.0037321585095070483, "phrase": "goal_solutions"}, {"score": 0.0035063024767122684, "phrase": "adaptation_actions"}, {"score": 0.0031107911390188055, "phrase": "monitored_quality_values"}, {"score": 0.0029994894380575604, "phrase": "estimated_earned_value"}, {"score": 0.0029530125680590413, "phrase": "global_indicator"}, {"score": 0.0028325548627901004, "phrase": "quantitative_contributions"}, {"score": 0.002803213985198645, "phrase": "alternative_functionalities"}, {"score": 0.0027741761880779535, "phrase": "quality_requirements"}, {"score": 0.0026888503045081505, "phrase": "relevant_quality_requirements"}, {"score": 0.002619748321217153, "phrase": "proper_timing_delay"}, {"score": 0.002579140290642792, "phrase": "last_adaptation_action"}, {"score": 0.002473895542219933, "phrase": "runtime_measures"}, {"score": 0.002360607691114015, "phrase": "goal_models"}, {"score": 0.002299921909935613, "phrase": "experimental_study"}, {"score": 0.0022642601698943687, "phrase": "real-life_online_shopping_system"}, {"score": 0.002206045784326466, "phrase": "goal-driven_self-optimization_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Uncertainty", " Goal-driven self-optimization", " Requirements goal models"], "paper_abstract": "Goal-driven self-optimization through feedback loops has shown effectiveness in reducing oscillating utilities due to a large number of uncertain factors in the runtime environments. However, such self-optimization is less satisfactory when there contains uncertainty in the predefined requirements goal models, such as imprecise contributions and unknown quality preferences, or during the switches of goal solutions, such as lack of understanding about the time for the adaptation actions to take effect. In this paper, we propose to handle such uncertainty in goal-driven self-optimization without interrupting the services. Taking the monitored quality values as the feedback, and the estimated earned value as the global indicator of self-optimization, our approach dynamically updates the quantitative contributions from alternative functionalities to quality requirements, tunes the preferences of relevant quality requirements, and determines a proper timing delay for the last adaptation action to take effect. After applying these runtime measures to limit the negative effect of the uncertainty in goal models and their suggested switches, an experimental study on a real-life online shopping system shows the improvements over goal-driven self-optimization approaches without uncertainty handling. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Uncertainty handling in goal-driven self-optimization - Limiting the negative effect on adaptation", "paper_id": "WOS:000333490400010"}