{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "subset_selection"}, {"score": 0.014659327292936366, "phrase": "machine_learning"}, {"score": 0.012080941313711376, "phrase": "target_concept"}, {"score": 0.010328264135057904, "phrase": "feature_interactions"}, {"score": 0.004657653216262924, "phrase": "robust_intelligence"}, {"score": 0.004449688143230257, "phrase": "computer_systems"}, {"score": 0.004304271837157217, "phrase": "feature_selection"}, {"score": 0.004077995480957875, "phrase": "irrelevant_features"}, {"score": 0.003354393040689453, "phrase": "unintentional_removal"}, {"score": 0.0032581736321024373, "phrase": "poor_classification_performance"}, {"score": 0.0030357976028714557, "phrase": "feature_interaction"}, {"score": 0.0029981559422442693, "phrase": "wide_range"}, {"score": 0.0029733203800202303, "phrase": "real-world_applications"}, {"score": 0.00288800021194675, "phrase": "high-dimensional_data"}, {"score": 0.002690820958068933, "phrase": "special_data_structure"}, {"score": 0.002668524425703961, "phrase": "feature_quality_evaluation"}, {"score": 0.002602734354498382, "phrase": "information-theoretic_feature_ranking_mechanism"}, {"score": 0.002404885278896803, "phrase": "representative_methods"}, {"score": 0.0023651843133643768, "phrase": "lesion_study"}, {"score": 0.0023261372216194383, "phrase": "critical_components"}, {"score": 0.002297274552621268, "phrase": "proposed_algorithm"}, {"score": 0.002231310272815607, "phrase": "related_issues"}, {"score": 0.0022036216160494925, "phrase": "data_structure"}, {"score": 0.002167235986623239, "phrase": "time_complexity"}, {"score": 0.0021049977753042253, "phrase": "interacting_features"}], "paper_keywords": ["Feature interaction", " feature selection", " search", " data structure", " classification"], "paper_abstract": "The evolving and adapting capabilities of robust intelligence are best manifested in its ability to learn. Machine learning enables computer systems to learn, and improve performance. Feature selection facilitates machine learning (e. g., classification) by aiming to remove irrelevant features. Feature (attribute) interaction presents a challenge to feature subset selection for classification. This is because a feature by itself might have little correlation with the target concept, but when it is combined with some other features, they can be strongly correlated with the target concept. Thus, the unintentional removal of these features may result in poor classification performance. It is computationally intractable to handle feature interactions in general. However, the presence of feature interaction in a wide range of real-world applications demands practical solutions that can reduce high-dimensional data while preserving feature interactions. In this paper, we take up the challenge to design a special data structure for feature quality evaluation, and to employ an information-theoretic feature ranking mechanism to efficiently handle feature interaction in subset selection. We conduct experiments to evaluate our approach by comparing with some representative methods, perform a lesion study to examine the critical components of the proposed algorithm to gain insights, and investigate related issues such as data structure, ranking, time complexity, and scalability in search of interacting features.", "paper_title": "Searching for interacting features in subset selection", "paper_id": "WOS:000266016300003"}