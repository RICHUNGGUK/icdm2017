{"auto_keywords": [{"score": 0.035620716932052585, "phrase": "low-level_audio-visual_features"}, {"score": 0.00481495049065317, "phrase": "collaborative_temporal_tags"}, {"score": 0.004775918707955445, "phrase": "purpose_-_video_summarisation"}, {"score": 0.004641770842098217, "phrase": "content-based_video_retrieval_research"}, {"score": 0.004585433265422727, "phrase": "new_video_summarisation_scheme"}, {"score": 0.0044385053213394175, "phrase": "socially_generated_temporal_tags"}, {"score": 0.004331393784852601, "phrase": "users'_collaborative_tagging_activities"}, {"score": 0.004244102948402086, "phrase": "video_bookmarks"}, {"score": 0.004158563941891469, "phrase": "temporal_or_positional_information"}, {"score": 0.004058180509184539, "phrase": "relative_time_codes"}, {"score": 0.004025258572860201, "phrase": "byte_offsets"}, {"score": 0.003740679163860117, "phrase": "meaningful_key_frames"}, {"score": 0.003419943984098415, "phrase": "traditional_video_summarisation_methods"}, {"score": 0.0032700071110068323, "phrase": "users'_high-level_collaborative_activities"}, {"score": 0.0031910037920846817, "phrase": "semantically_more_important_summaries"}, {"score": 0.0030262967460085366, "phrase": "video_frames"}, {"score": 0.0028121429464519733, "phrase": "good_sources"}, {"score": 0.0027893011631269873, "phrase": "summarising_videos"}, {"score": 0.00260246764210499, "phrase": "shared_information_resources"}, {"score": 0.00221063611719246, "phrase": "automatic_video_summarisation"}, {"score": 0.0021309254505358253, "phrase": "first_attempt"}, {"score": 0.0021049977753042253, "phrase": "users'_high-level_collaborative_tagging_activities"}], "paper_keywords": ["Folksonomy", " Collaborative tagging", " Web 2.0", " Video bookmarks", " Video summarisation", " Tagging", " Working patterns"], "paper_abstract": "Purpose - Video summarisation is one of the most active fields in content-based video retrieval research. A new video summarisation scheme is proposed by this paper based on socially generated temporal tags. Design/methodology/approach - To capture users' collaborative tagging activities the proposed scheme maintains video bookmarks, which contain some temporal or positional information about videos, such as relative time codes or byte offsets. For each video all the video bookmarks collected from users are then statistically analysed in order to extract some meaningful key frames (the video equivalent of keywords), which collectively constitute the summary of the video. Findings - Compared with traditional video summarisation methods that use low-level audio-visual features, the proposed method is based on users' high-level collaborative activities, and thus can produce semantically more important summaries than existing methods. Research limitations/implications - It is assumed that the video frames around the bookmarks inserted by users are informative and representative, and therefore can be used as good sources for summarising videos. Originality/value - Folksonomy, commonly called collaborative tagging, is a Web 2.0 method for users to freely annotate shared information resources with keywords. It has mostly been used for collaboratively tagging photos (Flickr), web site bookmarks (Delicious), or blog posts (Technorati), but has never been applied to the field of automatic video summarisation. It is believed that this is the first attempt to utilise users' high-level collaborative tagging activities, instead of low-level audio-visual features, for video summarisation.", "paper_title": "Video summarisation based on collaborative temporal tags", "paper_id": "WOS:000295711800008"}