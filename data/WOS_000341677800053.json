{"auto_keywords": [{"score": 0.04731991549640623, "phrase": "emotional_state"}, {"score": 0.015547854680881094, "phrase": "movie_clips"}, {"score": 0.015043289861642438, "phrase": "emotion_recognition_system"}, {"score": 0.014501560935276046, "phrase": "movie_clip"}, {"score": 0.0048150216412696885, "phrase": "eeg"}, {"score": 0.004356535752468849, "phrase": "scene_changes"}, {"score": 0.004213601332868765, "phrase": "dynamic_emotional_feature_extraction"}, {"score": 0.00418247778205288, "phrase": "low-level_visual_features"}, {"score": 0.0038263829059336564, "phrase": "dynamic_visual_features"}, {"score": 0.0037007799215748815, "phrase": "chroma"}, {"score": 0.0036327849511058156, "phrase": "hue"}, {"score": 0.003592581806180854, "phrase": "orientation_information"}, {"score": 0.0035135084960705816, "phrase": "predefined_time_interval"}, {"score": 0.003474624627033273, "phrase": "dynamic_brain_features"}, {"score": 0.0031434146012468307, "phrase": "short_time_fourier_transform"}, {"score": 0.0030628094110419697, "phrase": "reliable_features"}, {"score": 0.003006499028632742, "phrase": "hemisphere_power_asymmetry"}, {"score": 0.0028862231180242053, "phrase": "time-dependent_energy"}, {"score": 0.0028542615085879975, "phrase": "alpha_band"}, {"score": 0.002791393223133408, "phrase": "gamma_band"}, {"score": 0.0026697693423477727, "phrase": "fuzzy_tensor"}, {"score": 0.002572463625403536, "phrase": "visual_and_eeg_signals"}, {"score": 0.0024421501497321027, "phrase": "adaptive_neuro-fuzzy_inference"}, {"score": 0.002344398099179438, "phrase": "mean_opinion_scores"}, {"score": 0.0022927343007881846, "phrase": "teaching_signals"}, {"score": 0.0022757667100089243, "phrase": "experimental_results"}, {"score": 0.00222561197623787, "phrase": "anfis_classifier"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Emotion recognition", " 3D fuzzy GIST", " EEG", " ICA", " Adaptive neuro-fuzzy inference classifier"], "paper_abstract": "In this paper, we propose an emotion recognition system for understanding the emotional state of humans while watching a movie clip. Using various movies clips with scene changes over time, a 3D fuzzy GIST was used for dynamic emotional feature extraction from low-level visual features, and a 3D fuzzy tensor was used for semantic-level brain features related to the emotional state of humans. In the case of dynamic visual features, the 3D fuzzy GIST consists of L*C*H* color (L: Lightness; C: Chroma; and H: Hue) and orientation information of a movie clip in a predefined time interval. For dynamic brain features, we processed the electroencephalographic (EEG) signals, as stimulated by the movie clips to induce an emotional state, through both an independent component analysis (ICA) to eliminate artifacts, and Short Time Fourier Transform (STFT) to extract the reliable features. To obtain a hemisphere power asymmetry, the 3D tensor data for the brain signals were constructed according to the time-dependent energy at the alpha band (8-13 Hz) and gamma band (30-60 Hz). Finally, the 3D fuzzy GIST and 3D fuzzy tensor were obtained through fuzzy C-means clustering using visual and EEG signals, respectively. The obtained 3D fuzzy GIST and 3D fuzzy tensor features were used as inputs to an adaptive neuro-fuzzy inference (ANFIS) classifier, which was provided using the mean opinion scores (MOSs) as the teaching signals. Experimental results show that, using an ANFIS classifier, the proposed 3D fuzzy visual and EEG features are effective in building an emotion recognition system. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Emotion recognition based on 3D fuzzy visual and EEG features in movie clips", "paper_id": "WOS:000341677800053"}