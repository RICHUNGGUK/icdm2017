{"auto_keywords": [{"score": 0.03701760333821082, "phrase": "generalization_ability"}, {"score": 0.013188037451849304, "phrase": "cost_function"}, {"score": 0.008252518700515717, "phrase": "lvq"}, {"score": 0.00481495049065317, "phrase": "lvq_algorithms"}, {"score": 0.0046621835537196754, "phrase": "vector_quantization"}, {"score": 0.004550783060775205, "phrase": "powerful_and_intuitive_method"}, {"score": 0.004514241562580097, "phrase": "adaptive_nearest_prototype_classification"}, {"score": 0.004442032546224076, "phrase": "original_lvq"}, {"score": 0.004301046274139699, "phrase": "numerous_modifications"}, {"score": 0.004232232993872917, "phrase": "better_convergence"}, {"score": 0.0041144374213500715, "phrase": "mathematical_foundation"}, {"score": 0.0039042694651106884, "phrase": "limiting_case"}, {"score": 0.0038417798012011155, "phrase": "learning_rule"}, {"score": 0.0036602262729063775, "phrase": "better_stability"}, {"score": 0.003587125711973247, "phrase": "exact_dynamics"}, {"score": 0.0033223686422055834, "phrase": "statistical_physics"}, {"score": 0.0032559935867182035, "phrase": "on-line_learning"}, {"score": 0.0031909403420958752, "phrase": "mathematical_framework"}, {"score": 0.003114584448820957, "phrase": "different_lvq_algorithms"}, {"score": 0.003077092305006702, "phrase": "typical_scenario"}, {"score": 0.0029792984108210525, "phrase": "initial_conditions"}, {"score": 0.0029197572138773237, "phrase": "significant_differences"}, {"score": 0.002884603537502399, "phrase": "algorithmic_stability"}, {"score": 0.0027929100418926725, "phrase": "slightly_different_variants"}, {"score": 0.0027704446877717466, "phrase": "lvq."}, {"score": 0.0027370835853738626, "phrase": "five_lvq_algorithms"}, {"score": 0.0026932283763241127, "phrase": "kohonen"}, {"score": 0.0025349102304082715, "phrase": "vq"}, {"score": 0.00224558083320154, "phrase": "asymptotic_generalization_ability"}, {"score": 0.002182958452794581, "phrase": "model_parameters"}, {"score": 0.0021049977753042253, "phrase": "recent_alternative_proposals"}], "paper_keywords": ["online learning", " LVQ1", " LVQ2.1", " LVQ", " VQ", " LFM", " thermodynamic limit", " order parameters"], "paper_abstract": "Learning vector quantization (LVQ) constitutes a powerful and intuitive method for adaptive nearest prototype classification. However, original LVQ has been introduced based on heuristics and numerous modifications exist to achieve better convergence and stability. Recently, a mathematical foundation by means of a cost function has been proposed which, as a limiting case, yields a learning rule similar to classical LVQ2.1. It also motivates a modification which shows better stability. However, the exact dynamics as well as the generalization ability of many LVQ algorithms have not been thoroughly investigated so far. Using concepts from statistical physics and the theory of on-line learning, we present a mathematical framework to analyse the performance of different LVQ algorithms in a typical scenario in terms of their dynamics, sensitivity to initial conditions, and generalization ability. Significant differences in the algorithmic stability and generalization ability can be found already for slightly different variants of LVQ. We study five LVQ algorithms in detail: Kohonen's original LVQ1, unsupervised vector quantization (VQ), a mixture of VQ and LVQ, LVQ2.1, and a variant of LVQ which is based on a cost function. Surprisingly, basic LVQ I shows very good performance in terms of stability, asymptotic generalization ability, and robustness to initializations and model parameters which, in many cases, is superior to recent alternative proposals. (c) 2006 Elsevier Ltd. All rights reserved.", "paper_title": "Performance analysis of LVQ algorithms: A statistical physics approach", "paper_id": "WOS:000240269600012"}