{"auto_keywords": [{"score": 0.04476477802864247, "phrase": "facial_expressions"}, {"score": 0.00481495049065317, "phrase": "human_facial_expressions"}, {"score": 0.004675930527604869, "phrase": "real-time_recognition"}, {"score": 0.00440976345264104, "phrase": "facial_motion"}, {"score": 0.004332894955218135, "phrase": "monochrome_frontal_views"}, {"score": 0.00408617426304956, "phrase": "cluttered_and_dynamic_scenes"}, {"score": 0.003991449490087454, "phrase": "six_emotions"}, {"score": 0.0038989120088094185, "phrase": "unique_facial_expressions"}, {"score": 0.003447035529485425, "phrase": "spatial_ratio_template_tracker_algorithm"}, {"score": 0.003212663446866794, "phrase": "real-time_implementation"}, {"score": 0.0031565959573536194, "phrase": "robust_gradient_model"}, {"score": 0.003101503914610488, "phrase": "expression_recognition_system"}, {"score": 0.00304737045343781, "phrase": "facial_velocity_information"}, {"score": 0.0030118058266380503, "phrase": "identified_regions"}, {"score": 0.002890557197908352, "phrase": "rigid_head_motion"}, {"score": 0.002790511479398411, "phrase": "averaged_motion"}, {"score": 0.0027417911324611917, "phrase": "motion_signatures"}, {"score": 0.002646880721119838, "phrase": "support_vector_machines"}, {"score": 0.0025106241866273897, "phrase": "six_basic_emotions"}, {"score": 0.0024667783849055634, "phrase": "completed_system"}, {"score": 0.0021049977753042253, "phrase": "computer_user"}], "paper_keywords": ["expression", " face", " motion", " real-time"], "paper_abstract": "A fully automated, multistage system for real-time recognition of facial expression is presented. The system uses facial motion to characterize monochrome frontal views of facial expressions and is able to operate effectively in cluttered and dynamic scenes, recognizing the six emotions universally associated with unique facial expressions, namely happiness, sadness, disgust, surprise, fear, and anger. Faces are located using a spatial ratio template tracker algorithm. Optical flow of the face is subsequently determined using a real-time implementation of a robust gradient model. The expression recognition system then averages facial velocity information over identified regions of the face and cancels out rigid head motion by taking ratios of this averaged motion. The motion signatures produced are then classified using Support Vector Machines as either nonexpressive or as one of the six basic emotions. The completed system is demonstrated in two simple affective computing applications that respond in real-time to the facial expressions of the user, thereby providing the potential for improvements in the interaction between a computer user and technology.", "paper_title": "A real-time automated system for the recognition of human facial expressions", "paper_id": "WOS:000234882600008"}