{"auto_keywords": [{"score": 0.037796462302704156, "phrase": "logarithmic_entropy"}, {"score": 0.00481495049065317, "phrase": "sine_entropy_for_uncertain_variables._entropy"}, {"score": 0.003946960862020283, "phrase": "uncertainty_theory"}, {"score": 0.0024894376091589244, "phrase": "maximum_entropy_principle"}, {"score": 0.0023133055945761235, "phrase": "arc-cosine_distributed_variables"}, {"score": 0.0021496083700137305, "phrase": "maximum_sine_entropy"}], "paper_keywords": ["Uncertain variable", " entropy", " sine entropy", " maximum entropy principle"], "paper_abstract": "Entropy is a measure of the uncertainty associated with a variable whose value cannot be exactly predicated. In uncertainty theory, it has been quantified so far by logarithmic entropy. However, logarithmic entropy sometimes fails to measure the uncertainty. This paper will propose another type of entropy named sine entropy as a supplement, and explore its properties. After that, the maximum entropy principle will be introduced, and the arc-cosine distributed variables will be proved to have the maximum sine entropy with given expected value and variance.", "paper_title": "SINE ENTROPY FOR UNCERTAIN VARIABLES", "paper_id": "WOS:000325720900005"}