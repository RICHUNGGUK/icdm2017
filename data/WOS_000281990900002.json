{"auto_keywords": [{"score": 0.025129584687412828, "phrase": "ffd_method"}, {"score": 0.00481495049065317, "phrase": "dynamic_texture-based"}, {"score": 0.00474946741204285, "phrase": "recognition_of_facial_actions"}, {"score": 0.004475798524102238, "phrase": "dynamic_texture-based_approach"}, {"score": 0.004374772264092067, "phrase": "facial_action_units"}, {"score": 0.004085115444878828, "phrase": "temporal_segments"}, {"score": 0.0035945701438887282, "phrase": "face_region"}, {"score": 0.003545625043276134, "phrase": "input_video"}, {"score": 0.003418327319110734, "phrase": "motion_history_images_and_a"}, {"score": 0.0033410898465226417, "phrase": "nonrigid_registration"}, {"score": 0.003310684108128973, "phrase": "free-form_deformations"}, {"score": 0.003221111762383486, "phrase": "extracted_motion_representation"}, {"score": 0.0031483163191080425, "phrase": "motion_orientation_histogram_descriptors"}, {"score": 0.0029396242707327986, "phrase": "hidden_markov_models"}, {"score": 0.002769950045729965, "phrase": "input_image_sequence"}, {"score": 0.002539379289856756, "phrase": "mmi_facial_expression_database"}, {"score": 0.0025047659706737215, "phrase": "proposed_method"}, {"score": 0.0024706232839499546, "phrase": "average_event_recognition_accuracy"}, {"score": 0.0024147474002390763, "phrase": "mhi_method"}, {"score": 0.002327956449278255, "phrase": "generalization_performance"}, {"score": 0.0021340985236583034, "phrase": "spontaneous_expressions"}, {"score": 0.0021049977753042253, "phrase": "sensitive_artificial_listener_data_set"}], "paper_keywords": ["Facial image analysis", " facial expression", " dynamic texture", " motion"], "paper_abstract": "In this work, we propose a dynamic texture-based approach to the recognition of facial Action Units (AUs, atomic facial gestures) and their temporal models (i.e., sequences of temporal segments: neutral, onset, apex, and offset) in near-frontal-view face videos. Two approaches to modeling the dynamics and the appearance in the face region of an input video are compared: an extended version of Motion History Images and a novel method based on Nonrigid Registration using Free-Form Deformations (FFDs). The extracted motion representation is used to derive motion orientation histogram descriptors in both the spatial and temporal domain. Per AU, a combination of discriminative, frame-based GentleBoost ensemble learners and dynamic, generative Hidden Markov Models detects the presence of the AU in question and its temporal segments in an input image sequence. When tested for recognition of all 27 lower and upper face AUs, occurring alone or in combination in 264 sequences from the MMI facial expression database, the proposed method achieved an average event recognition accuracy of 89.2 percent for the MHI method and 94.3 percent for the FFD method. The generalization performance of the FFD method has been tested using the Cohn-Kanade database. Finally, we also explored the performance on spontaneous expressions in the Sensitive Artificial Listener data set.", "paper_title": "A Dynamic Texture-Based Approach to Recognition of Facial Actions and Their Temporal Models", "paper_id": "WOS:000281990900002"}