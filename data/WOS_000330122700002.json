{"auto_keywords": [{"score": 0.04809629388275188, "phrase": "mwsp"}, {"score": 0.008153674335490902, "phrase": "mwsp_approach"}, {"score": 0.00481495049065317, "phrase": "noisy_audio-video_conditions"}, {"score": 0.004527804152066942, "phrase": "robust_and_efficient_stream_integration_method"}, {"score": 0.004493130934067195, "phrase": "audio-visual_speech_recognition"}, {"score": 0.004390689303780405, "phrase": "audio_or_video_streams"}, {"score": 0.004307099985737249, "phrase": "unknown_and_time-varying_corruption"}, {"score": 0.004081385289516914, "phrase": "specific_measurements"}, {"score": 0.003957735532719663, "phrase": "appropriate_stream_weights"}, {"score": 0.0033158265075584796, "phrase": "speaker-independent_audio-visual_speech_recognition"}, {"score": 0.00322769360059123, "phrase": "clean_and_corrupted_utterances"}, {"score": 0.002820850247525606, "phrase": "excellent_performance"}, {"score": 0.0027670642397888494, "phrase": "well-known_dynamic_stream"}, {"score": 0.002683125911877974, "phrase": "fixed-weighted_integration_approach"}, {"score": 0.0024556852466581527, "phrase": "suitable_integration_weights"}, {"score": 0.002427473263013356, "phrase": "frame-by-frame_basis"}, {"score": 0.0022911901892022847, "phrase": "naturally_fluctuating_relative_reliability"}, {"score": 0.0022388390432214415, "phrase": "clean_conditions"}, {"score": 0.0021708894366462153, "phrase": "robust_recognition_performance"}, {"score": 0.002145942273032774, "phrase": "tested_conditions"}, {"score": 0.0021049977753042253, "phrase": "prior_knowledge"}], "paper_keywords": ["Automatic speech recognition", " human computer interaction", " speech recognition"], "paper_abstract": "This paper presents the maximum weighted stream posterior (MWSP) model as a robust and efficient stream integration method for audio-visual speech recognition in environments, where the audio or video streams may be subjected to unknown and time-varying corruption. A significant advantage of MWSP is that it does not require any specific measurements of the signal in either stream to calculate appropriate stream weights during recognition, and as such it is modality-independent. This also means that MWSP complements and can be used alongside many of the other approaches that have been proposed in the literature for this problem. For evaluation we used the large XM2VTS database for speaker-independent audio-visual speech recognition. The extensive tests include both clean and corrupted utterances with corruption added in either/both the video and audio streams using a variety of types (e.g., MPEG-4 video compression) and levels of noise. The experiments show that this approach gives excellent performance in comparison to another well-known dynamic stream weighting approach and also compared to any fixed-weighted integration approach in both clean conditions or when noise is added to either stream. Furthermore, our experiments show that the MWSP approach dynamically selects suitable integration weights on a frame-by-frame basis according to the level of noise in the streams and also according to the naturally fluctuating relative reliability of the modalities even in clean conditions. The MWSP approach is shown to maintain robust recognition performance in all tested conditions, while requiring no prior knowledge about the type or level of noise.", "paper_title": "Robust Audio-Visual Speech Recognition Under Noisy Audio-Video Conditions", "paper_id": "WOS:000330122700002"}