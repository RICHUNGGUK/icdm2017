{"auto_keywords": [{"score": 0.04363039692917957, "phrase": "bad_illumination"}, {"score": 0.015719716506582538, "phrase": "robust_face_recognition"}, {"score": 0.012998988751501475, "phrase": "extensive_experiments"}, {"score": 0.009310969536155523, "phrase": "proposed_method"}, {"score": 0.004763895422211728, "phrase": "context-aware_approach"}, {"score": 0.00421410521089045, "phrase": "uneven_illumination_environments"}, {"score": 0.004038076978795421, "phrase": "robust_face_recognition_systems"}, {"score": 0.0038079353103469865, "phrase": "individual_filtering_methods"}, {"score": 0.003767517649628532, "phrase": "image_enhancement"}, {"score": 0.003668333531296882, "phrase": "application_environments"}, {"score": 0.0035338315037521627, "phrase": "good_performance"}, {"score": 0.00335016692413066, "phrase": "normal_illumination"}, {"score": 0.003244567402785763, "phrase": "histogram_equalization"}, {"score": 0.003210110095236981, "phrase": "sufficiently_good_performance"}, {"score": 0.0031760175583084274, "phrase": "normal_images"}, {"score": 0.0029789104204803137, "phrase": "prior_knowledge"}, {"score": 0.002931569771634119, "phrase": "system-working_environment"}, {"score": 0.0027791193706247267, "phrase": "adaptive_preprocessing"}, {"score": 0.002720376476146181, "phrase": "feature_representation_configuration"}, {"score": 0.002662871928330334, "phrase": "filter_combination"}, {"score": 0.0026205405415623525, "phrase": "illumination_context-awareness"}, {"score": 0.0025109095718850376, "phrase": "inha"}, {"score": 0.002484227620653613, "phrase": "feret"}, {"score": 0.002317533977770783, "phrase": "uneven_illumination"}, {"score": 0.002256435842862802, "phrase": "proposed_system"}, {"score": 0.002220551141101661, "phrase": "exceptional_performance"}, {"score": 0.002196944917134202, "phrase": "varying_illumination_environments"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["filter processing", " face recognition", " genetic processing", " illumination"], "paper_abstract": "In this paper, we investigate how to preprocess and accurately identify features from both normal and bad input images, for robust face recognition under uneven illumination environments. Bad illumination is the most challenging problem when implementing robust face recognition systems. From extensive experiments, we found that the performance of individual filtering methods for image enhancement is highly dependent upon application environments. For example, retinex provides good performance under bad illumination. However, it provides very poor performance under normal illumination. On the other hand, histogram equalization provides sufficiently good performance for normal images, however, performance falls dramatically under bad illumination. Since no prior knowledge of the system-working environment can be assumed, the proposed method tries to provide adaptive preprocessing as well as feature representation configuration by exploring the filter combination based on illumination context-awareness. The proposed method has been tested on Inha and FERET image datasets at the preprocessing and feature representation stages for robust face recognition under uneven illumination. Extensive experiments show the proposed system can achieve exceptional performance in varying illumination environments. (c) 2006 Published by Elsevier B.V.", "paper_title": "Adaptive feature representation for robust face recognition using context-aware approach", "paper_id": "WOS:000244137700005"}