{"auto_keywords": [{"score": 0.03258074124501819, "phrase": "human_performance"}, {"score": 0.00960839180959141, "phrase": "haptic_information"}, {"score": 0.007537191680484452, "phrase": "pick-and-place_task"}, {"score": 0.0067069561231569, "phrase": "position_errors"}, {"score": 0.0058241051683672485, "phrase": "performance_degradation"}, {"score": 0.00481495049065317, "phrase": "constant_visual"}, {"score": 0.004791539509460757, "phrase": "haptic_time_delays"}, {"score": 0.004687584146342977, "phrase": "visual_feedback"}, {"score": 0.004530320329534992, "phrase": "robotic_bilateral_teleoperation"}, {"score": 0.004432007036873777, "phrase": "remote_location"}, {"score": 0.004262443682087016, "phrase": "communication_network"}, {"score": 0.004210791715561724, "phrase": "nonsynchronized_delay"}, {"score": 0.00410935022329555, "phrase": "constant_nonsynchronized_and_synchronized_time_delay"}, {"score": 0.004029952287166556, "phrase": "human_teleoperation_performance"}, {"score": 0.00400057357306865, "phrase": "experimental_setup"}, {"score": 0.003971408178423107, "phrase": "virtual_reality_environment"}, {"score": 0.003885176600463076, "phrase": "virtual_objects"}, {"score": 0.0038568492270268087, "phrase": "simulated_remote_environment"}, {"score": 0.0038287275986210543, "phrase": "haptic_device"}, {"score": 0.0037915495805311886, "phrase": "force_feedback"}, {"score": 0.0036198068824262464, "phrase": "synchronized_and_nonsynchronized_delays"}, {"score": 0.0035934073774126856, "phrase": "specific_parameters"}, {"score": 0.0035671997165370403, "phrase": "remote_virtual_environment"}, {"score": 0.003549833838782028, "phrase": "stable_teleportation"}, {"score": 0.0034642599795044445, "phrase": "experimental_tasks"}, {"score": 0.003438990973529508, "phrase": "predefined_geometrical_shapes"}, {"score": 0.0033725013794675606, "phrase": "structured_and_unstructured_interactions"}, {"score": 0.0033315975831074932, "phrase": "guiding_forces"}, {"score": 0.0031651325180154302, "phrase": "visual_and_haptic_time_delays"}, {"score": 0.0030587884803931964, "phrase": "task_completion_time"}, {"score": 0.0029632328136277968, "phrase": "haptic_time_delay"}, {"score": 0.0029201397661854376, "phrase": "anova_analyses"}, {"score": 0.002667869516253534, "phrase": "completion_time"}, {"score": 0.0025098414374397308, "phrase": "haptics_information"}, {"score": 0.002298544073884724, "phrase": "teleoperation_tasks"}, {"score": 0.0022706362238089244, "phrase": "inherent_time_delays"}, {"score": 0.0022104232660412767, "phrase": "time_delay"}, {"score": 0.002194279858055054, "phrase": "profound_effect"}, {"score": 0.0021465520836247225, "phrase": "patient_safety"}, {"score": 0.0021049977753042253, "phrase": "surgical_procedure"}], "paper_keywords": [""], "paper_abstract": "Visual feedback and force feedback (haptics) are the two streams of information in a robotic bilateral teleoperation where the operator manipulates a robot in a remote location. Delivering the visual and the haptic information depends in part on the characteristics of the communication network and results in a nonsynchronized delay. The goal is to study the effect of constant nonsynchronized and synchronized time delay of visual and haptic information on the human teleoperation performance. The experimental setup included a virtual reality environment, which allows the operator to manipulate the virtual objects in a simulated remote environment through a haptic device that renders the force feedback. The visual and the haptic information were delayed independently in the range of 0-500 ms, creating 121 different scenarios of synchronized and nonsynchronized delays. Selecting specific parameters of the remote virtual environment guaranteed stable teleportation, given the time delays under study. The experimental tasks included tracing predefined geometrical shapes and a pick-and-place task, which simulates both structured and unstructured interactions under the influence of guiding forces. Eight subjects (n = 8) participated in the experiment performing three repetitions of three different teleoperation tasks with 121 combinations of visual and haptic time delays. The measured parameters that were used to assess the human performance were the task completion time and the position errors expressed as a function of the visual and the haptic time delay. Then, regression and ANOVA analyses were performed. The results indicated that the human performance is a function of the sum of the two delays. As the sum of the two delays increases, the human performance degrades and is expressed with an increase in completion time and position errors. The performance degradation is more pronounced in the pick-and-place task compared to the tracing task. In scenarios where the visual and the haptics information were out of synchronization, the human performance was better than intentionally delaying one source of information in an attempt to synchronize and unify the two delays. The results of this study may be applied to any teleoperation tasks over a network with inherent time delays and more specifically to telesurgery in which performance degradation due to time delay has a profound effect on the quality of the healthcare delivered, patient safety, and ultimately the outcomes of the surgical procedure itself.", "paper_title": "Constant Visual and Haptic Time Delays in Simulated Bilateral Teleoperation: Quantifying the Human Operator Performance", "paper_id": "WOS:000335505300001"}