{"auto_keywords": [{"score": 0.032433713148480384, "phrase": "saws"}, {"score": 0.014916307589752258, "phrase": "parallel_applications"}, {"score": 0.00481495049065317, "phrase": "concurrent_many-core_runtime_systems"}, {"score": 0.00470975295439431, "phrase": "many-core_architectures"}, {"score": 0.004606843145343611, "phrase": "explosive_development"}, {"score": 0.004526129302830441, "phrase": "programming_models"}, {"score": 0.004446851362414958, "phrase": "openmp"}, {"score": 0.004407693205922426, "phrase": "tbb"}, {"score": 0.004311352359122141, "phrase": "increasing_number"}, {"score": 0.0039815737219022675, "phrase": "current_many-core_runtime_systems"}, {"score": 0.0038602215057106917, "phrase": "collaborative_scheduling"}, {"score": 0.003676926952533304, "phrase": "feedback-driven_adaptive_scheduling"}, {"score": 0.00353342812142574, "phrase": "efficient_solution"}, {"score": 0.0033955105098235345, "phrase": "many-core_systems"}, {"score": 0.002999823428906084, "phrase": "active_workers"}, {"score": 0.002934166052954463, "phrase": "active_deques"}, {"score": 0.0028572658971252616, "phrase": "runtime_characteristics"}, {"score": 0.0027578496677536373, "phrase": "prototype_system"}, {"score": 0.002685558057339722, "phrase": "cilk_runtime_system"}, {"score": 0.0026384167183586015, "phrase": "experimental_results"}, {"score": 0.0025578967205807843, "phrase": "sun_fire_server"}, {"score": 0.0024579623598183355, "phrase": "concurrent_parallel_applications"}, {"score": 0.0023935128386292966, "phrase": "existing_algorithms_a-steal"}, {"score": 0.0021049977753042253, "phrase": "processor_utilization"}], "paper_keywords": ["many-core architectures", " many-core runtime systems", " feedback-driven adaptive scheduling"], "paper_abstract": "The proliferation of many-core architectures has led to the explosive development of parallel applications using programming models, such as OpenMP, TBB, and Cilk/Cilk++. With increasing number of cores, however, it becomes even harder to efficiently schedule parallel applications on these resources since current many-core runtime systems still lack effective mechanisms to support collaborative scheduling of these applications. In this paper, we study feedback-driven adaptive scheduling based on work stealing, which provides an efficient solution for concurrently executing a set of applications on many-core systems. To dynamically estimate the number of cores desired by each application, a stable feedback-driven adaptive algorithm, called SAWS, is proposed using active workers and the length of active deques, which well captures the runtime characteristics of the applications. Furthermore, a prototype system is built by extending the Cilk runtime system, and the experimental results, which are obtained on a Sun Fire server, show that SAWS has more advantages for scheduling concurrent parallel applications. Specifically, compared with existing algorithms A-Steal and WS-EQUI, SAWS improves the performances by up to 12.43% and 21.32% with respect to mean response time respectively, and 25.78% and 46.98% with respect to processor utilization, respectively.", "paper_title": "Stable Adaptive Work-Stealing for Concurrent Many-Core Runtime Systems", "paper_id": "WOS:000304573100025"}