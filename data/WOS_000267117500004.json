{"auto_keywords": [{"score": 0.04549081542587916, "phrase": "class_probability_estimation"}, {"score": 0.014823346091290025, "phrase": "error_rate"}, {"score": 0.004435112270935294, "phrase": "probability-based_classifiers"}, {"score": 0.004237138632255772, "phrase": "test_instance"}, {"score": 0.004160435626849478, "phrase": "predicted_class"}, {"score": 0.003832031470970347, "phrase": "highest_class_probability_estimation"}, {"score": 0.0037454814403672697, "phrase": "actual_class"}, {"score": 0.0036275736378775757, "phrase": "classification_accuracy"}, {"score": 0.003449718244515019, "phrase": "direct_marketing"}, {"score": 0.0033410898465226417, "phrase": "different_promotion_strategies"}, {"score": 0.0032805541677236325, "phrase": "different_likelihood"}, {"score": 0.003105428650735113, "phrase": "accurate_class_probability_estimations"}, {"score": 0.003021392767766593, "phrase": "optimal_decisions"}, {"score": 0.0028863414975346512, "phrase": "state-of-the-art_probability-based_classifiers"}, {"score": 0.002610043728801011, "phrase": "attractive_algorithm"}, {"score": 0.0025047659706737215, "phrase": "locally_weighted_version"}, {"score": 0.002403724423251419, "phrase": "locally_weighted_learning"}, {"score": 0.0021636021558108474, "phrase": "weka"}, {"score": 0.0021340985236583034, "phrase": "experimental_results"}], "paper_keywords": ["C4.4", " locally weighted C4.4", " class probability estimation", " locally weighted learning", " conditional log likelihood", " AUC", " classification"], "paper_abstract": "Traditionally, the performance of a classifier is measured by its classification accuracy or error rate. In fact, probability-based classifiers also produce the class probability estimation (the probability that a test instance belongs to the predicted class). This information is often ignored in classification, as long as the class with the highest class probability estimation is identical to the actual class. In many data mining applications, however, classification accuracy and error rate are not enough. For example, in direct marketing, we often need to deploy different promotion strategies to customers with different likelihood (class probability) of buying some products. Thus, accurate class probability estimations are often required to make optimal decisions. In this paper, we firstly review some state-of-the-art probability-based classifiers and empirically investigate their class probability estimation performance. From our experimental results, we can draw a conclusion: C4.4 is an attractive algorithm for class probability estimation. Then, we present a locally weighted version of C4.4 to scale up its class probability estimation performance by combining locally weighted learning with C4.4. We call our improved algorithm locally weighted C4.4, simply LWC4.4. We experimentally test LWC4.4 using the whole 36 UCI data sets selected by Weka. The experimental results show that LWC4.4 significantly outperforms C4.4 in terms of class probability estimation.", "paper_title": "DECISION TREE WITH BETTER CLASS PROBABILITY ESTIMATION", "paper_id": "WOS:000267117500004"}