{"auto_keywords": [{"score": 0.03773940037527391, "phrase": "dictionary_elements"}, {"score": 0.00481495049065317, "phrase": "dictionary_learning_for_noisy_and_incomplete_hyperspectral_images"}, {"score": 0.004724365740062236, "phrase": "noisy_and_incomplete_hyperspectral_imagery"}, {"score": 0.004548253531664032, "phrase": "missing_data"}, {"score": 0.0045052562941109734, "phrase": "noise_statistics"}, {"score": 0.004215397034321004, "phrase": "potentially_entire_bands"}, {"score": 0.0036092644587974953, "phrase": "linear_combination"}, {"score": 0.0033875770020590796, "phrase": "observed_data"}, {"score": 0.003344895435289136, "phrase": "priori_training"}, {"score": 0.00322003996276874, "phrase": "particular_block"}, {"score": 0.0031895588542135245, "phrase": "small_relative"}, {"score": 0.0031593653672862924, "phrase": "block_dimensions"}, {"score": 0.0030126187386121613, "phrase": "underlying_dictionary"}, {"score": 0.002937153116494391, "phrase": "bayesian_perspective"}, {"score": 0.002881793492919646, "phrase": "sparse_dictionary_usage"}, {"score": 0.0027392018850028706, "phrase": "underlying_wavelength-dependent_noise_statistics"}, {"score": 0.0026452734009203764, "phrase": "gaussian_process"}, {"score": 0.002587180385280577, "phrase": "wavelength_dependence"}, {"score": 0.002538400273615248, "phrase": "significant_advantages"}, {"score": 0.0024361367292747215, "phrase": "gaussian"}, {"score": 0.0022643957465558287, "phrase": "hyperspectral_imagery"}, {"score": 0.002242940472941759, "phrase": "significant_number"}, {"score": 0.0021659920594094407, "phrase": "specific_wavelengths"}, {"score": 0.0021049977753042253, "phrase": "substantial_additive_noise"}], "paper_keywords": ["hyperspectral imagery", " missing data", " dictionary learning", " sparse coding", " Bayesian framework", " Gaussian process", " denoising", " beta process", " Indian buffet process", " Gibbs sampler", " parameter-free", " interpolation"], "paper_abstract": "We consider analysis of noisy and incomplete hyperspectral imagery, with the objective of removing the noise and inferring the missing data. The noise statistics may be wavelength dependent, and the fraction of data missing (at random) may be substantial, including potentially entire bands, offering the potential to significantly reduce the quantity of data that need be measured. To achieve this objective, the imagery is divided into contiguous three-dimensional (3D) spatio-spectral blocks of spatial dimension much less than the image dimension. It is assumed that each such 3D block may be represented as a linear combination of dictionary elements of the same dimension, plus noise, and the dictionary elements are learned in situ based on the observed data (no a priori training). The number of dictionary elements needed for representation of any particular block is typically small relative to the block dimensions, and all the image blocks are processed jointly (\"collaboratively\") to infer the underlying dictionary. We address dictionary learning from a Bayesian perspective, considering two distinct means of imposing sparse dictionary usage. These models allow inference of the number of dictionary elements needed as well as the underlying wavelength-dependent noise statistics. It is demonstrated that drawing the dictionary elements from a Gaussian process prior, imposing structure on the wavelength dependence of the dictionary elements, yields significant advantages, relative to the more conventional approach of using an independent and identically distributed Gaussian prior for the dictionary elements; this advantage is particularly evident in the presence of noise. The framework is demonstrated by processing hyperspectral imagery with a significant number of voxels missing uniformly at random, with imagery at specific wavelengths missing entirely, and in the presence of substantial additive noise.", "paper_title": "Dictionary Learning for Noisy and Incomplete Hyperspectral Images", "paper_id": "WOS:000302220800002"}