{"auto_keywords": [{"score": 0.03992659287798476, "phrase": "efficient_feature_selection"}, {"score": 0.00481495049065317, "phrase": "selected_features"}, {"score": 0.004721162131188487, "phrase": "software_defect_data"}, {"score": 0.00462919213721188, "phrase": "feature_irrelevance"}, {"score": 0.004598933498016774, "phrase": "missing_samples"}, {"score": 0.004479855062309818, "phrase": "balanced_distribution"}, {"score": 0.004406994912939125, "phrase": "defective_and_non-defective_software"}, {"score": 0.0042508289538799905, "phrase": "latter_software_class"}, {"score": 0.003993958025223994, "phrase": "positive_effects"}, {"score": 0.003954837422946628, "phrase": "feature_selection"}, {"score": 0.003852371777780562, "phrase": "defect_classification"}, {"score": 0.003537275726870251, "phrase": "selected_ensemble_learning_models"}, {"score": 0.003400640983719424, "phrase": "defect_classification_performance"}, {"score": 0.003356275163203055, "phrase": "forward_selection"}, {"score": 0.0032908057622663732, "phrase": "high_area"}, {"score": 0.0032585499655442404, "phrase": "receiver-operating_curve"}, {"score": 0.0031845067058084583, "phrase": "tested_datasets"}, {"score": 0.003051418904573872, "phrase": "pearson's_correlation"}, {"score": 0.0029334961578930054, "phrase": "ensemble_learners"}, {"score": 0.002914288956035066, "phrase": "random_forests"}, {"score": 0.0028857130140890787, "phrase": "proposed_algorithm"}, {"score": 0.002866817775018445, "phrase": "average_probability_ensemble"}, {"score": 0.0027741761880779535, "phrase": "poor_features"}, {"score": 0.0027200305495826797, "phrase": "weighted_support_vector_machines"}, {"score": 0.0026321198895843173, "phrase": "ape_model"}, {"score": 0.00260630351276416, "phrase": "greedy_forward_selection"}, {"score": 0.0025554259726979786, "phrase": "auc_values"}, {"score": 0.0025055391159787134, "phrase": "nasa_datasets"}, {"score": 0.002361632539339945, "phrase": "software_dataset"}, {"score": 0.0023155201226300955, "phrase": "accurate_classification"}, {"score": 0.0023003498123420237, "phrase": "defective_components"}, {"score": 0.002255431275670053, "phrase": "software_data_issues"}, {"score": 0.0022041312401435346, "phrase": "proposed_combined_learning_model"}, {"score": 0.0021825034787117986, "phrase": "remarkable_classification_performance"}, {"score": 0.002146926767291475, "phrase": "successful_quality_control"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Defect prediction", " Ensemble learning", " Software quality", " Feature selection", " Data imbalance", " Feature redundancy/correlation"], "paper_abstract": "Context: Several issues hinder software defect data including redundancy, correlation, feature irrelevance and missing samples. It is also hard to ensure balanced distribution between data pertaining to defective and non-defective software. In most experimental cases, data related to the latter software class is dominantly present in the dataset. Objective: The objectives of this paper are to demonstrate the positive effects of combining feature selection and ensemble learning on the performance of defect classification. Along with efficient feature selection, a new two-variant (with and without feature selection) ensemble learning algorithm is proposed to provide robustness to both data imbalance and feature redundancy. Method: We carefully combine selected ensemble learning models with efficient feature selection to address these issues and mitigate their effects on the defect classification performance. Results: Forward selection showed that only few features contribute to high area under the receiver-operating curve (AUC). On the tested datasets, greedy forward selection (GFS) method outperformed other feature selection techniques such as Pearson's correlation. This suggests that features are highly unstable. However, ensemble learners like random forests and the proposed algorithm, average probability ensemble (APE), are not as affected by poor features as in the case of weighted support vector machines (W-SVMs). Moreover, the APE model combined with greedy forward selection (enhanced APE) achieved AUC values of approximately 1.0 for the NASA datasets: PC2, PC4, and MC1. Conclusion: This paper shows that features of a software dataset must be carefully selected for accurate classification of defective components. Furthermore, tackling the software data issues, mentioned above, with the proposed combined learning model resulted in remarkable classification performance paving the way for successful quality control. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Software defect prediction using ensemble learning on selected features", "paper_id": "WOS:000347022800023"}