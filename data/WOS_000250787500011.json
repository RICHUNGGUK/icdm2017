{"auto_keywords": [{"score": 0.027000735806077272, "phrase": "infovis"}, {"score": 0.00481495049065317, "phrase": "insight-based_evaluation"}, {"score": 0.004621447740470602, "phrase": "benchmark_repository"}, {"score": 0.004567596860086148, "phrase": "information_visualization"}, {"score": 0.00438399094249306, "phrase": "accepted_and_growing_field"}, {"score": 0.004207734323806386, "phrase": "best_uses"}, {"score": 0.0040622852274783275, "phrase": "novel_visualizations"}, {"score": 0.004014923642015515, "phrase": "usability_studies"}, {"score": 0.003968112038249246, "phrase": "controlled_experiments"}, {"score": 0.003676811616723809, "phrase": "systematic_development"}, {"score": 0.0033868916699805224, "phrase": "different_conditions"}, {"score": 0.002258745901862197, "phrase": "visualization_contests"}, {"score": 0.0021049977753042253, "phrase": "infovis_benchmark_repository"}], "paper_keywords": ["visualization", " information", " competition", " contest", " benchmark", " repository", " measure", " metrics"], "paper_abstract": "Information Visualization (InfoVis) is now an accepted and growing field, but questions remain about the best uses for and the maturity of novel visualizations. Usability studies and controlled experiments are helpful, but generalization is difficult. We believe that the systematic development of benchmarks will facilitate the comparison of techniques and help identify their strengths under different conditions. We were involved in the organization and management of three InfoVis contests for the 2003, 2004, and 2005 IEEE InfoVis Symposia, which requested teams to report on insights gained while exploring data. We give a summary of the state of the art of evaluation in InfoVis, describe the three contests, summarize their results, discuss outcomes and lessons learned, and conjecture the future of visualization contests. All materials produced by the contests are archived in the InfoVis Benchmark Repository.", "paper_title": "Promoting insight-based evaluation of visualizations: From contest to benchmark repository", "paper_id": "WOS:000250787500011"}