{"auto_keywords": [{"score": 0.04886626441968086, "phrase": "visual_context"}, {"score": 0.00481495049065317, "phrase": "item_density"}, {"score": 0.004645057834614705, "phrase": "magic_lens_interactions"}, {"score": 0.0043452175611323335, "phrase": "handheld_augmented_reality_interfaces"}, {"score": 0.004278807087784626, "phrase": "dynamic_peephole_interface"}, {"score": 0.0041490029730869345, "phrase": "device_display"}, {"score": 0.004023120753104693, "phrase": "magic_lens_interface"}, {"score": 0.0038413947966606118, "phrase": "external_visual_context"}, {"score": 0.0035382855372646164, "phrase": "specific_attribute"}, {"score": 0.0034663083890589235, "phrase": "different_sizes"}, {"score": 0.003361069456060196, "phrase": "different_numbers"}, {"score": 0.00325901518290063, "phrase": "i.e._different_item_densities"}, {"score": 0.0032256881625734777, "phrase": "hand_motion_patterns"}, {"score": 0.003192700856094016, "phrase": "eye_movements"}, {"score": 0.0030017207229983385, "phrase": "sparsely_distributed_items"}, {"score": 0.002910545717767559, "phrase": "increasing_item_density"}, {"score": 0.0028807718824400697, "phrase": "user_performance"}, {"score": 0.002836679611901583, "phrase": "magic_lens_case"}, {"score": 0.0027363971333961967, "phrase": "dynamic_peephole_case"}, {"score": 0.002456272788591051, "phrase": "subjective_feedback"}, {"score": 0.0021821915946356168, "phrase": "mobile_ar"}, {"score": 0.002159852420283463, "phrase": "dynamic_peephole_interfaces"}, {"score": 0.0021267708018655493, "phrase": "spatially_tracked_personal_displays"}, {"score": 0.0021049977753042253, "phrase": "combined_personal_and_public_displays"}], "paper_keywords": ["Magic lens", " Dynamic peephole", " Small display", " Mobile device", " Camera phone", " Focus and context display", " Visual search", " Eye tracking", " Saccades", " Pupil dilation"], "paper_abstract": "This article reports on two user studies investigating the effect of visual context in handheld augmented reality interfaces. A dynamic peephole interface (without visual context beyond the device display) was compared to a magic lens interface (with video see-through augmentation of external visual context). The task was to explore items on a map and look for a specific attribute. We tested different sizes of visual context as well as different numbers of items per area, i.e. different item densities. Hand motion patterns and eye movements were recorded. We found that visual context is most effective for sparsely distributed items and gets less helpful with increasing item density. User performance in the magic lens case is generally better than in the dynamic peephole case, but approaches the performance of the latter the more densely the items are spaced. In all conditions, subjective feedback indicates that participants generally prefer visual context over the lack thereof. The insights gained from this study are relevant for designers of mobile AR and dynamic peephole interfaces, involving spatially tracked personal displays or combined personal and public displays, by suggesting when to use visual context.", "paper_title": "Impact of item density on the utility of visual context in magic lens interactions", "paper_id": "WOS:000270649700008"}