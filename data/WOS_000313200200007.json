{"auto_keywords": [{"score": 0.04855239486253465, "phrase": "svr"}, {"score": 0.01614591905146152, "phrase": "svc"}, {"score": 0.00481495049065317, "phrase": "linear_support_vector_regression"}, {"score": 0.004737579882204798, "phrase": "support_vector_regression"}, {"score": 0.004549524321051407, "phrase": "support_vector"}, {"score": 0.004333642054036135, "phrase": "popular_learning_techniques"}, {"score": 0.003900257249255497, "phrase": "linear_svc"}, {"score": 0.0036553070575015344, "phrase": "competitive_accuracy"}, {"score": 0.0032193047052275514, "phrase": "svr."}, {"score": 0.00303319936111073, "phrase": "state-of-the-art_training_methods"}, {"score": 0.0023016843709107297, "phrase": "proposed_linear-svr_training_methods"}, {"score": 0.0021049977753042253, "phrase": "kernel_svr."}], "paper_keywords": ["support vector regression", " Newton methods", " coordinate descent methods"], "paper_abstract": "Support vector regression (SVR) and support vector classification (SVC) are popular learning techniques, but their use with kernels is often time consuming. Recently, linear SVC without kernels has been shown to give competitive accuracy for some applications, but enjoys much faster training/testing. However, few studies have focused on linear SVR. In this paper, we extend state-of-the-art training methods for linear SVC to linear SVR. We show that the extension is straightforward for some methods, but is not trivial for some others. Our experiments demonstrate that for some problems, the proposed linear-SVR training methods can very efficiently produce models that are as good as kernel SVR.", "paper_title": "Large-scale Linear Support Vector Regression", "paper_id": "WOS:000313200200007"}