{"auto_keywords": [{"score": 0.029806330873165907, "phrase": "convex_hull"}, {"score": 0.014988765784248674, "phrase": "decision_maker"}, {"score": 0.00481495049065317, "phrase": "online_learning"}, {"score": 0.004101088357088207, "phrase": "sample_path"}, {"score": 0.0037244390953401533, "phrase": "highest_reward"}, {"score": 0.003301733505307784, "phrase": "nature's_choices"}, {"score": 0.0027446057983474994, "phrase": "reward-in-hindsight_function"}, {"score": 0.002553063001454623, "phrase": "important_case"}, {"score": 0.0024922258873137093, "phrase": "single_constraint"}, {"score": 0.0023369711258107244, "phrase": "highest_attainable_function"}, {"score": 0.0022268964676199292, "phrase": "explicit_strategy"}, {"score": 0.0021049977753042253, "phrase": "calibrated_forecasting_rule"}], "paper_keywords": [""], "paper_abstract": "We study online learning where the objective of the decision maker is to maximize her average long-term reward given that some average constraints are satisfied along the sample path. We define the reward-in-hindsight as the highest reward the decision maker could have achieved, while satisfying the constraints, had she known Nature's choices in advance. We show that in general the reward-in-hindsight is not attainable. The convex hull of the reward-in-hindsight function is, however, attainable. For the important case of a single constraint the convex hull turns out to be the highest attainable function. We further provide an explicit strategy that attains this convex hull using a calibrated forecasting rule.", "paper_title": "Online learning with constraints", "paper_id": "WOS:000239587900039"}