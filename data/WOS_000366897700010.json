{"auto_keywords": [{"score": 0.04853750751694913, "phrase": "voltage_scaling"}, {"score": 0.01212835523063854, "phrase": "vccmin"}, {"score": 0.009897908812147872, "phrase": "redundant_copies"}, {"score": 0.00481495049065317, "phrase": "minimum_supply_voltage"}, {"score": 0.004775726266706856, "phrase": "power-efficient_cache_design"}, {"score": 0.004546970518808189, "phrase": "efficient_way"}, {"score": 0.004346874334971379, "phrase": "large_caches"}, {"score": 0.004258843584164121, "phrase": "good_candidates"}, {"score": 0.004104838067758352, "phrase": "vccmin_problem"}, {"score": 0.004021689117050817, "phrase": "lower_bound"}, {"score": 0.003988901168289797, "phrase": "scalable_voltage"}, {"score": 0.003924121879214595, "phrase": "process_variation"}, {"score": 0.0036753171449945654, "phrase": "multibit_faults"}, {"score": 0.0035423376631308567, "phrase": "current_technologies"}, {"score": 0.00347054319869429, "phrase": "power_consumption"}, {"score": 0.0033449479263613848, "phrase": "data_redundancy"}, {"score": 0.0033176589215021353, "phrase": "memory_hierarchy"}, {"score": 0.003250403288147613, "phrase": "cache_coherence"}, {"score": 0.0031845067058084583, "phrase": "cache_organization"}, {"score": 0.0030818310926031024, "phrase": "cache_blocks"}, {"score": 0.002770389097966904, "phrase": "simple_error_detection_codes"}, {"score": 0.002626645763725465, "phrase": "existing_cache_design"}, {"score": 0.0023322317017275803, "phrase": "negligible_degradation"}, {"score": 0.00219311232069446, "phrase": "dynamic_power"}, {"score": 0.0021398115287338693, "phrase": "static_power"}, {"score": 0.0021049977753042253, "phrase": "previous_minimum_power"}], "paper_keywords": ["Reliability", " Performance", " Dynamic voltage scaling", " SRAM reliability", " cache replacement policy", " VCCMIN"], "paper_abstract": "Voltage scaling is known to be an efficient way of saving power and energy within a system, and large caches such as LLCs are good candidates for voltage scaling considering their constantly increasing size. However, the VCCMIN problem, in which the lower bound of scalable voltage is limited by process variation, has made it difficult to exploit the benefits of voltage scaling. Lowering VCCMIN incurs multibit faults, which cannot be efficiently resolved by current technologies due to their high complexity and power consumption. We overcame the limitation by exploiting the data redundancy of memory hierarchy. For example, cache coherence states and several layers of cache organization naturally expose the existence of redundancy within cache blocks. If blocks have redundant copies, their VCCMIN can be lowered; although more faults can occur in the blocks, they can be efficiently detected by simple error detection codes and recovered by reloading the redundant copies. Our scheme requires only minor modifications to the existing cache design. We verified our proposal on a cycle accurate simulator with SPLASH-2 and PARSEC benchmark suites and found that the VCCMIN of a 2MB L2 cache can be further lowered by 0.1V in 32nm technology with negligible degradation in performance. As a result, we could achieve 15.6% of reduction in dynamic power and 15.4% of reduction in static power compared to the previous minimum power.", "paper_title": "Lowering Minimum Supply Voltage for Power-Efficient Cache Design by Exploiting Data Redundancy", "paper_id": "WOS:000366897700010"}