{"auto_keywords": [{"score": 0.048727646052725185, "phrase": "action_models"}, {"score": 0.01802462030070602, "phrase": "tramp"}, {"score": 0.017381512554308788, "phrase": "target_domain"}, {"score": 0.00954721429163019, "phrase": "training_data"}, {"score": 0.007119301065525529, "phrase": "source_domains"}, {"score": 0.005828388447750829, "phrase": "transferred_knowledge"}, {"score": 0.00481495049065317, "phrase": "transfer_learning"}, {"score": 0.0045843245695654875, "phrase": "intense_research_interest"}, {"score": 0.004364696693320128, "phrase": "significant_amount"}, {"score": 0.004258843584164121, "phrase": "planning_domain"}, {"score": 0.004054745478848129, "phrase": "sufficient_training_data"}, {"score": 0.003988901168289797, "phrase": "learnt_action_models"}, {"score": 0.0039402177950179345, "phrase": "high_quality"}, {"score": 0.0037667216301666196, "phrase": "novel_algorithm_framework"}, {"score": 0.0036304470230058413, "phrase": "limited_training_data"}, {"score": 0.00347054319869429, "phrase": "available_information"}, {"score": 0.003290591812800382, "phrase": "learning_task"}, {"score": 0.0031199418866663543, "phrase": "tramp_transfers"}, {"score": 0.003056682083784002, "phrase": "first_building_structure_mappings"}, {"score": 0.002933973181012572, "phrase": "extra_knowledge"}, {"score": 0.0029100272315053253, "phrase": "web_search"}, {"score": 0.002583931950389087, "phrase": "weighted_formulas"}, {"score": 0.002322689143237591, "phrase": "different_settings"}, {"score": 0.002256973121326987, "phrase": "six_planning_domains"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Al planning", " Action model learning", " Transfer learning", " Markov logic networks", " Web search"], "paper_abstract": "Applying learning techniques to acquire action models is an area of intense research interest. Most previous work in this area has assumed that there is a significant amount of training data available in a planning domain of interest. However, it is often difficult to acquire sufficient training data to ensure the learnt action models are of high quality. In this paper, we seek to explore a novel algorithm framework, called TRAMP, to learn action models with limited training data in a target domain, via transferring as much of the available information from other domains (called source domains) as possible to help the learning task, assuming action models in source domains can be transferred to the target domain. TRAMP transfers knowledge from source domains by first building structure mappings between source and target domains, and then exploiting extra knowledge from Web search to bridge and transfer knowledge from sources. Specifically, TRAMP first encodes training data with a set of propositions, and formulates the transferred knowledge as a set of weighted formulas. After that it learns action models for the target domain to best explain the set of propositions and the transferred knowledge. We empirically evaluate TRAMP in different settings to see their advantages and disadvantages in six planning domains, including four International Planning Competition (IPC) domains and two synthetic domains. (C) 2014 Published by Elsevier B.V.", "paper_title": "Action-model acquisition for planning via transfer learning", "paper_id": "WOS:000336946300005"}