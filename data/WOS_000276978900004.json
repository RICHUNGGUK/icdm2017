{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "visual"}, {"score": 0.008432049284111382, "phrase": "ecg"}, {"score": 0.0046993598473345395, "phrase": "patient_fall_incident_detection."}, {"score": 0.004608879242346434, "phrase": "human_physiological_data"}, {"score": 0.004326624385772596, "phrase": "emergency_event_detection"}, {"score": 0.004181839414007266, "phrase": "elderly_people"}, {"score": 0.003775803846431323, "phrase": "surrounding_environment"}, {"score": 0.003631671435460452, "phrase": "integrated_patient_fall_detection_system"}, {"score": 0.003527181559366122, "phrase": "patient_activity_recognition"}, {"score": 0.003493021648360933, "phrase": "emergency_treatment"}, {"score": 0.003459191419478298, "phrase": "visual_data"}, {"score": 0.003392507399258166, "phrase": "user's_environment"}, {"score": 0.0033433365160336842, "phrase": "overhead_cameras"}, {"score": 0.0032629585038738856, "phrase": "physiological_data"}, {"score": 0.003200045185608395, "phrase": "subject's_body"}, {"score": 0.0031383410838018984, "phrase": "appropriate_tracking_techniques"}, {"score": 0.0030628762739398855, "phrase": "aforementioned_visual_perceptual_component"}, {"score": 0.003018468582368033, "phrase": "trajectory_tracking"}, {"score": 0.002931569771634119, "phrase": "acceleration_data"}, {"score": 0.0028333356794133053, "phrase": "fall_incident"}, {"score": 0.0027651847105654363, "phrase": "subject's_visual_location"}, {"score": 0.002672511078070529, "phrase": "emergency_event"}, {"score": 0.0025085435314540837, "phrase": "blood_oxygen_saturation"}, {"score": 0.002331781764406665, "phrase": "rules-based_evaluation"}, {"score": 0.0021049977753042253, "phrase": "user_based_evaluation"}], "paper_keywords": ["Telemonitoring", " visual tracking", " patient fall detection", " on-body sensor networks", " rules-based evaluation", " activity classification"], "paper_abstract": "The monitoring of human physiological data, in both normal and abnormal situations of activity, is interesting for the purpose of emergency event detection, especially in the case of elderly people living on their own. Several techniques have been proposed for identifying such distress situations using either motion, audio or video data from the monitored subject and the surrounding environment. This paper aims to present an integrated patient fall detection system that may be used for patient activity recognition and emergency treatment. Visual data captured from the user's environment, using overhead cameras among with motion and physiological data collected from the subject's body are utilized. Appropriate tracking techniques are applied to the aforementioned visual perceptual component enabling the trajectory tracking of the subjects, while acceleration data from the sensors can indicate a fall incident. Trajectory information and subject's visual location can verify fall and indicate an emergency event, whereas the interpretation of biosignals like electrocardiogram ( ECG) and blood oxygen saturation (SPO2) can indicate the severity of the incident with the help of rules-based evaluation. The paper includes also the assessment of several classifiers and meta-classifiers in terms of accuracy in detecting falls and a user based evaluation.", "paper_title": "ADVANCED CLASSIFICATION AND RULES-BASED EVALUATION OF MOTION, VISUAL AND BIOSIGNAL DATA FOR PATIENT FALL INCIDENT DETECTION", "paper_id": "WOS:000276978900004"}