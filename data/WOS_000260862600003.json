{"auto_keywords": [{"score": 0.029610180175796384, "phrase": "tts"}, {"score": 0.00481495049065317, "phrase": "humanoid_audio-visual_avatar"}, {"score": 0.004767546015485477, "phrase": "emotive_text-to-speech_synthesis"}, {"score": 0.004582528208024817, "phrase": "virtual_computer_agents"}, {"score": 0.004361276005140776, "phrase": "human-machine_interaction"}, {"score": 0.0043183186953102805, "phrase": "human-human_communication"}, {"score": 0.004150661689086371, "phrase": "human_communication"}, {"score": 0.0038727120021750973, "phrase": "realistic_avatars"}, {"score": 0.003778004256546193, "phrase": "natural-sounding_emotive_speech"}, {"score": 0.0037407704200033607, "phrase": "realistic-looking_emotional_facial_expressions"}, {"score": 0.0035249212996297332, "phrase": "novel_multimodal_framework"}, {"score": 0.003455765987713262, "phrase": "text-driven_emotive_audio-visual_avatar"}, {"score": 0.0033214855341753544, "phrase": "emotive_speech_synthesis"}, {"score": 0.0030988889679192965, "phrase": "speech_gestures"}, {"score": 0.0029199689963238726, "phrase": "general_framework"}, {"score": 0.002724207384182295, "phrase": "diphone_synthesizer"}, {"score": 0.0024306105794630246, "phrase": "rule-based_emotive_tts_synthesis_system_module"}, {"score": 0.002234092591045251, "phrase": "framework_design"}, {"score": 0.0022120408738490437, "phrase": "subjective_listening_experiments"}, {"score": 0.0021049977753042253, "phrase": "synthetic_talking_avatar"}], "paper_keywords": ["Audio-visual avatar", " emotive speech synthesis", " human-computer interaction", " multimodal system", " 3-D face modeling and animation", " TTS"], "paper_abstract": "Emotive audio-visual avatars are virtual computer agents which have the potential of improving the quality of human-machine interaction and human-human communication significantly. However, the understanding of human communication has not yet advanced to the point where it is possible to make realistic avatars that demonstrate interactions with natural-sounding emotive speech and realistic-looking emotional facial expressions. In this paper, We propose the various technical approaches of a novel multimodal framework leading to a text-driven emotive audio-visual avatar. Our primary work is focused on emotive speech synthesis, realistic emotional facial expression animation, and the co-articulation between speech gestures (i.e., lip movements) and facial expressions. A general framework of emotive text-to-speech (TTS) synthesis using a diphone synthesizer is designed and integrated into a generic 3-D avatar face model. Under the guidance of this framework, we therefore developed a realistic 3-D avatar prototype. A rule-based emotive TTS synthesis system module based on the Festival-MBROLA architecture has been designed to demonstrate the effectiveness of the framework design. Subjective listening experiments were carried out to evaluate the expressiveness of the synthetic talking avatar.", "paper_title": "Humanoid Audio-Visual Avatar With Emotive Text-to-Speech Synthesis", "paper_id": "WOS:000260862600003"}