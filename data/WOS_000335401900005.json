{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "robust_embeddings_in"}, {"score": 0.0046986841646790315, "phrase": "high-dimensional_linguistic_features._recent_research"}, {"score": 0.004562847483469705, "phrase": "rich_feature_representation"}, {"score": 0.004474468584252318, "phrase": "natural_language_processing"}, {"score": 0.004323886831151445, "phrase": "exceedingly_large_number"}, {"score": 0.004178351419209898, "phrase": "classification_performance"}, {"score": 0.004077394032903726, "phrase": "redundant_information"}, {"score": 0.003998380230709541, "phrase": "noisy_feature_presentations"}, {"score": 0.0038827100184187805, "phrase": "learning_algorithms"}, {"score": 0.003697287104870263, "phrase": "supervised_embedding_framework"}, {"score": 0.0036256123915754303, "phrase": "relative_positions"}, {"score": 0.0034693659976716197, "phrase": "input_features"}, {"score": 0.0034187896011435245, "phrase": "output_labels"}, {"score": 0.0033361232750221863, "phrase": "local_distribution"}, {"score": 0.003287482882222731, "phrase": "original_data"}, {"score": 0.003239549357111286, "phrase": "embedded_space"}, {"score": 0.003115105266246263, "phrase": "flexible_balance"}, {"score": 0.0030397596289795143, "phrase": "intrinsic_geometry"}, {"score": 0.002966230968271199, "phrase": "class_separability"}, {"score": 0.0029229677574293725, "phrase": "interclass_and_intraclass_instances"}, {"score": 0.002852256089630964, "phrase": "account_characteristics"}, {"score": 0.0028244513779243107, "phrase": "linguistic_features"}, {"score": 0.002769650208851401, "phrase": "inner_product-based_optimization_template"}, {"score": 0.0026501935378083663, "phrase": "empirical_kernel_mapping"}, {"score": 0.002573424607574822, "phrase": "computationally_tractable_processing"}, {"score": 0.002548331088496964, "phrase": "extremely_high-dimensional_input"}, {"score": 0.0024503741901918527, "phrase": "embedding_generation"}, {"score": 0.002356173823922118, "phrase": "six_data_sets"}, {"score": 0.002321787726770895, "phrase": "proposed_framework"}, {"score": 0.00229914226836813, "phrase": "better_classification_performance"}, {"score": 0.002265586601922693, "phrase": "support_vector_machine"}, {"score": 0.0022216045996270974, "phrase": "dimensionality_reduction_technique"}, {"score": 0.002146676231930343, "phrase": "better_class_discriminability"}], "paper_keywords": ["classification", " rich feature representation", " dimensionality reduction", " embedding", " (dis)similarity", " natural language processing"], "paper_abstract": "Recent research has shown the effectiveness of rich feature representation for tasks in natural language processing (NLP). However, exceedingly large number of features do not always improve classification performance. They may contain redundant information, lead to noisy feature presentations, and also render the learning algorithms intractable. In this paper, we propose a supervised embedding framework that modifies the relative positions between instances to increase the compatibility between the input features and the output labels and meanwhile preserves the local distribution of the original data in the embedded space. The proposed framework attempts to support flexible balance between the preservation of intrinsic geometry and the enhancement of class separability for both interclass and intraclass instances. It takes into account characteristics of linguistic features by using an inner product-based optimization template. (Dis)similarity features, also known as empirical kernel mapping, is employed to enable computationally tractable processing of extremely high-dimensional input, and also to handle nonlinearities in embedding generation when necessary. Evaluated on two NLP tasks with six data sets, the proposed framework provides better classification performance than the support vector machine without using any dimensionality reduction technique. It also generates embeddings with better class discriminability as compared to many existing embedding algorithms.", "paper_title": "DISCOVERING ROBUST EMBEDDINGS IN (DIS)SIMILARITY SPACE FOR HIGH-DIMENSIONAL LINGUISTIC FEATURES", "paper_id": "WOS:000335401900005"}