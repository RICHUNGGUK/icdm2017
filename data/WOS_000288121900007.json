{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "artificial_intelligence"}, {"score": 0.004594137808658537, "phrase": "complex_environments"}, {"score": 0.004551199992546761, "phrase": "realistic_environments"}, {"score": 0.004466519142879166, "phrase": "variable_number"}, {"score": 0.004143196873246147, "phrase": "standard_probabilistic_sequence_models"}, {"score": 0.004047020753789236, "phrase": "learning_techniques"}, {"score": 0.004009175817816061, "phrase": "sequential_data"}, {"score": 0.0038431888954930083, "phrase": "relational_complexity"}, {"score": 0.0037363522297378777, "phrase": "statistical_relational_learning_techniques"}, {"score": 0.003598492288058048, "phrase": "complex_sequential_data"}, {"score": 0.0034494494982242187, "phrase": "simple_model"}, {"score": 0.0033851984021896287, "phrase": "intermediate_position"}, {"score": 0.002912331664922248, "phrase": "probability_distribution"}, {"score": 0.0028580564897994175, "phrase": "relational_state_descriptions"}, {"score": 0.0028047899594686003, "phrase": "markov_assumption"}, {"score": 0.0024586427394152196, "phrase": "first-order_level"}, {"score": 0.0024014759148123736, "phrase": "remaining_part"}, {"score": 0.002323663295811215, "phrase": "satisfying_assignments"}, {"score": 0.002291089893848235, "phrase": "boolean_formula"}, {"score": 0.0022589720760078274, "phrase": "binary_decision_diagram"}, {"score": 0.0021857667493036786, "phrase": "resulting_technique"}, {"score": 0.0021349310877334378, "phrase": "probabilistic_relational_domains"}, {"score": 0.0021049977753042253, "phrase": "substantial_number"}], "paper_keywords": ["Statistical relational learning", " Stochastic relational process", " Markov processes", " Time series", " CP-Logic"], "paper_abstract": "One of the goals of artificial intelligence is to develop agents that learn and act in complex environments. Realistic environments typically feature a variable number of objects, relations amongst them, and non-deterministic transition behavior. While standard probabilistic sequence models provide efficient inference and learning techniques for sequential data, they typically cannot fully capture the relational complexity. On the other hand, statistical relational learning techniques are often too inefficient to cope with complex sequential data. In this paper, we introduce a simple model that occupies an intermediate position in this expressiveness/efficiency trade-off. It is based on CP-logic (Causal Probabilistic Logic), an expressive probabilistic logic for modeling causality. However, by specializing CP-logic to represent a probability distribution over sequences of relational state descriptions and employing a Markov assumption, inference and learning become more tractable and effective. Specifically, we show how to solve part of the inference and learning problems directly at the first-order level, while transforming the remaining part into the problem of computing all satisfying assignments for a Boolean formula in a binary decision diagram. We experimentally validate that the resulting technique is able to handle probabilistic relational domains with a substantial number of objects and relations.", "paper_title": "Stochastic relational processes: Efficient inference and applications", "paper_id": "WOS:000288121900007"}