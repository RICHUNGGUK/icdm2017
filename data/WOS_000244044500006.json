{"auto_keywords": [{"score": 0.03784144720028532, "phrase": "acoustic_patterns"}, {"score": 0.03285425557766291, "phrase": "static_spectral_patterns"}, {"score": 0.00481495049065317, "phrase": "spectral_and_temporal_patterns"}, {"score": 0.00443308765153716, "phrase": "continuous_speech"}, {"score": 0.004101281992566145, "phrase": "speech_signal"}, {"score": 0.003685067218455088, "phrase": "recent_paper"}, {"score": 0.003631671435460452, "phrase": "seven_types"}, {"score": 0.003409057326528229, "phrase": "coarticulated_vowels"}, {"score": 0.003359647377874098, "phrase": "current_paper"}, {"score": 0.003310951184365485, "phrase": "previous_study"}, {"score": 0.0032156592392706567, "phrase": "vowel_classification"}, {"score": 0.0031845067058084583, "phrase": "eight_types"}, {"score": 0.0030778231027679464, "phrase": "dynamical_spectral_patterns"}, {"score": 0.00303319936111073, "phrase": "temporal-durational_patterns"}, {"score": 0.0029602552900111407, "phrase": "eight_patterns"}, {"score": 0.002875027551180213, "phrase": "current_automatic_speech_recognition_techniques"}, {"score": 0.002778682854371595, "phrase": "phonetic_model"}, {"score": 0.002685558057339722, "phrase": "significant_vowel_information"}, {"score": 0.0025331002386232014, "phrase": "currently_accepted_boundaries"}, {"score": 0.002436289099444074, "phrase": "double-slope_dynamical_pattern"}, {"score": 0.002366110899738696, "phrase": "simple_durational_pattern"}, {"score": 0.002231747358665628, "phrase": "automatic_speech_recognition_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["acoustic patterns", " pattern recognition", " vowel classification", " automatic speech recognition"], "paper_abstract": "Many previous studies suggested that the information necessary for the identification of vowels from continuous speech is distributed both within and outside vowel boundaries. This information appears to be embedded in the speech signal in the form of various acoustic cues or patterns: spectral, energy, static, dynamic, and temporal. In a recent paper we identified seven types of acoustic patterns that might be exploited by listeners in the identification of coarticulated vowels. The current paper extends the previous study and quantizes the relevance for vowel classification of eight types of acoustic patterns, including static spectral patterns, dynamical spectral patterns, and temporal-durational patterns. Four of these eight patterns are not directly exploited by current automatic speech recognition techniques in computing the likelihood of each phonetic model. These four new patterns proved to contain significant vowel information. Two of these four new patterns represent static spectral patterns lying outside of the currently accepted boundaries of vowels, whereas one is a double-slope dynamical pattern and another one is a simple durational pattern. The findings of this paper may be important for both automatic speech recognition models and models of vowel/phoneme perception by humans. (C) 2006 Elsevier B.V. All rights reserved.", "paper_title": "On the relevance of some spectral and temporal patterns for vowel classification", "paper_id": "WOS:000244044500006"}