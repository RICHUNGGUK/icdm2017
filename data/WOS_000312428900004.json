{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "recommendation_algorithms"}, {"score": 0.0046621835537196754, "phrase": "new_measure"}, {"score": 0.004624751696958501, "phrase": "recommender_systems_performance"}, {"score": 0.004406360418456518, "phrase": "recommendation_algorithm"}, {"score": 0.004164516065972361, "phrase": "stable_algorithm"}, {"score": 0.004064958518350867, "phrase": "algorithm's_own_predictions"}, {"score": 0.004016072233242585, "phrase": "algorithm's_training_data"}, {"score": 0.003601628511550962, "phrase": "interesting_theoretical_property"}, {"score": 0.003390092184270794, "phrase": "desired_practical_property"}, {"score": 0.0033628392198449134, "phrase": "recommender_systems_designers"}, {"score": 0.0032956583072431423, "phrase": "unstable_recommendations"}, {"score": 0.0032428780373184207, "phrase": "users'_trust"}, {"score": 0.003216804708106142, "phrase": "recommender_systems"}, {"score": 0.003114584448820957, "phrase": "users'_acceptance"}, {"score": 0.0029672941061574375, "phrase": "extensive_empirical_evaluation"}, {"score": 0.0029197572138773237, "phrase": "six_popular_recommendation_algorithms"}, {"score": 0.002826949449085849, "phrase": "stability_performance"}, {"score": 0.0028042108531816943, "phrase": "individual_recommendation_algorithms"}, {"score": 0.0026181517251690606, "phrase": "model-based_recommendation_algorithms"}, {"score": 0.0025554669315362424, "phrase": "neighborhood-based_collaborative_filtering_techniques"}, {"score": 0.0024742098091226203, "phrase": "comprehensive_empirical_analysis"}, {"score": 0.002385872451981323, "phrase": "original_rating_data"}, {"score": 0.002347628167175859, "phrase": "input_data"}, {"score": 0.002300681752315682, "phrase": "new_incoming_ratings"}, {"score": 0.0022546720211200893, "phrase": "incoming_ratings"}, {"score": 0.0022095803687183107, "phrase": "evaluation_data"}, {"score": 0.0021049977753042253, "phrase": "recommendation_stability"}], "paper_keywords": ["Algorithms", " Measurement", " Performance", " Reliability", " Recommender systems", " evaluation of recommender systems", " performance measures", " recommendation stability", " recommendation accuracy", " collaborative filtering"], "paper_abstract": "The article explores stability as a new measure of recommender systems performance. Stability is defined to measure the extent to which a recommendation algorithm provides predictions that are consistent with each other. Specifically, for a stable algorithm, adding some of the algorithm's own predictions to the algorithm's training data (for example, if these predictions were confirmed as accurate by users) would not invalidate or change the other predictions. While stability is an interesting theoretical property that can provide additional understanding about recommendation algorithms, we believe stability to be a desired practical property for recommender systems designers as well, because unstable recommendations can potentially decrease users' trust in recommender systems and, as a result, reduce users' acceptance of recommendations. In this article, we also provide an extensive empirical evaluation of stability for six popular recommendation algorithms on four real-world datasets. Our results suggest that stability performance of individual recommendation algorithms is consistent across a variety of datasets and settings. In particular, we find that model-based recommendation algorithms consistently demonstrate higher stability than neighborhood-based collaborative filtering techniques. In addition, we perform a comprehensive empirical analysis of many important factors (e.g., the sparsity of original rating data, normalization of input data, the number of new incoming ratings, the distribution of incoming ratings, the distribution of evaluation data, etc.) and report the impact they have on recommendation stability.", "paper_title": "Stability of Recommendation Algorithms", "paper_id": "WOS:000312428900004"}