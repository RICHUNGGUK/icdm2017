{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "table_tennis"}, {"score": 0.010118796512593899, "phrase": "reward_function"}, {"score": 0.007704846854459792, "phrase": "different_playing_styles"}, {"score": 0.004765482708043842, "phrase": "inverse_reinforcement"}, {"score": 0.004644014990871423, "phrase": "complex_task"}, {"score": 0.00450231514359539, "phrase": "challenging_problem"}, {"score": 0.004253618550301311, "phrase": "necessary_motor_skills"}, {"score": 0.0038959121068990517, "phrase": "opponent's_court"}, {"score": 0.0037188360359702182, "phrase": "data-driven_identification"}, {"score": 0.003623949225126944, "phrase": "interactive_tasks"}, {"score": 0.0034771228725942846, "phrase": "largely_unexplored_problem"}, {"score": 0.0033190180867511605, "phrase": "computational_model"}, {"score": 0.003151736708029235, "phrase": "markov_decision_problem"}, {"score": 0.0029164434911787187, "phrase": "strategic_information"}, {"score": 0.002726740692380339, "phrase": "table_tennis_matches"}, {"score": 0.0026986685585382347, "phrase": "model-free_inverse_reinforcement_learning"}, {"score": 0.0025892330566358503, "phrase": "basic_elements"}, {"score": 0.0025100713447593773, "phrase": "striking_movements"}, {"score": 0.002310578855290687, "phrase": "different_playing_conditions"}, {"score": 0.0022749744354271816, "phrase": "estimated_reward_function"}, {"score": 0.0022168460543913787, "phrase": "expert-specific_strategic_information"}, {"score": 0.0021049977753042253, "phrase": "different_skill_levels"}], "paper_keywords": ["Computational models of decision processes", " Table tennis", " Inverse reinforcement learning"], "paper_abstract": "Learning a complex task such as table tennis is a challenging problem for both robots and humans. Even after acquiring the necessary motor skills, a strategy is needed to choose where and how to return the ball to the opponent's court in order to win the game. The data-driven identification of basic strategies in interactive tasks, such as table tennis, is a largely unexplored problem. In this paper, we suggest a computational model for representing and inferring strategies, based on a Markov decision problem, where the reward function models the goal of the task as well as the strategic information. We show how this reward function can be discovered from demonstrations of table tennis matches using model-free inverse reinforcement learning. The resulting framework allows to identify basic elements on which the selection of striking movements is based. We tested our approach on data collected from players with different playing styles and under different playing conditions. The estimated reward function was able to capture expert-specific strategic information that sufficed to distinguish the expert among players with different skill levels as well as different playing styles.", "paper_title": "Learning strategies in table tennis using inverse reinforcement learning", "paper_id": "WOS:000344733900007"}