{"auto_keywords": [{"score": 0.03363896917055258, "phrase": "alternative_measure"}, {"score": 0.00481495049065317, "phrase": "popular_way"}, {"score": 0.0034118234596993836, "phrase": "marginal_distributions"}, {"score": 0.0025537472239953807, "phrase": "-marginal_and_joint_distributions"}, {"score": 0.0021940118003312397, "phrase": "mutual_information"}, {"score": 0.0021049977753042253, "phrase": "operational_characterizations"}], "paper_keywords": ["divergence", " hypothesis testing", " information measures", " Kelly gambling", " mutual information"], "paper_abstract": "A popular way to measure the degree of dependence between two random objects is by their mutual information, defined as the divergence between the joint and product-of-marginal distributions. We investigate an alternative measure of dependence: the lautum information defined as the divergence between the product-of-marginal and joint distributions, i.e., swapping the arguments in the definition of mutual information. Some operational characterizations and properties are provided for this alternative measure of information.", "paper_title": "Lautum information", "paper_id": "WOS:000253602200002"}