{"auto_keywords": [{"score": 0.04327832021381773, "phrase": "smpss_programming_model"}, {"score": 0.00481495049065317, "phrase": "message-passing_dense_matrix_factorizations"}, {"score": 0.004307569753106432, "phrase": "cholesky_factorization"}, {"score": 0.004207734323806386, "phrase": "multicore_processors"}, {"score": 0.003764102683676185, "phrase": "scalapack"}, {"score": 0.0036553070575015344, "phrase": "algorithmic_restrictions"}, {"score": 0.0032889671598112023, "phrase": "limited_programming_effort"}, {"score": 0.0032315723330399375, "phrase": "experimental_results"}, {"score": 0.0031938648476635225, "phrase": "considerable_gains"}, {"score": 0.002941913249957503, "phrase": "conventional_approaches"}, {"score": 0.0028736379396305596, "phrase": "original_scalapack_implementation"}, {"score": 0.0023124457559811087, "phrase": "dynamic_out-of-order_scheduling"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Task parallelism", " Message-passing numerical libraries", " Linear algebra", " Clusters of multi-core processors"], "paper_abstract": "In this paper, we investigate how to exploit task-parallelism during the execution of the Cholesky factorization on clusters of multicore processors with the SMPSs programming model. Our analysis reveals that the major difficulties in adapting the code for this operation in ScaLAPACK to SMPSs lie in algorithmic restrictions and the semantics of the SMPSs programming model, but also that they both can be overcome with a limited programming effort. The experimental results report considerable gains in performance and scalability of the routine parallelized with SMPSs when compared with conventional approaches to execute the original ScaLAPACK implementation in parallel as well as two recent message-passing routines for this operation. In summary, our study opens the door to the possibility of reusing message-passing legacy codes/libraries for linear algebra, by introducing up-to-date techniques like dynamic out-of-order scheduling that significantly upgrade their performance, while avoiding a costly rewrite/reimplementation. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Leveraging task-parallelism in message-passing dense matrix factorizations using SMPSs", "paper_id": "WOS:000338614300006"}