{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "entropy_functionals"}, {"score": 0.00471811808206897, "phrase": "renyi_information_divergence"}, {"score": 0.004561019117546361, "phrase": "maximum_entropy_problems"}, {"score": 0.0044692705329574, "phrase": "renyi_q-entropy"}, {"score": 0.004233492114255375, "phrase": "expected_values"}, {"score": 0.003956113993518042, "phrase": "standard_expectation"}, {"score": 0.003772793879444995, "phrase": "generalized_expectation"}, {"score": 0.003671865026158296, "phrase": "nonextensive_statistics"}, {"score": 0.0035979378467361762, "phrase": "optimum_maximum_entropy_probability_distributions"}, {"score": 0.0034545033623115634, "phrase": "power-law_behaviour"}, {"score": 0.003272083495778595, "phrase": "renyi_entropy"}, {"score": 0.0032061793819537633, "phrase": "optimum_distributions"}, {"score": 0.002799388549023265, "phrase": "possible_expected_values"}, {"score": 0.0027616550517346066, "phrase": "general_properties"}, {"score": 0.002427549902743566, "phrase": "numerical_aspects"}, {"score": 0.002252880693912436, "phrase": "specific_cases"}, {"score": 0.0022074592164608134, "phrase": "reference_measure"}, {"score": 0.0021049977753042253, "phrase": "limit_case"}], "paper_keywords": ["Renyi entropy", " Renyi divergences", " maximum entropy principle", " nonextensivity", " Tsallis distributions"], "paper_abstract": "We consider the maximum entropy problems associated with Renyi Q-entropy, subject to two kinds of constraints on expected values. The constraints considered are a constraint on the standard expectation, and a constraint on the generalized expectation as encountered in nonextensive statistics. The optimum maximum entropy probability distributions, which can exhibit a power-law behaviour, are derived and characterized. The Renyi entropy of the optimum distributions can be viewed as a function of the constraint. This defines two families of entropy functionals in the space of possible expected values. General properties of these functionals, including nonnegativity, minimum, convexity, are documented. Their relationships as well as numerical aspects are also discussed. Finally, we work out some specific cases for the reference measure Q(x) and recover in a limit case some well-known entropies. (C) 2008 Elsevier Inc. All rights reserved.", "paper_title": "On some entropy functionals derived from Renyi information divergence", "paper_id": "WOS:000256289100001"}