{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "image_inpainting"}, {"score": 0.004011366422179016, "phrase": "ordinary_observer"}, {"score": 0.0038600230206554792, "phrase": "numerous_and_very_different_approaches"}, {"score": 0.003714368305523811, "phrase": "inpainting_problem"}, {"score": 0.002864628676257225, "phrase": "neighboring_pixels"}, {"score": 0.0026523079380037706, "phrase": "variational_model"}, {"score": 0.002527654365712841, "phrase": "working_algorithm"}, {"score": 0.0021049977753042253, "phrase": "combination_of_all_three_terms"}], "paper_keywords": ["Image inpainting", " partial differential equations (PDEs)", " texture synthesis", " variational models"], "paper_abstract": "Inpainting is the art of modifying an image in a form that is not detectable by an ordinary observer. There are numerous and very different approaches to tackle the inpainting problem, though as explained in this paper, the most successful algorithms are based upon one or two of the following three basic techniques: copy-and-paste texture synthesis, geometric partial differential equations (PDEs), and coherence among neighboring pixels. We combine these three building blocks in a variational model, and provide a working algorithm for image inpainting trying to approximate the minimum of the proposed energy functional. Our experiments show that the combination of all three terms of the proposed energy works better than taking each term separately, and the results obtained are within the state-of-the-art.", "paper_title": "A Comprehensive Framework for Image Inpainting", "paper_id": "WOS:000283593800010"}