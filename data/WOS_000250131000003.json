{"auto_keywords": [{"score": 0.04567075142558643, "phrase": "proposed_system"}, {"score": 0.01089203958818959, "phrase": "audio_data"}, {"score": 0.00481495049065317, "phrase": "head-pose_estimation"}, {"score": 0.004766388573192505, "phrase": "user-view_image_synthesis"}, {"score": 0.004553822674247401, "phrase": "body-mounted_system"}, {"score": 0.004485085675709643, "phrase": "user_experience"}, {"score": 0.004011603024990615, "phrase": "head-detection_camera"}, {"score": 0.003971111060168551, "phrase": "user_head_motions"}, {"score": 0.0038913443732432468, "phrase": "wide_angle_color_camera"}, {"score": 0.0038520615699124123, "phrase": "user_frontal_view_images"}, {"score": 0.003793876828939456, "phrase": "image_region"}, {"score": 0.003717656912608012, "phrase": "user_view"}, {"score": 0.003606178185661875, "phrase": "wide_angle_image"}, {"score": 0.003551694229680741, "phrase": "estimated_human_head_motions"}, {"score": 0.00349803055484394, "phrase": "synthesized_image"}, {"score": 0.0033588449972778004, "phrase": "storage_device"}, {"score": 0.0031926001871260524, "phrase": "head-mounted_cameras"}, {"score": 0.0027000395818027366, "phrase": "user_field"}, {"score": 0.0024392031587145728, "phrase": "significant_information"}, {"score": 0.0024023079401125492, "phrase": "human_activities"}, {"score": 0.0023301793939902015, "phrase": "wider_application_domains"}, {"score": 0.002283298119790413, "phrase": "digital_diary"}, {"score": 0.002260211578368138, "phrase": "interaction_analysis"}, {"score": 0.002237357942660354, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["body-mounted camera", " head motion", " user-view image", " wearable system"], "paper_abstract": "In this paper, we propose a body-mounted system to capture user experience as audio/visual information. The proposed system consists of two cameras (head-detection and wide angle) and a microphone. The head-detection camera captures user head motions, while the wide angle color camera captures user frontal view images. An image region approximately corresponding to user view is then synthesized from the wide angle image based on estimated human head motions. The synthesized image and head-motion data are stored in a storage device with audio data. This system overcomes the disadvantages of head-mounted cameras in terms of ease of putting on/taking off the device. It also has less obtrusive visual impact on third persons. Using the proposed system, we can simultaneously record audio data, images in the user field of view, and head gestures (nodding, shaking, etc.) simultaneously. These data contain significant information for recording/analyzing human activities and can be used in wider application domains such as a digital diary or interaction analysis. Experimental results demonstrate the effectiveness of the proposed system. (C) 2006 Elsevier B.V. All rights reserved.", "paper_title": "A body-mounted camera system for head-pose estimation and user-view image synthesis", "paper_id": "WOS:000250131000003"}