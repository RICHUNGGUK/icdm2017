{"auto_keywords": [{"score": 0.04397860317645382, "phrase": "frame_coding_structure"}, {"score": 0.03779503638379083, "phrase": "depth_maps"}, {"score": 0.034764351703008914, "phrase": "imvs_system"}, {"score": 0.00481495049065317, "phrase": "multiview_video_with_free_viewpoint_synthesis"}, {"score": 0.004770627232703404, "phrase": "interactive_multiview_video"}, {"score": 0.004471530397729526, "phrase": "server_view"}, {"score": 0.004430354365175098, "phrase": "neighboring_views"}, {"score": 0.0041653307620376535, "phrase": "periodic_view"}, {"score": 0.004101579688745222, "phrase": "optimal_tradeoff"}, {"score": 0.004076352180903171, "phrase": "storage_cost"}, {"score": 0.00405127920820053, "phrase": "expected_transmission_rate"}, {"score": 0.003916098498242888, "phrase": "existing_imvs_systems"}, {"score": 0.0038561471948364723, "phrase": "corresponding_frame_structure_optimization"}, {"score": 0.0037971101834761017, "phrase": "depth-image-based_rendering"}, {"score": 0.003750530116775201, "phrase": "imvs"}, {"score": 0.0037159680715717056, "phrase": "free_viewpoint_switching"}, {"score": 0.003569831390151506, "phrase": "captured_views"}, {"score": 0.0034720284451902083, "phrase": "virtual_view"}, {"score": 0.0034400245101881936, "phrase": "almost_continuum"}, {"score": 0.0033457659530207306, "phrase": "right-most_captured_views"}, {"score": 0.003194354458513131, "phrase": "user_behaviors"}, {"score": 0.0031746892156724006, "phrase": "previous_memoryless_models"}, {"score": 0.0031164146336810717, "phrase": "view-switching_model"}, {"score": 0.0030686679245324837, "phrase": "client's_future_view-switching_patterns"}, {"score": 0.0029027394930867902, "phrase": "imvs_session"}, {"score": 0.0028494425496120228, "phrase": "redundant_frames"}, {"score": 0.0028231611341151368, "phrase": "future_playback"}, {"score": 0.0027884948773692153, "phrase": "zero-delay_view_switching"}, {"score": 0.002687022487756706, "phrase": "new_joint_optimization"}, {"score": 0.0026458370516131255, "phrase": "transmission_schedule"}, {"score": 0.0025574318906261247, "phrase": "multiple_camera_views"}, {"score": 0.002518227743688769, "phrase": "iterative_algorithm"}, {"score": 0.002494993595618653, "phrase": "fast_and_near-optimal_solutions"}, {"score": 0.0024116163689723333, "phrase": "experimental_results"}, {"score": 0.0023819914954155905, "phrase": "proposed_optimized_rate-allocation_method"}, {"score": 0.002323826502178581, "phrase": "fixed_rate-allocation_scheme"}, {"score": 0.0022531089868518235, "phrase": "transmission_rate"}, {"score": 0.0022323154532645187, "phrase": "optimized_frame_structure"}, {"score": 0.0021710766932077972, "phrase": "i-frame-only_structure"}, {"score": 0.0021049977753042253, "phrase": "distributed_source_coding_frames"}], "paper_keywords": ["Media interaction", " multiview video", " video streaming", " view synthesis"], "paper_abstract": "In interactive multiview video streaming (IMVS), a client receives and observes one of many available viewpoints of the same scene and periodically requests from the server view switches to neighboring views, as the video is played back in time uninterruptedly. One key technical challenge is to design a frame coding structure that facilitates periodic view switching and achieves an optimal tradeoff between storage cost and expected transmission rate. In this paper, we first propose three significant improvements over existing IMVS systems and then study the corresponding frame structure optimization. First, using depth-image-based rendering, the new IMVS system enables free viewpoint switching, i.e., by encoding and transmitting both texture and depth maps of captured views, a client can select and synthesize any virtual view from an almost continuum of viewpoints between the left-most and right-most captured views. Second, the IMVS system adopts a more realistic Markovian view-switching model with memory that more accurately captures user behaviors than previous memoryless models [1]. A view-switching model is used in predicting client's future view-switching patterns. Third, assuming that the round-trip-time (RTT) delay during server-client communication is nonnegligible, during an IMVS session, the IMVS system additionally transmits redundant frames RTT into future playback, so that zero-delay view switching can be achieved. Given these improvements, we formalize a new joint optimization of the frame coding structure, transmission schedule, and quantization parameters of the texture and depth maps of multiple camera views. We propose an iterative algorithm to achieve fast and near-optimal solutions. The convergence of the algorithm is also demonstrated. Experimental results show that the proposed optimized rate-allocation method requires 38% lower transmission rate than the fixed rate-allocation scheme. In addition, with the same storage, the transmission rate of the optimized frame structure can be up to 55% lower than that of an I-frame-only structure and 27% lower than that of the structure without distributed source coding frames.", "paper_title": "Delay-Cognizant Interactive Streaming of Multiview Video With Free Viewpoint Synthesis", "paper_id": "WOS:000306599400001"}