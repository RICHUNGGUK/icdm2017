{"auto_keywords": [{"score": 0.04806645810598007, "phrase": "cloud_platform"}, {"score": 0.015719716506582538, "phrase": "multi-dimensional_correlated_files"}, {"score": 0.01293696589560445, "phrase": "fault_tolerance"}, {"score": 0.004695900553353526, "phrase": "effective_management"}, {"score": 0.004662427600500598, "phrase": "enormous_data_volumes"}, {"score": 0.0045471315699087385, "phrase": "research_efforts"}, {"score": 0.004324985524216987, "phrase": "multidimensional_correlations"}, {"score": 0.0038846843242954935, "phrase": "inter-file_correlations"}, {"score": 0.0036292245355184576, "phrase": "data_files"}, {"score": 0.0035393874762182486, "phrase": "real_practices"}, {"score": 0.0035015674744573377, "phrase": "correlated_files"}, {"score": 0.003306559295382181, "phrase": "new_challenge"}, {"score": 0.003247868216333148, "phrase": "multi-dimensional_correlations"}, {"score": 0.003213153188898728, "phrase": "\"subspace_locality"}, {"score": 0.002896071795090179, "phrase": "mapreduce_processing_paradigm"}, {"score": 0.0027841357057119317, "phrase": "underlying_file_systems"}, {"score": 0.002610198789888055, "phrase": "desired_data"}, {"score": 0.0025182951088683863, "phrase": "system_throughput"}, {"score": 0.0025003054002226965, "phrase": "batch_jobs"}, {"score": 0.002482443883144136, "phrase": "correlated_data_files"}, {"score": 0.002360933403998823, "phrase": "hdfs"}, {"score": 0.0023024126375034066, "phrase": "real_application_scenarios"}, {"score": 0.0021975548867457623, "phrase": "data_retrieval"}, {"score": 0.0021507795710951384, "phrase": "batch_olap_jobs"}, {"score": 0.0021201492891323587, "phrase": "well_balanced_workload"}, {"score": 0.0021049977753042253, "phrase": "distributed_computing_nodes"}], "paper_keywords": ["Distributed data allocation", " Cloud storage", " Multi-dimensional correlation", " Subspace locality"], "paper_abstract": "The effective management of enormous data volumes on the Cloud platform has attracted devoting research efforts. In this paper, we study the problem of allocating files with multidimensional correlations on the Cloud platform, such that files can be retrieved and processed more efficiently. Currently, most prevailing Cloud file systems allocate data following the principles of fault tolerance and availability, while inter-file correlations, i.e. files correlated with each other, are often neglected. As a matter of fact, data files are commonly correlated in various ways in real practices. And correlated files are most likely to be involved in the same computation process. Therefore, it raises a new challenge of allocating files with multi-dimensional correlations with the \"subspace locality\" taken into consideration to improve the system throughput. We propose two allocation methods for multi-dimensional correlated files stored on the Cloud platform, such that the I/O efficiency and data access locality are improved in the MapReduce processing paradigm, without hurting the fault tolerance and availability properties of the underlying file systems. Different from the techniques proposed in [1,2], which quickly map the locations of desired data for a given query Q, we focus on improving the system throughput for batch jobs over correlated data files. We clearly formulate the problem and study a series of solutions on HDFS [9]. Evaluations with real application scenarios prove the effectiveness of our proposals: significant I/O and network costs can be saved during the data retrieval and processing. Especially for batch OLAP jobs, our solution demonstrates well balanced workload among distributed computing nodes.", "paper_title": "Locality-aware allocation of multi-dimensional correlated files on the cloud platform", "paper_id": "WOS:000360554400003"}