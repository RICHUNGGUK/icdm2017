{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "interest_points"}, {"score": 0.01682828834496811, "phrase": "proposed_tracker"}, {"score": 0.0077611026145628734, "phrase": "art_trackers"}, {"score": 0.007587570031775923, "phrase": "target_dictionary"}, {"score": 0.00470697922443172, "phrase": "visual_tracking"}, {"score": 0.004661446705304497, "phrase": "important_task"}, {"score": 0.004556901872357751, "phrase": "human_computer_interaction"}, {"score": 0.004527462929045081, "phrase": "event_detection"}, {"score": 0.004498213310668266, "phrase": "video_indexing"}, {"score": 0.004440277230269978, "phrase": "recent_state"}, {"score": 0.004397313229350093, "phrase": "art_sparse_representation"}, {"score": 0.004369125487893476, "phrase": "sr"}, {"score": 0.004340671055146398, "phrase": "based_trackers"}, {"score": 0.004312622975366676, "phrase": "better_robustness"}, {"score": 0.004134658048970194, "phrase": "sr_trackers"}, {"score": 0.004107935669507044, "phrase": "low_execution_speed"}, {"score": 0.004068174255942041, "phrase": "particle_filter_framework"}, {"score": 0.0040027552011993005, "phrase": "major_aspects"}, {"score": 0.003964007795174772, "phrase": "slow_execution"}, {"score": 0.0038499929374478125, "phrase": "existing_sr_trackers"}, {"score": 0.0037392451233558234, "phrase": "robust_interest_point"}, {"score": 0.0036671822784770463, "phrase": "minimization_framework"}, {"score": 0.00325238798404366, "phrase": "candidate_window"}, {"score": 0.0032208807810825933, "phrase": "current_frame"}, {"score": 0.0031485421129798996, "phrase": "target_and_candidate_points"}, {"score": 0.0030086877092638945, "phrase": "noisy_matches"}, {"score": 0.0029795342727066696, "phrase": "robust_matching_criterion"}, {"score": 0.0028843751686557736, "phrase": "target_and_candidate_dictionary_elements"}, {"score": 0.002711842889248926, "phrase": "reliable_candidate_patches"}, {"score": 0.0024442137370930296, "phrase": "reported_state"}, {"score": 0.002312925203110055, "phrase": "regularization_parameters"}, {"score": 0.0022390081666133627, "phrase": "illumination_change"}, {"score": 0.0022029383047842627, "phrase": "background_clutter"}, {"score": 0.002160419006055386, "phrase": "benchmark_dataset"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual tracking", " l(1) minimization", " Interest points", " Harris corner", " Sparse representation"], "paper_abstract": "Visual tracking is an important task in various computer vision applications including visual surveillance, human computer interaction, event detection, video indexing and retrieval. Recent state of the art sparse representation (SR) based trackers show better robustness than many of the other existing trackers. One of the issues with these SR trackers is low execution speed. The particle filter framework is one of the major aspects responsible for slow execution, and is common to most of the existing SR trackers. In this paper,(1) we propose a robust interest point based tracker in l(1) minimization framework that runs at real-time with performance comparable to the state of the art trackers. In the proposed tracker, the target dictionary is obtained from the patches around target interest points. Next, the interest points from the candidate window of the current frame are obtained. The correspondence between target and candidate points is obtained via solving the proposed l(1) minimization problem. In order to prune the noisy matches, a robust matching criterion is proposed, where only the reliable candidate points that mutually match with target and candidate dictionary elements are considered for tracking. The object is localized by measuring the displacement of these interest points. The reliable candidate patches are used for updating the target dictionary. The performance and accuracy of the proposed tracker is benchmarked with several complex video sequences. The tracker is found to be considerably fast as compared to the reported state of the art trackers. The proposed tracker is further evaluated for various local patch sizes, number of interest points and regularization parameters. The performance of the tracker for various challenges including illumination change, occlusion, and background clutter has been quantified with a benchmark dataset containing 50 videos. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Robust tracking with interest points: A sparse representation approach", "paper_id": "WOS:000348261100004"}