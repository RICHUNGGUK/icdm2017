{"auto_keywords": [{"score": 0.03843856552198327, "phrase": "sda"}, {"score": 0.00481495049065317, "phrase": "linear_discriminant_analysis"}, {"score": 0.0044277810648955624, "phrase": "multivariate_normal"}, {"score": 0.004220624516321415, "phrase": "equal_covariance_matrix"}, {"score": 0.004120694410890683, "phrase": "different_means"}, {"score": 0.003975200317233532, "phrase": "single-cluster_structure"}, {"score": 0.00374399358035391, "phrase": "subclass_discriminant_analysis"}, {"score": 0.0030171910207671205, "phrase": "ksda."}, {"score": 0.002644179117033107, "phrase": "complicated_derivation"}, {"score": 0.00255068452076921, "phrase": "feature_space"}, {"score": 0.0024604876113911173, "phrase": "encouraging_experimental_results"}, {"score": 0.00240213106042981, "phrase": "eight_uci_data_sets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["linear discriminant analysis (LDA)", " kernel linear discriminant analysis (KLDA)", " subclass discriminant analysis (SDA)", " feature space", " kernel methods"], "paper_abstract": "In order to overcome the restricts of linear discriminant analysis (LDA), such as multivariate Normal distributed classes with equal covariance matrix but different means and the single-cluster structure in each class, subclass discriminant analysis (SDA) is proposed recently. In this paper the kernel SDA is presented, called KSDA. Moreover, we reformulate SDA so as to avoid the complicated derivation in the feature space. The encouraging experimental results on eight UCI data sets demonstrate the efficiency of our method. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Kernel subclass discriminant analysis", "paper_id": "WOS:000251500600044"}