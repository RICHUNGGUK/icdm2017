{"auto_keywords": [{"score": 0.05006851447987355, "phrase": "ldpc_codes"}, {"score": 0.038998282427906275, "phrase": "dc"}, {"score": 0.004481132747216135, "phrase": "belief_propagation"}, {"score": 0.0041891398413899435, "phrase": "wide_variety"}, {"score": 0.00415166680936294, "phrase": "constraint_satisfaction"}, {"score": 0.004059438255358923, "phrase": "inference_problems"}, {"score": 0.0038636556112977226, "phrase": "message-passing_algorithm"}, {"score": 0.0038119123317396954, "phrase": "\"normal\"_factor_graph"}, {"score": 0.0037608593980593035, "phrase": "\"difference-map\"_dynamics"}, {"score": 0.0034841647157189985, "phrase": "\"trapping_sets"}, {"score": 0.003376216135716632, "phrase": "bp_decoders"}, {"score": 0.0033459905006404207, "phrase": "low-density_parity_check"}, {"score": 0.0032423089921154503, "phrase": "error-floor_regime"}, {"score": 0.003058179790439378, "phrase": "first_decoder"}, {"score": 0.002936849401568391, "phrase": "second_decoder"}, {"score": 0.002897482096228207, "phrase": "important_\"difference-map\"_concept"}, {"score": 0.00277001889871322, "phrase": "bp-like_decoder"}, {"score": 0.00257760787870709, "phrase": "standard_bp_decoders"}, {"score": 0.0025202582748972122, "phrase": "similar_computational_complexity"}, {"score": 0.00247529638625566, "phrase": "simulation_results"}, {"score": 0.0024311346712789553, "phrase": "dc_and_dmbp_decoders"}, {"score": 0.002366361492754389, "phrase": "sum-product_bp"}, {"score": 0.0023033100935570755, "phrase": "mixed-integer_linear_programming"}, {"score": 0.0022419349154472806, "phrase": "close_relation"}, {"score": 0.0022118619998034742, "phrase": "dmbp_decoder"}, {"score": 0.0021920373388760314, "phrase": "reweighted_min-sum_algorithms"}, {"score": 0.002124036931047162, "phrase": "ruozzi"}, {"score": 0.00210499793203794, "phrase": "tatikonda"}], "paper_keywords": ["Belief propagation (BP)", " error floors", " graphical models", " iterative algorithms", " low-density parity check (LDPC) decoding", " projection algorithms", " reweighted max-product", " reweighted min-sum"], "paper_abstract": "The \"Divide and Concur\" (DC) algorithm introduced by Gravel and Elser can be considered a competitor to the belief propagation (BP) algorithm, in that both algorithms can be applied to a wide variety of constraint satisfaction, optimization, and inference problems. We show that DC can be interpreted as a message-passing algorithm on a \"normal\" factor graph. The \"difference-map\" dynamics of the DC algorithm enables it to avoid \"traps\" which may be related to the \"trapping sets\" or \"pseudo-codewords\" that plague BP decoders of low-density parity check (LDPC) codes in the error-floor regime. We investigate two decoders for LDPC codes based on these ideas. The first decoder is based directly on DC, while the second decoder borrows the important \"difference-map\" concept from the DC algorithm and translates it into a BP-like decoder. We show that this \"difference-map belief propagation\" (DMBP) decoder has dramatically improved error-floor performance compared to standard BP decoders, while maintaining a similar computational complexity. We present simulation results for LDPC codes comparing DC and DMBP decoders with other decoders based on sum-product BP, linear programming, and mixed-integer linear programming. We also describe the close relation of the DMBP decoder to reweighted min-sum algorithms, including those recently proposed by Ruozzi and Tatikonda.", "paper_title": "Divide and Concur and Difference-Map BP Decoders for LDPC Codes", "paper_id": "WOS:000286514200015"}