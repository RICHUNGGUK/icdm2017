{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "i-o_bottleneck"}, {"score": 0.004508048086020253, "phrase": "multiple_memory_models"}, {"score": 0.004271490815763164, "phrase": "memory_hierarchy"}, {"score": 0.0041703614123283165, "phrase": "i-o_model"}, {"score": 0.004120704822497578, "phrase": "aggarwal"}, {"score": 0.004071617711469736, "phrase": "vitter"}, {"score": 0.0040232373563629485, "phrase": "commun"}, {"score": 0.0039752546794224, "phrase": "acm"}, {"score": 0.0036553070575015344, "phrase": "architectural_advancements"}, {"score": 0.0035687137873965684, "phrase": "new_features"}, {"score": 0.0034220655476652683, "phrase": "i-o_model-most_notably_the_prefetching_capability"}, {"score": 0.0032814241292672013, "phrase": "prefetch"}, {"score": 0.0031277316566463978, "phrase": "traditional_i-o_models"}, {"score": 0.0030171910207671205, "phrase": "optimal_algorithms"}, {"score": 0.002741091312632307, "phrase": "memory_latency"}, {"score": 0.002692200353719145, "phrase": "memory_bandwidth"}, {"score": 0.002597012212823168, "phrase": "processing_speed"}, {"score": 0.0025354258731826148, "phrase": "intelligent_use"}, {"score": 0.002373472641477602, "phrase": "fundamental_problems"}, {"score": 0.0023171750718791713, "phrase": "running_times"}, {"score": 0.0022486729928886885, "phrase": "idealized_random_access_machines"}, {"score": 0.0021049977753042253, "phrase": "i-o_efficient_algorithms"}], "paper_keywords": ["external memory algorithms", " prefetching", " memory hierarchy", " sorting", " prediction sequence"], "paper_abstract": "Multiple memory models have been proposed to capture the effects of memory hierarchy culminating in the I-O model of Aggarwal and Vitter (Commun. ACM 31(9):1116-1127, [1988]). More than a decade of architectural advancements have led to new features that are not captured in the I-O model-most notably the prefetching capability. We propose a relatively simple Prefetch model that incorporates data prefetching in the traditional I-O models and show how to design optimal algorithms that can attain close to peak memory bandwidth. Unlike (the inverse of) memory latency, the memory bandwidth is much closer to the processing speed, thereby, intelligent use of prefetching can considerably mitigate the I-O bottleneck. For some fundamental problems, our algorithms attain running times approaching that of the idealized random access machines under reasonable assumptions. Our work also explains more precisely the significantly superior performance of the I-O efficient algorithms in systems that support prefetching compared to ones that do not.", "paper_title": "Combating I-O bottleneck using prefetching: model, algorithms, and ramifications", "paper_id": "WOS:000256914700004"}