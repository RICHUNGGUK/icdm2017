{"auto_keywords": [{"score": 0.04766724089045989, "phrase": "feature_regularization"}, {"score": 0.015719716506582538, "phrase": "feature_selection"}, {"score": 0.007932913265338005, "phrase": "omp-td"}, {"score": 0.004732785510739708, "phrase": "reinforcement_learning"}, {"score": 0.004417848254181138, "phrase": "value_function_approximation"}, {"score": 0.004123781267600542, "phrase": "selection_process"}, {"score": 0.0040186038781533946, "phrase": "function_approximation_accuracy"}, {"score": 0.003531474887552889, "phrase": "incremental_feature_selection"}, {"score": 0.003441352119167824, "phrase": "present_closed-form_smoothness"}, {"score": 0.003324743991757282, "phrase": "fourier_and_rbf_bases"}, {"score": 0.0030501665085457606, "phrase": "temporal_difference"}, {"score": 0.0030239842475439814, "phrase": "orthogonal_matching_pursuit"}, {"score": 0.0026342827320931937, "phrase": "smooth_tikhonov_omp-td"}, {"score": 0.002544951823639408, "phrase": "omp-td."}, {"score": 0.0022750059370204878, "phrase": "td"}, {"score": 0.002236055625099805, "phrase": "random_projections"}, {"score": 0.0021789194955896102, "phrase": "six_benchmark_domains"}, {"score": 0.0021049977753042253, "phrase": "basis_functions"}], "paper_keywords": ["Feature selection", " Reinforcement learning", " Function approximation", " Regularization", " Linear function approximation", " OMP-TD"], "paper_abstract": "We introduce feature regularization during feature selection for value function approximation. Feature regularization introduces a prior into the selection process, improving function approximation accuracy and reducing overfitting. We show that the smoothness prior is effective in the incremental feature selection setting and present closed-form smoothness regularizers for the Fourier and RBF bases. We present two methods for feature regularization which extend the temporal difference orthogonal matching pursuit (OMP-TD) algorithm and demonstrate the effectiveness of the smoothness prior; smooth Tikhonov OMP-TD and smoothness scaled OMP-TD. We compare these methods against OMP-TD, regularized OMP-TD and least squares TD with random projections, across six benchmark domains using two different types of basis functions.", "paper_title": "Regularized feature selection in reinforcement learning", "paper_id": "WOS:000359747100020"}