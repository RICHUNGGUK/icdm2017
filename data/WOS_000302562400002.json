{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "coefficient_regularized_regression_algorithm"}, {"score": 0.004157058883925715, "phrase": "excess_error"}, {"score": 0.0039341294012600085, "phrase": "proposed_algorithm"}, {"score": 0.0036553070575015344, "phrase": "reproducing_kernel_hilbert_space"}, {"score": 0.0033961782274326948, "phrase": "theoretical_analysis"}, {"score": 0.0027741761880779535, "phrase": "projected_domain"}, {"score": 0.0024842242921857705, "phrase": "preprocessing_step"}, {"score": 0.0023944552329463035, "phrase": "supervised_learning"}, {"score": 0.002224510044064184, "phrase": "empirical_risk_minimization"}, {"score": 0.0021049977753042253, "phrase": "projected_data"}], "paper_keywords": ["Regularized least square regression", " random projection", " reproducing kernel Hilbert spaces", " learning rate, coefficient regularization"], "paper_abstract": "In this paper, the coefficient regularized regression algorithm with random projection is proposed. The excess error of the proposed algorithm associated with the reproducing kernel Hilbert space is bounded. Theoretical analysis shows that it is possible to learn directly in the projected domain and that random projection, as a preprocessing step in supervised learning, leads to empirical risk minimization on the projected data computationally simple.", "paper_title": "THE COEFFICIENT REGULARIZED REGRESSION WITH RANDOM PROJECTION", "paper_id": "WOS:000302562400002"}