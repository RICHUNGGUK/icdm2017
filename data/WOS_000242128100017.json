{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "knowledge_sharing"}, {"score": 0.004743164872278112, "phrase": "autonomous_intelligent_systems"}, {"score": 0.004366970206156021, "phrase": "operator_definitions"}, {"score": 0.004174451361776433, "phrase": "completely_unknown_environment"}, {"score": 0.003990385737207714, "phrase": "better_learning_convergence"}, {"score": 0.003673675864705682, "phrase": "learned_set"}, {"score": 0.0036188435232325337, "phrase": "planning_operators"}, {"score": 0.0029984960344766705, "phrase": "new_evidence"}, {"score": 0.002953711377604328, "phrase": "prior_evidence"}, {"score": 0.0027811441123794427, "phrase": "rote_learning"}, {"score": 0.0026186324161493225, "phrase": "reinforcement_learning"}, {"score": 0.0024287485834314027, "phrase": "individual_learning"}, {"score": 0.002252602622785975, "phrase": "successful_plans"}, {"score": 0.0021049977753042253, "phrase": "individual_agents"}], "paper_keywords": [""], "paper_abstract": "Very few learning systems applied to problem solving have focused on learning operator definitions from the interaction with a completely unknown environment. In order to achieve better learning convergence, several agents that learn separately are allowed to interchange each learned set of planning operators. Learning is achieved by establishing plans, executing those plans in the environment, analyzing the results of the execution, and combining new evidence with prior evidence. Operators are generated incrementally by combining rote learning, induction, and a variant of reinforcement learning. The results show how allowing the communication among individual learning (and planning) agents provides a much better percentage of successful plans, plus an improved convergence rate than the individual agents alone.", "paper_title": "Learning by knowledge sharing in autonomous intelligent systems", "paper_id": "WOS:000242128100017"}