{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "classification_data"}, {"score": 0.0495648351427175, "phrase": "rough_set_theory"}, {"score": 0.03823852777286605, "phrase": "rough_sets"}, {"score": 0.033550893132319834, "phrase": "conditional_entropy"}, {"score": 0.004712065638657606, "phrase": "identity_disclosure"}, {"score": 0.004464326432401002, "phrase": "well-known_privacy_model"}, {"score": 0.004252469672259375, "phrase": "main_goal"}, {"score": 0.004094639048362357, "phrase": "individual_privacy"}, {"score": 0.003879234831701853, "phrase": "classification_models"}, {"score": 0.00355782527287734, "phrase": "data_quality"}, {"score": 0.0034442607586033657, "phrase": "anonymization_operations"}, {"score": 0.0032806521851034766, "phrase": "attribute_reduction_theory"}, {"score": 0.003107935254560724, "phrase": "classification_data_quality"}, {"score": 0.003074495313651187, "phrase": "anonymized_datasets"}, {"score": 0.002944284514509205, "phrase": "single-level_granulation"}, {"score": 0.0029126002350975634, "phrase": "hierarchical_conditional_entropy"}, {"score": 0.002881255933884771, "phrase": "multi-level_granulation"}, {"score": 0.0027295084882654917, "phrase": "attribute_values"}, {"score": 0.0025857324180891526, "phrase": "efficient_search_metric_and_present_a_novel_algorithm"}, {"score": 0.00235843888868088, "phrase": "attribute_value_taxonomies"}, {"score": 0.002333044307949414, "phrase": "theoretical_analysis"}, {"score": 0.0022830706430588482, "phrase": "real_world"}, {"score": 0.0021745003291048356, "phrase": "data_utility"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["k-Anonymity", " Rough sets", " Multi-level granulation", " Attribute value taxonomy", " Privacy preserving data mining"], "paper_abstract": "Identity disclosure is one of the most serious privacy concerns in many data mining applications. A well-known privacy model for protecting identity disclosure is k-anonymity. The main goal of anonymizing classification data is to protect individual privacy while maintaining the utility of the data in building classification models. In this paper, we present an approach based on rough sets for measuring the data quality and guiding the process of anonymization operations. First, we make use of the attribute reduction theory of rough sets and introduce the conditional entropy to measure the classification data quality of anonymized datasets. Then, we extend conditional entropy under single-level granulation to hierarchical conditional entropy under multi-level granulation, and study its properties by dynamically coarsening and refining attribute values. Guided by these properties, we develop an efficient search metric and present a novel algorithm for achieving k-anonymity, Hierarchical Conditional Entropy-based Top-Down Refinement (HCE-TDR), which combines rough set theory and attribute value taxonomies. Theoretical analysis and experiments on real world datasets show that our algorithm is efficient and improves data utility. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Anonymizing classification data using rough set theory", "paper_id": "WOS:000317163100008"}