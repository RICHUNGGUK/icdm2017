{"auto_keywords": [{"score": 0.04747975082880788, "phrase": "rminimax"}, {"score": 0.00481495049065317, "phrase": "simple_extension"}, {"score": 0.004742290714667451, "phrase": "celebrated_minimax_algorithm"}, {"score": 0.004670722261414736, "phrase": "zero-sum_two-player_games"}, {"score": 0.004600228893803583, "phrase": "rminimax."}, {"score": 0.00437281181878921, "phrase": "artificial_rival"}, {"score": 0.004241771072194993, "phrase": "optimal_way"}, {"score": 0.004114641015648682, "phrase": "randomized_shortest-path_framework"}, {"score": 0.003991305899593133, "phrase": "artificial_intelligence"}, {"score": 0.003871653343842317, "phrase": "worse_or_better_solutions"}, {"score": 0.003551694229680741, "phrase": "minimax_algorithm"}, {"score": 0.003410380718649286, "phrase": "possible_strategies"}, {"score": 0.003341839487905525, "phrase": "optimal_tradeoff"}, {"score": 0.0032251796659158696, "phrase": "entropy_spread"}, {"score": 0.0030500051941781034, "phrase": "expected_cost"}, {"score": 0.0030038988468808845, "phrase": "end_game"}, {"score": 0.002943502888225748, "phrase": "game_tree"}, {"score": 0.0027835848648596513, "phrase": "complete_paths"}, {"score": 0.002592523232809191, "phrase": "optimal_randomized_strategy"}, {"score": 0.00248927752933113, "phrase": "simple_recurrence_relation"}, {"score": 0.0024023079401125492, "phrase": "original_minimax."}, {"score": 0.002294929467537814, "phrase": "nondeterministic_strength-adapted_ai_opponent"}, {"score": 0.002226017732566121, "phrase": "principled_way"}, {"score": 0.002148226022654619, "phrase": "complete_rationality"}], "paper_keywords": ["MINIMAX", " randomized shortest paths (RSPs)", " two-player zero-sum perfect-information games"], "paper_abstract": "This paper proposes a simple extension of the celebrated MINIMAX algorithm used in zero-sum two-player games, called Rminimax. The Rminimax algorithm allows controlling the strength of an artificial rival by randomizing its strategy in an optimal way. In particular, the randomized shortest-path framework is applied for biasing the artificial intelligence (AI) adversary toward worse or better solutions, therefore controlling its strength. In other words, our model aims at introducing/implementing bounded rationality to the MINIMAX algorithm. This framework takes into account all possible strategies by computing an optimal tradeoff between exploration (quantified by the entropy spread in the tree) and exploitation (quantified by the expected cost to an end game) of the game tree. As opposed to other tree-exploration techniques, this new algorithm considers complete paths of a tree (strategies) where a given entropy is spread. The optimal randomized strategy is efficiently computed by means of a simple recurrence relation while keeping the same complexity as the original MINIMAX. As a result, the Rminimax implements a nondeterministic strength-adapted AI opponent for board games in a principled way, thus avoiding the assumption of complete rationality. Simulations on two common games show that Rminimax behaves as expected.", "paper_title": "Rminimax: An Optimally Randomized MINIMAX Algorithm", "paper_id": "WOS:000317643500031"}