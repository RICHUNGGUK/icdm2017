{"auto_keywords": [{"score": 0.03575585700361017, "phrase": "ekmse"}, {"score": 0.013003995320530546, "phrase": "training_samples"}, {"score": 0.00820663314239203, "phrase": "feature_extractor"}, {"score": 0.008073477706906853, "phrase": "linear_combination"}, {"score": 0.00481495049065317, "phrase": "error_model"}, {"score": 0.004762550320451225, "phrase": "fast_feature_extraction"}, {"score": 0.004685012337701536, "phrase": "kernel_minimum_squared_error"}, {"score": 0.004339459955098738, "phrase": "high-dimensional_kernel_space"}, {"score": 0.004108288481894523, "phrase": "kmse"}, {"score": 0.0039024546443934436, "phrase": "ekmse_model"}, {"score": 0.003868142906199082, "phrase": "computational_efficiency"}, {"score": 0.00380511089035825, "phrase": "kmse-based_feature_extraction_procedure"}, {"score": 0.003622088701900472, "phrase": "training_sample"}, {"score": 0.003429001377800255, "phrase": "efficient_kernel_minimum_squared_error"}, {"score": 0.003318108914777263, "phrase": "two-class_classification"}, {"score": 0.003264010423431402, "phrase": "proposed_ekmse"}, {"score": 0.0030395624703152212, "phrase": "small_portion"}, {"score": 0.0024276590297034064, "phrase": "feature_extraction"}, {"score": 0.00221153232497724, "phrase": "overfitting_problem"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": ["Machine learning", " Kernel minimum squared error", " Efficient kernel minimum squared error", " Feature extraction"], "paper_abstract": "The kernel minimum squared error (KMSE) expresses the feature extractor as a linear combination of all the training samples in the high-dimensional kernel space. To extract a feature from a sample, KMSE should calculate as many kernel functions as the training samples. Thus, the computational efficiency of the KMSE-based feature extraction procedure is inversely proportional to the size of the training sample set. In this paper, we propose an efficient kernel minimum squared error (EKMSE) model for two-class classification. The proposed EKMSE expresses each feature extractor as a linear combination of nodes, which are a small portion of the training samples. To extract a feature from a sample, EKMSE only needs to calculate as many kernel functions as the nodes. As the nodes are commonly much fewer than the training samples, EKMSE is much faster than KMSE in feature extraction. The EKMSE can achieve the same training accuracy as the standard KMSE. Also, EKMSE avoids the overfitting problem. We implement the EKMSE model using two algorithms. Experimental results show the feasibility of the EKMSE model.", "paper_title": "Improvement of the kernel minimum squared error model for fast feature extraction", "paper_id": "WOS:000320865100006"}