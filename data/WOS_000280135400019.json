{"auto_keywords": [{"score": 0.046273829908275756, "phrase": "virtual_characters"}, {"score": 0.04483027936171083, "phrase": "live_video"}, {"score": 0.0374287769677244, "phrase": "lighting_parameters"}, {"score": 0.00481495049065317, "phrase": "outdoor_illumination"}, {"score": 0.00471003041684707, "phrase": "statistical_analysis"}, {"score": 0.004658426838467567, "phrase": "augmented_reality"}, {"score": 0.0046073860169839305, "phrase": "illumination_consistency"}, {"score": 0.0045318666714939905, "phrase": "important_role"}, {"score": 0.004482206282876944, "phrase": "realistic_rendering"}, {"score": 0.004241914481080374, "phrase": "real_scene"}, {"score": 0.004103942174451674, "phrase": "novel_method"}, {"score": 0.004014452814186653, "phrase": "illumination_conditions"}, {"score": 0.003970439654470374, "phrase": "outdoor_videos"}, {"score": 0.0038838500580958744, "phrase": "fixed_viewpoint"}, {"score": 0.003757480190200645, "phrase": "analytical_model"}, {"score": 0.0034212450542713607, "phrase": "basic_illumination_model"}, {"score": 0.0031669873302916, "phrase": "lighting_conditions"}, {"score": 0.003132236287543072, "phrase": "live_videos"}, {"score": 0.002947790697936243, "phrase": "dynamic_objects"}, {"score": 0.0028993944292191433, "phrase": "intrusive_pedestrians"}, {"score": 0.002539689093411356, "phrase": "geometric_information"}, {"score": 0.0024299678474208023, "phrase": "real-time_performance"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["augmented reality", " illumination estimation", " image statistics", " outdoor scenes"], "paper_abstract": "Illumination consistency plays an important role in realistic rendering of virtual characters which are integrated into a live video of real scene. This paper proposes a novel method for estimating the illumination conditions of outdoor videos captured by a fixed viewpoint. We first derive an analytical model which relates the statistics of an image to the lighting parameters of the scene adhering to the basic illumination model. Exploiting this model, we then develop a framework to estimate the lighting conditions of live videos. In order to apply the above approach to scenes containing dynamic objects such as intrusive pedestrians and swaying trees, we enforce two constraints, namely spatial and temporal illumination coherence, to refine the solution. Our approach requires no geometric information of the scenes and is sufficient for real-time performance. Experiments show that with the lighting parameters recovered by our method, virtual characters can be seamlessly integrated into the live video. Copyright (C) 2010 John Wiley & Sons, Ltd.", "paper_title": "A new approach to outdoor illumination estimation based on statistical analysis for augmented reality", "paper_id": "WOS:000280135400019"}