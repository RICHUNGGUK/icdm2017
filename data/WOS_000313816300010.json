{"auto_keywords": [{"score": 0.04002553300900061, "phrase": "flowchecker"}, {"score": 0.007740489563401459, "phrase": "mpi_libraries"}, {"score": 0.0047804843375940835, "phrase": "message_flow_checking"}, {"score": 0.004661775069083667, "phrase": "message_passing_interface"}, {"score": 0.004513450434595191, "phrase": "software_bugs"}, {"score": 0.004354149483556514, "phrase": "large_number"}, {"score": 0.004276610897002087, "phrase": "program_failures"}, {"score": 0.004155399041702324, "phrase": "mpi_application_developers"}, {"score": 0.004086511476675031, "phrase": "open_mpi"}, {"score": 0.003923144245133288, "phrase": "daunting_problem"}, {"score": 0.003839422251550131, "phrase": "new_method"}, {"score": 0.003757480190200645, "phrase": "communication_related_bugs"}, {"score": 0.0036509280916606937, "phrase": "program_intentions"}, {"score": 0.003253994336864267, "phrase": "underlying_mpi_libraries"}, {"score": 0.0028279422436488116, "phrase": "diagnostic_information"}, {"score": 0.002797572252783356, "phrase": "mpi_library_developers"}, {"score": 0.0026889720516076205, "phrase": "flowchecker_prototype"}, {"score": 0.0026696952330308066, "phrase": "linux"}, {"score": 0.0026220625042810706, "phrase": "five_real-world_and_two_injected_bug_cases"}, {"score": 0.002575306883741445, "phrase": "mpi"}, {"score": 0.0024136908511423875, "phrase": "seven_evaluated_bug_cases"}, {"score": 0.002362105010110277, "phrase": "useful_diagnostic_information"}, {"score": 0.0023033100935570755, "phrase": "root_causes"}, {"score": 0.0022298571016688335, "phrase": "high_performance_linpack"}, {"score": 0.0022138542785562444, "phrase": "nas_parallel_benchmarks"}, {"score": 0.002174346780014853, "phrase": "low_runtime_overhead"}], "paper_keywords": ["Software reliability", " bug detection", " message passing interfaces"], "paper_abstract": "Despite the success of the Message Passing Interface (MPI), many MPI libraries have suffered from software bugs. These bugs severely impact the productivity of a large number of users, causing program failures or other errors. As a result, MPI application developers often have to spend days or weeks in vain debugging their own code. To address this daunting problem, this paper presents a new method called FlowChecker, which detects communication related bugs in MPI libraries. First, FlowChecker extracts program intentions of message passing (MP-intentions), which specify messages to be delivered from the sources to the destinations. Then FlowChecker tracks the message flows that actually occur in the underlying MPI libraries. Finally, FlowChecker checks whether the messages are correctly delivered from the sources to the destinations by comparing the message flows against the MP-intentions. If a mismatch is found, FlowChecker reports a bug and provides diagnostic information to help MPI library developers to understand and fix it. We have built a FlowChecker prototype on Linux and evaluated it with five real-world and two injected bug cases in three widely used MPI libraries, including Open MPI, MPICH2, and MVAPICH2. Our experimental results show that FlowChecker effectively detects all seven evaluated bug cases. Additionally, it provides useful diagnostic information for narrowing down or even pinpointing root causes of the bugs. Moreover, our experiments with High Performance Linpack and NAS Parallel Benchmarks show that FlowChecker induces low runtime overhead (0.9-5.6 percent on Open MPI, 0.9-8.1 percent on MPICH2, and 1.6-9.7 percent on MVAPICH2).", "paper_title": "Improving the Reliability of MPI Libraries via Message Flow Checking", "paper_id": "WOS:000313816300010"}