{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "relational_features"}, {"score": 0.03978906736096707, "phrase": "opinion_expressions"}, {"score": 0.03132471895452395, "phrase": "opinion_expression_extraction"}, {"score": 0.004780633011300165, "phrase": "fine-grained_opinion_analysis"}, {"score": 0.004746558955503364, "phrase": "fine-grained_opinion_analysis_methods"}, {"score": 0.004662427600500598, "phrase": "linguistic_features"}, {"score": 0.004187917910692495, "phrase": "semantic_role_structures"}, {"score": 0.00406971620207041, "phrase": "automatic_systems"}, {"score": 0.003997533498401968, "phrase": "fine-grained_opinion_analysis_tasks"}, {"score": 0.0038846843242954935, "phrase": "opinion_holders"}, {"score": 0.003603327452846714, "phrase": "natural-language_discourse"}, {"score": 0.003526735797659508, "phrase": "arbitrary_distances"}, {"score": 0.0034026714408341868, "phrase": "multiple_opinions"}, {"score": 0.0032947371184395237, "phrase": "optimal_analysis"}, {"score": 0.0031561148083611647, "phrase": "sufficiently_accurate_and_efficient_approximation"}, {"score": 0.003100085797251317, "phrase": "feature_sets"}, {"score": 0.0030779528295407925, "phrase": "machine_learning_approaches"}, {"score": 0.002927371124061966, "phrase": "best_model"}, {"score": 0.002875391177926809, "phrase": "soft_recall"}, {"score": 0.0028446460307503343, "phrase": "mpqa_corpus"}, {"score": 0.0028142286985235977, "phrase": "conventional_sequence_labeler"}, {"score": 0.0027841357057119317, "phrase": "local_contextual_features"}, {"score": 0.0027054473441439422, "phrase": "significant_improvements"}, {"score": 0.002647890142618442, "phrase": "extended_tasks"}, {"score": 0.0022777800735119405, "phrase": "extrinsic_evaluation"}, {"score": 0.002253410447951689, "phrase": "extracted_mpqa-style_opinion_expressions"}, {"score": 0.0022213218042340752, "phrase": "practical_opinion_mining_tasks"}, {"score": 0.002158505888557746, "phrase": "machine_learning_features"}, {"score": 0.0021049977753042253, "phrase": "statistically_significant_improvements"}], "paper_keywords": [""], "paper_abstract": "Fine-grained opinion analysis methods often make use of linguistic features but typically do not take the interaction between opinions into account. This article describes a set of experiments that demonstrate that relational features, mainly derived from dependency-syntactic and semantic role structures, can significantly improve the performance of automatic systems for a number of fine-grained opinion analysis tasks: marking up opinion expressions, finding opinion holders, and determining the polarities of opinion expressions. These features make it possible to model the way opinions expressed in natural-language discourse interact in a sentence over arbitrary distances. The use of relations requires us to consider multiple opinions simultaneously, which makes the search for the optimal analysis intractable. However, a reranker can be used as a sufficiently accurate and efficient approximation.A number of feature sets and machine learning approaches for the rerankers are evaluated. For the task of opinion expression extraction, the best model shows a 10-point absolute improvement in soft recall on the MPQA corpus over a conventional sequence labeler based on local contextual features, while precision decreases only slightly. Significant improvements are also seen for the extended tasks where holders and polarities are considered: 10 and 7 points in recall, respectively. In addition, the systems outperform previously published results for unlabeled (6 F-measure points) and polarity-labeled (10-15 points) opinion expression extraction. Finally, as an extrinsic evaluation, the extracted MPQA-style opinion expressions are used in practical opinion mining tasks. In all scenarios considered, the machine learning features derived from the opinion expressions lead to statistically significant improvements.", "paper_title": "Relational Features in Fine-Grained Opinion Analysis", "paper_id": "WOS:000325864800002"}