{"auto_keywords": [{"score": 0.045360605423936017, "phrase": "marginal_probabilities"}, {"score": 0.042151584995031466, "phrase": "bp"}, {"score": 0.03929486124723353, "phrase": "trbp"}, {"score": 0.00481495049065317, "phrase": "approximate_inference"}, {"score": 0.004778258911940497, "phrase": "inference_problems"}, {"score": 0.004741845603430361, "phrase": "graphical_models"}, {"score": 0.004634254474150777, "phrase": "constrained_optimization"}, {"score": 0.004581373625744533, "phrase": "free-energy_function"}, {"score": 0.004392565073466714, "phrase": "probabilistic_inference"}, {"score": 0.0042928648367867835, "phrase": "joint_distribution"}, {"score": 0.004163427731140163, "phrase": "unified_message-passing_algorithm_architecture"}, {"score": 0.004053362743156545, "phrase": "belief_propagation"}, {"score": 0.0038418555461260063, "phrase": "trw"}, {"score": 0.003769006950727621, "phrase": "product_algorithms"}, {"score": 0.003669330508576073, "phrase": "new_set"}, {"score": 0.0036413370053909886, "phrase": "convergent_algorithms"}, {"score": 0.0033857878144822906, "phrase": "main_idea"}, {"score": 0.0032836104153151973, "phrase": "general_perspective"}, {"score": 0.003246091321090681, "phrase": "existing_bp_and_trbp_algorithms"}, {"score": 0.003124086807493311, "phrase": "basic_optimization_formula"}, {"score": 0.002680114113899346, "phrase": "convex_duality"}, {"score": 0.0026393362602995254, "phrase": "\"primal-dual_ascent\"_algorithm"}, {"score": 0.0025694584194998356, "phrase": "bregman_successive_projection_scheme"}, {"score": 0.002482320290902079, "phrase": "general_type"}, {"score": 0.002370704665003412, "phrase": "fractional-free-energy_variational_principle"}, {"score": 0.002316788811533867, "phrase": "optimization_formula"}, {"score": 0.002272794656458419, "phrase": "\"norm-product\"_message-passing_algorithm"}, {"score": 0.0021049977753042253, "phrase": "nmplp"}], "paper_keywords": ["Approximate inference", " Bethe free energy", " Bregman projection", " convex free energy", " dual block ascent", " Fenchel duality", " graphical models", " linear programming (LP) relaxation", " Markov random fields (MRF)", " max-product algorithm", " maximum a posteriori probability (MAP) estimation", " sum-product algorithm"], "paper_abstract": "Inference problems in graphical models can be represented as a constrained optimization of a free-energy function. In this paper, we treat both forms of probabilistic inference, estimating marginal probabilities of the joint distribution and finding the most probable assignment, through a unified message-passing algorithm architecture. In particular we generalize the belief propagation (BP) algorithms of sum-product and max-product and tree-reweighted (TRW) sum and max product algorithms (TRBP) and introduce a new set of convergent algorithms based on \"convex-free-energy\" and linear-programming (LP) relaxation as a zero-temperature of a convex-free-energy. The main idea of this work arises from taking a general perspective on the existing BP and TRBP algorithms while observing that they all are reductions from the basic optimization formula of f + Sigma(i) h(i) where the function f is an extended-valued, strictly convex but nonsmooth and the functions h(i) are extended-valued functions (not necessarily convex). We use tools from convex duality to present the \"primal-dual ascent\" algorithm which is an extension of the Bregman successive projection scheme and is designed to handle optimization of the general type f + Sigma(i) h(i). We then map the fractional-free-energy variational principle for approximate inference onto the optimization formula above and introduce the \"norm-product\" message-passing algorithm. Special cases of the norm-product include sum-product and max-product (BP algorithms), TRBP and NMPLP algorithms. When the fractional-free-energy is set to be convex (convex-free-energy) the norm-product is globally convergent for the estimation of marginal probabilities and for approximating the LP-relaxation. We also introduce another branch of the norm-product which arises as the \"zero-temperature\" of the convex-free-energy which we refer to as the \"convex-max-product\". The convex-max-product is convergent (unlike max-product) and aims at solving the LP-relaxation.", "paper_title": "Norm-Product Belief Propagation: Primal-Dual Message-Passing for Approximate Inference", "paper_id": "WOS:000284419900027"}