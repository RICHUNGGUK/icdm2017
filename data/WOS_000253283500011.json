{"auto_keywords": [{"score": 0.014794088632651215, "phrase": "smvcir"}, {"score": 0.009091589699492232, "phrase": "mean_differences"}, {"score": 0.00481495049065317, "phrase": "variance-covariance_inverse_regression"}, {"score": 0.004405596416783185, "phrase": "classification_problem"}, {"score": 0.00436661740263741, "phrase": "sliced_inverse_regression"}, {"score": 0.004328022917325368, "phrase": "sir"}, {"score": 0.004232875294230749, "phrase": "linear_discriminant_analysis"}, {"score": 0.0040309035566691645, "phrase": "sliced_average_variance_estimation"}, {"score": 0.0032561349010603734, "phrase": "covariance_differences"}, {"score": 0.003128336741911927, "phrase": "new_data_analytic_method"}, {"score": 0.003073154478201771, "phrase": "mean_variance-covariance_regression"}, {"score": 0.002952516738708181, "phrase": "first_and_second_order_differences"}, {"score": 0.002515384834484012, "phrase": "useful_data-analytic_information"}, {"score": 0.0024930878032164757, "phrase": "mean_and_covariance_differences"}, {"score": 0.0023633857274905977, "phrase": "variance_differences"}, {"score": 0.002200861826643147, "phrase": "new_data"}, {"score": 0.0021620042653528846, "phrase": "enology_literature"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["classification", " dimension reduction", " discrimination", " QR-decomposition", " SAVE", " SIR", " visualization"], "paper_abstract": "Inverse regression methods have gained popularity over the last 10 years or so. More recently these methods have been applied to the classification problem. Sliced inverse regression (SIR) is equivalent to linear discriminant analysis and as such it detects mean differences between the classes. Sliced average variance estimation (SAVE) is designed to detect differences between the means, variances and covariances of the predictors across the classes. However, in SAVE each difference in variance across the groups takes up a dimension, and hence SAVE can have difficulty detecting mean differences and covariance differences. In this paper, we propose a new data analytic method, called sliced mean variance-covariance regression (SMVCIR) which can readily detect both first and second order differences between the classes even when many variance differences exist. Further, our procedure is based on an ordering of the dimensions based on their relative importance which is quite beneficial to interpretation. In particular, we demonstrate that useful data-analytic information about mean and covariance differences can be obtained from SMVCIR when SAVE finds many dimensions due to variance differences. Finally, the advantages of SMVCIR over SIR and SAVE are exemplified using a new data set from the enology literature. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Sliced mean variance-covariance inverse regression", "paper_id": "WOS:000253283500011"}