{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "background_knowledge"}, {"score": 0.01011804321489435, "phrase": "different_clustering_methods"}, {"score": 0.004688321299229397, "phrase": "collaborative_clustering"}, {"score": 0.004236639288852276, "phrase": "common_dataset"}, {"score": 0.004103212598803194, "phrase": "different_partitioning"}, {"score": 0.003952828685048176, "phrase": "consensual_clustering"}, {"score": 0.0038079353103469865, "phrase": "hard_task"}, {"score": 0.003108911488613549, "phrase": "collaboration_process"}, {"score": 0.00304321897427383, "phrase": "different_ways"}, {"score": 0.0023424328921363585, "phrase": "collaborative_process"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Collaborative clustering", " Unsupervised learning", " Classification", " Pattern recognition", " Knowledge-guided clustering"], "paper_abstract": "The aim of collaborative clustering is to make different clustering methods collaborate, in order to reach at an agreement on the partitioning of a common dataset. As different clustering methods can produce different partitioning of the same dataset, finding a consensual clustering from these results is often a hard task. The collaboration aims to make the methods agree on the partitioning through a refinement of their results. This process tends to make the results more similar. In this paper, after the introduction of the collaboration process, we present different ways to integrate background knowledge into it. Indeed, in recent years, the integration of background knowledge in clustering algorithms has been the subject of a lot of interest. This integration often leads to an improvement of the quality of the results. We discuss how such integration in the collaborative process is beneficial and we present experiments in which background knowledge is used to guide collaboration. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Collaborative clustering with background knowledge", "paper_id": "WOS:000274174000003"}