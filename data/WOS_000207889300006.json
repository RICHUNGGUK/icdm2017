{"auto_keywords": [{"score": 0.042406796888230874, "phrase": "speech_technology"}, {"score": 0.00481495049065317, "phrase": "speech-enabled_interfaces"}, {"score": 0.0045820747375409435, "phrase": "inclusive_design"}, {"score": 0.0035755653799043, "phrase": "technological_issues"}, {"score": 0.0034306925765832633, "phrase": "context-dependent_user_needs"}, {"score": 0.0032109670662222416, "phrase": "multimodal_user_interfaces"}, {"score": 0.0028596699752849682, "phrase": "best_practices"}, {"score": 0.0021049977753042253, "phrase": "older_adults"}], "paper_keywords": ["Universal access", " Speech technology", " Multimodal interaction", " User experience engineering"], "paper_abstract": "This paper presents a methodology to apply speech technology for compensating sensory, motor, cognitive and affective usage difficulties. It distinguishes (1) an analysis of accessibility and technological issues for the identification of context-dependent user needs and corresponding opportunities to include speech in multimodal user interfaces, and (2) an iterative generate-and-test process to refine the interface prototype and its design rationale. Best practices show that such inclusion of speech technology, although still imperfect in itself, can enhance both the functional and affective information and communication technology-experiences of specific user groups, such as persons with reading difficulties, hearing-impaired, intellectually disabled, children and older adults.", "paper_title": "Attuning speech-enabled interfaces to user and context for inclusive design: technology, methodology and practice", "paper_id": "WOS:000207889300006"}