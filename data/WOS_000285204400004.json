{"auto_keywords": [{"score": 0.04424296209239414, "phrase": "k_best_policies_problem"}, {"score": 0.03722512137998704, "phrase": "k-th_best_policy"}, {"score": 0.00481495049065317, "phrase": "discrete_markov_decision_processes"}, {"score": 0.004743594110762319, "phrase": "optimal_probabilistic-planning_algorithm"}, {"score": 0.0045357787854931894, "phrase": "markov_decision_process"}, {"score": 0.004424268136268051, "phrase": "optimal_policy"}, {"score": 0.004065156038847781, "phrase": "k_best_policies"}, {"score": 0.0040048667115255, "phrase": "discrete_markov_decision_process"}, {"score": 0.00367967106192446, "phrase": "dynamic_programming"}, {"score": 0.0034835554514445017, "phrase": "turing"}, {"score": 0.0034146585649631692, "phrase": "optimal_planning_problem"}, {"score": 0.002955050521440921, "phrase": "unreasonable_amounts"}, {"score": 0.002701361707441567, "phrase": "complete_algorithm"}, {"score": 0.0025571463140118805, "phrase": "i-th_policy"}, {"score": 0.002444883254621769, "phrase": "exactly_one_state"}, {"score": 0.0023727863021828547, "phrase": "approximate_algorithm"}, {"score": 0.0022460727898764216, "phrase": "good_scalability"}, {"score": 0.002168975681697056, "phrase": "approximate_algorithms"}], "paper_keywords": ["Probabilistic planning", " Markov decision process", " Policy ranking"], "paper_abstract": "An optimal probabilistic-planning algorithm solves a problem, usually modeled by a Markov decision process, by finding an optimal policy. In this paper, we study the k best policies problem. The problem is to find the k best policies of a discrete Markov decision process. The k best policies, k > 1, cannot be found directly using dynamic programming. Na < vely, finding the k-th best policy can be Turing reduced to the optimal planning problem, but the number of problems queried in the na < ve algorithm is exponential in k. We show empirically that solving k best policies problem by using this reduction requires unreasonable amounts of time even when k = 3. We then provide two new algorithms. The first is a complete algorithm, based on our theoretical contribution that the k-th best policy differs from the i-th policy, for some i < k, on exactly one state. The second is an approximate algorithm that skips many less useful policies. We show that both algorithms have good scalability. We also show that the approximate algorithms runs much faster and finds interesting, high-quality policies.", "paper_title": "Ranking policies in discrete Markov decision processes", "paper_id": "WOS:000285204400004"}