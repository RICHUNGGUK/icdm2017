{"auto_keywords": [{"score": 0.030926517488363503, "phrase": "concurrent_actor-critic_training"}, {"score": 0.028160967927341577, "phrase": "bellman_optimality"}, {"score": 0.00481495049065317, "phrase": "continuous-time_formulation"}, {"score": 0.004723322467153553, "phrase": "adaptive_critic_design"}, {"score": 0.004663215806112913, "phrase": "acd"}, {"score": 0.004430248457624686, "phrase": "discrete_case"}, {"score": 0.0041819982959552925, "phrase": "bptt"}, {"score": 0.0041023644174418205, "phrase": "real-time_recurrent_learning"}, {"score": 0.004050116768809519, "phrase": "rtrl"}, {"score": 0.003922378980031565, "phrase": "practical_benefits"}, {"score": 0.0037024804835018373, "phrase": "plant_descriptions"}, {"score": 0.003631945391344252, "phrase": "differential_equations"}, {"score": 0.0035399770257915466, "phrase": "standard_integration_routine"}, {"score": 0.003494866798828308, "phrase": "adaptive_step-size"}, {"score": 0.0034282732966589478, "phrase": "adaptive_sampling"}, {"score": 0.0033200826267264383, "phrase": "second-order_actor_adaptation"}, {"score": 0.0032784495310089253, "phrase": "newton"}, {"score": 0.003154012038613403, "phrase": "fast_actor_convergence"}, {"score": 0.0030938932434437178, "phrase": "general_plant"}, {"score": 0.002958021635132416, "phrase": "fast_critic_update"}, {"score": 0.0028100102841877835, "phrase": "necessary_adjustments"}, {"score": 0.0027741761880779535, "phrase": "critic_parameters"}, {"score": 0.0027212777001495176, "phrase": "actor_updates"}, {"score": 0.002601727192945944, "phrase": "first-order_approximation"}, {"score": 0.0024874156497091994, "phrase": "critic_and_actor_updates"}, {"score": 0.002347775213789611, "phrase": "substantial_error"}, {"score": 0.002244596395352896, "phrase": "temporal_difference_equation"}, {"score": 0.0021876814398268775, "phrase": "traditional_critic_training"}], "paper_keywords": ["actor-critic adaptation", " adaptive critic design (ACD)", " approximate dynamic programming", " backpropagation through time (BPTT)", " continuous adaptive critic designs", " real-time recurrent learning (RTRL)", " reinforcement learning", " second-order actor adaptation"], "paper_abstract": "A continuous-time formulation of an adaptive critic design (ACD) is investigated. Connections to the discrete case are made, where backpropagation through time (BPTT) and real-time recurrent learning (RTRL) are prevalent. Practical benefits are that this framework fits in well with plant descriptions given by differential equations and that any standard integration routine with adaptive step-size does an adaptive sampling for free. A second-order actor adaptation using Newton's method is established for fast actor convergence for a general plant and critic. Also, a fast critic update for concurrent actor-critic training is introduced to immediately apply necessary adjustments of critic parameters induced by actor updates to keep the Bellman optimality correct to first-order approximation after actor changes. Thus, critic and actor updates may be performed at the same time until some substantial error build up in the Bellman optimality or temporal difference equation, when a traditional critic training needs to be performed and then another interval of concurrent actor-critic training may resume.", "paper_title": "Continuous-time adaptive critics", "paper_id": "WOS:000246423400002"}