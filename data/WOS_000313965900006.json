{"auto_keywords": [{"score": 0.0466721450439183, "phrase": "multimedia_search"}, {"score": 0.0048150534652069, "phrase": "multimedia"}, {"score": 0.00468991337957911, "phrase": "visual_and_textual_modalities"}, {"score": 0.004356741449157895, "phrase": "explicit_meaning"}, {"score": 0.004311109608629196, "phrase": "visual_content"}, {"score": 0.004133292222875435, "phrase": "knowledge_models"}, {"score": 0.004025885154716127, "phrase": "well_known_semantic_gap"}, {"score": 0.00392125815948488, "phrase": "semantic_interpretation"}, {"score": 0.0037005154613244363, "phrase": "different_application_contexts"}, {"score": 0.003492155652400838, "phrase": "ontology_matching"}, {"score": 0.0030772505522663612, "phrase": "important_semantic_image_retrieval_issue"}, {"score": 0.0030130446986008277, "phrase": "common-sense_knowledge"}, {"score": 0.002858313353461727, "phrase": "previously_introduced_textual_concept"}, {"score": 0.002769304577201566, "phrase": "textual_and_visual_representation"}, {"score": 0.002654911400878851, "phrase": "novel_matching_technique"}, {"score": 0.0025994945418484935, "phrase": "multi-modal_graph"}, {"score": 0.002492098272172066, "phrase": "textual_and_visual_modalities"}, {"score": 0.0023640560785711923, "phrase": "exclusive_sources"}, {"score": 0.002339246282204109, "phrase": "extensional_information"}, {"score": 0.0021385822825864425, "phrase": "multimedia_domain"}, {"score": 0.0021049977753042253, "phrase": "experimental_evaluation"}], "paper_keywords": ["Multimedia search and retrieval", " Ontology matching", " Semantic gap", " Semantic image annotation", " Extensional and conceptual heterogeneity"], "paper_abstract": "Ontologies have been intensively applied for improving multimedia search and retrieval by providing explicit meaning to visual content. Several multimedia ontologies have been recently proposed as knowledge models suitable for narrowing the well known semantic gap and for enabling the semantic interpretation of images. Since these ontologies have been created in different application contexts, establishing links between them, a task known as ontology matching, promises to fully unlock their potential in support of multimedia search and retrieval. This paper proposes and compares empirically two extensional ontology matching techniques applied to an important semantic image retrieval issue: automatically associating common-sense knowledge to multimedia concepts. First, we extend a previously introduced textual concept matching approach to use both textual and visual representation of images. In addition, a novel matching technique based on a multi-modal graph is proposed. We argue that the textual and visual modalities have to be seen as complementary rather than as exclusive sources of extensional information in order to improve the efficiency of the application of an ontology matching approach in the multimedia domain. An experimental evaluation is included in the paper.", "paper_title": "Multimedia ontology matching by using visual and textual modalities", "paper_id": "WOS:000313965900006"}