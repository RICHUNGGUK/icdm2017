{"auto_keywords": [{"score": 0.03876199044309078, "phrase": "openratslam"}, {"score": 0.004814972659693092, "phrase": "slam"}, {"score": 0.004721893473387288, "phrase": "ratslam"}, {"score": 0.004630626571109149, "phrase": "navigation_system"}, {"score": 0.004511663118269957, "phrase": "neural_processes"}, {"score": 0.004367228576339114, "phrase": "rodent_brain"}, {"score": 0.00419997182602686, "phrase": "low_resolution"}, {"score": 0.004172722575842674, "phrase": "monocular_image_data"}, {"score": 0.004118751115632515, "phrase": "seminal_experiments"}, {"score": 0.003960972732123083, "phrase": "entire_suburb"}, {"score": 0.0038843558517333327, "phrase": "web_camera"}, {"score": 0.0038092152998069786, "phrase": "long_term_robot_delivery_trial"}, {"score": 0.0033439771810057717, "phrase": "leverage_advantages"}, {"score": 0.0032792555200980783, "phrase": "robot_and_sensor_abstraction"}, {"score": 0.003194898129853895, "phrase": "data_playback"}, {"score": 0.0030524448705134283, "phrase": "connected_ros_nodes"}, {"score": 0.0029933487820771217, "phrase": "ratslam's_pose_cells"}, {"score": 0.002878556952876824, "phrase": "local_view_cells"}, {"score": 0.0027681550491613603, "phrase": "fourth_node"}, {"score": 0.0027145478956494356, "phrase": "visual_odometry_estimates"}, {"score": 0.002543224008253855, "phrase": "ratslam_model"}, {"score": 0.0025102759256260703, "phrase": "salient_details"}, {"score": 0.0024616504443079512, "phrase": "ros_implementation"}, {"score": 0.0023213398100616132, "phrase": "class_diagrams"}, {"score": 0.0022912596877648723, "phrase": "sequence_diagrams"}, {"score": 0.0022468671200629024, "phrase": "parameter_tuning_strategies"}], "paper_keywords": ["RatSLAM", " OpenRatSLAM", " SLAM", " Navigation", " Mapping", " Brain-based", " Appearance-based", " ROS", " Open-source", " Hippocampus"], "paper_abstract": "RatSLAM is a navigation system based on the neural processes underlying navigation in the rodent brain, capable of operating with low resolution monocular image data. Seminal experiments using RatSLAM include mapping an entire suburb with a web camera and a long term robot delivery trial. This paper describes OpenRatSLAM, an open-source version of RatSLAM with bindings to the Robot Operating System framework to leverage advantages such as robot and sensor abstraction, networking, data playback, and visualization. OpenRatSLAM comprises connected ROS nodes to represent RatSLAM's pose cells, experience map, and local view cells, as well as a fourth node that provides visual odometry estimates. The nodes are described with reference to the RatSLAM model and salient details of the ROS implementation such as topics, messages, parameters, class diagrams, sequence diagrams, and parameter tuning strategies. The performance of the system is demonstrated on three publicly available open-source datasets.", "paper_title": "OpenRatSLAM: an open source brain-based SLAM system", "paper_id": "WOS:000316820200003"}