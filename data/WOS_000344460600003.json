{"auto_keywords": [{"score": 0.049110045082843494, "phrase": "imbalanced_data-sets"}, {"score": 0.008713768692145006, "phrase": "radial_basis_function_networks"}, {"score": 0.004756233569671719, "phrase": "learning_processes"}, {"score": 0.003924121879214595, "phrase": "poor_results"}, {"score": 0.003892126266260425, "phrase": "minority_classes"}, {"score": 0.003513443975425428, "phrase": "sensitive_techniques"}, {"score": 0.0033449479263613848, "phrase": "local_models"}, {"score": 0.003237116128682586, "phrase": "different_machine_learning_areas"}, {"score": 0.003158522476399068, "phrase": "output_weights"}, {"score": 0.002970260970134645, "phrase": "locally_tuned_response"}, {"score": 0.0027931892160452513, "phrase": "global_and_local_paradigms"}, {"score": 0.002759058732719621, "phrase": "weights_training_phase"}, {"score": 0.0027141975147496264, "phrase": "rbfns_design_methodology"}, {"score": 0.002659142621852998, "phrase": "least_mean_square"}, {"score": 0.002626645763725465, "phrase": "singular_value_decomposition"}, {"score": 0.0025523518748506347, "phrase": "local_and_global_weights"}, {"score": 0.0024903420152789135, "phrase": "learning_algorithms"}, {"score": 0.002449839292715327, "phrase": "classical_rbfn_design_methods"}, {"score": 0.002322689143237591, "phrase": "re-balance_techniques"}, {"score": 0.0022849068677290836, "phrase": "statistical_tests"}, {"score": 0.00219311232069446, "phrase": "rbfn_design_methodology"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Imbalanced data sets", " Radial Basis Function Networks", " Training algorithms", " Evolutionary computation"], "paper_abstract": "Nowadays, many real applications comprise data-sets where the distribution of the classes is significantly different. These data-sets are commonly known as imbalanced data-sets. Traditional classifiers are not able to deal with these kinds of data-sets because they tend to classify only majority classes, obtaining poor results for minority classes. The approaches that have been proposed to address this problem can be categorized into three types: resampling methods, algorithmic adaptations and cost sensitive techniques. Radial Basis Function Networks (RBFNs), artificial neural networks composed of local models or RBFs, have demonstrated their efficiency in different machine learning areas. Centers, widths and output weights for the RBFs must be determined when designing RBFNs. Taking into account the locally tuned response of RBFs, the objective of this paper is to study the influence of global and local paradigms on the weights training phase, within the RBFNs design methodology, for imbalanced data-sets. Least Mean Square and the Singular Value Decomposition have been chosen as representatives of local and global weights training paradigms respectively. These learning algorithms are inserted into classical RBFN design methods that are run on imbalanced data-sets and also on these data-sets preprocessed with re-balance techniques. After applying statistical tests to the results obtained, some guidelines about the RBFN design methodology for imbalanced data-sets are provided. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Training algorithms for Radial Basis Function Networks to tackle learning processes with imbalanced data-sets", "paper_id": "WOS:000344460600003"}