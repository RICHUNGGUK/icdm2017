{"auto_keywords": [{"score": 0.04612142010063672, "phrase": "elm"}, {"score": 0.01571957623049779, "phrase": "extreme_learning_machine"}, {"score": 0.004612147352416241, "phrase": "learning_scheme"}, {"score": 0.004305203085016233, "phrase": "lip_regularization"}, {"score": 0.004123781267600542, "phrase": "double_parallel_feedforward_neural_network"}, {"score": 0.003816197777388722, "phrase": "fast_learning_method"}, {"score": 0.003751011827704279, "phrase": "feedforward_networks"}, {"score": 0.0036553070575015344, "phrase": "single_hidden_layer"}, {"score": 0.0035620354052144656, "phrase": "key_problem"}, {"score": 0.0032398798149196432, "phrase": "hidden_nodes"}, {"score": 0.0026571010583973523, "phrase": "elm."}, {"score": 0.002375253757224999, "phrase": "dpfnn"}, {"score": 0.0023346234464901978, "phrase": "elm_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["DPFNN", " ELM", " L-1/2 regularizer"], "paper_abstract": "A learning scheme based on Extreme Learning Machine (ELM) and Lip regularization is proposed for a double parallel feedforward neural network. ELM has been widely used as a fast learning method for feedforward networks with a single hidden layer. A key problem for ELM is the choice of the (minimum) number of the hidden nodes. To resolve this problem, we propose to combine the L-1/2 regularization method, that becomes popular in recent years in informatics, with ELM. It is shown in our experiments that the involvement of the L-1/2 regularizer in DPFNN with ELM results in less hidden nodes but equally good performance. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Double parallel feedforward neural network based on extreme learning machine with L-1/2 regularizer", "paper_id": "WOS:000331851700014"}