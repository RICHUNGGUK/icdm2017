{"auto_keywords": [{"score": 0.049146612112995924, "phrase": "large-scale_erasure-coded_storage_systems"}, {"score": 0.033319191023934186, "phrase": "daco"}, {"score": 0.014542150195867836, "phrase": "disk_media_access_congestion"}, {"score": 0.014331237310513539, "phrase": "read-modify-write_operations"}, {"score": 0.014123339571293372, "phrase": "small-write_operations"}, {"score": 0.013000215835100942, "phrase": "composite_operation"}, {"score": 0.00481495049065317, "phrase": "high-performance_disk_architecture"}, {"score": 0.004195418010131832, "phrase": "conventional_disk"}, {"score": 0.004013662619667083, "phrase": "new_disk_architecture"}, {"score": 0.0037280480704056152, "phrase": "read"}, {"score": 0.003479692058963528, "phrase": "sector-based_pipeline_technology"}, {"score": 0.003428665921276366, "phrase": "block-level_data"}, {"score": 0.00307657476125683, "phrase": "large-scale_erasure-coded_storage_system"}, {"score": 0.002899965889623787, "phrase": "small-write_operation"}, {"score": 0.002464709648714996, "phrase": "significant_performance_improvement"}, {"score": 0.002346160830406661, "phrase": "worst_case"}, {"score": 0.0022223176391038785, "phrase": "important_implementation_issues"}, {"score": 0.002146926767291475, "phrase": "additional_cost"}, {"score": 0.0021049977753042253, "phrase": "daco."}], "paper_keywords": ["Disk architecture", " erasure code", " small-write problem", " storage system"], "paper_abstract": "Large-scale erasure-coded storage systems have a serious performance problem due to I/O congestion and disk media access congestion caused by read-modify-write operations involved in small-write operations. All the existing technologies based on the conventional disk can provide very limited performance improvement. This paper presents a new Disk Architecture with Composite Operation (DACO), whose disk media access interface consists of three kinds of operations: READ, WRITE, and Composite Operation (CO). The CO adopts a sector-based pipeline technology to implement block-level data modify operations, and thus, can replace the read-modify-write operations involved in small-write operations. When the DACO is adopted in a large-scale erasure-coded storage system with t fault tolerance, t I/Os and t disk media access operations can be reduced in each small-write operation, respectively. This alleviates both I/O congestion and disk media access congestion in nature, and thus, can remarkably improve the performance of large-scale erasure-coded storage systems. A simulation study shows that the DACO can provide significant performance improvement: reducing the average I/O response time by up to 31.16 percent even in the worst case where t = 1. This paper also discusses the important implementation issues of the DACO and investigates the additional cost involved in the DACO.", "paper_title": "DACO: A High-Performance Disk Architecture Designed Specially for Large-Scale Erasure-Coded Storage Systems", "paper_id": "WOS:000282239300005"}