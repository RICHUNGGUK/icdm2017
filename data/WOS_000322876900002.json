{"auto_keywords": [{"score": 0.031008719312842697, "phrase": "random_weights"}, {"score": 0.00481495049065317, "phrase": "metropolis-hastings_algorithms"}, {"score": 0.004734987730139094, "phrase": "metropolis-hastings_algorithm"}, {"score": 0.004579005794486596, "phrase": "monte_carlo"}, {"score": 0.004428139418750855, "phrase": "markov_chain"}, {"score": 0.004330321475256457, "phrase": "limit_distribution"}, {"score": 0.00428222231579898, "phrase": "target_distribution"}, {"score": 0.004141093507753515, "phrase": "different_proposal_distribution"}, {"score": 0.004072275820209647, "phrase": "proposed_value"}, {"score": 0.003960101604693806, "phrase": "particular_probability"}, {"score": 0.00389427992231721, "phrase": "previous_value"}, {"score": 0.003703282519292336, "phrase": "accepted_values"}, {"score": 0.0036214184763804034, "phrase": "positive_number"}, {"score": 0.003501991125315889, "phrase": "resulting_ergodic_mean"}, {"score": 0.003220315882881027, "phrase": "weighted_average"}, {"score": 0.003166751241099304, "phrase": "importance_sampling-type_estimator"}, {"score": 0.0030451958332949735, "phrase": "standard_theory"}, {"score": 0.0030113280682863234, "phrase": "importance_sampling"}, {"score": 0.0023941575109692336, "phrase": "original_estimator"}, {"score": 0.0023021895404322767, "phrase": "independence_metropolis-hastings"}, {"score": 0.002238664219600659, "phrase": "finite_support"}, {"score": 0.0021049977753042253, "phrase": "\"optimal\"_importance_sampling_estimator"}], "paper_keywords": ["Metropolis-Hastings algorithm", " Importance sampling", " Weighted estimators", " Variance reduction"], "paper_abstract": "The Metropolis-Hastings algorithm is one of the most basic and well-studied Markov chain Monte Carlo methods. It generates a Markov chain which has as limit distribution the target distribution by simulating observations from a different proposal distribution. A proposed value is accepted with some particular probability otherwise the previous value is repeated. As a consequence, the accepted values are repeated a positive number of times and thus any resulting ergodic mean is, in fact, a weighted average. It turns out that this weighted average is an importance sampling-type estimator with random weights. By the standard theory of importance sampling, replacement of these random weights by their (conditional) expectations leads to more efficient estimators. In this paper we study the estimator arising by replacing the random weights with certain estimators of their conditional expectations. We illustrate by simulations that it is often more efficient than the original estimator while in the case of the independence Metropolis-Hastings and for distributions with finite support we formally prove that it is even better than the \"optimal\" importance sampling estimator.", "paper_title": "Variance reduction of estimators arising from Metropolis-Hastings algorithms", "paper_id": "WOS:000322876900002"}