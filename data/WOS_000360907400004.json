{"auto_keywords": [{"score": 0.05007747893386848, "phrase": "scientific_publications"}, {"score": 0.048301352462041224, "phrase": "model-based_methods"}, {"score": 0.036865219833273295, "phrase": "keyword-based_dictionary"}, {"score": 0.03629239245675472, "phrase": "crf"}, {"score": 0.004321952227344232, "phrase": "five_entity_extraction_methods"}, {"score": 0.0039004184205037, "phrase": "wikipedia"}, {"score": 0.003407214479510987, "phrase": "wikipedia-based_dictionary"}, {"score": 0.003245359940011418, "phrase": "annotated_test_set"}, {"score": 0.0031759067385562553, "phrase": "computer_science"}, {"score": 0.002992456421856034, "phrase": "roc_curve"}, {"score": 0.0028968858148006823, "phrase": "precision-recall_curve"}, {"score": 0.0028195727965553367, "phrase": "evaluative_indicators"}, {"score": 0.002685558057339722, "phrase": "vocabulary-based_ones"}, {"score": 0.0025578967205807843, "phrase": "best_performance"}, {"score": 0.0024628046987344846, "phrase": "keyword-based_one"}, {"score": 0.0024231382864800173, "phrase": "higher_recall"}, {"score": 0.0023841092222805253, "phrase": "wikipedia-based_one"}, {"score": 0.002345707314211983, "phrase": "higher_precision"}, {"score": 0.002270745003370529, "phrase": "study_help"}, {"score": 0.0022101055924375725, "phrase": "informetric_research"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Entity extraction", " Vocabulary", " Dictionary", " Conditional random fields", " Content aware"], "paper_abstract": "The objective of this study is to evaluate the performance of five entity extraction methods for the task of identifying entities from scientific publications, including two vocabularybased methods (a keyword-based and a Wikipedia-based) and three model-based methods (conditional random fields (CRF), CRF with keyword-based dictionary, and CRF with Wikipedia-based dictionary). These methods are applied to an annotated test set of publications in computer science. Precision, recall, accuracy, area under the ROC curve, and area under the precision-recall curve are employed as the evaluative indicators. Results show that the model-based methods outperform the vocabulary-based ones, among which CRF with keyword-based dictionary has the best performance. Between the two vocabularybased methods, the keyword-based one has a higher recall and the Wikipedia-based one has a higher precision. The findings of this study help inform the understanding of informetric research at a more granular level. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Identifying entities from scientific publications: A comparison of vocabulary- and model-based methods", "paper_id": "WOS:000360907400004"}