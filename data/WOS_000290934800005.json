{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "general_software_defect-proneness_prediction_framework"}, {"score": 0.004769958800452922, "phrase": "background-predicting"}, {"score": 0.004747620102130588, "phrase": "defect-prone_software_components"}, {"score": 0.004681226806682058, "phrase": "economically_important_activity"}, {"score": 0.004551199992546761, "phrase": "good_deal"}, {"score": 0.003990385737207714, "phrase": "general_framework"}, {"score": 0.003953068310598579, "phrase": "software_defect_prediction"}, {"score": 0.0037363522297378777, "phrase": "competing_prediction_systems"}, {"score": 0.0033851984021896287, "phrase": "scheme_evaluation"}, {"score": 0.0033377940531761985, "phrase": "prediction_performance"}, {"score": 0.003306559295382181, "phrase": "competing_learning_schemes"}, {"score": 0.003229741076887151, "phrase": "defect_predictor"}, {"score": 0.003139903872290182, "phrase": "evaluated_learning_scheme"}, {"score": 0.003095923814666088, "phrase": "software_defects"}, {"score": 0.003066945490483524, "phrase": "new_data"}, {"score": 0.0030097975788892896, "phrase": "constructed_model"}, {"score": 0.0028715299874549245, "phrase": "proposed_framework"}, {"score": 0.002778529097886437, "phrase": "publicly_available_software_defect_data_sets"}, {"score": 0.0026384167183586015, "phrase": "different_learning_schemes"}, {"score": 0.002613709503583786, "phrase": "different_data_sets"}, {"score": 0.002493592357827492, "phrase": "small_details"}, {"score": 0.0022064376000055764, "phrase": "previous_approaches"}, {"score": 0.0021049977753042253, "phrase": "learning_scheme"}], "paper_keywords": ["Software defect prediction", " software defect-proneness prediction", " machine learning", " scheme evaluation"], "paper_abstract": "BACKGROUND-Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE-We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD-The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS-The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS-Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.", "paper_title": "A General Software Defect-Proneness Prediction Framework", "paper_id": "WOS:000290934800005"}