{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "mixed_reality_environments"}, {"score": 0.012931230982774818, "phrase": "virtual_humans"}, {"score": 0.00461575768501871, "phrase": "simple_and_robust_mixed_reality"}, {"score": 0.00444559516711374, "phrase": "real-time_interaction"}, {"score": 0.004301834610818624, "phrase": "consistent_illumination"}, {"score": 0.003897742942358768, "phrase": "integrated_and_enhanced_presence"}, {"score": 0.0038431888954930083, "phrase": "interaction_system"}, {"score": 0.003771631577951067, "phrase": "dialogue_module"}, {"score": 0.003649585593445665, "phrase": "speech_recognition"}, {"score": 0.003615443704375908, "phrase": "synthesis_system"}, {"score": 0.003548111729206587, "phrase": "speech_output"}, {"score": 0.0034984340449789745, "phrase": "dialogue_system"}, {"score": 0.0034332736827447654, "phrase": "body_motions"}, {"score": 0.003291051334991867, "phrase": "virtual_human_animation_layer"}, {"score": 0.003125175084962886, "phrase": "normal_key-frame_animations"}, {"score": 0.002939853413763817, "phrase": "previously_recorded_clips"}, {"score": 0.002912331664922248, "phrase": "real-time_idle_motions"}, {"score": 0.0028312983170567948, "phrase": "latter_category"}, {"score": 0.0026508575391771807, "phrase": "flexible_and_realistic_animation"}, {"score": 0.002552946390854313, "phrase": "previous_animation_layer"}, {"score": 0.0024586427394152196, "phrase": "precomputed_radiance_transfer"}, {"score": 0.0024128022009415476, "phrase": "illumination_model"}, {"score": 0.0023566987138026285, "phrase": "realistic_rendition"}, {"score": 0.0021049977753042253, "phrase": "unique_framework"}], "paper_keywords": ["presence", " interaction", " animation", " real-time rendering", " mixed reality"], "paper_abstract": "In this paper, we present a simple and robust mixed reality (MR) framework that allows for real-time interaction with virtual humans in mixed reality environments under consistent illumination. We will look at three crucial parts of this system: interaction, animation and global illumination of virtual humans for an integrated and enhanced presence. The interaction system comprises of a dialogue module, which is interfaced with a speech recognition and synthesis system. Next to speech output, the dialogue system generates face and body motions, which are in turn managed by the virtual human animation layer. Our fast animation engine can handle various types of motions, such as normal key-frame animations, or motions that are generated on-the-fly by adapting previously recorded clips. Real-time idle motions are an example of the latter category. All these different motions are generated and blended on-line, resulting in a flexible and realistic animation. Our robust rendering method operates in accordance with the previous animation layer, based on an extended for virtual humans precomputed radiance transfer (PRT) illumination model, resulting in a realistic rendition of such interactive virtual characters in mixed reality environments. Finally, we present a scenario that illustrates the interplay and application of our methods, glued under a unique framework for presence and interaction in MR.", "paper_title": "Presence and interaction in mixed reality environments", "paper_id": "WOS:000245503600004"}