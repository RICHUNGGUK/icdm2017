{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "threshold_neural_signal_detection"}, {"score": 0.03308128556916549, "phrase": "noise_benefit"}, {"score": 0.004268293864953256, "phrase": "detection_error"}, {"score": 0.004195418010131832, "phrase": "first_theorem"}, {"score": 0.004123781267600542, "phrase": "necessary_and_sufficient_condition"}, {"score": 0.004007083686875716, "phrase": "threshold_neuron"}, {"score": 0.003961330917648707, "phrase": "discrete_binary_signal_detection"}, {"score": 0.0038492126993451337, "phrase": "additive_scale-family_noise"}, {"score": 0.003634371940842838, "phrase": "optimal_noise_probability_density"}, {"score": 0.003513858978092492, "phrase": "gaussian"}, {"score": 0.003431481042678356, "phrase": "second_theorem"}, {"score": 0.003372844338742438, "phrase": "noise-benefit_condition"}, {"score": 0.0032398798149196432, "phrase": "continuous_probability_densities"}, {"score": 0.0031845067058084613, "phrase": "third_and_fourth_theorems"}, {"score": 0.00307657476125683, "phrase": "weighted-derivative_comparison"}, {"score": 0.0030414140732789186, "phrase": "signal_probability_densities"}, {"score": 0.00298942278888105, "phrase": "detection_threshold"}, {"score": 0.002938317647182056, "phrase": "signal_densities"}, {"score": 0.002711109302199029, "phrase": "scale_family"}, {"score": 0.002664749302333897, "phrase": "fifth_theorem"}, {"score": 0.0026191799769765085, "phrase": "collective_noise_benefits"}, {"score": 0.002544951823639408, "phrase": "parallel_array"}, {"score": 0.0025158514649823724, "phrase": "threshold_neurons"}, {"score": 0.0024586427394152196, "phrase": "individual_threshold_neuron"}, {"score": 0.0023346234464901978, "phrase": "stochastic_gradient-ascent_learning_algorithm"}, {"score": 0.0022815262950738814, "phrase": "optimal_noise_value"}, {"score": 0.002255431275670053, "phrase": "noise_probability_densities"}, {"score": 0.0021789194955896102, "phrase": "closed_form"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Optimal noise intensity", " Stochastic resonance", " Threshold neurons", " Signal detection", " Error probability", " Array detection"], "paper_abstract": "Five new theorems and a stochastic learning algorithm show that noise can benefit threshold neural signal detection by reducing the probability of detection error. The first theorem gives a necessary and sufficient condition for such a noise benefit when a threshold neuron performs discrete binary signal detection in the presence of additive scale-family noise. The theorem allows the User to find the optimal noise probability density for several closed-form noise types that include generalized Gaussian noise. The second theorem gives a noise-benefit condition for more general threshold signal detection when the signals have Continuous probability densities. The third and fourth theorems reduce this noise benefit to a weighted-derivative comparison of signal probability densities at the detection threshold when the signal densities are continuously differentiable and when the noise is symmetric and comes from a scale family. The fifth theorem shows how collective noise benefits can occur in a parallel array of threshold neurons even when an individual threshold neuron does not itself produce a noise benefit. The stochastic gradient-ascent learning algorithm can find the optimal noise value for noise probability densities that do not have a closed form. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Error-probability noise benefits in threshold neural signal detection", "paper_id": "WOS:000269808300024"}