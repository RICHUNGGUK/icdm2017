{"auto_keywords": [{"score": 0.03666106118361919, "phrase": "ca-svm"}, {"score": 0.012987541481580244, "phrase": "ca-linear"}, {"score": 0.011965321767357219, "phrase": "ca-dtw"}, {"score": 0.00478557489890886, "phrase": "game-based_virtual_environments"}, {"score": 0.004712913906047687, "phrase": "systematic_exploration"}, {"score": 0.004641351004344458, "phrase": "video_game_context"}, {"score": 0.004392565073466714, "phrase": "large_gesture_sets"}, {"score": 0.0041316803676012155, "phrase": "well-known_rubine_linear_classifier"}, {"score": 0.00399483173553482, "phrase": "contextual_information"}, {"score": 0.0037921662574137535, "phrase": "traditional_dtw"}, {"score": 0.0036777702949712457, "phrase": "multithreaded_kernel"}, {"score": 0.0035668128900149814, "phrase": "per-class_probability_estimation"}, {"score": 0.003501846136829077, "phrase": "contextually_based_prior_probability_distribution"}, {"score": 0.0033857878144822906, "phrase": "kinect-based_third-person_perspective_ve_game_prototype"}, {"score": 0.0033037970113095577, "phrase": "hand-to-hand_combat"}, {"score": 0.0032635467579751423, "phrase": "simple_gesture_collection_application"}, {"score": 0.0031747618267940155, "phrase": "game_prototype"}, {"score": 0.0030414140732789186, "phrase": "first_experiment"}, {"score": 0.0026986685585382347, "phrase": "contextually_aware_classifiers_ca-linear"}, {"score": 0.002469032978674379, "phrase": "second_experiment"}, {"score": 0.0024389277933858054, "phrase": "upper-bound_expectations"}, {"score": 0.002424012799998538, "phrase": "in-game_performance"}, {"score": 0.002286781334850213, "phrase": "in-game_evaluation"}, {"score": 0.0021049977753042253, "phrase": "game_recognition_accuracy"}], "paper_keywords": ["3D gesture recognition", " linear classifier", " dynamic time warping", " context", " video games", " SVM", " context-aware"], "paper_abstract": "We present a systematic exploration of how to utilize video game context (e.g., player and environmental state) to modify and augment existing 3D gesture recognizers to improve accuracy for large gesture sets. Specifically, our work develops and evaluates three strategies for incorporating context into 3D gesture recognizers. These strategies include modifying the well-known Rubine linear classifier to handle unsegmented input streams and per-frame retraining using contextual information (CA-Linear); a GPU implementation of dynamic time warping (DTW) that reduces the overhead of traditional DTW by utilizing context to evaluate only relevant time sequences inside of a multithreaded kernel (CA-DTW); and a multiclass SVM with per-class probability estimation that is combined with a contextually based prior probability distribution (CA-SVM). We evaluate each strategy using a Kinect-based third-person perspective VE game prototype that combines parkour-style navigation with hand-to-hand combat. Using a simple gesture collection application to collect a set of 57 gestures and the game prototype that implements 37 of these gestures, we conduct three experiments. In the first experiment, we evaluate the effectiveness of several established classifiers on our gesture set and demonstrate state-of-the-art results using our proposed method. In our second experiment, we generate 500 random scenarios having between 5 and 19 of the 57 gestures in context. We show that the contextually aware classifiers CA-Linear, CA-DTW, and CA-SVM significantly outperform their non-contextually aware counterparts by 37.74%, 36.04%, and 20.81%, respectively. On the basis of the results of the second experiment, we derive upper-bound expectations for in-game performance for the three CA classifiers: 96.61%, 86.79%, and 96.86%, respectively. Finally, our third experiment is an in-game evaluation of the three CA classifiers with and without context. Our results show that through the use of context, we are able to achieve an average in-game recognition accuracy of 89.67% with CA-Linear compared to 65.10% without context, 79.04% for CA-DTW compared to 58.1% without context, and 90.85% with CA-SVM compared to 75.2% without context.", "paper_title": "Exploring the Benefits of Context in 3D Gesture Recognition for Game-Based Virtual Environments", "paper_id": "WOS:000360088100001"}