{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multiple_body_parts"}, {"score": 0.044027087409931595, "phrase": "human_body"}, {"score": 0.041498983873604636, "phrase": "object_level"}, {"score": 0.004778088905211055, "phrase": "interacting_persons"}, {"score": 0.004441616106463486, "phrase": "mutual_occlusion"}, {"score": 0.004323690117778359, "phrase": "multiple_free-form_blobs"}, {"score": 0.004160612392068268, "phrase": "color_image_sequence"}, {"score": 0.003912335018240945, "phrase": "gaussian_mixture_model"}, {"score": 0.003837817436476726, "phrase": "pixel_level"}, {"score": 0.003764713814123286, "phrase": "individual_pixel"}, {"score": 0.003692997523960715, "phrase": "relaxation_labeling"}, {"score": 0.003650622777534568, "phrase": "attribute_relational_graph"}, {"score": 0.0036226558998405348, "phrase": "arg"}, {"score": 0.0035399770257915466, "phrase": "blob_level"}, {"score": 0.003459191419478298, "phrase": "coherent_blobs"}, {"score": 0.0034063576796640603, "phrase": "inter-blob_relations"}, {"score": 0.0033672608231654897, "phrase": "twofold_tracking_scheme"}, {"score": 0.003290403747743492, "phrase": "blob-to-blob_matching"}, {"score": 0.00322769360059123, "phrase": "blob-to-body-part_association"}, {"score": 0.002977061391551628, "phrase": "coarse_model"}, {"score": 0.002864628676257225, "phrase": "empirical_domain_knowledge"}, {"score": 0.0027458373015999916, "phrase": "intermittent_tracking_failures"}, {"score": 0.0026117657828249137, "phrase": "relational_graph"}, {"score": 0.0024842242921857705, "phrase": "tracking_results"}, {"score": 0.002326767693352058, "phrase": "'hugging'_interactions"}, {"score": 0.002273605493468005, "phrase": "arg-mmt_system"}, {"score": 0.0021708894366462153, "phrase": "recognition_system"}, {"score": 0.002154226045704907, "phrase": "human_interactions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["tracking", " body part", " human interaction", " occlusion", " ARG", " MMT"], "paper_abstract": "This paper presents it framework to simultaneously segment and track multiple body parts of interacting humans in the presence of mutual occlusion and shadow. The framework uses multiple free-form blobs and a coarse model of the human body. The color image sequence is processed at three levels: pixel level, blob level, and object level. A Gaussian mixture model is used at the pixel level to train and classify individual pixel based on color. Relaxation labeling ill an attribute relational graph (ARG) is used at the blob level to merge the pixels into coherent blobs and to represent inter-blob relations. A twofold tracking scheme is used that consists of blob-to-blob matching in consecutive frames and blob-to-body-part association within a frame. The tracking scheme resembles multi-target., multi-association tracking (MMT). A coarse model of the human body is applied at the object level as empirical domain knowledge to resolve ambiguity due to occlusion and to recover from intermittent tracking failures. The result is 'ARG-MMT': 'attribute relational graph based multi-target, multi-association tracker.' The tracking results are demonstrated for various sequences including 'punching,' 'hand-shitking,' 'pushing,' and 'hugging' interactions between two people. This ARG-MMT system may be used as a segmentation and tracking unit for a recognition system for human interactions. (c) 2005 Elsevier Inc. All rights reserved.", "paper_title": "Simultaneous tracking of multiple body parts of interacting persons", "paper_id": "WOS:000236655600001"}