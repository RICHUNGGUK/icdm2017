{"auto_keywords": [{"score": 0.0489853873227799, "phrase": "directional_motion_history_images"}, {"score": 0.0453350952845424, "phrase": "proposed_technique"}, {"score": 0.00481495049065317, "phrase": "automatic_visual_speech_segmentation"}, {"score": 0.004650918334490869, "phrase": "zernike"}, {"score": 0.0045709675813472884, "phrase": "appearance-based_visual_speech_recognition"}, {"score": 0.003910441483033426, "phrase": "popular_optical-flow_method"}, {"score": 0.0037989951856280423, "phrase": "zernike_moments"}, {"score": 0.0037336520904376687, "phrase": "dmhi"}, {"score": 0.003463196032143783, "phrase": "automatic_temporal_segmentation"}, {"score": 0.0034233569308012982, "phrase": "isolated_utterances"}, {"score": 0.0033257460346754687, "phrase": "isolated_utterance"}, {"score": 0.0032496585171039797, "phrase": "pair-wise_pixel_comparison"}, {"score": 0.0029794666460666646, "phrase": "leave-one-out_paradigm"}, {"score": 0.00282822695516646, "phrase": "better_performance"}, {"score": 0.002795671770303977, "phrase": "visemes_recognition"}, {"score": 0.002623184850933423, "phrase": "proposed_visual_speech_recognition_method"}, {"score": 0.002518989593177879, "phrase": "real-time_applications"}, {"score": 0.0024756080101497086, "phrase": "quick_motion_tracking_system"}, {"score": 0.002432971714608409, "phrase": "fast_classification_method"}, {"score": 0.0022828113789751694, "phrase": "lip_movement"}, {"score": 0.0022565201625076876, "phrase": "text_conversion"}, {"score": 0.0021794454466797382, "phrase": "noisy_environment"}, {"score": 0.0021049977753042253, "phrase": "impaired_persons"}], "paper_keywords": ["Motion analysis", " Temporal segmentation", " Directional motion history image", " Optical flow", " Zernike moments"], "paper_abstract": "Appearance-based visual speech recognition using only video signals is presented. The proposed technique is based on the use of directional motion history images (DMHIs), which is an extension of the popular optical-flow method for object tracking. Zernike moments of each DMHI are computed in order to perform the classification. The technique incorporates automatic temporal segmentation of isolated utterances. The segmentation of isolated utterance is achieved using pair-wise pixel comparison. Support vector machine is used for classification and the results are based on leave-one-out paradigm. Experimental results show that the proposed technique achieves better performance in visemes recognition than others reported in literature. The benefit of this proposed visual speech recognition method is that it is suitable for real-time applications due to quick motion tracking system and the fast classification method employed. It has applications in command and control using lip movement to text conversion and can be used in noisy environment and also for assisting speech impaired persons.", "paper_title": "Automatic visual speech segmentation and recognition using directional motion history images and Zernike moments", "paper_id": "WOS:000325115400001"}