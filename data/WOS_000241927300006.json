{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "animation_synthesis"}, {"score": 0.021509894064725407, "phrase": "inverse_kinematics"}, {"score": 0.008991380029652479, "phrase": "minimal_set"}, {"score": 0.00817788825471251, "phrase": "physical_constraints"}, {"score": 0.008095179953920504, "phrase": "articulated_body"}, {"score": 0.0047823219739028325, "phrase": "existing_work"}, {"score": 0.004544521651302002, "phrase": "motion-capture_data"}, {"score": 0.004231249907249981, "phrase": "articulated_object"}, {"score": 0.004048194450210347, "phrase": "body_joint_positions"}, {"score": 0.0038598702839340794, "phrase": "learning_perspective"}, {"score": 0.003545024951402818, "phrase": "physically_impossible_poses"}, {"score": 0.003509006038574667, "phrase": "common_solution"}, {"score": 0.003438058620195309, "phrase": "kinematic_constraints"}, {"score": 0.003403122817578447, "phrase": "skeleton_model"}, {"score": 0.003222687723450745, "phrase": "hierarchical_cluster_model_learnt"}, {"score": 0.0031899334050985175, "phrase": "motion_capture_database"}, {"score": 0.0030936482163040823, "phrase": "learnt_model"}, {"score": 0.0030310732341527168, "phrase": "different_joints"}, {"score": 0.003010496595090984, "phrase": "simultaneous_modelling"}, {"score": 0.002831462722290752, "phrase": "simple_and_efficient_manner"}, {"score": 0.002764746104121352, "phrase": "ik"}, {"score": 0.002690406375639144, "phrase": "end-effector_positions"}, {"score": 0.0026091594819333654, "phrase": "\"learnt_inverse_kinematics\"_framework"}, {"score": 0.002556359086441866, "phrase": "animation_syntheses"}, {"score": 0.002538996868327341, "phrase": "different_types"}, {"score": 0.0025217522723800204, "phrase": "articulated_structures"}, {"score": 0.00240426758768164, "phrase": "flat_surface_walking_animation"}, {"score": 0.002331641523873951, "phrase": "full_human_body_motion"}, {"score": 0.0021049977753042253, "phrase": "torso_positions"}], "paper_keywords": ["learnt inverse kinematics", " animation synthesis", " hierarchical clustering"], "paper_abstract": "Existing work on animation synthesis can be roughly split into two approaches, those that combine segments of motion-capture data, and those that perform inverse kinematics. In this paper, we present a method for performing animation synthesis of an articulated object (e.g. human body and a dog) from a minimal set of body joint positions, following the approach of inverse kinematics. We tackle this problem from a learning perspective. Firstly, we address the need for knowledge on the physical constraints of the articulated body, so as to avoid the generation of a physically impossible poses. A common solution is to heuristically specify the kinematic constraints for the skeleton model. In this paper however, the physical constraints of the articulated body are represented using a hierarchical cluster model learnt from a motion capture database. Additionally, we shall show that the learnt model automatically captures the correlation between different joints through simultaneous modelling of their angles. We then show how this model can be utilised to perform inverse kinematics in a simple and efficient manner. Crucially, we describe how IK is carried out from a minimal set of end-effector positions. Following this, we show how this \"learnt inverse kinematics\" framework can be used to perform animation syntheses on different types of articulated structures. To this end, the results presented include the retargeting of a flat surface walking animation to various uneven terrains to demonstrate the synthesis of a full human body motion from the positions of only the hands, feet and torso. Additionally, we show how the same method can be applied to the animation synthesis of a dog using only its feet and torso positions. (C) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Learnt inverse kinematics for animation synthesis", "paper_id": "WOS:000241927300006"}