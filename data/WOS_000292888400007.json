{"auto_keywords": [{"score": 0.04953037099094609, "phrase": "human_activities"}, {"score": 0.040437138629194604, "phrase": "real_life"}, {"score": 0.027950397072185783, "phrase": "sequential_activity"}, {"score": 0.00481495049065317, "phrase": "sensor-based_human_activity_recognition"}, {"score": 0.004723322467153553, "phrase": "sensor_readings"}, {"score": 0.004615656893404919, "phrase": "pervasive_computing"}, {"score": 0.004458722048888919, "phrase": "assistive_living"}, {"score": 0.003735862292632131, "phrase": "complex_issues"}, {"score": 0.0036646935906338414, "phrase": "existing_models"}, {"score": 0.003636605792981828, "phrase": "interleaved_and_concurrent_activities"}, {"score": 0.003227693600591227, "phrase": "novel_pattern_mining_approach"}, {"score": 0.0031298260299218684, "phrase": "concurrent_activities"}, {"score": 0.0030938932434437178, "phrase": "unified_framework"}, {"score": 0.003046621804854539, "phrase": "emerging_pattern"}, {"score": 0.0029656229252935443, "phrase": "significant_changes"}, {"score": 0.002875678729214613, "phrase": "sensor_features"}, {"score": 0.0027992118597278087, "phrase": "existing_learning-based_approaches"}, {"score": 0.002703869368554536, "phrase": "activity_models"}, {"score": 0.002532526438148958, "phrase": "simple_and_complex_activities"}, {"score": 0.002465161736207254, "phrase": "real-world_traces"}, {"score": 0.0023538120430501392, "phrase": "static_and_temporal_models"}, {"score": 0.002273605493468005, "phrase": "time_slice"}, {"score": 0.002145942273032774, "phrase": "interleaved_activity"}, {"score": 0.0021049977753042253, "phrase": "concurrent_activity"}], "paper_keywords": ["Human activity recognition", " pattern analysis", " emerging pattern", " classifier design and evaluation"], "paper_abstract": "Recognizing human activities from sensor readings has recently attracted much research interest in pervasive computing due to its potential in many applications, such as assistive living and healthcare. This task is particularly challenging because human activities are often performed in not only a simple (i.e., sequential), but also a complex (i.e., interleaved or concurrent) manner in real life. Little work has been done in addressing complex issues in such a situation. The existing models of interleaved and concurrent activities are typically learning-based. Such models lack of flexibility in real life because activities can be interleaved and performed concurrently in many different ways. In this paper, we propose a novel pattern mining approach to recognize sequential, interleaved, and concurrent activities in a unified framework. We exploit Emerging Pattern-a discriminative pattern that describes significant changes between classes of data-to identify sensor features for classifying activities. Different from existing learning-based approaches which require different training data sets for building activity models, our activity models are built upon the sequential activity trace only and can be applied to recognize both simple and complex activities. We conduct our empirical studies by collecting real-world traces, evaluating the performance of our algorithm, and comparing our algorithm with static and temporal models. Our results demonstrate that, with a time slice of 15 seconds, we achieve an accuracy of 90.96 percent for sequential activity, 88.1 percent for interleaved activity, and 82.53 percent for concurrent activity.", "paper_title": "A Pattern Mining Approach to Sensor-Based Human Activity Recognition", "paper_id": "WOS:000292888400007"}