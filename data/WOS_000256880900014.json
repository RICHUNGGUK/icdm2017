{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "upper_bounds"}, {"score": 0.004658426838467567, "phrase": "execution_times"}, {"score": 0.0036352070472201086, "phrase": "necessary_step"}, {"score": 0.0033465923623290034, "phrase": "validation_process"}, {"score": 0.0032376465741070274, "phrase": "hard_real-time_systems"}, {"score": 0.0028360962841331634, "phrase": "underlying_processor_architecture"}, {"score": 0.00240328454980006, "phrase": "branch_prediction"}, {"score": 0.0021049977753042253, "phrase": "different_approaches"}], "paper_keywords": ["verification", " reliability", " hard real time", " worst-case execution times"], "paper_abstract": "The determination of upper bounds on execution times, commonly called worst-case execution times (WCETs), is a necessary step in the development and validation process for hard real-time systems. This problem is hard if the underlying processor architecture has components, such as caches, pipelines, branch prediction, and other speculative components. This article describes different approaches to this problem and surveys several commercially available tools(1) and research prototypes.", "paper_title": "The worst-case execution-time problem - Overview of methods and survey of tools", "paper_id": "WOS:000256880900014"}