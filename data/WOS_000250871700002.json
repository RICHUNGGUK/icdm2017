{"auto_keywords": [{"score": 0.041367212659941525, "phrase": "srs"}, {"score": 0.010612331287242087, "phrase": "large_and_noisy_multimedia_data"}, {"score": 0.004696491408936132, "phrase": "multimedia_data"}, {"score": 0.004412881870378388, "phrase": "information_sources"}, {"score": 0.004376378707877484, "phrase": "machine_learning_algorithms"}, {"score": 0.004304271837157217, "phrase": "large-sized_and_noisy_datasets"}, {"score": 0.004163587877500036, "phrase": "good_sampling"}, {"score": 0.004112020122418323, "phrase": "training_influences"}, {"score": 0.004077995480957875, "phrase": "final_results"}, {"score": 0.003977594755967813, "phrase": "simple_random_sample"}, {"score": 0.003863568356785813, "phrase": "satisfactory_results"}, {"score": 0.003737234606207431, "phrase": "large_and_noisy_dataset"}, {"score": 0.00352597432462803, "phrase": "huge_datasets"}, {"score": 0.00345344412693677, "phrase": "memory_constraints"}, {"score": 0.003285380677401785, "phrase": "multimedia_applications"}, {"score": 0.0032446544415922615, "phrase": "data_size"}, {"score": 0.0030867203659106727, "phrase": "new_and_efficient_method"}, {"score": 0.00292426293067148, "phrase": "simple_distance_measure"}, {"score": 0.00284034646798833, "phrase": "sample_set"}, {"score": 0.002805121439110729, "phrase": "whole_set"}, {"score": 0.002591927716261631, "phrase": "elegant_manner"}, {"score": 0.0024149139610228887, "phrase": "audio_datasets"}, {"score": 0.002316476356455291, "phrase": "proposed_method"}, {"score": 0.002249961956629804, "phrase": "sample_representativeness"}, {"score": 0.002212812864395738, "phrase": "small_sample_sizes"}, {"score": 0.0021049977753042253, "phrase": "least_expensive_method"}], "paper_keywords": ["algorithms", " performance", " sampling", " noise", " histogram", " image classification", " audio event identification"], "paper_abstract": "As the amount of multimedia data is increasing day-by-day thanks to less expensive storage devices and increasing numbers of information sources, machine learning algorithms are faced with large-sized and noisy datasets. Fortunately, the use of a good sampling set for training influences the final results significantly. But using a simple random sample (SRS) may not obtain satisfactory results because such a sample may not adequately represent the large and noisy dataset due to its blind approach in selecting samples. The difficulty is particularly apparent for huge datasets where, due to memory constraints, only very small sample sizes are used. This is typically the case for multimedia applications, where data size is usually very large. In this article we propose a new and efficient method to sample of large and noisy multimedia data. The proposed method is based on a simple distance measure that compares the histograms of the sample set and the whole set in order to estimate the representativeness of the sample. The proposed method deals with noise in an elegant manner which SRS and other methods are not able to deal with. We experiment on image and audio datasets. Comparison with SRS and other methods shows that the proposed method is vastly superior in terms of sample representativeness, particularly for small sample sizes although time-wise it is comparable to SRS, the least expensive method in terms of time.", "paper_title": "Efficient sampling of training set in large and noisy multimedia data", "paper_id": "WOS:000250871700002"}