{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "face_recognition"}, {"score": 0.004790756351382389, "phrase": "person_re-identification"}, {"score": 0.004671588539217021, "phrase": "video_cameras"}, {"score": 0.004589931063884726, "phrase": "capture_conditions"}, {"score": 0.004430854231170318, "phrase": "person_re-identification_applications"}, {"score": 0.004255763014983192, "phrase": "limited_amount"}, {"score": 0.0042343667228600225, "phrase": "reference_samples"}, {"score": 0.004191894957742565, "phrase": "temporal_and_spatial_conditions"}, {"score": 0.004067008258427604, "phrase": "system_responses"}, {"score": 0.004026208353551013, "phrase": "facial_trajectory"}, {"score": 0.003935892934907777, "phrase": "robust_spatio-temporal_recognition"}, {"score": 0.003886592615976175, "phrase": "facial_models"}, {"score": 0.0038475956342813936, "phrase": "operational_data"}, {"score": 0.003780286517897356, "phrase": "adaptive_ensemble-based_system"}, {"score": 0.0037423521744765075, "phrase": "spatio-temporal_face_recognition"}, {"score": 0.003676877371758866, "phrase": "diverse_set"}, {"score": 0.003658380794655729, "phrase": "facial_captures"}, {"score": 0.003487222504700868, "phrase": "artmap_classifiers"}, {"score": 0.0034435227255605787, "phrase": "dynamic_pso-based_learning_strategy"}, {"score": 0.003366233863411861, "phrase": "boolean_combination"}, {"score": 0.0033156708990372047, "phrase": "target_samples"}, {"score": 0.00317648284060926, "phrase": "universal_models"}, {"score": 0.003160495519296451, "phrase": "one-sided_selection"}, {"score": 0.0031208772639433145, "phrase": "facial_trajectories"}, {"score": 0.003073988343893906, "phrase": "individual-specific_ensemble"}, {"score": 0.003020171537471668, "phrase": "target_individuals"}, {"score": 0.0028355237433457313, "phrase": "knowledge_corruption"}, {"score": 0.0028070431733705735, "phrase": "memory_management_strategy"}, {"score": 0.002785870108471127, "phrase": "kullback-leibler_divergence"}, {"score": 0.002744000573794144, "phrase": "stored_validation_samples"}, {"score": 0.0027027586012564548, "phrase": "system's_memory_consumption"}, {"score": 0.0026891491143652083, "phrase": "spatio-temporal_fusion"}, {"score": 0.0026554236621262515, "phrase": "classifier_predictions"}, {"score": 0.002635391215833176, "phrase": "time_window"}, {"score": 0.0026089155578797097, "phrase": "second_threshold"}, {"score": 0.0025892330566358503, "phrase": "self-update_facial_models"}, {"score": 0.0024431733736805057, "phrase": "abrupt_and_gradual_patterns"}, {"score": 0.002406441884512916, "phrase": "transaction_level"}, {"score": 0.0023702613167480607, "phrase": "proposed_system"}, {"score": 0.0023464429394777354, "phrase": "auc_accuracy"}, {"score": 0.002311162358845935, "phrase": "abrupt_changes"}, {"score": 0.002276411038564617, "phrase": "gradual_changes"}, {"score": 0.0022649435091175287, "phrase": "subject-based_analysis"}, {"score": 0.0022252591643049744, "phrase": "different_poses"}, {"score": 0.0021807544600219216, "phrase": "goat-like_individuals"}, {"score": 0.002153391175758982, "phrase": "spatio-temporal_fusion_approaches"}, {"score": 0.002121007106306501, "phrase": "proposed_accumulation_scheme"}, {"score": 0.0021049977753042253, "phrase": "highest_discrimination"}], "paper_keywords": ["Video-to-video face recognition", " Person re-identification", " Adaptive biometrics", " Multi-classifier systems"], "paper_abstract": "Recognizing individuals of interest from faces captured with video cameras raises several challenges linked to changes in capture conditions (e.g., variation in illumination and pose). Moreover, in person re-identification applications, the facial models needed for matching are typically designed a priori, with a limited amount of reference samples captured under constrained temporal and spatial conditions. Tracking can, however, be used to regroup the system responses linked to a facial trajectory (facial captures from a person) for robust spatio-temporal recognition, and to update facial models over time using operational data. In this paper, an adaptive ensemble-based system is proposed for spatio-temporal face recognition (FR). Given a diverse set of facial captures in a trajectory of a target individual, an ensemble of 2-class classifiers is designed. A pool of ARTMAP classifiers is generated using a dynamic PSO-based learning strategy, and classifiers are selected and combined using Boolean combination. To train classifiers, target samples are combined with a set of reference non-target samples selected from the cohort and universal models using One-Sided Selection. During operations, facial trajectories are captured, and each individual-specific ensemble of the system seeks to detect target individuals, and possibly self-update their facial models. To update an ensemble, a learn-and-combine strategy is employed to avoid knowledge corruption, and a memory management strategy based on Kullback-Leibler divergence allows to rank and select stored validation samples over time to bound the system's memory consumption. Spatio-temporal fusion is performed by accumulating classifier predictions over a time window, and a second threshold allows to self-update facial models. The proposed systems were validated with videos from the Face in Action and COX-S2V datasets, that feature both abrupt and gradual patterns of change. At the transaction level, results show that the proposed system allows to increase AUC accuracy by about 3 % for scenarios with abrupt changes, and by about 5 % with gradual changes. Subject-based analysis reveals the difficulties of face recognition with different poses, affecting more significantly the lamb- and goat-like individuals. Compared to reference spatio-temporal fusion approaches, results show that the proposed accumulation scheme produces the highest discrimination.", "paper_title": "An adaptive ensemble-based system for face recognition in person re-identification", "paper_id": "WOS:000358057300003"}