{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "human_behavior"}, {"score": 0.004751216062917875, "phrase": "space-time_silhouette_characterization"}, {"score": 0.004242291530697285, "phrase": "viewpoint_invariance"}, {"score": 0.0034963129868796033, "phrase": "moving_areas"}, {"score": 0.003359119985242403, "phrase": "binary_volume"}, {"score": 0.003163326114997034, "phrase": "moving_person"}, {"score": 0.0031006232333900055, "phrase": "space-time_volume"}, {"score": 0.00260657976055413, "phrase": "action_recognition"}, {"score": 0.0024875444192203485, "phrase": "nearest_neighbor_classifier"}, {"score": 0.002438203996977464, "phrase": "mahanalobis_distance"}, {"score": 0.002250415129116109, "phrase": "seven_persons"}, {"score": 0.0021910825909008946, "phrase": "eight_actions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["behavior recognition", " action recognition", " motion analysis"], "paper_abstract": "In this study, a method for human action recognition is proposed. Only one camera is used, without calibration. Viewpoint invariance is obtained by several acquisitions of the same action. The originality of the method consists in characterizing each sequence globally, to enhance the robustness. After detection of moving areas throughout each image, a binary volume is obtained, composed by all the silhouettes of the moving person. This space-time volume is characterized by a vector of its 3D geometric moments. These moments are normalized to be invariant to the position, scale and duration of actions. Action recognition is then carried out using a nearest neighbor classifier based on Mahanalobis distance. Results are presented on a base of 1614 sequences performed by seven persons and categorized in eight actions. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Recognition of human behavior by space-time silhouette characterization", "paper_id": "WOS:000251440800009"}