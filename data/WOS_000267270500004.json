{"auto_keywords": [{"score": 0.038987763109041416, "phrase": "emerging_cubes"}, {"score": 0.01384176449871971, "phrase": "emerging_cube"}, {"score": 0.013444597288291324, "phrase": "emergence_constraint"}, {"score": 0.00481495049065317, "phrase": "trend_reversals"}, {"score": 0.004658426838467567, "phrase": "interesting_knowledge"}, {"score": 0.0046073860169839305, "phrase": "real_world_context"}, {"score": 0.0040366412779632085, "phrase": "classical_borders"}, {"score": 0.0038624981944755813, "phrase": "storage_space"}, {"score": 0.0038342108263454628, "phrase": "computation_time"}, {"score": 0.003778253716938922, "phrase": "simple_characterization"}, {"score": 0.003615217162972726, "phrase": "cube_navigation_tools"}, {"score": 0.0034975571855450373, "phrase": "classical_and_proposed_borders"}, {"score": 0.003459191419478298, "phrase": "cube_transversals"}, {"score": 0.003309877074892399, "phrase": "great_interest"}, {"score": 0.0031437775259091794, "phrase": "upper_bound"}, {"score": 0.003097865379563127, "phrase": "exact_size"}, {"score": 0.002931569771634119, "phrase": "analytical_estimation"}, {"score": 0.0028993944292191433, "phrase": "database_access"}, {"score": 0.0028360962841331634, "phrase": "probabilistic_counting"}, {"score": 0.00280496585980086, "phrase": "proposed_borders"}, {"score": 0.0027437235598539904, "phrase": "near-optimal_algorithm"}, {"score": 0.0026543514413663893, "phrase": "algorithm_various_iterations"}, {"score": 0.002511803988580901, "phrase": "reduced_and_lossless_representations"}, {"score": 0.0024389277933858054, "phrase": "cube_closure"}, {"score": 0.002368160970983679, "phrase": "different_data_distributions"}, {"score": 0.0022741894748181243, "phrase": "introduced_condensed_and_concise_representations"}, {"score": 0.0021520139248317333, "phrase": "proposed_estimation_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["OLAP mining", " Data warehouse", " Data cube", " Trend analysis", " Cube size estimation", " Closure"], "paper_abstract": "Discovering trend reversals between two data cubes provides users with a novel and interesting knowledge when the real world context fluctuates: What is new? Which trends appear or emerge? Which tendencies are immersing or disappear? With the concept of Emerging Cube, we capture such trend reversals by enforcing an emergence constraint. We resume the classical borders for the Emerging Cube and introduce a new one which optimizes both storage space and computation time, provides a simple characterization of the size of Emerging Cubes, as well as classification and cube navigation tools. We soundly state the connection between the classical and proposed borders by using cube transversals. Knowing the size of Emerging Cubes without computing them is of great interest in particular for adjusting at best the underlying emergence constraint. We address this issue by studying an upper bound and characterizing the exact size of Emerging Cubes. We propose two strategies for quickly estimate their size: one based on analytical estimation, without database access, and one based on probabilistic counting using the proposed borders as the input of the near-optimal algorithm HYPERLOGLOG. Due to the efficiency of the estimation algorithm various iterations can be performed to calibrate at best the emergence constraint. Moreover, we propose reduced and lossless representations of the Emerging Cube by using the concept of cube closure. Finally, we perform experiments for different data distributions in order to measure on one hand the size of the introduced condensed and concise representations and on the other hand the performance (accuracy and computation time) of the proposed estimation method. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Emerging Cubes: Borders, size estimations and lossless reductions", "paper_id": "WOS:000267270500004"}