{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "distributional_clustering"}, {"score": 0.041030905463758836, "phrase": "lsquare"}, {"score": 0.004700027722284931, "phrase": "text_categorization"}, {"score": 0.004435230698216773, "phrase": "ever-increasing_amounts"}, {"score": 0.004329331617724, "phrase": "digital_libraries"}, {"score": 0.0041450181887917135, "phrase": "new_text_categorization_method"}, {"score": 0.0039685202936462815, "phrase": "learning_logic_technique"}, {"score": 0.0038364365168131586, "phrase": "text_classifiers"}, {"score": 0.0037811784409635023, "phrase": "high_dimensionality"}, {"score": 0.0034491650585057754, "phrase": "feature_clustering"}, {"score": 0.003334309053314909, "phrase": "ideal_alternative"}, {"score": 0.003115908199991072, "phrase": "distributional_clustering_method"}, {"score": 0.0030121159909273897, "phrase": "efficient_representation"}, {"score": 0.0029117710453690827, "phrase": "training_text_classifiers"}, {"score": 0.002760778494680823, "phrase": "proposed_method"}, {"score": 0.0027078298877475965, "phrase": "comparable_classification_accuracy"}, {"score": 0.002617759257159818, "phrase": "svm"}, {"score": 0.002592369213499121, "phrase": "exact_experimental_settings"}, {"score": 0.0025549840900344623, "phrase": "small_number"}, {"score": 0.002530359917257626, "phrase": "training_documents"}, {"score": 0.0024818194799172263, "phrase": "webkb"}, {"score": 0.0023079225317714815, "phrase": "good_choice"}, {"score": 0.002252701813819903, "phrase": "limited_amount"}, {"score": 0.002230984431056064, "phrase": "labeled_training_data"}, {"score": 0.002135812692862058, "phrase": "training_size"}, {"score": 0.0021049977753042253, "phrase": "classification_performance"}], "paper_keywords": ["text categorization", " feature selection", " machine learning"], "paper_abstract": "Text categorization is continuing to be one of the most researched NLP problems due to the ever-increasing amounts of electronic documents and digital libraries. In this paper, we present a new text categorization method that combines the distributional clustering of words and a learning logic technique, called Lsquare, for constructing text classifiers. The high dimensionality of text in a document has not been fruitful for the task of categorization, for which reason, feature clustering has been proven to be an ideal alternative to feature selection for reducing the dimensionality. We, therefore, use distributional clustering method (IB) to generate an efficient representation of documents and apply Lsquare for training text classifiers. The method was extensively tested and evaluated. The proposed method achieves higher or comparable classification accuracy and F(1) results compared with SVM on exact experimental settings with a small number of training documents on three benchmark data sets WebKB, 20Newsgroup, and Reuters21578. The results prove that the method is a good choice for applications with a limited amount of labeled training data. We also demonstrate the effect of changing training size on the classification performance of the learners.", "paper_title": "A new text categorization technique using distributional clustering and learning logic", "paper_id": "WOS:000239077800001"}