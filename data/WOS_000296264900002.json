{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "irregular_algorithms"}, {"score": 0.02780171105606632, "phrase": "unordered_algorithms"}, {"score": 0.00469678464293492, "phrase": "computational_science"}, {"score": 0.004469042910390712, "phrase": "irregular_data_structures"}, {"score": 0.00265038878247831, "phrase": "work_efficiency"}, {"score": 0.0021049977753042253, "phrase": "parallel_execution"}], "paper_keywords": ["Irregular Algorithms", " Amorphous Data-parallelism", " Parallel Breadth-first Search", " Single-Source Shortest Path", " Discrete-Event Simulation", " Minimal Spanning Tree", " Multicore processors", " Galois system", " Algorithms", " Languages", " Performance"], "paper_abstract": "Outside of computational science, most problems are formulated in terms of irregular data structures such as graphs, trees and sets. Unfortunately, we understand relatively little about the structure of parallelism and locality in irregular algorithms. In this paper, we study several algorithms for four such problems: discrete-event simulation, single-source shortest path, breadth-first search, and minimal spanning trees. We show that these algorithms can be classified into two categories that we call unordered and ordered, and demonstrate experimentally that there is a trade-off between parallelism and work efficiency: unordered algorithms usually have more parallelism than their ordered counterparts for the same problem, but they may also perform more work. Nevertheless, our experimental results show that unordered algorithms typically lead to more scalable implementations, demonstrating that less work-efficient irregular algorithms may be better for parallel execution.", "paper_title": "Ordered vs. Unordered: a Comparison of Parallelism and Work-efficiency in Irregular Algorithms", "paper_id": "WOS:000296264900002"}