{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "stereoscopic_displays"}, {"score": 0.00464976086880886, "phrase": "online_system"}, {"score": 0.004438250823243621, "phrase": "stereoscopic_environment"}, {"score": 0.004352974291381376, "phrase": "recent_extensions"}, {"score": 0.003996727479807572, "phrase": "naive_depth_estimate"}, {"score": 0.003800026771283179, "phrase": "particular_user"}, {"score": 0.0033952989364738353, "phrase": "parameterized_self-organizing_map"}, {"score": 0.0032914145394036657, "phrase": "essig"}, {"score": 0.0028729252198422825, "phrase": "iterative_solver"}, {"score": 0.002828611294209297, "phrase": "gaze_position"}, {"score": 0.002731381261399358, "phrase": "tracker_acquisition"}, {"score": 0.0026374845514245547, "phrase": "user_study"}, {"score": 0.002566685388128598, "phrase": "psom"}, {"score": 0.0024977819584875573, "phrase": "gaze_depth"}, {"score": 0.0024118962715000197, "phrase": "horizontal_and_vertical_position"}, {"score": 0.0023289568500915207, "phrase": "high_accuracy_wheatstone_haploscope"}, {"score": 0.002301947614465974, "phrase": "medium_accuracy_active_stereo_display"}, {"score": 0.00224013518726087, "phrase": "recommended_method"}, {"score": 0.002188472974132732, "phrase": "gaze_depth_information"}], "paper_keywords": ["Visual Perception", " Stereo", " Stereoscopic displays", " eye tracking", " 3D eye tracking", " vergence"], "paper_abstract": "This article summarizes our previous work on developing an online system to allow the estimation of 3D gaze depth using eye tracking in a stereoscopic environment. We report on recent extensions allowing us to report the full 3D gaze position. Our system employs a 3D calibration process that determines the parameters of a mapping from a naive depth estimate, based simply on triangulation, to a refined 3D gaze point estimate tuned to a particular user. We show that our system is an improvement on the geometry-based 3D gaze estimation returned by a proprietary algorithm provided with our tracker. We also compare our approach with that of the Parameterized Self-Organizing Map (PSOM) method, due to Essig and colleagues, which also individually calibrates to each user. We argue that our method is superior in speed and ease of calibration, is easier to implement, and does not require an iterative solver to produce a gaze position, thus guaranteeing computation at the rate of tracker acquisition. In addition, we report on a user study that indicates that, compared with PSOM, our method more accurately estimates gaze depth, and is nearly as accurate in estimating horizontal and vertical position. Results are verified on two different 4D eye tracking systems, a high accuracy Wheatstone haploscope and a medium accuracy active stereo display. Thus, it is the recommended method for applications that primarily require gaze depth information, while its ease of use makes it suitable for many applications requiring full 3D gaze position.", "paper_title": "Online 3D Gaze Localization on Stereoscopic Displays", "paper_id": "WOS:000335574900003"}