{"auto_keywords": [{"score": 0.050077833883343935, "phrase": "dynamic_inventory_control"}, {"score": 0.04943789244668963, "phrase": "multi-agent_supply-chain_system"}, {"score": 0.04161515974158362, "phrase": "crl"}, {"score": 0.00464517030102152, "phrase": "rl"}, {"score": 0.004322967486451877, "phrase": "machine_intelligence"}, {"score": 0.0041703614123283165, "phrase": "trial-and-error_iterations"}, {"score": 0.0040050835356293365, "phrase": "case-based_reinforcement_learning_algorithm"}, {"score": 0.0038290829316346654, "phrase": "traditional_time-triggered_and_event-triggered_ordering_policies"}, {"score": 0.003611751858608048, "phrase": "dynamic_environment"}, {"score": 0.0034529760173586583, "phrase": "excessive_inventory"}, {"score": 0.0030171910207671205, "phrase": "target_service_level"}, {"score": 0.002963390095037466, "phrase": "multi-agent_simulation"}, {"score": 0.002923668065402269, "phrase": "simplified_two-echelon_supply_chain"}, {"score": 0.0026362590493392785, "phrase": "review_methods"}, {"score": 0.002543043781904587, "phrase": "general_learning_method"}, {"score": 0.0025089420019955232, "phrase": "proposed_one"}, {"score": 0.002398529964696261, "phrase": "supply-chain_management"}, {"score": 0.0023770623950910962, "phrase": "scm"}, {"score": 0.002282667669149476, "phrase": "well-designed_\"connections"}, {"score": 0.002133778742462575, "phrase": "mas"}, {"score": 0.0021049984022903177, "phrase": "scm."}], "paper_keywords": ["Inventory control", " Reinforcement learning", " Supply-chain management", " Multi-agent simulation"], "paper_abstract": "Reinforcement learning (RL) appeals to many researchers in recent years because of its generality. It is an approach to machine intelligence that learns to achieve the given goal by trial-and-error iterations with its environment. This paper proposes a case-based reinforcement learning algorithm (CRL) for dynamic inventory control in a multi-agent supply-chain system. Traditional time-triggered and event-triggered ordering policies remain popular because they are easy to implement. But in the dynamic environment, the results of them may become inaccurate causing excessive inventory (cost) or shortage. Under the condition of nonstationary, customer demand, the S value of (T, S) and (Q, S) inventory review method is learnt using the proposed algorithm for satisfying target service level, respectively. Multi-agent simulation of a simplified two-echelon supply chain, where proposed algorithm is implemented, is run for a few times. The results show the effectiveness of CRL in both review methods. We also consider a framework for general learning method based on proposed one, which may be helpful in all aspects of supply-chain management (SCM). Hence, it is suggested that well-designed \"connections\" are necessary to be built between CRL, multi-agent system (MAS) and SCM. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "Case-based reinforcement learning for dynamic inventory control in a multi-agent supply-chain system", "paper_id": "WOS:000263817100094"}