{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "nearest_neighbor_search"}, {"score": 0.004714869813251479, "phrase": "-d_tree"}, {"score": 0.004552648949390462, "phrase": "first_spatial_data_structures"}, {"score": 0.004274527415193801, "phrase": "high-dimensional_spaces"}, {"score": 0.004041546659145336, "phrase": "overlapping_cells"}, {"score": 0.0033919477901198716, "phrase": "nearest_neighbor"}, {"score": 0.0030319482153908037, "phrase": "simple_potential_function"}, {"score": 0.0028866770996648057, "phrase": "point_configuration"}, {"score": 0.002767696345005216, "phrase": "potential_function"}, {"score": 0.0025264171945423254, "phrase": "doubling_measure"}, {"score": 0.002422249273477746, "phrase": "query_distributions"}, {"score": 0.0022580713471027996, "phrase": "bounded_doubling_dimension"}, {"score": 0.0021049977753042253, "phrase": "topic_model"}], "paper_keywords": ["Nearest neighbor", " Intrinsic dimension", " Spatial partition", " k-d tree", " Random projection"], "paper_abstract": "The -d tree was one of the first spatial data structures proposed for nearest neighbor search. Its efficacy is diminished in high-dimensional spaces, but several variants, with randomization and overlapping cells, have proved to be successful in practice. We analyze three such schemes. We show that the probability that they fail to find the nearest neighbor, for any data set and any query point, is directly related to a simple potential function that captures the difficulty of the point configuration. We then bound this potential function in several situations of interest: when the data are drawn from a doubling measure; when the data and query distributions are identical and are supported on a set of bounded doubling dimension; and when the data are documents from a topic model.", "paper_title": "Randomized Partition Trees for Nearest Neighbor Search", "paper_id": "WOS:000352434300011"}