{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "point_clouds"}, {"score": 0.004782587436296574, "phrase": "enhanced_vector_quantization"}, {"score": 0.004750440867604888, "phrase": "modern_scanners"}, {"score": 0.004671012181488876, "phrase": "huge_quantities"}, {"score": 0.004531357177195719, "phrase": "object's_surface"}, {"score": 0.0044706300051082035, "phrase": "short_time"}, {"score": 0.004193059395895776, "phrase": "interactive_rates"}, {"score": 0.004109023004472115, "phrase": "novel_procedure"}, {"score": 0.003959288961559545, "phrase": "optimized_version"}, {"score": 0.003932654396285872, "phrase": "soft_vector_quantization"}, {"score": 0.0038538167879752137, "phrase": "resulting_technique"}, {"score": 0.003626626504149897, "phrase": "classical_soft_vq_approaches"}, {"score": 0.0035539019235553897, "phrase": "computationally_expensive_iterative_optimization"}, {"score": 0.003412783661090541, "phrase": "adequate_partitioning"}, {"score": 0.003378385493203297, "phrase": "data_space"}, {"score": 0.003266201217790818, "phrase": "computational_time"}, {"score": 0.0031577303835881964, "phrase": "data_points"}, {"score": 0.0030735451757603555, "phrase": "real_applications"}, {"score": 0.0028734504725098802, "phrase": "n."}, {"score": 0.002853396755102163, "phrase": "voxel_side"}, {"score": 0.002777302487818768, "phrase": "data_distribution"}, {"score": 0.002721562843196732, "phrase": "zador's_criterion"}, {"score": 0.0025696192337207155, "phrase": "compression_rate"}, {"score": 0.002501073751997206, "phrase": "nontrained_users"}, {"score": 0.0022145052062614514, "phrase": "evq"}, {"score": 0.0021700361584578633, "phrase": "general_procedure"}, {"score": 0.0021408862709571615, "phrase": "vq_applications"}, {"score": 0.002126458181856629, "phrase": "large_data_sets"}, {"score": 0.0021049977753042253, "phrase": "relatively_low_dimensionality"}], "paper_keywords": ["clustering", " filtering", " point-clouds reduction", " reconstruction error", " space partitioning", " three-dimensional (3-D) scanner"], "paper_abstract": "Modern scanners are able to deliver huge quantities of three-dimensional (3-D) data points sampled on an object's surface, in a short time. These data have to be filtered and their cardinality reduced to come up with a mesh manageable at interactive rates. We introduce here a novel procedure to accomplish these two tasks, which is based on an optimized version of soft vector quantization (VQ). The resulting technique has been termed enhanced vector quantization (EVQ) since it introduces several improvements with respect to the classical soft VQ approaches. These are based on computationally expensive iterative optimization; local computation is introduced here, by means of an adequate partitioning of the data space called hyperbox (HB), to reduce the computational time so as to be linear in the number of data points N, saving more than 80% of time in real applications. Moreover, the algorithm can be fully parallelized, thus leading to an implementation that is sublinear in N. The voxel side and the other parameters are automatically determined from data distribution on the basis of the Zador's criterion. This makes the algorithm completely automatic. Because the only parameter to be specified is the compression rate, the procedure is suitable even for nontrained users. Results obtained in reconstructing faces of both humans and puppets as well as artifacts from point clouds publicly available on the web are reported and discussed, in comparison with other methods available in the literature. EVQ has been conceived as a general procedure, suited for VQ applications with large data sets whose data space has relatively low dimensionality.", "paper_title": "Reducing and filtering point clouds with enhanced vector quantization", "paper_id": "WOS:000243918400014"}