{"auto_keywords": [{"score": 0.044944435151402014, "phrase": "text_lines"}, {"score": 0.010612387000973441, "phrase": "historical_document_images"}, {"score": 0.0087758756896911, "phrase": "grayscale_images"}, {"score": 0.004667149874736771, "phrase": "language_independent_global_method"}, {"score": 0.004630910803911567, "phrase": "automatic_text_line_extraction"}, {"score": 0.004577076689777069, "phrase": "proposed_approach"}, {"score": 0.004523865550323285, "phrase": "energy_map"}, {"score": 0.004471270242168067, "phrase": "text_image"}, {"score": 0.004119762981892093, "phrase": "novel_idea"}, {"score": 0.004055998173160551, "phrase": "binary_images"}, {"score": 0.003931402465972151, "phrase": "first_algorithm"}, {"score": 0.003885668358145471, "phrase": "binary_document_images"}, {"score": 0.0035660913513115267, "phrase": "text_line"}, {"score": 0.003363879163446908, "phrase": "i."}, {"score": 0.003298357357267836, "phrase": "unmarked_component"}, {"score": 0.0032599633778910516, "phrase": "closest_text_line"}, {"score": 0.0032220148724914867, "phrase": "second_algorithm"}, {"score": 0.0031721009574803127, "phrase": "grayscale_document_images"}, {"score": 0.002888396879326153, "phrase": "medial_seams"}, {"score": 0.002821516317503421, "phrase": "separating_seams"}, {"score": 0.0027886573969044042, "phrase": "upper_and_lower_boundaries"}, {"score": 0.002681859084438076, "phrase": "new_benchmark_dataset"}, {"score": 0.00253916011199984, "phrase": "text_line_extraction"}, {"score": 0.0024803459795996116, "phrase": "different_languages"}, {"score": 0.0024419028284236323, "phrase": "arabic"}, {"score": 0.002422947943241213, "phrase": "english"}, {"score": 0.00240404667888379, "phrase": "spanish"}, {"score": 0.002376027109070317, "phrase": "binary_dataset"}, {"score": 0.0023209828061385596, "phrase": "binary_algorithm"}, {"score": 0.0022407927161620855, "phrase": "mentioned_datasets"}, {"score": 0.002223351523626989, "phrase": "report_segmentation_accuracy"}, {"score": 0.002154930852763048, "phrase": "state-of-the-art_text_line_segmentation_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Seam carving", " Line extraction", " Multilingual", " Signed distance transform", " Dynamic programming", " Handwriting"], "paper_abstract": "In this paper we present a language independent global method for automatic text line extraction. The proposed approach computes an energy map of a text image and determines the seams that pass across and between text lines. In this work we have developed two algorithms along this novel idea, one for binary images and the other for grayscale images. The first algorithm works on binary document images and assumes it is possible to extract the components along text lines. The seam passes on the middle and along the text line, I, and marks the components that make the letters and words of I. It then assigns the unmarked component to the closest text line. The second algorithm works directly on grayscale document images. It computes the distance transform directly from the grayscale images and generates two types of seams: medial seams and separating seams. The medial seams determine the text lines and the separating seams define the upper and lower boundaries of these text lines. Moreover, we present a new benchmark dataset of historical document images with various types of challenges. The dataset contains a groundtruth for text line extraction and it contains samples with different languages such as: Arabic, English and Spanish. A binary dataset is used to test the binary algorithm. We performed various experimental results using our two algorithms on the mentioned datasets and report segmentation accuracy. We also compare our algorithms with the state-of-the-art text line segmentation methods. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Text line extraction for historical document images", "paper_id": "WOS:000327561000004"}