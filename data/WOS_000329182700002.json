{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "divergence_analysis"}, {"score": 0.004769958800452922, "phrase": "growing_interest"}, {"score": 0.004725385523804256, "phrase": "graphics_processing_units"}, {"score": 0.0046593017130868, "phrase": "renewed_attention"}, {"score": 0.004572643867232483, "phrase": "simd"}, {"score": 0.004466519142879166, "phrase": "tremendous_computational_power"}, {"score": 0.003615443704375908, "phrase": "different_values"}, {"score": 0.0034171734618737436, "phrase": "data_divergences"}, {"score": 0.0032756158688245, "phrase": "industrial_quality_compiler"}, {"score": 0.003095923814666088, "phrase": "simd_code"}, {"score": 0.003066945490483524, "phrase": "non-simd_cpus"}, {"score": 0.0028580564897994175, "phrase": "automatic_optimization"}, {"score": 0.0028312983170567948, "phrase": "simd_programs"}, {"score": 0.002765490759189057, "phrase": "last_point"}, {"score": 0.002675914969626753, "phrase": "divergence-aware_register_spiller"}, {"score": 0.002552946390854313, "phrase": "rematerialize_or_share_common_data"}, {"score": 0.002323663295811215, "phrase": "well-known_benchmarks"}, {"score": 0.002291089893848235, "phrase": "divergence-aware_spiller"}, {"score": 0.0022698007904626747, "phrase": "gpu"}, {"score": 0.0021450029487459403, "phrase": "register_allocator"}, {"score": 0.0021049977753042253, "phrase": "baseline_compiler"}], "paper_keywords": ["Languages", " Design", " Algorithms", " Performance", " Static program analysis", " divergence analysis", " SIMD", " graphics processing units", " high performance"], "paper_abstract": "Growing interest in graphics processing units has brought renewed attention to the Single Instruction Multiple Data (SIMD) execution model. SIMD machines give application developers tremendous computational power; however, programming them is still challenging. In particular, developers must deal with memory and control-flow divergences. These phenomena stem from a condition that we call data divergence, which occurs whenever two processing elements (PEs) see the same variable name holding different values. This article introduces divergence analysis, a static analysis that discovers data divergences. This analysis, currently deployed in an industrial quality compiler, is useful in several ways: it improves the translation of SIMD code to non-SIMD CPUs, it helps developers to manually improve their SIMD applications, and it also guides the automatic optimization of SIMD programs. We demonstrate this last point by introducing the notion of a divergence-aware register spiller. This spiller uses information from our analysis to either rematerialize or share common data between PEs. As a testimony of its effectiveness, we have tested it on a suite of 395 CUDA kernels from well-known benchmarks. The divergence-aware spiller produces GPU code that is 26.21% faster than the code produced by the register allocator used in the baseline compiler.", "paper_title": "Divergence Analysis", "paper_id": "WOS:000329182700002"}