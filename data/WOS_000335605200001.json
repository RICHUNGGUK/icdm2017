{"auto_keywords": [{"score": 0.046081391722127746, "phrase": "regression_models"}, {"score": 0.004815057755580334, "phrase": "cross-validation"}, {"score": 0.0046650615456476155, "phrase": "classification_models"}, {"score": 0.004143196873246147, "phrase": "high_variance"}, {"score": 0.003998286635727259, "phrase": "practical_applications"}, {"score": 0.003966776222128288, "phrase": "qsar."}, {"score": 0.0038431888954930083, "phrase": "best_practices"}, {"score": 0.0037234376132464463, "phrase": "selected_models"}, {"score": 0.0036794956254952126, "phrase": "key_operational_component"}, {"score": 0.0036360703245710124, "phrase": "proposed_methods"}, {"score": 0.003607404191062938, "phrase": "cloud_computing"}, {"score": 0.0035648266669315943, "phrase": "routine_use"}, {"score": 0.003536720212056521, "phrase": "previously_infeasible_approaches"}, {"score": 0.0033860360186761533, "phrase": "repeated_grid-search_v-fold_cross-validation"}, {"score": 0.0032161835102640372, "phrase": "repeated_nested_cross-validation_algorithm"}, {"score": 0.003128270147867462, "phrase": "variable_selection"}, {"score": 0.0031035949505887083, "phrase": "parameter_tuning"}, {"score": 0.0028110458014332187, "phrase": "repeated_grid-search"}, {"score": 0.0027778413437997613, "phrase": "general_case"}, {"score": 0.002669959049383929, "phrase": "seven_qsar_datasets"}, {"score": 0.002607246047604476, "phrase": "prediction_performance"}, {"score": 0.0025259082947443343, "phrase": "different_splits"}, {"score": 0.0024763626300729575, "phrase": "v-fold_cross-validation"}, {"score": 0.0022162970216404927, "phrase": "optimal_model"}, {"score": 0.002138636271204459, "phrase": "nested_cross-validation"}, {"score": 0.0021049977753042253, "phrase": "prediction_error"}], "paper_keywords": [""], "paper_abstract": "Background: We address the problem of selecting and assessing classification and regression models using cross-validation. Current state-of-the-art methods can yield models with high variance, rendering them unsuitable for a number of practical applications including QSAR. In this paper we describe and evaluate best practices which improve reliability and increase confidence in selected models. A key operational component of the proposed methods is cloud computing which enables routine use of previously infeasible approaches. Methods: We describe in detail an algorithm for repeated grid-search V-fold cross-validation for parameter tuning in classification and regression, and we define a repeated nested cross-validation algorithm for model assessment. As regards variable selection and parameter tuning we define two algorithms (repeated grid-search cross-validation and double cross-validation), and provide arguments for using the repeated grid-search in the general case. Results: We show results of our algorithms on seven QSAR datasets. The variation of the prediction performance, which is the result of choosing different splits of the dataset in V-fold cross-validation, needs to be taken into account when selecting and assessing classification and regression models. Conclusions: We demonstrate the importance of repeating cross-validation when selecting an optimal model, as well as the importance of repeating nested cross-validation when assessing a prediction error.", "paper_title": "Cross-validation pitfalls when selecting and assessing regression and classification models", "paper_id": "WOS:000335605200001"}