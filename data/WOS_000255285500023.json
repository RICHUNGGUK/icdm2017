{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "gpu_cluster"}, {"score": 0.008459693423397939, "phrase": "zippy"}, {"score": 0.004544629724830453, "phrase": "attractive_platform"}, {"score": 0.004492406361795448, "phrase": "large_scale_general-purpose_computation"}, {"score": 0.004289419884432487, "phrase": "programming_model"}, {"score": 0.004240116703465252, "phrase": "high_performance_general-purpose_computation"}, {"score": 0.004191537267607188, "phrase": "gpu"}, {"score": 0.004095567486538121, "phrase": "complex_problem"}, {"score": 0.003887894704361635, "phrase": "zippy_frame-work"}, {"score": 0.0035855066449812273, "phrase": "gpu_cluster_programming"}, {"score": 0.003523822585025555, "phrase": "two-level_parallelism_hierarchy"}, {"score": 0.003463196032143783, "phrase": "non-uniform_memory_access"}, {"score": 0.0032309093154028663, "phrase": "message_passing"}, {"score": 0.0031937337757356526, "phrase": "shared-memory_models"}, {"score": 0.003120657021758196, "phrase": "global_arrays"}, {"score": 0.0028944757265206332, "phrase": "multiple_gpus"}, {"score": 0.002795671770303977, "phrase": "data_locality"}, {"score": 0.0027159094186967247, "phrase": "optimal_performance"}, {"score": 0.002447101794397243, "phrase": "cubes_isosurface_extraction"}, {"score": 0.002377260665147444, "phrase": "lattice_boltzmann_flow_simulation"}, {"score": 0.0021668575137633317, "phrase": "parallel_visualization"}, {"score": 0.0021049977753042253, "phrase": "computation_modules"}], "paper_keywords": [""], "paper_abstract": "Due to its high performance/cost ratio, a GPU cluster is an attractive platform for large scale general-purpose computation and visualization applications. However, the programming model for high performance general-purpose computation on GPU clusters remains a complex problem. In this paper, we introduce the Zippy frame-work, a general and scalable solution to this problem. It abstracts the GPU cluster programming with a two-level parallelism hierarchy and a non-uniform memory access (NUMA) model. Zippy preserves the advantages of both message passing and shared-memory models. It employs global arrays (GA) to simplify the communication, synchronization, and collaboration among multiple GPUs. Moreover, it exposes data locality to the programmer for optimal performance and scalability. We present three example applications developed with Zippy: sort-last volume rendering, Marching Cubes isosurface extraction and rendering, and lattice Boltzmann flow simulation with online visualization. They demonstrate that Zippy can ease the development and integration of parallel visualization, graphics, and computation modules on a GPU cluster.", "paper_title": "Zippy: A framework for computation and visualization on a GPU cluster", "paper_id": "WOS:000255285500023"}