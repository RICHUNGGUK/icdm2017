{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "salient_region_detection"}, {"score": 0.04083790901679277, "phrase": "different_feature_maps"}, {"score": 0.0355691858622509, "phrase": "bottom-up_feature_maps"}, {"score": 0.028924345435916012, "phrase": "proposed_fusion_method"}, {"score": 0.025498182661174745, "phrase": "salient_regions"}, {"score": 0.004781498797706604, "phrase": "fusing_bottom-up"}, {"score": 0.00474827840031692, "phrase": "top-down_features"}, {"score": 0.004682525167261325, "phrase": "single_image"}, {"score": 0.004601606675066839, "phrase": "global_contrast-based_salient_region_detection_models"}, {"score": 0.003919515745050147, "phrase": "existing_fusion_methods"}, {"score": 0.0038383157378810277, "phrase": "simple_averaging_method"}, {"score": 0.003798346343693706, "phrase": "selective_method"}, {"score": 0.0036425727071563965, "phrase": "existing_salient_region_detection_models"}, {"score": 0.0035795609511543023, "phrase": "novel_salient_region_model"}, {"score": 0.0035299344877334385, "phrase": "bottom-up_and_top-down_mechanisms"}, {"score": 0.0033265580369717996, "phrase": "top-down_cue"}, {"score": 0.0031348622158167195, "phrase": "final_salient_regions"}, {"score": 0.003027286031578399, "phrase": "photographer's_preference"}, {"score": 0.002754863452181364, "phrase": "feature_maps"}, {"score": 0.002697726021470387, "phrase": "adaptive_weights"}, {"score": 0.002641770514171764, "phrase": "confidence_level"}, {"score": 0.002614228362365338, "phrase": "feature_map"}, {"score": 0.002498150733439951, "phrase": "significant_top-down_feature"}, {"score": 0.002370589610989257, "phrase": "fusion_process"}, {"score": 0.002218299213266519, "phrase": "experimental_results"}, {"score": 0.0021875036343988806, "phrase": "proposed_model"}], "paper_keywords": ["Human visual system (HVS)", " salient region detection", " bottom-up and top-down visual attention"], "paper_abstract": "Recently, some global contrast-based salient region detection models have been proposed based on only the low-level feature of color. It is necessary to consider both color and orientation features to overcome their limitations, and thus improve the performance of salient region detection for images with low-contrast in color and high-contrast in orientation. In addition, the existing fusion methods for different feature maps, like the simple averaging method and the selective method, are not effective sufficiently. To overcome these limitations of existing salient region detection models, we propose a novel salient region model based on the bottom-up and top-down mechanisms: the color contrast and orientation contrast are adopted to calculate the bottom-up feature maps, while the top-down cue of depth-from-focus from the same single image is used to guide the generation of final salient regions, since depth-from-focus reflects the photographer's preference and knowledge of the task. A more general and effective fusion method is designed to combine the bottom-up feature maps. According to the degree-of-scattering and eccentricities of feature maps, the proposed fusion method can assign adaptive weights to different feature maps to reflect the confidence level of each feature map. The depth-from-focus of the image as a significant top-down feature for visual attention in the image is used to guide the salient regions during the fusion process; with its aid, the proposed fusion method can filter out the background and highlight salient regions for the image. Experimental results show that the proposed model outperforms the state-of-the-art models on three public available data sets.", "paper_title": "Salient Region Detection by Fusing Bottom-Up and Top-Down Features Extracted From a Single Image", "paper_id": "WOS:000345531500007"}