{"auto_keywords": [{"score": 0.028348389990739437, "phrase": "gm_proposal"}, {"score": 0.00481495049065317, "phrase": "bayesian_inversion"}, {"score": 0.004771196027464407, "phrase": "multimodal_distributions"}, {"score": 0.004727837281331949, "phrase": "parametric_uncertainties"}, {"score": 0.004414907432703781, "phrase": "inverse_modeling_procedure"}, {"score": 0.004335000368745273, "phrase": "simulation_results"}, {"score": 0.004237138632255772, "phrase": "real_system"}, {"score": 0.004141476915000558, "phrase": "bayes'_rule"}, {"score": 0.004085115444878828, "phrase": "general_approach"}, {"score": 0.0040479661688863884, "phrase": "inverse_modeling_problems"}, {"score": 0.00393852508392789, "phrase": "posterior_distribution"}, {"score": 0.0038849148160362257, "phrase": "uncertain_model_parameters"}, {"score": 0.0037454814403672697, "phrase": "large_number"}, {"score": 0.003711409222544974, "phrase": "repetitive_forward_simulations"}, {"score": 0.0036441884295335502, "phrase": "sampling_process"}, {"score": 0.0035781807623238905, "phrase": "prohibitive_computational_burden"}, {"score": 0.0032805541677236325, "phrase": "adaptive_importance_sampling_algorithm"}, {"score": 0.002993887707344862, "phrase": "proposal_distribution"}, {"score": 0.0027954035431845344, "phrase": "polynomial_chaos"}, {"score": 0.0026220103561723045, "phrase": "surrogate_model"}, {"score": 0.0025744696954056404, "phrase": "computational_burden"}, {"score": 0.002539379289856756, "phrase": "computational-demanding_forward_model_evaluations"}, {"score": 0.0024481198073210567, "phrase": "proposed_adaptive_importance_sampling_algorithm"}, {"score": 0.002327956449278255, "phrase": "appropriate_number"}, {"score": 0.002275299774554847, "phrase": "specific_problem"}, {"score": 0.0021243539405631866, "phrase": "limited_number"}, {"score": 0.0021049977753042253, "phrase": "forward_simulations"}], "paper_keywords": ["Inverse modeling", " Uncertainty reduction", " Adaptive sampling", " Gaussian mixture", " Mixture of polynomial chaos expansions"], "paper_abstract": "Parametric uncertainties are encountered in the simulations of many physical systems, and may be reduced by an inverse modeling procedure that calibrates the simulation results to observations on the real system being simulated. Following Bayes' rule, a general approach for inverse modeling problems is to sample from the posterior distribution of the uncertain model parameters given the observations. However, the large number of repetitive forward simulations required in the sampling process could pose a prohibitive computational burden. This difficulty is particularly challenging when the posterior is multimodal. We present in this paper an adaptive importance sampling algorithm to tackle these challenges. Two essential ingredients of the algorithm are: 1) a Gaussian mixture (GM) model adaptively constructed as the proposal distribution to approximate the possibly multimodal target posterior, and 2) a mixture of polynomial chaos (PC) expansions, built according to the GM proposal, as a surrogate model to alleviate the computational burden caused by computational-demanding forward model evaluations. In three illustrative examples, the proposed adaptive importance sampling algorithm demonstrates its capabilities of automatically finding a GM proposal with an appropriate number of modes for the specific problem under study, and obtaining a sample accurately and efficiently representing the posterior with limited number of forward simulations. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "An adaptive importance sampling algorithm for Bayesian inversion with multimodal distributions", "paper_id": "WOS:000354120200011"}