{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "graph_integration"}, {"score": 0.0047267100475487595, "phrase": "protein_functional_classification"}, {"score": 0.0046544071297876695, "phrase": "protein_function"}, {"score": 0.004611554879923759, "phrase": "central_problem"}, {"score": 0.004513087388483271, "phrase": "partially_or_fully_automated_methods"}, {"score": 0.003880017219275826, "phrase": "accurate_predictions"}, {"score": 0.003750529559133893, "phrase": "available_sources"}, {"score": 0.0036030386046805598, "phrase": "positive_signals"}, {"score": 0.0034613276345111543, "phrase": "functional_prediction"}, {"score": 0.0033768959341690524, "phrase": "inaccurate_or_false_edges"}, {"score": 0.003244050414264445, "phrase": "prediction_accuracy"}, {"score": 0.0031845067058084583, "phrase": "noise_levels"}, {"score": 0.003145417398038261, "phrase": "integration_efficiency"}, {"score": 0.0030876784650745973, "phrase": "recent_method"}, {"score": 0.0030686679245324837, "phrase": "graph-based_learning"}, {"score": 0.0029937855454238507, "phrase": "theoretically_firm"}, {"score": 0.0029297595441334823, "phrase": "protein_similarity_graphs"}, {"score": 0.002687022487756706, "phrase": "protein_similarity_measures"}, {"score": 0.002629539710839523, "phrase": "classification_accuracy"}, {"score": 0.0026052812376885504, "phrase": "test_set"}, {"score": 0.0025732834751685803, "phrase": "remote_sequence_homology"}, {"score": 0.0023382335380460304, "phrase": "roc_curve"}, {"score": 0.0022531089868518235, "phrase": "increased_sparsity"}, {"score": 0.002157697367447098, "phrase": "negligible_computational_cost"}], "paper_keywords": [""], "paper_abstract": "Motivation: Predicting protein function is a central problem in bioinformatics, and many approaches use partially or fully automated methods based on various combination of sequence, structure and other information on proteins or genes. Such information establishes relationships between proteins that can be modelled most naturally as edges in graphs. A priori, however, it is often unclear which edges from which graph may contribute most to accurate predictions. For that reason, one established strategy is to integrate all available sources, or graphs as in graph integration, in the hope that the positive signals will add to each other. However, in the problem of functional prediction, noise, i.e. the presence of inaccurate or false edges, can still be large enough that integration alone has little effect on prediction accuracy. In order to reduce noise levels and to improve integration efficiency, we present here a recent method in graph-based learning, graph sharpening, which provides a theoretically firm yet intuitive and practical approach for disconnecting undesirable edges from protein similarity graphs. This approach has several attractive features: it is quick, scalable in the number of proteins, robust with respect to errors and tolerant of very diverse types of protein similarity measures. Results: We tested the classification accuracy in a test set of 599 proteins with remote sequence homology spread over 20 Gene Ontology (GO) functional classes. When compared to integration alone, graph sharpening plus integration of four vastly different molecular similarity measures improved the overall classification by nearly 30 [0.17 average increase in the area under the ROC curve (AUC)]. Moreover, and partially through the increased sparsity of the graphs induced by sharpening, this gain in accuracy came at negligible computational cost: sharpening and integration took on average 4.66 (4.44) CPU seconds.", "paper_title": "Graph sharpening plus graph integration: a synergy that improves protein functional classification", "paper_id": "WOS:000251334800015"}