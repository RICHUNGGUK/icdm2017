{"auto_keywords": [{"score": 0.04243745322817866, "phrase": "elec"}, {"score": 0.00481495049065317, "phrase": "enhanced_lipschitz_embedding_classifier"}, {"score": 0.00443308765153716, "phrase": "enhanced_lipschitz_embedding"}, {"score": 0.004112175423546628, "phrase": "speech_signals"}, {"score": 0.003990385737207714, "phrase": "geodesic_distance"}, {"score": 0.0038721890530859578, "phrase": "intrinsic_geometry"}, {"score": 0.003729335910488339, "phrase": "speech_corpus"}, {"score": 0.0036188435232325337, "phrase": "euclidean_distance"}, {"score": 0.003485304124598714, "phrase": "minimal_geodesic_distance"}, {"score": 0.003382017342396959, "phrase": "different_emotions"}, {"score": 0.0032571885279065126, "phrase": "high_dimensional_feature"}, {"score": 0.0031606404966938568, "phrase": "lower_space"}, {"score": 0.003043957650600757, "phrase": "class_labels"}, {"score": 0.002976019715894587, "phrase": "neighbor_training_vectors"}, {"score": 0.0029095936591723645, "phrase": "compressed_low_space"}, {"score": 0.0028021527740710508, "phrase": "test_data"}, {"score": 0.0027602925235474317, "phrase": "six_archetypal_emotional_states"}, {"score": 0.002465593351432208, "phrase": "experimental_results"}, {"score": 0.0024287485834314027, "phrase": "clear_and_noisy_data"}, {"score": 0.0023040642263522505, "phrase": "traditional_methods"}, {"score": 0.0022696277881969896, "phrase": "dimensionality_reduction"}, {"score": 0.0021049977753042253, "phrase": "speaker-independent_emotion_recognition"}], "paper_keywords": ["Enhanced Lipschitz embedding", " emotion recognition", " dimensionality reduction"], "paper_abstract": "This paper proposes an Enhanced Lipschitz Embedding based Classifier (ELEC) for the classification of multi-emotions from speech signals. ELEC adopts geodesic distance to preserve the intrinsic geometry at all scales of speech corpus, instead of Euclidean distance. Based on the minimal geodesic distance to vectors of different emotions, ELEC maps the high dimensional feature vectors into a lower space. Through analyzing the class labels of the neighbor training vectors in the compressed low space, ELEC classifies the test data into six archetypal emotional states, i.e. neutral, anger, fear, happiness, sadness and surprise. Experimental results on clear and noisy data set demonstrate that compared with the traditional methods of dimensionality reduction and classification, ELEC achieves 15% improvement on average for speaker-independent emotion recognition and 11% for speaker-dependent.", "paper_title": "AN ENHANCED LIPSCHITZ EMBEDDING CLASSIFIER FOR MULTI-EMOTION SPEECH ANALYSIS", "paper_id": "WOS:000273425500007"}