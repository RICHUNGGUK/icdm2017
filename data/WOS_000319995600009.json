{"auto_keywords": [{"score": 0.03325556933091906, "phrase": "sparse_ls-svm."}, {"score": 0.031042443925142046, "phrase": "ls-svm"}, {"score": 0.00481495049065317, "phrase": "hyper-parameter_selection"}, {"score": 0.004758457292840376, "phrase": "sparse_ls-svm_via_minimization"}, {"score": 0.004459334186889869, "phrase": "better_generalization_capability"}, {"score": 0.00438105507792004, "phrase": "prediction_time"}, {"score": 0.004278807087784626, "phrase": "full_dense_ls-svm."}, {"score": 0.004129873531628877, "phrase": "careful_selection"}, {"score": 0.003939296259436904, "phrase": "high_generalization_capability"}, {"score": 0.003541923233726252, "phrase": "cross_validation"}, {"score": 0.00333869177584604, "phrase": "ls-svms"}, {"score": 0.0031845067058084583, "phrase": "good_hyper-parameters"}, {"score": 0.0030195184114140063, "phrase": "new_hyper-parameter_selection_method"}, {"score": 0.002984027623988469, "phrase": "lgem-hps"}, {"score": 0.002846175473457555, "phrase": "localized_generalization"}, {"score": 0.0025892330566358503, "phrase": "square_error"}, {"score": 0.0025587867729949037, "phrase": "sensitivity_measure"}, {"score": 0.0025137856138000014, "phrase": "new_sensitivity_measure"}, {"score": 0.0023139986108451967, "phrase": "smaller_training_error"}, {"score": 0.002286781334850213, "phrase": "minimum_sensitivity"}, {"score": 0.002259883463607508, "phrase": "minor_changes"}, {"score": 0.002181069180139225, "phrase": "eleven_uci_data_sets"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Least squares support vector machine (LS-SVM)", " localized generalization error model (L-GEM)", " sensitivity measure", " hyper-parameter selection", " sparsity"], "paper_abstract": "Sparse LS-SVM yields better generalization capability and reduces prediction time in comparison to full dense LS-SVM. However, both methods require careful selection of hyper-parameters (HPS) to achieve high generalization capability. Leave-One-Out Cross Validation (LOO-CV) and k-fold Cross Validation (k-CV) are the two most widely used hyper-parameter selection methods for LS-SVMs. However, both fail to select good hyper-parameters for sparse LS-SVM. In this paper we propose a new hyper-parameter selection method, LGEM-HPS, for LS-SVM via minimization of the Localized Generalization Error (L-GEM). The L-GEM consists of two major components: empirical mean square error and sensitivity measure. A new sensitivity measure is derived for LS-SVM to enable the LGEM-HPS select hyper-parameters yielding LS-SVM with smaller training error and minimum sensitivity to minor changes in inputs. Experiments on eleven UCI data sets show the effectiveness of the proposed method for selecting hyper-parameters for sparse LS-SVM.", "paper_title": "HYPER-PARAMETER SELECTION FOR SPARSE LS-SVM VIA MINIMIZATION OF ITS LOCALIZED GENERALIZATION ERROR", "paper_id": "WOS:000319995600009"}