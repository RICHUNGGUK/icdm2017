{"auto_keywords": [{"score": 0.024178155617610865, "phrase": "nicta"}, {"score": 0.00481495049065317, "phrase": "pedestrian_detection"}, {"score": 0.004716031208088975, "phrase": "existing_methods"}, {"score": 0.004677032188041644, "phrase": "pedestrian_detection_work"}, {"score": 0.004394592555435104, "phrase": "training_dataset"}, {"score": 0.0043401761815767, "phrase": "testing_dataset"}, {"score": 0.004250969091124481, "phrase": "feature_space"}, {"score": 0.00399415558125301, "phrase": "scene_complexity"}, {"score": 0.003847546889061499, "phrase": "new_method"}, {"score": 0.0036756196381448015, "phrase": "transfer_learning_technique"}, {"score": 0.003540661500026125, "phrase": "pedestrian_detection_performance"}, {"score": 0.0033824008297657494, "phrase": "basic_idea"}, {"score": 0.003285380677401785, "phrase": "training_set"}, {"score": 0.00313849462329633, "phrase": "unseen_scene"}, {"score": 0.0030611534228319717, "phrase": "selected_samples"}, {"score": 0.0030231983220281836, "phrase": "unseen_set"}, {"score": 0.002960979624379786, "phrase": "new_classification_model"}, {"score": 0.0029242629306714773, "phrase": "transfer_learning"}, {"score": 0.002828556054338357, "phrase": "classification_model"}, {"score": 0.002690820958068933, "phrase": "unseen_scenes"}, {"score": 0.0026354246446771324, "phrase": "training_samples"}, {"score": 0.0025704485156071463, "phrase": "training_scene"}, {"score": 0.002496659907186784, "phrase": "entire_training_samples"}, {"score": 0.0024452510143564057, "phrase": "traditional_pedestrian_detection_methods"}, {"score": 0.0024149139610228887, "phrase": "proposed_algorithm"}, {"score": 0.0023750478314945303, "phrase": "different_scenes"}, {"score": 0.0021944684609599245, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Pedestrian detection", " Scene change", " Manifold learning", " Transfer learning"], "paper_abstract": "Most of the existing methods for pedestrian detection work well, only when the following assumption is satisfied: the features extracted from the training dataset and the testing dataset have very similar distributions in the feature space. However, in practice, this assumption does not hold because of the scene complexity and variation. In this paper, a new method is proposed for detecting pedestrians in various scenes based on the transfer learning technique. Our proposed method employs the following two strategies for improving the pedestrian detection performance. First, a new sample screening method based on manifold learning is proposed. The basic idea is to choose samples from the training set, which may be similar to the samples from the unseen scene, and then merge the selected samples into the unseen set. Second, a new classification model based on transfer learning is proposed. The advantage of the classification model is that only a small number of samples need to be used from the unseen scenes. Most of the training samples are still obtained from the training scene, which take up to 90% of the entire training samples. Compared to the traditional pedestrian detection methods, the proposed algorithm can adapt to different scenes for detecting pedestrians. Experiments on two pedestrian detection benchmark datasets, DC and NICTA, showed that the method can obtain better performance as compared to other previous methods. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Transfer learning for pedestrian detection", "paper_id": "WOS:000312175500006"}