{"auto_keywords": [{"score": 0.047561873019288416, "phrase": "nca"}, {"score": 0.03671665642897199, "phrase": "pca"}, {"score": 0.028689653408013865, "phrase": "lap"}, {"score": 0.013970052654071276, "phrase": "face_recognition"}, {"score": 0.010454509303651546, "phrase": "comparative_study"}, {"score": 0.009501683555234827, "phrase": "sss_problem"}, {"score": 0.009145103974957268, "phrase": "dcv"}, {"score": 0.00481495049065317, "phrase": "neighbourhood_components_analysis"}, {"score": 0.0047597635659244655, "phrase": "small_sample_size_problem"}, {"score": 0.004723322467153553, "phrase": "discriminant_common_vectors"}, {"score": 0.004340343873304156, "phrase": "linear_projection_matrices"}, {"score": 0.004307099985737249, "phrase": "dimensionality_reduction"}, {"score": 0.004160612392068268, "phrase": "sample_space"}, {"score": 0.003650622777534568, "phrase": "different_objective_functions"}, {"score": 0.003512841739654183, "phrase": "principal_component_analysis"}, {"score": 0.0034227128856749185, "phrase": "linear"}, {"score": 0.0034063576796640603, "phrase": "discriminant_analysis"}, {"score": 0.003290403747743492, "phrase": "classification_accuracy"}, {"score": 0.002820850247525606, "phrase": "projection_matrix"}, {"score": 0.0027564303939865476, "phrase": "optimal_solution"}, {"score": 0.0023995846112991625, "phrase": "linear_dimensionality_reduction"}, {"score": 0.002381169982803105, "phrase": "subsequent_classification"}, {"score": 0.002291194794507377, "phrase": "orl"}, {"score": 0.002256160492562828, "phrase": "yale"}, {"score": 0.002154226045704907, "phrase": "future_study"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Principal component analysis (PCA)", " linear discriminant analysis (LDA)", " discriminant common vectors (DCV)", " neighbourhood components analysis (NCA)", " Laplacianfaces (LAP)", " small sample size (SSS)", " face recognition"], "paper_abstract": "Discriminant common vectors (DCV), neighbourhood components analysis (NCA) and Laplacianfaces (LAP) are three recently proposed methods which can effectively learn linear projection matrices for dimensionality reduction in face recognition. where the dimension of the sample space is typically larger than the number of samples in the training set and consequently the so-called small sample size (SSS) problem exists. The three methods obtained their respective projection matrices based on different objective functions and all claimed to be superior to such methods as Principal component analysis (PCA) and PCA plus Linear discriminant analysis (PCA + LDA) in terms of classification accuracy. However, in literature, no comparative study is carried out among them. In this paper, we carry out a comparative study among them in face recognition (or generally in the SSS problem), and argue that the projection matrix yielded by DCV is the optimal solution to both NCA and LAP in terms of their respective objective functions, whereas neither NCA nor LAP may get their own optimal solutions. In addition, we show that DCV is more efficient than both NCA and LAP for both linear dimensionality reduction and subsequent classification in SSS problem. Finally, experiments are conducted on ORL, AR and YALE face databases to verify out-arguments and to present some insights for future study. (c) 2005 Elsevier B.V. All rights reserved.", "paper_title": "Discriminant common vectors versus neighbourhood components analysis and Laplacianfaces: A comparative study in small sample size problem", "paper_id": "WOS:000236716100004"}