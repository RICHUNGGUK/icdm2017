{"auto_keywords": [{"score": 0.04417301402964413, "phrase": "nui"}, {"score": 0.00481495049065317, "phrase": "pose_kernel"}, {"score": 0.004626680470601208, "phrase": "recent_popularization"}, {"score": 0.004574247691703376, "phrase": "real_time_depth_sensors"}, {"score": 0.00447115003744675, "phrase": "potential_applications"}, {"score": 0.004420472010542188, "phrase": "online_gesture_recognition"}, {"score": 0.004104722208522451, "phrase": "significant_robustness"}, {"score": 0.004035107125458193, "phrase": "gesture_recognition"}, {"score": 0.0039216854691927865, "phrase": "noisy_data"}, {"score": 0.0038551626276406175, "phrase": "popular_depth_sensor"}, {"score": 0.0035796471115594553, "phrase": "recognition_execution_speed"}, {"score": 0.003419943984098415, "phrase": "real-time_gesture_recognition"}, {"score": 0.0033619033669956317, "phrase": "noisy_skeleton_stream"}, {"score": 0.0032302647179383915, "phrase": "kinect_depth_sensors"}, {"score": 0.00308610073274614, "phrase": "angular_representation"}, {"score": 0.0030337085953063125, "phrase": "skeleton_joints"}, {"score": 0.0029148831519944358, "phrase": "key_poses"}, {"score": 0.0028653893877383188, "phrase": "support_vector_machine_multi-class_classifier"}, {"score": 0.002585539416877115, "phrase": "key_pose_sequence"}, {"score": 0.0025416235470290286, "phrase": "decision_forest"}, {"score": 0.0023329572140896237, "phrase": "initial_or_neutral_pose"}, {"score": 0.0022933216359142736, "phrase": "proposed_method"}, {"score": 0.002254357921422124, "phrase": "real_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Online gesture recognition", " Key pose identification", " Skeleton representation", " Depth sensors", " 3D motion", " Natural user interface"], "paper_abstract": "The recent popularization of real time depth sensors has diversified the potential applications of online gesture recognition to end-user natural user interface (NUI). This requires significant robustness of the gesture recognition to cope with the noisy data from the popular depth sensor, while the quality of the final NUI heavily depends on the recognition execution speed. This work introduces a method for real-time gesture recognition from a noisy skeleton stream, such as those extracted from Kinect depth sensors. Each pose is described using an angular representation of the skeleton joints. Those descriptors serve to identify key poses through a Support Vector Machine multi-class classifier, with a tailored pose kernel. The gesture is labeled on-the-fly from the key pose sequence with a decision forest, which naturally performs the gesture time control/warping and avoids the requirement for an initial or neutral pose. The proposed method runs in real time and its robustness is evaluated in several experiments. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Online gesture recognition from pose kernel learning and decision forests", "paper_id": "WOS:000331854700008"}