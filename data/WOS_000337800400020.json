{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "matrix-matrix_multiplication"}, {"score": 0.004618166136069052, "phrase": "simd."}, {"score": 0.004392565073466714, "phrase": "new_methodology"}, {"score": 0.00417793854311445, "phrase": "single_instruction_multiple_data_unit"}, {"score": 0.0039737570920809215, "phrase": "shared_cache"}, {"score": 0.0037168948492715386, "phrase": "higher_execution_speed"}, {"score": 0.0036553070575015344, "phrase": "atlas_state"}, {"score": 0.0035648266669315943, "phrase": "art_library"}, {"score": 0.002966084234963723, "phrase": "data_cache_accesses"}, {"score": 0.0028446460307503343, "phrase": "memory_hierarchy"}, {"score": 0.0026384167183586015, "phrase": "software_characteristics"}, {"score": 0.002158505888557746, "phrase": "high_quality_solutions"}, {"score": 0.0021049977753042253, "phrase": "smaller_search_space"}], "paper_keywords": ["Matrix-Matrix Multiplication", " Data cache", " Cache associativity", " Multi-core", " SIMD", " Memory management"], "paper_abstract": "In this paper, a new methodology for speeding up Matrix-Matrix Multiplication using Single Instruction Multiple Data unit, at one and more cores having a shared cache, is presented. This methodology achieves higher execution speed than ATLAS state of the art library (speedup from 1.08 up to 3.5), by decreasing the number of instructions (load/store and arithmetic) and the data cache accesses and misses in the memory hierarchy. This is achieved by fully exploiting the software characteristics (e.g. data reuse) and hardware parameters (e.g. data caches sizes and associativities) as one problem and not separately, giving high quality solutions and a smaller search space.", "paper_title": "A Matrix-Matrix Multiplication methodology for single/multi-core architectures using SIMD", "paper_id": "WOS:000337800400020"}