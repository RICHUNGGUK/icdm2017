{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "stability_theory"}, {"score": 0.027273189594755196, "phrase": "proposed_framework"}, {"score": 0.009060861278808473, "phrase": "search_point_positions"}, {"score": 0.00475390577915698, "phrase": "stochastic_meta-heuristic"}, {"score": 0.0046046429665581555, "phrase": "optimization_algorithms"}, {"score": 0.004389451298343287, "phrase": "approximate_solutions"}, {"score": 0.004361526027730043, "phrase": "optimization_problems"}, {"score": 0.004306205029641728, "phrase": "special_prior_knowledge"}, {"score": 0.004118026552723285, "phrase": "practical_applications"}, {"score": 0.003925486550801027, "phrase": "prior_knowledge"}, {"score": 0.003635903652803253, "phrase": "algorithm_design"}, {"score": 0.0034000375671935953, "phrase": "mathematical_grounds"}, {"score": 0.0032617323680009217, "phrase": "dynamic_characteristics"}, {"score": 0.0031794236141757, "phrase": "concrete_algorithms"}, {"score": 0.0030017207229983385, "phrase": "existingmeta-heuristic_algorithms"}, {"score": 0.0028429935010577975, "phrase": "pseudo-random_numbers"}, {"score": 0.002718581874516321, "phrase": "linear_combination"}, {"score": 0.0027012576751290433, "phrase": "normally_distributed_random_numbers"}, {"score": 0.002675477598833661, "phrase": "fixed_input_term"}, {"score": 0.002599600404892265, "phrase": "search_point"}, {"score": 0.0022729292542096077, "phrase": "control_rule"}, {"score": 0.002251227801482381, "phrase": "search_point_distribution"}, {"score": 0.0021664698544866753, "phrase": "optimization_capability"}, {"score": 0.0021049977753042253, "phrase": "numerical_simulation"}], "paper_keywords": ["meta-heuristics", " global optimization", " stochastic optimization", " normal distribution"], "paper_abstract": "In Recent years, a paradigm of optimization algorithms referred to as \"meta-heuristics\" have been gaining attention as a means of obtaining approximate solutions to optimization problems quickly without any special prior knowledge of the problems. Meta-heuristics are characterized by flexibility in implementation. In practical applications, we can make use of not only existing algorithms but also revised algorithms that reflect the prior knowledge of the problems. Most meta-heuristic algorithms lack mathematical grounds, however, and therefore generally require a process of trial and error for the algorithm design and its parameter adjustment. For one of the resolution of the problem, we propose an approach to design algorithms with mathematical grounds. The approach consists of first constructing a \"framework\" of which dynamic characteristics can be derived theoretically and then designing concrete algorithms within the framework. In this paper, we propose such a framework that employs two following basic strategies commonly used in existingmeta-heuristic algorithms, namely, (1) multipoint searching, and (2) stochastic searching with pseudo-random numbers. In the framework, the update-formula of search point positions is given by a linear combination of normally distributed random numbers and a fixed input term. We also present a stability theory of the search point distribution for the proposed framework, using the variance of the search point positions as the index of stability. This theory can be applied to any algorithm that is designed within the proposed framework, and the results can be used to obtain a control rule for the search point distribution of each algorithm. We also verify the stability theory and the optimization capability of an algorithm based on the proposed framework by numerical simulation.", "paper_title": "A New Framework with a Stability Theory for Multipoint-Type and Stochastic Meta-Heuristic Optimization Algorithms", "paper_id": "WOS:000359464400032"}