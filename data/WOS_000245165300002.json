{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "action_models"}, {"score": 0.006928882447899808, "phrase": "arms"}, {"score": 0.004774115617883476, "phrase": "plan_examples"}, {"score": 0.004733625412289433, "phrase": "weighted_max-sat._ai_planning"}, {"score": 0.004575053987970206, "phrase": "formal_action"}, {"score": 0.004536244367689415, "phrase": "plan_description_language"}, {"score": 0.0040779081518317415, "phrase": "difficult_and_time-consuming_task"}, {"score": 0.0035731269727067496, "phrase": "successful_observed_plans"}, {"score": 0.003512702405367876, "phrase": "previous_work"}, {"score": 0.0034828730516958807, "phrase": "action-model_learning"}, {"score": 0.003394891095032025, "phrase": "complete_knowledge"}, {"score": 0.0032950412841674026, "phrase": "observed_plans"}, {"score": 0.003104038398386081, "phrase": "example_plans"}, {"score": 0.003038532168038562, "phrase": "observation_agent"}, {"score": 0.0029617414861784525, "phrase": "logical_encoding"}, {"score": 0.002886885861509621, "phrase": "full_state_information"}, {"score": 0.002801935384649699, "phrase": "real_world_application"}, {"score": 0.00268488398249084, "phrase": "training_examples"}, {"score": 0.0025947642929906407, "phrase": "plan_example"}, {"score": 0.0024234763342790852, "phrase": "statistical_distribution"}, {"score": 0.0024028742248152425, "phrase": "frequent_sets"}, {"score": 0.0022828795331819025, "phrase": "weighted_propositional_satisfiability"}, {"score": 0.0022538275528826, "phrase": "max-sat"}, {"score": 0.002178144355363467, "phrase": "max-sat_solver"}, {"score": 0.002132135985573126, "phrase": "theoretical_foundations"}, {"score": 0.0021049977753042253, "phrase": "learning_problem"}], "paper_keywords": ["learning action models", " automated planning", " statistical relational learning"], "paper_abstract": "AI planning requires the definition of action models using a formal action and plan description language, such as the standard Planning Domain Definition Language (PDDL), as input. However, building action models from scratch is a difficult and time-consuming task, even for experts. In this paper, we develop an algorithm called ARMS (action-relation modelling system) for automatically discovering action models from a set of successful observed plans. Unlike the previous work in action-model learning, we do not assume complete knowledge of states in the middle of observed plans. In fact, our approach works when no or partial intermediate states are given. These example plans are obtained by an observation agent who does not know the logical encoding of the actions and the full state information between the actions. In a real world application, the cost is prohibitively high in labelling the training examples by manually annotating every state in a plan example from snapshots of an environment. To learn action models, ARMS gathers knowledge on the statistical distribution of frequent sets of actions in the example plans. It then builds a weighted propositional satisfiability (weighted MAX-SAT) problem and solves it using a MAX-SAT solver. We lay the theoretical foundations of the learning problem and evaluate the effectiveness of ARMS empirically. (C) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Learning action models from plan examples using weighted MAX-SAT", "paper_id": "WOS:000245165300002"}