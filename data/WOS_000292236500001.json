{"auto_keywords": [{"score": 0.043657532050050255, "phrase": "similarity_criterion"}, {"score": 0.00481495049065317, "phrase": "contour_regularities"}, {"score": 0.004723847090183984, "phrase": "levenshtein_edit_distance"}, {"score": 0.00459039896577789, "phrase": "new_method"}, {"score": 0.004293434614435972, "phrase": "freeman_chain_codes"}, {"score": 0.004034841146538891, "phrase": "levenshtein_edit_distance_computation"}, {"score": 0.003809932244103758, "phrase": "minimal_cost_edit_sequence"}, {"score": 0.003702206069379459, "phrase": "contour_segments"}, {"score": 0.0034625012596827334, "phrase": "similar_part"}, {"score": 0.003332537728389913, "phrase": "average_contour_region"}, {"score": 0.003131637033429892, "phrase": "identified_regularities"}, {"score": 0.002928765962664163, "phrase": "contour_groups"}, {"score": 0.002859533151305368, "phrase": "new_prototypes"}, {"score": 0.002752139271586703, "phrase": "classification_task"}, {"score": 0.002512926336312949, "phrase": "classification_purposes"}, {"score": 0.002488985155689794, "phrase": "experimental_results"}, {"score": 0.0023388183537341213, "phrase": "training_data"}, {"score": 0.0022725931637071852, "phrase": "classification_error"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Contour regularities", " Shape prototypes", " Edit distance"], "paper_abstract": "This paper describes a new method for quantifying the regularity of contours and comparing them (when encoded by Freeman chain codes) in terms of a similarity criterion which relies on information gathered from Levenshtein edit distance computation. The criterion used allows subsequences to be found from the minimal cost edit sequence that specifies an alignment of contour segments which are similar. Two external parameters adjust the similarity criterion. The information about each similar part is encoded by strings that represent an average contour region. An explanation of how to construct a prototype based on the identified regularities is also reviewed. The reliability of the prototypes is evaluated by replacing contour groups (samples) by new prototypes used as the training set in a classification task. This way, the size of the data set can be reduced without sensibly affecting its representational power for classification purposes. Experimental results show that this scheme achieves a reduction in the size of the training data set of about 80% while the classification error only increases by 0.45% in one of the three data sets studied. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Characterization of contour regularities based on the Levenshtein edit distance", "paper_id": "WOS:000292236500001"}