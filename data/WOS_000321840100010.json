{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "real-time_facial_animation"}, {"score": 0.004646496622257368, "phrase": "real-time_performance-driven_facial_animation_system"}, {"score": 0.004205395707787349, "phrase": "facial_landmark_points"}, {"score": 0.003916098498242888, "phrase": "ordinary_web_camera"}, {"score": 0.0034444213065548688, "phrase": "user-specific_blendshape_model"}, {"score": 0.00332375606483146, "phrase": "main_technical_contribution"}, {"score": 0.0029441472095672397, "phrase": "training_data"}, {"score": 0.0027025233739857374, "phrase": "predefined_facial_poses"}, {"score": 0.0024108455980729284, "phrase": "fast_motions"}, {"score": 0.002150580119047236, "phrase": "partial_occlusions"}, {"score": 0.0021049977753042253, "phrase": "lighting_conditions"}], "paper_keywords": ["face tracking", " monocular video tracking", " 3D avatars", " facial performance", " user-specific blendshapes"], "paper_abstract": "We present a real-time performance-driven facial animation system based on 3D shape regression. In this system, the 3D positions of facial landmark points are inferred by a regressor from 2D video frames of an ordinary web camera. From these 3D points, the pose and expressions of the face are recovered by fitting a user-specific blendshape model to them. The main technical contribution of this work is the 3D regression algorithm that learns an accurate, user-specific face alignment model from an easily acquired set of training data, generated from images of the user performing a sequence of predefined facial poses and expressions. Experiments show that our system can accurately recover 3D face shapes even for fast motions, non-frontal faces, and exaggerated expressions. In addition, some capacity to handle partial occlusions and changing lighting conditions is demonstrated.", "paper_title": "3D Shape Regression for Real-time Facial Animation", "paper_id": "WOS:000321840100010"}