{"auto_keywords": [{"score": 0.0282066988930242, "phrase": "proposed_system"}, {"score": 0.00481495049065317, "phrase": "image_retrieval"}, {"score": 0.004772137871562584, "phrase": "automatic_image_annotation"}, {"score": 0.004645959941491617, "phrase": "semantic_search"}, {"score": 0.0046046429665581555, "phrase": "large_image_databases"}, {"score": 0.004523103062368843, "phrase": "retrieval_performance"}, {"score": 0.004462892860919036, "phrase": "existing_annotation_schemes"}, {"score": 0.004364310576600359, "phrase": "users'_expectation"}, {"score": 0.00419229472352669, "phrase": "novel_method"}, {"score": 0.004009074013302036, "phrase": "support_vector_machines"}, {"score": 0.003973398317120165, "phrase": "decision_trees"}, {"score": 0.003732368382223596, "phrase": "training_regions"}, {"score": 0.0036991458715587163, "phrase": "image_segmentation"}, {"score": 0.003666217992454448, "phrase": "feature_extraction"}, {"score": 0.0035374012552316573, "phrase": "support_vector_machine"}, {"score": 0.0034902664176377943, "phrase": "preprocessing_technique"}, {"score": 0.0034283921404628975, "phrase": "input_training_data"}, {"score": 0.0032638170723261538, "phrase": "decision_tree_learning"}, {"score": 0.0031350397225314262, "phrase": "similar_regions"}, {"score": 0.002971182100871581, "phrase": "original_rules"}, {"score": 0.002931569771634119, "phrase": "modified_ones"}, {"score": 0.0028411768240129585, "phrase": "complete_and_effective_annotation_rules"}, {"score": 0.0027659126653647712, "phrase": "unknown_image"}, {"score": 0.0024620842899061614, "phrase": "standard_corel_dataset"}, {"score": 0.0022816681646340518, "phrase": "experimental_results"}, {"score": 0.002251227801482381, "phrase": "proposed_algorithm"}, {"score": 0.002162316557411786, "phrase": "traditional_learning_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Annotation rules", " Support vector machine", " Decision tree", " Automatic image annotation", " Image retrieval"], "paper_abstract": "Automatic image annotation can be used to facilitate semantic search in large image databases. However, retrieval performance of the existing annotation schemes is far from the users' expectation. In this paper, we propose a novel method to automatically annotate image through the rules generated by support vector machines and decision trees. In order to obtain the rules, we collect a set of training regions by image segmentation, feature extraction and discretization. We first employ a support vector machine as a preprocessing technique to refine the input training data and then use it to improve the rules generated by decision tree learning. The preprocessing can effectively deal with the similar regions in an image as well. Moreover, we integrate the original rules to the modified ones, so as to formulate the complete and effective annotation rules. We can translate an unknown image into text by this algorithm, and the proposed system can retrieve images queried by both images and keywords. Experiments are carried out in a standard Corel dataset and images collected from the Web to test the accuracy and robustness of the proposed system. Experimental results show the proposed algorithm can annotate and retrieve images more efficiently than traditional learning algorithms. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "An annotation rule extraction algorithm for image retrieval", "paper_id": "WOS:000305771400003"}