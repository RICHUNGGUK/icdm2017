{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "optimized_product_quantization"}, {"score": 0.004756805752518494, "phrase": "product_quantization"}, {"score": 0.004586531354697466, "phrase": "effective_vector_quantization_method"}, {"score": 0.00450368324850566, "phrase": "product_quantizer"}, {"score": 0.004395532072377065, "phrase": "exponentially_large_codebook"}, {"score": 0.004086350434865782, "phrase": "high-dimensional_vector_space"}, {"score": 0.004012759066384553, "phrase": "cartesian"}, {"score": 0.0037301606780397456, "phrase": "optimal_space_decomposition"}, {"score": 0.003618443379266972, "phrase": "pq_performance"}, {"score": 0.0034887749053459584, "phrase": "unaddressed_issue"}, {"score": 0.0032629585038738856, "phrase": "quantization_distortions"}, {"score": 0.0032039415997394817, "phrase": "space_decomposition"}, {"score": 0.0031459887611258765, "phrase": "quantization_codebooks"}, {"score": 0.0030147970456037274, "phrase": "challenging_optimization_problem"}, {"score": 0.0029602552900111407, "phrase": "first_solution"}, {"score": 0.002751751956416832, "phrase": "gaussian_assumption"}, {"score": 0.0027019561451518768, "phrase": "theoretical_analysis"}, {"score": 0.002466139325703204, "phrase": "compact_encoding"}, {"score": 0.002436289099444074, "phrase": "exhaustive_ranking"}, {"score": 0.0023063614119692476, "phrase": "inverted_multi-indexing"}, {"score": 0.002278440725193305, "phrase": "non-exhaustive_search"}, {"score": 0.0021049977753042253, "phrase": "image_retrieval"}], "paper_keywords": ["Vector quantization", " nearest neighbor search", " image retrieval", " compact encoding", " inverted indexing"], "paper_abstract": "Product quantization (PQ) is an effective vector quantization method. A product quantizer can generate an exponentially large codebook at very low memory/time cost. The essence of PQ is to decompose the high-dimensional vector space into the Cartesian product of subspaces and then quantize these subspaces separately. The optimal space decomposition is important for the PQ performance, but still remains an unaddressed issue. In this paper, we optimize PQ by minimizing quantization distortions w.r.t the space decomposition and the quantization codebooks. We present two novel solutions to this challenging optimization problem. The first solution iteratively solves two simpler sub-problems. The second solution is based on a Gaussian assumption and provides theoretical analysis of the optimality. We evaluate our optimized product quantizers in three applications: (i) compact encoding for exhaustive ranking [ 1], (ii) building inverted multi-indexing for non-exhaustive search [ 2], and (iii) compacting image representations for image retrieval [ 3]. In all applications our optimized product quantizers outperform existing solutions.", "paper_title": "Optimized Product Quantization", "paper_id": "WOS:000334109000009"}