{"auto_keywords": [{"score": 0.04182833290656605, "phrase": "different_tasks"}, {"score": 0.00481495049065317, "phrase": "multitask_bregman"}, {"score": 0.004755054742217193, "phrase": "traditional_clustering_methods"}, {"score": 0.004676345706416371, "phrase": "single_clustering_task"}, {"score": 0.004618166136069052, "phrase": "single_data_set"}, {"score": 0.004541712637353326, "phrase": "newly_emerging_applications"}, {"score": 0.004503959683578956, "phrase": "multiple_similar_clustering_tasks"}, {"score": 0.0037480753312398754, "phrase": "individual_performance"}, {"score": 0.003579750245670577, "phrase": "general_approaches"}, {"score": 0.0035204268675160257, "phrase": "wide_family"}, {"score": 0.0034620831765465425, "phrase": "multitask_settings"}, {"score": 0.003292770855568091, "phrase": "loss_function"}, {"score": 0.0031712256091350316, "phrase": "task_regularization"}, {"score": 0.003092690568543981, "phrase": "general_bregman_divergences"}, {"score": 0.0030541531847589833, "phrase": "within-task_loss"}, {"score": 0.0029909851863915283, "phrase": "average_bregman_divergence"}, {"score": 0.002953711377604328, "phrase": "data_sample"}, {"score": 0.0028685304140180137, "phrase": "task_regularizations"}, {"score": 0.0027857990883821504, "phrase": "clustering_results"}, {"score": 0.002671722386856879, "phrase": "probabilistic_interpretation"}, {"score": 0.0026384167183586015, "phrase": "proposed_formulations"}, {"score": 0.0025838249689625775, "phrase": "joint_density_estimation"}, {"score": 0.002519800066326798, "phrase": "alternate_procedures"}, {"score": 0.002477998427152547, "phrase": "induced_optimization_problems"}, {"score": 0.00241658945942583, "phrase": "clustering_models"}, {"score": 0.00223196703759329, "phrase": "empirical_results"}, {"score": 0.002158505888557746, "phrase": "proposed_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multitask learning", " Clustering", " Bregman divergences"], "paper_abstract": "Traditional clustering methods deal with a single clustering task on a single data set. In some newly emerging applications, multiple similar clustering tasks are involved simultaneously. In this case, we not only desire a partition for each task, but also want to discover the relationship among clusters of different tasks. It is also expected that utilizing the relationship among tasks can improve the individual performance of each task. In this paper, we propose general approaches to extend a wide family of traditional clustering models/algorithms to multitask settings. We first generally formulate the multitask clustering as minimizing a loss function composed of a within-task loss and a task regularization. Then based on the general Bregman divergences, the within-task loss is defined as the average Bregman divergence from a data sample to its cluster centroid. And two types of task regularizations are proposed to encourage coherence among clustering results of tasks. Afterwards, we further provide a probabilistic interpretation to the proposed formulations from a viewpoint of joint density estimation. Finally, we propose alternate procedures to solve the induced optimization problems. In such procedures, the clustering models and the relationship among clusters of different tasks are updated alternately, and the two phases boost each other. Empirical results on several real data sets validate the effectiveness of the proposed approaches. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Multitask Bregman clustering", "paper_id": "WOS:000290838600025"}