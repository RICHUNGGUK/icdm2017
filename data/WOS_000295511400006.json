{"auto_keywords": [{"score": 0.03644451033122438, "phrase": "rater_performance"}, {"score": 0.010552443547876595, "phrase": "labeler_accuracy"}, {"score": 0.01046315591347303, "phrase": "truth_estimation"}, {"score": 0.00587902264934129, "phrase": "consensus_level"}, {"score": 0.005055642737521301, "phrase": "collate"}, {"score": 0.00481495049065317, "phrase": "robust_statistical_label_fusion_through_consensus_level"}, {"score": 0.004574247691703376, "phrase": "medical_images"}, {"score": 0.0043953478557600565, "phrase": "established_gold_standard"}, {"score": 0.0043208252177835815, "phrase": "manual_voxel"}, {"score": 0.004223415145617665, "phrase": "neuroanatomist_expert"}, {"score": 0.004046627438964482, "phrase": "high_inter-observer_variability"}, {"score": 0.0039553744129764016, "phrase": "novel_structures"}, {"score": 0.0036727235025069828, "phrase": "statistical_methods"}, {"score": 0.003641433168173135, "phrase": "data_sets"}, {"score": 0.0034297140422566577, "phrase": "ground_truth_labels"}, {"score": 0.0033811403330431897, "phrase": "empirical_datasets"}, {"score": 0.0033619033669956317, "phrase": "statistical_fusion"}, {"score": 0.0032954289787083713, "phrase": "visually_inconsistent_findings"}, {"score": 0.003193606324727067, "phrase": "statistical_approach"}, {"score": 0.0031754329320561317, "phrase": "single_observers"}, {"score": 0.0031573626285069157, "phrase": "direct_voting"}, {"score": 0.003007846011394511, "phrase": "label_estimation"}, {"score": 0.002965229277927781, "phrase": "statistical_fusion_methods"}, {"score": 0.0028653893877383188, "phrase": "spatially_varying_models"}, {"score": 0.0026986685585382347, "phrase": "spatially_varying_performance"}, {"score": 0.002563487683381462, "phrase": "simple_idea"}, {"score": 0.002326304140277375, "phrase": "high_contrast_edges"}, {"score": 0.0022287497627555895, "phrase": "differing_models"}, {"score": 0.002216054733102974, "phrase": "observer_behavior"}, {"score": 0.002153653728048424, "phrase": "significant_improvement"}, {"score": 0.0021413855297794946, "phrase": "label_accuracy"}, {"score": 0.0021291870676682406, "phrase": "rater_assessment"}, {"score": 0.0021170579470073305, "phrase": "previous_fusion_methods"}], "paper_keywords": ["Consensus level", " labeler accuracy and truth estimation (COLLATE)", " data fusion", " delineation", " labeling", " parcellation", " simultaneous truth and performance level estimation (STAPLE)", " statistical analysis"], "paper_abstract": "Segmentation and delineation of structures of interest in medical images is paramount to quantifying and characterizing structural, morphological, and functional correlations with clinically relevant conditions. The established gold standard for performing segmentation has been manual voxel-by-voxel labeling by a neuroanatomist expert. This process can be extremely time consuming, resource intensive and fraught with high inter-observer variability. Hence, studies involving characterizations of novel structures or appearances have been limited in scope (numbers of subjects), scale (extent of regions assessed), and statistical power. Statistical methods to fuse data sets from several different sources (e. g., multiple human observers) have been proposed to simultaneously estimate both rater performance and the ground truth labels. However, with empirical datasets, statistical fusion has been observed to result in visually inconsistent findings. So, despite the ease and elegance of a statistical approach, single observers and/or direct voting are often used in practice. Hence, rater performance is not systematically quantified and exploited during label estimation. To date, statistical fusion methods have relied on characterizations of rater performance that do not intrinsically include spatially varying models of rater performance. Herein, we present a novel, robust statistical label fusion algorithm to estimate and account for spatially varying performance. This algorithm, COnsensus Level, Labeler Accuracy and Truth Estimation (COLLATE), is based on the simple idea that some regions of an image are difficult to label (e. g., confusion regions: boundaries or low contrast areas) while other regions are intrinsically obvious (e. g., consensus regions: centers of large regions or high contrast edges). Unlike its predecessors, COLLATE estimates the consensus level of each voxel and estimates differing models of observer behavior in each region. We show that COLLATE provides significant improvement in label accuracy and rater assessment over previous fusion methods in both simulated and empirical datasets.", "paper_title": "Robust Statistical Label Fusion Through Consensus Level, Labeler Accuracy, and Truth Estimation (COLLATE)", "paper_id": "WOS:000295511400006"}