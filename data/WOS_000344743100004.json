{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "prediction_models"}, {"score": 0.0047273577269638725, "phrase": "individual_predictions"}, {"score": 0.004641351004344458, "phrase": "feature_contributions"}, {"score": 0.00443308765153716, "phrase": "sensitivity_analysis-based_method"}, {"score": 0.0038624981944755813, "phrase": "regression_model"}, {"score": 0.0037231102027070724, "phrase": "existing_general_methods"}, {"score": 0.0035233696341819437, "phrase": "input_features"}, {"score": 0.002931569771634119, "phrase": "additive_model"}, {"score": 0.002748775748298028, "phrase": "commonly_used_additive_model-specific_methods"}, {"score": 0.0026252106881752067, "phrase": "method's_usefulness"}, {"score": 0.002530359917257626, "phrase": "artificial_and_real-world_data_sets"}, {"score": 0.0023944552329463035, "phrase": "running_times"}, {"score": 0.002286781334850213, "phrase": "controlled_experiment"}, {"score": 0.002163930783583212, "phrase": "method's_explanations"}, {"score": 0.0021049977753042253, "phrase": "participants'_understanding"}], "paper_keywords": ["Knowledge discovery", " Data mining", " Visualization", " Interpretability", " Decision support"], "paper_abstract": "We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classification or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-specific methods. We illustrate the method's usefulness with examples from artificial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method's explanations improved the participants' understanding of the model.", "paper_title": "Explaining prediction models and individual predictions with feature contributions", "paper_id": "WOS:000344743100004"}