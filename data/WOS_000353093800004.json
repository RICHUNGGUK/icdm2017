{"auto_keywords": [{"score": 0.045757345554595, "phrase": "local_appearance_models"}, {"score": 0.012873525233903225, "phrase": "response_maps"}, {"score": 0.010537144818792504, "phrase": "test_time"}, {"score": 0.00481495049065317, "phrase": "in-the-wild_images"}, {"score": 0.004721893473387288, "phrase": "global_appearance"}, {"score": 0.004645714863712397, "phrase": "novel_method"}, {"score": 0.0045559136361908795, "phrase": "facial_landmarking"}, {"score": 0.004526365546684684, "phrase": "unconstrained_conditions"}, {"score": 0.004482400730101345, "phrase": "part-based_framework"}, {"score": 0.00445332728705756, "phrase": "part-based_methods"}, {"score": 0.004324802749898957, "phrase": "per-point_response_map"}, {"score": 0.00419997182602686, "phrase": "valid_face_shape"}, {"score": 0.004105367230078949, "phrase": "per-point_responses"}, {"score": 0.004012885020428863, "phrase": "better_appearance_models"}, {"score": 0.0037968334163829944, "phrase": "shape_fitting_strategy"}, {"score": 0.003639471039860495, "phrase": "-wild_imagery"}, {"score": 0.0035806923950599005, "phrase": "varying_head_poses"}, {"score": 0.0035574466515880337, "phrase": "facial_expressions"}, {"score": 0.0035114053248663335, "phrase": "lighting_conditions"}, {"score": 0.003477264432055326, "phrase": "image_quality"}, {"score": 0.0034322572683276654, "phrase": "pose-wise_experts"}, {"score": 0.003236802914194731, "phrase": "computation_cost"}, {"score": 0.0031228618763672173, "phrase": "right_expert"}, {"score": 0.0030326180561817497, "phrase": "gross_errors"}, {"score": 0.002935393439834135, "phrase": "training_examples"}, {"score": 0.002859856368059419, "phrase": "global_similarity_measure"}, {"score": 0.0027591477674456227, "phrase": "single_test_sample-specific_expert"}, {"score": 0.0025934566395017424, "phrase": "recently_proposed_use"}, {"score": 0.0024939618994290016, "phrase": "gaussian_processes"}, {"score": 0.0024376912001213362, "phrase": "localised_regression"}, {"score": 0.002413964586947992, "phrase": "novel_way"}, {"score": 0.002189009136006588, "phrase": "cross-dataset_experiment"}, {"score": 0.0021676977432828373, "phrase": "considerable_performance_improvement"}, {"score": 0.00214659338413584, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Facial landmarking", " Regression", " Part-based models", " Gaussian processes"], "paper_abstract": "We present a novel method that tackles the problem of facial landmarking in unconstrained conditions within the part-based framework. Part-based methods alternate the evaluation of local appearance models to produce a per-point response map and a shape fitting step which finds a valid face shape that maximises the sum of the per-point responses. Our approach focuses on obtaining better appearance models for the creation of the response maps, and it can be used in combination with any shape fitting strategy. Local appearance models need to tackle very heterogeneous data when dealing with in-the-wild imagery due to factors as varying head poses, facial expressions, identity, lighting conditions, or image quality among others. Pose-wise experts are typically used in this scenario so that each expert deals with more homogeneous data. However, the computation cost at test time is significantly increased. Furthermore, choosing the right expert is not straightforward, which can lead to gross errors. We propose to dynamically select at test time the training examples used for inference. We use a global similarity measure to select the most adequate training examples for inference, and create a single test sample-specific expert using a localised inference technique. To illustrate the validity of these ideas, we capitalise on the recently proposed use of regression to generate local appearance models. In particular, we use Gaussian processes, as their non-parametric nature easily allows for localised regression. This novel way of constructing the response maps is combined with two state-of-the-art standard shape fitting algorithms, the popular Constrained Local Models framework and the Consensus of Exemplars method. We validate our method on two publicly available datasets as well as on a cross-dataset experiment showing a considerable performance improvement of the proposed approach. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Facial landmarking for in-the-wild images with local inference based on global appearance", "paper_id": "WOS:000353093800004"}