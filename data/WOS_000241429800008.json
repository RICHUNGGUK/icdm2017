{"auto_keywords": [{"score": 0.03581756621697852, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "support_vector_machines"}, {"score": 0.004024863549087511, "phrase": "feature_ranking"}, {"score": 0.003829290275367182, "phrase": "fast_classifier"}, {"score": 0.0037537380967196123, "phrase": "k-nearest-neighbours"}, {"score": 0.0036070601923916196, "phrase": "forward_selection"}, {"score": 0.003232688815503571, "phrase": "svm"}, {"score": 0.0031061129850110994, "phrase": "optimal_number"}, {"score": 0.0028113140998735366, "phrase": "outguess_steganographic_software"}, {"score": 0.002444883254621769, "phrase": "selected_features"}, {"score": 0.0023259039577313294, "phrase": "wide_variety"}, {"score": 0.0022799458141165587, "phrase": "embedding_rates"}, {"score": 0.0021049977753042253, "phrase": "steghide"}], "paper_keywords": [""], "paper_abstract": "This paper presents a methodology to select features before training a classifier based on Support Vector Machines (SVM). In this study 23 features presented in [1] are analysed. A feature ranking is performed using a fast classifier called K-Nearest-Neighbours combined with a forward selection. The result of the feature selection is afterward tested on SVM to select the optimal number of features. This method is tested with the Outguess steganographic software and 14 features are selected while keeping the same classification performances. Results confirm that the selected features are efficient for a wide variety of embedding rates. The same methodology is also applied for Steghide and F5 to see if feature selection is possible on these schemes.", "paper_title": "A feature selection methodology for steganalysis", "paper_id": "WOS:000241429800008"}