{"auto_keywords": [{"score": 0.047698377071202586, "phrase": "multiple_instances"}, {"score": 0.00481495049065317, "phrase": "multi-core_architectures"}, {"score": 0.004710944813540894, "phrase": "single_process"}, {"score": 0.0046938292389998824, "phrase": "multiple_data"}, {"score": 0.00465978700305179, "phrase": "spmd"}, {"score": 0.004493207015584002, "phrase": "possibly_varying_arguments"}, {"score": 0.004428248351415723, "phrase": "widespread_adoption"}, {"score": 0.004396120480895021, "phrase": "massively_multicore_processors"}, {"score": 0.004238929161010395, "phrase": "abundant_compute_resources"}, {"score": 0.004177631185971939, "phrase": "power-efficient_manner"}, {"score": 0.004042919099733537, "phrase": "distributed_process_launch"}, {"score": 0.0040135756033094225, "phrase": "hierarchical_techniques"}, {"score": 0.003786337629480068, "phrase": "single_node"}, {"score": 0.0036775717816768133, "phrase": "new_process"}, {"score": 0.003624361893008392, "phrase": "faster_global_job_launch"}, {"score": 0.0035719191251314918, "phrase": "emerging_dynamic_and_resilient_execution_models"}, {"score": 0.0034692911858848893, "phrase": "process_pools"}, {"score": 0.0034440966820590024, "phrase": "fault_isolation"}, {"score": 0.0033696019683761274, "phrase": "relatively_shorter_period"}, {"score": 0.0031787077057214086, "phrase": "overall_performance"}, {"score": 0.00315561677959372, "phrase": "runtime_systems"}, {"score": 0.0031212935348800467, "phrase": "adaptive_process-replication_reliability"}, {"score": 0.0030315735229977958, "phrase": "process_management_interfaces"}, {"score": 0.003009548189374684, "phrase": "future_manycore_operating_systems"}, {"score": 0.00289123004877327, "phrase": "efficient_spawning"}, {"score": 0.0028493650087584774, "phrase": "massively_multicore_architectures"}, {"score": 0.002601065207135226, "phrase": "multiple_executables"}, {"score": 0.002526261001496249, "phrase": "memory_locality"}, {"score": 0.0024987660207458555, "phrase": "numa-aware_extensions"}, {"score": 0.002444668348634501, "phrase": "large_memory-mapped_segments"}, {"score": 0.0023570895666021664, "phrase": "vector_operating_system_interfaces"}, {"score": 0.002264364091368269, "phrase": "specific_cores"}, {"score": 0.002159460831267798, "phrase": "traditional_method"}, {"score": 0.0021359494324422997, "phrase": "new_processes"}, {"score": 0.0021049977753042253, "phrase": "exec_system"}], "paper_keywords": ["process spawn optimization", " scalable intra-node process launch", " batched system calls", " vector operating system interfaces", " manycore runtime systems"], "paper_abstract": "The execution of a single process multiple data (SPMD) application involves running multiple instances of a process with possibly varying arguments. With the widespread adoption of massively multicore processors, there has been a focus towards harnessing the abundant compute resources effectively in a power-efficient manner. Although much work has been done towards optimizing distributed process launch using hierarchical techniques, there has been a void in studying the performance of spawning processes within a single node. Reducing the latency to spawn a new process locally results in faster global job launch. Further, emerging dynamic and resilient execution models are designed on the premise of maintaining process pools for fault isolation and launching several processes in a relatively shorter period of time. Optimizing the latency and throughput for spawning processes would help improve the overall performance of runtime systems, allow adaptive process-replication reliability and motivate the design and implementation of process management interfaces in future manycore operating systems. In this paper, we study the several limiting factors for efficient spawning of processes on massively multicore architectures. We have developed a library to optimize launching multiple instances of the same executable. Our microbenchmarks show a 20-80% decrease in the process spawn time for multiple executables. We further discuss the effects of memory locality and propose NUMA-aware extensions to optimize launching processes with large memory-mapped segments including dynamic shared libraries. Finally, we describe vector operating system interfaces for spawning a batch of processes from a given executable on specific cores. Our results show a speedup of a factor of 40-50 over the traditional method of launching new processes using fork and exec system calls.", "paper_title": "Optimizing process creation and execution on multi-core architectures", "paper_id": "WOS:000318356600007"}