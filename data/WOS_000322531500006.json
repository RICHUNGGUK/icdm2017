{"auto_keywords": [{"score": 0.043083320582523676, "phrase": "learning_system"}, {"score": 0.01699086126747644, "phrase": "average_performance"}, {"score": 0.010612387000973441, "phrase": "demanding_lord"}, {"score": 0.008538430514005609, "phrase": "sliding_window"}, {"score": 0.004669254965563445, "phrase": "recommendation_systems"}, {"score": 0.004637478829869904, "phrase": "information_filtering"}, {"score": 0.004543436145505023, "phrase": "account_feedback"}, {"score": 0.0044209926093642235, "phrase": "user_experience"}, {"score": 0.004287166497171827, "phrase": "machine_learning_literature"}, {"score": 0.004157374465795314, "phrase": "target_concept"}, {"score": 0.003963211180578005, "phrase": "concept_drift"}, {"score": 0.0038300786263543835, "phrase": "training_instances"}, {"score": 0.0037523473563976246, "phrase": "drifting_concepts"}, {"score": 0.003688773272422118, "phrase": "general_analytic_study"}, {"score": 0.0034332736827447654, "phrase": "previous_works"}, {"score": 0.003386645324034521, "phrase": "instantaneous_performance"}, {"score": 0.0033635683594830158, "phrase": "specific_underlying_learners"}, {"score": 0.0033406481167452436, "phrase": "data_characteristics"}, {"score": 0.0032728171827367068, "phrase": "analytic_model"}, {"score": 0.0032063591061580526, "phrase": "memory_window_size"}, {"score": 0.003173636240475185, "phrase": "prediction_performance"}, {"score": 0.0030879936732269293, "phrase": "iterative_feedback"}, {"score": 0.0030356410934402503, "phrase": "target_concepts"}, {"score": 0.002796407494570146, "phrase": "signal-to-noise_approach"}, {"score": 0.0027395968397212053, "phrase": "underlying_machine"}, {"score": 0.002730240935688002, "phrase": "learning_algorithms"}, {"score": 0.002549672862868133, "phrase": "stepping_stone"}, {"score": 0.002515014676664348, "phrase": "memory_window"}, {"score": 0.002430411367515404, "phrase": "specific_modeling_system"}, {"score": 0.0023810183846557486, "phrase": "proposed_methodology"}, {"score": 0.002238767763626708, "phrase": "support_vector_machines"}, {"score": 0.0022234951091677085, "phrase": "naive_bayes"}, {"score": 0.0022083264126633085, "phrase": "nearest_neighbor"}, {"score": 0.002170854875902186, "phrase": "classification_and_regression_tasks"}], "paper_keywords": ["Concept drift", " Adaptive learning", " Demanding lord problem", " User modeling", " Incremental learning"], "paper_abstract": "In a variety of settings ranging from recommendation systems to information filtering, approaches which take into account feedback have been introduced to improve services and user experience. However, as also indicated in the machine learning literature, there exist several settings where the requirements and target concept of a learning system changes over time, which consists a case of \"concept drift\". In several systems, a sliding window over the training instances has been used to follow drifting concepts. However, no general analytic study has been performed on the relation between the size of the sliding window and the average performance of a learning system, since previous works have focused on instantaneous performance and specific underlying learners and data characteristics. This work proposes an analytic model that describes the effect of memory window size on the prediction performance of a learning system that is based on iterative feedback. The analysis considers target concepts changing over time, either periodically or randomly, using a formulation termed \"the problem of the demanding lord\". Using a signal-to-noise approach to sketch learning ability of underlying machine learning algorithms, we estimate the average performance of a learning system regardless of its underlying algorithm and, as a corollary, propose a stepping stone toward finding the memory window that maximizes the average performance for a given drift setting and a specific modeling system. We experimentally support the proposed methodology with very promising results on three synthetic and four real datasets, using a variety of learning algorithms including Support Vector Machines, Naive Bayes, Nearest Neighbor and Decision Trees on classification and regression tasks. The results validate the analysis and indicate very good estimation performance in different settings.", "paper_title": "Revisiting the effect of history on learning performance: the problem of the demanding lord", "paper_id": "WOS:000322531500006"}