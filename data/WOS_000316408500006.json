{"auto_keywords": [{"score": 0.041754020747534086, "phrase": "bcg"}, {"score": 0.009700757349971448, "phrase": "linear_systems"}, {"score": 0.004814951920900716, "phrase": "biconjugate"}, {"score": 0.004644146045859622, "phrase": "wide_variety"}, {"score": 0.004561019117546361, "phrase": "different_scientific_and_engineering_fields"}, {"score": 0.00414830454375092, "phrase": "biconjugate_gradient_method"}, {"score": 0.003929391999210588, "phrase": "enormous_computational_cost"}, {"score": 0.00389404213807752, "phrase": "gpu_computing"}, {"score": 0.003638823482920949, "phrase": "suitable_implementations"}, {"score": 0.003557509959237602, "phrase": "gpu_architecture"}, {"score": 0.0032353235992319796, "phrase": "gpu."}, {"score": 0.0030783143919343972, "phrase": "sparse_matrix_vector_product"}, {"score": 0.0029959083611586497, "phrase": "cusparse"}, {"score": 0.0029421965146816486, "phrase": "ellr"}, {"score": 0.0028120802837806234, "phrase": "complex_matrices"}, {"score": 0.0027122004450783072, "phrase": "gpu"}, {"score": 0.0026634937939104177, "phrase": "test_matrices"}, {"score": 0.0025804616931593897, "phrase": "single_and_double_precision_data"}, {"score": 0.0024774888010414206, "phrase": "ellr-t_routine"}, {"score": 0.0024440836179156593, "phrase": "best_performance"}, {"score": 0.002367875199095903, "phrase": "complex_test_matrices"}, {"score": 0.002212460584002629, "phrase": "large_linear_system"}, {"score": 0.0021049977753042253, "phrase": "broad_range"}], "paper_keywords": ["BiConjugate gradient method", " GPU computing", " Parallel computing", " Linear system of equations"], "paper_abstract": "In a wide variety of applications from different scientific and engineering fields, the solution of complex and/or nonsymmetric linear systems of equations is required. To solve this kind of linear systems the BiConjugate Gradient method (BCG) is especially relevant. Nevertheless, BCG has a enormous computational cost. GPU computing is useful for accelerating this kind of algorithms but it is necessary to develop suitable implementations to optimally exploit the GPU architecture. In this paper, we show how BCG can be effectively accelerated when all operations are computed on a GPU. So, BCG has been implemented with two alternative routines of the Sparse Matrix Vector product (SpMV): the CUSPARSE library and the ELLR-T routine. Although our interest is focused on complex matrices, our implementation has been evaluated on a GPU for two sets of test matrices: complex and real, in single and double precision data. Experimental results show that BCG based on ELLR-T routine achieves the best performance, particularly for the set of complex test matrices. Consequently, this method can be useful as a tool to efficiently solve large linear system of equations (complex and/or nonsymmetric) involved in a broad range of applications.", "paper_title": "The BiConjugate gradient method on GPUs", "paper_id": "WOS:000316408500006"}