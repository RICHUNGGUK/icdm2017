{"auto_keywords": [{"score": 0.04757311966409255, "phrase": "process_models"}, {"score": 0.0374786552751376, "phrase": "noisy_logs"}, {"score": 0.00481495049065317, "phrase": "study_of_quality_and_accuracy_trade-offs"}, {"score": 0.004775335634705251, "phrase": "process_mining"}, {"score": 0.004525629293824217, "phrase": "process_execution_logs"}, {"score": 0.004414806639101985, "phrase": "ordering_relationships"}, {"score": 0.004253618550301311, "phrase": "standard_constructs"}, {"score": 0.0039323225960857956, "phrase": "correct_execution_sequence"}, {"score": 0.0036502716977381004, "phrase": "correct_logs"}, {"score": 0.0032109670662222416, "phrase": "process_logs"}, {"score": 0.003132236287543072, "phrase": "block-structured_model"}, {"score": 0.002968192753809507, "phrase": "fully_accurate_process_model"}, {"score": 0.0028715299874549245, "phrase": "inaccurate_data"}, {"score": 0.0027323899681456535, "phrase": "low_quality"}, {"score": 0.0026324658253309673, "phrase": "optional_structures"}, {"score": 0.0024232694434408093, "phrase": "high-quality_process_models"}, {"score": 0.0022962708568492734, "phrase": "new_quality_metrics"}, {"score": 0.0022679195103377124, "phrase": "novel_quality-based_algorithm"}, {"score": 0.0021049977753042253, "phrase": "real_and_synthetic_data"}], "paper_keywords": ["process mining", " knowledge discovery", " quality metric", " quality-accuracy trade-off", " quality-based algorithm"], "paper_abstract": "In recent years, many algorithms have been proposed to extract process models from process execution logs. The process models describe the ordering relationships between tasks in a process in terms of standard constructs like sequence, parallel, choice, and loop. Most algorithms assume that each trace in a log represents a correct execution sequence based on a model. In practice, logs are often noisy, and algorithms designed for correct logs are not able to handle noisy logs. In this paper we share our key insights from a study of noise in process logs both real and synthetic. We found that all process logs can be explained by a block-structured model with two special self-loop and optional structures, making it trivial to build a fully accurate process model for any given log, even one with inaccurate data or noise present in it. However, such a model suffers from low quality. By controlling the use of self-loop and optional structures of tasks and blocks of tasks, we can balance the quality and accuracy trade-off to derive high-quality process models that explain a given percentage of traces in the log. Finally, new quality metrics and a novel quality-based algorithm for model extraction from noisy logs are described. The results of the experiments with the algorithm on real and synthetic data are reported and analyzed at length.", "paper_title": "A Study of Quality and Accuracy Trade-offs in Process Mining", "paper_id": "WOS:000303924600009"}