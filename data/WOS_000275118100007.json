{"auto_keywords": [{"score": 0.04278492914891542, "phrase": "acoustical_features"}, {"score": 0.03467996204914694, "phrase": "expressive_intentions"}, {"score": 0.00481495049065317, "phrase": "perceptual_organization_of_affective_and_sensorial_expressive_intentions"}, {"score": 0.004768649568826951, "phrase": "music_performance"}, {"score": 0.004722791767189843, "phrase": "expression_communication"}, {"score": 0.004654826737377134, "phrase": "added_value"}, {"score": 0.004587835274176236, "phrase": "musical_performance"}, {"score": 0.004185289462328125, "phrase": "previous_work"}, {"score": 0.004046020290832207, "phrase": "relevant_features"}, {"score": 0.003949377440799037, "phrase": "different_expressive_intentions"}, {"score": 0.003855034057431947, "phrase": "emotional_and_sensorial_adjectives"}, {"score": 0.003744780941673966, "phrase": "machine_learning_techniques"}, {"score": 0.003637669525737665, "phrase": "expressive_performances"}, {"score": 0.0035679633126097115, "phrase": "selected_features"}, {"score": 0.0034826993555190765, "phrase": "low-dimensional_space"}, {"score": 0.003350480663660326, "phrase": "acoustical_similarity"}, {"score": 0.0030414140732789186, "phrase": "subjective_evaluation"}, {"score": 0.002883718207958817, "phrase": "perceptual_point"}, {"score": 0.0026175952455594277, "phrase": "first_experiment"}, {"score": 0.0025181367444581993, "phrase": "different_categories"}, {"score": 0.002446024708601971, "phrase": "second_experiment"}, {"score": 0.002285674008055581, "phrase": "common_evaluation_criteria"}, {"score": 0.0021881743793875767, "phrase": "perceptual_organization"}, {"score": 0.0021670777282518424, "phrase": "affective_and_sensorial_expressive_intentions"}, {"score": 0.0021049977753042253, "phrase": "resulting_spatial_representation"}], "paper_keywords": ["Design", " Human Factors", " Expression", " music performance"], "paper_abstract": "Expression communication is the added value of a musical performance. It is part of the reason why music is interesting to listen to and sounds alive. Previous work on the analysis of acoustical features yielded relevant features for the recognition of different expressive intentions, inspired both by emotional and sensorial adjectives. In this article, machine learning techniques are employed to understand how expressive performances represented by the selected features are clustered on a low-dimensional space, and to define a measure of acoustical similarity. Being that expressive intentions are similar according to the features used for the recognition, and since recognition implies subjective evaluation, we hypothesized that performances are similar also from a perceptual point of view. We then compared and integrated the clustering of acoustical features with the results of two listening experiments. A first experiment aims at verifying whether subjects can distinguish different categories of expressive intentions, and a second experiment aims at understanding which expressions are perceptually clustered together in order to derive common evaluation criteria adopted by listeners, and to obtain the perceptual organization of affective and sensorial expressive intentions. An interpretation of the resulting spatial representation based on action is proposed and discussed.", "paper_title": "Perceptual Organization of Affective and Sensorial Expressive Intentions in Music Performance", "paper_id": "WOS:000275118100007"}