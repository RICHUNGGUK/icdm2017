{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "multi-layer_neural_networks"}, {"score": 0.010598398016088499, "phrase": "neural_networks"}, {"score": 0.007301800650444211, "phrase": "proposed_algorithm"}, {"score": 0.0033633514001658086, "phrase": "searching_process"}, {"score": 0.003015143226706584, "phrase": "three-layer_neural_networks"}, {"score": 0.002579140290642792, "phrase": "error_function"}, {"score": 0.002311933249234786, "phrase": "newton_iteration_method"}, {"score": 0.0021049977753042253, "phrase": "convergence_rate"}], "paper_keywords": ["multi-layer neural networks", " training algorithm", " coordinate rotation method SPDS algorithm"], "paper_abstract": "This paper proposes for multi-layer neural networks a learning algorithm which dynamically records the information of every sample as it goes through every neuron by means of several arrays, the information can be called by programs at any moment. For each searching process, only one parameter of the neural networks is allowed to change. The parameters of three-layer neural networks are classified into four categories. For each type, according to the characteristics of multi-layer neural networks, the expressions of error function and its first-order and second-order derivative are deduced in this algorithm. The Newton iteration method is applied to the proposed algorithm so as to speed up the convergence rate. The proposed algorithm adjusts the data in the arrays synchronously as long as changes occur in the parameters of the neural networks.", "paper_title": "A single parameter dynamic searching algorithm for multi-layer neural networks (part I)", "paper_id": "WOS:000259152300009"}