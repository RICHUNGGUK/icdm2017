{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "max-norm"}, {"score": 0.003988487841970088, "phrase": "general_non-uniform_sampling_distribution"}, {"score": 0.0036680857629458816, "phrase": "convex_relaxation"}, {"score": 0.003444732262403694, "phrase": "max-norm_constrained_maximum_likelihood_estimate"}, {"score": 0.0029131986574478046, "phrase": "information-theoretical_methods"}, {"score": 0.0025960262223338293, "phrase": "general_sampling_model"}, {"score": 0.0023133055945761235, "phrase": "optimal_rate"}, {"score": 0.002195162304124588, "phrase": "frobenius_norm_loss"}, {"score": 0.0021496083700137305, "phrase": "computational_algorithms"}, {"score": 0.0021049977753042253, "phrase": "numerical_performance"}], "paper_keywords": ["1-bit matrix completion", " low-rank matrix", " max-norm", " trace-norm", " constrained optimization", " maximum likelihood estimate", " optimal rate of convergence"], "paper_abstract": "We consider in this paper the problem of noisy 1-bit matrix completion under a general non-uniform sampling distribution using the max-norm as a convex relaxation for the rank. A max-norm constrained maximum likelihood estimate is introduced and studied. The rate of convergence for the estimate is obtained. Information-theoretical methods are used to establish a minimax lower bound under the general sampling model. The minimax upper and lower bounds together yield the optimal rate of convergence for the Frobenius norm loss. Computational algorithms and numerical performance are also discussed.", "paper_title": "A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion", "paper_id": "WOS:000335457100005"}