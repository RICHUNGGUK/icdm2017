{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "partial_variations"}, {"score": 0.015584374765208468, "phrase": "local_features"}, {"score": 0.015450179982189918, "phrase": "statistical_learning"}, {"score": 0.013865766846374993, "phrase": "facial_images"}, {"score": 0.010367593442893543, "phrase": "local_feature_descriptors"}, {"score": 0.004649474569983707, "phrase": "enormous_interest"}, {"score": 0.004608997772926119, "phrase": "face_recognition"}, {"score": 0.00450933377534525, "phrase": "computer_vision"}, {"score": 0.004470071518923524, "phrase": "pattern_recognition"}, {"score": 0.004278807087784626, "phrase": "diverse_variations"}, {"score": 0.003802135020791801, "phrase": "discriminative_feature"}, {"score": 0.0036393456309815166, "phrase": "core_information"}, {"score": 0.003607630811220324, "phrase": "original_images"}, {"score": 0.003438058620195309, "phrase": "face_recognition_method"}, {"score": 0.0032336801561165113, "phrase": "facial_image"}, {"score": 0.0031223774204093713, "phrase": "scale-invariant_feature_transform"}, {"score": 0.0027741761880779535, "phrase": "probability_density"}, {"score": 0.0027140798043053986, "phrase": "facial_data"}, {"score": 0.0026436755508085223, "phrase": "typical_variations"}, {"score": 0.002552628669352939, "phrase": "partial_occlusions"}, {"score": 0.002508284945907166, "phrase": "classification_stage"}, {"score": 0.002475532161577715, "phrase": "estimated_probability_density"}, {"score": 0.0024113009621042677, "phrase": "weighted_distance_measure"}, {"score": 0.002359046870732839, "phrase": "computational_experiments"}, {"score": 0.0023384629381463054, "phrase": "benchmark_data_sets"}, {"score": 0.0022777800735119405, "phrase": "proposed_method"}, {"score": 0.0021610874773389096, "phrase": "conventional_face_recognition_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Face recognition", " Local features", " Statistical learning", " SIFT", " Facial image variations"], "paper_abstract": "Despite the enormous interest in face recognition in the field of computer vision and pattern recognition, it still remains a challenge because of the diverse variations in facial images. In order to deal with variations such as illuminations, expressions, poses, and occlusions, it is important to find a discriminative feature that is robust to the variations while keeping the core information of original images. In this paper, we attempt to develop a face recognition method that is robust to partial variations through statistical learning of local features. By representing a facial image as a set of local feature descriptors such as scale-invariant feature transform (SIFT), we expect to achieve a representation robust to the variations in typical 2D images, such as illuminations and translations. By estimating the probability density of local feature descriptors observed in facial data, we expect to absorb typical variations in facial images, such as expressions and partial occlusions. In the classification stage, the estimated probability density is used to define the weighted distance measure between two images. Through computational experiments on benchmark data sets, we show that the proposed method is more robust to partial variations such as expressions and occlusions than conventional face recognition methods. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Robust recognition of face with partial variations using local features and statistical learning", "paper_id": "WOS:000332132400006"}