{"auto_keywords": [{"score": 0.04461281863692053, "phrase": "lallouache"}, {"score": 0.020437219175384585, "phrase": "escudier"}, {"score": 0.006024203774768158, "phrase": "benoit"}, {"score": 0.00481495049065317, "phrase": "speech_face_perception"}, {"score": 0.004747045411757796, "phrase": "speech_production"}, {"score": 0.004538237970796847, "phrase": "visual_speech_information"}, {"score": 0.004495457341039889, "phrase": "speech_identification"}, {"score": 0.004390254067258742, "phrase": "cathiard"}, {"score": 0.004348862343755694, "phrase": "tiberghien"}, {"score": 0.004307859176736301, "phrase": "tseva"}, {"score": 0.004247075069089933, "phrase": "m.-t."}, {"score": 0.004137847132703627, "phrase": "anticipatory_rounding"}, {"score": 0.004118290204189668, "phrase": "acoustic_pauses"}, {"score": 0.003993394845843522, "phrase": "xiith_international_congress"}, {"score": 0.003974517925101667, "phrase": "phonetic_sciences"}, {"score": 0.0039557298818491205, "phrase": "aix-en-provence"}, {"score": 0.0039371367946333564, "phrase": "france"}, {"score": 0.0037637181095425587, "phrase": "articulatory_measurements"}, {"score": 0.00373705659722071, "phrase": "silent_pauses"}, {"score": 0.0037018003824739625, "phrase": "perceptual_gating_paradigm"}, {"score": 0.00345591314303117, "phrase": "general_anticipatory_control_model"}, {"score": 0.0032647792316543604, "phrase": "coarticulation_models"}, {"score": 0.0032416406134314663, "phrase": "speech_sensitivity"}, {"score": 0.0032263057510551123, "phrase": "audio_visual_desynchronization"}, {"score": 0.0031958526151512332, "phrase": "stork"}, {"score": 0.003180960033617116, "phrase": "d."}, {"score": 0.00309899874032682, "phrase": "humans"}, {"score": 0.003069592752438294, "phrase": "nato"}, {"score": 0.0029905599321238077, "phrase": "springer-verlag"}, {"score": 0.0029764178439923455, "phrase": "berlin"}, {"score": 0.0029623275944170614, "phrase": "tokyo"}, {"score": 0.002852015921489843, "phrase": "consonant_auditory"}, {"score": 0.002838518963706938, "phrase": "visual_streams"}, {"score": 0.0027851650749963932, "phrase": "typical_cvcv_span"}, {"score": 0.002765416217014478, "phrase": "first_preliminary_test"}, {"score": 0.0025450776186520933, "phrase": "colloque"}, {"score": 0.0025390464483931504, "phrase": "de_physique"}, {"score": 0.0024677748410128334, "phrase": "francais_d'acoustique"}, {"score": 0.0023533964075338016, "phrase": "first_time"}, {"score": 0.002265713864915649, "phrase": "main_purpose"}, {"score": 0.002249639986821758, "phrase": "present_contribution"}, {"score": 0.0022231026365146815, "phrase": "new_data"}, {"score": 0.002191669798405392, "phrase": "apparent_contradictions"}, {"score": 0.0021351902267935726, "phrase": "speakers'_behavior"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Auditory-visual speech perception", " Speech production", " Anticipation"], "paper_abstract": "At the beginning of the 90's, it was definitively demonstrated that as early as the visual speech information is perceivable, speech identification can be processed. Cathiard et al. [Cathiard, M.-A., Tiberghien, G., Tseva, A., Lallouache, M.-T., Escudier, P., 1991. Visual perception of anticipatory rounding during acoustic pauses: a cross-language study. In: Proceedings of the XIIth International Congress of Phonetic Sciences, Aix-en-Provence, France, 4, pp. 50-53] used different V-to-V anticipatory spans, with articulatory measurements, along silent pauses, in a perceptual gating paradigm, and established that up to 200 ms \"speech can be seen before it is heard\". These results were later framed into the framework of a general anticipatory control model, the Movement Expansion Model [Abry, C., Lallouache, M.-T., Cathiard, M.-A., 1996]. How can coarticulation models account for speech sensitivity to audio visual desynchronization? In: Stork, D., Hennecke, M. (Eds.), Speechreading by Humans and Machines, NATO ASI Series F: Computer, Vol. 150. Springer-Verlag, Berlin, Tokyo, pp. 247-255]. Surprisingly the timing of the vowel and consonant auditory and visual streams remained until now poorly understood within the typical CVCV span. A first preliminary test was published by Escudier, Benoit and Lallouache [Escudier, P., Benoit, C., Lallouache, M.-T., 1990. Identification visuelle de stimuli associes a l'opposition /i/-/y/: etude statique. Colloque de physique, supplement au n(o) 2, tome 51, ler Congres Francais d'Acoustique, C2-541-544]: this is the issue we took up again more than 10 years later. And for the first time we found that \"speech can be heard before it is seen\". The main purpose of the present contribution will be to bring new data in order to clear up apparent contradictions, essentially due to misconceptions of variability and lawfulness in speakers' behavior. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Speech face perception is locked to anticipation in speech production", "paper_id": "WOS:000278282000005"}