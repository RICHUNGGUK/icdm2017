{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "human_annotation"}, {"score": 0.012977958185259214, "phrase": "antiquated_ideal"}, {"score": 0.004743806810821005, "phrase": "big_data"}, {"score": 0.0046046429665581555, "phrase": "disruptive_impact"}, {"score": 0.004370814742381778, "phrase": "semantic_interpretation_tasks"}, {"score": 0.004274257668843717, "phrase": "critical_part"}, {"score": 0.004211069233133584, "phrase": "big_data_semantics"}, {"score": 0.0038798015183611275, "phrase": "single_correct_truth"}, {"score": 0.003601235776892337, "phrase": "seven_myths"}, {"score": 0.00296675450822924, "phrase": "new_theory"}, {"score": 0.0026726283357752585, "phrase": "human_interpretation"}, {"score": 0.002217880187104576, "phrase": "useful_representation"}, {"score": 0.0021049977753042253, "phrase": "reasonable_interpretations"}], "paper_keywords": [""], "paper_abstract": "Big data is having a disruptive impact across the sciences. Human annotation of semantic interpretation tasks is a critical part of big data semantics, but it is based on an antiquated ideal of a single correct truth that needs to be similarly disrupted. We expose seven myths about human annotation, most of which derive from that antiquated ideal of truth, and dispel these myths with examples from our research. We propose a new theory of truth, crowd truth, that is based on the intuition that human interpretation is subjective, and that measuring annotations on the same objects of interpretation (in our examples, sentences) across a crowd will provide a useful representation of their subjectivity and the range of reasonable interpretations.", "paper_title": "Truth Is a Lie: Crowd Truth and the Seven Myths of Human Annotation", "paper_id": "WOS:000353079700003"}