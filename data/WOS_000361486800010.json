{"auto_keywords": [{"score": 0.048706186715194215, "phrase": "side_information"}, {"score": 0.015719716506582538, "phrase": "logarithmic_loss"}, {"score": 0.01248289411401326, "phrase": "random_variable"}, {"score": 0.010435409021063343, "phrase": "mutual_information"}, {"score": 0.004542780650208743, "phrase": "natural_measure"}, {"score": 0.004361428012479218, "phrase": "optimal_prediction_risk"}, {"score": 0.004067152645111547, "phrase": "relevance_measure"}, {"score": 0.0037487368769596814, "phrase": "loss_function"}, {"score": 0.003619993477999133, "phrase": "natural_data_processing_property"}, {"score": 0.0034551632687788857, "phrase": "alphabet_size"}, {"score": 0.0031111332159761344, "phrase": "corresponding_loss_function"}, {"score": 0.0029009722548088306, "phrase": "new_characterization"}, {"score": 0.0024072121760839427, "phrase": "specified_data_processing_property"}, {"score": 0.0022841153001549193, "phrase": "causal_influence"}, {"score": 0.0022576249214220187, "phrase": "stochastic_processes"}, {"score": 0.0021927323694667694, "phrase": "different_causality_measures"}, {"score": 0.0021049977753042253, "phrase": "directed_information"}], "paper_keywords": ["Axiomatic characterizations", " causality measures", " data processing", " directed information", " logarithmic loss"], "paper_abstract": "We consider a natural measure of relevance: the reduction in optimal prediction risk in the presence of side information. For any given loss function, this relevance measure captures the benefit of side information for performing inference on a random variable under this loss function. When such a measure satisfies a natural data processing property, and the random variable of interest has alphabet size greater than two, we show that it is uniquely characterized by the mutual information, and the corresponding loss function coincides with logarithmic loss. In doing so, our work provides a new characterization of mutual information, and justifies its use as a measure of relevance. When the alphabet is binary, we characterize the only admissible forms the measure of relevance can assume while obeying the specified data processing property. Our results naturally extend to measuring the causal influence between stochastic processes, where we unify different causality measures in the literature as instantiations of directed information.", "paper_title": "Justification of Logarithmic Loss via the Benefit of Side Information", "paper_id": "WOS:000361486800010"}