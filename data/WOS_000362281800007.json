{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "frequently-accessed_cache_item"}, {"score": 0.003714368305523811, "phrase": "cache_stampede"}, {"score": 0.0034063576796640603, "phrase": "web_servers"}, {"score": 0.003309452522760298, "phrase": "natural_countermeasure"}, {"score": 0.002730023736069673, "phrase": "expiration_time"}, {"score": 0.00247944491239733, "phrase": "optimal_algorithms"}, {"score": 0.0023857603808363527, "phrase": "early_expirations"}, {"score": 0.0021049977753042253, "phrase": "real-world_applications"}], "paper_keywords": [""], "paper_abstract": "When a frequently-accessed cache item expires, multiple requests to that item can trigger a cache miss and start regenerating that same item at the same time. This phenomenon, known as cache stampede, severely limits the performance of databases and web servers. A natural countermeasure to this issue is to let the processes that perform such requests to randomly ask for a regeneration before the expiration time of the item. In this paper we give optimal algorithms for performing such probabilistic early expirations. Our algorithms are theoretically optimal and have much better performances than other solutions used in real-world applications.", "paper_title": ". Optimal Probabilistic Cache Stampede Prevention", "paper_id": "WOS:000362281800007"}