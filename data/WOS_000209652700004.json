{"auto_keywords": [{"score": 0.03593541658762068, "phrase": "human_beings"}, {"score": 0.010389175602450866, "phrase": "mas"}, {"score": 0.008515524316456987, "phrase": "trust_management"}, {"score": 0.00481495049065317, "phrase": "multi-agent_trust_management_systems"}, {"score": 0.004749824776508639, "phrase": "open_and_dynamic_multiagent_systems"}, {"score": 0.00385431710959668, "phrase": "serious_breakdowns"}, {"score": 0.0034717929086014636, "phrase": "age-old_mechanism"}, {"score": 0.0032725712584012953, "phrase": "basic_idea"}, {"score": 0.0030017207229983385, "phrase": "future_interaction_decisions"}, {"score": 0.0028944757265206332, "phrase": "large_number"}, {"score": 0.0028682668647074397, "phrase": "trust_management_models"}, {"score": 0.0027282915297520624, "phrase": "research_effort"}, {"score": 0.0023694065215394593, "phrase": "existing_research"}, {"score": 0.0022847009758393405, "phrase": "existing_trust_models"}, {"score": 0.0022537212268979507, "phrase": "game_theoretic_perspective"}, {"score": 0.002213065910356615, "phrase": "special_implications"}, {"score": 0.0021049977753042253, "phrase": "possible_research_agenda"}], "paper_keywords": ["Trust", " reputation", " multi-agent systems", " game theory"], "paper_abstract": "In open and dynamic multiagent systems (MASs), agents often need to rely on resources or services provided by other agents to accomplish their goals. During this process, agents are exposed to the risk of being exploited by others. These risks, if not mitigated, can cause serious breakdowns in the operation of MASs and threaten their long-term wellbeing. To protect agents from the uncertainty in the behavior of their interaction partners, the age-old mechanism of trust between human beings is re-contexted into MASs. The basic idea is to let agents self-police the MAS by rating each other on the basis of their observed behavior and basing future interaction decisions on such information. Over the past decade, a large number of trust management models were proposed. However, there is a lack of research effort in several key areas, which are critical to the success of trust management in MASs where human beings and agents coexist. The purpose of this paper is to give an overview of existing research in trust management in MASs. We analyze existing trust models from a game theoretic perspective to highlight the special implications of including human beings in an MAS, and propose a possible research agenda to advance the state of the art in this field.", "paper_title": "A Survey of Multi-Agent Trust Management Systems", "paper_id": "WOS:000209652700004"}