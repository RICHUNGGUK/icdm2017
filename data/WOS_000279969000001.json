{"auto_keywords": [{"score": 0.048934493542192786, "phrase": "color_images"}, {"score": 0.014332697622971458, "phrase": "visual_cues"}, {"score": 0.011951642005864748, "phrase": "human-computer_interactions"}, {"score": 0.011235438943195803, "phrase": "new_algorithm"}, {"score": 0.011082137791149605, "phrase": "probabilistic_graphical_model"}, {"score": 0.00481495049065317, "phrase": "visual_cue_preservation"}, {"score": 0.004667454318370122, "phrase": "gray-scale_images"}, {"score": 0.004540126719762935, "phrase": "publication_cost"}, {"score": 0.004416257191177784, "phrase": "blind_people"}, {"score": 0.004295752645085445, "phrase": "conventional_color"}, {"score": 0.004266141613620429, "phrase": "gray_algorithms"}, {"score": 0.004193000200816171, "phrase": "practical_applications"}, {"score": 0.003899199029692063, "phrase": "important_cues"}, {"score": 0.003858936100805083, "phrase": "transformed_gray-scale_images"}, {"score": 0.0037665925842197967, "phrase": "extremely_high_time_cost"}, {"score": 0.0036008989464331835, "phrase": "reasonable_transformation"}, {"score": 0.0032569835069392924, "phrase": "markov_random_field"}, {"score": 0.003190024306903021, "phrase": "gray_procedure"}, {"score": 0.0031244373828278236, "phrase": "labeling_process"}, {"score": 0.0030814613175385703, "phrase": "newly_well-defined_visual_cues"}, {"score": 0.0030076664326204013, "phrase": "transformed_gray-scale_image"}, {"score": 0.0028852371404397862, "phrase": "color_image"}, {"score": 0.0026643006135750025, "phrase": "different_people"}, {"score": 0.0026367554281038572, "phrase": "different_cues"}, {"score": 0.0023356349192255074, "phrase": "visual_cue_preservation_procedure"}, {"score": 0.0022404996930993413, "phrase": "integral_minimization_problem"}, {"score": 0.002179234170770192, "phrase": "natural_color_images"}, {"score": 0.002164180792169302, "phrase": "artificial_pictures"}, {"score": 0.002119640369431708, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "representative_conventional_algorithms"}], "paper_keywords": ["Color to gray", " probabilistic graphical model", " visual cue"], "paper_abstract": "Both commercial and scientific applications often need to transform color images into gray-scale images, e. g., to reduce the publication cost in printing color images or to help color blind people see visual cues of color images. However, conventional color to gray algorithms are not ready for practical applications because they encounter the following problems: 1) Visual cues are not well defined so it is unclear how to preserve important cues in the transformed gray-scale images; 2) some algorithms have extremely high time cost for computation; and 3) some require human-computer interactions to have a reasonable transformation. To solve or at least reduce these problems, we propose a new algorithm based on a probabilistic graphical model with the assumption that the image is defined over a Markov random field. Thus, color to gray procedure can be regarded as a labeling process to preserve the newly well-defined visual cues of a color image in the transformed gray-scale image. Visual cues are measurements that can be extracted from a color image by a perceiver. They indicate the state of some properties of the image that the perceiver is interested in perceiving. Different people may perceive different cues from the same color image and three cues are defined in this paper, namely, color spatial consistency, image structure information, and color channel perception priority. We cast color to gray as a visual cue preservation procedure based on a probabilistic graphical model and optimize the model based on an integral minimization problem. We apply the new algorithm to both natural color images and artificial pictures, and demonstrate that the proposed approach outperforms representative conventional algorithms in terms of effectiveness and efficiency. In addition, it requires no human-computer interactions.", "paper_title": "Color to Gray: Visual Cue Preservation", "paper_id": "WOS:000279969000001"}