{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "distributed_multilevel_diversity_coding"}, {"score": 0.004587637898736067, "phrase": "k"}, {"score": 0.004303830426772906, "phrase": "k_components"}, {"score": 0.0040481944502103505, "phrase": "distributed_manner"}, {"score": 0.0036928221419965253, "phrase": "alpha_encoders"}, {"score": 0.003438058620195309, "phrase": "first_alpha_components"}, {"score": 0.0032668821950788533, "phrase": "corresponding_alpha_sources"}, {"score": 0.002949598537993663, "phrase": "multilayer_slepian-wolf_coding_scheme"}, {"score": 0.0023798115577749225, "phrase": "general_k"}, {"score": 0.0021928902836049384, "phrase": "celebrated_result"}, {"score": 0.0021485016752498497, "phrase": "yeung"}, {"score": 0.002105173923807407, "phrase": "zhang"}], "paper_keywords": ["Data compression", " diversity coding", " entropy inequality", " Lagrange multiplier", " linear programming", " rate region", " Slepian-Wolf", " superposition"], "paper_abstract": "In distributed multilevel diversity coding, K correlated sources (each with K components) are encoded in a distributed manner such that, given the outputs from any alpha encoders, the decoder can reconstruct the first alpha components of each of the corresponding alpha sources. For this problem, the optimality of a multilayer Slepian-Wolf coding scheme based on binning and superposition is established when K <= 3. The same conclusion is shown to hold for general K under a certain symmetry condition, which generalizes a celebrated result by Yeung and Zhang.", "paper_title": "Distributed Multilevel Diversity Coding", "paper_id": "WOS:000363256500040"}