{"auto_keywords": [{"score": 0.04366249129064219, "phrase": "defective_classes"}, {"score": 0.015096354488044243, "phrase": "software_quality"}, {"score": 0.008274194333597724, "phrase": "design_evolution_metrics"}, {"score": 0.00481495049065317, "phrase": "defect_prediction"}, {"score": 0.004775726266706856, "phrase": "object_oriented_systems"}, {"score": 0.0044005599565517875, "phrase": "available_resources"}, {"score": 0.0043114466990006334, "phrase": "object-oriented_development"}, {"score": 0.004021689117050817, "phrase": "challenging_and_difficult_activity"}, {"score": 0.0036753171449945654, "phrase": "elementary_design_evolution_metrics"}, {"score": 0.0033176589215021353, "phrase": "ranked_list"}, {"score": 0.0031199432791946405, "phrase": "chidamber"}, {"score": 0.0030944828434567966, "phrase": "kemerer's_metrics"}, {"score": 0.0030441844088874366, "phrase": "rhino"}, {"score": 0.002933973181012572, "phrase": "complexity_metrics"}, {"score": 0.002898127432512101, "phrase": "zimmermann_et_al"}, {"score": 0.0028394608929512553, "phrase": "eclipse"}, {"score": 0.002583931950389087, "phrase": "top-ranked_classes"}, {"score": 0.002449839292715327, "phrase": "known_metrics"}, {"score": 0.0022849068677290836, "phrase": "significantly_better_predictions"}, {"score": 0.002266246304762945, "phrase": "defect_density"}, {"score": 0.002157433262687853, "phrase": "testing_effort"}, {"score": 0.002131054594847684, "phrase": "test_activity"}, {"score": 0.0021049977753042253, "phrase": "reduced_volume"}], "paper_keywords": ["Defect prediction", " Design evolution metrics", " Error tolerant graph matching"], "paper_abstract": "Testing is the most widely adopted practice to ensure software quality. However, this activity is often a compromise between the available resources and software quality. In object-oriented development, testing effort should be focused on defective classes. Unfortunately, identifying those classes is a challenging and difficult activity on which many metrics, techniques, and models have been tried. In this paper, we investigate the usefulness of elementary design evolution metrics to identify defective classes. The metrics include the numbers of added, deleted, and modified attributes, methods, and relations. The metrics are used to recommend a ranked list of classes likely to contain defects for a system. They are compared to Chidamber and Kemerer's metrics on several versions of Rhino and of ArgoUML. Further comparison is conducted with the complexity metrics computed by Zimmermann et al. on several releases of Eclipse. The comparisons are made according to three criteria: presence of defects, number of defects, and defect density in the top-ranked classes. They show that the design evolution metrics, when used in conjunction with known metrics, improve the identification of defective classes. In addition, they show that the design evolution metrics make significantly better predictions of defect density than other metrics and, thus, can help in reducing the testing effort by focusing test activity on a reduced volume of code.", "paper_title": "Design evolution metrics for defect prediction in object oriented systems", "paper_id": "WOS:000287097200006"}