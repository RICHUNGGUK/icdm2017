{"auto_keywords": [{"score": 0.03793044352294926, "phrase": "clomp"}, {"score": 0.00481495049065317, "phrase": "openmp_application_overheads"}, {"score": 0.004485735417293941, "phrase": "widespread_use"}, {"score": 0.00443308765153716, "phrase": "large_scale_systems"}, {"score": 0.004228577663320847, "phrase": "sufficient_performance"}, {"score": 0.0040097139701644165, "phrase": "openmp_regions"}, {"score": 0.00384731849108269, "phrase": "desired_openmp_usage_scenario"}, {"score": 0.0033984088755183287, "phrase": "openmp_implementations"}, {"score": 0.0032800186243040663, "phrase": "existing_epcc_benchmark_suite"}, {"score": 0.003091767402370757, "phrase": "openmp_overheads"}, {"score": 0.0030017207229983385, "phrase": "application_usage_scenarios"}, {"score": 0.002651213849567608, "phrase": "epcc."}, {"score": 0.002498961351132696, "phrase": "openmp_parallelization"}, {"score": 0.00246957392654378, "phrase": "smt_and_numa_systems"}, {"score": 0.0024118292918742967, "phrase": "clompi"}, {"score": 0.0022598906141897087, "phrase": "openmp"}, {"score": 0.002181069180139225, "phrase": "mpi_helper_threads"}, {"score": 0.002104997932051691, "phrase": "nic."}], "paper_keywords": ["OpenMP", " Benchmarking", " Performance", " Profiling", " Shared memory"], "paper_abstract": "Despite its ease of use, OpenMP has failed to gain widespread use on large scale systems, largely due to its failure to deliver sufficient performance. Our experience indicates that the cost of initiating OpenMP regions is simply too high for the desired OpenMP usage scenario of many applications. In this paper, we introduce CLOMP, a new benchmark to characterize this aspect of OpenMP implementations accurately. CLOMP complements the existing EPCC benchmark suite to provide simple, easy to understand measurements of OpenMP overheads in the context of application usage scenarios. Our results for several OpenMP implementations demonstrate that CLOMP identifies the amount of work required to compensate for the overheads observed with EPCC. We also show that CLOMP also captures limitations for OpenMP parallelization on SMT and NUMA systems. Finally, CLOMPI, our MPI extension of CLOMP, demonstrates which aspects of OpenMP interact poorly with MPI when MPI helper threads cannot run on the NIC.", "paper_title": "CLOMP: Accurately Characterizing OpenMP Application Overheads", "paper_id": "WOS:000266089000002"}