{"auto_keywords": [{"score": 0.04327832021381773, "phrase": "base_classifiers"}, {"score": 0.009533956334618668, "phrase": "transformed_dataset"}, {"score": 0.00481495049065317, "phrase": "multiclass_boosting"}, {"score": 0.00440976345264104, "phrase": "multiclass_datasets"}, {"score": 0.003968112038249246, "phrase": "hamming_loss"}, {"score": 0.0037862398004482253, "phrase": "loss_functions"}, {"score": 0.0036126731589251906, "phrase": "k_weights"}, {"score": 0.0032697235411641695, "phrase": "m-example_dataset"}, {"score": 0.0030833537429977797, "phrase": "km_examples"}, {"score": 0.0027741761880779535, "phrase": "original_dataset"}, {"score": 0.0026313840069327713, "phrase": "time_efficiency"}, {"score": 0.0025254115243261875, "phrase": "weighted_examples"}, {"score": 0.002381365139274329, "phrase": "naive_bayes"}, {"score": 0.002353554841514325, "phrase": "decision_trees"}, {"score": 0.0021805284035566553, "phrase": "ecc"}, {"score": 0.0021049977753042253, "phrase": "output_coding"}], "paper_keywords": ["ensemble methods", " boosting", " multiclass learning", " pseudoloss", " Hamming loss"], "paper_abstract": "AdaBoost.M2 and AdaBoost. MH are boosting algorithms for learning from multiclass datasets. They have received less attention than other boosting algorithms because they require base classifiers that can handle the pseudoloss or Hamming loss, respectively. The difficulty with these loss functions is that each example is associated with k weights, where k is the number of classes. We address this issue by transforming an m-example dataset with k weights per example into a dataset with km examples and one weight per example. Minimising error on the transformed dataset is equivalent to minimising loss on the original dataset. Resampling the transformed dataset can be used for time efficiency and base classifiers that cannot handle weighted examples. We empirically apply the transformation on several multiclass datasets using naive Bayes and decision trees as base classifiers. Our experiment shows that it is competitive with AdaBoost. ECC, a boosting algorithm using output coding.", "paper_title": "Transforming examples for multiclass boosting", "paper_id": "WOS:000274673700003"}