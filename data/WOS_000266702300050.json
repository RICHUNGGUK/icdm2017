{"auto_keywords": [{"score": 0.049757144405741305, "phrase": "receptive_fields"}, {"score": 0.00481495049065317, "phrase": "multilayer_perceptrons"}, {"score": 0.0047026237903774895, "phrase": "neural_networks"}, {"score": 0.004562027986828209, "phrase": "new_neural_network_architecture"}, {"score": 0.0044706300051082035, "phrase": "referential_multilayer_perceptrons"}, {"score": 0.0043663006236597975, "phrase": "generalized_receptive_fields"}, {"score": 0.004150829420202823, "phrase": "considerable_level"}, {"score": 0.004081385289516914, "phrase": "resulting_receptive_fields"}, {"score": 0.0038930368103015467, "phrase": "locally_available_experimental_data"}, {"score": 0.003802135020791801, "phrase": "design_strategy"}, {"score": 0.003763827319426842, "phrase": "novel_architecture"}, {"score": 0.003700833742881285, "phrase": "modeling_capabilities"}, {"score": 0.0036635429301869527, "phrase": "contributing_rmlps"}, {"score": 0.0035539019235553897, "phrase": "first_phase"}, {"score": 0.003401278997237025, "phrase": "specialized_version"}, {"score": 0.0033669963955215427, "phrase": "commonly_encountered_fuzzy_c-means"}, {"score": 0.0030839447259626215, "phrase": "information_granules"}, {"score": 0.0029915976131073825, "phrase": "input_and_output_variables"}, {"score": 0.002892219926795975, "phrase": "second_phase"}, {"score": 0.002843772431469196, "phrase": "global_view"}, {"score": 0.002767934112798688, "phrase": "input-output_relationships"}, {"score": 0.002685024286204448, "phrase": "rmlp"}, {"score": 0.00257831812581194, "phrase": "corresponding_context"}, {"score": 0.0025696192337207155, "phrase": "fuzzy_set"}, {"score": 0.00252656192077797, "phrase": "receptive_field"}, {"score": 0.0024674880645446312, "phrase": "locally_available_data"}, {"score": 0.0024343522820859578, "phrase": "nonlinear_mapping"}, {"score": 0.0024097920845706795, "phrase": "referential_mode"}, {"score": 0.0023139986108451946, "phrase": "global_minimization"}, {"score": 0.0022906498741695094, "phrase": "linear_aggregation_unit"}, {"score": 0.002259883463607508, "phrase": "output_layer"}, {"score": 0.0022370795358896784, "phrase": "overall_architecture"}, {"score": 0.0021773853011112882, "phrase": "numeric_experiments"}, {"score": 0.002162711766975021, "phrase": "synthetic_and_real-world_data_sets"}, {"score": 0.0021049977753042253, "phrase": "standard_rbf_neural_networks"}], "paper_keywords": ["Conditional clustering", " Local modeling", " Neural receptive fields", " Radial basis function (RBF) networks", " Referential neural networks"], "paper_abstract": "In this paper, we propose a new neural network architecture based on a family of referential multilayer perceptrons (RMLPs)that play a role of generalized receptive fields. In contrast to \"standard\" radial basis function (RBF) neural networks, the proposed topology of the network offers a considerable level of flexibility as the resulting receptive fields are highly diversified and capable of adjusting themselves to the characteristics of the locally available experimental data. We discuss in detail a design strategy of the novel architecture that fully exploits the modeling capabilities of the contributing RMLPs. The strategy comprises three phases. In the first phase, we form a \"blueprint\" of the network by employing a specialized version of the commonly encountered fuzzy C-means (FCM) clustering algorithm, namely the conditional (context-based) FCM. In this phase our intent is to generate a collection of information granules (fuzzy sets) in the space of input and output variables, narrowed down to some certain contexts. In the second phase, based upon a global view at the structure, we refine the input-output relationships by engaging a collection of RMLPs where each RMLP is trained by using the subset of data associated with the corresponding context fuzzy set. During training each receptive field focuses on the characteristics of these locally available data and builds a nonlinear mapping in a referential mode. Finally, the connections of the receptive fields are optimized through global minimization of the linear aggregation unit located at the output layer of the overall architecture. We also include a series of numeric experiments involving synthetic and real-world data sets which provide a thorough comparative analysis with standard RBF neural networks. (c) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Using multilayer perceptrons as receptive fields in the design of neural networks", "paper_id": "WOS:000266702300050"}