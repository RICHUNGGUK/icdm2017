{"auto_keywords": [{"score": 0.05007851542092211, "phrase": "head_gesture"}, {"score": 0.04127376972439469, "phrase": "hgi"}, {"score": 0.04011642300399219, "phrase": "identity_verification"}, {"score": 0.004174824849669107, "phrase": "natural_and_sensitive_user-wheelchair_interface"}, {"score": 0.004053362743156545, "phrase": "original_integrated_approach"}, {"score": 0.003974349782102708, "phrase": "based_interface"}, {"score": 0.0037834649508375544, "phrase": "facial_pose_estimation"}, {"score": 0.0036733470451885465, "phrase": "two-factor_face_authentication"}, {"score": 0.003531474887552889, "phrase": "topographic_independent_component_analysis"}, {"score": 0.003445591238183763, "phrase": "multispace_random_projection"}, {"score": 0.0033452741392850523, "phrase": "synergetic_computer"}, {"score": 0.0031377955308198634, "phrase": "facial_poses"}, {"score": 0.003107034833468438, "phrase": "motion_profile_generator"}, {"score": 0.002914288956035066, "phrase": "estimated_facial_pose"}, {"score": 0.0028715299874549245, "phrase": "motion_control"}, {"score": 0.0028293966058473476, "phrase": "actuate_motor_movements"}, {"score": 0.002680114113899346, "phrase": "user-wheelchair_interface"}, {"score": 0.0026538282523433684, "phrase": "disabled_and_elderly_users"}, {"score": 0.0025892330566358503, "phrase": "genuine_face"}, {"score": 0.0025638362414466278, "phrase": "valid_token"}, {"score": 0.0025137856138000014, "phrase": "authorized_access"}, {"score": 0.0024525907271610125, "phrase": "electric_powered_wheelchair"}, {"score": 0.0024285367068965524, "phrase": "epw"}, {"score": 0.0021682027434117095, "phrase": "proposed_face-based_control_strategy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Facial pose estimation", " Face authentication", " Head gesture based interface", " State machine", " Electric powered wheelchair"], "paper_abstract": "The head pose and movement of a user is closely related with his/her intention and thought, recognition of such information could be useful to develop a natural and sensitive user-wheelchair interface. This paper presents an original integrated approach to a head gesture based interface (HGI) which can perform both identity verification and facial pose estimation. Identity verification is performed by two-factor face authentication which is implemented by the combination of topographic independent component analysis (TICA) and multispace random projection (MRP). Modified synergetic computer with melting (Modified SC-MELT) is introduced to classify facial poses. Motion profile generator (MPG) is thoroughly developed during the integration to convert each estimated facial pose sequence into motion control signal to actuate motor movements. The HGI is intended to be deployed as a user-wheelchair interface for disabled and elderly users in which only users with genuine face and valid token may be granted authorized access and hence pilot an electric powered wheelchair (EPW) using their faces. The integration has been verified under a number of experiments to justify the feasibility and performance of the proposed face-based control strategy. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "An integrated approach for head gesture based interface", "paper_id": "WOS:000299324200010"}