{"auto_keywords": [{"score": 0.03351070397865124, "phrase": "complex_objects"}, {"score": 0.013663048037458232, "phrase": "distance_measure"}, {"score": 0.004814954423896811, "phrase": "cid"}, {"score": 0.004580872896983597, "phrase": "almost_all_human_endeavors"}, {"score": 0.004533055713299744, "phrase": "great_interest"}, {"score": 0.00450933377534525, "phrase": "time_series_data_mining"}, {"score": 0.004427276005631389, "phrase": "classification_algorithms"}, {"score": 0.00433531459712787, "phrase": "recent_empirical_evidence"}, {"score": 0.004290049612864442, "phrase": "simple_nearest_neighbor_classification"}, {"score": 0.004135296401536423, "phrase": "nearest_neighbor_algorithm"}, {"score": 0.003954837422946628, "phrase": "motion_capture_data"}, {"score": 0.0038726511261766377, "phrase": "cardiology_data"}, {"score": 0.003732898113268911, "phrase": "recent_work"}, {"score": 0.0036938996194386016, "phrase": "time_series_clustering"}, {"score": 0.003468287913322255, "phrase": "somewhat_surprising_claim"}, {"score": 0.0032393479516888996, "phrase": "different_classes"}, {"score": 0.003213920601037463, "phrase": "different_complexities"}, {"score": 0.0030735451757603555, "phrase": "human_eye"}, {"score": 0.0030096178580223676, "phrase": "current_distance_measures"}, {"score": 0.0029781530607129653, "phrase": "simple_objects"}, {"score": 0.0029238768315330305, "phrase": "nearest_neighbor_classification"}, {"score": 0.0028405715222684183, "phrase": "simpler_class"}, {"score": 0.0027164585428301837, "phrase": "clustering_algorithm"}, {"score": 0.002645992747675361, "phrase": "sparser_and_larger_diameter_cluster"}, {"score": 0.0025841336988141235, "phrase": "first_complexity-invariant_distance_measure"}, {"score": 0.00251048377083841, "phrase": "significant_improvements"}, {"score": 0.002320090649243125, "phrase": "triangular_inequality"}, {"score": 0.002271798880229819, "phrase": "data_mining_algorithms"}, {"score": 0.0022303670135912714, "phrase": "largest_and_most_comprehensive_set"}, {"score": 0.002218668420806254, "phrase": "time_series_mining_experiments"}, {"score": 0.0021896891011033105, "phrase": "single_work"}, {"score": 0.0021610874773389096, "phrase": "complexity-invariant_distance_measures"}, {"score": 0.0021049977753042253, "phrase": "vast_majority"}], "paper_keywords": ["Time series", " Classification", " Clustering", " Similarity measures", " Complexity"], "paper_abstract": "The ubiquity of time series data across almost all human endeavors has produced a great interest in time series data mining in the last decade. While dozens of classification algorithms have been applied to time series, recent empirical evidence strongly suggests that simple nearest neighbor classification is exceptionally difficult to beat. The choice of distance measure used by the nearest neighbor algorithm is important, and depends on the invariances required by the domain. For example, motion capture data typically requires invariance to warping, and cardiology data requires invariance to the baseline (the mean value). Similarly, recent work suggests that for time series clustering, the choice of clustering algorithm is much less important than the choice of distance measure used.In this work we make a somewhat surprising claim. There is an invariance that the community seems to have missed, complexity invariance. Intuitively, the problem is that in many domains the different classes may have different complexities, and pairs of complex objects, even those which subjectively may seem very similar to the human eye, tend to be further apart under current distance measures than pairs of simple objects. This fact introduces errors in nearest neighbor classification, where some complex objects may be incorrectly assigned to a simpler class. Similarly, for clustering this effect can introduce errors by \"suggesting\" to the clustering algorithm that subjectively similar, but complex objects belong in a sparser and larger diameter cluster than is truly warranted.We introduce the first complexity-invariant distance measure for time series, and show that it generally produces significant improvements in classification and clustering accuracy. We further show that this improvement does not compromise efficiency, since we can lower bound the measure and use a modification of triangular inequality, thus making use of most existing indexing and data mining algorithms. We evaluate our ideas with the largest and most comprehensive set of time series mining experiments ever attempted in a single work, and show that complexity-invariant distance measures can produce improvements in classification and clustering in the vast majority of cases.", "paper_title": "CID: an efficient complexity-invariant distance for time series", "paper_id": "WOS:000331632100003"}