{"auto_keywords": [{"score": 0.04466781698087983, "phrase": "object_affordances"}, {"score": 0.03924757433032126, "phrase": "effect_categories"}, {"score": 0.00481495049065317, "phrase": "perceptual_space"}, {"score": 0.004767261858417823, "phrase": "learned_affordances"}, {"score": 0.004424268136268051, "phrase": "anthropomorphic_robot"}, {"score": 0.004337028108577593, "phrase": "range_camera"}, {"score": 0.004065156038847781, "phrase": "first_step"}, {"score": 0.0036250779580069455, "phrase": "second_step"}, {"score": 0.0031372369299648203, "phrase": "desired_goals"}, {"score": 0.0030906666356950887, "phrase": "end_states"}, {"score": 0.0030600032877646263, "phrase": "demonstrated_actions"}, {"score": 0.00299958349498286, "phrase": "plan_execution"}, {"score": 0.002955050521440921, "phrase": "corrective_actions"}, {"score": 0.0029111767710750117, "phrase": "perceptual_structures"}, {"score": 0.0027557911038816256, "phrase": "learning_system"}, {"score": 0.0027284410545226306, "phrase": "shares_crucial_elements"}, {"score": 0.002444883254621769, "phrase": "goal-free_exploration"}, {"score": 0.0023609780669713288, "phrase": "goal_emulation"}, {"score": 0.0022913497040895586, "phrase": "older_infants"}, {"score": 0.0022573076362326135, "phrase": "symbolic_inference_capability"}, {"score": 0.002234893735225432, "phrase": "non-linguistic_animals"}, {"score": 0.002168975681697056, "phrase": "action_plans"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Affordance", " Developmental robotics", " Sensorimotor learning", " Manipulation", " Perception", " Cognitive robotics"], "paper_abstract": "In this paper, we show that through self-interaction and self-observation, an anthropomorphic robot equipped with a range camera can learn object affordances and use this knowledge for planning. In the first step of learning, the robot discovers commonalities in its action-effect experiences by discovering effect categories. Once the effect categories are discovered, in the second step, affordance predictors for each behavior are obtained by learning the mapping from the object features to the effect categories. After learning, the robot can make plans to achieve desired goals, emulate end states of demonstrated actions, monitor the plan execution and take corrective actions using the perceptual structures employed or discovered during learning. We argue that the learning system proposed shares crucial elements with the development of infants of 7-10 months age, who explore the environment and learn the dynamics of the objects through goal-free exploration. In addition, we discuss goal emulation and planning in relation to older infants with no symbolic inference capability and non-linguistic animals which utilize object affordances to make action plans. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Goal emulation and planning in perceptual space using learned affordances", "paper_id": "WOS:000291899800009"}