{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-linear_algebra"}, {"score": 0.004765482708043842, "phrase": "subspace_learning_approach"}, {"score": 0.004692227830462433, "phrase": "linear_projection"}, {"score": 0.004596295252559861, "phrase": "implicit_structural_or_locally-spatial_information"}, {"score": 0.004364919932563366, "phrase": "new_tensor_data_representation_model"}, {"score": 0.004188198923320451, "phrase": "data_points"}, {"score": 0.003757480190200645, "phrase": "tensor_space_product"}, {"score": 0.0036996627006622975, "phrase": "original_feature_space"}, {"score": 0.0036052633308076933, "phrase": "new_optimization_algorithm"}, {"score": 0.003569444314231951, "phrase": "lagrangian"}, {"score": 0.003336225354214798, "phrase": "optimal_linear_projections"}, {"score": 0.003071274938566466, "phrase": "fuzzy_matrix_model"}, {"score": 0.002977419551510206, "phrase": "non-interested_determinant"}, {"score": 0.0029164434911787187, "phrase": "quadratic_sample_correlation_model"}, {"score": 0.002755104031926742, "phrase": "linear_programming"}, {"score": 0.002726740692380339, "phrase": "extensive_experimental_results"}, {"score": 0.0022283519468680475, "phrase": "principal_component_analysis"}, {"score": 0.0022053994402287925, "phrase": "linear_discriminant_analysis"}, {"score": 0.0021826828321952615, "phrase": "locality_preserving_projections"}, {"score": 0.002126907587540404, "phrase": "classification_accuracies"}, {"score": 0.0021049977753042253, "phrase": "computational_expenses"}], "paper_keywords": ["Subspace learning", " Dimensionality reduction", " Linear discriminant analysis", " Statistical analysis", " Medical science", " Pattern recognition"], "paper_abstract": "We propose a multi-linear algebra based subspace learning approach for finding linear projection which preserves some implicit structural or locally-spatial information among the original feature space. Our method uses a new tensor data representation model, in which, each group of data points are partitioned into several equal-sized sub-groups with its neighbors affiliated to them, and all sub-groups are concatenated to represent as the tensor space product of the original feature space. Then, a new optimization algorithm called Lagrangian multiplier mode (L-mode) is presented for computing the optimal linear projections. We show that our method has three ways for resolving the Small Sample Size problem: by applying the fuzzy matrix model to avoid the disturbance from non-interested determinant, by a quadratic sample correlation model, and by projecting the samples into a manifold using linear programming. Extensive experimental results conducted on two benchmark face biometrics datasets i.e. Yale-B and CMU-PIE, and a nutrition surveillance dataset demonstrate that our method is effective and robust than the state-of-the-arts such as Principal Component Analysis, Linear Discriminant Analysis, Locality Preserving Projections and their variations on both classification accuracies and computational expenses.", "paper_title": "Modular discriminant analysis and its applications", "paper_id": "WOS:000316341300002"}