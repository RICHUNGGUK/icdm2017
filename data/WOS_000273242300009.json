{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "markerless_motion_capture"}, {"score": 0.030868459343445714, "phrase": "humaneva_ii_dataset"}, {"score": 0.004780334370089564, "phrase": "visual_hull"}, {"score": 0.004528488165249491, "phrase": "human_motion"}, {"score": 0.004336556638639097, "phrase": "multiple_color_cameras"}, {"score": 0.004274396662662802, "phrase": "accurate_and_anatomically_consistent_tracking_algorithm"}, {"score": 0.004152725837204292, "phrase": "specific_models"}, {"score": 0.0041079938275505575, "phrase": "tracking_approach"}, {"score": 0.004063741692442559, "phrase": "levenberg-marquardt_minimization_scheme"}, {"score": 0.004019964326034457, "phrase": "iterative_closest_point_algorithm"}, {"score": 0.0039196351785300045, "phrase": "body_segment"}, {"score": 0.003891430578662587, "phrase": "anatomical_consistency"}, {"score": 0.0038218004095195183, "phrase": "rotational_and_translational_joint_range"}, {"score": 0.0037398806676032068, "phrase": "specific_joint"}, {"score": 0.003699579190650754, "phrase": "subject_specific_model"}, {"score": 0.0035942114996235803, "phrase": "automatic_model_generation_algorithm"}, {"score": 0.003504470784139224, "phrase": "ieee_trans"}, {"score": 0.00333163309034114, "phrase": "human_shapes"}, {"score": 0.0032484270911235526, "phrase": "proceedings_siggraph"}, {"score": 0.003190265467214105, "phrase": "biomechanically_consistent_kinematic_models"}, {"score": 0.0031558679589831287, "phrase": "pose-shape_matching_algorithm"}, {"score": 0.0030328769643087066, "phrase": "six_degrees"}, {"score": 0.002872827714395808, "phrase": "overall_method"}, {"score": 0.0025313767218525965, "phrase": "method_performance"}, {"score": 0.002127965733093433, "phrase": "humaneva_ii"}, {"score": 0.0021049977753042253, "phrase": "variable_number"}], "paper_keywords": ["Markerless motion capture", " Tracking", " 3D reconstruction", " Human body model", " Shape from silhouette"], "paper_abstract": "An approach for accurately measuring human motion through Markerless Motion Capture (MMC) is presented. The method uses multiple color cameras and combines an accurate and anatomically consistent tracking algorithm with a method for automatically generating subject specific models. The tracking approach employed a Levenberg-Marquardt minimization scheme over an iterative closest point algorithm with six degrees of freedom for each body segment. Anatomical consistency was maintained by enforcing rotational and translational joint range of motion constraints for each specific joint. A subject specific model of the subjects was obtained through an automatic model generation algorithm (Corazza et al. in IEEE Trans. Biomed. Eng., 2009) which combines a space of human shapes (Anguelov et al. in Proceedings SIGGRAPH, 2005) with biomechanically consistent kinematic models and a pose-shape matching algorithm. There were 15 anatomical body segments and 14 joints, each with six degrees of freedom (13 and 12, respectively for the HumanEva II dataset). The overall method is an improvement over (Mundermann et al. in Proceedings of CVPR, 2007) in terms of both accuracy and robustness. Since the method was originally developed for a parts per thousand yen8 cameras, the method performance was tested both (i) on the HumanEva II dataset (Sigal and Black, Technical Report CS-06-08, 2006) in a 4 camera configuration, (ii) on a series of motions including walking trials, a very challenging gymnastic motion and a dataset with motions similar to HumanEva II but with variable number of cameras.", "paper_title": "Markerless Motion Capture through Visual Hull, Articulated ICP and Subject Specific Model Generation", "paper_id": "WOS:000273242300009"}