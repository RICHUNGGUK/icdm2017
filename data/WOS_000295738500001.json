{"auto_keywords": [{"score": 0.04553324499556954, "phrase": "mmse"}, {"score": 0.01571930956934301, "phrase": "mmse_dimension"}, {"score": 0.004669845451682529, "phrase": "n_standard_gaussian"}, {"score": 0.004195418010131832, "phrase": "random_variable_x"}, {"score": 0.003308862957060602, "phrase": "mmse._mmse_dimension"}, {"score": 0.0031360786664165093, "phrase": "asymptotic_ratio"}, {"score": 0.003088384809415812, "phrase": "nonlinear_mmse"}, {"score": 0.0030181987092440955, "phrase": "mmse."}, {"score": 0.0028170314398963704, "phrase": "renyi's_information_dimension"}, {"score": 0.0023981301755351607, "phrase": "information_dimension"}, {"score": 0.0021375377706211686, "phrase": "gaussian_noise"}], "paper_keywords": ["Additive noise", " Bayesian statistics", " Gaussian noise", " high-SNR asymptotics", " minimum mean-square error (MMSE)", " mutual information", " non-Gaussian noise", " Renyi information dimension"], "paper_abstract": "If is N standard Gaussian, the minimum mean-square error (MMSE) of estimating a random variable X based on root snr X + N vanishes at least as fast as 1/snr as snr -> infinity. We define the MMSE dimension of X as the limit as snr -> infinity of the product of and the MMSE. MMSE dimension is also shown to be the asymptotic ratio of nonlinear MMSE to linear MMSE. For discrete, absolutely continuous or mixed distribution we show that MMSE dimension equals Renyi's information dimension. However, for a class of self-similar singular (e. g., Cantor distribution), we show that the product of and MMSE oscillates around information dimension periodically in (dB). We also show that these results extend considerably beyond Gaussian noise under various technical conditions.", "paper_title": "MMSE Dimension", "paper_id": "WOS:000295738500001"}