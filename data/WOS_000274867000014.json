{"auto_keywords": [{"score": 0.04609016223528991, "phrase": "hsmm"}, {"score": 0.00958989380608205, "phrase": "underlying_stochastic_process"}, {"score": 0.004815002214368699, "phrase": "hidden"}, {"score": 0.0046192222897398685, "phrase": "popular_hidden_markov_model"}, {"score": 0.004283423748543866, "phrase": "semi-markov_chain"}, {"score": 0.004203343568960231, "phrase": "variable_duration"}, {"score": 0.003882970272082245, "phrase": "wider_range"}, {"score": 0.0037249853525936428, "phrase": "model_parameters"}, {"score": 0.0035198224928307854, "phrase": "observation_sequence"}, {"score": 0.00340217066797559, "phrase": "best_state_sequence"}, {"score": 0.003226899588787952, "phrase": "machine_recognition"}, {"score": 0.0031190082119319272, "phrase": "thirty_scientific_and_engineering_areas"}, {"score": 0.003026127736667187, "phrase": "handwriting_recognition"}, {"score": 0.0030033417337933625, "phrase": "functional_mri_brain_mapping"}, {"score": 0.0029694830678462787, "phrase": "network_anomaly_detection"}, {"score": 0.0026014984513015368, "phrase": "unified_description"}, {"score": 0.002543148295176345, "phrase": "general_issues"}, {"score": 0.002495521662819317, "phrase": "boundary_conditions"}, {"score": 0.0024211628058125067, "phrase": "conventional_models"}, {"score": 0.0023848164282879885, "phrase": "explicit_duration"}, {"score": 0.002366847878952636, "phrase": "variable_transition"}, {"score": 0.002340147988348115, "phrase": "residential_time"}, {"score": 0.0022618378709785172, "phrase": "observation_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Hidden Markov model (HMM)", " Hidden semi-Markov model (HSMM)", " Explicit duration HMM", " Variable duration HMM", " Forward-backward (FB) algorithm", " Viterbi algorithm"], "paper_abstract": "As an extension to the popular hidden Markov model (HMM), a hidden semi-Markov model (HSMM) allows the underlying stochastic process to be a semi-Markov chain. Each state has variable duration and a number of observations being produced while in the state. This makes it suitable for use in a wider range of applications. Its forward-backward algorithms can be used to estimate/update the model parameters, determine the predicted, filtered and smoothed probabilities, evaluate goodness of an observation sequence fitting to the model, and find the best state sequence of the underlying stochastic process. Since the HSMM was initially introduced in 1980 for machine recognition of speech, it has been applied in thirty scientific and engineering areas, such as speech recognition/synthesis, human activity recognition/prediction, handwriting recognition, functional MRI brain mapping, and network anomaly detection. There are about three hundred papers published in the literature. An overview of HSMMs is presented in this paper, including modelling, inference, estimation, implementation and applications. It first provides a unified description of various HSMMs and discusses the general issues behind them. The boundary conditions of HSMM are extended. Then the conventional models, including the explicit duration, variable transition, and residential time of HSMM, are discussed. Various duration distributions and observation models are presented. Finally, the paper draws an outline of the applications. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Hidden semi-Markov models", "paper_id": "WOS:000274867000014"}