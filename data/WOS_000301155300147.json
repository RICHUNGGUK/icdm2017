{"auto_keywords": [{"score": 0.02865776864445492, "phrase": "conditional_mutual_information_estimation"}, {"score": 0.00481495049065317, "phrase": "cumulate_conditional_mutual_information_minimization"}, {"score": 0.004581505405526037, "phrase": "core_issues"}, {"score": 0.0044968982227349625, "phrase": "pattern_recognition"}, {"score": 0.004441359373498799, "phrase": "machine_learning_systems"}, {"score": 0.004305481798183612, "phrase": "considerable_attention"}, {"score": 0.004046020290832207, "phrase": "new_feature_subset_selection_algorithm"}, {"score": 0.003617616153730564, "phrase": "mutual_information"}, {"score": 0.003378385493203297, "phrase": "original_set"}, {"score": 0.003234425353582135, "phrase": "potential_redundant_features"}, {"score": 0.003135356056324338, "phrase": "minimal_information_loss"}, {"score": 0.0030582832134483685, "phrase": "cumulate_conditional_mutual_information_minimization_criterion"}, {"score": 0.0027341763737751467, "phrase": "sample_insufficiency"}, {"score": 0.0026013505538490223, "phrase": "fast_implementation"}, {"score": 0.002444333100610621, "phrase": "computationally_intractable_problem"}, {"score": 0.002414082940963702, "phrase": "empirical_results"}, {"score": 0.0022967713922705, "phrase": "better_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Classification", " Feature selection", " Conditional mutual information", " Relevance", " Redundancy"], "paper_abstract": "Feature selection is one of the core issues in designing pattern recognition and machine learning systems, and has attracted considerable attention in the literature. In this paper, a new feature subset selection algorithm with conditional mutual information is proposed, which firstly guarantees to find a subset of which the mutual information with the class is the same as that of the original set of features, and then eliminates potential redundant features from the view of minimal information loss based on the cumulate conditional mutual information minimization criterion. From the reliability point of view, this criterion can also abate the disturbance caused by sample insufficiency in conditional mutual information estimation. In addition, a fast implementation of conditional mutual information estimation is proposed and used to tackle the computationally intractable problem. Empirical results verify that our algorithm is efficient and achieves better accuracy than several representative feature selection algorithms for three typical classifiers on various datasets. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Feature subset selection with cumulate conditional mutual information minimization", "paper_id": "WOS:000301155300147"}