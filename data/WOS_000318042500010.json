{"auto_keywords": [{"score": 0.04683922641836833, "phrase": "ap"}, {"score": 0.007673209416420863, "phrase": "affinity_propagation"}, {"score": 0.00481495049065317, "phrase": "dense_data"}, {"score": 0.004568871736067739, "phrase": "efficient_implementation"}, {"score": 0.004392565073466714, "phrase": "graphical_processing_units"}, {"score": 0.004236972807770466, "phrase": "multiple_gpus"}, {"score": 0.004042295865725559, "phrase": "data_sets"}, {"score": 0.00398959232769596, "phrase": "similarity_matrices"}, {"score": 0.0038692638652494697, "phrase": "crisp_clustering_applications"}, {"score": 0.0037198532511087566, "phrase": "n-pattern_data"}, {"score": 0.0032054891061528896, "phrase": "large_similarity_matrices"}, {"score": 0.00308163068747474, "phrase": "matrix_operations"}, {"score": 0.002725994306480105, "phrase": "decomposition_scheme"}, {"score": 0.0025977542995083624, "phrase": "low_communication-to-computation_ratio"}, {"score": 0.0025414699652861667, "phrase": "favorable_communication_pattern"}, {"score": 0.0023694065215394593, "phrase": "slow_network"}, {"score": 0.0023079225317714815, "phrase": "global_device_memory"}, {"score": 0.0021705796895687864, "phrase": "single_unit"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["multiple-GPU implementation", " affinity propagation", " cluster analysis", " OpenCL"], "paper_abstract": "This work presents an efficient implementation of affinity propagation (AP) on clusters of graphical processing units (GPUs). AP is a state-of-the-art method for finding exemplars in data sets described by similarity matrices. It is typically employed in crisp clustering applications. However, when finding exemplars in an n-pattern data set with dense, non-metric similarities, AP performs iterative processing of three nxn floating point matrices. One of them stores the similarities, and the other two store the values that will ultimately pinpoint the exemplars. For large similarity matrices, AP is therefore computationally expensive. Although matrix operations of AP are well suited for GPUs, its memory footprint limits the size of tasks that can be solved on one unit. We present, however, a decomposition scheme for AP that distributes the calculations over multiple GPUs, with low communication-to-computation ratio. Because of this favorable communication pattern, our implementation finds exemplars in large, dense similarity data efficiently, even when GPUs are connected by a slow network. Furthermore, by combining global device memory of multiple GPUs, it can solve problems that would not fit in a single unit. Copyright (c) 2012 John Wiley & Sons, Ltd.", "paper_title": "Finding exemplars in dense data with affinity propagation on clusters of GPUs", "paper_id": "WOS:000318042500010"}