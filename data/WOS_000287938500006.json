{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "training_algorithm"}, {"score": 0.004723322467153553, "phrase": "support_vector_machine_classifiers"}, {"score": 0.004545240514015278, "phrase": "key_features"}, {"score": 0.003750260412839128, "phrase": "selection_strategies"}, {"score": 0.0033737457695128203, "phrase": "working_set_strategies"}, {"score": 0.0032463805170627686, "phrase": "convergence_rates"}, {"score": 0.002977061391551631, "phrase": "best_known_rates"}, {"score": 0.0025521085778978042, "phrase": "performed_iterations"}, {"score": 0.00247944491239733, "phrase": "new_training_algorithm"}, {"score": 0.0022956075241520064, "phrase": "new_algorithm"}, {"score": 0.002251813863195168, "phrase": "significantly_less_iterations"}, {"score": 0.0021049977753042253, "phrase": "standard_training_algorithms"}], "paper_keywords": ["support vector machines", " decomposition algorithms"], "paper_abstract": "We develop, analyze, and test a training algorithm for support vector machine classifiers without offset. Key features of this algorithm are a new, statistically motivated stopping criterion, new warm start options, and a set of inexpensive working set selection strategies that significantly reduce the number of iterations. For these working set strategies, we establish convergence rates that, not surprisingly, coincide with the best known rates for SVMs with offset. We further conduct various experiments that investigate both the run time behavior and the performed iterations of the new training algorithm. It turns out, that the new algorithm needs significantly less iterations and also runs substantially faster than standard training algorithms for SVMs with offset.", "paper_title": "Training SVMs Without Offset", "paper_id": "WOS:000287938500006"}