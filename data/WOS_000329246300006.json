{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dynamic_mixture_models"}, {"score": 0.004397000006837371, "phrase": "markov_chain_monte_carlo"}, {"score": 0.004088807948906792, "phrase": "block-sampling_the_discrete_latent_variables"}, {"score": 0.0036998728605395384, "phrase": "multi-move_extension"}, {"score": 0.003600351201298387, "phrase": "single-move_gibbs_sampler"}, {"score": 0.003503508070417038, "phrase": "gerlach"}, {"score": 0.00344044060365321, "phrase": "carter"}, {"score": 0.0033784950290182136, "phrase": "kohn"}, {"score": 0.003287482882222731, "phrase": "j._am"}, {"score": 0.0032287945968849188, "phrase": "stat"}, {"score": 0.002765776659294382, "phrase": "adaptive_metropolis-hastings_scheme"}, {"score": 0.002548331088496964, "phrase": "discrete_states"}, {"score": 0.002203016940021265, "phrase": "visual_inspection"}, {"score": 0.0021632743048552554, "phrase": "sample_partial_autocorrelations"}, {"score": 0.0021049977753042253, "phrase": "discrete_latent_variables"}], "paper_keywords": ["Adaptive Metropolis-Hastings", " Conditionally linear models", " Gibbs sampling", " State-space models"], "paper_abstract": "We show how to improve the efficiency of Markov Chain Monte Carlo (MCMC) simulations in dynamic mixture models by block-sampling the discrete latent variables. Two algorithms are proposed: the first is a multi-move extension of the single-move Gibbs sampler devised by Gerlach, Carter and Kohn (in J. Am. Stat. Assoc. 95, 819-828, 2000); the second is an adaptive Metropolis-Hastings scheme that performs well even when the number of discrete states is large. Three empirical examples illustrate the gain in efficiency achieved. We also show that visual inspection of sample partial autocorrelations of the discrete latent variables helps anticipating whether blocking can be effective.", "paper_title": "Efficient MCMC sampling in dynamic mixture models", "paper_id": "WOS:000329246300006"}