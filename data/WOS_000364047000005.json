{"auto_keywords": [{"score": 0.04448671687401455, "phrase": "salient_object_detection"}, {"score": 0.004382913938427474, "phrase": "seven_challenging_data_sets"}, {"score": 0.004212759658511567, "phrase": "segmentation_methods"}, {"score": 0.003969784439380027, "phrase": "consistent_rapid_progress"}, {"score": 0.0037967593942595233, "phrase": "running_time"}, {"score": 0.0037407704200033607, "phrase": "top_contenders"}, {"score": 0.0034901729647741353, "phrase": "previous_benchmark"}, {"score": 0.003176626803985225, "phrase": "closely_related_areas"}, {"score": 0.003068327486877065, "phrase": "precise_definition"}, {"score": 0.0030081030319492343, "phrase": "appropriate_treatment"}, {"score": 0.0027513507830537165, "phrase": "center_bias"}, {"score": 0.002724207384182295, "phrase": "scene_complexity"}, {"score": 0.0026973310437053573, "phrase": "model_performance"}, {"score": 0.002605329434787829, "phrase": "hard_cases"}, {"score": 0.002454835845644037, "phrase": "useful_hints"}, {"score": 0.002301572462091142, "phrase": "probable_solutions"}, {"score": 0.002223039450439376, "phrase": "evaluation_scores"}, {"score": 0.0021902063413831545, "phrase": "set_bias"}, {"score": 0.0021365562685368767, "phrase": "future_research_directions"}, {"score": 0.0021049977753042253, "phrase": "rapidly_growing_field"}], "paper_keywords": ["Salient object detection", " saliency", " explicit saliency", " visual attention", " regions of interest", " objectness", " segmentation", " interestingness", " importance", " eye movements"], "paper_abstract": "We extensively compare, qualitatively and quantitatively, 41 state-of-the-art models (29 salient object detection, 10 fixation prediction, 1 objectness, and 1 baseline) over seven challenging data sets for the purpose of benchmarking salient object detection and segmentation methods. From the results obtained so far, our evaluation shows a consistent rapid progress over the last few years in terms of both accuracy and running time. The top contenders in this benchmark significantly outperform the models identified as the best in the previous benchmark conducted three years ago. We find that the models designed specifically for salient object detection generally work better than models in closely related areas, which in turn provides a precise definition and suggests an appropriate treatment of this problem that distinguishes it from other problems. In particular, we analyze the influences of center bias and scene complexity in model performance, which, along with the hard cases for the state-of-the-art models, provide useful hints toward constructing more challenging large-scale data sets and better saliency models. Finally, we propose probable solutions for tackling several open problems, such as evaluation scores and data set bias, which also suggest future research directions in the rapidly growing field of salient object detection.", "paper_title": "Salient Object Detection: A Benchmark", "paper_id": "WOS:000364047000005"}