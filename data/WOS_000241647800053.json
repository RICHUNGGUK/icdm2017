{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "classification_rules"}, {"score": 0.004494570360108983, "phrase": "implicative_statistics"}, {"score": 0.004417848254181138, "phrase": "classification_trees"}, {"score": 0.004159446063902181, "phrase": "gras'_implication_index"}, {"score": 0.003816197777388722, "phrase": "induced_decision_tree"}, {"score": 0.0034118234596993836, "phrase": "contingency_tables"}, {"score": 0.003353521531649663, "phrase": "interesting_alternatives"}, {"score": 0.003296212583539166, "phrase": "gras'_index"}, {"score": 0.002680114113899346, "phrase": "second_usage"}, {"score": 0.0025449518236394103, "phrase": "zighed"}, {"score": 0.0025014259919355453, "phrase": "rakotomalala"}, {"score": 0.0021049977753042253, "phrase": "induced_tree"}], "paper_keywords": [""], "paper_abstract": "This paper highlights the interest of implicative statistics for classification trees. We start by showing how Gras' implication index may be defined for the rules derived from an induced decision tree. Then, we show that residuals used in the modeling of contingency tables provide interesting alternatives to Gras' index. We then consider two main usages of these indexes. The first is purely descriptive and concerns the a posteriori individual evaluation of the classification rules. The second usage, considered for instance by Zighed and Rakotomalala [15], relies upon the intensity of implication to define the conclusion in each leaf of the induced tree.", "paper_title": "Implication strength of classification rules", "paper_id": "WOS:000241647800053"}