{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "interest_detection"}, {"score": 0.0047732596509542135, "phrase": "visual_distance_estimation_for_sensor-rich_video"}, {"score": 0.004690952711665194, "phrase": "technological_advances"}, {"score": 0.004590052784169268, "phrase": "camera_sensors"}, {"score": 0.004300133642951283, "phrase": "large_number"}, {"score": 0.004262881313926916, "phrase": "geo-tagged_photos"}, {"score": 0.004028452405970376, "phrase": "challenging_problem"}, {"score": 0.003924629168434799, "phrase": "media_data"}, {"score": 0.003581797255879607, "phrase": "important_objects"}, {"score": 0.0034742854447532678, "phrase": "existing_solutions"}, {"score": 0.002931569771634119, "phrase": "large_video_repositories"}, {"score": 0.002868404184756449, "phrase": "novel_technique"}, {"score": 0.002831158147480665, "phrase": "sensor-generated_meta-data"}, {"score": 0.002675252546913683, "phrase": "continuous_streams"}, {"score": 0.002629026692001082, "phrase": "video_frames"}, {"score": 0.0026062133750675894, "phrase": "existing_smartphones"}, {"score": 0.0025059724686541263, "phrase": "collective_set"}, {"score": 0.0024412911465483225, "phrase": "acquired_auxiliary_meta-data"}, {"score": 0.002357632753637638, "phrase": "interesting_regions"}, {"score": 0.002257070536352418, "phrase": "camera_positions"}, {"score": 0.0022277448907881306, "phrase": "fully_automated_way"}, {"score": 0.0021607883988873492, "phrase": "proposed_method"}], "paper_keywords": ["Point of interest", " sensor-rich video", " visual distance estimation"], "paper_abstract": "Due to technological advances and the popularity of camera sensors, it is now straightforward for users to capture and share videos. A large number of geo-tagged photos and videos have been accumulating continuously on the web, posing a challenging problem for mining this type of media data. In one application scenario, users might desire to know what the Points of Interest (POI) are which contain important objects or places in a video. Existing solutions attempt to examine the content of the videos and recognize objects and events. This is typically time-consuming and computationally expensive and the results can be uneven. Therefore these methods face challenges when applied to large video repositories. We propose a novel technique that leverages sensor-generated meta-data (camera locations and viewing directions) which are automatically acquired as continuous streams together with the video frames. Existing smartphones can easily accommodate such integrated recording tasks. By considering a collective set of videos and leveraging the acquired auxiliary meta-data, our approach is able to detect interesting regions and objects (POIs) and their distances from the camera positions in a fully automated way. Because of its computational efficiency, the proposed method scales well and our experiments show very promising results.", "paper_title": "Point of Interest Detection and Visual Distance Estimation for Sensor-Rich Video", "paper_id": "WOS:000344720300011"}