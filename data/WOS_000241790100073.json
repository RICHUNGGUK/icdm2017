{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "non-identifiable_models"}, {"score": 0.004701015188740582, "phrase": "hierarchical_learning_machines"}, {"score": 0.004535124351828787, "phrase": "neural_networks"}, {"score": 0.004023120753104693, "phrase": "bayes_ensemble_learning"}, {"score": 0.0038810583785936505, "phrase": "good_generalization_performance"}, {"score": 0.0034426417353349567, "phrase": "posterior_distribution"}, {"score": 0.0031654684543975077, "phrase": "parameter_space"}, {"score": 0.002841545331522694, "phrase": "new_learning_algorithm"}, {"score": 0.0026126405272417783, "phrase": "localized_posterior_distribution"}, {"score": 0.0021561514733516676, "phrase": "smaller_generalization_error"}, {"score": 0.0021049977753042253, "phrase": "reduced_rank_approximations"}], "paper_keywords": [""], "paper_abstract": "Hierarchical learning machines much as neural networks are now being used in many applications. Although the Bayes ensemble learning gives the good generalization performance in such hierarchical learning machines, it is difficult to realize the posterior distribution because of the singularities in the parameter space. In this paper, we propose a new learning algorithm which enables us to construct a localized posterior distribution. We call this method Localized Bayes estimation and theoretically show that it attains the smaller generalization error in reduced rank approximations.", "paper_title": "Localized Bayes estimation for non-identifiable models", "paper_id": "WOS:000241790100073"}