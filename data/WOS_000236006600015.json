{"auto_keywords": [{"score": 0.049631680892871025, "phrase": "google"}, {"score": 0.04278010865393869, "phrase": "search_tasks"}, {"score": 0.028795760913979913, "phrase": "different_classes"}, {"score": 0.00481495049065317, "phrase": "evaluation_behavior"}, {"score": 0.004681226806682058, "phrase": "search_engine_effectiveness"}, {"score": 0.004551199992546761, "phrase": "increased_interest"}, {"score": 0.004487541157100498, "phrase": "additional_feedback"}, {"score": 0.00444559516711374, "phrase": "users'_information"}, {"score": 0.00422177384286051, "phrase": "adaptive_search_engines"}, {"score": 0.004182301599359094, "phrase": "explicit_and_implicit_feedback_indicators"}, {"score": 0.0039716833701918365, "phrase": "appropriate_models"}, {"score": 0.003771631577951067, "phrase": "search_engines"}, {"score": 0.003701401653850141, "phrase": "determining_factors"}, {"score": 0.003615443704375908, "phrase": "eye_tracking"}, {"score": 0.003353521531649663, "phrase": "query_result"}, {"score": 0.0031695693589575916, "phrase": "query_result_abstracts"}, {"score": 0.002765490759189057, "phrase": "search_behavior_variability"}, {"score": 0.0025892330566358503, "phrase": "user_models"}, {"score": 0.002564985233317994, "phrase": "task_models"}, {"score": 0.0025290375256888883, "phrase": "greater_predictors"}, {"score": 0.0023902026696615473, "phrase": "different_kinds"}, {"score": 0.0023678143146455017, "phrase": "search_behaviors"}, {"score": 0.002248366278757655, "phrase": "query-based_search_interface_designs"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["web search", " eye tracking", " information retrieval", " human-computer interaction", " information seeking"], "paper_abstract": "To improve search engine effectiveness, we have observed an increased interest in gathering additional feedback about users' information needs that goes beyond the queries they type in. Adaptive search engines use explicit and implicit feedback indicators to model users or search tasks. In order to create appropriate models, it is essential to understand how users interact with search engines, including the determining factors of their actions. Using eye tracking, we extend this understanding by analyzing the sequences and patterns with which users evaluate query result returned to them when using Google. We find that the query result abstracts are viewed in the order of their ranking in only about one fifth of the cases, and only an average of about three abstracts per result page are viewed at all. We also compare search behavior variability with respect to different classes of users and different classes of search tasks to reveal whether user models or task models may be greater predictors of behavior. We discover that gender and task significantly influence different kinds of search behaviors discussed here. The results are suggestive of improvements to query-based search interface designs with respect to both their use of space and workflow. (c) 2005 Elsevier Ltd. All rights reserved.", "paper_title": "The influence fo task and gender on search and evaluation behavior using Google", "paper_id": "WOS:000236006600015"}