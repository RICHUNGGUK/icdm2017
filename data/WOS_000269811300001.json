{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "imbalanced_datasets"}, {"score": 0.0047270364435530975, "phrase": "taxonomy"}, {"score": 0.004640398886726948, "phrase": "imbalanced_data"}, {"score": 0.004534517530868195, "phrase": "recent_challenges"}, {"score": 0.004492841495994535, "phrase": "machine_learning"}, {"score": 0.004002972723329302, "phrase": "preprocessing_stage"}, {"score": 0.003929689573550262, "phrase": "preprocessing_focused_oil_balancing_data"}, {"score": 0.0036496814103475174, "phrase": "minority_class_examples"}, {"score": 0.0034368818187904744, "phrase": "prototype_selection_procedure"}, {"score": 0.003281643474564305, "phrase": "high_classification_rate"}, {"score": 0.0031918759137610523, "phrase": "majority_class_examples"}, {"score": 0.0031625006830124512, "phrase": "evolutionary_algorithms"}, {"score": 0.00309023627455429, "phrase": "classical_prototype_selection"}, {"score": 0.0030617935728586006, "phrase": "good_results"}, {"score": 0.0030056887638095883, "phrase": "fitness_function"}, {"score": 0.002909960617042717, "phrase": "reduction_rates"}, {"score": 0.0025802660239538353, "phrase": "different_fitness_functions"}, {"score": 0.0025329623864528317, "phrase": "good_trade-off"}, {"score": 0.0023091093387071593, "phrase": "overall_comparison"}, {"score": 0.002266765479420981, "phrase": "state_of_the_art_undersampling_methods"}, {"score": 0.002174303033371869, "phrase": "nonparametric_statistical_procedures"}, {"score": 0.0021344259291927914, "phrase": "evolutionary_undersampling"}, {"score": 0.0021049977753042253, "phrase": "nonevolutionary_models"}], "paper_keywords": ["Classification", " class imbalance problem", " undersampling", " prototype selection", " evolutionary algorithms"], "paper_abstract": "Learning with imbalanced data is one of the recent challenges in machine learning. Various solutions have been proposed in order to find a treatment for this problem, such as modifying methods or the application of a preprocessing stage. Within the preprocessing focused oil balancing data, two tendencies exist: reduce the set of examples (undersampling) or replicate minority class examples (oversampling). Undersampling with imbalanced datasets could be considered as a prototype selection procedure with the purpose of balancing datasets to achieve a high classification rate, avoiding the bias toward majority class examples. Evolutionary algorithms have been used for classical prototype selection showing good results, where the fitness function is associated to the classification and reduction rates. In this paper, we propose a set of methods called evolutionary undersampling that take into consideration the nature of the problem and use different fitness functions for getting a good trade-off between balance of distribution of classes and performance. The study includes a taxonomy of the approaches and an overall comparison among our models and state of the art undersampling methods. The results have been contrasted by using nonparametric statistical procedures and show that evolutionary undersampling outperforms the nonevolutionary models when the degree of imbalance is increased.", "paper_title": "Evolutionary Undersampling for Classification with Imbalanced Datasets: Proposals and Taxonomy", "paper_id": "WOS:000269811300001"}