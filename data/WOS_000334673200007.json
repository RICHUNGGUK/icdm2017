{"auto_keywords": [{"score": 0.025901709702066917, "phrase": "parsec"}, {"score": 0.00481495049065317, "phrase": "architectural_support_for_handling_jitter"}, {"score": 0.004772818068176176, "phrase": "shared_memory"}, {"score": 0.004628223381645729, "phrase": "increasing_number"}, {"score": 0.00439041997682389, "phrase": "optimal_performance"}, {"score": 0.00431388720289049, "phrase": "memory_applications"}, {"score": 0.004201571673071299, "phrase": "kernel_threads"}, {"score": 0.004128317208406523, "phrase": "bus_contention"}, {"score": 0.0037973594873521596, "phrase": "parallel_programs"}, {"score": 0.0036499505265403377, "phrase": "large_cmp_based_systems"}, {"score": 0.003477505397536663, "phrase": "large_multi-core_processors"}, {"score": 0.003298631258267805, "phrase": "novel_jitter_measurement_unit"}, {"score": 0.0032410683344688625, "phrase": "distributed_protocol"}, {"score": 0.0031289290660162145, "phrase": "wasted_cycles"}, {"score": 0.0029679371578791446, "phrase": "dvfs"}, {"score": 0.002890557197908352, "phrase": "critical_instructions"}, {"score": 0.0027660443371695024, "phrase": "os_cache"}, {"score": 0.002705808393126695, "phrase": "os_cache_lines"}, {"score": 0.002670296619878048, "phrase": "memory_interference"}, {"score": 0.002623669616798891, "phrase": "detailed_cycle"}, {"score": 0.0023918783117166326, "phrase": "deterministic_timing_overhead"}, {"score": 0.002288797099841088, "phrase": "modest_dvfs_factors"}, {"score": 0.002238930800075706, "phrase": "overall_jitter"}, {"score": 0.0021236300589450143, "phrase": "area_overhead"}], "paper_keywords": ["CMP", " hardware support for OS", " DVFS", " operating system jitter", " HPC application"], "paper_abstract": "With an increasing number of cores per chip, it is becoming harder to guarantee optimal performance for parallel shared memory applications due to interference caused by kernel threads, interrupts, bus contention, and temperature management schemes (referred to as jitter). We demonstrate that the performance of parallel programs gets reduced (up to 35.22 percent) in large CMP based systems. In this paper, we characterize the jitter for large multi-core processors, and evaluate the loss in performance. We propose a novel jitter measurement unit that uses a distributed protocol to keep track of the number of wasted cycles. Subsequently, we try to compensate for jitter by using DVFS across a region of timing critical instructions called a frame. Additionally, we propose an OS cache that intelligently manages the OS cache lines to reduce memory interference. By performing detailed cycle accurate simulations, we show that we are able to execute a suite of Splash2 and Parsec benchmarks with a deterministic timing overhead limited to 2 percent for 14 out of 17 benchmarks with modest DVFS factors. We reduce the overall jitter by an average 13.5 percent for Splash2 and 6.4 percent for Parsec. The area overhead of our scheme is limited to 1 percent.", "paper_title": "Architectural Support for Handling Jitter in Shared Memory Based Parallel Applications", "paper_id": "WOS:000334673200007"}