{"auto_keywords": [{"score": 0.02936570424733835, "phrase": "data_sets"}, {"score": 0.02582322432083657, "phrase": "bi"}, {"score": 0.014075476752309397, "phrase": "multiple_partitions"}, {"score": 0.00481495049065317, "phrase": "latent_tree_models"}, {"score": 0.004766388573192505, "phrase": "multidimensional_clustering"}, {"score": 0.004718314112245913, "phrase": "real-world_data"}, {"score": 0.00437281181878921, "phrase": "growing_interest"}, {"score": 0.004198965651975536, "phrase": "previous_work"}, {"score": 0.004073113268289532, "phrase": "latent_tree_model"}, {"score": 0.004032006845439495, "phrase": "ltm"}, {"score": 0.00395101799538683, "phrase": "multiple_latent_variables"}, {"score": 0.003911135156992, "phrase": "chen_et_al"}, {"score": 0.003793876828939456, "phrase": "latent_variable"}, {"score": 0.003736567662016446, "phrase": "soft_partition"}, {"score": 0.003551694229680741, "phrase": "ltm_approach"}, {"score": 0.0034803228231621687, "phrase": "model_selection"}, {"score": 0.002988685006809336, "phrase": "rich_and_meaningful_clustering_results"}, {"score": 0.00217017119491777, "phrase": "clustering_results"}, {"score": 0.0021049977753042253, "phrase": "alternative_methods"}], "paper_keywords": ["Model-based clustering", " Multiple partitions", " Latent tree models"], "paper_abstract": "Real-world data are often multifaceted and can be meaningfully clustered in more than one way. There is a growing interest in obtaining multiple partitions of data. In previous work we learnt from data a latent tree model (LTM) that contains multiple latent variables (Chen et al. 2012). Each latent variable represents a soft partition of data and hence multiple partitions result in. The LTM approach can, through model selection, automatically determine how many partitions there should be, what attributes define each partition, and how many clusters there should be for each partition. It has been shown to yield rich and meaningful clustering results. Our previous algorithm EAST for learning LTMs is only efficient enough to handle data sets with dozens of attributes. This paper proposes an algorithm called BI that can deal with data sets with hundreds of attributes. We empirically compare BI with EAST and other more efficient LTM learning algorithms, and show that BI outperforms its competitors on data sets with hundreds of attributes. In terms of clustering results, BI compares favorably with alternative methods that are not based on LTMs.", "paper_title": "Greedy learning of latent tree models for multidimensional clustering", "paper_id": "WOS:000347694700011"}