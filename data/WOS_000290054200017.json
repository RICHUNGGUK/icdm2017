{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "ensemble_methods"}, {"score": 0.04974208475172307, "phrase": "binary_classifiers"}, {"score": 0.04617998264114106, "phrase": "multiple_classes"}, {"score": 0.03977146875669389, "phrase": "binarization_techniques"}, {"score": 0.004747429622531595, "phrase": "multi-class_problems"}, {"score": 0.004455061431809975, "phrase": "classification_problems"}, {"score": 0.004346266306175988, "phrase": "different_ways"}, {"score": 0.004195418010131832, "phrase": "original_data"}, {"score": 0.004151188559520802, "phrase": "two-class_subsets"}, {"score": 0.004092937456065441, "phrase": "different_binary_model"}, {"score": 0.004049783994776266, "phrase": "new_subset"}, {"score": 0.003950846696972114, "phrase": "binarization_strategies"}, {"score": 0.0032527939106509946, "phrase": "empirical_analysis"}, {"score": 0.003229870860371533, "phrase": "different_aggregations"}, {"score": 0.0030847461428168614, "phrase": "double_study"}, {"score": 0.0030199761431186434, "phrase": "different_base_classifiers"}, {"score": 0.0027741761880779535, "phrase": "ensemble_techniques"}, {"score": 0.002744888626958772, "phrase": "classifiers'_themselves"}, {"score": 0.002530359917257626, "phrase": "experimental_study"}, {"score": 0.0024597305738431226, "phrase": "support_vector_machines"}, {"score": 0.0024423826953133844, "phrase": "decision_trees"}, {"score": 0.002391067964886602, "phrase": "rule_based_systems"}, {"score": 0.0022355610034493225, "phrase": "base_classifiers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Multi-classification", " Pairwise learning", " One-vs-one", " One-vs-all", " Decomposition strategies", " Ensembles"], "paper_abstract": "Classification problems involving multiple classes can be addressed in different ways. One of the most popular techniques consists in dividing the original data set into two-class subsets, learning a different binary model for each new subset. These techniques are known as binarization strategies. In this work, we are interested in ensemble methods by binarization techniques; in particular, we focus on the well-known one-vs-one and one-vs-all decomposition strategies, paying special attention to the final step of the ensembles, the combination of the outputs of the binary classifiers. Our aim is to develop an empirical analysis of different aggregations to combine these outputs. To do so, we develop a double study: first, we use different base classifiers in order to observe the suitability and potential of each combination within each classifier. Then, we compare the performance of these ensemble techniques with the classifiers' themselves. Hence, we also analyse the improvement with respect to the classifiers that handle multiple classes inherently. We carry out the experimental study with several well-known algorithms of the literature such as Support Vector Machines, Decision Trees, Instance Based Learning or Rule Based Systems. We will show, supported by several statistical analyses, the goodness of the binarization techniques with respect to the base classifiers and finally we will point out the most robust techniques within this framework. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "An overview of ensemble methods for binary classifiers in multi-class problems: Experimental study on one-vs-one and one-vs-all schemes", "paper_id": "WOS:000290054200017"}