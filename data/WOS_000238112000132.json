{"auto_keywords": [{"score": 0.042977379303080404, "phrase": "fnt"}, {"score": 0.010612384215170072, "phrase": "pattern_recognition"}, {"score": 0.008886486600637606, "phrase": "decision_tree"}, {"score": 0.008480545221236839, "phrase": "neural_network"}, {"score": 0.004551199992546761, "phrase": "novel_induction_model"}, {"score": 0.003916098498242888, "phrase": "basic_analysis"}, {"score": 0.0037363522297378777, "phrase": "subsequent_quantitative_analysis"}, {"score": 0.0034332736827447654, "phrase": "test_selection_measure"}, {"score": 0.003066945490483524, "phrase": "continuous_attributes"}, {"score": 0.0028446460307503343, "phrase": "neural_network_node"}, {"score": 0.002765490759189057, "phrase": "new_attribute_relations"}, {"score": 0.0026633568650501873, "phrase": "symbolic_rules"}, {"score": 0.002470237978694949, "phrase": "decision_process"}, {"score": 0.0024241817763927163, "phrase": "experimental_studies"}, {"score": 0.0023127544795063263, "phrase": "natural_domains"}, {"score": 0.0022064376000055764, "phrase": "clear_advantages"}, {"score": 0.0021049977753042253, "phrase": "generalization_ability"}], "paper_keywords": [""], "paper_abstract": "This paper presents a novel induction model named Flexible Neural Tree (FNT) for pattern recognition. FNT uses decision tree to do basic analysis and neural network to do subsequent quantitative analysis. The Pure Information Gain I(X-i;V), which is defined as test selection measure for FNT to construct decision tree, can be used to handle continuous attributes directly. When the information embodied by neural network node can show new attribute relations, FNT extracts symbolic rules from neural network to increase the performance of decision process. Experimental studies on a set of natural domains show that FNT has clear advantages with respect to the generalization ability.", "paper_title": "Flexible Neural Tree for pattern recognition", "paper_id": "WOS:000238112000132"}