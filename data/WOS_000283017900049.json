{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "nonlinear_regression_models"}, {"score": 0.04957466661795797, "phrase": "scale_mixtures"}, {"score": 0.04907561130245922, "phrase": "skew-normal_distributions"}, {"score": 0.0043080553835735825, "phrase": "bayesian_analysis"}, {"score": 0.0041074234667687875, "phrase": "novel_class"}, {"score": 0.004000010693331517, "phrase": "useful_generalization"}, {"score": 0.003936910716320182, "phrase": "symmetrical_nonlinear_regression_models"}, {"score": 0.0038748022659578865, "phrase": "error_distributions"}, {"score": 0.003773449694108617, "phrase": "heavy-tailed_distributions"}, {"score": 0.0034299649219748513, "phrase": "main_advantage"}, {"score": 0.0032355864829403413, "phrase": "nice_hierarchical_representation"}, {"score": 0.0031342307827666675, "phrase": "markov_chain"}, {"score": 0.0031176485976102688, "phrase": "monte_carlo"}, {"score": 0.0029565620771207003, "phrase": "joint_posterior_distribution"}, {"score": 0.0028487656293168795, "phrase": "robust_aspects"}, {"score": 0.0028037753646260937, "phrase": "flexible_class"}, {"score": 0.0027594936602962075, "phrase": "outlying_and_influential_observations"}, {"score": 0.002687235334499192, "phrase": "bayesian_case"}, {"score": 0.0025892330566358503, "phrase": "kullback-leibler_divergence"}, {"score": 0.002481588370380518, "phrase": "model_selection_criteria"}, {"score": 0.00241658945942583, "phrase": "newly_developed_procedures"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Bayesian inference", " Nonlinear regression models", " Scale mixtures of skew-normal distributions"], "paper_abstract": "The purpose of this paper is to develop a Bayesian analysis for nonlinear regression models under scale mixtures of skew-normal distributions. This novel class of models provides a useful generalization of the symmetrical nonlinear regression models since the error distributions cover both skewness and heavy-tailed distributions such as the skew-t, skew-slash and the skew-contaminated normal distributions. The main advantage of these class of distributions is that they have a nice hierarchical representation that allows the implementation of Markov chain Monte Carlo (MCMC) methods to simulate samples from the joint posterior distribution. In order to examine the robust aspects of this flexible class, against outlying and influential observations, we present a Bayesian case deletion influence diagnostics based on the Kullback-Leibler divergence. Further, some discussions on the model selection criteria are given. The newly developed procedures are illustrated considering two simulations study, and a real data previously analyzed under normal and skew-normal nonlinear regression models. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Bayesian nonlinear regression models with scale mixtures of skew-normal distributions: Estimation and case influence diagnostics", "paper_id": "WOS:000283017900049"}