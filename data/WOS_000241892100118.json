{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "logical_mdps"}, {"score": 0.004297795905522757, "phrase": "logical_markov_decision_processes"}, {"score": 0.003997891221012094, "phrase": "relational_reinforcement_learning"}, {"score": 0.003835972725191194, "phrase": "new_model"}, {"score": 0.0037188360359702182, "phrase": "abstract_state_space"}, {"score": 0.0034951469511975346, "phrase": "simple_way"}, {"score": 0.0033190180867511605, "phrase": "good_property"}, {"score": 0.003151736708029235, "phrase": "prototype_action"}, {"score": 0.0028715299874549245, "phrase": "distinct_feature"}, {"score": 0.0026986685585382347, "phrase": "applicable_abstract_actions"}, {"score": 0.0025361866386341796, "phrase": "valid_substitutions"}, {"score": 0.0024333239726872604, "phrase": "complementary_abstract_state_space"}, {"score": 0.002310578855290687, "phrase": "prototype_actions"}, {"score": 0.0022399174232611853, "phrase": "model-free_theta-learing_method"}, {"score": 0.0021049977753042253, "phrase": "state-action-substitution_value_funcion"}], "paper_keywords": [""], "paper_abstract": "In this paper we introduce negation into Logical Markov Decision Processes, which is a model of Relational Reinforcement Learning. In the new model nLMDP the abstract state space can be constructed in a simple way, so that a good property of complementarity holds. Prototype action is also introduced into the model. A distinct feature of the model is that applicable abstract actions can be obtained automatically with valid substitutions. Given a complementary abstract state space and a set of prototype actions, a model-free Theta-learing method is implemented for evaluating the state-action-substitution value funcion.", "paper_title": "Unique state and automatical action abstracting based on logical MDPs with negation", "paper_id": "WOS:000241892100118"}