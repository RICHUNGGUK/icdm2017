{"auto_keywords": [{"score": 0.03749405118920914, "phrase": "abstract_features"}, {"score": 0.00481495049065317, "phrase": "robust_asr"}, {"score": 0.00445712058827745, "phrase": "novel_supervised_pre-training_technique"}, {"score": 0.004094018760244776, "phrase": "robust_speech_recognition"}, {"score": 0.004031238480458909, "phrase": "adverse_environments"}, {"score": 0.0039085400187964196, "phrase": "proposed_approach"}, {"score": 0.003702702337768558, "phrase": "dnn_parameters"}, {"score": 0.0034806529881619454, "phrase": "acoustic_environment_variations"}, {"score": 0.0030994630902300133, "phrase": "early_fine-tuned_dnn_model"}, {"score": 0.0029361086955646625, "phrase": "clean_speech_database"}, {"score": 0.00282470997972535, "phrase": "derived_abstract_features"}, {"score": 0.0027599042621376624, "phrase": "target_values"}, {"score": 0.0026965813247045427, "phrase": "standard_error_back-propagation_algorithm"}, {"score": 0.0026347074232350503, "phrase": "stochastic_gradient_descent_method"}, {"score": 0.0025151755329660837, "phrase": "initial_parameters"}, {"score": 0.002457455982638966, "phrase": "dnn."}, {"score": 0.002364172626241202, "phrase": "proposed_algorithm"}, {"score": 0.0022394839933089074, "phrase": "better_results"}, {"score": 0.0021049977753042253, "phrase": "conventional_pre-training_methods"}], "paper_keywords": ["deep neural networks (DNNs)", " pre-training", " denoising", " back-propagation", " robust speech recognition"], "paper_abstract": "In this letter, we propose a novel supervised pre-training technique for deep neural network (DNN)-hidden Markov model systems to achieve robust speech recognition in adverse environments. In the proposed approach, our aim is to initialize the DNN parameters such that they yield abstract features robust to acoustic environment variations. In order to achieve this, we first derive the abstract features from an early fine-tuned DNN model which is trained based on a clean speech database. By using the derived abstract features as the target values, the standard error back-propagation algorithm with the stochastic gradient descent method is performed to estimate the initial parameters of the DNN. The performance of the proposed algorithm was evaluated on Aurora-4 DB, and better results were observed compared to a number of conventional pre-training methods.", "paper_title": "Supervised Denoising Pre-Training for Robust ASR with DNN-HMM", "paper_id": "WOS:000368904200037"}