{"auto_keywords": [{"score": 0.04121986505406995, "phrase": "cross-media_retrieval"}, {"score": 0.015229139933711604, "phrase": "media_objects"}, {"score": 0.01512218688180685, "phrase": "different_modalities"}, {"score": 0.010108050104383225, "phrase": "mmdssg"}, {"score": 0.008027331682312157, "phrase": "mmdss"}, {"score": 0.00481495049065317, "phrase": "based_cross-media_retrieval"}, {"score": 0.004696407360309416, "phrase": "complementary_nature"}, {"score": 0.004116440453049531, "phrase": "manifold_learning_based_cross-media_retrieval_approach"}, {"score": 0.003725470458263889, "phrase": "concurrent_media_objects"}, {"score": 0.0036727235025069828, "phrase": "complementary_information"}, {"score": 0.0035949949979695063, "phrase": "integrated_semantics"}, {"score": 0.0034077704063304208, "phrase": "modality_bridge"}, {"score": 0.0031845067058084613, "phrase": "multimedia_document"}, {"score": 0.0030293828200315797, "phrase": "multidimensional_scaling"}, {"score": 0.002986461855862617, "phrase": "mmd_semantic_space"}, {"score": 0.002830839166653185, "phrase": "system_performance"}, {"score": 0.0028006988338192375, "phrase": "first_one"}, {"score": 0.0027121844541913367, "phrase": "second_one"}, {"score": 0.002664221051021009, "phrase": "new_items"}, {"score": 0.002570817338292482, "phrase": "mmdss."}, {"score": 0.002309754152767196, "phrase": "semantic_subspace"}, {"score": 0.0021582723621960693, "phrase": "experiment_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["cross-rnedia retrieval", " semantic complernentary", " modality complernentary", " manifold learning", " multimedia document"], "paper_abstract": "Media objects of different modalities always exist jointly and they are naturally cornplementary of each other, either in the view of semantics or in the view of modality. In this paper, we propose a manifold learning based cross-media retrieval approach that gives solutions to the two intrinsically basic but crucial questions of media objects semantics understanding and cross-media retrieval. First., considering the semantic complementary, how can we represent the concurrent media objects and fuse the complementary information they carry to understand the integrated semantics precisely. Second, considering the modality complementary, how can we accomplish the modality bridge to establish the cross-index and facilitate the cross-media retrieval? To solve the two problems, we first construct a Multimedia Document (MMD) Semi-Semantic Graph (MMDSSG) and their adopt Multidimensional Scaling to create an MMD Semantic Space (MMDSS). Both long-term and short-term feedbacks are proposed to boost the system performance. The first one is used to refine the MMDSSG and the second one is adopted to introduce new items that are not in the training set into the MMDSS. Since all of the MMDs and their component media objects of different modalities lie in the MMDSS and they are indexed uniformly by their coordinates in the MMDSS regardless of their modalities, the semantic subspace is actually a bridge of media objects which are of different modalities and the cross-media retrieval can be easily achieved. Experiment results are encouraging and indicate that the proposed approach is effective.", "paper_title": "Manifold learning based cross-media retrieval: A solution to media object complementary nature", "paper_id": "WOS:000245923000007"}