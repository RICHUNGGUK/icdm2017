{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "malay_tweet_normalization"}, {"score": 0.004740126725341152, "phrase": "natural_language_processing"}, {"score": 0.004648222388468414, "phrase": "normalizing_twitter_messages"}, {"score": 0.004558091785667046, "phrase": "different_well-defined_approaches"}, {"score": 0.004452228677941085, "phrase": "english_language"}, {"score": 0.004214640316113842, "phrase": "malay"}, {"score": 0.003974071684351861, "phrase": "malay_twitter_messages"}, {"score": 0.003927625349474979, "phrase": "corpus-driven_analysis"}, {"score": 0.003761900996118551, "phrase": "seven_main_modules"}, {"score": 0.0031909826501320313, "phrase": "english"}, {"score": 0.0030321497870310077, "phrase": "parallel_tweet_dataset"}, {"score": 0.002915514089373717, "phrase": "development_and_testing_stages"}, {"score": 0.002643139338194745, "phrase": "bleu"}, {"score": 0.002612194827110595, "phrase": "baseline_bleu"}, {"score": 0.0024436119167523156, "phrase": "smt-like_normalization_system"}, {"score": 0.002349561762300369, "phrase": "identical_parallel_dataset"}, {"score": 0.0023220573674955776, "phrase": "experimental_results"}, {"score": 0.0022769287097263564, "phrase": "higher_accuracy"}, {"score": 0.002250272652754455, "phrase": "normalization_system"}, {"score": 0.0021636476333109144, "phrase": "malay_tweets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Malay", " Twitter", " Text normalization", " Noisy text"], "paper_abstract": "Research in natural language processing has increasingly focused on normalizing Twitter messages. Currently, while different well-defined approaches have been proposed for the English language, the problem remains far from being solved for other languages, such as Malay. Thus, in this paper, we propose an approach to normalize the Malay Twitter messages based on corpus-driven analysis. An architecture for Malay Tweet normalization is presented, which comprises seven main modules: (1) enhanced tokenization, (2) In-Vocabulary (IV) detection, (3) specialized dictionary query, (4) repeated letter elimination, (5) abbreviation adjusting, (6) English word translation, and (7) de-tokenization. A parallel Tweet dataset, consisting of 9000 Malay Tweets, is used in the development and testing stages. To measure the performance of the system, an evaluation is carried out. The result is promising whereby we score 0.83 in BLEU against the baseline BLEU, which scores 0.46. To compare the accuracy of the architecture with other statistical approaches, an SMT-like normalization system is implemented, trained, and evaluated with an identical parallel dataset. The experimental results demonstrate that we achieve higher accuracy by the normalization system, which is designed based on the features of Malay Tweets, compared to the SMT-like system.(C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "An architecture for Malay Tweet normalization", "paper_id": "WOS:000340307000001"}