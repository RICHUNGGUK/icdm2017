{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "obstruction-free_photography"}, {"score": 0.004610058444728656, "phrase": "unified_computational_approach"}, {"score": 0.003907586297783078, "phrase": "single_image"}, {"score": 0.003613119346373748, "phrase": "short_image"}, {"score": 0.0031984060035955292, "phrase": "relative_position"}, {"score": 0.00303553181618577, "phrase": "obstructing_elements"}, {"score": 0.0026175952455594277, "phrase": "desired_background_scene"}, {"score": 0.0025279105573394727, "phrase": "visual_obstructions"}, {"score": 0.0023371689326096476, "phrase": "controlled_experiments"}, {"score": 0.0021049977753042253, "phrase": "raindrop-covered_windows"}], "paper_keywords": ["reflection removal", " occlusion removal", " image and video decomposition"], "paper_abstract": "We present a unified computational approach for taking photos through reflecting or occluding elements such as windows and fences. Rather than capturing a single image, we instruct the user to take a short image sequence while slightly moving the camera. Differences that often exist in the relative position of the background and the obstructing elements from the camera allow us to separate them based on their motions, and to recover the desired background scene as if the visual obstructions were not there. We show results on controlled experiments and many real and practical scenarios, including shooting through reflections, fences, and raindrop-covered windows.", "paper_title": "A Computational Approach for Obstruction-Free Photography", "paper_id": "WOS:000358786600045"}