{"auto_keywords": [{"score": 0.04494806290970924, "phrase": "direct_bp_ndp"}, {"score": 0.0431872167057894, "phrase": "ndpso"}, {"score": 0.00481495049065317, "phrase": "direct_back_propagation"}, {"score": 0.004758376187562744, "phrase": "bp"}, {"score": 0.0045913502687410755, "phrase": "ndp"}, {"score": 0.004510184935928004, "phrase": "particle_swarm_optimisation"}, {"score": 0.004249825947483216, "phrase": "pso_algorithm"}, {"score": 0.0037731618765688584, "phrase": "heuristic_dynamic_programming_algorithms"}, {"score": 0.003706410380455668, "phrase": "model-based_adaptive_critic_designs"}, {"score": 0.003576416581189716, "phrase": "online_learning_control_paradigm"}, {"score": 0.0035341028694769036, "phrase": "critic_bp_neural_network"}, {"score": 0.0031939996970411027, "phrase": "bellman's_equation"}, {"score": 0.0031374619658664843, "phrase": "action_bp_neural_network"}, {"score": 0.0030273620861817055, "phrase": "inertia_weight"}, {"score": 0.002921114512115261, "phrase": "critic_bp_network_output"}, {"score": 0.002852356597632014, "phrase": "ultimate_reward-to-go_objective"}, {"score": 0.0027522340188241446, "phrase": "collective_aid"}, {"score": 0.002719644855867468, "phrase": "action-critic_bp_neural_networks"}, {"score": 0.002593091742792519, "phrase": "social_coefficients"}, {"score": 0.002472412920623605, "phrase": "ndpso's_mutation_mechanism"}, {"score": 0.002385595105638277, "phrase": "dynamic_performance"}, {"score": 0.0023433334920926713, "phrase": "standard_pso._empirical_experiments"}, {"score": 0.0022745508619577927, "phrase": "unimodal_and_multimodal_benchmark_functions"}, {"score": 0.0021946656099592608, "phrase": "ndpso's_effectiveness"}], "paper_keywords": ["neural network", " adaptive critic designs", " particle swarm optimisation", " back propagation", " dynamic programming"], "paper_abstract": "In this paper, we introduce direct back propagation (BP) neural dynamic programming (NDP) into particle swarm optimisation (PSO). Thus, a direct BP NDP inspired PSO algorithm, which we call NDPSO, is proposed. In NDPSO, since direct BP NDP belongs to the class of heuristic dynamic programming algorithms based on model-based adaptive critic designs and often serves as an online learning control paradigm, critic BP neural network is trained to optimise a total reward-to-go objective, namely to balance Bellman's equation, while action BP neural network is used to train the inertia weight, cognitive, and social coefficients so that the critic BP network output can approach an ultimate reward-to-go objective of success. With the collective aid of action-critic BP neural networks, inertia weight, cognitive, and social coefficients become more adaptive. Besides, the NDPSO's mutation mechanism also has greatly improved the dynamic performance of the standard PSO. Empirical experiments are conducted on both unimodal and multimodal benchmark functions. The experimental results demonstrate NDPSO's effectiveness and superiority to many other PSO variants on solving most multimodal problems.", "paper_title": "Direct back propagation neural dynamic programming-based particle swarm optimisation", "paper_id": "WOS:000342848200004"}