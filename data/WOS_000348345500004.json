{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "fine-grained_categorization"}, {"score": 0.014333489079376448, "phrase": "distinctive_details"}, {"score": 0.009962423626705526, "phrase": "local_alignments"}, {"score": 0.004580243025274209, "phrase": "prior_work"}, {"score": 0.004474645041899596, "phrase": "specific_object_parts"}, {"score": 0.004103212598803194, "phrase": "corresponding_regions"}, {"score": 0.0038900709793274484, "phrase": "training_images"}, {"score": 0.0038642157757169315, "phrase": "unseen_images"}, {"score": 0.003449972561293443, "phrase": "distribution-based_features"}, {"score": 0.003427032390942116, "phrase": "color_fisher_vectors"}, {"score": 0.003359119985242403, "phrase": "localized_appearance"}, {"score": 0.0033367819052051995, "phrase": "fine-grained_categories"}, {"score": 0.003314591878914152, "phrase": "popular_matching_oriented_shape-sensitive_features"}, {"score": 0.003281583286051379, "phrase": "hog."}, {"score": 0.0032272929113113203, "phrase": "subtle_local_differences"}, {"score": 0.0029689853349030007, "phrase": "stanford_dogs_datasets"}, {"score": 0.002842920225545139, "phrase": "bird_and_dog_species"}, {"score": 0.0027312956497456374, "phrase": "color_fisher_vector_parameterization"}, {"score": 0.0026152965305133373, "phrase": "object_segmentation"}, {"score": 0.0025125868638809284, "phrase": "object_detectors"}, {"score": 0.002470987929071079, "phrase": "object_confidence_saliency_maps"}, {"score": 0.0023346234464901978, "phrase": "proposed_local_alignments"}, {"score": 0.0023113506171584157, "phrase": "new_state"}, {"score": 0.002213147136067999, "phrase": "human_intervention"}, {"score": 0.0021049977753042253, "phrase": "fine-grained_object_category"}], "paper_keywords": ["Alignment", " Image representation", " Object classification"], "paper_abstract": "The aim of this paper is fine-grained categorization without human interaction. Different from prior work, which relies on detectors for specific object parts, we propose to localize distinctive details by roughly aligning the objects using just the overall shape. Then, one may proceed to the classification by examining the corresponding regions of the alignments. More specifically, the alignments are used to transfer part annotations from training images to unseen images (supervised alignment), or to blindly yet consistently segment the object in a number of regions (unsupervised alignment). We further argue that for the distinction of subclasses, distribution-based features like color Fisher vectors are better suited for describing localized appearance of fine-grained categories than popular matching oriented shape-sensitive features, like HOG. They allow capturing the subtle local differences between subclasses, while at the same time being robust to misalignments between distinctive details. We evaluate the local alignments on the CUB-2011 and on the Stanford Dogs datasets, composed of 200 and 120, visually very hard to distinguish bird and dog species. In our experiments we study and show the benefit of the color Fisher vector parameterization, the influence of the alignment partitioning, and the significance of object segmentation on fine-grained categorization. We, furthermore, show that by using object detectors as voters to generate object confidence saliency maps, we arrive at fully unsupervised, yet highly accurate fine-grained categorization. The proposed local alignments set a new state-of-the-art on both the fine-grained birds and dogs datasets, even without any human intervention. What is more, the local alignments reveal what appearance details are most decisive per fine-grained object category.", "paper_title": "Local Alignments for Fine-Grained Categorization", "paper_id": "WOS:000348345500004"}