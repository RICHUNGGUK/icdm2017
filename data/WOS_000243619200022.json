{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "constrained_camera_motion"}, {"score": 0.004724365740062236, "phrase": "missing_parts"}, {"score": 0.0046797114400479135, "phrase": "video_sequence"}, {"score": 0.004620825188916713, "phrase": "moving_or_stationary_camera"}, {"score": 0.003994409920585572, "phrase": "simple_preprocessing_stage"}, {"score": 0.003944112858235306, "phrase": "video_inpainting"}, {"score": 0.003894446653225716, "phrase": "preprocessing_stage"}, {"score": 0.0036092644587974953, "phrase": "consistent_results"}, {"score": 0.003474575242120264, "phrase": "search_space"}, {"score": 0.0034308013197924987, "phrase": "first_video_inpainting_step"}, {"score": 0.0033875770020590796, "phrase": "moving_objects"}, {"score": 0.003051073364818384, "phrase": "moving_foreground"}, {"score": 0.0029935730127943496, "phrase": "priority-based_scheme"}, {"score": 0.0029558409515535525, "phrase": "second_step"}, {"score": 0.002909342017421165, "phrase": "remaining_hole"}, {"score": 0.0027218799769229596, "phrase": "remaining_pixels"}, {"score": 0.0026705669656375197, "phrase": "spatial_texture_synthesis_techniques"}, {"score": 0.0026452734009203764, "phrase": "spatiotemporal_domain"}, {"score": 0.0026202187680903063, "phrase": "proposed_framework"}, {"score": 0.0025063909490744855, "phrase": "similar_types"}, {"score": 0.002435834440131485, "phrase": "camera_motion"}, {"score": 0.0023448318062933527, "phrase": "statistical_models"}, {"score": 0.0022572213326336374, "phrase": "rich_and_cluttered_backgrounds"}, {"score": 0.0021659920594094407, "phrase": "motion_artifacts"}, {"score": 0.0021318918306931474, "phrase": "real_examples"}, {"score": 0.0021049977753042253, "phrase": "consumer_hand-held_camera"}], "paper_keywords": ["camera motion", " special effects", " texture synthesis", " video inpainting"], "paper_abstract": "A framework for inpainting missing parts of a video sequence recorded with a moving or stationary camera is presented in this work. The region to be inpainted is general: It may be still or moving, in the background or in the foreground, it may occlude one object and be occluded by some other object. The algorithm consists of a simple preprocessing stage and two steps of video inpainting. In the preprocessing stage, we roughly segment each frame into foreground and background. We use this segmentation to build three image mosaics that help to produce time consistent results and also improve the performance of the algorithm by reducing the search space. In the first video inpainting step, we reconstruct moving objects in the foreground that are \"occluded\" by the region to be inpainted. To this end, we fill the gap as much as possible by copying information from the moving foreground in other frames, using a priority-based scheme. In the second step, we inpaint the remaining hole with the background. To accomplish this, we first align the frames and directly copy when possible. The remaining pixels are filled in by extending spatial texture synthesis techniques to the spatiotemporal domain. The proposed framework has several advantages over state-of-the-art algorithms that deal with similar types of data and constraints. It permits some camera motion, is simple to implement, fast, does not require statistical models of background nor foreground, works well in the presence of rich and cluttered backgrounds, and the results show that there is no visible blurring or motion artifacts. A number of real examples taken with a consumer hand-held camera are shown supporting these findings.", "paper_title": "Video inpainting under constrained camera motion", "paper_id": "WOS:000243619200022"}