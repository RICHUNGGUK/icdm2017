{"auto_keywords": [{"score": 0.046081391722127746, "phrase": "proposed_image_descriptor"}, {"score": 0.03980713684810354, "phrase": "dct_coefficients"}, {"score": 0.00481495049065317, "phrase": "real-time_context_classification"}, {"score": 0.004626796109657584, "phrase": "dct-gist_image_representation_model"}, {"score": 0.0043345662747335065, "phrase": "real-time_scene_context_classification"}, {"score": 0.004225950334493496, "phrase": "low_computational_resources"}, {"score": 0.004165105357908494, "phrase": "mobile_and_other_single_sensor_devices"}, {"score": 0.0039019217388438134, "phrase": "discrete_cosine_transform"}, {"score": 0.0037087324991876727, "phrase": "digital_signal_processor"}, {"score": 0.0036288825833675127, "phrase": "proposed_solution"}, {"score": 0.003424225677958491, "phrase": "novel_image_representation"}, {"score": 0.003362660648932247, "phrase": "natural_images"}, {"score": 0.0033021988455635403, "phrase": "laplacian_distributions"}, {"score": 0.0032310733124059536, "phrase": "scale_parameter"}, {"score": 0.002918826667294298, "phrase": "spatial_hierarchy_approach"}, {"score": 0.0028663222014133813, "phrase": "dct_statistics"}, {"score": 0.0028455850650967477, "phrase": "image_sub-regions"}, {"score": 0.0027943943921568456, "phrase": "spatial_envelope"}, {"score": 0.002684984491718288, "phrase": "support_vector_machine_classifier"}, {"score": 0.002665555782056494, "phrase": "context_recognition_purpose"}, {"score": 0.0025242409510332527, "phrase": "proposed_representation_technique"}, {"score": 0.0025059724686541263, "phrase": "better_results"}, {"score": 0.002460876181416983, "phrase": "popular_gist_descriptor"}, {"score": 0.0024253827365474734, "phrase": "last_representation"}, {"score": 0.0023817332409567403, "phrase": "computational_costs"}, {"score": 0.0022967713922705, "phrase": "proposed_representation_model"}, {"score": 0.0021749654069549047, "phrase": "textons"}, {"score": 0.002151388538895855, "phrase": "spatial_hierarchy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Scene representation", " Scene classification", " Image descriptor", " GIST", " JPEG", " DCT features", " Mobile devices", " Wearable cameras"], "paper_abstract": "In this paper we introduce the DCT-GIST image representation model which is useful to summarize the context of the scene. The proposed image descriptor addresses the problem of real-time scene context classification on devices with limited memory and low computational resources (e.g., mobile and other single sensor devices such as wearable cameras). Images are holistically represented starting from the statistics collected in the Discrete Cosine Transform (DCT) domain. Since the DCT coefficients are usually computed within the digital signal processor for the JPEG conversion/storage, the proposed solution allows to obtain an instant and \"free of charge\" image signature. The novel image representation exploits the DCT coefficients of natural images by modelling them as Laplacian distributions which are summarized by the scale parameter in order to capture the context of the scene. Only discriminative DCT frequencies corresponding to edges and textures are retained to build the descriptor of the image. A spatial hierarchy approach allows to collect the DCT statistics on image sub-regions to better encode the spatial envelope of the scene. The proposed image descriptor is coupled with a Support Vector Machine classifier for context recognition purpose. Experiments on the well-known 8 Scene Context Dataset as well as on the MIT-67 Indoor Scene dataset demonstrate that the proposed representation technique achieves better results with respect to the popular GIST descriptor, outperforming this last representation also in terms of computational costs. Moreover, the experiments pointed out that the proposed representation model closely matches other state-of-the-art methods based on bag of Textons collected on spatial hierarchy. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Representing scenes for real-time context classification on mobile devices", "paper_id": "WOS:000348880300007"}