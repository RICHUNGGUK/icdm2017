{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multiagent_systems"}, {"score": 0.04940203756018457, "phrase": "sequential_action_selection"}, {"score": 0.048734215142491696, "phrase": "model-based_reinforcement_learning"}, {"score": 0.034582024677350484, "phrase": "traditional_prioritized_sweeping"}, {"score": 0.004265760046406154, "phrase": "model-free_reinforcement_learning"}, {"score": 0.003944112858235306, "phrase": "large_number"}, {"score": 0.003725470458263889, "phrase": "good_performance"}, {"score": 0.003395640013786862, "phrase": "self-interested_agents"}, {"score": 0.0032073043728420817, "phrase": "single_situation"}, {"score": 0.003072918736387408, "phrase": "learning_process"}, {"score": 0.002987296274887908, "phrase": "markov"}, {"score": 0.002861302930564756, "phrase": "n-person_general-sum_extensive_form_game"}, {"score": 0.002683304054823427, "phrase": "backward_induction"}, {"score": 0.0026077803487003, "phrase": "action_selection"}, {"score": 0.0024630345285372958, "phrase": "subgame_perfect_equilibrium_points"}, {"score": 0.0023936956017015696, "phrase": "optimal_joint_actions"}, {"score": 0.002326304140277375, "phrase": "new_joint_actions"}, {"score": 0.0021049977753042253, "phrase": "new_results"}], "paper_keywords": ["multiagent systems", " Markov games", " model-based reinforcement learning", " extensive form game"], "paper_abstract": "Model-based reinforcement learning uses the gathered information, during each experience, more efficiently than model-free reinforcement learning. This is especially interesting in multiagent systems, since a large number of experiences are necessary to achieve a good performance. In this paper, model-based reinforcement learning is developed for a group of self-interested agents with sequential action selection based on traditional prioritized sweeping. Every single situation of decision making in this learning process, called extensive Markov game, is modeled as n-person general-sum extensive form game with perfect information. A modified version of backward induction is proposed for action selection, which adjusts the tradeoff between selecting subgame perfect equilibrium points, as the optimal joint actions, and learning new joint actions. The algorithm is proved to be convergent and discussed based on the new results on the convergence of the traditional prioritized sweeping.", "paper_title": "Model-Based Reinforcement Learning in Multiagent Systems with Sequential Action Selection", "paper_id": "WOS:000290125800012"}