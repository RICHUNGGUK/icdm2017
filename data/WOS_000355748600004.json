{"auto_keywords": [{"score": 0.04540932995392894, "phrase": "previous_work"}, {"score": 0.043891862951523704, "phrase": "nash_equilibrium"}, {"score": 0.028095627153136907, "phrase": "rational_opponents"}, {"score": 0.02693232201986096, "phrase": "sosne_outcomes"}, {"score": 0.00481495049065317, "phrase": "decision_entrustment_mechanism"}, {"score": 0.004777214679969785, "phrase": "repeated_bilateral_agent_interactions"}, {"score": 0.004721162131188487, "phrase": "social_optimality"}, {"score": 0.004665764181113345, "phrase": "multiagent_interactions"}, {"score": 0.00462919213721188, "phrase": "robust_strategies"}, {"score": 0.00443308765153716, "phrase": "efficient_outcomes"}, {"score": 0.00438105507792004, "phrase": "large_body"}, {"score": 0.003986103192038901, "phrase": "prisoner's_dilemma_game"}, {"score": 0.00384731849108269, "phrase": "alternative_solution_concept"}, {"score": 0.0035141291835319682, "phrase": "agents'_payoffs"}, {"score": 0.003405109584265324, "phrase": "nash_equilibrium_payoff_profile"}, {"score": 0.0033651019362620866, "phrase": "infinitely_repeated_games"}, {"score": 0.003312486229143855, "phrase": "solution_concept"}, {"score": 0.003286486670483032, "phrase": "sosne"}, {"score": 0.0032350961776525075, "phrase": "system-level_performance"}, {"score": 0.002943147037670826, "phrase": "good_strategy"}, {"score": 0.002807178116892454, "phrase": "different_strategies"}, {"score": 0.00266693888510356, "phrase": "particular_class"}, {"score": 0.0024842242921857705, "phrase": "novel_learning_strategy_tafso"}, {"score": 0.0023415390666563177, "phrase": "opponent's_behavior"}, {"score": 0.0022777800735119405, "phrase": "extensive_simulations"}, {"score": 0.002224510044064184, "phrase": "better_performance"}, {"score": 0.0021896891011033105, "phrase": "average_payoffs"}], "paper_keywords": ["Multiagent learning", " Repeated games", " Socially optimal outcomes sustained by Nash equilibrium"], "paper_abstract": "During multiagent interactions, robust strategies are needed to help the agents to coordinate their actions on efficient outcomes. A large body of previous work focuses on designing strategies towards the goal of Nash equilibrium under self-play, which can be extremely inefficient in many situations such as prisoner's dilemma game. To this end, we propose an alternative solution concept, socially optimal outcome sustained by Nash equilibrium (SOSNE), which refers to those outcomes that maximize the sum of all agents' payoffs among all the possible outcomes that can correspond to a Nash equilibrium payoff profile in the infinitely repeated games. Adopting the solution concept of SOSNE guarantees that the system-level performance can be maximized provided that no agent will sacrifice its individual profits. On the other hand, apart from performing well under self-play, a good strategy should also be able to well respond against those opponents adopting different strategies as much as possible. To this end, we consider a particular class of rational opponents and we target at influencing those opponents to coordinate on SOSNE outcomes. We propose a novel learning strategy TaFSO which combines the characteristics of both teacher and follower strategies to effectively influence the opponent's behavior towards SOSNE outcomes by exploiting their limitations. Extensive simulations show that our strategy TaFSO achieves better performance in terms of average payoffs obtained than previous work under both self-play and against the same class of rational opponents.", "paper_title": "Introducing decision entrustment mechanism into repeated bilateral agent interactions to achieve social optimality", "paper_id": "WOS:000355748600004"}