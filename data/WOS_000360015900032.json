{"auto_keywords": [{"score": 0.0447884783780907, "phrase": "prefix_code"}, {"score": 0.015719716506582538, "phrase": "prefix_codes"}, {"score": 0.01243606882848431, "phrase": "optimal_prefix_code"}, {"score": 0.01075965462975971, "phrase": "average_codeword_length"}, {"score": 0.00470697922443172, "phrase": "statistical_compression"}, {"score": 0.004571692719970733, "phrase": "compressed_sequence"}, {"score": 0.004469151810727749, "phrase": "optimal_prefix_codes"}, {"score": 0.004354763128496983, "phrase": "storage_space"}, {"score": 0.003964007795174772, "phrase": "sequence_length"}, {"score": 0.003900257249255497, "phrase": "alphabet_size"}, {"score": 0.0038375280115736958, "phrase": "naive_storage"}, {"score": 0.003527181559366122, "phrase": "approximate_technique"}, {"score": 0.00325238798404366, "phrase": "additive_epsilon"}, {"score": 0.0031690434364310435, "phrase": "second_approximation"}, {"score": 0.00265090644169702, "phrase": "sixfold-to-eightfold_space_reductions"}, {"score": 0.002591335708291347, "phrase": "slower_encoding"}, {"score": 0.0023054252458274823, "phrase": "classical_implementations"}, {"score": 0.0022756672722130424, "phrase": "moderate_penalty"}, {"score": 0.0022536005664642294, "phrase": "average_code_length"}, {"score": 0.002160419006055386, "phrase": "optimal_algorithms"}, {"score": 0.0021394674440767124, "phrase": "length-restricted_codes"}, {"score": 0.0021049977753042253, "phrase": "optimal_ones"}], "paper_keywords": ["Computers and information processing", " data systems", " data compression", " huffman coding"], "paper_abstract": "Most of the attention in statistical compression is given to the space used by the compressed sequence, a problem completely solved with optimal prefix codes. However, in many applications, the storage space used to represent the prefix code itself can be an issue. In this paper, we introduce and compare several techniques to store prefix codes. Let N be the sequence length and n be the alphabet size. Then, a naive storage of an optimal prefix code uses O(n log n) bits. Our first technique shows how to use O(n log log(N/n)) bits to store the optimal prefix code. Then, we introduce an approximate technique that, for any 0 < epsilon < 1/2, takes O(n log log(1/epsilon)) bits to store a prefix code with an average codeword length within an additive epsilon of the minimum. Finally, a second approximation takes, for any constant c > 1, O(n(1/c) log n) bits to store a prefix code with an average codeword length at most c times the minimum. In all cases, our data structures allow encoding and decoding of any symbol in O(1) time. We experimentally compare our new techniques with the state of the art, showing that we achieve sixfold-to-eightfold space reductions, at the price of a slower encoding (2.5-8 times slower) and decoding (12-24 times slower). The approximations further reduce this space and improve the time significantly, up to recovering the speed of classical implementations, for a moderate penalty in the average code length. As a byproduct, we compare various heuristic, approximate, and optimal algorithms to generate length-restricted codes, showing that the optimal ones are clearly superior and practical enough to be implemented.", "paper_title": "Efficient and Compact Representations of Prefix Codes", "paper_id": "WOS:000360015900032"}