{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "spectral_tracking"}, {"score": 0.004609094651134046, "phrase": "temporally_complex_signals"}, {"score": 0.004429566229017728, "phrase": "real-world_audio_information_processing"}, {"score": 0.004026598712747509, "phrase": "background_music"}, {"score": 0.003994714109598034, "phrase": "sinusoidal_trajectories"}, {"score": 0.003947358102140903, "phrase": "temporal_characteristics"}, {"score": 0.0037485269508155516, "phrase": "musical_instrument"}, {"score": 0.003559675269411366, "phrase": "sound_segments"}, {"score": 0.00347574024760684, "phrase": "statistical_classifiers"}, {"score": 0.0033668870709083884, "phrase": "non-mixed_sounds"}, {"score": 0.0032099453192629976, "phrase": "subsequent_detection"}, {"score": 0.0031845067058084583, "phrase": "sound_categories"}, {"score": 0.0031467250930224126, "phrase": "mixed_sound"}, {"score": 0.0030847461428168614, "phrase": "temporal_overlapping"}, {"score": 0.002988101395789399, "phrase": "optimal_spectral_tracking_algorithm"}, {"score": 0.002964415652865295, "phrase": "low_computational_complexity"}, {"score": 0.002826181226538412, "phrase": "iterative_improvement"}, {"score": 0.002792638947473095, "phrase": "sinusoidal_decomposition"}, {"score": 0.0026836723685046407, "phrase": "temporal_mixture"}, {"score": 0.0025892330566358503, "phrase": "statistical_integration"}, {"score": 0.002558495760339272, "phrase": "temporal_features"}, {"score": 0.002429451930463481, "phrase": "detection_method"}, {"score": 0.0023626775529531486, "phrase": "mixed_sounds"}, {"score": 0.0022977342663599042, "phrase": "narrow-band_correlation_coefficients"}, {"score": 0.0022524395393089544, "phrase": "segmental_signal-to-noise_ratio"}, {"score": 0.0021049977753042253, "phrase": "proposed_detection_method"}], "paper_keywords": ["speech detection", " speech and music discrimination", " sinusoidal model", " spectral tracking", " sinusoidal trajectory"], "paper_abstract": "How to deal with Sounds that include spectrally and temporally complex signals such as speech and music remains a problem in real-world audio information processing. We have devised (1) a classification method based on sinusoidal trajectories for speech and music and (2) a detection method based on (1) for speech with background music. Sinusoidal trajectories represent the temporal characteristics of each category of sounds Such as speech, singing voice and musical instrument. From the trajectories, 20 temporal features are extracted and used to classify sound segments into the categories by using statistical classifiers. The average F, measure of the classification of non-mixed sounds was 0.939, which might be sufficiently high to apply to subsequent detection of sound categories in a mixed sound. To handle the temporal overlapping of sounds, we also developed an optimal spectral tracking algorithm with low computational complexity; it is based oil dynamic programming (DP) with iterative improvement for the sinusoidal decomposition of signals. The classification and detection of a temporal mixture of speech and music are performed by a statistical integration of the temporal features of their trajectories and the optimization of the combination of their categories. The detection method was experimentally evaluated using 400 samples of mixed sounds, and the average of the narrow-band correlation coefficients and improvement in the segmental signal-to-noise ratio (SNR) were 0.55 and +5.67 dB, respectively, which show effectiveness of the proposed detection method. (c) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Detection of speech and music based on spectral tracking", "paper_id": "WOS:000258175400001"}