{"auto_keywords": [{"score": 0.049581014501477005, "phrase": "multiclass_classification"}, {"score": 0.01547769010205604, "phrase": "multiple_scores"}, {"score": 0.010340075174548725, "phrase": "class_membership_probability"}, {"score": 0.007115155541440107, "phrase": "class_membership_probabilities"}, {"score": 0.005040729134978087, "phrase": "zadrozny_et_al"}, {"score": 0.00481495049065317, "phrase": "direct_estimation"}, {"score": 0.0047152877145889656, "phrase": "accurate_estimation"}, {"score": 0.0046176782475198085, "phrase": "data_mining"}, {"score": 0.004475022550508119, "phrase": "existing_methods"}, {"score": 0.004382364826200616, "phrase": "binary_classification"}, {"score": 0.0041481266398007074, "phrase": "multiclass_classifier"}, {"score": 0.004126479266916876, "phrase": "binary_classifiers"}, {"score": 0.004030449969901066, "phrase": "binary_classifier"}, {"score": 0.003998937402959455, "phrase": "target_estimate"}, {"score": 0.003973178859619635, "phrase": "roc_curve"}, {"score": 0.003946960862020283, "phrase": "simple_and_general_method"}, {"score": 0.003735907769330928, "phrase": "predicted_class"}, {"score": 0.0035453686625290886, "phrase": "representative_existing_methods"}, {"score": 0.0035225213801271037, "phrase": "pav_method"}, {"score": 0.003508439059651207, "phrase": "non-parametric_method"}, {"score": 0.0034267429854665035, "phrase": "binning_method"}, {"score": 0.0033381913087533457, "phrase": "\"accuracy_table"}, {"score": 0.003303412571939192, "phrase": "different_method"}, {"score": 0.0031513240597392843, "phrase": "reliable_probabilities"}, {"score": 0.0030940816793713606, "phrase": "parametric_method"}, {"score": 0.003061838370348944, "phrase": "platt's_method"}, {"score": 0.0030299300464039615, "phrase": "multiple_logistic_regression"}, {"score": 0.002951602182766167, "phrase": "japanese_social_surveys"}, {"score": 0.0028903961059456654, "phrase": "support_vector_machines"}, {"score": 0.002875293362426483, "phrase": "naive_bayes_classifiers"}, {"score": 0.0027142679199484783, "phrase": "cross_entropy"}, {"score": 0.002693018258362651, "phrase": "reliability_diagram"}, {"score": 0.0025824576209656676, "phrase": "proposed_smoothing_method"}, {"score": 0.0025622372343683804, "phrase": "accuracy_table"}, {"score": 0.0024699626298073547, "phrase": "mse"}, {"score": 0.002450602177683066, "phrase": "squared_error"}, {"score": 0.002301211274459965, "phrase": "pendigits"}, {"score": 0.0021049977753042253, "phrase": "pendigits_dataset"}], "paper_keywords": ["Multiclass classification", " Class membership probabilities", " Accuarcy table", " Logistic regression", " Direct estimation", " Multiple classification scores"], "paper_abstract": "Accurate estimation of class membership probability is needed for many applications in data mining and decision-making, to which multiclass classification is often applied. Since existing methods for estimation of class membership probability are designed for binary classification, in which only a single score outputted from a classifier can be used, an approach for multiclass classification requires both a decomposition of a multiclass classifier into binary classifiers and a combination of estimates obtained from each binary classifier to a target estimate. We propose a simple and general method for directly estimating class membership probability for any class in multiclass classification without decomposition and combination, using multiple scores not only for a predicted class but also for other proper classes. To make it possible to use multiple scores, we propose to modify or extend representative existing methods. As a non-parametric method, which refers to the idea of a binning method as proposed by Zadrozny et al., we create an \"accuracy table\" by a different method. Moreover we smooth accuracies on the table with methods such as the moving average to yield reliable probabilities (accuracies). As a parametric method, we extend Platt's method to apply a multiple logistic regression. On two different datasets (open-ended data from Japanese social surveys and the 20 Newsgroups) both with Support Vector Machines and naive Bayes classifiers, we empirically show that the use of multiple scores is effective in the estimation of class membership probabilities in multiclass classification in terms of cross entropy, the reliability diagram, the ROC curve and AUC (area under the ROC curve), and that the proposed smoothing method for the accuracy table works quite well. Finally, we show empirically that in terms of MSE (mean squared error), our best proposed method is superior to an expansion for multiclass classification of a PAV method proposed by Zadrozny et al., in both the 20 Newsgroups dataset and the Pendigits dataset, but is slightly worse than the state-of-the-art method, which is an expansion for multiclass classification of a combination of boosting and a PAV method, on the Pendigits dataset.", "paper_title": "Direct estimation of class membership probabilities for multiclass classification using multiple scores", "paper_id": "WOS:000265769000004"}