{"auto_keywords": [{"score": 0.035744371431884255, "phrase": "flow_field"}, {"score": 0.00481495049065317, "phrase": "autonomous_moving_system"}, {"score": 0.004695900553353526, "phrase": "motion_analysis"}, {"score": 0.004637478829869904, "phrase": "dense_optical_flow_fields"}, {"score": 0.0045607070754363245, "phrase": "new_generation"}, {"score": 0.004522796947899013, "phrase": "robotic_moving_systems"}, {"score": 0.004485200522202792, "phrase": "real-time_constraints"}, {"score": 0.004374267836149339, "phrase": "surveillance_scenario"}, {"score": 0.004319830179921363, "phrase": "especially_designed_autonomous_mobile_robot"}, {"score": 0.0040916230716372265, "phrase": "computational_resources"}, {"score": 0.0035947360742084253, "phrase": "moving_objects"}, {"score": 0.0034332736827447654, "phrase": "refining_phase"}, {"score": 0.0032381878248821383, "phrase": "descriptive_motion_properties"}, {"score": 0.0031317126905234145, "phrase": "collecting_stage"}, {"score": 0.003092690568543981, "phrase": "hierarchical_or_density-based_scheme"}, {"score": 0.002978508766388785, "phrase": "different_motion_models"}, {"score": 0.00290473242917264, "phrase": "model_selection_method"}, {"score": 0.0028446460307503343, "phrase": "novel_method"}, {"score": 0.0027395968397212053, "phrase": "distinct_moving_objects"}, {"score": 0.0027054473441439422, "phrase": "bayesian_formulation"}, {"score": 0.0025623050508233078, "phrase": "realistic_surveillance_situation"}, {"score": 0.002477998427152547, "phrase": "proposed_methods"}, {"score": 0.0024573577356299765, "phrase": "reliable_motion_information"}, {"score": 0.0023964590500856887, "phrase": "specialized_computers"}, {"score": 0.002346861891137455, "phrase": "resulting_segmentation"}, {"score": 0.002158505888557746, "phrase": "surveillance_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Motion segmentation", " Optical flow", " Moving observer", " Active surveillance", " Mobile robot"], "paper_abstract": "This article discusses the motion analysis based on dense optical flow fields and for a new generation of robotic moving systems with real-time constraints. It focuses on a surveillance scenario where an especially designed autonomous mobile robot uses a monocular camera for perceiving motion in the environment. The computational resources and the processing-time are two of the most critical aspects in robotics and therefore, two non-parametric techniques are proposed, namely, the Hybrid Hierarchical Optical Flow Segmentation and the Hybrid Density-Based Optical Flow Segmentation. Both methods are able to extract the moving objects by performing two consecutive operations: refining and collecting. During the refining phase, the flow field is decomposed in a set of clusters and based on descriptive motion properties. These properties are used in the collecting stage by a hierarchical or density-based scheme to merge the set of clusters that represent different motion models. In addition, a model selection method is introduced. This novel method analyzes the flow field and estimates the number of distinct moving objects using a Bayesian formulation. The research evaluates the performance achieved by the methods in a realistic surveillance situation. The experiments conducted proved that the proposed methods extract reliable motion information in real-time and without using specialized computers. Moreover, the resulting segmentation is less computationally demanding compared to other recent methods and therefore, they are suitable for most of the robotic or surveillance applications. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Unsupervised flow-based motion analysis for an autonomous moving system", "paper_id": "WOS:000337660900002"}