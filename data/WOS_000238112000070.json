{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "neural_architecture"}, {"score": 0.0046993598473345395, "phrase": "reinforcement_learning"}, {"score": 0.004586531354697466, "phrase": "self-organizing_neural_networks"}, {"score": 0.0043161190928529755, "phrase": "unsupervised_learning"}, {"score": 0.004012500850311087, "phrase": "self-organizing_neural_architecture"}, {"score": 0.003640516896245813, "phrase": "cognitive_codes"}, {"score": 0.0035530197642369464, "phrase": "multi-modal_pattern_spaces"}, {"score": 0.0028195727965553367, "phrase": "dynamic_environment"}, {"score": 0.002751751956416832, "phrase": "external_evaluative_feedback_signals"}, {"score": 0.0025892330566358503, "phrase": "case_study"}, {"score": 0.002526938673434697, "phrase": "td-falcon"}, {"score": 0.002348883765159185, "phrase": "cognitive_task"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_reinforcement_learning_approach"}], "paper_keywords": [""], "paper_abstract": "Self-organizing neural networks are typically associated with unsupervised learning. This paper presents a self-organizing neural architecture, known as TD-FALCON, that learns cognitive codes across multi-modal pattern spaces, involving states, actions, and rewards, and is capable of adapting and functioning in a dynamic environment with external evaluative feedback signals. We present a case study of TD-FALCON on a mine avoidance and navigation cognitive task, and illustrate its performance by comparing with a state-of-the-art reinforcement learning approach based on gradient descent backpropagation algorithm.", "paper_title": "Self-organizing neural architecture for reinforcement learning", "paper_id": "WOS:000238112000070"}