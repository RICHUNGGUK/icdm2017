{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "grasp_adaptation"}, {"score": 0.004773476989344654, "phrase": "human_corrections"}, {"score": 0.004651177631663439, "phrase": "object_interaction"}, {"score": 0.0045124316982387315, "phrase": "robust_grasp"}, {"score": 0.004396790930873782, "phrase": "external_perturbations"}, {"score": 0.0043213410601860985, "phrase": "grasped_object"}, {"score": 0.003962998498942108, "phrase": "statistical_model"}, {"score": 0.003911862375084159, "phrase": "hand_posture"}, {"score": 0.003828091961373454, "phrase": "perceived_contact"}, {"score": 0.0036817833826578395, "phrase": "multi-step_learning_procedure"}, {"score": 0.003510507340837656, "phrase": "initial_hand_posture"}, {"score": 0.0033762956164519286, "phrase": "human_teacher"}, {"score": 0.0032331613500559764, "phrase": "robot_hand"}, {"score": 0.0031365819432206004, "phrase": "resulting_sequence"}, {"score": 0.003109519872758431, "phrase": "hand_postures"}, {"score": 0.0030166226457616616, "phrase": "posture-contact_pairs"}, {"score": 0.0028513785049061767, "phrase": "key_feature"}, {"score": 0.002766171878646582, "phrase": "learned_model"}, {"score": 0.0026718978608934077, "phrase": "correction-replay_steps"}, {"score": 0.002525489173110693, "phrase": "new_models"}, {"score": 0.0024713335323674223, "phrase": "contact_signatures"}, {"score": 0.0024393978073660757, "phrase": "different_object"}, {"score": 0.0023562342764987254, "phrase": "icub_robot"}, {"score": 0.0022174469839432013, "phrase": "successful_model_reuse"}, {"score": 0.0021982976170703884, "phrase": "improved_adaptation"}, {"score": 0.002179313258573377, "phrase": "additional_rounds"}, {"score": 0.0021604924928015283, "phrase": "model_refinement"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Policy refinement", " Learning and adaptive systems", " Tactile sensing", " Grasp adaptation", " Humanoid robots"], "paper_abstract": "In the context of object interaction and manipulation, one characteristic of a robust grasp is its ability to comply with external perturbations applied to the grasped object while still maintaining the grasp. In this work, we introduce an approach for grasp adaptation which learns a statistical model to adapt hand posture solely based on the perceived contact between the object and fingers. Using a multi-step learning procedure, the model dataset is built by first demonstrating an initial hand posture, which is then physically corrected by a human teacher pressing on the fingertips, exploiting compliance in the robot hand. The learner then replays the resulting sequence of hand postures, to generate a dataset of posture-contact pairs that are not influenced by the touch of the teacher. A key feature of this work is that the learned model may be further refined by repeating the correction-replay steps. Alternatively, the model may be reused in the development of new models, characterized by the contact signatures of a different object. Our approach is empirically validated on the iCub robot. We demonstrate grasp adaptation in response to changes in contact, and show successful model reuse and improved adaptation with additional rounds of model refinement. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Iterative learning of grasp adaptation through human corrections", "paper_id": "WOS:000298205900005"}