{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "style_transfer"}, {"score": 0.005795662179008235, "phrase": "assembled_analogy"}, {"score": 0.0047006058139556686, "phrase": "exemplar_model"}, {"score": 0.004575195715264118, "phrase": "target's_structure"}, {"score": 0.004534136929881113, "phrase": "main_challenge"}, {"score": 0.004193316635088688, "phrase": "shape_analogies"}, {"score": 0.004155670607078649, "phrase": "iq_testing"}, {"score": 0.004130760425485278, "phrase": "shape_analogy_queries"}, {"score": 0.003597139600764093, "phrase": "logical_process"}, {"score": 0.003543445557071389, "phrase": "source-to-target_analogies"}, {"score": 0.003286722111554471, "phrase": "similar_structure"}, {"score": 0.003104086547947925, "phrase": "main_technical_challenge"}, {"score": 0.002976019715894587, "phrase": "human_logic"}, {"score": 0.002922759536495576, "phrase": "typical_analogies"}, {"score": 0.002861822702206142, "phrase": "small_set"}, {"score": 0.0028446460307503343, "phrase": "simple_transformations"}, {"score": 0.002719055901632759, "phrase": "shape_analogy"}, {"score": 0.002678433668156678, "phrase": "optimal_set"}, {"score": 0.0026623547595573953, "phrase": "source-to-target_transformations"}, {"score": 0.0025219085140220773, "phrase": "exemplar_shape"}, {"score": 0.0024917159298274297, "phrase": "desired_output_model"}, {"score": 0.0024544817577464816, "phrase": "proposed_framework"}, {"score": 0.00240328454980006, "phrase": "style_properties"}, {"score": 0.0023460767171603054, "phrase": "significant_improvements"}, {"score": 0.0022022878843247257, "phrase": "partial_scans"}, {"score": 0.0021498542694398273, "phrase": "structural_template"}, {"score": 0.002124106476971252, "phrase": "scan_style"}, {"score": 0.0021049977753042253, "phrase": "completed_surfaces"}], "paper_keywords": [""], "paper_abstract": "Style transfer aims to apply the style of an exemplar model to a target one, while retaining the target's structure. The main challenge in this process is to algorithmically distinguish style from structure, a high-level, potentially ill-posed cognitive task. Inspired by cognitive science research we recast style transfer in terms of shape analogies. In IQ testing, shape analogy queries present the subject with three shapes: source, target and exemplar, and ask them to select an output such that the transformation, or analogy, from the exemplar to the output is similar to that from the source to the target. The logical process involved in identifying the source-to-target analogies implicitly detects the structural differences between the source and target and can be used effectively to facilitate style transfer. Since the exemplar has a similar structure to the source, applying the analogy to the exemplar will provide the output we seek. The main technical challenge we address is to compute the source to target analogies, consistent with human logic. We observe that the typical analogies we look for consist of a small set of simple transformations, which when applied to the exemplar generate a continuous, seamless output model. To assemble a shape analogy, we compute an optimal set of source-to-target transformations, such that the assembled analogy best fits these criteria. The assembled analogy is then applied to the exemplar shape to produce the desired output model. We use the proposed framework to seamlessly transfer a variety of style properties between 2D and 3D objects and demonstrate significant improvements over the state of the art in style transfer. We further show that our framework can be used to successfully complete partial scans with the help of a user provided structural template, coherently propagating scan style across the completed surfaces.", "paper_title": "Analogy-driven 3D style transfer", "paper_id": "WOS:000337543000018"}