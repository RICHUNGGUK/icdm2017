{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "response_surface_methodology"}, {"score": 0.004510184935928004, "phrase": "multiple_kernels"}, {"score": 0.004430452655732319, "phrase": "weighted_linear_sum"}, {"score": 0.00430067200637091, "phrase": "different_kernels"}, {"score": 0.004125314447335291, "phrase": "multiple_sources"}, {"score": 0.003980687255880282, "phrase": "different_notions"}, {"score": 0.003619235073669304, "phrase": "usual_ones"}, {"score": 0.0035551969986263553, "phrase": "canonical_support_vector_machine_formulation"}, {"score": 0.0034922880300145283, "phrase": "new_regularization_parameters"}, {"score": 0.0034101316738399203, "phrase": "solution_quality"}, {"score": 0.003118838635447237, "phrase": "cross-validation_data"}, {"score": 0.0030273620861817055, "phrase": "digit_recognition_benchmark_data_sets"}, {"score": 0.0029561107046138136, "phrase": "multiple_kernel_learning"}, {"score": 0.0028185852354729026, "phrase": "support_vector_count"}, {"score": 0.002593091742792519, "phrase": "statistically_similar_or_higher_accuracy_results"}, {"score": 0.00248718591918233, "phrase": "support_vectors"}, {"score": 0.0024577274522206436, "phrase": "suitable_regularization"}, {"score": 0.002385595105638277, "phrase": "better_knowledge_extraction"}, {"score": 0.002357337046408753, "phrase": "unnecessary_kernels"}, {"score": 0.0022881443200668886, "phrase": "favored_kernels"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Support vector machine", " Multiple kernel learning", " Regularization", " Response surface methodology"], "paper_abstract": "In recent years, several methods have been proposed to combine multiple kernels using a weighted linear sum of kernels. These different kernels may be using information coming from multiple sources or may correspond to using different notions of similarity on the same source. We note that such methods, in addition to the usual ones of the canonical support vector machine formulation, introduce new regularization parameters that affect the solution quality and, in this work, we propose to optimize them using response surface methodology on cross-validation data. On several bioinformatics and digit recognition benchmark data sets, we compare multiple kernel learning and our proposed regularized variant in terms of accuracy, support vector count, and the number of kernels selected. We see that our proposed variant achieves statistically similar or higher accuracy results by using fewer kernel functions and/or support vectors through suitable regularization; it also allows better knowledge extraction because unnecessary kernels are pruned and the favored kernels reflect the properties of the problem at hand. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Regularizing multiple kernel learning using response surface methodology", "paper_id": "WOS:000282729300013"}