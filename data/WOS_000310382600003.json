{"auto_keywords": [{"score": 0.04665103656723687, "phrase": "pp"}, {"score": 0.009760150833074762, "phrase": "ss-le."}, {"score": 0.008072330553569715, "phrase": "constant_number"}, {"score": 0.00481495049065317, "phrase": "space_complexity"}, {"score": 0.0047810714349158165, "phrase": "self-stabilizing_leader_election"}, {"score": 0.0044237053504308285, "phrase": "angluin"}, {"score": 0.004270178957872099, "phrase": "mediated_population_protocol"}, {"score": 0.004165879874212301, "phrase": "extra_memory"}, {"score": 0.004121960535174029, "phrase": "agent-to-agent_communication_link"}, {"score": 0.003936910716320182, "phrase": "mobile_agents"}, {"score": 0.003909185474360582, "phrase": "limited_resources"}, {"score": 0.00385431710959668, "phrase": "general_distributed_system"}, {"score": 0.0038271712887391015, "phrase": "autonomous_agents"}, {"score": 0.003800215925586887, "phrase": "leader_election"}, {"score": 0.003720479367430766, "phrase": "key_role"}, {"score": 0.003578600071301459, "phrase": "distributed_systems"}, {"score": 0.0035533891890176823, "phrase": "huge_numbers"}, {"score": 0.003454314459767129, "phrase": "mpp"}, {"score": 0.003322540556404882, "phrase": "finite_number"}, {"score": 0.0032991276152705934, "phrase": "transient_failures"}, {"score": 0.003275879115801376, "phrase": "cai_et_al"}, {"score": 0.002658863179011018, "phrase": "least_agent-states"}, {"score": 0.0021049977753042253, "phrase": "complete_alternative"}], "paper_keywords": ["Population protocols", " Mediated population protocols", " Leader election", " Self-stabilization", " Space complexity"], "paper_abstract": "Chatzigiannakis et al. (Lect Notes Comput Sci 5734:56-76, 2009) extended the Population Protocol (PP) of Angluin et al. (2004) and introduced the Mediated Population Protocol (MPP) by introducing an extra memory on every agent-to-agent communication link (i.e., edge), in order to model more powerful networks of mobile agents with limited resources. For a general distributed system of autonomous agents, Leader Election (LE) plays a key role in their efficient coordination. A Self-Stabilizing (SS) protocol has ideal properties required for distributed systems of huge numbers of not highly reliable agents typically modeled by PP or MPP; it does not require any initialization and tolerates a finite number of transient failures. Cai et al. (2009) showed that for a system of agents, any PP for SS-LE requires at least agent-states, and gave a PP with agent-states for SS-LE. In this paper, we show, for a system of agents, any MPP for SS-LE with 2 edge-states (i.e., 1 bit memory) on every edge requires at least agent-states, and give an MPP for SS-LE with agent-states and 2 edge-states on every edge. Furthermore, we show that a constant number of edge-states on every edge do not help in designing an MPP for SS-LE with a constant number of agent-states, and that there is no MPP for SS-LE with 2 agent-states, regardless of the number of edge-states; the edge-state is not a complete alternative of the agent-state, although it can help in reducing the number of agent-states, when solving SS-LE.", "paper_title": "On space complexity of self-stabilizing leader election in mediated population protocol", "paper_id": "WOS:000310382600003"}