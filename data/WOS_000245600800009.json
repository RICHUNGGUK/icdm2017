{"auto_keywords": [{"score": 0.04818186976728298, "phrase": "relief"}, {"score": 0.00481495049065317, "phrase": "feature_weighting"}, {"score": 0.004271786540537981, "phrase": "proposed_algorithms"}, {"score": 0.0041703614123283165, "phrase": "new_feature_weighting_algorithms"}, {"score": 0.003969250376327401, "phrase": "large_increase"}, {"score": 0.003933736547198066, "phrase": "computational_complexity"}, {"score": 0.0038290829316346654, "phrase": "mathematical_interpretation"}, {"score": 0.003777800904236079, "phrase": "seemingly_heuristic_relief_algorithm"}, {"score": 0.0037272031155266556, "phrase": "online_method"}, {"score": 0.003677280504320639, "phrase": "convex_optimization_problem"}, {"score": 0.003628024127607343, "phrase": "margin-based_objective_function"}, {"score": 0.0034685354330506605, "phrase": "real_application"}, {"score": 0.0032716011062067286, "phrase": "implicit_assumption"}, {"score": 0.0032277611129050234, "phrase": "nearest_neighbors"}, {"score": 0.0031702173541386888, "phrase": "original_feature_space"}, {"score": 0.003085813569061001, "phrase": "weighted_space"}, {"score": 0.002963390095037466, "phrase": "outlier_data"}, {"score": 0.002897482096228207, "phrase": "iterative_relief"}, {"score": 0.0026600905156986317, "phrase": "expectation-maximization_algorithm"}, {"score": 0.0025660347613972573, "phrase": "multiclass_settings"}, {"score": 0.0025202582748972122, "phrase": "new_multiclass_margin_definition"}, {"score": 0.00247529638625566, "phrase": "computational_costs"}, {"score": 0.0024421008630165046, "phrase": "online_learning_algorithm"}, {"score": 0.002387758958649797, "phrase": "convergence_analysis"}, {"score": 0.002282667669149476, "phrase": "large-scale_experiments"}, {"score": 0.0022520496048464406, "phrase": "uci_and_microarray_data_sets"}, {"score": 0.0021049977753042253, "phrase": "presented_theoretical_results"}], "paper_keywords": ["feature weighting", " feature selection", " RELIEF", " iterative algorithm", " DNA microarray", " classification"], "paper_abstract": "RELIEF is considered one of the most successful algorithms for assessing the quality of features. In this paper, we propose a set of new feature weighting algorithms that perform significantly better than RELIEF, without introducing a large increase in computational complexity. Our work starts from a mathematical interpretation of the seemingly heuristic RELIEF algorithm as an online method solving a convex optimization problem with a margin-based objective function. This interpretation explains the success of RELIEF in real application and enables us to identify and address its following weaknesses. RELIEF makes an implicit assumption that the nearest neighbors found in the original feature space are the ones in the weighted space and RELIEF lacks a mechanism to deal with outlier data. We propose an iterative RELIEF (I-RELIEF) algorithm to alleviate the deficiencies of RELIEF by exploring the framework of the Expectation-Maximization algorithm. We extend I-RELIEF to multiclass settings by using a new multiclass margin definition. To reduce computational costs, an online learning algorithm is also developed. Convergence analysis of the proposed algorithms is presented. The results of large-scale experiments on the UCI and microarray data sets are reported, which demonstrate the effectiveness of the proposed algorithms, and verify the presented theoretical results.", "paper_title": "Iterative RELIEF for feature weighting: Algorithms, theories, and applications", "paper_id": "WOS:000245600800009"}