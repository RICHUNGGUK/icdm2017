{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "automatic_scale_selection"}, {"score": 0.029628979287270617, "phrase": "fixed-scale_image_encoding"}, {"score": 0.004413846562278824, "phrase": "autonomous_inspection_robot"}, {"score": 0.004135010810625326, "phrase": "novel_features"}, {"score": 0.003958937342925219, "phrase": "camera_images"}, {"score": 0.0036288825833675127, "phrase": "map_and_multi-scale_harris_detector"}, {"score": 0.0033626641500888108, "phrase": "gwr"}, {"score": 0.0031159081999910694, "phrase": "principal_component_analysis"}, {"score": 0.0030491175617778977, "phrase": "pca"}, {"score": 0.0027341763737751467, "phrase": "automatically_scaled_image_patches"}, {"score": 0.0024253827365474734, "phrase": "visual_input_space"}], "paper_keywords": ["automated inspection", " scale invariance", " online novelty detection"], "paper_abstract": "This paper presents experiments with an autonomous inspection robot, whose task was to highlight novel features in its environment from camera images. The experiments used two different attention mechanisms - saliency map and multi-scale Harris detector - and two different novelty detection mechanisms - the Grow-When-Required (GWR) neural network and an incremental Principal Component Analysis (PCA). For all mechanisms we compared fixed-scale image encoding with automatically scaled image patches. Results show that automatic scale selection provides a more efficient representation of the visual input space, but that performance is generally better using a fixed-scale image encoding. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Visual novelty detection with automatic scale selection", "paper_id": "WOS:000249771900006"}