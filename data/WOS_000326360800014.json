{"auto_keywords": [{"score": 0.04908562719345398, "phrase": "agricultural_commodities_task_domain"}, {"score": 0.04772698635453266, "phrase": "task_domain"}, {"score": 0.040460662577633456, "phrase": "experimental_study"}, {"score": 0.039013734513926375, "phrase": "marathi"}, {"score": 0.033434053074508197, "phrase": "mohan_et_al"}, {"score": 0.00481495049065317, "phrase": "speech_recognition"}, {"score": 0.0047747348769918, "phrase": "indian_languages"}, {"score": 0.004636594774238505, "phrase": "speech_recognition_based_services"}, {"score": 0.004353831792593701, "phrase": "increasing_number"}, {"score": 0.004105435059094976, "phrase": "small_vocabulary_speech_recognition_task"}, {"score": 0.004054117395250279, "phrase": "indian"}, {"score": 0.003953256858638655, "phrase": "multi-lingual_system"}, {"score": 0.003589404014552974, "phrase": "subspace_gaussian_mixture_model"}, {"score": 0.003286420941205958, "phrase": "multi-lingual_scenario"}, {"score": 0.0030857431184193765, "phrase": "speech_data"}, {"score": 0.0030216031606457214, "phrase": "targeted_user_population"}, {"score": 0.0029837589912490026, "phrase": "spoken_dialogue_systems"}, {"score": 0.002766415324343602, "phrase": "multiple_languages"}, {"score": 0.0026975346834867335, "phrase": "multi-lingual_systems"}, {"score": 0.002564862727498502, "phrase": "cross-corpus_acoustic_normalization_procedure"}, {"score": 0.002500987934534128, "phrase": "speaker_adaptive_training"}, {"score": 0.0023779596230982234, "phrase": "resulting_multi-lingual_system"}, {"score": 0.0023481578019624843, "phrase": "best_speech_recognition_performance"}, {"score": 0.0022420373745572837, "phrase": "\"similar\"_context-dependent_states"}, {"score": 0.0021770116505684394, "phrase": "hindi_speech_recognition_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Automatic speech recognition", " Multi-lingual speech recognition", " Subspace modelling", " Under-resourced languages", " Acoustic-normalization"], "paper_abstract": "In developing speech recognition based services for any task domain, it is necessary to account for the support of an increasing number of languages over the life of the service. This paper considers a small vocabulary speech recognition task in multiple Indian languages. To configure a multi-lingual system in this task domain, an experimental study is presented using data from two linguistically similar languages Hindi and Marathi. We do so by training a subspace Gaussian mixture model (SGMM) (Povey et al., 2011; Rose et al., 2011) under a multi-lingual scenario (Burget et al., 2010; Mohan et al., 2012a). Speech data was collected from the targeted user population to develop spoken dialogue systems in an agricultural commodities task domain for this experimental study. It is well known that acoustic, channel and environmental mismatch between data sets from multiple languages is an issue while building multi-lingual systems of this nature. As a result, we use a cross-corpus acoustic normalization procedure which is a variant of speaker adaptive training (SAT) (Mohan et al., 2012a). The resulting multi-lingual system provides the best speech recognition performance for both languages. Further, the effect of sharing \"similar\" context-dependent states from the Marathi language on the Hindi speech recognition performance is presented. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Acoustic modelling for speech recognition in Indian languages in an agricultural commodities task domain", "paper_id": "WOS:000326360800014"}