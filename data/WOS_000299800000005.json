{"auto_keywords": [{"score": 0.049488021144002546, "phrase": "linear_discriminant_analysis"}, {"score": 0.03782808165713525, "phrase": "multi-view_dynemes"}, {"score": 0.031004918011388126, "phrase": "discriminant_movement_representation"}, {"score": 0.00481495049065317, "phrase": "fuzzy_distances"}, {"score": 0.004553128404612054, "phrase": "novel_multi-view_human_movement_recognition_method"}, {"score": 0.004332322079100859, "phrase": "multi-view_human_movement_videos"}, {"score": 0.004122179528285764, "phrase": "basic_multi-view_human_movement_primitives"}, {"score": 0.0038978806337961565, "phrase": "movement_video"}, {"score": 0.003778566972399296, "phrase": "new_feature_space"}, {"score": 0.0034851070574149993, "phrase": "time_invariant_multi-view_movement_representation"}, {"score": 0.003234425353582135, "phrase": "human_body_postures"}, {"score": 0.0031746155143471725, "phrase": "dyneme_space"}, {"score": 0.003058599381153191, "phrase": "lda"}, {"score": 0.0028737647829311587, "phrase": "low_dimensionality_space"}, {"score": 0.0028206052780047424, "phrase": "view_identification_problem"}, {"score": 0.002700348931172875, "phrase": "circular_block_shift_procedure"}, {"score": 0.002585206414738808, "phrase": "minimum_euclidean_distance"}, {"score": 0.002444333100610621, "phrase": "circular_shift_invariance_property"}, {"score": 0.002384757932061618, "phrase": "dft"}, {"score": 0.0022825131641434964, "phrase": "camera_viewpoint_identification"}, {"score": 0.0022402661832994094, "phrase": "nearest_centroid_classification_step"}, {"score": 0.0021851480717840484, "phrase": "high_human_movement_classification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Activity recognition", " Multi-view dynemes", " Fuzzy vector quantization", " Linear discriminant analysis"], "paper_abstract": "In this paper, a novel multi-view human movement recognition method is presented. A novel representation of multi-view human movement videos is proposed that is based on learning basic multi-view human movement primitives, called multi-view dynemes. The movement video is represented in a new feature space (called dyneme space) using these multi-view dynemes, thus producing a time invariant multi-view movement representation. Fuzzy distances from the multi-view dynemes are used to represent the human body postures in the dyneme space. Three variants of Linear Discriminant Analysis (LDA) are evaluated to achieve a discriminant movement representation in a low dimensionality space. The view identification problem is solved either by using a circular block shift procedure followed by the evaluation of the minimum Euclidean distance from any dyneme, or by exploiting the circular shift invariance property of the Discrete Fourier Transform (DFT). The discriminant movement representation combined with camera viewpoint identification and a nearest centroid classification step leads to a high human movement classification accuracy. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "Multi-view human movement recognition based on fuzzy distances and linear discriminant analysis", "paper_id": "WOS:000299800000005"}