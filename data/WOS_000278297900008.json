{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "automatic_translation"}, {"score": 0.011177595834644016, "phrase": "german"}, {"score": 0.004756161254039343, "phrase": "translingual_qa_systems"}, {"score": 0.004472760779811399, "phrase": "translingual_question-answer"}, {"score": 0.004350777114615379, "phrase": "online_translators"}, {"score": 0.004271300595883407, "phrase": "qa_systems"}, {"score": 0.004142039499650824, "phrase": "spanish_language"}, {"score": 0.0039920586058503705, "phrase": "actual_translations"}, {"score": 0.003931262694860093, "phrase": "google"}, {"score": 0.0038950888505884687, "phrase": "promt_translator"}, {"score": 0.0038593331981451257, "phrase": "worldlingo"}, {"score": 0.0038004655673708016, "phrase": "objective_and_subjective_evaluation_measures"}, {"score": 0.003618034355727254, "phrase": "comparative_study"}, {"score": 0.0035301176972299627, "phrase": "factual_questions"}, {"score": 0.0034977005973838306, "phrase": "clef_collection"}, {"score": 0.00339182621699898, "phrase": "french"}, {"score": 0.0033709949363899326, "phrase": "spanish"}, {"score": 0.0030738153524707094, "phrase": "promt"}, {"score": 0.0028726347068397887, "phrase": "spanish-german_pair"}, {"score": 0.002846238033172098, "phrase": "good_assessment"}, {"score": 0.0028200832328369816, "phrase": "google_online_translator"}, {"score": 0.00269286089128731, "phrase": "lexical_nature"}, {"score": 0.0026273662637635747, "phrase": "poor_translation"}, {"score": 0.0026032174806986256, "phrase": "interrogative_particle"}, {"score": 0.002524309110841349, "phrase": "evaluation_methodology"}, {"score": 0.0023956021950024124, "phrase": "resulting_question"}, {"score": 0.0023735785441690097, "phrase": "effective_input"}, {"score": 0.0023517568875393345, "phrase": "translingual_qa_system"}, {"score": 0.0021842376228111537, "phrase": "adequate_response"}, {"score": 0.0021049977753042253, "phrase": "improved_translingual_qa_systems"}], "paper_keywords": ["Translation services", " Computer applications", " Knowledge management", " Languages", " Error analysis", " Quality improvement"], "paper_abstract": "Purpose This study aims to focus on the evaluation of systems for the automatic translation of questions destined to translingual question-answer (QA) systems. The efficacy of online translators when performing as tools in QA systems is analysed using a collection of documents in the Spanish language. Design/methodology/approach Automatic translation is evaluated in terms of the functionality of actual translations produced by three online translators (Google Translator, Promt Translator, and Worldlingo) by means of objective and subjective evaluation measures, and the typology of errors produced was identified. For this purpose, a comparative study of the quality of the translation of factual questions of the CLEF collection of queries was carried out, from German and French to Spanish. Findings It was observed that the rates of error for the three systems evaluated here are greater in the translations pertaining to the language pair German-Spanish. Promt was identified as the most reliable translator of the three (on average) for the two linguistic combinations evaluated. However, for the Spanish-German pair, a good assessment of the Google online translator was obtained as well. Most errors (46.38 percent) tended to be of a lexical nature, followed by those due to a poor translation of the interrogative particle of the query (31.16 percent). Originality/value The evaluation methodology applied focuses above all on the finality of the translation. That is, does the resulting question serve as effective input into a translingual QA system? Thus, instead of searching for \"perfection\", the functionality of the question and its capacity to lead one to an adequate response are appraised. The results obtained contribute to the development of improved translingual QA systems.", "paper_title": "Analysis of errors in the automatic translation of questions for translingual QA systems", "paper_id": "WOS:000278297900008"}