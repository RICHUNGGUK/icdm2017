{"auto_keywords": [{"score": 0.04170198874623122, "phrase": "vl_data"}, {"score": 0.00481495049065317, "phrase": "fuzzy_c-means"}, {"score": 0.0044491728131708505, "phrase": "objective_definition"}, {"score": 0.0038616499489536123, "phrase": "primary_tasks"}, {"score": 0.0038110933504990683, "phrase": "pattern_recognition"}, {"score": 0.003786062857121556, "phrase": "data_mining_communities"}, {"score": 0.003748823861741978, "phrase": "vl_databases"}, {"score": 0.0037119497772861165, "phrase": "vl_images"}, {"score": 0.003076152130543236, "phrase": "noniterative_extension"}, {"score": 0.002927712863777628, "phrase": "fcm"}, {"score": 0.0027318042427022953, "phrase": "numerical_experiments"}, {"score": 0.0025489778320184255, "phrase": "loadable_data"}, {"score": 0.0024662589776071864, "phrase": "ground_truth"}, {"score": 0.002450039362463466, "phrase": "empirical_results"}, {"score": 0.00242590924077914, "phrase": "random_sampling"}, {"score": 0.002308768837799101, "phrase": "good_choices"}, {"score": 0.0022191333270475087, "phrase": "vl_algorithms"}, {"score": 0.0021049977753042253, "phrase": "different_vl_fcm_clustering_schemes"}], "paper_keywords": ["Big data", " fuzzy c-means (FCM)", " kernel methods", " scalable clustering", " very large (VL) data"], "paper_abstract": "Very large (VL) data or big data are any data that you cannot load into your computer's working memory. This is not an objective definition, but a definition that is easy to understand and one that is practical, because there is a dataset too big for any computer you might use; hence, this is VL data for you. Clustering is one of the primary tasks used in the pattern recognition and data mining communities to search VL databases (including VL images) in various applications, and so, clustering algorithms that scale well to VL data are important and useful. This paper compares the efficacy of three different implementations of techniques aimed to extend fuzzy c-means (FCM) clustering to VL data. Specifically, we compare methods that are based on 1) sampling followed by noniterative extension; 2) incremental techniques that make one sequential pass through subsets of the data; and 3) kernelized versions of FCM that provide approximations based on sampling, including three proposed algorithms. We use both loadable and VL datasets to conduct the numerical experiments that facilitate comparisons based on time and space complexity, speed, quality of approximations to batch FCM (for loadable data), and assessment of matches between partitions and ground truth. Empirical results show that random sampling plus extension FCM, bit-reduced FCM, and approximate kernel FCM are good choices to approximate FCM for VL data. We conclude by demonstrating the VL algorithms on a dataset with 5 billion objects and presenting a set of recommendations regarding the use of different VL FCM clustering schemes.", "paper_title": "Fuzzy c-Means Algorithms for Very Large Data", "paper_id": "WOS:000311853200011"}