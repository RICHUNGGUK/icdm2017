{"auto_keywords": [{"score": 0.044380667726653916, "phrase": "diverse_classifiers"}, {"score": 0.03977013399469452, "phrase": "selection_process"}, {"score": 0.03370549904505103, "phrase": "multilayer_ensemble"}, {"score": 0.027100729214662247, "phrase": "msspso_algorithm"}, {"score": 0.02512571059927161, "phrase": "experimental_results"}, {"score": 0.00481495049065317, "phrase": "multilayer_ensemble_pruning_via_novel_multi-sub-swarm"}, {"score": 0.004795395078760977, "phrase": "particle_swarm_optimization"}, {"score": 0.004717960684395242, "phrase": "classifier_ensemble_methods"}, {"score": 0.004604136423327813, "phrase": "machine-learning_and_data-mining_communities"}, {"score": 0.004331393784852601, "phrase": "single_classifier"}, {"score": 0.003944112858235306, "phrase": "proper_base"}, {"score": 0.0036207206487324506, "phrase": "ensemble_pruning"}, {"score": 0.0035189057079817285, "phrase": "optimal_combination"}, {"score": 0.0034060348526709634, "phrase": "base_classifiers"}, {"score": 0.003378385493203297, "phrase": "useful_information"}, {"score": 0.0032967724149749853, "phrase": "pruning_process"}, {"score": 0.0029172611440429963, "phrase": "multimodal_optimization_problem"}, {"score": 0.002881793492919646, "phrase": "novel_multi-sub-swarm_particle_swarm"}, {"score": 0.0027330029055210926, "phrase": "multilayer_ensemble_pruning_model"}, {"score": 0.0026560841114619147, "phrase": "base_classifier"}, {"score": 0.002613103872300205, "phrase": "oracle_output"}, {"score": 0.002508663916554954, "phrase": "different_pruning"}, {"score": 0.0024781515864648242, "phrase": "previous_oracle_output"}, {"score": 0.0024083881142747954, "phrase": "uci_dataset"}, {"score": 0.0022561982694417116, "phrase": "generalization_performance"}, {"score": 0.0022287497627555895, "phrase": "multi-classifiers_ensemble_system"}, {"score": 0.0021049977753042253, "phrase": "pruning_technique"}], "paper_keywords": ["Particle swarm optimization", " ensemble pruning", " classifier ensemble", " multi-layer ensemble model"], "paper_abstract": "Recently, classifier ensemble methods are gaining more and more attention in the machine-learning and data-mining communities. In most cases, the performance of an ensemble is better than a single classifier. Many methods for creating diverse classifiers were developed during the past decade. When these diverse classifiers are generated, it is important to select the proper base classifier to join the ensemble. Usually, this selection process is called pruning the ensemble. In general, the ensemble pruning is a selection process in which an optimal combination will be selected from many existing base classifiers. Some base classifiers containing useful information may be excluded in this pruning process. To avoid this problem, the multilayer ensemble pruning model is used in this paper. In this model, the pruning of one layer can be seen as a multimodal optimization problem. A novel multi-sub-swarm particle swarm optimization (MSSPSO) is used here to find multi-solutions for this multilayer ensemble pruning model. In this model, each base classifier will generate an oracle output. Each layer will use MSSPSO algorithm to generate a different pruning based on previous oracle output. A series of experiments using UCI dataset is conducted, the experimental results show that the multilayer ensemble pruning via MSSPSO algorithm can improve the generalization performance of the multi-classifiers ensemble system. Besides, the experimental results show a relationship between the diversity and the pruning technique.", "paper_title": "Multilayer Ensemble Pruning via Novel Multi-sub-swarm Particle Swarm Optimization", "paper_id": "WOS:000269280700009"}