{"auto_keywords": [{"score": 0.041156613157296774, "phrase": "neural_network_language_models"}, {"score": 0.00481495049065317, "phrase": "off-line_handwriting_recognition"}, {"score": 0.004739777076599284, "phrase": "unconstrained"}, {"score": 0.0047026237903774895, "phrase": "off-line_continuous_handwritten_text_recognition"}, {"score": 0.004278807087784626, "phrase": "different_promising_techniques"}, {"score": 0.003832198214757852, "phrase": "decoding_process"}, {"score": 0.003432044343307207, "phrase": "bidirectional_recurrent_neural_networks"}, {"score": 0.003299460925313939, "phrase": "hybrid_hidden_markov_models"}, {"score": 0.0031223774204093713, "phrase": "experimental_results"}, {"score": 0.0028630535573013686, "phrase": "consistent_word_error_rate_reductions"}, {"score": 0.00266693888510356, "phrase": "statistical_n-gram_language_models"}, {"score": 0.0025038930574283174, "phrase": "best_word_error_rate"}, {"score": 0.0023881683972170422, "phrase": "rover_combination"}, {"score": 0.002259883463607508, "phrase": "current_benchmark_results"}, {"score": 0.0022070310530794097, "phrase": "iam_database"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Handwritten text recognition (HTR)", " Language models (LMs)", " Neural networks (NNs)", " Neural network language model (NN LM)", " Bidirectional long short-term memory neural networks (BLSTM)", " Hybrid HMM/ANN models", " ROVER combination"], "paper_abstract": "Unconstrained off-line continuous handwritten text recognition is a very challenging task which has been recently addressed by different promising techniques. This work presents our latest contribution to this task, integrating neural network language models in the decoding process of three state-of-the-art systems: one based on bidirectional recurrent neural networks, another based on hybrid hidden Markov models and, finally, a combination of both. Experimental results obtained on the IAM off-line database demonstrate that consistent word error rate reductions can be achieved with neural network language models when compared with statistical N-gram language models on the three tested systems. The best word error rate, 16.1%, reported with ROVER combination of systems using neural network language models significantly outperforms current benchmark results for the IAM database. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Neural network language models for off-line handwriting recognition", "paper_id": "WOS:000331669300008"}