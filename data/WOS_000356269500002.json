{"auto_keywords": [{"score": 0.0389569451865242, "phrase": "falcon"}, {"score": 0.00481495049065317, "phrase": "autonomous_adaptive_agents"}, {"score": 0.004729856080441582, "phrase": "real-time_first-person_shooter_computer_game"}, {"score": 0.004456872931482395, "phrase": "ai_methodologies"}, {"score": 0.004224627834741731, "phrase": "vast_amount"}, {"score": 0.004100851549096203, "phrase": "real-time_computer_games"}, {"score": 0.004004436217742343, "phrase": "traditional_board_games"}, {"score": 0.003957078581524691, "phrase": "card_games"}, {"score": 0.0036408354779365643, "phrase": "self-organizing_neural_network"}, {"score": 0.003450966222451681, "phrase": "well-known_first-person_shooter_computer_game"}, {"score": 0.0034101316738399203, "phrase": "unreal_tournament"}, {"score": 0.0031939996970411027, "phrase": "game_environment"}, {"score": 0.0031003255054939524, "phrase": "temporal_difference"}, {"score": 0.002852356597632014, "phrase": "proper_strategies"}, {"score": 0.0027522340188241446, "phrase": "different_weapons"}, {"score": 0.0026241684260044414, "phrase": "experimental_results"}, {"score": 0.002315574871863272, "phrase": "previously_learned_knowledge"}, {"score": 0.002181626277903721, "phrase": "different_opponent"}, {"score": 0.002142970278347126, "phrase": "different_map"}, {"score": 0.0021049977753042253, "phrase": "relatively_short_period"}], "paper_keywords": ["Adaptive resonance theory operations", " real-time computer game", " reinforcement learning", " temporal difference learning", " unreal tournament"], "paper_abstract": "Games are good test-beds to evaluate AI methodologies. In recent years, there has been a vast amount of research dealing with real-time computer games other than the traditional board games or card games. This paper illustrates how we create agents by employing FALCON, a self-organizing neural network that performs reinforcement learning, to play a well-known first-person shooter computer game called Unreal Tournament. Rewards used for learning are either obtained from the game environment or estimated using the temporal difference learning scheme. In this way, the agents are able to acquire proper strategies and discover the effectiveness of different weapons without any guidance or intervention. The experimental results show that our agents learn effectively and appropriately from scratch while playing the game in real-time. Moreover, with the previously learned knowledge retained, our agent is able to adapt to a different opponent in a different map within a relatively short period of time.", "paper_title": "Creating Autonomous Adaptive Agents in a Real-Time First-Person Shooter Computer Game", "paper_id": "WOS:000356269500002"}