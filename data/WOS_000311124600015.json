{"auto_keywords": [{"score": 0.04647778853118898, "phrase": "virtual_objects"}, {"score": 0.022203666076004387, "phrase": "real_scene"}, {"score": 0.0190426747816445, "phrase": "commodity_haptic_devices"}, {"score": 0.010612387000973441, "phrase": "visuo-haptic_mixed_reality"}, {"score": 0.008330291454711774, "phrase": "virtual_tool"}, {"score": 0.006936721396532046, "phrase": "user's_hand"}, {"score": 0.0047709540557306284, "phrase": "unobstructed_tool-hand_integration"}, {"score": 0.004312622975366676, "phrase": "see-through_display_technology"}, {"score": 0.004234129588974058, "phrase": "real_and_virtual_objects"}, {"score": 0.004176194589991187, "phrase": "haptic_devices"}, {"score": 0.004119049028319832, "phrase": "haptic_interaction"}, {"score": 0.0038981499110532273, "phrase": "obstruction_and_misalignment_issues"}, {"score": 0.0038271712887391015, "phrase": "correct_integration"}, {"score": 0.0037231102027070724, "phrase": "user's_real_hand"}, {"score": 0.0036721416244816455, "phrase": "mixed_reality_scene"}, {"score": 0.0035233696341819437, "phrase": "novel_mixed_reality_paradigm"}, {"score": 0.0031845067058084583, "phrase": "visually_consistent_integration"}, {"score": 0.003027462227648001, "phrase": "visual_obstruction"}, {"score": 0.002999749669403939, "phrase": "misalignment_issues"}, {"score": 0.002686284749214443, "phrase": "-based_segmentation"}, {"score": 0.0026494723416072316, "phrase": "haptic_device"}, {"score": 0.0025892330566358503, "phrase": "image-based_models"}, {"score": 0.00241658945942583, "phrase": "successful_proof-of-concept_implementation"}, {"score": 0.0021441057555396013, "phrase": "user_performance"}, {"score": 0.0021049977753042253, "phrase": "misalignment_correction"}], "paper_keywords": ["Mixed reality", " visuo-haptic mixed reality", " occlusion handling", " haptic interfaces", " image-based rendering"], "paper_abstract": "Visuo-haptic mixed reality consists of adding to a real scene the ability to see and touch virtual objects. It requires the use of see-through display technology for visually mixing real and virtual objects, and haptic devices for adding haptic interaction with the virtual objects. Unfortunately, the use of commodity haptic devices poses obstruction and misalignment issues that complicate the correct integration of a virtual tool and the user's real hand in the mixed reality scene. In this work, we propose a novel mixed reality paradigm where it is possible to touch and see virtual objects in combination with a real scene, using commodity haptic devices, and with a visually consistent integration of the user's hand and the virtual tool. We discuss the visual obstruction and misalignment issues introduced by commodity haptic devices, and then propose a solution that relies on four simple technical steps: color-based segmentation of the hand, tracking-based segmentation of the haptic device, background repainting using image-based models, and misalignment-free compositing of the user's hand. We have developed a successful proof-of-concept implementation, where a user can touch virtual objects and interact with them in the context of a real scene, and we have evaluated the impact on user performance of obstruction and misalignment correction.", "paper_title": "Visuo-Haptic Mixed Reality with Unobstructed Tool-Hand Integration", "paper_id": "WOS:000311124600015"}