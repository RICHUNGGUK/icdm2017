{"auto_keywords": [{"score": 0.04842456838190479, "phrase": "gaussian_markov_random_fields"}, {"score": 0.04527099105579865, "phrase": "cholesky_factorization"}, {"score": 0.00481495049065317, "phrase": "sparse_matrix_r_package"}, {"score": 0.00470341117804131, "phrase": "mcmc_methods"}, {"score": 0.0045143706249204905, "phrase": "r_package"}, {"score": 0.004461761855323898, "phrase": "sparse_matrix_algebra"}, {"score": 0.004282391936827106, "phrase": "sparse_positive_definite_matrices"}, {"score": 0.0040385352882334235, "phrase": "competing_philosophical_maxims"}, {"score": 0.0038761135052054765, "phrase": "existing_tools"}, {"score": 0.003487721546598799, "phrase": "fast_fortran_routines"}, {"score": 0.0030833537429977797, "phrase": "algorithmic_steps"}, {"score": 0.0026313840069327713, "phrase": "factorization_results"}, {"score": 0.0025106241866273897, "phrase": "memory_savings"}, {"score": 0.002409503258044183, "phrase": "large_matrices"}, {"score": 0.002381365139274329, "phrase": "slightly_smaller_factors"}, {"score": 0.002353554841514325, "phrase": "huge_matrices"}, {"score": 0.002258745901862197, "phrase": "markov_chain_monte_carlo_methods"}, {"score": 0.0021049977753042253, "phrase": "efficient_cholesky_factorization"}], "paper_keywords": ["Cholesky factorization", " compactly supported covariance function", " compressed sparse row format", " symmetric positive-definite matrix", " stochastic modeling", " S3/S4"], "paper_abstract": "spam is an R package for sparse matrix algebra with emphasis on a Cholesky factorization of sparse positive definite matrices. The implemantation of spam is based on the competing philosophical maxims to be competitively fast compared to existing tools and to be easy to use, modify and extend. The first is addressed by using fast Fortran routines and the second by assuring S3 and S4 compatibility. One of the features of spam is to exploit the algorithmic steps of the Cholesky factorization and hence to perform only a fraction of the workload when factorizing matrices with the same sparsity structure. Simulations show that exploiting this break-down of the factorization results in a speed-up of about a factor 5 and memory savings of about a factor 10 for large matrices and slightly smaller factors for huge matrices. The article is motivated with Markov chain Monte Carlo methods for Gaussian Markov random fields, but many other statistical applications are mentioned that profit from an efficient Cholesky factorization as well.", "paper_title": "spam: A Sparse Matrix R Package with Emphasis on MCMC Methods for Gaussian Markov Random Fields", "paper_id": "WOS:000282056300001"}