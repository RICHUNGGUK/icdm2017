{"auto_keywords": [{"score": 0.04633392568746383, "phrase": "cardinality_constraints"}, {"score": 0.010101056455315156, "phrase": "uncertain_data"}, {"score": 0.005939114637162139, "phrase": "armstrong_sketch"}, {"score": 0.00481495049065317, "phrase": "qualitatively_uncertain_data"}, {"score": 0.004771672073078768, "phrase": "modern_applications"}, {"score": 0.004728780808284175, "phrase": "advanced_techniques"}, {"score": 0.004623224002010226, "phrase": "large_volumes"}, {"score": 0.0043793594257092805, "phrase": "principled_tool"}, {"score": 0.0038590090616766434, "phrase": "uncertain_instance"}, {"score": 0.0034623203126093833, "phrase": "intuitive_way"}, {"score": 0.0033393377529146893, "phrase": "precise_value"}, {"score": 0.0032061793819537633, "phrase": "natural_possible_world_semantics"}, {"score": 0.00298238929037041, "phrase": "associated_implication_problem"}, {"score": 0.002915701586760994, "phrase": "linear_input_time"}, {"score": 0.002466303439899648, "phrase": "conservative_use"}, {"score": 0.002400241288973103, "phrase": "data_engineers"}, {"score": 0.0023571835517819124, "phrase": "armstrong_sketches"}, {"score": 0.0022836785412390544, "phrase": "domain_experts"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Data and knowledge visualization", " Data models", " Database semantics", " Management of integrity constraints", " Requirements engineering"], "paper_abstract": "Modern applications require advanced techniques and tools to process large volumes of uncertain data. For that purpose we introduce cardinality constraints as a principled tool to control the occurrences of uncertain data. Uncertainty is modeled qualitatively by assigning to each object a degree of possibility by which the object occurs in an uncertain instance. Cardinality constraints are assigned a degree of certainty that stipulates on which objects they hold. Our framework empowers users to model uncertainty in an intuitive way, without the requirement to put a precise value on it. Our class of cardinality constraints enjoys a natural possible world semantics, which is exploited to establish several tools to reason about them. We characterize the associated implication problem axiomatically and algorithmically in linear input time. Furthermore, we show how to visualize any given set of our cardinality constraints in the form of an Armstrong sketch. Even though the problem of finding an Armstrong sketch is precisely exponential, our algorithm computes a sketch with conservative use of time and space. Data engineers may therefore compute Armstrong sketches that they can jointly inspect with domain experts in order to consolidate the set of cardinality constraints meaningful for a given application domain. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Cardinality constraints on qualitatively uncertain data", "paper_id": "WOS:000362857900008"}