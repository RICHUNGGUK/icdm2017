{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "gpu"}, {"score": 0.007671093604712484, "phrase": "gpu_memory"}, {"score": 0.006954272395206041, "phrase": "gpu-to-gpu_case"}, {"score": 0.006535108782860173, "phrase": "host-to-host_case"}, {"score": 0.004568891248626221, "phrase": "gpu."}, {"score": 0.004524145463916772, "phrase": "gpu_adaptations"}, {"score": 0.004435996651495295, "phrase": "boyer-moore"}, {"score": 0.003903269701018361, "phrase": "host_cpu"}, {"score": 0.0037402558657576124, "phrase": "base_gpu_implementation"}, {"score": 0.0036914757355166966, "phrase": "performance_gain"}, {"score": 0.0028108693928384503, "phrase": "aho-corasick"}, {"score": 0.0026933542552712033, "phrase": "single-thread_cpu_implementation"}, {"score": 0.002640781900605126, "phrase": "best_multithreaded_implementation"}, {"score": 0.002497319603143104, "phrase": "single-threaded_cpu_implementation"}, {"score": 0.002377206033025253, "phrase": "best_multithreaded_code"}, {"score": 0.002346160830406661, "phrase": "quad-core_host"}, {"score": 0.0022703060319871713, "phrase": "latter_case"}, {"score": 0.0022406537579986842, "phrase": "early_versions"}, {"score": 0.0021753413850499467, "phrase": "corresponding_versions"}, {"score": 0.0021539955106204354, "phrase": "ac_adaptations"}, {"score": 0.0021049977753042253, "phrase": "multipattern_boyer-moore"}], "paper_keywords": ["Multipattern string matching", " Aho-Corasick", " multipattern Boyer-Moore", " GPU", " CUDA"], "paper_abstract": "We develop GPU adaptations of the Aho-Corasick and multipattern Boyer-Moore string matching algorithms for the two cases GPU-to-GPU (input to the algorithms is initially in GPU memory and the output is left in GPU memory) and host-to-host (input and output are in the memory of the host CPU). For the GPU-to-GPU case, we consider several refinements to a base GPU implementation and measure the performance gain from each refinement. For the host-to-host case, we analyze two strategies to communicate between the host and the GPU and show that one is optimal with respect to runtime while the other requires less device memory. This analysis is done for GPUs with one I/O channel to the host as well as those with 2. Experiments conducted on an NVIDIA Tesla GT200 GPU that has 240 cores running off of a Xeon 2.8 GHz quad-core host CPU show that, for the GPU-to-GPU case, our Aho-Corasick GPU adaptation achieves a speedup between 8.5 and 9.5 relative to a single-thread CPU implementation and between 2.4 and 3.2 relative to the best multithreaded implementation. For the host-to-host case, the GPU AC code achieves a speedup of 3.1 relative to a single-threaded CPU implementation. However, the GPU is unable to deliver any speedup relative to the best multithreaded code running on the quad-core host. In fact, the measured speedups for the latter case ranged between 0.74 and 0.83. Early versions of our multipattern Boyer-Moore adaptations ran 7 to 10 percent slower than corresponding versions of the AC adaptations and we did not refine the multipattern Boyer-Moore codes further.", "paper_title": "GPU-to-GPU and Host-to-Host Multipattern String Matching on a GPU", "paper_id": "WOS:000318641600009"}