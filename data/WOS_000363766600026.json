{"auto_keywords": [{"score": 0.029759469482311604, "phrase": "cpu_core_hours'_metric"}, {"score": 0.00481495049065317, "phrase": "distributed_symmetric_sparse_matrix_vector_multiplication_algorithm"}, {"score": 0.00464811139983244, "phrase": "sparse_matrix_vector_multiply"}, {"score": 0.004509694461067052, "phrase": "important_kernel"}, {"score": 0.004397487039229447, "phrase": "high_performance_computing_applications"}, {"score": 0.003995876175614403, "phrase": "large_scale_computations"}, {"score": 0.0038379074449947067, "phrase": "high_end_multi-core_architectures"}, {"score": 0.00376127170364341, "phrase": "messaging_passing_interface"}, {"score": 0.003487222504700868, "phrase": "recently_proposed_implementation"}, {"score": 0.0034348484776384643, "phrase": "distributed_symmetric_spmvm"}, {"score": 0.0033492947290751996, "phrase": "large_sparse_symmetric_matrices"}, {"score": 0.0032989853590079153, "phrase": "ab_initio_nuclear_structure_calculations"}, {"score": 0.003233075944817365, "phrase": "important_features"}, {"score": 0.0031208772639433145, "phrase": "previously_reported_implementations"}, {"score": 0.0030431198971423937, "phrase": "underlying_symmetry"}, {"score": 0.0029672941061574375, "phrase": "hybrid_paradigm"}, {"score": 0.002907992115184249, "phrase": "expensive_communications"}, {"score": 0.0027370835853738626, "phrase": "main_measure"}, {"score": 0.002709589081384597, "phrase": "resource_usage"}, {"score": 0.0025892330566358503, "phrase": "topology-aware_mapping_heuristic"}, {"score": 0.002563219920877287, "phrase": "simplified_network_load_model"}, {"score": 0.002486734224234698, "phrase": "different_spmvm_implementations"}, {"score": 0.0024125253170522816, "phrase": "dragonfly_topology"}, {"score": 0.0023405257495466352, "phrase": "distributed_spmvm_implementation"}, {"score": 0.0023053339328456234, "phrase": "matrix_symmetry"}, {"score": 0.0022706700510423954, "phrase": "communication_yields"}, {"score": 0.0022478501955483007, "phrase": "best_value"}, {"score": 0.0021697677572213086, "phrase": "data_movement_overheads"}], "paper_keywords": ["distributed symmetric SpMVM", " hybrid MPI/OpenMP parallelism", " topology-aware mapping", " reduced data movement"], "paper_abstract": "Sparse matrix vector multiply (SpMVM) is an important kernel that frequently arises in high performance computing applications. Due to its low arithmetic intensity, several approaches have been proposed in literature to improve its scalability and efficiency in large scale computations. In this paper, our target systems are high end multi-core architectures and we use messaging passing interface + open multiprocessing hybrid programming model for parallelism. We analyze the performance of recently proposed implementation of the distributed symmetric SpMVM, originally developed for large sparse symmetric matrices arising in ab initio nuclear structure calculations. We study important features of this implementation and compare with previously reported implementations that do not exploit underlying symmetry. Our SpMVM implementations leverage the hybrid paradigm to efficiently overlap expensive communications with computations. Our main comparison criterion is the CPU core hours' metric, which is the main measure of resource usage on supercomputers. We analyze the effects of topology-aware mapping heuristic using simplified network load model. We have tested the different SpMVM implementations on two large clusters with 3D Torus and Dragonfly topology. Our results show that the distributed SpMVM implementation that exploits matrix symmetry and hides communication yields the best value for the CPU core hours' metric and significantly reduces data movement overheads. Copyright (c) 2015John Wiley & Sons, Ltd.", "paper_title": "Performance analysis of distributed symmetric sparse matrix vector multiplication algorithm for multi-core architectures", "paper_id": "WOS:000363766600026"}