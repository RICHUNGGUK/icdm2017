{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "random_neural_network"}, {"score": 0.004371660146981191, "phrase": "novel_weight_initialization_method"}, {"score": 0.0038846843242954935, "phrase": "signal-flow_equations"}, {"score": 0.003603327452846714, "phrase": "linear_system"}, {"score": 0.003451766520526601, "phrase": "nonnegativity_constraints"}, {"score": 0.0032016639006812826, "phrase": "formulated_linear_nonnegative_least_squares_problem"}, {"score": 0.003034158379493625, "phrase": "projected_gradient_algorithm"}, {"score": 0.002724909017963099, "phrase": "developed_initialization_method"}, {"score": 0.00266693888510356, "phrase": "better_performance"}, {"score": 0.0025273383208209922, "phrase": "solution_quality"}, {"score": 0.002473560912156024, "phrase": "execution_time"}, {"score": 0.0023694065215394593, "phrase": "random_initialization"}, {"score": 0.0022453451864218477, "phrase": "combinatorial_optimization_emergency_response_problem"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Random neural network (RNN)", " Weight initialization", " Nonnegative least squares (NNLS)", " Projected gradient method", " Combinatorial optimization"], "paper_abstract": "in this paper, we propose a novel weight initialization method for the random neural network. The method relies on approximating the signal-flow equations of the network to obtain a linear system of equations with nonnegativity constraints. For the solution of the formulated linear nonnegative least squares problem we have developed a projected gradient algorithm. It is shown that supervised learning with the developed initialization method has better performance in terms of both solution quality and execution time than learning with random initialization when applied to a combinatorial optimization emergency response problem. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "A novel weight initialization method for the random neural network", "paper_id": "WOS:000272607000020"}