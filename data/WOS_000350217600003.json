{"auto_keywords": [{"score": 0.03961489279775645, "phrase": "high_temporal_resolution"}, {"score": 0.03885478211962643, "phrase": "visual_information"}, {"score": 0.00481495049065317, "phrase": "neuromorphic_event-driven_precise"}, {"score": 0.004548778268252678, "phrase": "spike_timing_precision"}, {"score": 0.0044883089984593455, "phrase": "spike-driven_pattern_recognition_algorithms"}, {"score": 0.004326113419290302, "phrase": "gray_levels"}, {"score": 0.004297256607382827, "phrase": "spike_timings"}, {"score": 0.004197758831410097, "phrase": "almost_every_spike-based_modeling"}, {"score": 0.00400559360117678, "phrase": "incorrect_artificial_and_redundant_spike_timings"}, {"score": 0.003899745240916238, "phrase": "biological_findings"}, {"score": 0.003860774424566198, "phrase": "visual_processing"}, {"score": 0.0037336520904376687, "phrase": "new_concept"}, {"score": 0.003671663469605366, "phrase": "pixel-individual_asynchronous_level-crossing_sampling"}, {"score": 0.003562656752692045, "phrase": "asynchronous_neuromorphic_visual_sensors"}, {"score": 0.0035270425911920595, "phrase": "conventional_cameras"}, {"score": 0.003433796409346569, "phrase": "fixed_points"}, {"score": 0.003376769321692139, "phrase": "entire_array"}, {"score": 0.003343007152920687, "phrase": "fixed_amplitude_changes"}, {"score": 0.0029931118601224612, "phrase": "neuromorphic_event-based_visual_sensors"}, {"score": 0.0028463798740405665, "phrase": "conventional_range"}, {"score": 0.002827365415832384, "phrase": "machine_vision_acquisition_frequencies"}, {"score": 0.0027525658515943985, "phrase": "information_theory"}, {"score": 0.0026797398345997114, "phrase": "temporal_resolution"}, {"score": 0.00265292826903791, "phrase": "high_temporal_acquisition"}, {"score": 0.0026175952455594277, "phrase": "conventional_spikes"}, {"score": 0.002591403838835242, "phrase": "frame-based_acquisition"}, {"score": 0.0025568881277209725, "phrase": "standard_artificial_vision"}, {"score": 0.0024396547357855777, "phrase": "real_data"}, {"score": 0.002391067964886602, "phrase": "information_loss"}, {"score": 0.0023592142778542055, "phrase": "temporal_precision"}, {"score": 0.0023044856709624494, "phrase": "neuromorphic_asynchronous_visual_sensors"}, {"score": 0.0022814200422609774, "phrase": "practical_applications"}, {"score": 0.0022661710658109916, "phrase": "theoretical_investigations"}, {"score": 0.002184101477091303, "phrase": "precise_sequence"}, {"score": 0.00216950156199795, "phrase": "spike_times"}, {"score": 0.0021191645265024855, "phrase": "considerable_advantages"}, {"score": 0.0021049977753042253, "phrase": "neuro-inspired_visual_computations"}], "paper_keywords": [""], "paper_abstract": "This letter introduces a study to precisely measure what an increase in spike timing precision can add to spike-driven pattern recognition algorithms. The concept of generating spikes from images by converting gray levels into spike timings is currently at the basis of almost every spike-based modeling of biological visual systems. The use of images naturally leads to generating incorrect artificial and redundant spike timings and, more important, also contradicts biological findings indicating that visual processing is massively parallel, asynchronous with high temporal resolution. A new concept for acquiring visual information through pixel-individual asynchronous level-crossing sampling has been proposed in a recent generation of asynchronous neuromorphic visual sensors. Unlike conventional cameras, these sensors acquire data not at fixed points in time for the entire array but at fixed amplitude changes of their input, resulting optimally sparse in space and timepixel individually and precisely timed only if new, (previously unknown) information is available (event based). This letter uses the high temporal resolution spiking output of neuromorphic event-based visual sensors to show that lowering time precision degrades performance on several recognition tasks specifically when reaching the conventional range of machine vision acquisition frequencies (30-60Hz). The use of information theory to characterize separability between classes for each temporal resolution shows that high temporal acquisition provides up to 70% more information that conventional spikes generated from frame-based acquisition as used in standard artificial vision, thus drastically increasing the separability between classes of objects. Experiments on real data show that the amount of information loss is correlated with temporal precision. Our information-theoretic study highlights the potentials of neuromorphic asynchronous visual sensors for both practical applications and theoretical investigations. Moreover, it suggests that representing visual information as a precise sequence of spike times as reported in the retina offers considerable advantages for neuro-inspired visual computations.", "paper_title": "What Can Neuromorphic Event-Driven Precise Timing Add to Spike-Based Pattern Recognition?", "paper_id": "WOS:000350217600003"}