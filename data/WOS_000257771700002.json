{"auto_keywords": [{"score": 0.03935512626074735, "phrase": "training_data"}, {"score": 0.010358012194994883, "phrase": "configuration_space"}, {"score": 0.009497823135990019, "phrase": "robot_manipulator"}, {"score": 0.008011926533515438, "phrase": "inverse_kinematic_solution"}, {"score": 0.007526070098813498, "phrase": "function_decomposition"}, {"score": 0.00709409622134086, "phrase": "second_approach"}, {"score": 0.004601606675066839, "phrase": "real-time_implementation"}, {"score": 0.004569630374630379, "phrase": "visual-motor_control"}, {"score": 0.004202741104973709, "phrase": "amtec_robotics"}, {"score": 0.0041589926969138585, "phrase": "primary_objective"}, {"score": 0.004087084193780308, "phrase": "target_point"}, {"score": 0.004044534825749132, "phrase": "task_space"}, {"score": 0.003974597387549594, "phrase": "arbitrary_initial_configuration"}, {"score": 0.0038922607214377557, "phrase": "new_clustering_algorithm"}, {"score": 0.0038651944848734133, "phrase": "kohonen_som_lattice"}, {"score": 0.0035795609511543023, "phrase": "orientation_feedback"}, {"score": 0.0035299344877334385, "phrase": "first_approach"}, {"score": 0.0034931650881768286, "phrase": "inverse_jacobian_matrices"}, {"score": 0.003303412571939195, "phrase": "significant_improvement"}, {"score": 0.0030591665967282886, "phrase": "multiple_solutions"}, {"score": 0.003027286031578399, "phrase": "inverse_kinematic_problem"}, {"score": 0.002964515198409409, "phrase": "position_level"}, {"score": 0.0029131986574478046, "phrase": "redundant_manipulator"}, {"score": 0.002832928222306059, "phrase": "multiple_configurations"}, {"score": 0.0027645030021576926, "phrase": "existing_visual_motor_coordination_schemes"}, {"score": 0.00256895975568914, "phrase": "learning_architecture"}, {"score": 0.00244632460902489, "phrase": "explicit_kinematic_model"}, {"score": 0.002420815160284086, "phrase": "combined_robot_manipulator"}, {"score": 0.0024039564563674673, "phrase": "camera_configuration"}, {"score": 0.0023052356887304204, "phrase": "trained_network"}, {"score": 0.0022338588371647278, "phrase": "joint_angle_vector"}, {"score": 0.002202847728425357, "phrase": "target_position"}, {"score": 0.00217987162651941, "phrase": "single_step"}, {"score": 0.0021049977753042253, "phrase": "current_state"}], "paper_keywords": ["VMC", " visual motor coordination", " 7 DOF robot manipulators", " PowerCube", " function decomposition", " sub-clustering", " redundancy resolution", " KSOM", " inverse kinematics"], "paper_abstract": "This paper deals with real-time implementation of visual-motor control of a 7 degree of freedom (DOF) robot manipulator using self-organized map (SOM) based learning approach. The robot manipulator considered here is a 7 DOF PowerCube manipulator from Amtec Robotics. The primary objective is to reach a target point in the task space using only a single step movement from any arbitrary initial configuration of the robot manipulator. A new clustering algorithm using Kohonen SOM lattice has been proposed that maintains the fidelity of training data. Two different approaches have been proposed to find an inverse kinematic solution without using any orientation feedback. In the first approach, the inverse Jacobian matrices are learnt from the training data using function decomposition. It is shown that function decomposition leads to significant improvement in accuracy of inverse kinematic solution. In the second approach, a concept called sub-clustering in configuration space is suggested to provide multiple solutions for the inverse kinematic problem. Redundancy is resolved at position level using several criteria. A redundant manipulator is dexterous owing to the availability of multiple configurations for a given end-effector position. However, existing visual motor coordination schemes provide only one inverse kinematic solution for every target position even when the manipulator is kinematically redundant. Thus, the second approach provides a learning architecture that can capture redundancy from the training data. The training data are generated using explicit kinematic model of the combined robot manipulator and camera configuration. The training is carried out off-line and the trained network is used on-line to compute the joint angle vector to reach a target position in a single step only. The accuracy attained is better than the current state of art.", "paper_title": "Visual motor control of a 7 DOF robot manipulator using function decomposition and sub-clustering in configuration space", "paper_id": "WOS:000257771700002"}