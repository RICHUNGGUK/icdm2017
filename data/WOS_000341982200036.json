{"auto_keywords": [{"score": 0.05005171419241422, "phrase": "imperfect_channel-state_information"}, {"score": 0.049274416860062835, "phrase": "medard"}, {"score": 0.03594221968333573, "phrase": "mutual_information"}, {"score": 0.02320348270137187, "phrase": "snr"}, {"score": 0.00465964893087681, "phrase": "fading_channels"}, {"score": 0.004494570360108983, "phrase": "gaussian_channel_input_x"}, {"score": 0.0043495571869907376, "phrase": "conditional_entropy"}, {"score": 0.0041136473765874815, "phrase": "gaussian_random_variable"}, {"score": 0.0040334640350288, "phrase": "linear_minimum_mean-square_error"}, {"score": 0.003777261911983744, "phrase": "rate-splitting_approach"}, {"score": 0.0037402558657576124, "phrase": "lower_bound"}, {"score": 0.0036433294654548056, "phrase": "gaussian_input_x"}, {"score": 0.002962543869356265, "phrase": "medard's_lower_bound"}, {"score": 0.0028762499230524812, "phrase": "arbitrary_number_l"}, {"score": 0.0027560092576928595, "phrase": "independent_gaussian_random_variables"}, {"score": 0.0026148807877309417, "phrase": "p._among"}, {"score": 0.0025055391159787134, "phrase": "power_allocations"}, {"score": 0.002480961181275199, "phrase": "total_number"}, {"score": 0.0023384629381463054, "phrase": "analytically_expressible_capacity"}, {"score": 0.0023020630230448135, "phrase": "gaussian"}, {"score": 0.0022113879114507577, "phrase": "gaussian-input_mutual_information"}, {"score": 0.0021896891011033105, "phrase": "signal-to-noise_ratio"}, {"score": 0.0021049977753042253, "phrase": "channel_estimation_error"}], "paper_keywords": ["Channel capacity", " fading channels", " flat fading", " imperfect channel-state information"], "paper_abstract": "As shown by Medard, the capacity of fading channels with imperfect channel-state information can be lower-bounded by assuming a Gaussian channel input X with power P and by upper-bounding the conditional entropy h(X vertical bar Y, (H) over cap) by the entropy of a Gaussian random variable with variance equal to the linear minimum mean-square error in estimating X from (Y, (H) over cap). We demonstrate that, using a rate-splitting approach, this lower bound can be sharpened: by expressing the Gaussian input X as the sum of two independent Gaussian variables X-1 and X-2 and by applying Medard's lower bound first to bound the mutual information between X-1 and Y while treating X-2 as noise, and by applying it a second time to the mutual information between X-2 and Y while assuming X-1 to be known, we obtain a capacity lower bound that is strictly larger than Medard's lower bound. We then generalize this approach to an arbitrary number L of layers, where X is expressed as the sum of L independent Gaussian random variables of respective variances P-l, l = 1,..., L summing up to P. Among all such rate-splitting bounds, we determine the supremum over power allocations P-l and total number of layers L. This supremum is achieved for L -> 8 and gives rise to an analytically expressible capacity lower bound. For Gaussian fading, this novel bound is shown to converge to the Gaussian-input mutual information as the signal-to-noise ratio (SNR) grows, provided that the variance of the channel estimation error H - (H) over cap tends to zero as the SNR tends to infinity.", "paper_title": "A Rate-Splitting Approach to Fading Channels With Imperfect Channel-State Information", "paper_id": "WOS:000341982200036"}