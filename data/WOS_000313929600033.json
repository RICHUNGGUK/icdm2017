{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "sign_language_translation_system"}, {"score": 0.04277739174650543, "phrase": "word_sequence"}, {"score": 0.025601921204736637, "phrase": "new_domain"}, {"score": 0.004703149944841539, "phrase": "new_version"}, {"score": 0.004417487764326481, "phrase": "new_task"}, {"score": 0.004365881789903319, "phrase": "new_semantic_domain"}, {"score": 0.004214637810698362, "phrase": "speech_recognizer"}, {"score": 0.0041328796505374155, "phrase": "spoken_utterance"}, {"score": 0.003776674472150248, "phrase": "sign_language"}, {"score": 0.0034646205853140558, "phrase": "system_adaptability"}, {"score": 0.003397362086358944, "phrase": "new_improvements"}, {"score": 0.0033053807885373905, "phrase": "task_dependent_information"}, {"score": 0.0032667240408191015, "phrase": "parallel_corpus"}, {"score": 0.003203294948113915, "phrase": "spanish_variants"}, {"score": 0.003128798520531889, "phrase": "language_model"}, {"score": 0.0029849474387154827, "phrase": "speech_recogniser"}, {"score": 0.0029616217177058602, "phrase": "data-oriented_language"}, {"score": 0.002892729377519916, "phrase": "machine_translator"}, {"score": 0.0027814417101979317, "phrase": "avatar_animation_module"}, {"score": 0.002748895580860912, "phrase": "new_editor"}, {"score": 0.002727409429089543, "phrase": "rapidly_design"}, {"score": 0.0026954938318408464, "phrase": "required_signs"}, {"score": 0.0025514448896987096, "phrase": "spanish"}, {"score": 0.002531463482341473, "phrase": "spanish_sign_language"}, {"score": 0.0023773911659018803, "phrase": "whole_translation"}, {"score": 0.0022858947785232464, "phrase": "bleu"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Adaptation", " New domain", " Few resources", " Deaf people", " Spanish sign language (LSE)", " Spoken language translation", " Sign animation"], "paper_abstract": "This paper describes a new version of a speech into sign language translation system with new tools and characteristics for increasing its adaptability to a new task or a new semantic domain. This system is made up of a speech recognizer (for decoding the spoken utterance into a word sequence), a natural language translator (for converting a word sequence into a sequence of signs belonging to the sign language), and a 3D avatar animation module (for playing back the signs). In order to increase the system adaptability, this paper presents new improvements in all the three main modules for generating automatically the task dependent information from a parallel corpus: automatic generation of Spanish variants when generating the vocabulary and language model for the speech recogniser, an acoustic adaptation module for the speech recogniser, data-oriented language and translation models for the machine translator and a list of signs to design. The avatar animation module includes a new editor for rapidly design of the required signs. These developments have been necessary to reduce the effort when adapting a Spanish into Spanish sign language (LSE: Lengua de Signos Espanola) translation system to a new domain. The whole translation presents a SER (Sign Error Rate) lower than 10% and a BLEU higher than 90% while the effort for adapting the system to a new domain has been reduced more than 50%. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Increasing adaptability of a speech into sign language translation system", "paper_id": "WOS:000313929600033"}