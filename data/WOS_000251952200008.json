{"auto_keywords": [{"score": 0.036146701610938206, "phrase": "audio_elements"}, {"score": 0.00481495049065317, "phrase": "audio_keywords"}, {"score": 0.00475413908468027, "phrase": "text-like_audio_content_analysis"}, {"score": 0.004634799977448855, "phrase": "classical_text_document_analysis"}, {"score": 0.0044237033788643715, "phrase": "unsupervised_approach"}, {"score": 0.0039620308501590795, "phrase": "content-based_audio_analysis"}, {"score": 0.003829877278269543, "phrase": "proven_text_analysis_theories"}, {"score": 0.0037495207047193034, "phrase": "general_audio_signals"}, {"score": 0.0037021153060910164, "phrase": "complicated_and_strongly_varying_distribution"}, {"score": 0.003624429617337833, "phrase": "feature_space"}, {"score": 0.003548368289666932, "phrase": "iterative_spectral_clustering_method"}, {"score": 0.0035183910023550246, "phrase": "context-dependent_scaling_factors"}, {"score": 0.003459191419478298, "phrase": "audio_data_stream"}, {"score": 0.00337224813954299, "phrase": "clustering_method"}, {"score": 0.0033437537557378157, "phrase": "temporal_signal_segments"}, {"score": 0.003315499339103866, "phrase": "similar_low-level_features"}, {"score": 0.003259702394241964, "phrase": "natural_clusters"}, {"score": 0.003032820755030689, "phrase": "semantic_content"}, {"score": 0.0027159094186967247, "phrase": "heuristic_importance_indicators"}, {"score": 0.0026252106881752067, "phrase": "key_audio_elements"}, {"score": 0.0025591748412278174, "phrase": "multiple_audio_documents"}, {"score": 0.002505412457777352, "phrase": "audio_element_importance"}, {"score": 0.0024736973328071026, "phrase": "expected_term_frequency"}, {"score": 0.002421726275597666, "phrase": "expected_inverse_document_frequency"}, {"score": 0.0023708445073819277, "phrase": "expected_term_duration"}, {"score": 0.0023111922860677672, "phrase": "inverse_document_duration"}, {"score": 0.002215081186105616, "phrase": "encouraging_results"}, {"score": 0.0021049977753042253, "phrase": "content-based_audio_document_analysis"}], "paper_keywords": ["audio content mining", " audio element", " audio keywords", " content-based audio analysis", " key audio element", " knowledge discovery"], "paper_abstract": "Inspired by classical text document analysis employing the concept of (key) words, this paper presents an unsupervised approach to discover (key) audio elements in general audio documents. The (key) audio elements can be considered the equivalents of the text (key) words, and enable content-based audio analysis and retrieval following the analogy to the proven text analysis theories and methods. Since general audio signals usually show complicated and strongly varying distribution and density in the feature space, we propose an iterative spectral clustering method with context-dependent scaling factors to decompose an audio data stream into audio elements. Using this clustering method, temporal signal segments with similar low-level features are grouped into natural clusters that we adopt as audio elements. To detect those audio elements that are most representative for the semantic content, that is, the key audio elements, two cases are considered. First, if only one audio document is available for analysis, a number of heuristic importance indicators are defined and employed to detect the key audio elements. For the case that multiple audio documents are available, more sophisticated measures for audio element importance, including expected term frequency (ETF), expected inverse document frequency (EIDF), expected term duration (ETD) and expected inverse document duration (EIDD), are proposed. Our experiments showed encouraging results regarding the quality of the obtained (key) audio elements and their potential applicability for content-based audio document analysis and retrieval.", "paper_title": "Audio keywords discovery for text-like audio content analysis and retrieval", "paper_id": "WOS:000251952200008"}