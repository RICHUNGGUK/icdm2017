{"auto_keywords": [{"score": 0.03405024562525929, "phrase": "video_shot"}, {"score": 0.03211942512231789, "phrase": "audio_features"}, {"score": 0.00481495049065317, "phrase": "tennis_broadcast"}, {"score": 0.004511485198940203, "phrase": "sport_video_structure_analysis"}, {"score": 0.0043560464825349275, "phrase": "statistical_model"}, {"score": 0.004020492138367616, "phrase": "stochastic_modelling"}, {"score": 0.00392100783796804, "phrase": "global_framework"}, {"score": 0.0038819041309353024, "phrase": "hidden_markov_models"}, {"score": 0.003673675864705682, "phrase": "audio_and_visual_cues"}, {"score": 0.0035292625231068517, "phrase": "particular_domain"}, {"score": 0.0034940519373446335, "phrase": "tennis_videos"}, {"score": 0.003407549468745519, "phrase": "prior_information"}, {"score": 0.0033735490732324713, "phrase": "tennis_content"}, {"score": 0.00327356326590461, "phrase": "basic_temporal_unit"}, {"score": 0.0031925019616678217, "phrase": "visual_features"}, {"score": 0.003066945490483524, "phrase": "shot_view"}, {"score": 0.0029909851863915283, "phrase": "audio_events"}, {"score": 0.0027741761880779535, "phrase": "first_one"}, {"score": 0.0027054473441439422, "phrase": "manual_segmentation"}, {"score": 0.0025730425700096365, "phrase": "second_one"}, {"score": 0.002509284173541882, "phrase": "automatic_segmentation"}, {"score": 0.0024842242921857705, "phrase": "classification_process"}, {"score": 0.002398464540102246, "phrase": "overall_hmm_process"}, {"score": 0.0023745087648471613, "phrase": "typical_tennis_scenes"}, {"score": 0.002224510044064184, "phrase": "hmm-based_fusion"}, {"score": 0.0021049977753042253, "phrase": "similar_quality"}], "paper_keywords": ["video structure analysis", " macro-segmentation", " cross-modality", " hidden Markov models"], "paper_abstract": "This paper focuses on the integration of multimodal features for sport video structure analysis. The method relies on a statistical model which takes into account both the shot content and the interleaving of shots. This stochastic modelling is performed in the global framework of Hidden Markov Models (HMMs) that can be efficiently applied to merge audio and visual cues. Our approach is validated in the particular domain of tennis videos. The model integrates prior information about tennis content and editing rules. The basic temporal unit is the video shot. Visual features are used to characterize the type of shot view. Audio features describe the audio events within a video shot. Two sets of audio features are used in this study: the first one is extracted from a manual segmentation of the soundtrack and is more reliable. The second one is provided by an automatic segmentation and classification process. As a result of the overall HMM process, typical tennis scenes are simultaneously segmented and identified. The experiments illustrate the improvement of HMM-based fusion over indexing using only the best single media, when both media are of similar quality.", "paper_title": "Audiovisual integration for tennis broadcast structuring", "paper_id": "WOS:000240913200005"}