{"auto_keywords": [{"score": 0.03232309960947834, "phrase": "proposed_algorithm"}, {"score": 0.009686378890915778, "phrase": "decision_trees"}, {"score": 0.00481495049065317, "phrase": "multi-objective_evolutionary_induction"}, {"score": 0.004610058444728656, "phrase": "evolutionary_algorithms"}, {"score": 0.004435230698216773, "phrase": "classification_rules"}, {"score": 0.004246428036409373, "phrase": "relevant_approach"}, {"score": 0.004165105357908494, "phrase": "decision_tree_induction_algorithms"}, {"score": 0.003987755561492638, "phrase": "classification_problems"}, {"score": 0.003855034057431947, "phrase": "induction_algorithms"}, {"score": 0.0036553070575015344, "phrase": "recursive_top-down_data"}, {"score": 0.0035852640843794252, "phrase": "greedy_split_evaluation"}, {"score": 0.0035336109352157763, "phrase": "main_problem"}, {"score": 0.0034491650585057754, "phrase": "quality_loss"}, {"score": 0.003399466007862412, "phrase": "partitioning_process"}, {"score": 0.0033021988455635403, "phrase": "statistically_insignificant_rules"}, {"score": 0.0031614748814351823, "phrase": "new_ga-based_algorithm"}, {"score": 0.0029830992938695007, "phrase": "greedy_strategy"}, {"score": 0.002897710777957041, "phrase": "local_optima"}, {"score": 0.002760778494680823, "phrase": "lexicographic_multi-objective_approach"}, {"score": 0.0025059724686541263, "phrase": "decision_tree_induction_algorithm"}, {"score": 0.0024818194799172263, "phrase": "different_public_datasets"}, {"score": 0.0024224481033945943, "phrase": "experimental_results"}, {"score": 0.002319127685733821, "phrase": "previously_described_problems"}, {"score": 0.002285674008055581, "phrase": "accuracy_gains"}, {"score": 0.0021566056345478373, "phrase": "significantly_reduction"}, {"score": 0.0021049977753042253, "phrase": "tree_sizes"}], "paper_keywords": ["lexicographic multi-objective genetic algorithms", " decision tree induction", " classification tasks", " data mining"], "paper_abstract": "Among the several tasks that evolutionary algorithms have successfully employed, the induction of classification rules and decision trees has been shown to be a relevant approach for several application domains. Decision tree induction algorithms represent one of the most popular techniques for dealing with classification problems. However, conventionally used decision trees induction algorithms present limitations due to the strategy they usually implement: recursive top-down data partitioning through a greedy split evaluation. The main problem with this strategy is quality loss during the partitioning process, which can lead to statistically insignificant rules. In this paper, we propose a new GA-based algorithm for decision tree induction. The proposed algorithm aims to prevent the greedy strategy and to avoid converging to local optima. For such, it is based on a lexicographic multi-objective approach. In order to evaluate the proposed algorithm, it is compared with a well-known and frequently used decision tree induction algorithm using different public datasets. According to the experimental results, the proposed algorithm is able to avoid the previously described problems, reporting accuracy gains. Even more important, the proposed algorithm induced models with a significantly reduction in the complexity considering tree sizes.", "paper_title": "Lexicographic multi-objective evolutionary induction of decision trees", "paper_id": "WOS:000208449600010"}