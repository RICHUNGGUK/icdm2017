{"auto_keywords": [{"score": 0.03079144726629598, "phrase": "opponent_actions"}, {"score": 0.00481495049065317, "phrase": "competitive_domains"}, {"score": 0.004618342952383313, "phrase": "clear_advantage"}, {"score": 0.0039684322717435045, "phrase": "machine_learning_method"}, {"score": 0.0036924762294207633, "phrase": "robocup_domain"}, {"score": 0.0035957006001349915, "phrase": "direct_access"}, {"score": 0.0035550029054401016, "phrase": "opponent_inputs"}, {"score": 0.0034226302212225206, "phrase": "opponent_behavior"}, {"score": 0.0030658872249549893, "phrase": "low-level_behavior"}, {"score": 0.003042697264766327, "phrase": "individual_opponent_agents"}, {"score": 0.002735816302446788, "phrase": "previous_classifier"}, {"score": 0.0026741832921475667, "phrase": "machine_learning_techniques"}, {"score": 0.002279841453843241, "phrase": "ombo"}, {"score": 0.002254003531073337, "phrase": "striker_agent"}, {"score": 0.0022284577808744316, "phrase": "goalie_actions"}, {"score": 0.002169968849836984, "phrase": "striker-goalie_scenario"}, {"score": 0.0021049977753042253, "phrase": "acquired_opponent's_model"}], "paper_keywords": ["Opponent modeling", " learning about agents", " hybrid learning"], "paper_abstract": "In competitive domains, some knowledge about the opponent can give players a clear advantage. This idea led many people to propose approaches that automatically acquire models of opponents, based only on the observation of their input-output behavior. If opponent outputs could be accessed directly, a model can be constructed by feeding a machine learning method with traces of the behavior of the opponent. However, that is not the case in the RoboCup domain where an agent does not have direct access to the opponent inputs and outputs. Rather, the agent sees the opponent behavior from its own point of view and inputs and outputs (actions) have to be inferred from observation. In this paper, we present an approach to model low-level behavior of individual opponent agents. First, we build a classifier to infer and label opponent actions based on observation. Second, our agent observes an opponent and labels its actions using the previous classifier. From these observations, machine learning techniques generate a model that predicts the opponent actions. Finally, the agent uses the model to anticipate opponent actions. In order to test our ideas, we have created an architecture called OMBO (Opponent Modeling Based on Observation). Using OMBO, a striker agent can anticipate goalie actions. Results show that in this striker-goalie scenario, scores are significantly higher using the acquired opponent's model of actions.", "paper_title": "OMBO: An opponent modeling approach", "paper_id": "WOS:000265525800002"}