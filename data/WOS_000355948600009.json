{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "generalized_zipf_law"}, {"score": 0.04838919478929022, "phrase": "zipf's_law"}, {"score": 0.034599608456397014, "phrase": "statistical_regularities"}, {"score": 0.02246846748295755, "phrase": "inter-textual_relationship"}, {"score": 0.004568671314041992, "phrase": "long_time"}, {"score": 0.0044687642978081185, "phrase": "statistical_regularity"}, {"score": 0.0043952640674674425, "phrase": "george_k._zipf"}, {"score": 0.0042050950311143115, "phrase": "rank_x"}, {"score": 0.004158847144705244, "phrase": "constant_various_explanations"}, {"score": 0.003967878573196525, "phrase": "mandelbrot_process"}, {"score": 0.0038810583785936505, "phrase": "first_approach"}, {"score": 0.003859650639671721, "phrase": "mandelbrot_studies"}, {"score": 0.00372333905856154, "phrase": "information_theory"}, {"score": 0.0036823699601344962, "phrase": "entropy_concept"}, {"score": 0.00356213805517703, "phrase": "fractal_theory"}, {"score": 0.0033797211728461584, "phrase": "simple_geometric_pattern"}, {"score": 0.002967494450025507, "phrase": "step_i."}, {"score": 0.0024514184802832016, "phrase": "linear_relationship"}, {"score": 0.0024311346712789553, "phrase": "entropy_h-i"}], "paper_keywords": ["Zipf's law", " Signal theory", " Entropy", " Text"], "paper_abstract": "Zipf's law has intrigued people for a long time. This distribution models a certain type of statistical regularity observed in a text. George K. Zipf showed that, if a word is characterised by its frequency, then, rank and frequency are not independent and approximately verify the relationship: Rank x frequency approximate to constant Various explanations have been advanced to explain this law. In this article, we talk about the Mandelbrot process, which includes two very different approaches. In the first approach, Mandelbrot studies language generation as the transmission of a signal and bases it on information theory, using the entropy concept. In the second, geometric approach, he draws a parallel with the fractal theory, where each word of the text is a sequence of characters framed by two separators, meaning a simple geometric pattern. This leads us to hypothesise that, since the statistical regularities observed have several possible explanations, Zipf's law carries other patterns. To verify this hypothesis, we chose a text, which we modified and degraded in several successive stages. We called T-i the text degraded at step i. We then segmented T (i) into words. We found that rank and frequency were not independent and approximately verified the relationship: Rank beta(i) x frequency approximate to constant beta(i) > 1 The coefficient beta (i) increases with each step i. We call Eq. (1) the generalized Zipf law. We found statistical regularities in the deconstruction of the text. We notably observed a linear relationship between the entropy H-i and the amount of effort E (i) of the various degraded texts T (i) . To verify our assumptions, we degraded a text of approximately 200 pages. At each step, we calculated various parameters such as entropy, the amount of effort, and the coefficient. We observed an inter-textual relationship between entropy and the amount of effort. This paper therefore provides a proof of this relationship. coefficient. We observed an inter-textual relationship between entropy and the amount of effort. This paper therefore provides a proof of this relationship.", "paper_title": "The deconstruction of a text: the permanence of the generalized Zipf law-the inter-textual relationship between entropy and effort amount", "paper_id": "WOS:000355948600009"}