{"auto_keywords": [{"score": 0.036239981319313816, "phrase": "euclidean"}, {"score": 0.00481495049065317, "phrase": "heterogeneous_data"}, {"score": 0.00477513738640734, "phrase": "generalized_coupled_tensor_factorization"}, {"score": 0.004657653216262924, "phrase": "missing_link_prediction"}, {"score": 0.004486800020569973, "phrase": "missing_connections"}, {"score": 0.004250969091124481, "phrase": "missing_entries"}, {"score": 0.004198323646273642, "phrase": "relational_dataset"}, {"score": 0.004112020122418323, "phrase": "multiway_arrays"}, {"score": 0.0038796562792487, "phrase": "link_prediction_problem"}, {"score": 0.003847546889061499, "phrase": "data_fusion"}, {"score": 0.003799878496075633, "phrase": "simultaneous_factorization"}, {"score": 0.003737234606207431, "phrase": "latent_factors"}, {"score": 0.003630073540438812, "phrase": "previous_studies"}, {"score": 0.003600022318864217, "phrase": "joint_factorization"}, {"score": 0.0034967818541774844, "phrase": "single_loss_function"}, {"score": 0.0033964919992320024, "phrase": "kullback-leibler-divergence"}, {"score": 0.003354393040689453, "phrase": "specific_tensor_factorization_models"}, {"score": 0.0030995835539697893, "phrase": "loss_functions"}, {"score": 0.002960979624379786, "phrase": "generalized_coupled_tensor_factorization_framework"}, {"score": 0.0027818804382539444, "phrase": "multiple_sources"}, {"score": 0.0027588314610845705, "phrase": "coupled_factorization"}, {"score": 0.0027133032795773697, "phrase": "link_prediction_performance"}, {"score": 0.002624482632439123, "phrase": "suitable_loss_function"}, {"score": 0.002591927716261631, "phrase": "tensor_factorization_model"}, {"score": 0.002549146857303602, "phrase": "accurate_missing_link_prediction_and_loss_functions"}, {"score": 0.0024759682272230735, "phrase": "link_prediction"}, {"score": 0.002424984362388813, "phrase": "commonly-used_loss_functions"}, {"score": 0.002316476356455289, "phrase": "difficult_cases"}, {"score": 0.002268769196700254, "phrase": "cold_start_problem"}, {"score": 0.0022220423638260015, "phrase": "new_entity"}, {"score": 0.0021049977753042253, "phrase": "large-scale_data"}], "paper_keywords": ["Coupled tensor factorization", " Link prediction", " Heterogeneous data", " Missing data", " Data fusion"], "paper_abstract": "This study deals with missing link prediction, the problem of predicting the existence of missing connections between entities of interest. We approach the problem as filling in missing entries in a relational dataset represented by several matrices and multiway arrays, that will be simply called tensors. Consequently, we address the link prediction problem by data fusion formulated as simultaneous factorization of several observation tensors where latent factors are shared among each observation. Previous studies on joint factorization of such heterogeneous datasets have focused on a single loss function (mainly squared Euclidean distance or Kullback-Leibler-divergence) and specific tensor factorization models (CANDECOMP/PARAFAC and/or Tucker). However, in this paper, we study various alternative tensor models as well as loss functions including the ones already studied in the literature using the generalized coupled tensor factorization framework. Through extensive experiments on two real-world datasets, we demonstrate that (i) joint analysis of data from multiple sources via coupled factorization significantly improves the link prediction performance, (ii) selection of a suitable loss function and a tensor factorization model is crucial for accurate missing link prediction and loss functions that have not been studied for link prediction before may outperform the commonly-used loss functions, (iii) joint factorization of datasets can handle difficult cases, such as the cold start problem that arises when a new entity enters the dataset, and (iv) our approach is scalable to large-scale data.", "paper_title": "Link prediction in heterogeneous data via generalized coupled tensor factorization", "paper_id": "WOS:000347948900007"}