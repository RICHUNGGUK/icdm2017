{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "value_prediction"}, {"score": 0.0495648351427175, "phrase": "speculative_execution"}, {"score": 0.039248806804460544, "phrase": "software_value_prediction_techniques"}, {"score": 0.03764439525398964, "phrase": "software_speculation_techniques"}, {"score": 0.004712065638657606, "phrase": "gpu._gpus"}, {"score": 0.004611369021812453, "phrase": "fundamentally_different_architectures"}, {"score": 0.004512814529823301, "phrase": "conventional_wisdom"}, {"score": 0.004161553532799662, "phrase": "image_processing"}, {"score": 0.003635600104609725, "phrase": "limited_parallelism"}, {"score": 0.0034629341517018438, "phrase": "runtime_parallelism"}, {"score": 0.003193129886123359, "phrase": "relatively_high_overhead"}, {"score": 0.0030086877092638945, "phrase": "immediate_performance_gain"}, {"score": 0.0027295084882654917, "phrase": "existing_gpus"}, {"score": 0.002656650588033728, "phrase": "performance_gain"}, {"score": 0.0025031188149336257, "phrase": "hardware_implementation"}, {"score": 0.0024761702541879213, "phrase": "speculative_execution_operations"}, {"score": 0.0024495111090152857, "phrase": "gpu_architectures"}, {"score": 0.0023970487263732737, "phrase": "software_performance_overheads"}, {"score": 0.0023079225317714815, "phrase": "hardware_extensions"}, {"score": 0.002270745003370529, "phrase": "almost_tenfold_reduction"}, {"score": 0.002222102813520549, "phrase": "divergent_sequential_operations"}], "paper_keywords": ["Value prediction", " Speculative execution", " GPU"], "paper_abstract": "GPUs and CPUs have fundamentally different architectures. It is conventional wisdom that GPUs can accelerate only those applications that exhibit very high parallelism, especially vector parallelism such as image processing. In this paper, we explore the possibility of using GPUs for value prediction and speculative execution: we implement software value prediction techniques to accelerate programs with limited parallelism, and software speculation techniques to accelerate programs that contain runtime parallelism, which are hard to parallelize statically. Our experiment results show that due to the relatively high overhead, mapping software value prediction techniques on existing GPUs may not bring any immediate performance gain. On the other hand, although software speculation techniques introduce some overhead as well, mapping these techniques to existing GPUs can already bring some performance gain over CPU. Based on these observations, we explore the hardware implementation of speculative execution operations on GPU architectures to reduce the software performance overheads. The results indicate that the hardware extensions result in almost tenfold reduction of the control divergent sequential operations with only moderate hardware (5-8%) and power consumption (1-5%) overheads.", "paper_title": "Value Prediction and Speculative Execution on GPU", "paper_id": "WOS:000291043700001"}