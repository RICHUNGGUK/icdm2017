{"auto_keywords": [{"score": 0.0269975468480172, "phrase": "euclidean"}, {"score": 0.00481495049065317, "phrase": "vector_quantization"}, {"score": 0.004733625412289433, "phrase": "training_data_selection"}, {"score": 0.004130376386308024, "phrase": "training_data_points"}, {"score": 0.00402610372759447, "phrase": "lvq_prototypes"}, {"score": 0.0039244530915794025, "phrase": "main_goal"}, {"score": 0.003512702405367876, "phrase": "misclassification_errors"}, {"score": 0.002838033152426417, "phrase": "class_prototype"}, {"score": 0.0027194778713860715, "phrase": "proposed_methodology"}, {"score": 0.0026507289852980512, "phrase": "weighted_norm"}, {"score": 0.002413153346716919, "phrase": "different_levels"}, {"score": 0.0023123057299992587, "phrase": "input_attributes"}, {"score": 0.002159623311924437, "phrase": "controlled_experiment"}, {"score": 0.0021049977753042253, "phrase": "web_available_data_sets"}], "paper_keywords": ["learning vector quantization LVQ", " pattern classification", " clustering", " data selection", " neural networks"], "paper_abstract": "In this paper, we propose a method that selects a subset of the training data points to update LVQ prototypes. The main goal is to conduct the prototypes to converge at a more convenient location, diminishing misclassification errors. The method selects an update set composed by a subset of points considered to be at the risk of being captured by another class prototype. We associate the proposed methodology to a weighted norm, instead of the Euclidean, in order to establish different levels of relevance for the input attributes. The technique was implemented on a controlled experiment and on Web available data sets.", "paper_title": "Learning vector quantization with training data selection", "paper_id": "WOS:000233172000015"}