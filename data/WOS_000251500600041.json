{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "recurrent_neural_networks"}, {"score": 0.004725385523804256, "phrase": "distributed_delays"}, {"score": 0.004424768776701965, "phrase": "delay-dependent_state_estimation_problem"}, {"score": 0.004143196873246147, "phrase": "time-varying_and_distributed_time-varying_delays"}, {"score": 0.003771631577951067, "phrase": "delay-dependent_criterion"}, {"score": 0.0035648266669315943, "phrase": "neuron_states"}, {"score": 0.0033377940531761985, "phrase": "estimation_error"}, {"score": 0.003038237581227068, "phrase": "time-varying_delay"}, {"score": 0.0028986672783671147, "phrase": "activation_functions"}, {"score": 0.0025171669791790438, "phrase": "recently_commonly_used_lipschitz_conditions"}, {"score": 0.0022273034991008326, "phrase": "obtained_condition"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["state estimator", " recurrent neural networks", " exponential stability", " distributed delay", " linear matrix inequality"], "paper_abstract": "In this paper, the delay-dependent state estimation problem for recurrent neural networks with both time-varying and distributed time-varying delays is investigated. Through available output measurements, a delay-dependent criterion is established to estimate the neuron states such that the dynamics of the estimation error is globally exponentially stable. The derivative of a time-varying delay satisfies tau(t)<=mu and the activation functions are assumed to be neither monotonic nor differentiable, and more general than the recently commonly used Lipschitz conditions. Finally, two illustrative examples are given to demonstrate the usefulness of the obtained condition. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Exponential state estimation for recurrent neural networks with distributed delays", "paper_id": "WOS:000251500600041"}