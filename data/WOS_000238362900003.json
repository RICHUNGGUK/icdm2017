{"auto_keywords": [{"score": 0.0044524122425287005, "phrase": "scalable_point-to-point_interconnects"}, {"score": 0.004153041453795458, "phrase": "user-level_access"}, {"score": 0.003773870856027139, "phrase": "latency_hiding_techniques"}, {"score": 0.0037087324991876727, "phrase": "improved_throughput"}, {"score": 0.0031431690368229443, "phrase": "overall_performance_improvement"}, {"score": 0.0029830992938695007, "phrase": "data_movement"}, {"score": 0.002931569771634119, "phrase": "protection_domains"}, {"score": 0.002855934865505357, "phrase": "dominant_contributor"}, {"score": 0.0028065957753430713, "phrase": "improved_scalability"}, {"score": 0.0027341763737751467, "phrase": "system_call"}, {"score": 0.0025723630851105304, "phrase": "small_additional_benefit"}, {"score": 0.0024412911465483225, "phrase": "additional_hardware_support"}], "paper_keywords": ["architecture", " user-level", " input/output devices", " performance analysis", " simulation"], "paper_abstract": "To address the growing I/O bottleneck, next-generation distributed I/O architectures employ scalable point-to-point interconnects and minimize operating system overhead by providing user-level access to the I/O subsystem. Reduced I/O overhead allows I/O intensive applications to efficiently employ latency hiding techniques for improved throughput. This paper presents the design of a novel scalable user-level I/O architecture and evaluates the impact of various architectural mechanisms in terms of overall performance improvement. Results demonstrate that eliminating data movement across protection domains is the dominant contributor to improved scalability. Eliminating system call and interrupt overhead only has a small additional benefit that may not justify the additional hardware support required. While this evaluation is based on one specific design, the conclusions can be generalized to other user-level I/O architectures.", "paper_title": "Design trade-offs for user-level I/O architectures", "paper_id": "WOS:000238362900003"}