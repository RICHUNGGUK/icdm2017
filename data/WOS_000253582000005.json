{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "relevance_vector_machines"}, {"score": 0.004752221133109136, "phrase": "large_scale_datasets"}, {"score": 0.004392565073466714, "phrase": "automated_learning"}, {"score": 0.004195418010131832, "phrase": "large_scale_text_sets"}, {"score": 0.00406001734835979, "phrase": "bayesian_inference_learning"}, {"score": 0.003954837422946628, "phrase": "state-of-the-art_performance"}, {"score": 0.003584025547693836, "phrase": "large_scale_sets"}, {"score": 0.0034911335714333507, "phrase": "limited_success"}, {"score": 0.003334309053314909, "phrase": "computational_constraints"}, {"score": 0.0032266093099550955, "phrase": "diversified_set"}, {"score": 0.0031845067058084613, "phrase": "divide-and-conquer_approaches"}, {"score": 0.003021502415143067, "phrase": "smaller_working_sets"}, {"score": 0.0028857130140890787, "phrase": "training_examples"}, {"score": 0.002530359917257626, "phrase": "classification_performance"}, {"score": 0.0024325244760735566, "phrase": "large_training"}, {"score": 0.002233301265743633, "phrase": "performance_gains"}, {"score": 0.0021896891011033105, "phrase": "sparse_solutions"}, {"score": 0.0021049977753042253, "phrase": "distributed_environments"}], "paper_keywords": ["large scale learning", " text classification", " relevance vector machines"], "paper_abstract": "In this paper we develop and analyze methods for expanding automated learning of Relevance Vector Machines (RVM) to large scale text sets. RVM rely on Bayesian inference learning and while maintaining state-of-the-art performance, offer sparse and probabilistic solutions. However, efforts towards applying RVM to large scale sets have met with limited success in the past, due to computational constraints. We propose a diversified set of divide-and-conquer approaches where decomposition techniques promote the definition of smaller working sets that permit the use of all training examples. The rationale is that by exploring incremental, ensemble and boosting strategies, it is possible to improve classification performance, taking advantage of the large training set available. Results on Reuters-21578 and RCV1 are presented, showing performance gains and maintaining sparse solutions that can be deployed in distributed environments.", "paper_title": "Towards expanding relevance vector machines to large scale datasets", "paper_id": "WOS:000253582000005"}