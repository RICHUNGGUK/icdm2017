{"auto_keywords": [{"score": 0.04957786067961377, "phrase": "miniature_rotorcraft"}, {"score": 0.0340713317788495, "phrase": "imu_measurements"}, {"score": 0.00481495049065317, "phrase": "velocity_estimation"}, {"score": 0.00471465954562773, "phrase": "successful_operation"}, {"score": 0.004520272777451894, "phrase": "automated_guidance"}, {"score": 0.004243552607799184, "phrase": "accurate_estimates"}, {"score": 0.004177049813981273, "phrase": "vehicle's_body_velocities"}, {"score": 0.004134287445161739, "phrase": "euler"}, {"score": 0.004047141845635495, "phrase": "larger_rotorcraft"}, {"score": 0.00392125815948488, "phrase": "traditional_approach"}, {"score": 0.003819339842998955, "phrase": "highly_accurate_imu"}, {"score": 0.0037793152987497286, "phrase": "gps_measurements"}, {"score": 0.0036810726176482278, "phrase": "small_scale"}, {"score": 0.0035665344993417603, "phrase": "lower_quality_mems_imus"}, {"score": 0.0034738037330064885, "phrase": "limited_payload"}, {"score": 0.0034193226278107346, "phrase": "indoor_applications"}, {"score": 0.003278167066287366, "phrase": "state_estimates"}, {"score": 0.003028969851366049, "phrase": "novel_framework"}, {"score": 0.0029972030224205506, "phrase": "state_estimation"}, {"score": 0.0029346624184926305, "phrase": "dynamic_flight_model"}, {"score": 0.002798662730881037, "phrase": "onboard_monocular_camera"}, {"score": 0.002769304577201566, "phrase": "computer_vision"}, {"score": 0.002697245874076643, "phrase": "existing_approaches"}, {"score": 0.0025858215477025117, "phrase": "single_vision_algorithm"}, {"score": 0.0025318431634446426, "phrase": "vehicle's_state"}, {"score": 0.0024272350606639147, "phrase": "multiple_vision_algorithms"}, {"score": 0.002219040041886641, "phrase": "laboratory_environment"}, {"score": 0.0021957487795963666, "phrase": "different_motion_types"}], "paper_keywords": ["Visual motion estimation", " Rotorcraft state", " estimation", " Sensor fusion"], "paper_abstract": "Successful operation of a miniature rotorcraft relies on capabilities including automated guidance, trajectory following, and teleoperation; all of which require accurate estimates of the vehicle's body velocities and Euler angles. For larger rotorcraft that operate outdoors, the traditional approach is to combine a highly accurate IMU with GPS measurements. However, for small scale rotorcraft that operate indoors, lower quality MEMS IMUs are used because of limited payload. In indoor applications GPS is usually not available, and state estimates based on IMU measurements drift over time. In this paper, we propose a novel framework for state estimation that combines a dynamic flight model, IMU measurements, and 3D velocity estimates computed from an onboard monocular camera using computer vision. Our work differs from existing approaches in that, rather than using a single vision algorithm to update the vehicle's state, we capitalize on the strengths of multiple vision algorithms by integrating them into a meta-algorithm for 3D motion estimation. Experiments are conducted on two real helicopter platforms in a laboratory environment for different motion types to demonstrate and evaluate the effectiveness of our approach.", "paper_title": "A vision based ensemble approach to velocity estimation for miniature rotorcraft", "paper_id": "WOS:000357652400001"}