{"auto_keywords": [{"score": 0.040004239383294164, "phrase": "many-core_architecture"}, {"score": 0.015117640524627047, "phrase": "parallel_architectures"}, {"score": 0.014701545075464102, "phrase": "design_space"}, {"score": 0.013519795437358633, "phrase": "area_efficiency"}, {"score": 0.00481495049065317, "phrase": "algorithm-oriented_design"}, {"score": 0.004787874367741664, "phrase": "efficient_many-core_architectures"}, {"score": 0.004747544039399003, "phrase": "dense_matrix_multiplication"}, {"score": 0.004720845168057651, "phrase": "recent_integrated_circuit_technologies"}, {"score": 0.004538091274791439, "phrase": "single_chip"}, {"score": 0.004181631210603936, "phrase": "extra_metrics"}, {"score": 0.00399704519135802, "phrase": "best_performance"}, {"score": 0.003974550062454033, "phrase": "chip_area"}, {"score": 0.003941043585193222, "phrase": "best_sustainable_performance"}, {"score": 0.003853062158993238, "phrase": "algorithm-oriented_approach"}, {"score": 0.0037458319094677353, "phrase": "design_space_exploration"}, {"score": 0.0036725447588682823, "phrase": "experimental_execution_results"}, {"score": 0.003641574955457217, "phrase": "particular_benchmark"}, {"score": 0.003550218173441985, "phrase": "formal_analysis"}, {"score": 0.003490586026139388, "phrase": "main_architectural_aspects"}, {"score": 0.003431952055664272, "phrase": "particular_architectural_aspect"}, {"score": 0.0032526761451728537, "phrase": "architectural_aspects"}, {"score": 0.0030395056129324575, "phrase": "external_memory"}, {"score": 0.0030138579483664917, "phrase": "memory_hierarchy"}, {"score": 0.002938202365941281, "phrase": "theoretical_analysis"}, {"score": 0.0029134070107177915, "phrase": "dense_matrix_multiplication_algorithm"}, {"score": 0.0028322528979854923, "phrase": "execution_cycles"}, {"score": 0.002808349127118576, "phrase": "architectural_parameters"}, {"score": 0.0024940728986998463, "phrase": "memory_bandwidth"}, {"score": 0.0024383151463193793, "phrase": "performance_efficiency"}, {"score": 0.0023043010697170246, "phrase": "peak_performance"}, {"score": 0.002246417055582878, "phrase": "previous_many-core_architectures"}, {"score": 0.0021776365628787065, "phrase": "lower_memory_bandwidth"}, {"score": 0.0021049977753042253, "phrase": "previous_state-of-the-art_many-cores_architectures"}], "paper_keywords": ["Matrix multiplication", " Many-core", " High-performance", " Algorithm-oriented design", " Application-specific integrated circuit"], "paper_abstract": "Recent integrated circuit technologies have opened the possibility to design parallel architectures with hundreds of cores on a single chip. The design space of these parallel architectures is huge with many architectural options. Exploring the design space gets even more difficult if, beyond performance and area, we also consider extra metrics like performance and area efficiency, where the designer tries to design the architecture with the best performance per chip area and the best sustainable performance. In this paper we present an algorithm-oriented approach to design a many-core architecture. Instead of doing the design space exploration of the many core architecture based on the experimental execution results of a particular benchmark of algorithms, our approach is to make a formal analysis of the algorithms considering the main architectural aspects and to determine how each particular architectural aspect is related to the performance of the architecture when running an algorithm or set of algorithms. The architectural aspects considered include the number of cores, the local memory available in each core, the communication bandwidth between the many-core architecture and the external memory and the memory hierarchy. To exemplify the approach we did a theoretical analysis of a dense matrix multiplication algorithm and determined an equation that relates the number of execution cycles with the architectural parameters. Based on this equation a many-core architecture has been designed. The results obtained indicate that a 100 mm(2) integrated circuit design of the proposed architecture, using a 65 nm technology, is able to achieve 464 GFLOPs (double precision floating-point) for a memory bandwidth of 16 GB/s. This corresponds to a performance efficiency of 71 %. Considering a 45 nm technology, a 100 mm(2) chip attains 833 GFLOPs which corresponds to 84 % of peak performance These figures are better than those obtained by previous many-core architectures, except for the area efficiency which is limited by the lower memory bandwidth considered. The results achieved are also better than those of previous state-of-the-art many-cores architectures designed specifically to achieve high performance for matrix multiplication.", "paper_title": "Algorithm-oriented design of efficient many-core architectures applied to dense matrix multiplication", "paper_id": "WOS:000347527800015"}