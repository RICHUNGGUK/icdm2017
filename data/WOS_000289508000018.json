{"auto_keywords": [{"score": 0.0338877499416512, "phrase": "lr-fir"}, {"score": 0.03108178984361603, "phrase": "proposed_algorithm"}, {"score": 0.00481495049065317, "phrase": "decision_support_rules"}, {"score": 0.004794114682072429, "phrase": "fuzzy_predictive_models"}, {"score": 0.004395742407834023, "phrase": "decision_makers"}, {"score": 0.004310752197635499, "phrase": "systems_engineers"}, {"score": 0.004282787299993434, "phrase": "ai_experts"}, {"score": 0.004163678671861766, "phrase": "data_analysis_process"}, {"score": 0.0039955060673136766, "phrase": "potential_drawbacks"}, {"score": 0.003952385950442126, "phrase": "computational_intelligence"}, {"score": 0.003834099867584972, "phrase": "often_limited_interpretability"}, {"score": 0.0037517752294252494, "phrase": "interpretability_limitations"}, {"score": 0.0036951980987864775, "phrase": "ci_models"}, {"score": 0.0036791898979344328, "phrase": "rule_extraction_methods"}, {"score": 0.003631578683409655, "phrase": "model_results"}, {"score": 0.0035535870069951393, "phrase": "reasonably_simple_and_actionable_rules"}, {"score": 0.00346972260297944, "phrase": "rule_extraction"}, {"score": 0.0034322572683276654, "phrase": "final_responsibility"}, {"score": 0.0033441960007710705, "phrase": "ci"}, {"score": 0.0033222630615013763, "phrase": "computer-based_method"}, {"score": 0.003257960296952439, "phrase": "novel_rule-extraction_algorithm"}, {"score": 0.0031743392477419506, "phrase": "fir"}, {"score": 0.0031262551667795685, "phrase": "fuzzy_inductive_reasoning"}, {"score": 0.0030524448705134283, "phrase": "good_qualitative_relationships"}, {"score": 0.002973904674745238, "phrase": "future_behaviour"}, {"score": 0.0028723099159640407, "phrase": "linguistic_rules"}, {"score": 0.0028536497989610763, "phrase": "fir_model"}, {"score": 0.0028351105637388556, "phrase": "lr-fir_functioning"}, {"score": 0.002792318079594211, "phrase": "boolean_algebra"}, {"score": 0.002644678812707061, "phrase": "multi-valued_logic"}, {"score": 0.0026217900041939184, "phrase": "partial_do-not-care_conditions"}, {"score": 0.0025543022789584354, "phrase": "fir_methodology"}, {"score": 0.0025377028579210417, "phrase": "obtained_rules"}, {"score": 0.0025102759256260703, "phrase": "predictive_rules"}, {"score": 0.0024563059480239985, "phrase": "fir_models"}, {"score": 0.002398274973378986, "phrase": "five_data-sets"}, {"score": 0.002281377734623141, "phrase": "iris"}, {"score": 0.002271422637218634, "phrase": "pima_indian_diabetes"}, {"score": 0.002227413549228654, "phrase": "main_behaviour"}, {"score": 0.0021937733197480397, "phrase": "domain_experts'_point"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Fuzzy inductive reasoning", " Fuzzy logic", " Rule extraction", " Virtual campus", " Global heat", " Brain tumours", " Iris", " Pima Indian Diabetes"], "paper_abstract": "In several application areas like banking, insurance, medicine, education, business, to name just a few, there are huge, sometimes unstructured data collections, and there is a need to convert data into information. On the other hand, decision makers in industry are usually not statisticians, mathematicians, systems engineers, or AI experts. So it is important, to organize the results of the data analysis process and to present it in a form that can be easily interpreted by non-experts. One of the potential drawbacks affecting the application of computational intelligence (CI) methods in general to the analysis of data is the often limited interpretability of the results they yield. One way to overcome interpretability limitations is by explaining the operation of CI models using rule extraction methods. The interpretability of the model results should be greatly improved by their description in terms of reasonably simple and actionable rules that decision makers could rely on. In fact, rule extraction should provide whom the final responsibility for taking decisions rests, with an explanation about how a CI or related computer-based method has reached its decision. This paper describes a novel rule-extraction algorithm based on fuzzy logic, name LR-FIR (linguistic rules in FIR), that starts from the fuzzy inductive reasoning (FIR) methodology. FIR is able to obtain good qualitative relationships between the variables that compose the system and to predict the future behaviour of that system. The proposed algorithm (LR-FIR) is able to derive linguistic rules from a FIR model. The LR-FIR functioning is similar to those used in Boolean algebra. However the premises and consequences of rules are not necessarily binary in nature, hence the algorithm must be able to deal with multi-valued logic, and accept partial do-not-care conditions. Due to the fact that LR-FIR was developed within the FIR methodology, the obtained rules could be considered as predictive rules and deal naturally with the uncertainty captured in the FIR models. LR-FIR, in this paper, was evaluated using five data-sets from different domains: e-learning, global change temperature, brain tumour diagnosis, and two of the most used classical UCI data-sets: IRIS and Pima Indian Diabetes. The rules extracted by LR-FIR capture the main behaviour of each application, from the domain experts' point of view, demonstrating in this sense, the efficiency of the proposed algorithm. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "On the extraction of decision support rules from fuzzy predictive models", "paper_id": "WOS:000289508000018"}