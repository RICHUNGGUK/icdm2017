{"auto_keywords": [{"score": 0.0391916005540395, "phrase": "bn"}, {"score": 0.03663614835271814, "phrase": "ss"}, {"score": 0.00481495049065317, "phrase": "bayesian_network_super-structures"}, {"score": 0.004750178261675602, "phrase": "large_bayesian_networks"}, {"score": 0.004581660953729745, "phrase": "challenging_problem"}, {"score": 0.004439097815805505, "phrase": "structure_space"}, {"score": 0.0043793594257092805, "phrase": "effective_way"}, {"score": 0.00389404213807752, "phrase": "specialized_methods"}, {"score": 0.003671865026158296, "phrase": "hybrid_approach"}, {"score": 0.003638823482920949, "phrase": "bn_structure_learning"}, {"score": 0.003220709449062307, "phrase": "approximate-deterministic_relationships"}, {"score": 0.0031062822219953524, "phrase": "small_samples"}, {"score": 0.0030644247579222333, "phrase": "second_algorithm"}, {"score": 0.0029689311901364797, "phrase": "computational_optimized_version"}, {"score": 0.0029289191071848403, "phrase": "recent_hpc_algorithm"}, {"score": 0.0029025435402480326, "phrase": "de_morais"}, {"score": 0.0027616550517346066, "phrase": "attractive_accuracy"}, {"score": 0.0027367816003722252, "phrase": "ss_recovery"}, {"score": 0.002639502113350897, "phrase": "proposed_algorithms"}, {"score": 0.002466303439899648, "phrase": "ss_estimation"}, {"score": 0.0023253967212081626, "phrase": "computational_cost"}, {"score": 0.002162951519368368, "phrase": "analyzed_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Bayesian networks", " Structure learning", " Super-structure"], "paper_abstract": "Learning large Bayesian networks (BN) from data is a challenging problem due to the vastness of the structure space. An effective way to turn this problem affordable is the use of super-structures SS (undirected graphs that contain the BN skeleton). However, the literature has been lacking of specialized methods for estimating SS. We present here two algorithms intended for such purpose in the hybrid approach of BN structure learning. The first one, called Opt01SS, learns SS using only zero-and-first-order conditional independence (Cl) tests in a way that allows dealing with the presence of approximate-deterministic relationships and inconsistent CIs, commonly found in small samples. The second algorithm, called OptHPC, is a computational optimized version of the recent HPC algorithm (De Morais and Aussem 2010, [17]) that showed an attractive accuracy for SS recovery. Results on various benchmark networks showed that the proposed algorithms achieve a balance between sensitivity and specificity clearly more favorable for the task of SS estimation than several representative state-of-the-art methods. The computational cost was also found to be reasonable, being Opt01SS one of the most competitive among the analyzed algorithms. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Efficient methods for learning Bayesian network super-structures", "paper_id": "WOS:000326909600002"}