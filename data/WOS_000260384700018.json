{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "computer_vision"}, {"score": 0.02771436929865281, "phrase": "overhead_video"}, {"score": 0.004698514007994158, "phrase": "established_procedural_model"}, {"score": 0.004641351004344458, "phrase": "information_visualization"}, {"score": 0.004556901872357751, "phrase": "first_operation"}, {"score": 0.004446677711302801, "phrase": "raw_data"}, {"score": 0.004392565073466714, "phrase": "data_tables"}, {"score": 0.004031699976413366, "phrase": "relevant_data"}, {"score": 0.003545024951402818, "phrase": "data_transforms"}, {"score": 0.003438058620195309, "phrase": "low_level_computer_vision"}, {"score": 0.0033961782274326948, "phrase": "high_level_reasoning"}, {"score": 0.003293688299319582, "phrase": "human_analyst"}, {"score": 0.0031747618267940155, "phrase": "low_level_perception"}, {"score": 0.002913650880082273, "phrase": "viz-a-vis"}, {"score": 0.0027403605798830984, "phrase": "activity_analysis"}, {"score": 0.0027069560455629917, "phrase": "natural_settings"}, {"score": 0.002673957615079041, "phrase": "variable_periods"}, {"score": 0.00257735013358606, "phrase": "rich_opportunities"}, {"score": 0.0025459275963373496, "phrase": "long-term_behavioral_and_occupancy_analysis"}, {"score": 0.0023944552329463035, "phrase": "initial_steps"}, {"score": 0.0022797772939670063, "phrase": "overwhelmingly_large_volumes"}, {"score": 0.0021441057555396013, "phrase": "automatic_video_analysis"}, {"score": 0.0021049977753042253, "phrase": "open_problem"}], "paper_keywords": ["Spatiotemporal visualization", " time series data", " video visualization", " sensor analytics", " image/video analytics"], "paper_abstract": "In the established procedural model of information visualization, the first operation is to transform raw data into data tables [1]. The transforms typically include abstractions that aggregate and segment relevant data and are usually defined by a human, user or programmer. The theme of this paper is that for video, data transforms should be supported by low level computer vision. High level reasoning still resides in the human analyst, while part of the low level perception is handled by the computer. To illustrate this approach, we present Viz-A-Vis, an overhead video capture and access system for activity analysis in natural settings over variable periods of time. Overhead video provides rich opportunities for long-term behavioral and occupancy analysis, but it poses considerable challenges. We present initial steps addressing two challenges. First, overhead video generates overwhelmingly large volumes of video impractical to analyze manually. Second, automatic video analysis remains an open problem for computer vision.", "paper_title": "Viz-A-Vis: Toward Visualizing Video through Computer Vision", "paper_id": "WOS:000260384700018"}