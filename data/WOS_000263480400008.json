{"auto_keywords": [{"score": 0.03484553832957215, "phrase": "lli"}, {"score": 0.00481495049065317, "phrase": "nonlinear_dimensionality_reduction"}, {"score": 0.004771435352180973, "phrase": "locally_linear_inlaying"}, {"score": 0.0047283116134926645, "phrase": "high-dimensional_data"}, {"score": 0.00460125407969429, "phrase": "information_processing"}, {"score": 0.004457309741979921, "phrase": "intrinsic_structures"}, {"score": 0.004051828608343507, "phrase": "low-dimensional_non-linear_manifold"}, {"score": 0.0037506567448470163, "phrase": "novel_algorithm"}, {"score": 0.0035677736570659813, "phrase": "simple_geometric_intuitions"}, {"score": 0.0034403745992576808, "phrase": "global_embedding"}, {"score": 0.0033937776228549557, "phrase": "nonlinear_manifold"}, {"score": 0.0033326252993345685, "phrase": "divide-and-conquer_strategy"}, {"score": 0.0030707512751243214, "phrase": "data_points"}, {"score": 0.0028293966058473476, "phrase": "nonuniform_sample_distribution"}, {"score": 0.002765776659294382, "phrase": "existing_algorithms"}, {"score": 0.0027282915297520624, "phrase": "isometric_feature_mapping"}, {"score": 0.002559951153813876, "phrase": "locally_linear_coordination"}, {"score": 0.0025367677884730972, "phrase": "llc"}, {"score": 0.0023694065215394593, "phrase": "embedding_results"}, {"score": 0.002305589818994465, "phrase": "information_theory"}, {"score": 0.0022847009758393405, "phrase": "kolmogorov_complexity_theory"}, {"score": 0.0021049977753042253, "phrase": "synthetic_and_real-world_data_sets"}], "paper_keywords": ["Isometric feature mapping", " local tangent space alignment", " locally linear inlaying (LLI)", " manifold learning", " nonlinear dimensionality reduction", " robustness"], "paper_abstract": "High-dimensional data is involved in many fields of information processing. However, sometimes, the intrinsic structures of these data can be described by a few degrees of freedom. To discover these degrees of freedom or the low-dimensional non-linear manifold underlying a high-dimensional space, many manifold learning algorithms have been proposed. Here we describe a novel algorithm, locally linear inlaying (LLI), which combines simple geometric intuitions and rigorously established optimality to compute the global embedding of a nonlinear manifold. Using a divide-and-conquer strategy, LLI gains some advantages in itself. First, its time complexity is linear in the number of data points, and hence LLI can be implemented efficiently. Second, LLI overcomes problems caused by the nonuniform sample distribution. Third, unlike existing algorithms such as isometric feature mapping (Isomap), local tangent space alignment (LTSA), and locally linear coordination (LLC), LLI is robust to noise. In addition, to evaluate the embedding results quantitatively, two criteria based on information theory and Kolmogorov complexity theory, respectively, are proposed. Furthermore, we demonstrated the efficiency and effectiveness of our proposal by synthetic and real-world data sets.", "paper_title": "Nonlinear Dimensionality Reduction by Locally Linear Inlaying", "paper_id": "WOS:000263480400008"}