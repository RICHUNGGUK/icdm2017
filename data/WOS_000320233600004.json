{"auto_keywords": [{"score": 0.010612387000973441, "phrase": "multi-agent_system"}, {"score": 0.005025778589294135, "phrase": "common_grounds"}, {"score": 0.004781498797706604, "phrase": "ontology-guided_learning"}, {"score": 0.004569630374630379, "phrase": "group_commitment"}, {"score": 0.004522080178250592, "phrase": "common_ontology"}, {"score": 0.0043367547691560175, "phrase": "real_world"}, {"score": 0.004306610946695577, "phrase": "communicating_agents"}, {"score": 0.003212424802083714, "phrase": "general_method"}, {"score": 0.002974886152979996, "phrase": "particular_agent"}, {"score": 0.002842840150239715, "phrase": "positive_and_negative_examples"}, {"score": 0.0027071661844502992, "phrase": "known_concept_learning_methods"}, {"score": 0.002560000295424659, "phrase": "received_set"}, {"score": 0.0025156683465194967, "phrase": "learning_agent"}, {"score": 0.0024377918036784336, "phrase": "learning_process"}, {"score": 0.002329530057661417, "phrase": "common_ontologies"}, {"score": 0.0021049977753042253, "phrase": "learned_concepts"}], "paper_keywords": ["Agent", " Multi-agent system", " Ontology", " Concept", " Learning", " Object", " Feature", " Probability", " Communication"], "paper_abstract": "Traditionally, communication among agents has been established based on the group commitment to a common ontology which is unfortunately often too strong or unrealistic. In the real world of communicating agents, it is preferred to enable agents to exchange information while they keep their own individual ontology. While this assumption makes agents represent their knowledge more independently and give them more flexibility, it also adds to the complexity of communication. We believe that agents can overcome this complexity by using their learning capability. The agents can learn any concept they do not know but want to communicate about with other agents in the multi-agent system where they work in. Our goal in this paper is to present a general method for agents using ontologies to teach each other concepts to improve their communication, and therefore cooperation abilities. In our method, a particular agent that understands a concept only ambiguously intends to learn it by receiving positive and negative examples for that concept from the other agents. Then, utilizing one of the known concept learning methods, the agent learns the concept in question. In case of conflicts in the received set of examples, the learning agent asks other agents again to get involved in the learning process by taking votes. While this method allows agents not to share common ontologies, it enables agents to establish common grounds on the concepts known only by some of them if these common grounds are needed during cooperation. In fact, the learned concepts by an agent are compromised among the views of other agents the method improves the autonomy of agents using them significantly.", "paper_title": "Common understanding in a multi-agent system using ontology-guided learning", "paper_id": "WOS:000320233600004"}