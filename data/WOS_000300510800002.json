{"auto_keywords": [{"score": 0.028088183852130657, "phrase": "vgs"}, {"score": 0.014122370358664722, "phrase": "vgs_model"}, {"score": 0.012124263636308493, "phrase": "gradient_magnitude"}, {"score": 0.00481495049065317, "phrase": "image_quality_assessment"}, {"score": 0.004760394308239882, "phrase": "visual_gradient_similarity"}, {"score": 0.0046797114400479135, "phrase": "full-reference_image_quality_assessment"}, {"score": 0.004522406417999492, "phrase": "multiscale_visual_gradient_similarity"}, {"score": 0.004247560712327667, "phrase": "three-stage_approach"}, {"score": 0.003989351600022163, "phrase": "pointwise_comparison"}, {"score": 0.0038114397487574838, "phrase": "gradient_direction"}, {"score": 0.0036207206487324506, "phrase": "intrascale_pooling"}, {"score": 0.0034988876789164235, "phrase": "interscale_pooling"}, {"score": 0.003419943984098415, "phrase": "human_visual_systems"}, {"score": 0.00308610073274614, "phrase": "stevens'_power_law"}, {"score": 0.0029148831519944358, "phrase": "quality_uniformity"}, {"score": 0.002881793492919646, "phrase": "visual_detection_threshold"}, {"score": 0.0028006988338192375, "phrase": "visual_frequency_sensitivity"}, {"score": 0.002753138528582461, "phrase": "subjective_image_quality"}, {"score": 0.002706383680762465, "phrase": "optimal_values"}, {"score": 0.002585539416877115, "phrase": "existing_iqa_databases"}, {"score": 0.0025416235470290286, "phrase": "good_performance"}, {"score": 0.002442025065383455, "phrase": "cross_validation"}, {"score": 0.002414290278501595, "phrase": "experimental_results"}, {"score": 0.0021908807203548345, "phrase": "prediction_precision"}, {"score": 0.0021049977753042253, "phrase": "low_computational_cost"}], "paper_keywords": ["Contrast registration", " human visual system", " image quality assessment (IQA)", " power law", " quality uniformity", " visual gradient similarity (VGS)"], "paper_abstract": "A full-reference image quality assessment (IQA) model by multiscale visual gradient similarity (VGS) is presented. The VGS model adopts a three-stage approach: First, global contrast registration for each scale is applied. Then, pointwise comparison is given by multiplying the similarity of gradient direction with the similarity of gradient magnitude. Third, intrascale pooling is applied, followed by interscale pooling. Several properties of human visual systems on image gradient have been explored and incorporated into the VGS model. It has been found that Stevens' power law is also suitable for gradient magnitude. Other factors such as quality uniformity, visual detection threshold of gradient, and visual frequency sensitivity also affect subjective image quality. The optimal values of two parameters of VGS are trained with existing IQA databases, and good performance of VGS has been verified by cross validation. Experimental results show that VGS is competitive with state-of-the-art metrics in terms of prediction precision, reliability, simplicity, and low computational cost.", "paper_title": "Image Quality Assessment by Visual Gradient Similarity", "paper_id": "WOS:000300510800002"}