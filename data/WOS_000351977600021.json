{"auto_keywords": [{"score": 0.049675053299362525, "phrase": "random_forest"}, {"score": 0.009571669568801561, "phrase": "rfv"}, {"score": 0.009491307821836603, "phrase": "rfp"}, {"score": 0.00481495049065317, "phrase": "novelty_detection"}, {"score": 0.00467424463996457, "phrase": "non-exhaustive_learning"}, {"score": 0.0044237033788643715, "phrase": "complete_set"}, {"score": 0.004294381488413906, "phrase": "new_classes"}, {"score": 0.004151188559520802, "phrase": "data_errors"}, {"score": 0.003995772867224968, "phrase": "traditional_proximity-based_approaches"}, {"score": 0.003829877278269543, "phrase": "different_samples"}, {"score": 0.0034445472801689046, "phrase": "proposed_framework"}, {"score": 0.0031777570808834213, "phrase": "different_classes"}, {"score": 0.0030457198309616694, "phrase": "ensemble_methods"}, {"score": 0.0030071857666598193, "phrase": "decision_tree"}, {"score": 0.0029817668105720924, "phrase": "base_classifiers"}, {"score": 0.002785978280998868, "phrase": "vote_distribution"}, {"score": 0.0027274643070540733, "phrase": "testing_sample"}, {"score": 0.002658863179011018, "phrase": "proximity_matrix"}, {"score": 0.002636539205560064, "phrase": "rf"}, {"score": 0.002603012037901889, "phrase": "special_kernel_metric"}, {"score": 0.002526780881314497, "phrase": "proposed_approaches"}, {"score": 0.002380934815435267, "phrase": "gaussian_mixed_model"}, {"score": 0.0023013968622710847, "phrase": "five_benchmark_data_sets"}, {"score": 0.00227225841515826, "phrase": "experimental_results"}, {"score": 0.0022339789476489877, "phrase": "proposed_methods"}, {"score": 0.002215081186105616, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Novelty detection", " Ensemble learning", " Random forest", " Proximity matrix"], "paper_abstract": "In many online classification tasks or non-exhaustive learning, it is often impossible to define a training set with a complete set of classes. The presence of new classes as well as the novelties caused by data errors can severely affect the performance of classifiers. Traditional proximity-based approaches usually utilize the distance to measure the proximity of different samples. In this study, we propose a framework that uses ensemble learning to detect novelty based on Random Forest (RF). The proposed framework is based on the observation that an ensemble of classifiers can provide a kind of metric to characterize different classes and measure their proximity. In particular, we apply ensemble methods with the decision tree as base classifiers and present two specific approaches, RFV and RFP, based on random forest. RFV uses the vote distribution of RF on a testing sample, and RFP takes the proximity matrix of RF as a special kernel metric to discover the novelty. The proposed approaches are compared against two common approaches: support vector domain description (SVDD) and Gaussian Mixed Model (GMM) on one artificial data set and five benchmark data sets. The experimental results show that the proposed methods achieve better performance in terms of accuracy and recall. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Two approaches for novelty detection using random forest", "paper_id": "WOS:000351977600021"}