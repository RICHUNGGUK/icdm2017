{"auto_keywords": [{"score": 0.049460287006492736, "phrase": "multi-view_image_sequences"}, {"score": 0.030690493677208327, "phrase": "multiple_views"}, {"score": 0.00481495049065317, "phrase": "clg-motion_flow"}, {"score": 0.004424441580112395, "phrase": "human_action_recognition"}, {"score": 0.0042550030421781605, "phrase": "combined_motion"}, {"score": 0.004092026656771699, "phrase": "variability_consideration"}, {"score": 0.0037844916274672544, "phrase": "invariant_moments"}, {"score": 0.003735522846193052, "phrase": "flow_deviations"}, {"score": 0.0035923719610602214, "phrase": "global_shape_flow_feature"}, {"score": 0.0035228596881051763, "phrase": "image_sequences"}, {"score": 0.0034099718632933027, "phrase": "human_action"}, {"score": 0.003257960296952439, "phrase": "multidimensional_clg_optic_flow"}, {"score": 0.003194898129853895, "phrase": "flow_feature_vectors"}, {"score": 0.003133052778244851, "phrase": "spatial-temporal_action_boundary"}, {"score": 0.002935393439834135, "phrase": "multidimensional_hmms"}, {"score": 0.0028412769256691, "phrase": "combined_features"}, {"score": 0.0027681550491613603, "phrase": "robust_view-invariant_operation"}, {"score": 0.0026969099161088398, "phrase": "different_human_actions"}, {"score": 0.0026619761089539595, "phrase": "daily_life"}, {"score": 0.0025934566395017424, "phrase": "indoor_and_outdoor_environment"}, {"score": 0.002543224008253855, "phrase": "maximum_likelihood_estimation_approach"}, {"score": 0.002413964586947992, "phrase": "proposed_method"}, {"score": 0.002336527289457915, "phrase": "action_recognition"}, {"score": 0.0022177498761722773, "phrase": "invariant_analysis"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["action recognition", " action matrix", " combined local-global (CLG) optic flow", " invariant Zernike moments", " multi-view image sequence", " multidimensional hidden Markov model (MDHMM)"], "paper_abstract": "In this paper, we present a method for human action recognition from multi-view image sequences that uses the combined motion and shape flow information with variability consideration. A combined local-global (CLG) optic flow is used to extract motion flow feature and invariant moments with flow deviations are used to extract the global shape flow feature from the image sequences. In our approach, human action is represented as a set of multidimensional CLG optic flow and shape flow feature vectors in the spatial-temporal action boundary. Actions are modeled by using a set of multidimensional HMMs for multiple views using the combined features, which enforce robust view-invariant operation. We recognize different human actions in daily life successfully in the indoor and outdoor environment using the maximum likelihood estimation approach. The results suggest robustness of the proposed method with respect to Multiple views action recognition, scale and phase variations, and invariant analysis of silhouettes. (c) 2007 Elsevier Ltd. All rights reserved.", "paper_title": "Human action recognition using shape and CLG-motion flow from multi-view image sequences", "paper_id": "WOS:000255818900011"}