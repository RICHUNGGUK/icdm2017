{"auto_keywords": [{"score": 0.04381987555039217, "phrase": "multiple_clients"}, {"score": 0.02491593281159906, "phrase": "lru"}, {"score": 0.00481495049065317, "phrase": "multiclient_cache_hierarchies"}, {"score": 0.0047823219739028325, "phrase": "application_hints"}, {"score": 0.004749913509007163, "phrase": "multilevel_caching"}, {"score": 0.004638195656547484, "phrase": "new_challenges"}, {"score": 0.004606759374526927, "phrase": "traditional_cache_management"}, {"score": 0.004483120978156604, "phrase": "appropriate_cache"}, {"score": 0.004362786303912385, "phrase": "additional_challenges"}, {"score": 0.004289215825521407, "phrase": "lower_levels"}, {"score": 0.004103662938882996, "phrase": "positive_and_negative_effects"}, {"score": 0.003899476621346112, "phrase": "additional_delays"}, {"score": 0.003769006950727621, "phrase": "other's_blocks"}, {"score": 0.003718045060236861, "phrase": "exclusive_caching_schemes"}, {"score": 0.0033116807159861766, "phrase": "positive_effects"}, {"score": 0.0032447099613882313, "phrase": "negative_ones"}, {"score": 0.0032008178062970746, "phrase": "karma"}, {"score": 0.0031682817605340028, "phrase": "readily_available_information"}, {"score": 0.0031360786664165093, "phrase": "client's_future_access_profile"}, {"score": 0.0030310732341527168, "phrase": "best_replacement_policy"}, {"score": 0.0029798924689472014, "phrase": "global_scheme"}, {"score": 0.0029096837584084182, "phrase": "shared_cache_space"}, {"score": 0.002812237329893584, "phrase": "exclusive_caching"}, {"score": 0.0027741761880779535, "phrase": "nonshared_data"}, {"score": 0.002690406375639144, "phrase": "previous_studies"}, {"score": 0.002627000223796678, "phrase": "minor_changes"}, {"score": 0.0026002844796442818, "phrase": "storage_interface"}, {"score": 0.002487612781045517, "phrase": "minor_interface_changes"}, {"score": 0.0024707163158758307, "phrase": "smart_allocation"}, {"score": 0.002453934333239467, "phrase": "replacement_policies"}, {"score": 0.0023636455694730787, "phrase": "existing_solutions"}, {"score": 0.0023239884641409196, "phrase": "arc"}, {"score": 0.0023079225317714815, "phrase": "multiq"}, {"score": 0.002292243761395491, "phrase": "lru-sp"}, {"score": 0.0021705796895687864, "phrase": "better_cache_performance"}, {"score": 0.0021049977753042253, "phrase": "representative_workloads"}], "paper_keywords": ["Cache", " multilevel", " hints"], "paper_abstract": "Multilevel caching, common in many storage configurations, introduces new challenges to traditional cache management: data must be kept in the appropriate cache and replication avoided across the various cache levels. Additional challenges are introduced when the lower levels of the hierarchy are shared by multiple clients. Sharing can have both positive and negative effects. While data fetched by one client can be used by another client without incurring additional delays, clients competing for cache buffers can evict each other's blocks and interfere with exclusive caching schemes. We present a global noncentralized, dynamic and informed management policy for multiple levels of cache, accessed by multiple clients. Our algorithm, MC(2), combines local, per client management with a global, system-wide scheme, to emphasize the positive effects of sharing and reduce the negative ones. Our local management scheme, Karma, uses readily available information about the client's future access profile to save the most valuable blocks, and to choose the best replacement policy for them. The global scheme uses the same information to divide the shared cache space between clients, and to manage this space. Exclusive caching is maintained for nonshared data and is disabled when sharing is identified. Previous studies have partially addressed these challenges through minor changes to the storage interface. We show that all these challenges can in fact be addressed by combining minor interface changes with smart allocation and replacement policies. We show the superiority of our approach through comparison to existing solutions, including LRU, ARC, MultiQ, LRU-SP, and Demote, as well as a lower bound on optimal I/O response times. Our simulation results demonstrate better cache performance than all other solutions and up to 87% better performance than LRU on representative workloads.", "paper_title": "Management of Multilevel, Multiclient Cache Hierarchies with Application Hints", "paper_id": "WOS:000290382100002"}