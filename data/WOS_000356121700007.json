{"auto_keywords": [{"score": 0.04320512154983126, "phrase": "low-rank_analysis"}, {"score": 0.00481495049065317, "phrase": "robust_multi-modal_medical_image_fusion"}, {"score": 0.0046928556063004214, "phrase": "low-rank_structural_analysis"}, {"score": 0.0045348429403481464, "phrase": "robust_multi-modal_medical_image_fusion_method"}, {"score": 0.00440093312826378, "phrase": "novel_framework"}, {"score": 0.004363401436068803, "phrase": "multi-scale_image_decomposition"}, {"score": 0.004307700591183651, "phrase": "anisotropic_heat_kernel_design"}, {"score": 0.003937126962709418, "phrase": "multi-scale_structure_features"}, {"score": 0.003837205620832367, "phrase": "complex_noise_perturbation"}, {"score": 0.0037719988989298983, "phrase": "anisotropic_heat_kernel"}, {"score": 0.0036762529165489644, "phrase": "image_pyramid"}, {"score": 0.003629291866667764, "phrase": "multi-level_image_properties"}, {"score": 0.0034033029171804106, "phrase": "multi-scale_structure-preserving_image_decomposition"}, {"score": 0.003274499008699115, "phrase": "meaningfully_scale-aware_salient_information"}, {"score": 0.003177687211289478, "phrase": "image_layer_groups"}, {"score": 0.003123652729688503, "phrase": "first_step"}, {"score": 0.0030573959252626695, "phrase": "low-rank_components"}, {"score": 0.0030054007508185858, "phrase": "scale_space"}, {"score": 0.00296698375549856, "phrase": "salient_features"}, {"score": 0.0029165216647792924, "phrase": "underlying_noise"}, {"score": 0.0028302635493019867, "phrase": "natural_way"}, {"score": 0.0027347937102326285, "phrase": "complementary_salient_information"}, {"score": 0.0026998264237910884, "phrase": "multi-modal_images"}, {"score": 0.0026425357050743003, "phrase": "s-shaped_weighting_function"}, {"score": 0.002597577409911978, "phrase": "large-scale_layers"}, {"score": 0.0025424508991051483, "phrase": "maximum_selection_principle"}, {"score": 0.00249919111154604, "phrase": "small-scale_layers"}, {"score": 0.0024252458095689847, "phrase": "extensive_experiments"}, {"score": 0.002353483216544667, "phrase": "comprehensive_and_quantitative_comparisons"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multi-modal image fusion", " Data-specific filter", " Anisotropic heat kernel design", " Low-rank analysis", " Multi-scale decomposition"], "paper_abstract": "This paper proposes a novel and robust multi-modal medical image fusion method, which is built upon a novel framework comprising multi-scale image decomposition based on anisotropic heat kernel design, scale-aware salient information extraction based on low-rank analysis, and scale-specific fusion rules. Our framework respects multi-scale structure features, while being robust to complex noise perturbation. First, anisotropic heat kernel is computed by constructing an image pyramid and embedding multi-level image properties into 2D manifolds in a divide-and-conquer way, consequently, multi-scale structure-preserving image decomposition can be accommodated. Second, to extract meaningfully scale-aware salient information, we conduct low-rank analysis over the image layer groups obtained in the first step, and employ the low-rank components to form the scale space of the salient features, wherein the underlying noise can be synchronously decoupled in a natural way. Third, to better fuse the complementary salient information extracted from multi-modal images, we design an S-shaped weighting function to fuse the large-scale layers, and employ the maximum selection principle to handle the small-scale layers. Moreover, we have conducted extensive experiments on MRI and PET/SPECT images. The comprehensive and quantitative comparisons with state-of-the-art methods demonstrate the informativeness, accuracy, robustness, and versatility of our novel approach. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Robust multi-modal medical image fusion via anisotropic heat diffusion guided low-rank structural analysis", "paper_id": "WOS:000356121700007"}