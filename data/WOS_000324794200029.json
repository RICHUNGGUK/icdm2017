{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "malicious_model"}, {"score": 0.0045959609346817535, "phrase": "data_mining_algorithms"}, {"score": 0.0042859292226559535, "phrase": "participating_parties'_data_privacy"}, {"score": 0.003516079377293321, "phrase": "semi-honest_model"}, {"score": 0.002817639725689939, "phrase": "perceptron_learning_algorithms"}, {"score": 0.002566685388128598, "phrase": "vertically_partitioned_data_sets"}, {"score": 0.002205560249972527, "phrase": "first_perceptron_learning_algorithms"}, {"score": 0.0021049977753042253, "phrase": "data_privacy"}], "paper_keywords": ["Perceptron learning", " Privacy preserving", " Malicious model"], "paper_abstract": "Privacy preserving data mining algorithms are proposed to protect the participating parties' data privacy in data mining processes. So far, most of these algorithms only work in the semi-honest model that assumes all parties follow the algorithms honestly. In this paper, we propose two privacy preserving perceptron learning algorithms in the malicious model, for horizontally and vertically partitioned data sets, respectively. So far as we know, our algorithms are the first perceptron learning algorithms that can protect data privacy in the malicious model.", "paper_title": "Privacy preserving perceptron learning in malicious model", "paper_id": "WOS:000324794200029"}