{"auto_keywords": [{"score": 0.041930175435788225, "phrase": "fast_motion"}, {"score": 0.00481495049065317, "phrase": "optical-flow_computation"}, {"score": 0.004761732436126133, "phrase": "well-known_technique"}, {"score": 0.004691684576246597, "phrase": "important_fields"}, {"score": 0.004571559854487074, "phrase": "visual_modality"}, {"score": 0.004537804310268603, "phrase": "high_interest"}, {"score": 0.004438019162720755, "phrase": "real-time_processing"}, {"score": 0.0041515831652973794, "phrase": "date_use"}, {"score": 0.004136221184894985, "phrase": "basic_models"}, {"score": 0.004060256280654948, "phrase": "generic_tasks"}, {"score": 0.003927004211021119, "phrase": "subpixel_motion_resolution"}, {"score": 0.003784049616066444, "phrase": "complex_optical-flow_approach"}, {"score": 0.0035135084960705816, "phrase": "high-frame-rate_sensors"}, {"score": 0.003385555209074879, "phrase": "low-motion_scene"}, {"score": 0.0033110234463504125, "phrase": "gradient-based_approach"}, {"score": 0.0032622464094096463, "phrase": "best_options"}, {"score": 0.0031317713853981064, "phrase": "real-time_implementation"}, {"score": 0.0030628094110419697, "phrase": "regular_data"}, {"score": 0.0028648759706752162, "phrase": "optical-flow_processing"}, {"score": 0.0026996706283276407, "phrase": "data_throughput"}, {"score": 0.00265987582861194, "phrase": "clock_cycle"}, {"score": 0.002630414143385786, "phrase": "computing_scheme"}, {"score": 0.002582032847722892, "phrase": "fpga_technology"}, {"score": 0.002562929776267296, "phrase": "vlsi_implementation"}, {"score": 0.002534539169474629, "phrase": "developed_customized_dsp_architecture"}, {"score": 0.002344398099179438, "phrase": "high-frame-rare_processing"}, {"score": 0.002309828105129336, "phrase": "optical-flow_model"}, {"score": 0.0022009497295481678, "phrase": "system_resource_requrements"}, {"score": 0.0021846599115561832, "phrase": "fpga_devices"}, {"score": 0.0021444597601392146, "phrase": "system's_performance"}], "paper_keywords": ["Image motion analysis", " Real-time systems", " FPGAs", " Architecture of vision systems"], "paper_abstract": "Optical-flow computation is a well-known technique and there are important fields in which the application of this visual modality commands high interest. Nevertheless, most real-world applications require real-time processing. all issue which has only recently been addressed. Most real-time systems described to date use basic models which limit their applicability to generic tasks, especially when fast motion is presented or when subpixel motion resolution is required. Therefore, instead of implementing a complex optical-flow approach, we describe here a very high-frame-rate optical-flow processing system. Recent advances in image sensor technology make it possible nowadays to use high-frame-rate sensors, to properly sample fast motion (i.e. as a low-motion scene), which makes a gradient-based approach one of the best options in terms Of accuracy and comsumption of resources for any real-time implementation. Taking advantage of the regular data now of this kind of algorithm, our approach implements a novel superpipelined. fully parallelized architecture for optical-flow processing. The system is fully working and is organized into More than 70 pipeline stages, which achieve a data throughput of one pixel per clock cycle. This computing scheme is well suited to FPGA technology and VLSI implementation. The developed Customized DSP architecture is capable of processing up to 170 frames per second at a resolution of 800 600 pixels. We discuss the advantages of high-frame-rare processing and justify the optical-flow model chosen for the implementation. We analyze this architecture, measure the system resource requrements Using FPGA devices and finally evaluate the system's performance and compare it with other approaches described in the literature. (c) 2008 Elsevier Inc. All rights reserved.", "paper_title": "Superpipelined high-performance optical-flow computation architecture", "paper_id": "WOS:000261013900003"}