{"auto_keywords": [{"score": 0.03925855052566655, "phrase": "search_algorithm"}, {"score": 0.015719716506582538, "phrase": "search-based_software_engineering"}, {"score": 0.015251017798080092, "phrase": "search_algorithms"}, {"score": 0.009628845117320576, "phrase": "test_data_generation"}, {"score": 0.007950214148668295, "phrase": "\"default\"_values"}, {"score": 0.004354315061804687, "phrase": "genetic_algorithms"}, {"score": 0.0036393456309815166, "phrase": "optimal_settings"}, {"score": 0.0035918768194006735, "phrase": "possible_problems"}, {"score": 0.003219553875143356, "phrase": "largest_empirical_analysis"}, {"score": 0.0029110999689379497, "phrase": "object-oriented_software"}, {"score": 0.0028731024405707277, "phrase": "evosuite_tool"}, {"score": 0.002475532161577715, "phrase": "good_settings"}, {"score": 0.0022678201262721323, "phrase": "different_techniques"}, {"score": 0.0021610874773389096, "phrase": "reasonable_and_justified_choice"}, {"score": 0.0021328586481696157, "phrase": "parameter_tuning"}, {"score": 0.0021049977753042253, "phrase": "long_and_expensive_process"}], "paper_keywords": ["Search-based software engineering", " Test data generation", " Object-oriented", " Unit testing", " Tuning", " EvoSuite", " Java", " Response surface", " Design of experiments"], "paper_abstract": "Many software engineering problems have been addressed with search algorithms. Search algorithms usually depend on several parameters (e.g., population size and crossover rate in genetic algorithms), and the choice of these parameters can have an impact on the performance of the algorithm. It has been formally proven in the No Free Lunch theorem that it is impossible to tune a search algorithm such that it will have optimal settings for all possible problems. So, how to properly set the parameters of a search algorithm for a given software engineering problem? In this paper, we carry out the largest empirical analysis so far on parameter tuning in search-based software engineering. More than one million experiments were carried out and statistically analyzed in the context of test data generation for object-oriented software using the EvoSuite tool. Results show that tuning does indeed have impact on the performance of a search algorithm. But, at least in the context of test data generation, it does not seem easy to find good settings that significantly outperform the \"default\" values suggested in the literature. This has very practical value for both researchers (e.g., when different techniques are compared) and practitioners. Using \"default\" values is a reasonable and justified choice, whereas parameter tuning is a long and expensive process that might or might not pay off in the end.", "paper_title": "Parameter tuning or default values? An empirical investigation in search-based software engineering", "paper_id": "WOS:000319774300007"}