{"auto_keywords": [{"score": 0.04516267803280923, "phrase": "multiple_views"}, {"score": 0.01180266826768433, "phrase": "proposed_approach"}, {"score": 0.010612387000973441, "phrase": "rgb-d_image_understanding"}, {"score": 0.007868954527253419, "phrase": "intrinsic_relations"}, {"score": 0.00470325458481566, "phrase": "massive_rgb-depth"}, {"score": 0.004508661664944657, "phrase": "compelling_need"}, {"score": 0.004466519142879166, "phrase": "effective_rgb-d_content_understanding_techniques"}, {"score": 0.004424768776701965, "phrase": "rgb-d_images"}, {"score": 0.004143196873246147, "phrase": "real-world_objects"}, {"score": 0.003990385737207714, "phrase": "compact_and_discriminative_features"}, {"score": 0.003897742942358768, "phrase": "rgb-d_content"}, {"score": 0.003861288537079326, "phrase": "effective_feature_representation"}, {"score": 0.0037188360359702182, "phrase": "robust_multiview_feature"}, {"score": 0.0033377940531761985, "phrase": "integrated_formulation"}, {"score": 0.003291051334991867, "phrase": "joint_optimization"}, {"score": 0.003125175084962886, "phrase": "effective_features"}, {"score": 0.003066945490483524, "phrase": "learning_process"}, {"score": 0.0029816229984366374, "phrase": "feature_learning_function"}, {"score": 0.002912331664922248, "phrase": "robust_nonnegative_graph_embedding_function"}, {"score": 0.002765490759189057, "phrase": "local_geometric_and_discriminating_structure"}, {"score": 0.002675914969626753, "phrase": "joint_sparsity"}, {"score": 0.0026014425686078993, "phrase": "data_factorization"}, {"score": 0.0024586427394152196, "phrase": "efficient_computational_solution"}, {"score": 0.0023902026696615473, "phrase": "rigorous_theoretical_proof"}, {"score": 0.0021857677257931256, "phrase": "rgb-d"}, {"score": 0.0021249064184347658, "phrase": "extensive_experiments"}], "paper_keywords": ["Algorithms", " Performance", " RGB-D content", " image understanding", " multiview feature learning"], "paper_abstract": "The availability of massive RGB-depth (RGB-D) images poses a compelling need for effective RGB-D content understanding techniques. RGB-D images provide synchronized information from multiple views (e.g., color and depth) of real-world objects and scenes. This work proposes learning compact and discriminative features from the multiple views of RGB-D content toward effective feature representation for RGB-D image understanding. In particular, a robust multiview feature learning approach is developed, which exploits the intrinsic relations among multiple views. The feature learning in multiple views is jointly optimized in an integrated formulation. The joint optimization essentially exploits the intrinsic relations among the views, leading to effective features and making the learning process robust to noises. The feature learning function is formulated as a robust nonnegative graph embedding function over multiple graphs in various views. The graphs characterize the local geometric and discriminating structure of the multiview data. The joint sparsity in l(1)-norm graph embedding and l(21)-norm data factorization further enhances the robustness of feature learning. We derive an efficient computational solution for the proposed approach and provide rigorous theoretical proof with regard to its convergence. We apply the proposed approach to two RGB-D image understanding tasks: RGB-D object classification and RGB-D scene categorization. We conduct extensive experiments on two real-world RGB-D image datasets. The experimental results have demonstrated the effectiveness of the proposed approach.", "paper_title": "Robust Multiview Feature Learning for RGB-D Image Understanding", "paper_id": "WOS:000354049800005"}