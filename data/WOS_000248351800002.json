{"auto_keywords": [{"score": 0.04809176147872217, "phrase": "authorship_verification_problem"}, {"score": 0.00481495049065317, "phrase": "pseudonymous_authors"}, {"score": 0.0041074234667687875, "phrase": "single_author"}, {"score": 0.0033579708256295847, "phrase": "new_learning-based_method"}, {"score": 0.0026307897899760383, "phrase": "underlying_idea"}, {"score": 0.002316105585203396, "phrase": "learned_models"}, {"score": 0.0022434880661725493, "phrase": "best_features"}, {"score": 0.0021049977753042253, "phrase": "learning_process"}], "paper_keywords": ["authorship attribution", " one-class learning", " unmasking"], "paper_abstract": "In the authorship verification problem, we are given examples of the writing of a single author and are asked to determine if given long texts were or were not written by this author. We present a new learning-based method for adducing the \"depth of difference\" between two example sets and offer evidence that this method solves the authorship verification problem with very high accuracy. The underlying idea is to test the rate of degradation of the accuracy of learned models as the best features are iteratively dropped from the learning process.", "paper_title": "Measuring differentiability: Unmasking pseudonymous authors", "paper_id": "WOS:000248351800002"}