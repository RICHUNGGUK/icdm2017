{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "action_string"}, {"score": 0.00461302961851157, "phrase": "explosive_growth"}, {"score": 0.004529093447865156, "phrase": "capture_data"}, {"score": 0.004312622975366672, "phrase": "efficient_and_reliable_methods"}, {"score": 0.003910106508089187, "phrase": "mocap_devices"}, {"score": 0.0038624981944755813, "phrase": "home_entertainment_systems"}, {"score": 0.0038154673253945003, "phrase": "real-time_human_motion_annotation"}, {"score": 0.0035233696341819437, "phrase": "new_motion_annotation_method"}, {"score": 0.00327356326590461, "phrase": "probabilistic_pose_feature"}, {"score": 0.0031942814007173254, "phrase": "gaussian_mixture"}, {"score": 0.0030043508031729277, "phrase": "clustered_pose_feature_model"}, {"score": 0.002949598537993663, "phrase": "motion_clip"}, {"score": 0.0027572166867780275, "phrase": "dynamic_programming-based_string_matching_method"}, {"score": 0.0026252106881752067, "phrase": "action_strings"}, {"score": 0.0024842242921857705, "phrase": "real-time_target"}, {"score": 0.002409188797323273, "phrase": "hierarchical_action_string_structure"}, {"score": 0.0022938068444116827, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["motion annotation", " action recognition", " GMM pose feature", " action string", " string matching"], "paper_abstract": "Even though there is an explosive growth of motion capture data, there is still a lack of efficient and reliable methods to automatically annotate all the motions in a database. Moreover, because of the popularity of mocap devices in home entertainment systems, real-time human motion annotation or recognition becomes more and more imperative. This paper presents a new motion annotation method that achieves both the aforementioned two targets at the same time. It uses a probabilistic pose feature based on the Gaussian Mixture Model to represent each pose. After training a clustered pose feature model, a motion clip could be represented as an action string. Then, a dynamic programming-based string matching method is introduced to compare the differences between action strings. Finally, in order to achieve the real-time target, we construct a hierarchical action string structure to quickly label each given action string. The experimental results demonstrate the efficacy and efficiency of our method. Copyright (c) 2014 John Wiley & Sons, Ltd.", "paper_title": "Real-time motion data annotation via action string", "paper_id": "WOS:000337524300010"}