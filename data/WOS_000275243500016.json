{"auto_keywords": [{"score": 0.044728827124546816, "phrase": "tpr"}, {"score": 0.043384232041233727, "phrase": "fpr"}, {"score": 0.04027757193224259, "phrase": "small_samples"}, {"score": 0.00481495049065317, "phrase": "roc-related_estimates"}, {"score": 0.004457309741979921, "phrase": "varying_decision_thresholds"}, {"score": 0.004397000006837371, "phrase": "estimated_roc_curve"}, {"score": 0.004317848984770719, "phrase": "true_positive_rate"}, {"score": 0.004051828608343507, "phrase": "key_metric"}, {"score": 0.003683097597914604, "phrase": "training_data"}, {"score": 0.0036167509502276294, "phrase": "natural_question"}, {"score": 0.003456087239186551, "phrase": "auc"}, {"score": 0.0033326252993345685, "phrase": "true_metrics"}, {"score": 0.0032429499567088113, "phrase": "simulation_study"}, {"score": 0.0032135959043774085, "phrase": "data_models"}, {"score": 0.0031556799865964974, "phrase": "real_microarray_data"}, {"score": 0.00297454367746853, "phrase": "square_differences"}, {"score": 0.002934237411711622, "phrase": "estimated_and_true_metrics"}, {"score": 0.002816556934231128, "phrase": "large_samples"}, {"score": 0.0027282915297520624, "phrase": "true_and_estimated_metrics"}, {"score": 0.0026069623057065664, "phrase": "weak_regression"}, {"score": 0.002525248554951453, "phrase": "estimated_metric"}, {"score": 0.002491015208328868, "phrase": "classification_rules"}, {"score": 0.0024460897937643032, "phrase": "linear_discriminant_analysis"}, {"score": 0.002423931101340771, "phrase": "linear_support_vector_machine"}, {"score": 0.002402123190752255, "phrase": "svm"}, {"score": 0.002337293761711272, "phrase": "svm."}, {"score": 0.002316105585203396, "phrase": "error_estimation"}, {"score": 0.0021049977753042253, "phrase": "published_roc_results"}], "paper_keywords": [""], "paper_abstract": "Motivation: The receiver operator characteristic (ROC) curves are commonly used in biomedical applications to judge the performance of a discriminant across varying decision thresholds. The estimated ROC curve depends on the true positive rate (TPR) and false positive rate (FPR), with the key metric being the area under the curve (AUC). With small samples these rates need to be estimated from the training data, so a natural question arises: How well do the estimates of the AUC, TPR and FPR compare with the true metrics? Results: Through a simulation study using data models and analysis of real microarray data, we show that (i) for small samples the root mean square differences of the estimated and true metrics are considerable; (ii) even for large samples, there is only weak correlation between the true and estimated metrics; and (iii) generally, there is weak regression of the true metric on the estimated metric. For classification rules, we consider linear discriminant analysis, linear support vector machine (SVM) and radial basis function SVM. For error estimation, we consider resubstitution, three kinds of crossvalidation and bootstrap. Using resampling, we show the unreliability of some published ROC results.", "paper_title": "Small-sample precision of ROC-related estimates", "paper_id": "WOS:000275243500016"}