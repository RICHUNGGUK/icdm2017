{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "monotone_boolean_functions"}, {"score": 0.015571631695157741, "phrase": "uniform_distribution"}, {"score": 0.014389835652222679, "phrase": "monotone_boolean_function"}, {"score": 0.010891827748248711, "phrase": "average_sensitivity"}, {"score": 0.004517334089033334, "phrase": "learning_algorithm"}, {"score": 0.004184274042752558, "phrase": "first_result"}, {"score": 0.004078780515171644, "phrase": "single_variable_function"}, {"score": 0.003950631096355195, "phrase": "minimum_correlation"}, {"score": 0.003912974119795913, "phrase": "majority_function"}, {"score": 0.003875674688691641, "phrase": "fair_monotone_functions"}, {"score": 0.0037900142749506425, "phrase": "blum_et_al"}, {"score": 0.003730047622562076, "phrase": "proc"}, {"score": 0.003566897271386661, "phrase": "performance_guarantee"}, {"score": 0.003532885029484907, "phrase": "best_known_learning_algorithm"}, {"score": 0.0025830324526904427, "phrase": "somewhat_unintuitive_result"}, {"score": 0.0021595521075096808, "phrase": "new_learning_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["PAC learning", " monotone Boolean functions", " harmonic analysis", " majority function"], "paper_abstract": "In this paper, we prove two general theorems on monotone Boolean functions which are useful for constructing a learning algorithm for monotone Boolean functions under the uniform distribution. A monotone Boolean function is called fair if it takes the value 1 on exactly half of its inputs. The first result proved in this paper is that a single variable function f (x) = x(i) has the minimum correlation with the majority function among all fair monotone functions. This proves the conjecture by Blum et al. (1998, Proc. 39th FOCS, pp. 408-415) and improves the performance guarantee of the best known learning algorithm for monotone Boolean functions under the uniform distribution they proposed. Our second result is on the relationship between the influences and the average sensitivity of a monotone Boolean function. The influence of variable x(i) on f is defined as the probability that f (x) differs from f (x circle plus e(i)) where x is chosen uniformly from (0, 1)(n) and x (circle plus) e(i) means x with its ith bit flipped. The average sensitivity of f is defined as the sum of the influences over all variables x(i). We prove that a somewhat unintuitive result which says if the influence of every variable on a monotone Boolean function is small, i.e., O(1/n(c)) for some constant c > 0, then the average sensitivity of the function must be large, i.e., Omega(log n). We also discuss how to apply this result to the construction of a new learning algorithm for monotone Boolean functions. (c) 2005 Elsevier B.V. All rights reserved.", "paper_title": "On learning monotone Boolean functions under the uniform distribution", "paper_id": "WOS:000234779800002"}