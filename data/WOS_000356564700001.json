{"auto_keywords": [{"score": 0.04075092054031414, "phrase": "cta"}, {"score": 0.022732688157009264, "phrase": "rta"}, {"score": 0.011804008776845664, "phrase": "usability_problems"}, {"score": 0.007401835721837215, "phrase": "query_tool"}, {"score": 0.0060499740884159435, "phrase": "unique_usability_problems"}, {"score": 0.005007405076518339, "phrase": "rta."}, {"score": 0.00481495049065317, "phrase": "formative_usability_testing"}, {"score": 0.004778145748896516, "phrase": "physician_data_query_tool"}, {"score": 0.004505123806025276, "phrase": "intensive_care_registry-physician_data_query_tool"}, {"score": 0.004459252690006674, "phrase": "icu_quality_improvement_processes"}, {"score": 0.004324410631569266, "phrase": "usability_evaluation_study"}, {"score": 0.004150916144510748, "phrase": "six_usability-testing_tasks"}, {"score": 0.004056389961627438, "phrase": "real-working_context"}, {"score": 0.003903586935992704, "phrase": "verbal_protocols"}, {"score": 0.003775803846431323, "phrase": "verbal_output"}, {"score": 0.003756518244967687, "phrase": "standardized_measures"}, {"score": 0.0036897882079331887, "phrase": "usability_problem_detection"}, {"score": 0.0036615523899977, "phrase": "problem_severity_level"}, {"score": 0.0036335318564543044, "phrase": "overall_effectiveness"}, {"score": 0.0034787373417055423, "phrase": "usability_evaluation"}, {"score": 0.003452110978165299, "phrase": "data_query_tool"}, {"score": 0.003382096094265075, "phrase": "intensive_care_physicians"}, {"score": 0.003288130735513798, "phrase": "navigation_issues"}, {"score": 0.0032713278333553687, "phrase": "error_messages"}, {"score": 0.003196767658539796, "phrase": "query_tool's_screens"}, {"score": 0.0031641758661104117, "phrase": "unique_issues"}, {"score": 0.003148004393603339, "phrase": "system_match"}, {"score": 0.0031319153105988217, "phrase": "subjects'_language"}, {"score": 0.003084138237955827, "phrase": "in-depth_verbal_protocol_analysis"}, {"score": 0.0030370877795599413, "phrase": "intensive_care_physicians'_query_design_strategies"}, {"score": 0.002930067708455535, "phrase": "cta_usability_problem_detection_effectiveness"}, {"score": 0.0028340618944491434, "phrase": "average_difference"}, {"score": 0.0027341831896834706, "phrase": "cfa"}, {"score": 0.0025842629550143813, "phrase": "cia"}, {"score": 0.002551347953392069, "phrase": "usability-problem_detection"}, {"score": 0.0025188541214907685, "phrase": "intensive_care_physician_query_design_strategies"}, {"score": 0.0023868275250400347, "phrase": "new_user_requirements"}, {"score": 0.002285022889269964, "phrase": "formative_usability_evaluation_studies"}, {"score": 0.0022733343455751823, "phrase": "health_information_technology"}, {"score": 0.0021987994275190314, "phrase": "usability_studies"}, {"score": 0.0021763599397084583, "phrase": "user_expertise"}, {"score": 0.0021431284357819325, "phrase": "user_profile"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["User-computer interface", " Usability", " Methodologies", " Think Aloud", " ICU", " Databases"], "paper_abstract": "Objective: To compare the performance of the Concurrent (CFA) and Retrospective (RTA) Think Aloud method and to assess their value in a formative usability evaluation of an Intensive Care Registry-physician data query tool designed to support ICU quality improvement processes. Methods: Sixteen representative intensive care physicians participated in the usability evaluation study. Subjects were allocated to either the CTA or RTA method by a matched randomized design. Each subject performed six usability-testing tasks of varying complexity in the query tool in a real-working context. Methods were compared with regard to number and type of problems detected. Verbal protocols of CTA and RTA were analyzed in depth to assess differences in verbal output. Standardized measures were applied to assess thoroughness in usability problem detection weighted per problem severity level and method overall effectiveness in detecting usability problems with regard to the time subjects spent per method. Results: The usability evaluation of the data query tool revealed a total of 43 unique usability problems that the intensive care physicians encountered. CTA detected unique usability problems with regard to graphics/symbols, navigation issues, error messages, and the organization of information on the query tool's screens. RTA detected unique issues concerning system match with subjects' language and applied terminology. The in-depth verbal protocol analysis of CTA provided information on intensive care physicians' query design strategies. Overall, CTA performed significantly better than RTA in detecting usability problems. CTA usability problem detection effectiveness was 0.80 vs. 0.62 (p < 0.05) respectively, with an average difference of 42% less time spent per subject compared to RTA. In addition, CFA was more thorough in detecting usability problems of a moderate (0.85 vs. 0.7) and severe nature (0.71 vs. 0.57). Conclusion: In this study, the CIA is more effective in usability-problem detection and provided clarification of intensive care physician query design strategies to inform redesign of the query tool. However, CTA does not outperform RTA. The RTA additionally elucidated unique usability problems and new user requirements. Based on the results of this study, we recommend the use of CFA in formative usability evaluation studies of health information technology. However, we recommend further research on the application of RTA in usability studies with regard to user expertise and experience when focusing on user profile customized (re)design. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "The value of Retrospective and Concurrent Think Aloud in formative usability testing of a physician data query tool", "paper_id": "WOS:000356564700001"}