{"auto_keywords": [{"score": 0.04522690430865453, "phrase": "unlabeled_data"}, {"score": 0.013059188762904156, "phrase": "gaussians"}, {"score": 0.011164320895001354, "phrase": "'full'_gaussians"}, {"score": 0.00481495049065317, "phrase": "reliability_estimation"}, {"score": 0.0047797212183363835, "phrase": "structural_systems"}, {"score": 0.004675565200598801, "phrase": "classification-based_surrogate_model"}, {"score": 0.004506968388996092, "phrase": "training_data"}, {"score": 0.004424953471635011, "phrase": "known_responses"}, {"score": 0.004360412703519539, "phrase": "large_number"}, {"score": 0.004265354774450696, "phrase": "unknown_responses"}, {"score": 0.004218602458288531, "phrase": "semi-supervised_learning_methods"}, {"score": 0.004111488691642256, "phrase": "enhanced_probabilistic_neural_network"}, {"score": 0.003948613642680196, "phrase": "labeled_point"}, {"score": 0.0037505809981715024, "phrase": "'full'_covariance_matrix"}, {"score": 0.003670132914800207, "phrase": "gaussian"}, {"score": 0.0036285315458900284, "phrase": "'spherical'_covariance_matrix"}, {"score": 0.003562444653947001, "phrase": "expectation-maximization_algorithm"}, {"score": 0.0034975571855450343, "phrase": "labeled_and_unlabeled_data"}, {"score": 0.0033220706785945815, "phrase": "labeled_datapoints"}, {"score": 0.003190367939051776, "phrase": "particular_datapoint"}, {"score": 0.003097865379563127, "phrase": "bayes_decision_criterion"}, {"score": 0.003030247482854539, "phrase": "final_output_layer"}, {"score": 0.0029641011108505785, "phrase": "test_patterns"}, {"score": 0.002888747754856871, "phrase": "failure_class"}, {"score": 0.002857041057269513, "phrase": "primary_benefit"}, {"score": 0.002825681384008326, "phrase": "proposed_method"}, {"score": 0.002763988044737562, "phrase": "better_estimation"}, {"score": 0.0027437235598539904, "phrase": "'full'_covariance_matrices"}, {"score": 0.0026838147966444783, "phrase": "underlying_data"}, {"score": 0.0025963890234079333, "phrase": "probability_density_functions"}, {"score": 0.0024933837962398267, "phrase": "additional_computational_costs"}, {"score": 0.0024299678474208023, "phrase": "classification_results"}, {"score": 0.0023079225317714815, "phrase": "analytic_problem"}, {"score": 0.0022825763382627443, "phrase": "truss_problem"}, {"score": 0.002216336059488137, "phrase": "proposed_reliability_estimation_process"}, {"score": 0.002175913488493802, "phrase": "considerable_improvements"}, {"score": 0.0021520139248317333, "phrase": "classifier_performance"}, {"score": 0.0021049977753042253, "phrase": "sufficient_accuracy"}], "paper_keywords": ["Reliability analysis", " Probabilistic neural network", " Expectation-Maximization", " Semi-supervised learning", " Classification"], "paper_abstract": "The accuracy of a classification-based surrogate model for reliability assessment can be improved by augmenting the training data (labeled data or data with known responses) with a large number of unlabeled data (data with unknown responses) in semi-supervised learning methods. In this research, an enhanced Probabilistic Neural Network (PNN) algorithm is proposed where the Gaussians at each labeled point are not assumed to be spherical. Each of the Gaussians has a 'full' covariance matrix instead of simply assuming the Gaussian with a 'spherical' covariance matrix. First, the Expectation-Maximization algorithm is applied on the labeled and unlabeled data while assuming that the number of 'full' Gaussians is equal to the number of labeled datapoints. The contribution of each of these 'full' Gaussians at a particular datapoint is found by using the Bayes Theorem. The Bayes decision criterion is then used in the final output layer of the PNN to classify test patterns into either the safe or the failure class. The primary benefit of the proposed method comes from utilizing unlabeled data for better estimation of 'full' covariance matrices of constituting Gaussian clusters of underlying data, which are then used to estimate the Probability Density Functions of classes for classification. This procedure does not require additional computational costs to improve the accuracy of the classification results since the cost of unlabeled data is negligible in general. Two examples including an analytic problem and a truss problem are presented in order to validate the proposed reliability estimation process. The results reflect considerable improvements of the classifier performance for estimating reliability while maintaining sufficient accuracy.", "paper_title": "An enhanced classification approach for reliability estimation of structural systems", "paper_id": "WOS:000336223900009"}