{"auto_keywords": [{"score": 0.038497557054923366, "phrase": "invariant_direction"}, {"score": 0.008493358141629225, "phrase": "camera_calibration"}, {"score": 0.005766611600152839, "phrase": "quadratic_entropy"}, {"score": 0.00481495049065317, "phrase": "entropy_minimization"}, {"score": 0.00479207796606729, "phrase": "shadow_removal"}, {"score": 0.0046793272171911215, "phrase": "colour_images"}, {"score": 0.004634969772496517, "phrase": "finlayson_et_al"}, {"score": 0.0046019765734675415, "phrase": "ieee_trans"}, {"score": 0.004547591716376058, "phrase": "mach"}, {"score": 0.0044088696713815295, "phrase": "special_direction"}, {"score": 0.004346310547489431, "phrase": "\"invariant_direction"}, {"score": 0.004284635278525657, "phrase": "particular_colour_features"}, {"score": 0.004193752569079365, "phrase": "greyscale_image"}, {"score": 0.004095021635819183, "phrase": "scene_illumination"}, {"score": 0.003998605730752489, "phrase": "particular_type"}, {"score": 0.003913766234300536, "phrase": "main_approach"}, {"score": 0.003876637620664603, "phrase": "special_angle"}, {"score": 0.003821601550492043, "phrase": "colour_target"}, {"score": 0.003713853637227992, "phrase": "colour_patch_images"}, {"score": 0.0036005398246162184, "phrase": "different_approach"}, {"score": 0.0034329016461293774, "phrase": "colour_image"}, {"score": 0.0033281313561978414, "phrase": "correct_invariant_direction"}, {"score": 0.003273042924888307, "phrase": "pixel_values"}, {"score": 0.003249712705799968, "phrase": "smaller_entropy"}, {"score": 0.0032111967830711413, "phrase": "wrong_direction"}, {"score": 0.003158037762087072, "phrase": "correct_projection_results"}, {"score": 0.0031355247199092865, "phrase": "probability_distribution_spike"}, {"score": 0.0026723985560486076, "phrase": "effective_description"}, {"score": 0.002653338327081413, "phrase": "entropy-minimization_task"}, {"score": 0.002584603537014602, "phrase": "shannon's_definition"}, {"score": 0.002560051845560703, "phrase": "observed_pixels"}, {"score": 0.0025417908598658816, "phrase": "kernel_density_probability_distribution"}, {"score": 0.0024407392661353836, "phrase": "efficient_fast_gauss_transform"}, {"score": 0.002310372057903139, "phrase": "usual_definition"}, {"score": 0.002293887955533707, "phrase": "resulting_algorithm"}, {"score": 0.002255879946493978, "phrase": "shadow_removal_step"}, {"score": 0.0022451363846071543, "phrase": "good_shadow-free_colour_image_results"}, {"score": 0.0021507128934288335, "phrase": "strong_minimum"}, {"score": 0.0021150721590334843, "phrase": "new_property"}, {"score": 0.0021049977753042253, "phrase": "image_formation"}], "paper_keywords": ["Illumination", " Reflectance", " Intrinsic images", " Illumination invariants", " Color", " Shadows", " Entropy", " Quadratic entropy"], "paper_abstract": "Recently, a method for removing shadows from colour images was developed (Finlayson et al. in IEEE Trans. Pattern Anal. Mach. Intell. 28:59-68, 2006) that relies upon finding a special direction in a 2D chromaticity feature space. This \"invariant direction\" is that for which particular colour features, when projected into 1D, produce a greyscale image which is approximately invariant to intensity and colour of scene illumination. Thus shadows, which are in essence a particular type of lighting, are greatly attenuated. The main approach to finding this special angle is a camera calibration: a colour target is imaged under many different lights, and the direction that best makes colour patch images equal across illuminants is the invariant direction. Here, we take a different approach. In this work, instead of a camera calibration we aim at finding the invariant direction from evidence in the colour image itself. Specifically, we recognize that producing a 1D projection in the correct invariant direction will result in a 1D distribution of pixel values that have smaller entropy than projecting in the wrong direction. The reason is that the correct projection results in a probability distribution spike, for pixels all the same except differing by the lighting that produced their observed RGB values and therefore lying along a line with orientation equal to the invariant direction. Hence we seek that projection which produces a type of intrinsic, independent of lighting reflectance-information only image by minimizing entropy, and from there go on to remove shadows as previously. To be able to develop an effective description of the entropy-minimization task, we go over to the quadratic entropy, rather than Shannon's definition. Replacing the observed pixels with a kernel density probability distribution, the quadratic entropy can be written as a very simple formulation, and can be evaluated using the efficient Fast Gauss Transform. The entropy, written in this embodiment, has the advantage that it is more insensitive to quantization than is the usual definition. The resulting algorithm is quite reliable, and the shadow removal step produces good shadow-free colour image results whenever strong shadow edges are present in the image. In most cases studied, entropy has a strong minimum for the invariant direction, revealing a new property of image formation.", "paper_title": "Entropy Minimization for Shadow Removal", "paper_id": "WOS:000268008000003"}