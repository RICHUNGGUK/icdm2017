{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "conversational_experiences"}, {"score": 0.004643839937761046, "phrase": "wearable_device"}, {"score": 0.004478782833067256, "phrase": "human-human_and_human-artifact_interactions"}, {"score": 0.004216566615939546, "phrase": "human_perception"}, {"score": 0.004140924670517666, "phrase": "personal_and_social_everyday-life_experiences"}, {"score": 0.003922011960904278, "phrase": "visible_scenes"}, {"score": 0.0037825134619339537, "phrase": "perceived_experiences"}, {"score": 0.0035824802350703376, "phrase": "nonverbal_behavior"}, {"score": 0.0035181731203867456, "phrase": "indexed_stored_experiences"}, {"score": 0.003312009953245191, "phrase": "multimodal_knowledge_base"}, {"score": 0.003252542052430779, "phrase": "daily_life"}, {"score": 0.0031941384895530426, "phrase": "infrared_led_id_tag_system"}, {"score": 0.0029887957779347394, "phrase": "relative_positions"}, {"score": 0.002899861600151726, "phrase": "camera's_visual_field"}, {"score": 0.0027463775689957255, "phrase": "\"interaction_scope"}, {"score": 0.002600995957987461, "phrase": "relative_human-object_positions"}, {"score": 0.0025388705701873075, "phrase": "high_probability"}, {"score": 0.002478225374613311, "phrase": "conversational_interactions"}, {"score": 0.002419025278429845, "phrase": "experimental_conversational_sessions"}, {"score": 0.002361236012575149, "phrase": "interaction_scope"}, {"score": 0.0021049977753042253, "phrase": "proposed_interaction_scope"}], "paper_keywords": ["experience capturing", " conversational experience", " everyday-life computing", " wearable device"], "paper_abstract": "We have developed a wearable device that records the activities of human-human and human-artifact interactions. Using microphones and cameras, the device imitates human perception, recording personal and social everyday-life experiences in multiple modalities, such as voice and visible scenes. These sensors record the perceived experiences continuously, and detect and index interactions from nonverbal behavior. The indexed stored experiences can serve as the. rst step toward a multimodal knowledge base created from daily life. An infrared LED ID tag system detects interactions, in terms of the ID and the relative positions of objects within the camera's visual field. In this study, we propose an \"interaction scope\" which is defined as the range of relative human-object positions that have a high probability of occurring in conversational interactions. Analysis of experimental conversational sessions confirms that this interaction scope exists and can represent these interactions naturally. We also demonstrate that our tag system effectively detects and measures the proposed interaction scope.", "paper_title": "The wearable sensor devices for detecting conversational experiences", "paper_id": "WOS:000251156200003"}