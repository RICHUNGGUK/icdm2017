{"auto_keywords": [{"score": 0.04976849859687576, "phrase": "defect_prediction_models"}, {"score": 0.036513433888240764, "phrase": "-time_quality_assurance"}, {"score": 0.00481495049065317, "phrase": "time_quality_assurance"}, {"score": 0.00473727773195392, "phrase": "well-known_technique"}, {"score": 0.004691273968935458, "phrase": "defect-prone_files"}, {"score": 0.004353040792349733, "phrase": "critical_files"}, {"score": 0.004186325123152709, "phrase": "considerable_time"}, {"score": 0.004092026656771699, "phrase": "even_code_snippets"}, {"score": 0.003859146369720225, "phrase": "large_software_systems"}, {"score": 0.0035343512834706417, "phrase": "quality_assurance_activity"}, {"score": 0.0033548872248104814, "phrase": "risky_changes"}, {"score": 0.003133052778244851, "phrase": "change_risk_model"}, {"score": 0.003082427650896418, "phrase": "wide_range"}, {"score": 0.0029933487820771217, "phrase": "software_change"}, {"score": 0.0029258435787995985, "phrase": "added_lines"}, {"score": 0.0028973794653974327, "phrase": "developer_experience"}, {"score": 0.002869191468702503, "phrase": "large-scale_study"}, {"score": 0.002850551552945005, "phrase": "six_open_source"}, {"score": 0.002832032388853002, "phrase": "five_commercial_projects"}, {"score": 0.002813633198636833, "phrase": "multiple_domains"}, {"score": 0.002653313402950335, "phrase": "average_accuracy"}, {"score": 0.0023062508214156123, "phrase": "defect-inducing_changes"}, {"score": 0.0021961592899628615, "phrase": "effort-reducing_way"}, {"score": 0.0021049977753042253, "phrase": "high-quality_software"}], "paper_keywords": ["Maintenance", " software metrics", " mining software repositories", " defect prediction", " just-in-time prediction"], "paper_abstract": "Defect prediction models are a well-known technique for identifying defect-prone files or packages such that practitioners can allocate their quality assurance efforts (e. g., testing and code reviews). However, once the critical files or packages have been identified, developers still need to spend considerable time drilling down to the functions or even code snippets that should be reviewed or tested. This makes the approach too time consuming and impractical for large software systems. Instead, we consider defect prediction models that focus on identifying defect-prone (\"risky\") software changes instead of files or packages. We refer to this type of quality assurance activity as \"Just-In-Time Quality Assurance,\" because developers can review and test these risky changes while they are still fresh in their minds (i.e., at check-in time). To build a change risk model, we use a wide range of factors based on the characteristics of a software change, such as the number of added lines, and developer experience. A large-scale study of six open source and five commercial projects from multiple domains shows that our models can predict whether or not a change will lead to a defect with an average accuracy of 68 percent and an average recall of 64 percent. Furthermore, when considering the effort needed to review changes, we find that using only 20 percent of the effort it would take to inspect all changes, we can identify 35 percent of all defect-inducing changes. Our findings indicate that \"Just-In-Time Quality Assurance\" may provide an effort-reducing way to focus on the most risky changes and thus reduce the costs of developing high-quality software.", "paper_title": "A Large-Scale Empirical Study of Just-in-Time Quality Assurance", "paper_id": "WOS:000319338200003"}