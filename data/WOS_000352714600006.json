{"auto_keywords": [{"score": 0.03679048193550957, "phrase": "ladmpsap"}, {"score": 0.010629284793276007, "phrase": "ladm"}, {"score": 0.007740489288296054, "phrase": "parallel_splitting"}, {"score": 0.007686869513340498, "phrase": "adaptive_penalty"}, {"score": 0.007580733198578168, "phrase": "machine_learning"}, {"score": 0.006735446298970364, "phrase": "adm"}, {"score": 0.006152682544490038, "phrase": "multi-block_case"}, {"score": 0.00474827840031692, "phrase": "separable_convex_programs"}, {"score": 0.004475022550508119, "phrase": "convex_programs"}, {"score": 0.004321656690200878, "phrase": "multiple_blocks"}, {"score": 0.004217425501814589, "phrase": "traditional_alternating_direction_method"}, {"score": 0.004030449969901066, "phrase": "quadratic_penalty_term"}, {"score": 0.00396075511616602, "phrase": "two-block_case"}, {"score": 0.0037587915908689497, "phrase": "great_demand"}, {"score": 0.0037066895459425824, "phrase": "adm_based_methods"}, {"score": 0.003444732262403694, "phrase": "multi-block_separable_convex_programs"}, {"score": 0.003314965171168532, "phrase": "convergence_results"}, {"score": 0.0031458272260508637, "phrase": "penalty_parameter"}, {"score": 0.003069867656852932, "phrase": "sufficient_and_necessary_conditions"}, {"score": 0.002974886152979993, "phrase": "simple_optimality_measure"}, {"score": 0.00293361812353423, "phrase": "convergence_rate"}, {"score": 0.0028828348726682965, "phrase": "ergodic_sense"}, {"score": 0.002832928222306059, "phrase": "extra_convex_set_constraints"}, {"score": 0.002803398730609738, "phrase": "refined_parameter_estimation"}, {"score": 0.0027645030021576926, "phrase": "practical_version"}, {"score": 0.00272614545678894, "phrase": "faster_convergence"}, {"score": 0.00256895975568914, "phrase": "objective_function"}, {"score": 0.0024894376091589244, "phrase": "sparse_representation"}, {"score": 0.0024721021985994115, "phrase": "low-rank_recovery"}, {"score": 0.002420815160284086, "phrase": "form_solutions"}, {"score": 0.00217987162651941, "phrase": "numerical_experiments"}, {"score": 0.0021049977753042253, "phrase": "numerical_accuracy"}], "paper_keywords": ["Convex programs", " Alternating direction method", " Linearized alternating direction method", " Proximal alternating direction method", " Parallel splitting", " Adaptive renalty"], "paper_abstract": "Many problems in machine learning and other fields can be (re)formulated as linearly constrained separable convex programs. In most of the cases, there are multiple blocks of variables. However, the traditional alternating direction method (ADM) and its linearized version (LADM, obtained by linearizing the quadratic penalty term) are for the two-block case and cannot be naively generalized to solve the multi-block case. So there is great demand on extending the ADM based methods for the multi-block case. In this paper, we propose LADM with parallel splitting and adaptive penalty (LADMPSAP) to solve multi-block separable convex programs efficiently. When all the component objective functions have bounded subgradients, we obtain convergence results that are stronger than those of ADM and LADM, e.g., allowing the penalty parameter to be unbounded and proving the sufficient and necessary conditions for global convergence. We further propose a simple optimality measure and reveal the convergence rate of LADMPSAP in an ergodic sense. For programs with extra convex set constraints, with refined parameter estimation we devise a practical version of LADMPSAP for faster convergence. Finally, we generalize LADMPSAP to handle programs with more difficult objective functions by linearizing part of the objective function as well. LADMPSAP is particularly suitable for sparse representation and low-rank recovery problems because its subproblems have closed form solutions and the sparsity and low-rankness of the iterates can be preserved during the iteration. It is also highly parallelizable and hence fits for parallel or distributed computing. Numerical experiments testify to the advantages of LADMPSAP in speed and numerical accuracy.", "paper_title": "Linearized alternating direction method with parallel splitting and adaptive penalty for separable convex programs in machine learning", "paper_id": "WOS:000352714600006"}