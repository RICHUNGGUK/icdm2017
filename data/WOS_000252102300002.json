{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "rule_learning"}, {"score": 0.004681226806682058, "phrase": "recent_research"}, {"score": 0.004342430078306461, "phrase": "highly_accurate_hypotheses"}, {"score": 0.0034657012607680173, "phrase": "well-known_rule_learners"}, {"score": 0.0032756178178692434, "phrase": "ripper"}, {"score": 0.00315473564699977, "phrase": "foil"}, {"score": 0.002953711377604328, "phrase": "benchmark_system"}, {"score": 0.002765490759189057, "phrase": "small_rule_sets"}, {"score": 0.0024241817763927163, "phrase": "similar_level"}, {"score": 0.0023346234464901978, "phrase": "state-of-the-art_rule_learners"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["rule learning", " simplicity", " stochastic local search"], "paper_abstract": "While recent research on rule learning has focused largely on finding highly accurate hypotheses, we evaluate the degree to which these hypotheses are also simple, that is small. To realize this, we compare well-known rule learners, such as CN2, RIPPER, PART, FOIL and C5.0 rules, with the benchmark system SL2 that explicitly aims at computing small rule sets with few literals. The results show that it is possible to obtain a similar level of accuracy as state-of-the-art rule learners using much smaller rule sets. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "An experimental evaluation of simplicity in rule learning", "paper_id": "WOS:000252102300002"}