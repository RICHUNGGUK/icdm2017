{"auto_keywords": [{"score": 0.04843603269514023, "phrase": "information_retrieval"}, {"score": 0.00481495049065317, "phrase": "multiple_criteria"}, {"score": 0.004336115760817672, "phrase": "-performance_improvement"}, {"score": 0.0035989687070420977, "phrase": "document_relevance"}, {"score": 0.003435092524339692, "phrase": "single_score"}, {"score": 0.002952146666681891, "phrase": "multiple_criteria_framework"}, {"score": 0.002850682396853918, "phrase": "aggregation_mechanism"}, {"score": 0.002752695791351096, "phrase": "decision_rules"}, {"score": 0.0026892447164623247, "phrase": "positive_and_negative_reasons"}, {"score": 0.002421291757425244, "phrase": "better_ranking"}, {"score": 0.0022841153001549193, "phrase": "resulting_procedure"}, {"score": 0.002154693685426657, "phrase": "criteria_design"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": ["information retrieval", " relevance", " multiple criteria"], "paper_abstract": "Research in Information Retrieval shows -performance improvement when many sources of evidence are combined to produce a ranking of documents. Most current approaches assess document relevance by computing a single score which aggregates values of some attributes or criteria. We propose a multiple criteria framework using an aggregation mechanism based on decision rules identifying positive and negative reasons for judging whether a document should get a better ranking than another. The resulting procedure also handles imprecision in criteria design. Experimental results are reported.", "paper_title": "A multiple criteria approach for information retrieval", "paper_id": "WOS:000241594700020"}