{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "autonomous_document_cleaning-a_generative_approach"}, {"score": 0.00450000390667755, "phrase": "scanned_text_documents"}, {"score": 0.004308455856718928, "phrase": "manual_line_strokes"}, {"score": 0.004267004541988167, "phrase": "spilled_ink"}, {"score": 0.004026505114417176, "phrase": "single_letter-size_page"}, {"score": 0.0037811784409635023, "phrase": "character_representations"}, {"score": 0.003744780941673966, "phrase": "document_patches"}, {"score": 0.0035679633126097115, "phrase": "probabilistic_generative_model_parameterizing_pattern_features"}, {"score": 0.0034159525504642656, "phrase": "model's_latent_variables"}, {"score": 0.0032389001343643064, "phrase": "model_parameters"}, {"score": 0.003146212656743413, "phrase": "truncated_variational_em_approach"}, {"score": 0.003070996252787868, "phrase": "learned_representation"}, {"score": 0.0030267296900520217, "phrase": "clean_document"}, {"score": 0.002869793011316547, "phrase": "pattern_class"}, {"score": 0.002801166393333128, "phrase": "quality_measure"}, {"score": 0.0027341763737751467, "phrase": "character_and_non-character_patterns"}, {"score": 0.0026817365934071486, "phrase": "full_latin_alphabet"}, {"score": 0.0026175952455594277, "phrase": "single_page"}, {"score": 0.0025673856614952854, "phrase": "sufficiently_many_character_examples"}, {"score": 0.0023530698447434308, "phrase": "lower_number"}, {"score": 0.0023303871145705954, "phrase": "character_types"}, {"score": 0.0022094759531152072, "phrase": "structural_regularity"}, {"score": 0.0021254913611527455, "phrase": "different_example_applications"}, {"score": 0.0021049977753042253, "phrase": "different_alphabets"}], "paper_keywords": ["Probabilistic generative models", " document cleaning", " scanned text", " unsupervised learning", " expectation maximization", " variational approximation", " expectation truncation"], "paper_abstract": "We study the task of cleaning scanned text documents that are strongly corrupted by dirt such as manual line strokes, spilled ink, etc. We aim at autonomously removing such corruptions from a single letter-size page based only on the information the page contains. Our approach first learns character representations from document patches without supervision. For learning, we use a probabilistic generative model parameterizing pattern features, their planar arrangements and their variances. The model's latent variables describe pattern position and class, and feature occurrences. Model parameters are efficiently inferred using a truncated variational EM approach. Based on the learned representation, a clean document can be recovered by identifying, for each patch, pattern class and position while a quality measure allows for discrimination between character and non-character patterns. For a full Latin alphabet we found that a single page does not contain sufficiently many character examples. However, even if heavily corrupted by dirt, we show that a page containing a lower number of character types can efficiently and autonomously be cleaned solely based on the structural regularity of the characters it contains. In different example applications with different alphabets, we demonstrate and discuss the effectiveness, efficiency and generality of the approach.", "paper_title": "Autonomous Document Cleaning-A Generative Approach to Reconstruct Strongly Corrupted Scanned Texts", "paper_id": "WOS:000341981300004"}