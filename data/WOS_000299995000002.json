{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "abs"}, {"score": 0.004577440795549049, "phrase": "banked_shared_last-level_cache"}, {"score": 0.004388450908826472, "phrase": "memory_latencies"}, {"score": 0.004278807087784626, "phrase": "multicore_system"}, {"score": 0.004189523950071494, "phrase": "last-level"}, {"score": 0.00413686062124337, "phrase": "llc"}, {"score": 0.003982741546775355, "phrase": "common_resources"}, {"score": 0.003932654396285872, "phrase": "shared_cache_space"}, {"score": 0.003899612025233852, "phrase": "main_memory_bandwidth"}, {"score": 0.0036296886647898094, "phrase": "prefetch_aggressiveness"}, {"score": 0.0035091888798162176, "phrase": "system_standpoint"}, {"score": 0.0033926758710459866, "phrase": "commercial_chip_multiprocessors"}, {"score": 0.0032800186243040663, "phrase": "independent_banks"}, {"score": 0.003144426503333397, "phrase": "first_time"}, {"score": 0.003091767402370757, "phrase": "banked_llc_organization"}, {"score": 0.002939007076062123, "phrase": "hill-climbing_approach"}, {"score": 0.00284137141260141, "phrase": "llc_bank"}, {"score": 0.002805597755796506, "phrase": "inter-bank_communication"}, {"score": 0.00266693888510356, "phrase": "user-oriented_metrics"}, {"score": 0.0026445028886931837, "phrase": "harmonic_mean"}, {"score": 0.002471661547432869, "phrase": "weighted_speedup"}, {"score": 0.0024302416436559867, "phrase": "memory_bandwidth_consumption"}, {"score": 0.0023694065215394593, "phrase": "eight-core_baseline_system"}, {"score": 0.0023395610923736595, "phrase": "aggressive_sequential_prefetch"}, {"score": 0.0023100907305651872, "phrase": "fixed_degree"}, {"score": 0.0022906498741695094, "phrase": "similar_conclusions"}, {"score": 0.0021773853011112882, "phrase": "llc_size"}, {"score": 0.0021408862709571615, "phrase": "parallel_applications"}], "paper_keywords": ["Design", " Performance", " Prefetch", " shared resources management"], "paper_abstract": "Hardware data prefetch is a very well known technique for hiding memory latencies. However, in a multicore system fitted with a shared Last-Level Cache (LLC), prefetch induced by a core consumes common resources such as shared cache space and main memory bandwidth. This may degrade the performance of other cores and even the overall system performance unless the prefetch aggressiveness of each core is controlled from a system standpoint. On the other hand, LLCs in commercial chip multiprocessors are more and more frequently organized in independent banks. In this contribution, we target for the first time prefetch in a banked LLC organization and propose ABS, a low-cost controller with a hill-climbing approach that runs stand-alone at each LLC bank without requiring inter-bank communication. Using multiprogrammed SPEC2K6 workloads, our analysis shows that the mechanism improves both user-oriented metrics (Harmonic Mean of Speedups by 27% and Fairness by 11%) and system-oriented metrics (Weighted Speedup increases 22% and Memory Bandwidth Consumption decreases 14%) over an eight-core baseline system that uses aggressive sequential prefetch with a fixed degree. Similar conclusions can be drawn by varying the number of cores or the LLC size, when running parallel applications, or when other prefetch engines are controlled.", "paper_title": "ABS: A Low-Cost Adaptive Controller for Prefetching in a Banked Shared Last-Level Cache", "paper_id": "WOS:000299995000002"}