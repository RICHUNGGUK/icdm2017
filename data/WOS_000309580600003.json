{"auto_keywords": [{"score": 0.03727254882129724, "phrase": "ultimate_discriminative_task"}, {"score": 0.00481495049065317, "phrase": "nonparametric_guidance_of_autoencoder_representations"}, {"score": 0.00478218760286811, "phrase": "label_information"}, {"score": 0.004733458808453602, "phrase": "unsupervised_learning"}, {"score": 0.004637478829869904, "phrase": "density_modeling"}, {"score": 0.004605917942709477, "phrase": "exploratory_data_analysis"}, {"score": 0.004331320910631647, "phrase": "discriminative_tasks"}, {"score": 0.004301834610818624, "phrase": "discriminative_algorithms"}, {"score": 0.00422899036681456, "phrase": "highly-informative_features"}, {"score": 0.0039362209515303795, "phrase": "autoencoder_neural_networks"}, {"score": 0.00388278852285898, "phrase": "latent_representations"}, {"score": 0.0037267877774290374, "phrase": "pure_unsupervised_learning"}, {"score": 0.003480541792744611, "phrase": "continuing_challenge"}, {"score": 0.003173636240475185, "phrase": "priori_information"}, {"score": 0.003141246279336443, "phrase": "statistical_variation"}, {"score": 0.002883833572486452, "phrase": "typical_strategy"}, {"score": 0.002825251837733693, "phrase": "parametric_discriminative_model"}, {"score": 0.002777341265639153, "phrase": "autoencoder_training"}, {"score": 0.002720916895509682, "phrase": "nonparametric_approach"}, {"score": 0.0026839372202435065, "phrase": "gaussian_process"}, {"score": 0.002602555367635598, "phrase": "nonparametric_model"}, {"score": 0.0025409639091476363, "phrase": "useful_discriminative_function"}, {"score": 0.0023810183846557486, "phrase": "guidance_mechanism"}, {"score": 0.002332626862738603, "phrase": "real-_world_application"}, {"score": 0.0023167153974120083, "phrase": "rehabilitation_research"}, {"score": 0.0022234951091677085, "phrase": "statistically_significant_covariate_information"}, {"score": 0.002141334979696276, "phrase": "small_norb_image_recognition_problem"}, {"score": 0.0021049977753042253, "phrase": "lighting_labels"}], "paper_keywords": ["autoencoder", " gaussian process", " gaussian process latent variable model", " representation learning", " unsupervised learning"], "paper_abstract": "While unsupervised learning has long been useful for density modeling, exploratory data analysis and visualization, it has become increasingly important for discovering features that will later be used for discriminative tasks. Discriminative algorithms often work best with highly-informative features; remarkably, such features can often be learned without the labels. One particularly effective way to perform such unsupervised learning has been to use autoencoder neural networks, which find latent representations that are constrained but nevertheless informative for reconstruction. However, pure unsupervised learning with autoencoders can find representations that may or may not be useful for the ultimate discriminative task. It is a continuing challenge to guide the training of an autoencoder so that it finds features which will be useful for predicting labels. Similarly, we often have a priori information regarding what statistical variation will be irrelevant to the ultimate discriminative task, and we would like to be able to use this for guidance as well. Although a typical strategy would be to include a parametric discriminative model as part of the autoencoder training, here we propose a nonparametric approach that uses a Gaussian process to guide the representation. By using a nonparametric model, we can ensure that a useful discriminative function exists for a given set of features, without explicitly instantiating it. We demonstrate the superiority of this guidance mechanism on four data sets, including a real- world application to rehabilitation research. We also show how our proposed approach can learn to explicitly ignore statistically significant covariate information that is label-irrelevant, by evaluating on the small NORB image recognition problem in which pose and lighting labels are available.", "paper_title": "Nonparametric Guidance of Autoencoder Representations using Label Information", "paper_id": "WOS:000309580600003"}