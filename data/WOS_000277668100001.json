{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "automated_creation"}, {"score": 0.00476323161560059, "phrase": "tactile_facial_images"}, {"score": 0.004712065638657606, "phrase": "portrait_photos"}, {"score": 0.004561826854638056, "phrase": "important_social_and_emotional_roles"}, {"score": 0.00436890075128947, "phrase": "visual_media"}, {"score": 0.004206767038617782, "phrase": "visual_impairment"}, {"score": 0.004072573194988867, "phrase": "systematic_approach"}, {"score": 0.003985487777785535, "phrase": "human_facial_images"}, {"score": 0.003921393143378986, "phrase": "tactile_form"}, {"score": 0.003775803846431323, "phrase": "tactile_printer"}, {"score": 0.003519561814102764, "phrase": "deformable_bayesian_active_shape_model"}, {"score": 0.0033888405252810927, "phrase": "anthropometric_priors"}, {"score": 0.0032278559855285945, "phrase": "face_dataset"}, {"score": 0.0031417377608722, "phrase": "inference_algorithm"}, {"score": 0.0030414140732789186, "phrase": "new_face_images"}, {"score": 0.0029763124376934813, "phrase": "input-adaptive_face_sketch"}, {"score": 0.0028348690177346448, "phrase": "input-specific_details"}, {"score": 0.0028043588777213533, "phrase": "semantic-aware_processing"}, {"score": 0.002656650588033728, "phrase": "face_alignment"}, {"score": 0.002613870237087035, "phrase": "proposed_method"}, {"score": 0.0023970487263732737, "phrase": "subjective_evaluations"}, {"score": 0.00235843888868088, "phrase": "produced_tactile_face_images"}, {"score": 0.0022830706430588482, "phrase": "six_visually-impaired_users"}, {"score": 0.002198173002125909, "phrase": "proposed_approach"}, {"score": 0.0021394674440767124, "phrase": "vital_visual_information"}, {"score": 0.0021049977753042253, "phrase": "face_image"}], "paper_keywords": ["Image matching", " image shape analysis", " pattern recognition", " tactile graphics"], "paper_abstract": "Portrait photos (facial images) play important social and emotional roles in our life. This type of visual media is unfortunately inaccessible by users with visual impairment. This paper proposes a systematic approach for automatically converting human facial images into a tactile form that can be printed on a tactile printer and explored by a user who is blind. We propose a deformable Bayesian Active Shape Model (BASM), which integrates anthropometric priors with shape and appearance information learnt from a face dataset. We design an inference algorithm under this model for processing new face images to create an input-adaptive face sketch. Further, the model is enhanced by input-specific details through semantic-aware processing. We report experiments on evaluating the accuracy of face alignment using the proposed method, with comparison with other state-of-the-art results. Furthermore, subjective evaluations of the produced tactile face images were performed by 17 persons including six visually-impaired users, confirming the effectiveness of the proposed approach in conveying via haptics vital visual information in a face image.", "paper_title": "A Bayesian Approach to Automated Creation of Tactile Facial Images", "paper_id": "WOS:000277668100001"}