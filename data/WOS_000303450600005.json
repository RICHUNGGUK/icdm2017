{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "novel_mechanism"}, {"score": 0.004737579882204798, "phrase": "enhanced_gaze_estimation"}, {"score": 0.004345363360869553, "phrase": "prior_knowledge"}, {"score": 0.004116823963855969, "phrase": "computer_screen"}, {"score": 0.003985487777785535, "phrase": "probability_map"}, {"score": 0.0036159990127332315, "phrase": "proposed_system"}, {"score": 0.0033888405252810927, "phrase": "gaze_estimation_device"}, {"score": 0.0033163269450817716, "phrase": "saliency_framework"}, {"score": 0.003245359940011418, "phrase": "resulting_gaze_point_vector"}, {"score": 0.003057910095857785, "phrase": "tracking_data"}, {"score": 0.002992456421856031, "phrase": "low_accuracy_webcam_based_eye_tracker"}, {"score": 0.0029126002350975634, "phrase": "head_pose_tracker"}, {"score": 0.0027741761880779535, "phrase": "commercial_eye"}, {"score": 0.0025578967205807843, "phrase": "low_accuracy_eye_gaze_tracker"}, {"score": 0.0021049977753042253, "phrase": "different_visual_gaze_estimation_systems"}], "paper_keywords": ["HCI", " Gaze estimation", " Saliency", " Head pose", " Eye location"], "paper_abstract": "In this paper we present a novel mechanism to obtain enhanced gaze estimation for subjects looking at a scene or an image. The system makes use of prior knowledge about the scene (e.g. an image on a computer screen), to define a probability map of the scene the subject is gazing at, in order to find the most probable location. The proposed system helps in correcting the fixations which are erroneously estimated by the gaze estimation device by employing a saliency framework to adjust the resulting gaze point vector. The system is tested on three scenarios: using eye tracking data, enhancing a low accuracy webcam based eye tracker, and using a head pose tracker. The correlation between the subjects in the commercial eye tracking data is improved by an average of 13.91%. The correlation on the low accuracy eye gaze tracker is improved by 59.85%, and for the head pose tracker we obtain an improvement of 10.23%. These results show the potential of the system as a way to enhance and self-calibrate different visual gaze estimation systems.", "paper_title": "What Are You Looking at?", "paper_id": "WOS:000303450600005"}