{"auto_keywords": [{"score": 0.03135485784204427, "phrase": "rap_algorithm"}, {"score": 0.00481495049065317, "phrase": "fine-grained_many-cores"}, {"score": 0.004662622277282557, "phrase": "order_processors"}, {"score": 0.004486147558765763, "phrase": "execution_window_place"}, {"score": 0.004428812979024961, "phrase": "memory_level_parallelism"}, {"score": 0.004302463542835521, "phrase": "shared_parallel_caches"}, {"score": 0.0042611497796259026, "phrase": "mlp_demand"}, {"score": 0.004233826962599848, "phrase": "current_cache_hierarchies"}, {"score": 0.004060432002446197, "phrase": "modern_designs"}, {"score": 0.003931879808909078, "phrase": "recent_highly_parallel_architectures"}, {"score": 0.0037586895199831095, "phrase": "numerous_lighter_cores"}, {"score": 0.0036631824752208753, "phrase": "mlp"}, {"score": 0.0036279606700393794, "phrase": "per-core_basis"}, {"score": 0.003524377837382856, "phrase": "mlp_pressure"}, {"score": 0.003468110711566472, "phrase": "multiple_memory_requests"}, {"score": 0.0034458553242115073, "phrase": "existing_computation"}, {"score": 0.0032309820601312787, "phrase": "simultaneous_prefetches"}, {"score": 0.0030885689801303123, "phrase": "gcc-derived_compiler"}, {"score": 0.0030294669203999565, "phrase": "emerging_fine-grained_many-core_architecture"}, {"score": 0.002933458667525067, "phrase": "well-known_loop"}, {"score": 0.002813169398244266, "phrase": "state-of-the_art_gcc_implementation"}, {"score": 0.0027416032255956585, "phrase": "hardware_configuration"}, {"score": 0.002654693503799094, "phrase": "simple_hardware_prefetching_mechanism"}, {"score": 0.0026207039474589, "phrase": "run-time_improvements"}, {"score": 0.0025051226957195634, "phrase": "design-space_exploration"}, {"score": 0.0024571577953004546, "phrase": "considered_target_architecture"}, {"score": 0.002386922774536045, "phrase": "chip_resources"}, {"score": 0.0023639590354685817, "phrase": "per-core_prefetch_storage"}, {"score": 0.0022307321581833918, "phrase": "design_points"}, {"score": 0.0021809687586808522, "phrase": "pareto-optimal_hardware-software_configuration"}, {"score": 0.0021049977753042253, "phrase": "bare-bones_design"}], "paper_keywords": ["Compiler", " Prefetching", " Manycore", " PRAM", " XMT", " Parallel"], "paper_abstract": "Super-scalar, out-of-order processors that can have tens of read and write requests in the execution window place significant demands on Memory Level Parallelism (MLP). Multi- and many-cores with shared parallel caches further increase MLP demand. Current cache hierarchies however have been unable to keep up with this trend, with modern designs allowing only 4-16 concurrent cache misses. This disconnect is exacerbated by recent highly parallel architectures (e.g. GPUs) where power and area per-core budget favor numerous lighter cores with less resources, further reducing support for MLP on a per-core basis. Support for hardware and software prefetch increases MLP pressure since these techniques overlap multiple memory requests with existing computation. In this paper, we propose and evaluate a novel Resource-Aware Prefetching (RAP) compiler algorithm that is aware of the number of simultaneous prefetches supported, and optimized for the same. We implemented our algorithm in a GCC-derived compiler and evaluated its performance using an emerging fine-grained many-core architecture. Our results show that the RAP algorithm outperforms a well-known loop prefetching algorithm by up to 40.15% in run-time on average across benchmarks and the state-of-the art GCC implementation by up to 34.79%, depending upon hardware configuration. Moreover, we compare the RAP algorithm with a simple hardware prefetching mechanism, and show run-time improvements of up to 24.61%. To demonstrate the robustness of our approach, we conduct a design-space exploration (DSE) for the considered target architecture by varying (i) the amount of chip resources designated for per-core prefetch storage and (ii) off-chip bandwidth. We show that the RAP algorithm is robust in that it improves performance across all design points considered. We also identify the Pareto-optimal hardware-software configuration which delivers 53.66% run-time improvement on average while using only 5.47% more chip area than the bare-bones design.", "paper_title": "Resource-Aware Compiler Prefetching for Fine-Grained Many-Cores", "paper_id": "WOS:000291043700005"}