{"auto_keywords": [{"score": 0.02246846748295755, "phrase": "kalman"}, {"score": 0.00481495049065317, "phrase": "multi-modal_data_fusion"}, {"score": 0.004651271219032404, "phrase": "autonomous_navigation"}, {"score": 0.004597951649247307, "phrase": "mobile_robot"}, {"score": 0.004441616106463486, "phrase": "proper_state_estimation"}, {"score": 0.00427410962921379, "phrase": "multi-modal_data_fusion_algorithm"}, {"score": 0.004081385289516914, "phrase": "general_localization_problem"}, {"score": 0.004034572092608487, "phrase": "urban_search"}, {"score": 0.004003660777805554, "phrase": "rescue_environment"}, {"score": 0.003957735532719663, "phrase": "different_sensory_modalities"}, {"score": 0.0038973170902076707, "phrase": "different_nature"}, {"score": 0.0035673211706948576, "phrase": "common_practice"}, {"score": 0.003512841739654183, "phrase": "ekf-based_solutions"}, {"score": 0.0034326732528567826, "phrase": "standard_statistical_test"}, {"score": 0.0032777653153451265, "phrase": "anomalous_data"}, {"score": 0.00322769360059123, "phrase": "filter_performance"}, {"score": 0.003070166825722112, "phrase": "well_visual_and_laser_anomalous_residuals"}, {"score": 0.0030232568024943455, "phrase": "multi-modal_data_fusion_systems"}, {"score": 0.0029656229252935417, "phrase": "incoming_observations"}, {"score": 0.0027777389949155975, "phrase": "actual_anomalies"}, {"score": 0.0025917270871556475, "phrase": "standard_statistical_tests"}, {"score": 0.0025619562094446884, "phrase": "different_state-of-the-art_machine"}, {"score": 0.0024368411484675823, "phrase": "robotics_community"}, {"score": 0.002326767693352058, "phrase": "precise_reference"}, {"score": 0.00230003335593664, "phrase": "vicon_system"}, {"score": 0.0022388390432214415, "phrase": "outdoor_environment"}], "paper_keywords": ["Localization", " Kalman filter", " Multi-modal data fusion", " Anomaly detection", " Mobile robots"], "paper_abstract": "If we aim for autonomous navigation of a mobile robot, it is crucial and essential to have proper state estimation of its position and orientation. We already designed a multi-modal data fusion algorithm that combines visual, laser-based, inertial, and odometric modalities in order to achieve robust solution to a general localization problem in challenging Urban Search and Rescue environment. Since different sensory modalities are prone to different nature of errors, and their reliability varies vastly as the environment changes dynamically, we investigated further means of improving the localization. The common practice related to the EKF-based solutions such as ours is a standard statistical test of the observations-or of its corresponding filter residuals-performed to reject anomalous data that deteriorate the filter performance. In this paper we show how important it is to treat well visual and laser anomalous residuals, especially in multi-modal data fusion systems where the frequency of incoming observations varies significantly across the modalities. In practice, the most complicated part is to correctly identify the actual anomalies, which are to be rejected, and therefore here lies our major contribution. We go beyond the standard statistical tests by exploring different state-of-the-art machine learning approaches and exploiting our rich dataset that we share with the robotics community. We demonstrate the implications of our research both indoor (with precise reference from a Vicon system) as well as in challenging outdoor environment. In the final, we prove that monitoring the health of the observations in Kalman filtering is something, that is often overlooked, however, it definitively should not be.", "paper_title": "Improving multi-modal data fusion by anomaly detection", "paper_id": "WOS:000357652400002"}