{"auto_keywords": [{"score": 0.032226660433101705, "phrase": "two-part_codes"}, {"score": 0.030074948199064692, "phrase": "kt"}, {"score": 0.00481495049065317, "phrase": "mdl_principle"}, {"score": 0.00471811808206897, "phrase": "large_alphabets"}, {"score": 0.004394218564523274, "phrase": "source_alphabet"}, {"score": 0.004176509019758331, "phrase": "compressed_data_sequence_length_n."}, {"score": 0.004092463367307375, "phrase": "rissanen's_strongest_sense"}, {"score": 0.004023713505078134, "phrase": "fixed-size_alphabets"}, {"score": 0.003916098498242888, "phrase": "alphabet_size"}, {"score": 0.0034428109010424175, "phrase": "code_bits"}, {"score": 0.0034079696245884073, "phrase": "unknown_parameter"}, {"score": 0.0032389643666649094, "phrase": "maximin_senses"}, {"score": 0.0031737251921267725, "phrase": "almost_every_source"}, {"score": 0.0028569549040495163, "phrase": "well-known_krichevsky-trofimov"}, {"score": 0.0028184476518849015, "phrase": "low-complexity_sequential_probability_estimates"}, {"score": 0.002660482980203146, "phrase": "average_minimax"}, {"score": 0.0025630077791393125, "phrase": "first_order"}, {"score": 0.0023867021254922755, "phrase": "sequential_modification"}, {"score": 0.0022074592164608134, "phrase": "sequential_codes"}, {"score": 0.0021776870246727233, "phrase": "coding_sequences"}, {"score": 0.0021049977753042253, "phrase": "alphabet_symbols"}], "paper_keywords": ["independent and identically distributed (i.i.d.) sources", " maximin redundancy", " minimax redundancy", " minimum description length (MDL)", " redundancy", " redundancy for most sources", " redundancy-capacity theorem", " sequential codes", " universal coding"], "paper_abstract": "Average case universal compression of independent and identically distributed (i.i.d.) sources is investigated, where the source alphabet is large, and may be sublinear in size or even larger than the compressed data sequence length n. In particular, the well-known results, including Rissanen's strongest sense lower bound, for fixed-size alphabets are extended to the case where the alphabet size k is allowed to grow with n. It is shown that as long as k = o(n), instead of the coding cost in the fixed-size alphabet case of 0.5 log n extra code bits for each one of the k - I unknown probability parameters, the cost is now 0.5 log(n/k) code bits for each unknown parameter. This result is shown to be the lower bound in the minimax and maximin senses, as well as for almost every source in the class. Achievability of this bound is demonstrated with two-part codes based on quantization of the maximum-likelihood (ML) probability parameters, as well as by using the well-known Krichevsky-Trofimov (KT) low-complexity sequential probability estimates. For very large alphabets, k >> n, it is shown that an average minimax and maximin bound on the redundancy is essentially (to first order) log(k/n) bits per symbol. This bound is shown to be achievable both with two-part codes and with a sequential modification of the KT estimates. For k = Theta(n), the redundancy is Theta(1) bits per symbol. Finally, sequential codes are designed for coding sequences in which only m < min{k, n} alphabet symbols occur.", "paper_title": "On the MDL principle for i.i.d. sources with large alphabets", "paper_id": "WOS:000237147400009"}