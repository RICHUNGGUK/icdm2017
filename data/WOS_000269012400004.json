{"auto_keywords": [{"score": 0.04199668928862169, "phrase": "critical_tasks"}, {"score": 0.03676980026117848, "phrase": "design_time"}, {"score": 0.02340798264375971, "phrase": "shared_cache"}, {"score": 0.00481495049065317, "phrase": "dynamic_cache_management"}, {"score": 0.004774937143916685, "phrase": "embedded_chip_multiprocessors"}, {"score": 0.004656871909510407, "phrase": "dynamic_cache"}, {"score": 0.004485200522202792, "phrase": "media_applications"}, {"score": 0.004447915226010682, "phrase": "multiple_utilization_scenarios"}, {"score": 0.0038112201846057445, "phrase": "performance_penalty"}, {"score": 0.0034476484413811987, "phrase": "cache_footprint"}, {"score": 0.003279039724748895, "phrase": "critical_tasks_safety"}, {"score": 0.0030160945545795468, "phrase": "cache_footprints"}, {"score": 0.002953711377604328, "phrase": "flush_penalty"}, {"score": 0.0027974705482714884, "phrase": "experimental_workload"}, {"score": 0.002682917193736698, "phrase": "multiple_tasks"}, {"score": 0.0026384167183586015, "phrase": "extended_mediabench_suite"}, {"score": 0.002509284173541882, "phrase": "relative_variations"}, {"score": 0.002477998427152547, "phrase": "execution_time"}, {"score": 0.002327310963701377, "phrase": "realistic_scenario_switching_frequencies"}, {"score": 0.0023079225317714793, "phrase": "inter-task_cache_interference"}, {"score": 0.0022413233627905696, "phrase": "repartitioned_cache"}, {"score": 0.0021049977753042253, "phrase": "off-chip_memory_traffic"}], "paper_keywords": ["Multiprocessor", " Cache management", " Compositionality", " Predictability"], "paper_abstract": "This paper proposes a dynamic cache repartitioning technique that enhances compositionality on platforms executing media applications with multiple utilization scenarios. Because the repartitioning between scenarios requires a cache flush, two undesired effects may occur: (1) in particular, the execution of critical tasks may be disturbed and (2) in general, a performance penalty is involved. To cope with these effects we propose a method which: (1) determines, at design time, the cache footprint of each tasks, such that it creates the premises for critical tasks safety, and minimum flush in general, and (2) enforces, at run-time, the design time determined cache footprints and further decreases the flush penalty. We implement our dynamic cache management strategy on a CAKE multiprocessor with 4 Trimedia cores. The experimental workload consists of 6 multimedia applications, each of which formed by multiple tasks belonging to an extended MediaBench suite. We found on average that: (1) the relative variations of critical tasks execution time are less than 0.1%, regardless of the scenario switching frequency, (2) for realistic scenario switching frequencies the inter-task cache interference is at most 4% for the repartitioned cache, whereas for the shared cache it reaches 68%, and (3) the off-chip memory traffic reduces with 60%, and the performance (in cycles per instruction) enhances with 10%, when compared with the shared cache.", "paper_title": "Compositional, Dynamic Cache Management for Embedded Chip Multiprocessors", "paper_id": "WOS:000269012400004"}