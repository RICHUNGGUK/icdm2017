{"auto_keywords": [{"score": 0.0322430302584721, "phrase": "teaca"}, {"score": 0.010612387000973441, "phrase": "thread_progress_aware_coherence_adaption"}, {"score": 0.004925077682000568, "phrase": "application_execution_time"}, {"score": 0.004621279527317074, "phrase": "chip_multiprocessor_systems"}, {"score": 0.004435363840720883, "phrase": "shared_resources"}, {"score": 0.004367581653370531, "phrase": "on-chip_caches"}, {"score": 0.004278807087784626, "phrase": "unbalanced_progress"}, {"score": 0.004127753467337283, "phrase": "inherent_synchronization_primitives"}, {"score": 0.003921129887153952, "phrase": "fast_threads"}, {"score": 0.0038413947966606118, "phrase": "precious_cycles"}, {"score": 0.003724810609448597, "phrase": "slow_progress"}, {"score": 0.0035932440062595252, "phrase": "energy_inefficiency"}, {"score": 0.003413284742632989, "phrase": "energy_consumption"}, {"score": 0.003275807170434343, "phrase": "cache_coherence_policy"}, {"score": 0.002971016979295967, "phrase": "thread_progress_information"}, {"score": 0.0028076592725295646, "phrase": "memory_system_statistics"}, {"score": 0.0026532596852754525, "phrase": "estimated_thread_progress_information"}, {"score": 0.0025726416100664853, "phrase": "leader_threads"}, {"score": 0.002546315584783112, "phrase": "laggard_threads"}, {"score": 0.00250732953434891, "phrase": "thread_categorization_decisions"}, {"score": 0.002443671484766342, "phrase": "efficient_coherence_adaption"}, {"score": 0.0024186620196958867, "phrase": "cmp_systems"}, {"score": 0.002393907896783117, "phrase": "hybrid_coherence_protocols"}, {"score": 0.0023694065215394593, "phrase": "experimental_results"}, {"score": 0.002250601866422547, "phrase": "directory_protocol"}, {"score": 0.0021049977753042253, "phrase": "energy_dissipation"}], "paper_keywords": ["Cache coherence", " coherence protocol", " chip multiprocessor system", " parallel application", " energy efficiency"], "paper_abstract": "For chip multiprocessor systems (CMPs), the interference on shared resources such as on-chip caches typically leads to unbalanced progress among threads. Because of the inherent synchronization primitives, such as barriers and locks, cores running fast threads have to waste precious cycles to wait for cores with slow progress, which leads to performance and energy inefficiency. For the purpose of improving performance and reducing energy consumption, this paper proposes to adapt the cache coherence policy for threads according to their delay-tolerant levels. Specifically, this paper proposes Thread progrEss Aware Coherence Adaption (TEACA) which utilizes the thread progress information as hints for coherence adaption. TEACA dynamically utilize the memory system statistics to estimate the progress of threads. Based on the estimated thread progress information, TEACA categorizes threads into leader threads and laggard threads. The thread categorization decisions are then leveraged for efficient coherence adaption on CMP systems supporting hybrid coherence protocols. Experimental results show that, on a 64-core CMP system, TEACA outperforms directory protocol in application execution time and a recently proposed hybrid protocol in both application execution time and energy dissipation.", "paper_title": "Thread Progress Aware Coherence Adaption for Hybrid Cache Coherence Protocols", "paper_id": "WOS:000342179600020"}