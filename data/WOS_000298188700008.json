{"auto_keywords": [{"score": 0.032630281276040125, "phrase": "cca"}, {"score": 0.00481495049065317, "phrase": "robust_co-training._co-training"}, {"score": 0.004733347359490221, "phrase": "multiview_semi-supervised_learning_algorithm"}, {"score": 0.004600389726895716, "phrase": "labeled_and_unlabeled_data"}, {"score": 0.004199406257273994, "phrase": "confident_predictions"}, {"score": 0.004128192012388041, "phrase": "unlabeled_examples"}, {"score": 0.003559284776569813, "phrase": "even_very_few_inaccurately_labeled_examples"}, {"score": 0.0034395119150793787, "phrase": "learned_classifiers"}, {"score": 0.0033811403330431897, "phrase": "large_extent"}, {"score": 0.0032487508969192293, "phrase": "new_method"}, {"score": 0.0032302647179383915, "phrase": "named_robust_co-training"}, {"score": 0.0031215289677725693, "phrase": "canonical_correlation_analysis"}, {"score": 0.002881793492919646, "phrase": "unlabeled_training_examples"}, {"score": 0.002753138528582461, "phrase": "low-dimensional_and_closely_correlated_representation"}, {"score": 0.002527150892127982, "phrase": "unlabeled_example"}, {"score": 0.0024842242921857705, "phrase": "original_labeled_examples"}, {"score": 0.0023196699954340437, "phrase": "cca_examination"}, {"score": 0.00224151735457093, "phrase": "original_labeled_data"}, {"score": 0.0021784009230363627, "phrase": "robust_co-training"}, {"score": 0.0021049977753042253, "phrase": "encouraging_experimental_results"}], "paper_keywords": ["Canonical correlation analysis (CCA)", " multiview learning", " semi-supervised learning", " web-page classification", " advertisement classification", " handwritten digit recognition"], "paper_abstract": "Co-training is a multiview semi-supervised learning algorithm to learn from both labeled and unlabeled data, which iteratively adopts a classifier trained on one view to teach the other view using some confident predictions given on unlabeled examples. However, as it does not examine the reliability of the labels provided by classifiers on either view, co-training might be problematic. Even very few inaccurately labeled examples can deteriorate the performance of learned classifiers to a large extent. In this paper, a new method named robust co-training is proposed, which integrates canonical correlation analysis (CCA) to inspect the predictions of co-training on those unlabeled training examples. CCA is applied to obtain a low-dimensional and closely correlated representation of the original multiview data. Based on this representation the similarities between an unlabeled example and the original labeled examples are determined. Only those examples whose predicted labels are consistent with the outcome of CCA examination are eligible to augment the original labeled data. The performance of robust co-training is evaluated on several different classification problems where encouraging experimental results are observed.", "paper_title": "ROBUST CO-TRAINING", "paper_id": "WOS:000298188700008"}