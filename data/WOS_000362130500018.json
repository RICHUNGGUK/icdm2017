{"auto_keywords": [{"score": 0.031598478638872954, "phrase": "large_environments"}, {"score": 0.00481495049065317, "phrase": "mobile_robot"}, {"score": 0.004763565662615503, "phrase": "euclidean_data_difference_dimension_reduction"}, {"score": 0.0045879792359519375, "phrase": "novel_method"}, {"score": 0.004539005582217309, "phrase": "mobile_robot_map_representation"}, {"score": 0.004371660146981191, "phrase": "manifold_based_map"}, {"score": 0.004210458358142504, "phrase": "color_histogram"}, {"score": 0.004165497627464024, "phrase": "omni-directional_camera_images"}, {"score": 0.00409895142748329, "phrase": "low_dimensional_space"}, {"score": 0.0040334640350288, "phrase": "local_and_global_geometry"}, {"score": 0.0038431888954930083, "phrase": "independent_feature_vectors"}, {"score": 0.0037615180375561805, "phrase": "euclidean_data_difference"}, {"score": 0.0035457302646174148, "phrase": "introduced_dimension_reduction_method"}, {"score": 0.0034890505116128606, "phrase": "superior_performance"}, {"score": 0.003433296660872882, "phrase": "lle"}, {"score": 0.003396956425685827, "phrase": "pca"}, {"score": 0.0033602844686125375, "phrase": "benchmark_data_sets"}, {"score": 0.003306559295382181, "phrase": "hard_dimension_reduction"}, {"score": 0.0031845067058084583, "phrase": "mapping_matrix"}, {"score": 0.003100085797251317, "phrase": "real_time_robot_localization"}, {"score": 0.003034158379493625, "phrase": "real_world_experiments"}, {"score": 0.002953711377604328, "phrase": "adjacent_places"}, {"score": 0.0028142286985235977, "phrase": "dimension_reduction"}, {"score": 0.002724909017963099, "phrase": "non-smooth_manifold"}, {"score": 0.002568435291444709, "phrase": "k-means_method"}, {"score": 0.0024339783012484032, "phrase": "obtained_cluster"}, {"score": 0.0023694065215394593, "phrase": "successful_experiments"}, {"score": 0.0022574539115388075, "phrase": "robotic_applications"}, {"score": 0.0021975548867457606, "phrase": "visual_place_classification"}, {"score": 0.002174041708084857, "phrase": "kidnaped-robot_localization"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Mapping", " Dimension reduction", " Mobile robot localization", " Manifold based map"], "paper_abstract": "In this paper, a novel method for mobile robot map representation is presented. We introduce a manifold based map which is constructed by mapping the color histogram of omni-directional camera images into a low dimensional space while preserving local and global geometry. The geometry is preserved using orthogonal and independent feature vectors consisting of the Euclidean data difference and the nearest and farthest neighbor data vectors. The introduced dimension reduction method has shown superior performance compared to LLE and PCA in benchmark data sets providing a hard dimension reduction of 768 into 3. This mapping matrix has been used for real time robot localization and mapping in real world experiments. In large environments, adjacent places share the same set of objects and features therefore dimension reduction may end up in a non-smooth manifold. To apply the method in large environments, first a K-Means method is used to cluster the environment and then each obtained cluster is processed separately. Successful experiments on 7 different data sets show effectiveness of this method for robotic applications such as mapping, visual place classification and kidnaped-robot localization. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Manifold based map representation for mobile robot using Euclidean data difference dimension reduction", "paper_id": "WOS:000362130500018"}