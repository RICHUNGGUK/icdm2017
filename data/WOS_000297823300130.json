{"auto_keywords": [{"score": 0.04825016108360528, "phrase": "rsm"}, {"score": 0.010612379340043753, "phrase": "response_surface_methodology"}, {"score": 0.008781399488190083, "phrase": "polynomial_estimation"}, {"score": 0.008594250290111108, "phrase": "feasible_area"}, {"score": 0.004752873752686246, "phrase": "artificial_neural_network"}, {"score": 0.00471193241675062, "phrase": "simulated_annealing"}, {"score": 0.004228839109569368, "phrase": "designed_experiments"}, {"score": 0.004156259296367594, "phrase": "optimal_response"}, {"score": 0.00403221710768334, "phrase": "original_problem"}, {"score": 0.003945879572348638, "phrase": "small_sections"}, {"score": 0.003828091961373454, "phrase": "optimum_provision"}, {"score": 0.0037786899855446, "phrase": "well_known_optimization_technique"}, {"score": 0.0037299231609021783, "phrase": "gradient_method"}, {"score": 0.003665874747419775, "phrase": "real_world_problems"}, {"score": 0.003450213580299164, "phrase": "good_representation"}, {"score": 0.003405671497507337, "phrase": "objective_function"}, {"score": 0.003332704619499476, "phrase": "main_problem"}, {"score": 0.0028390477456009568, "phrase": "neural_networks"}, {"score": 0.0026951616152303373, "phrase": "rsm_context"}, {"score": 0.002449997042686432, "phrase": "estimated_objective_function"}, {"score": 0.0024078737745407614, "phrase": "suitable_point"}, {"score": 0.0023664730217196252, "phrase": "different_complexities"}, {"score": 0.0022562464662197867, "phrase": "proposed_method"}, {"score": 0.002227083991228041, "phrase": "comparison_results"}, {"score": 0.002188784900536406, "phrase": "proposed_algorithm"}, {"score": 0.0021604924928015283, "phrase": "classical_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Response surface methodology", " Simulated annealing", " Artificial neural networks"], "paper_abstract": "Response surface methodology (RSM) explores the relationships between several explanatory variables and one or more response variables. The main idea of RSM is to use a set of designed experiments to obtain an optimal response. RSM tries to simplify the original problem through some polynomial estimation over small sections of the feasible area, elaborating on optimum provision through a well known optimization technique, say Gradient Method. As the real world problems are usually very complicated, polynomial estimation may not perform well in providing a good representation of the objective function. Also, the main problem of the Gradient Method, getting trapped in local minimum (maximum), makes RSM at a disadvantage, while defining sub-sections of the feasible area is also a problem faced by analyst. In this article, neural networks are used as a means to improve the estimation in the RSM context. This approach leads to reducing the calculations. Furthermore, it is proposed to use simulated annealing in maximizing the estimated objective function in reaching a suitable point. Three examples of different complexities are solved to shed light on the merits of the proposed method. The comparison results indicate that the proposed algorithm outperforms the classical method. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Improving response surface methodology by using artificial neural network and simulated annealing", "paper_id": "WOS:000297823300130"}