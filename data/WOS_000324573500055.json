{"auto_keywords": [{"score": 0.04773866258910522, "phrase": "approximation_error"}, {"score": 0.04683209630512588, "phrase": "nystrom_method"}, {"score": 0.0409303070249204, "phrase": "random_matrix_theory"}, {"score": 0.029420333683948783, "phrase": "kernel_matrix"}, {"score": 0.028992395857802566, "phrase": "p-power_law"}, {"score": 0.00476697427418509, "phrase": "kernel_classification"}, {"score": 0.004399905285945236, "phrase": "positive_semidefinite"}, {"score": 0.004227064760262924, "phrase": "small_set"}, {"score": 0.004060986196931943, "phrase": "concentration_inequality"}, {"score": 0.004020492138367616, "phrase": "integral_operators"}, {"score": 0.0036921366375716005, "phrase": "spectral_norm"}, {"score": 0.003407549468745519, "phrase": "large_eigengap"}, {"score": 0.003306559295382181, "phrase": "total_number"}, {"score": 0.00327356326590461, "phrase": "data_points"}, {"score": 0.0031606404966938568, "phrase": "sampled_data_points"}, {"score": 0.002931569771634119, "phrase": "positive_constant"}, {"score": 0.0025473475682739784, "phrase": "incoherence_assumption"}, {"score": 0.0024842242921857705, "phrase": "kernel_classification_approach"}, {"score": 0.002362620540317279, "phrase": "improved_bound"}, {"score": 0.0021262403223013242, "phrase": "support_vectors"}], "paper_keywords": ["Approximation error", " concentration inequality", " kernel methods", " Nystrom method", " random matrix theory"], "paper_abstract": "We develop two approaches for analyzing the approximation error bound for the Nystrom method that approximates a positive semidefinite (PSD) matrix by sampling a small set of columns, one based on a concentration inequality for integral operators, and one based on random matrix theory. We show that the approximation error, measured in the spectral norm, can be improved from O(N/root m) to O(N/m(1-rho)) in the case of large eigengap, where N is the total number of data points, m is the number of sampled data points, and rho is an element of (0, 1/2) is a positive constant that characterizes the eigengap. When the eigenvalues of the kernel matrix follow a p-power law, our analysis based on random matrix theory further improves the bound to O(N/m(p-1))under an incoherence assumption. We present a kernel classification approach based on the Nystrom method and derive its generalization performance using the improved bound. We show that when the eigenvalues of the kernel matrix follow a p-power law, we can reduce the number of support vectors to N-2p/(p(2)-1), which is sublinear in N when p > 1 + root 2, without seriously sacrificing its generalization performance.", "paper_title": "Improved Bounds for the Nystrom Method With Application to Kernel Classification", "paper_id": "WOS:000324573500055"}