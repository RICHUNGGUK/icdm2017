{"auto_keywords": [{"score": 0.03762781989614991, "phrase": "svm_ensembles"}, {"score": 0.03586595380876287, "phrase": "adaboost"}, {"score": 0.00481495049065317, "phrase": "support_vector_machine_ensemble_classifiers"}, {"score": 0.004506968388996092, "phrase": "base_learners"}, {"score": 0.00433645229352341, "phrase": "machine_learning_community"}, {"score": 0.004241914481080374, "phrase": "promising_capabilities"}, {"score": 0.004172360444377281, "phrase": "classification_accuracy"}, {"score": 0.004081385289516914, "phrase": "neural_network"}, {"score": 0.0040366412779632085, "phrase": "decision_tree_ensembles"}, {"score": 0.0039269071382230444, "phrase": "comprehensive_empirical_research"}, {"score": 0.0038838500580958744, "phrase": "support_vector_machine"}, {"score": 0.0036352070472201086, "phrase": "paper_analyses"}, {"score": 0.0032198357970567595, "phrase": "twenty_real-world_data_sets"}, {"score": 0.002931569771634119, "phrase": "svm_ensemble_classifiers"}, {"score": 0.0028675712105299496, "phrase": "different_kernel_functions"}, {"score": 0.0028360962841331634, "phrase": "different_numbers"}, {"score": 0.00280496585980086, "phrase": "base_svm_learners"}, {"score": 0.0026838147966444783, "phrase": "experimental_results"}, {"score": 0.0025257081555100556, "phrase": "single_svm"}, {"score": 0.0024843799663933843, "phrase": "svm"}, {"score": 0.0024569466759289055, "phrase": "ensemble_performs"}, {"score": 0.002337848196418384, "phrase": "relatively_higher_generality"}, {"score": 0.002261666793030715, "phrase": "polynomial_kernel_function"}, {"score": 0.002200077887697072, "phrase": "industrial_case_study"}, {"score": 0.002175913488493802, "phrase": "gear_defect_detection"}, {"score": 0.0021049977753042253, "phrase": "empirical_analysis_results"}], "paper_keywords": ["Ensemble classification", " Support vector machines (SVMs)", " AdaBoost", " Bagging"], "paper_abstract": "Ensemble classification - combining the results of a set of base learners - has received much attention in the machine learning community and has demonstrated promising capabilities in improving classification accuracy. Compared with neural network or decision tree ensembles, there is no comprehensive empirical research in support vector machine (SVM) ensembles. To fill this void, this paper analyses and compares SVM ensembles with four different ensemble constructing techniques, namely bagging, AdaBoost, Arc-X4 and a modified AdaBoost. Twenty real-world data sets from the UCI repository are used as benchmarks to evaluate and compare the performance of these SVM ensemble classifiers by their classification accuracy. Different kernel functions and different numbers of base SVM learners are tested in the ensembles. The experimental results show that although SVM ensembles are not always better than a single SVM, the SVM bagged ensemble performs as well or better than other methods with a relatively higher generality, particularly SVMs with a polynomial kernel function. Finally, an industrial case study of gear defect detection is conducted to validate the empirical analysis results. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "Empirical analysis of support vector machine ensemble classifiers", "paper_id": "WOS:000263817100088"}