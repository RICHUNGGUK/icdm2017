{"auto_keywords": [{"score": 0.04883686163654379, "phrase": "recorded_call"}, {"score": 0.004815006269869078, "phrase": "blind"}, {"score": 0.004654931049193343, "phrase": "mel-frequency"}, {"score": 0.004517137548648729, "phrase": "speech_recordings"}, {"score": 0.004237666411136617, "phrase": "recording_device"}, {"score": 0.004066076430818046, "phrase": "intrinsic_artifacts"}, {"score": 0.0038576618286586387, "phrase": "source_mobile_device"}, {"score": 0.003701401653850141, "phrase": "mfcc_features"}, {"score": 0.0036324746826127997, "phrase": "speech_contents"}, {"score": 0.0036052633308076933, "phrase": "speaker's_characteristics"}, {"score": 0.003511613254403125, "phrase": "device-based_technique"}, {"score": 0.0034203874753429113, "phrase": "source_transmission_devices"}, {"score": 0.0031965070898750912, "phrase": "mel-cepstrum_coefficients"}, {"score": 0.0031606404966938568, "phrase": "intrinsic_mobile_device_features"}, {"score": 0.003136952589428254, "phrase": "near-silent_segments"}, {"score": 0.003021141590548526, "phrase": "different_speakers"}, {"score": 0.002987236799291296, "phrase": "proposed_features"}, {"score": 0.002942619810718864, "phrase": "five_different_combinations"}, {"score": 0.002920561105784389, "phrase": "statistical_moments"}, {"score": 0.002833962854197749, "phrase": "standard_deviation"}, {"score": 0.002708843102301451, "phrase": "feature_sets"}, {"score": 0.0026583500966092044, "phrase": "five_supervised_learning_techniques"}, {"score": 0.002570520019509534, "phrase": "bayesian"}, {"score": 0.0023566987138026285, "phrase": "probabilistic-based_and_nearest-neighbor-based_algorithms"}, {"score": 0.0021857667493036786, "phrase": "naive_bayesian_classifier"}, {"score": 0.0021369416775353107, "phrase": "average_accuracy"}], "paper_keywords": ["Pattern recognition", " Mel-frequency cepstrum coefficient", " Entropy", " Device-based detection technique"], "paper_abstract": "Mel-frequency cepstrum coefficients (MFCCs) extracted from speech recordings has been proven to be the most effective feature set to capture the frequency spectra produced by a recording device. This paper claims that audio evidence such as a recorded call contains intrinsic artifacts at both transmitting and receiving ends. These artifacts allow recognition of the source mobile device on the other end through recording the call. However, MFCC features are contextualized by the speech contents, speaker's characteristics and environments. Thus, a device-based technique needs to consider the identification of source transmission devices and improve the robustness of MFCCs. This paper aims to investigate the use of entropy of Mel-cepstrum coefficients to extract intrinsic mobile device features from near-silent segments, where it remains robust to the characteristics of different speakers. The proposed features are compared with five different combinations of statistical moments of MFCCs, including the mean, standard deviation, variance, skewness, and kurtosis of MFCCs. All feature sets are analyzed by using five supervised learning techniques, namely, support vector machine, nave Bayesian, neural network, linear logistic regression, and rotation forest classifier, as well as two unsupervised learning techniques known as probabilistic-based and nearest-neighbor-based algorithms. The experimental results show that the best performance was achieved with entropy-MFCC features that use the naive Bayesian classifier, which resulted in an average accuracy of 99.99% among 21 mobile devices. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Blind source mobile device identification based on recorded call", "paper_id": "WOS:000344430700025"}