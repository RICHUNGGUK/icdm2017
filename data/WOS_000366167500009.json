{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "prism"}, {"score": 0.015301848399182682, "phrase": "mapreduce"}, {"score": 0.004771435352180973, "phrase": "fine-grained_resource-aware_scheduling"}, {"score": 0.00460125407969429, "phrase": "popular_model"}, {"score": 0.004559661374976129, "phrase": "data-intensive_computation"}, {"score": 0.004357245559948974, "phrase": "small_map"}, {"score": 0.004144908086646161, "phrase": "large_number"}, {"score": 0.003978866233891427, "phrase": "running_time"}, {"score": 0.003942877273973905, "phrase": "data-intensive_jobs"}, {"score": 0.00385431710959668, "phrase": "recent_efforts"}, {"score": 0.003802135020791801, "phrase": "resource-efficient_mapreduce_schedulers"}, {"score": 0.003584025547693836, "phrase": "sub-optimal_job_performance"}, {"score": 0.0034560481756572632, "phrase": "highly_varying_resource_requirements"}, {"score": 0.00330246222643051, "phrase": "task-level_schedulers"}, {"score": 0.0032429499567088113, "phrase": "available_resources"}, {"score": 0.0031990183472675377, "phrase": "job_execution_time"}, {"score": 0.002778385486855157, "phrase": "constant_resource_usage_profile"}, {"score": 0.0026913130726432645, "phrase": "phase_level"}, {"score": 0.0025951294037626174, "phrase": "phase-level_scheduling"}, {"score": 0.002548331088496964, "phrase": "resource_usage_variability"}, {"score": 0.002423931101340771, "phrase": "mapreduce_jobs"}, {"score": 0.0023586493263143553, "phrase": "phase-level_scheduling_algorithm"}, {"score": 0.002326669201839705, "phrase": "execution_parallelism_and_resource_utilization"}, {"score": 0.002233301265743633, "phrase": "standard_benchmarks"}, {"score": 0.002193013499219711, "phrase": "high_resource_utilization"}, {"score": 0.0021436720821474973, "phrase": "job_running_time"}, {"score": 0.0021049977753042253, "phrase": "current_hadoop_schedulers"}], "paper_keywords": ["Cloud computing", " MapReduce", " Hadoop", " scheduling", " resource allocation"], "paper_abstract": "MapReduce has become a popular model for data-intensive computation in recent years. By breaking down each job into small map and reduce tasks and executing them in parallel across a large number of machines, MapReduce can significantly reduce the running time of data-intensive jobs. However, despite recent efforts toward designing resource-efficient MapReduce schedulers, existing solutions that focus on scheduling at the task-level still offer sub-optimal job performance. This is because tasks can have highly varying resource requirements during their lifetime, which makes it difficult for task-level schedulers to effectively utilize available resources to reduce job execution time. To address this limitation, we introduce PRISM, a fine-grained resource-aware MapReduce scheduler that divides tasks into phases, where each phase has a constant resource usage profile, and performs scheduling at the phase level. We first demonstrate the importance of phase-level scheduling by showing the resource usage variability within the lifetime of a task using a wide-range of MapReduce jobs. We then present a phase-level scheduling algorithm that improves execution parallelism and resource utilization without introducing stragglers. In a 10-node Hadoop cluster running standard benchmarks, PRISM offers high resource utilization and provides 1.3x improvement in job running time compared to the current Hadoop schedulers.", "paper_title": "PRISM: Fine-Grained Resource-Aware Scheduling for MapReduce", "paper_id": "WOS:000366167500009"}