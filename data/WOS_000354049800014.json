{"auto_keywords": [{"score": 0.05007776289246191, "phrase": "spatial_correlation"}, {"score": 0.04358338931417153, "phrase": "natural_images"}, {"score": 0.03954089128065463, "phrase": "co-occurrence_matrix"}, {"score": 0.026923506720802518, "phrase": "oxford"}, {"score": 0.004772818068176176, "phrase": "visual_object_retrieval"}, {"score": 0.004448705308279165, "phrase": "content-based_image_retrieval"}, {"score": 0.004409782453832227, "phrase": "cbir"}, {"score": 0.004332897530608981, "phrase": "bovw"}, {"score": 0.004201571673071299, "phrase": "visual_words"}, {"score": 0.004074212307838049, "phrase": "generated_visual_words"}, {"score": 0.003985602342418578, "phrase": "corresponding_visual_features"}, {"score": 0.003780692127133743, "phrase": "visual_word"}, {"score": 0.003714748329627737, "phrase": "visual_word_co-occurrence"}, {"score": 0.0036660436272785476, "phrase": "small_affine-invariant_regions"}, {"score": 0.0034018288705284427, "phrase": "novel_high-order_predictor"}, {"score": 0.0033131804981786747, "phrase": "spatially_correlated_visual_words"}, {"score": 0.0032697235411641695, "phrase": "penalty_tree"}, {"score": 0.003007389443770562, "phrase": "co-occurrence_weighting_similarity_measure"}, {"score": 0.0026352496813713292, "phrase": "frequent_co"}, {"score": 0.0025106241866273897, "phrase": "paris_building_datasets"}, {"score": 0.0024559368099486647, "phrase": "imagenet_dataset"}, {"score": 0.0023918783117166326, "phrase": "large-scale_evaluation"}, {"score": 0.0023708980662168547, "phrase": "cross-dataset_evaluations"}, {"score": 0.002339771435910601, "phrase": "oxford_and_paris_datasets"}, {"score": 0.002298902547676131, "phrase": "holidays_datasets"}, {"score": 0.002248816575548875, "phrase": "thorough_experimental_results"}, {"score": 0.0021049977753042253, "phrase": "bovw_model"}], "paper_keywords": ["Algorithms", " Experimentation", " Performance", " BOVW", " spatial correlation", " high-order predictor", " penalty tree", " Co-Cosine", " Co-TFIDF"], "paper_abstract": "Bag-of-visual-words (BOVW)-based image representation has received intense attention in recent years and has improved content-based image retrieval (CBIR) significantly. BOVW does not consider the spatial correlation between visual words in natural images and thus biases the generated visual words toward noise when the corresponding visual features are not stable. This article outlines the construction of a visual word co-occurrence matrix by exploring visual word co-occurrence extracted from small affine-invariant regions in a large collection of natural images. Based on this co-occurrence matrix, we first present a novel high-order predictor to accelerate the generation of spatially correlated visual words and a penalty tree (PTree) to continue generating the words after the prediction. Subsequently, we propose two methods of co-occurrence weighting similarity measure for image ranking: Co-Cosine and Co-TFIDF. These two new schemes down-weight the contributions of the words that are less discriminative because of frequent co-occurrences with other words. We conduct experiments on Oxford and Paris Building datasets, in which the ImageNet dataset is used to implement a large-scale evaluation. Cross-dataset evaluations between the Oxford and Paris datasets and Oxford and Holidays datasets are also provided. Thorough experimental results suggest that our method outperforms the state of the art without adding much additional cost to the BOVW model.", "paper_title": "Exploring Spatial Correlation for Visual Object Retrieval", "paper_id": "WOS:000354049800014"}