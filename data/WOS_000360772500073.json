{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "deep_learning_model"}, {"score": 0.044147786268980686, "phrase": "multiple_documents"}, {"score": 0.0047283116134926645, "phrase": "compositional_process"}, {"score": 0.0045804107341714, "phrase": "key_challenge"}, {"score": 0.004539005582217305, "phrase": "natural_language_processing"}, {"score": 0.004497973025639345, "phrase": "information_retrieval"}, {"score": 0.004457309741979921, "phrase": "extractive_style"}, {"score": 0.004437115547184535, "phrase": "query-oriented_multi-document_summarization"}, {"score": 0.00429828390000229, "phrase": "proper_set"}, {"score": 0.0041637779492720295, "phrase": "pre-given_query"}, {"score": 0.004051828608343507, "phrase": "novel_document_summarization_framework"}, {"score": 0.0038895008852940323, "phrase": "outstanding_extraction_ability"}, {"score": 0.003535489842686145, "phrase": "new_query-oriented_extraction_technique"}, {"score": 0.0033326252993345685, "phrase": "whole_deep_architecture"}, {"score": 0.0032135959043774085, "phrase": "information_loss"}, {"score": 0.0031845067058084583, "phrase": "reconstruction_validation"}, {"score": 0.0030707512751243214, "phrase": "deep_architecture_layer"}, {"score": 0.003015401937358271, "phrase": "dynamic_programming"}, {"score": 0.0026188490199688013, "phrase": "proposed_framework"}, {"score": 0.0025716240685409535, "phrase": "experiment_results"}, {"score": 0.002525248554951453, "phrase": "proposed_method"}, {"score": 0.002502374576203785, "phrase": "state-of-the-art_extractive_summarization_approaches"}, {"score": 0.0024129269611844794, "phrase": "statistical_analysis"}, {"score": 0.002391067964886602, "phrase": "query_words"}, {"score": 0.0023586493263143553, "phrase": "amazon's_mechanical_turk"}, {"score": 0.0022640009579466924, "phrase": "underlying_relationships"}, {"score": 0.0022434880661725493, "phrase": "topic_words"}, {"score": 0.0021632743048552536, "phrase": "summarization_task"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Deep learning", " Query-oriented summarization", " Multi-document", " Neocortex simulation"], "paper_abstract": "Capturing the compositional process from words to documents is a key challenge in natural language processing and information retrieval: Extractive style query-oriented multi-document summarization generates a summary by extracting a proper set of sentences from multiple documents based on pre-given query. This paper proposes a novel document summarization framework based on deep learning model, which has been shown outstanding extraction ability in many real-world applications. The framework consists of three parts: concepts extraction, summary generation, and reconstruction validation. A new query-oriented extraction technique is proposed to extract information distributed in multiple documents. Then, the whole deep architecture is fine-tuned by minimizing the information loss in reconstruction validation. According to the concepts extracted from deep architecture layer by layer, dynamic programming is used to seek most informative set of sentences for the summary. Experiment on three benchmark datasets (DUC 2005, 2006, and 2007) assess and confirm the effectiveness of the proposed framework and algorithms. Experiment results show that the proposed method outperforms state-of-the-art extractive summarization approaches. Moreover, we also provide the statistical analysis of query words based on Amazon's Mechanical Turk (MTurk) crowdsourcing platform. There exists underlying relationships from topic words to the content which can contribute to summarization task. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Query-oriented unsupervised multi-document summarization via deep learning model", "paper_id": "WOS:000360772500073"}