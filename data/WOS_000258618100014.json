{"auto_keywords": [{"score": 0.04426252329364738, "phrase": "mmp"}, {"score": 0.00481495049065317, "phrase": "dictionary_adaptation"}, {"score": 0.004769182299692333, "phrase": "recurrent_pattern_image_coding"}, {"score": 0.004568525347438891, "phrase": "recently_introduced_coding_algorithm"}, {"score": 0.004293434614435972, "phrase": "traditional_transform"}, {"score": 0.004272969980602508, "phrase": "quantization-based_methods"}, {"score": 0.004192078165260057, "phrase": "approximate_pattern"}, {"score": 0.004132411680987228, "phrase": "adaptive_multiscale_dictionaries"}, {"score": 0.004034841146538891, "phrase": "scaled_versions"}, {"score": 0.003996458454723708, "phrase": "previously_encoded_image_blocks"}, {"score": 0.00386496062825374, "phrase": "predictive_coding_schemes"}, {"score": 0.003791763445590174, "phrase": "source's_probability_distribution"}, {"score": 0.003632080001489739, "phrase": "mmp's_dictionary_adaptation"}, {"score": 0.0034459835582278746, "phrase": "increased_coding_efficiency"}, {"score": 0.0033969001271637964, "phrase": "dictionaries'_symbols"}, {"score": 0.0033645655483989746, "phrase": "new_dictionary_design_methods"}, {"score": 0.00326939082861424, "phrase": "effective_compromise"}, {"score": 0.0031921317979928406, "phrase": "new_dictionary_elements"}, {"score": 0.00311669276800628, "phrase": "codebook_redundancy"}, {"score": 0.0030285084113651035, "phrase": "experimental_results"}, {"score": 0.0029853535424953595, "phrase": "proposed_techniques"}, {"score": 0.002942811795757911, "phrase": "consistent_improvements"}, {"score": 0.0029147869733574844, "phrase": "psnr_performance"}, {"score": 0.002873247913129334, "phrase": "original_mmp_algorithm"}, {"score": 0.0026235360404084137, "phrase": "proposed_algorithm"}, {"score": 0.002598543802992702, "phrase": "relevant_gains"}, {"score": 0.002500927169609655, "phrase": "nonsmooth_images"}, {"score": 0.0024301229420875155, "phrase": "smooth_images"}, {"score": 0.0023388183537341213, "phrase": "new_paradigm"}, {"score": 0.002166349705365602, "phrase": "image_coding"}, {"score": 0.0021252533072727707, "phrase": "wide_range"}, {"score": 0.0021049977753042253, "phrase": "image_types"}], "paper_keywords": ["adaptive pattern matching", " dictionary-based coding", " image coding", " vector quantization"], "paper_abstract": "In this paper, we exploit a recently introduced coding algorithm called multidimensional multiscale parser (MMP) as an alternative to the traditional transform quantization-based methods. MMP uses approximate pattern matching with adaptive multiscale dictionaries that contain concatenations of scaled versions of previously encoded image blocks. We propose the use of predictive coding schemes that modify the source's probability distribution, in order to favour the efficiency of MMP's dictionary adaptation. Statistical conditioning is also used, allowing for an increased coding efficiency of the dictionaries' symbols. New dictionary design methods, that allow for an effective compromise between the introduction of new dictionary elements and the reduction of codebook redundancy, are also proposed. Experimental results validate the proposed techniques by showing consistent improvements in PSNR performance over the original MMP algorithm. When compared with state-of-the-art methods, like IPEG2000 and H.264/AVC, the proposed algorithm achieves relevant gains (up to 6 dB) for nonsmooth images and very competitive results for smooth images. These results strongly suggest that the new paradigm posed by MMP can be regarded as an alternative to the one traditionally used in image coding, for a wide range of image types.", "paper_title": "On dictionary adaptation for recurrent pattern image coding", "paper_id": "WOS:000258618100014"}