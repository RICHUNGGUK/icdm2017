{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "real-time_knowledge-driven_activity_recognition"}, {"score": 0.004573953147933065, "phrase": "substantial_progress"}, {"score": 0.004468415400599571, "phrase": "pervasive_and_mobile_computing"}, {"score": 0.004127394241838696, "phrase": "real-time_continuous_activity_recognition"}, {"score": 0.003884212965525665, "phrase": "novel_approach"}, {"score": 0.003848088904418221, "phrase": "real-time_sensor_data_segmentation"}, {"score": 0.0036382660173943393, "phrase": "dynamic_segmentation_model"}, {"score": 0.0035211747962710246, "phrase": "varied_time_windows"}, {"score": 0.0033919477901198716, "phrase": "segmentation_window_size"}, {"score": 0.0033447157263095223, "phrase": "temporal_information"}, {"score": 0.003313592421224647, "phrase": "sensor_data"}, {"score": 0.0031770714776989282, "phrase": "activity_recognition"}, {"score": 0.0030178044717552605, "phrase": "daily_living"}, {"score": 0.0029618842673339173, "phrase": "segmentation_model"}, {"score": 0.0028799352389969443, "phrase": "wide_range"}, {"score": 0.002853124436286832, "phrase": "activity_recognition_scenarios"}, {"score": 0.002722758109991685, "phrase": "working_mechanism"}, {"score": 0.0026974065918918275, "phrase": "relevant_algorithms"}, {"score": 0.002598333022293788, "phrase": "knowledge-driven_activity_recognition"}, {"score": 0.0025264171945423254, "phrase": "presented_approach"}, {"score": 0.002456486927713543, "phrase": "prototype_system"}, {"score": 0.0023223663501882917, "phrase": "average_recognition_accuracy"}, {"score": 0.0022475295254231714, "phrase": "real_time_activity_recognition"}, {"score": 0.0021649437083408425, "phrase": "underlying_model"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Ontology", " Sensor data segmentation", " Time window", " Real-time activity recognition", " Ontological activity modelling", " Temporal information"], "paper_abstract": "Approaches and algorithms for activity recognition have recently made substantial progress due to advancements in pervasive and mobile computing, smart environments and ambient assisted living. Nevertheless, it is still difficult to achieve real-time continuous activity recognition as sensor data segmentation remains a challenge. This paper presents a novel approach to real-time sensor data segmentation for continuous activity recognition. Central to the approach is a dynamic segmentation model, based on the notion of varied time windows, which can shrink and expand the segmentation window size by using temporal information of sensor data and activities as well as the state of activity recognition. The paper first analyzes the characteristics of activities of daily living from which the segmentation model that is applicable to a wide range of activity recognition scenarios is motivated and developed. It then describes the working mechanism and relevant algorithms of the model in the context of knowledge-driven activity recognition based on ontologies. The presented approach has been implemented in a prototype system and evaluated in a number of experiments. Results have shown average recognition accuracy above 83% in all experiments for real time activity recognition, which proves the approach and the underlying model. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Dynamic sensor data segmentation for real-time knowledge-driven activity recognition", "paper_id": "WOS:000330572400004"}