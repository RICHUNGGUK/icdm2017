{"auto_keywords": [{"score": 0.037796462302704156, "phrase": "relevance_measure"}, {"score": 0.00481495049065317, "phrase": "architecture_design"}, {"score": 0.004690694501758065, "phrase": "neural_network_research"}, {"score": 0.004569630374630379, "phrase": "proper_size"}, {"score": 0.004382364826200616, "phrase": "oversize_trained_network"}, {"score": 0.004314127287770832, "phrase": "smaller_one"}, {"score": 0.004246947739596565, "phrase": "established_performance"}, {"score": 0.004115697805448384, "phrase": "sensitivity-based_approach"}, {"score": 0.004051595625804513, "phrase": "hidden_adalines"}, {"score": 0.003988487841970088, "phrase": "madaline"}, {"score": 0.003480993634130542, "phrase": "adalines'_sensitivity_measure"}, {"score": 0.0033910448175165004, "phrase": "least_relevant_adaline"}, {"score": 0.0032861588691414667, "phrase": "sensitivity_measure"}, {"score": 0.0031845067058084583, "phrase": "adaline's_output_inversions"}, {"score": 0.0031348622158167195, "phrase": "input_variation"}, {"score": 0.003069867656852932, "phrase": "overall_input_patterns"}, {"score": 0.0028828348726682965, "phrase": "adaline's_sensitivity_value"}, {"score": 0.0027936239349923464, "phrase": "absolute_value"}, {"score": 0.002750056254309311, "phrase": "adaline's_outgoing_weights"}, {"score": 0.002637160140011997, "phrase": "pruning_algorithm"}, {"score": 0.002502519068890319, "phrase": "adaline"}, {"score": 0.0024634797027967203, "phrase": "least_relevance_value"}, {"score": 0.0024377918036784336, "phrase": "hidden_layer"}, {"score": 0.0021609076467365247, "phrase": "pruning_approach"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": ["Adaline", " Madaline", " Architecture pruning", " Sensitivity measure", " Relevance measure"], "paper_abstract": "Architecture design is a very important issue in neural network research. One popular way to find proper size of a network is to prune an oversize trained network to a smaller one while keeping established performance. This paper presents a sensitivity-based approach to prune hidden Adalines from a Madaline with causing as little as possible performance loss and thus easy compensating for the loss. The approach is novel in setting up a relevance measure, by means of an Adalines' sensitivity measure, to locate the least relevant Adaline in a Madaline. The sensitivity measure is the probability of an Adaline's output inversions due to input variation with respect to overall input patterns, and the relevance measure is defined as the multiplication of the Adaline's sensitivity value by the summation of the absolute value of the Adaline's outgoing weights. Based on the relevance measure, a pruning algorithm can be simply programmed, which iteratively prunes an Adaline with the least relevance value from hidden layer of a given Madaline and then conducts some compensations until no more Adalines can be removed under a given performance requirement. The effectiveness of the pruning approach is verified by some experimental results.", "paper_title": "A sensitivity-based approach for pruning architecture of Madalines", "paper_id": "WOS:000270649100011"}