{"auto_keywords": [{"score": 0.04187357453276302, "phrase": "fixed_basis"}, {"score": 0.00481495049065317, "phrase": "random_projections"}, {"score": 0.004789565954062318, "phrase": "universal"}, {"score": 0.004633429997452688, "phrase": "class_f_subset"}, {"score": 0.004608060637237746, "phrase": "r-n_e.g."}, {"score": 0.004545240514015278, "phrase": "digital_signals"}, {"score": 0.004520351823685038, "phrase": "digital_images"}, {"score": 0.0038230844545071303, "phrase": "small_number"}, {"score": 0.003802135020791801, "phrase": "random_measurements"}, {"score": 0.003760578617706127, "phrase": "simple_linear_program"}, {"score": 0.0035012758747074496, "phrase": "vertical_bar"}, {"score": 0.0030516519650413748, "phrase": "n-dimensional_gaussian_vectors"}, {"score": 0.003034916887102753, "phrase": "independent_standard_normal_entries"}, {"score": 0.002968886579905784, "phrase": "decay_estimate"}, {"score": 0.0028804274673073713, "phrase": "overwhelming_probability"}, {"score": 0.00236289633510808, "phrase": "higher_accuracy"}, {"score": 0.002330612108529907, "phrase": "k_measurements"}, {"score": 0.00223637611933381, "phrase": "similar_results"}, {"score": 0.0021049977753042253, "phrase": "measurement_ensemble"}], "paper_keywords": ["concentration of measure", " convex optimization", " duality in optimization", " linear programming", " random matrices", " random projections", " signal recovery", " singular values of random matrices", " sparsity", " trigonometric expansions", " uncertainty principle"], "paper_abstract": "Suppose we are given a vector f in a class F subset of R-N e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision is an element of in the Euclidean (l(2)) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the,nth largest entry of the vector If I (or of its coefficients in a fixed basis) obeys vertical bar f vertical bar((n)) < R (.) n(-1/P), where R > 0 and p > 0. Suppose that we take measurements y(k) = < f, X-k >; k = 1..., K, where the X-k are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0 < p < 1 and with overwhelming probability, our reconstruction f(#) defined as the solution to the constraints y(k) = < f(#), X-k > with minimal l(1) norm, obeys parallel to f - f(#)parallel to(l2) <= C-p (.) R (.) (K/log N)(-r), r = 1/p - 1/2 There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed.", "paper_title": "Near-optimal signal recovery from random projections: Universal encoding strategies?", "paper_id": "WOS:000242503300015"}