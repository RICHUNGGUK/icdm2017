{"auto_keywords": [{"score": 0.04430475728264122, "phrase": "active_vision"}, {"score": 0.04014843959765129, "phrase": "ecological_conditions"}, {"score": 0.0047277417909824745, "phrase": "adaptive_top-down"}, {"score": 0.004642105253191792, "phrase": "simple_camera-arm_robot"}, {"score": 0.004190305872545087, "phrase": "key_solution"}, {"score": 0.0033890026927890058, "phrase": "attention_focus"}, {"score": 0.0033397385936467204, "phrase": "good_visual_actions"}, {"score": 0.003279160988534828, "phrase": "manipulation_actions"}, {"score": 0.0031961879138783012, "phrase": "learning_feedback"}, {"score": 0.0031267359296488118, "phrase": "limited_fovea"}, {"score": 0.0030253688063143157, "phrase": "computational_architecture"}, {"score": 0.0024106932919085097, "phrase": "simple_simulated_camera-arm_robot"}, {"score": 0.0023669270875629205, "phrase": "search-and-reach_tasks"}, {"score": 0.0023496433751182162, "phrase": "color-blob_\"objects"}, {"score": 0.0021439311243100913, "phrase": "architecture_principles"}, {"score": 0.0021049977753042253, "phrase": "full_exploitation"}], "paper_keywords": ["Bottom-up top-down overt attention", " camera-arm robot", " ecological active vision", " eye-hand coupling", " inhibition of return", " memory", " partial observability", " reinforcement learning"], "paper_abstract": "Vision gives primates a wealth of information useful to manipulate the environment, but at the same time it can easily overwhelm their computational resources. Active vision is a key solution found by nature to solve this problem: a limited fovea actively displaced in space to collect only relevant information. Here we highlight that in ecological conditions this solution encounters four problems: 1) the agent needs to learn where to look based on its goals; 2) manipulation causes learning feedback in areas of space possibly outside the attention focus; 3) good visual actions are needed to guide manipulation actions, but only these can generate learning feedback; and 4) a limited fovea causes aliasing problems. We then propose a computational architecture (\"BITPIC\") to overcome the four problems, integrating four bioinspired key ingredients: 1) reinforcement-learning fovea-based top-down attention; 2) a strong vision-manipulation coupling; 3) bottom-up periphery-based attention; and 4) a novel action-oriented memory. The system is tested with a simple simulated camera-arm robot solving a class of search-and-reach tasks involving color-blob \"objects.\" The results show that the architecture solves the problems, and hence the tasks, very efficiently, and highlight how the architecture principles can contribute to a full exploitation of the advantages of active vision in ecological conditions.", "paper_title": "Ecological Active Vision: Four Bioinspired Principles to Integrate Bottom-Up and Adaptive Top-Down Attention Tested With a Simple Camera-Arm Robot", "paper_id": "WOS:000351465900002"}