{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "children's_speech"}, {"score": 0.009627242002016588, "phrase": "linear_transformation"}, {"score": 0.004777034835192062, "phrase": "limited_data"}, {"score": 0.004720717782144015, "phrase": "formant-like_peak_alignment"}, {"score": 0.00459186790405058, "phrase": "acoustic_models"}, {"score": 0.00453772385360173, "phrase": "adults_results"}, {"score": 0.00450198136261303, "phrase": "poor_performance"}, {"score": 0.004413846562278824, "phrase": "speech_acoustics"}, {"score": 0.004361792415184563, "phrase": "acoustical_differences"}, {"score": 0.0042426974826585695, "phrase": "shorter_vocal_tracts"}, {"score": 0.004209269012699911, "phrase": "smaller_vocal_cords"}, {"score": 0.004110549138321181, "phrase": "speaker_adaptation"}, {"score": 0.003966776222128288, "phrase": "real-world_applications"}, {"score": 0.0038890781420303916, "phrase": "adaptation_data"}, {"score": 0.0037234376132464463, "phrase": "common_speaker_adaptation_techniques"}, {"score": 0.0036794956254952126, "phrase": "reasonable_performance"}, {"score": 0.003508834578859094, "phrase": "discrete_frequency_domain"}, {"score": 0.00303072749758085, "phrase": "frequency_warping"}, {"score": 0.002971309306027602, "phrase": "mel-warped_triangular_filter_banks"}, {"score": 0.002901538668877986, "phrase": "cepstral_space"}, {"score": 0.0028110458014332187, "phrase": "formant-like_peak_alignment_algorithm"}, {"score": 0.0027559226203857316, "phrase": "adult_acoustic_models"}, {"score": 0.0026594033724490172, "phrase": "gaussian_mixtures"}, {"score": 0.002566255769251419, "phrase": "zolfaghari"}, {"score": 0.002525941570368959, "phrase": "robinson"}, {"score": 0.0024182339264054225, "phrase": "gaussians"}, {"score": 0.0023990982005125763, "phrase": "proceedings_of_international_conference"}, {"score": 0.0023801608396295396, "phrase": "spoken_language_processing"}, {"score": 0.0023058910418682676, "phrase": "limited_adaptation_data"}, {"score": 0.0022606512324475584, "phrase": "traditional_vocal_tract_length_normalization"}, {"score": 0.0022428042503686053, "phrase": "vtln"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": [""], "paper_abstract": "Automatic recognition of children's speech using acoustic models trained by adults results in poor performance due to differences in speech acoustics. These acoustical differences are a consequence of children having shorter vocal tracts and smaller vocal cords than adults. Hence, speaker adaptation needs to be performed. However, in real-world applications, the amount of adaptation data available may be less than what,is needed by common speaker adaptation techniques to yield reasonable performance. In this paper, we first study, in the discrete frequency domain, the relationship between frequency warping in the front-end and corresponding transformations in the back-end. Three common feature extraction schemes are investigated and their transformation linearity in the back-end are discussed. In particular, we show that under certain approximations, frequency warping of MFCC features with Mel-warped triangular filter banks equals a linear transformation in the cepstral space. Based on that linear transformation, a formant-like peak alignment algorithm is proposed to adapt adult acoustic models to children's speech. The peaks are estimated by Gaussian mixtures using the Expectation-Maximization (EM) algorithm [Zolfaghari, P., Robinson, T., 1996. Formant analysis using mixtures of Gaussians, Proceedings of International Conference on Spoken Language Processing, 1229-1232]. For limited adaptation data, the algorithm outperforms traditional vocal tract length normalization (VTLN) and maximum likelihood linear regression (MLLR) techniques. (c) 2005 Elsevier Ltd. All rights reserved.", "paper_title": "Adaptation of children's speech with limited data based on formant-like peak alignment", "paper_id": "WOS:000240727800003"}