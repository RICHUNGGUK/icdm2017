{"auto_keywords": [{"score": 0.04136547746428909, "phrase": "emotional_state"}, {"score": 0.015719716506582538, "phrase": "emotion_detection"}, {"score": 0.0156301483768096, "phrase": "spoken_dialogue_systems"}, {"score": 0.014719493016453401, "phrase": "different_information_sources"}, {"score": 0.014304416139630995, "phrase": "emotion_predictions"}, {"score": 0.011571532087915597, "phrase": "classification_rates"}, {"score": 0.004252389342697521, "phrase": "different_kinds"}, {"score": 0.004013524489681638, "phrase": "information_fusion"}, {"score": 0.0038099959232779194, "phrase": "second_information_fusion_module"}, {"score": 0.0035648266669315943, "phrase": "previous_studies"}, {"score": 0.0032122679403131537, "phrase": "posterior_processing_stage"}, {"score": 0.0031116404200520614, "phrase": "decision_level"}, {"score": 0.0027634902834910184, "phrase": "modular_architecture"}, {"score": 0.0026924262536607915, "phrase": "spoken_dialogue_system"}, {"score": 0.0025929837295811673, "phrase": "real_time"}, {"score": 0.0022240805921303875, "phrase": "standard_fusion"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Adaptive spoken dialogue systems", " Combination of classifiers", " Information fusion", " Emotion detection", " Human computer interaction"], "paper_abstract": "This paper proposes a technique to enhance emotion detection in spoken dialogue systems by means of two modules that combine different information sources. The first one, called Fusion-0, combines emotion predictions generated by a set of classifiers that deal with different kinds of information about each sentence uttered by the user. To do this, the module employs several methods for information fusion that produce other predictions about the emotional state of the user. The predictions are the input to the second information fusion module, called Fusion-1, where they are combined to deduce the emotional state of the user. Fusion-0 represents a method employed in previous studies to enhance classification rates, whereas Fusion-1 represents the novelty of the technique, which is the combination of emotion predictions generated by Fusion-0. One advantage of the technique is that it can be applied as a posterior processing stage to any other methods that combine information from different information sources at the decision level. This is so because the technique works on the predictions (outputs) of the methods, without interfering in the procedure used to obtain these predictions. Another advantage is that the technique can be implemented as a modular architecture, which facilitates the setting up within a spoken dialogue system as well as the deduction of the emotional state of the user in real time. Experiments have been carried out considering classifiers to deal with prosodic, acoustic, lexical, and dialogue acts information, and three methods to combine information: multiplication of probabilities, average of probabilities, and unweighted vote. The results show that the technique enhances the classification rates of the standard fusion by 2.27% and 3.38% absolute in experiments carried out considering two and three emotion categories, respectively. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Enhancement of emotion detection in spoken dialogue systems by combining several information sources", "paper_id": "WOS:000294104000012"}