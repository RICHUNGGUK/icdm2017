{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "shared_multimedia"}, {"score": 0.004548253531664032, "phrase": "audiovisual_bimodal_segmentation"}, {"score": 0.003419943984098415, "phrase": "audio_features"}, {"score": 0.003051073364818384, "phrase": "initial_cost-effective_annotation"}, {"score": 0.002570817338292482, "phrase": "new_audio-driven_approach"}, {"score": 0.0021049977753042253, "phrase": "shared_audiovisual_streams"}], "paper_keywords": [""], "paper_abstract": "Events can be primarily identified based only on audio features, allowing an initial cost-effective annotation of multimedia content. A new audio-driven approach enables temporal alignment and management of shared audiovisual streams.", "paper_title": "Syncing Shared Multimedia through Audiovisual Bimodal Segmentation", "paper_id": "WOS:000359560500004"}