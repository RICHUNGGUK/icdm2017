{"auto_keywords": [{"score": 0.044090548582325764, "phrase": "visual_words"}, {"score": 0.03190648354827103, "phrase": "visual_word"}, {"score": 0.00481495049065317, "phrase": "w-tree_indexing"}, {"score": 0.004776297980616768, "phrase": "fast_visual_word_generation"}, {"score": 0.004514241562580097, "phrase": "image_retrieval"}, {"score": 0.004477992162329249, "phrase": "visual_recognition"}, {"score": 0.004301046274139699, "phrase": "visual_word_generation"}, {"score": 0.004164516065972361, "phrase": "corresponding_local_features"}, {"score": 0.0041144374213500715, "phrase": "high-dimensional_space"}, {"score": 0.003999907278478564, "phrase": "multibranch_trees"}, {"score": 0.0038573081851680656, "phrase": "time_cost"}, {"score": 0.003675023529026644, "phrase": "large_number"}, {"score": 0.003515479934694842, "phrase": "spatial_correlation"}, {"score": 0.003487222504700868, "phrase": "local_features"}, {"score": 0.0033492947290751996, "phrase": "visual_word_generation_process"}, {"score": 0.0030523478413779686, "phrase": "co-occurrence_table"}, {"score": 0.0027929100418926725, "phrase": "corresponding_co-occurrence_table"}, {"score": 0.0027260525536580912, "phrase": "probabilistic_weight"}, {"score": 0.0025761937402886954, "phrase": "k-means_tree"}, {"score": 0.0024742098091226203, "phrase": "searching_path"}, {"score": 0.002395530243993313, "phrase": "small_number"}, {"score": 0.002319346861878611, "phrase": "proposed_scheme"}, {"score": 0.002263799931018574, "phrase": "fast_library"}, {"score": 0.00224558083320154, "phrase": "approximate_nearest_neighbors"}, {"score": 0.002218526133566788, "phrase": "random_kd-trees"}, {"score": 0.0021917966722180132, "phrase": "oxford_data_set"}, {"score": 0.002174155795026218, "phrase": "thorough_experimental_results"}, {"score": 0.0021049977753042253, "phrase": "new_scheme"}], "paper_keywords": ["Bag-of-visual-words (BOVW)", " co-occurrence table", " probabilistic weight", " spatial correlation", " tree structure"], "paper_abstract": "The bag-of-visual-words representation has been widely used in image retrieval and visual recognition. The most time-consuming step in obtaining this representation is the visual word generation, i.e., assigning visual words to the corresponding local features in a high-dimensional space. Recently, structures based on multibranch trees and forests have been adopted to reduce the time cost. However, these approaches cannot perform well without a large number of backtrackings. In this paper, by considering the spatial correlation of local features, we can significantly speed up the time consuming visual word generation process while maintaining accuracy. In particular, visual words associated with certain structures frequently co-occur; hence, we can build a co-occurrence table for each visual word for a large-scale data set. By associating each visual word with a probability according to the corresponding co-occurrence table, we can assign a probabilistic weight to each node of a certain index structure (e.g., a KD-tree and a K-means tree), in order to re-direct the searching path to be close to its global optimum within a small number of backtrackings. We carefully study the proposed scheme by comparing it with the fast library for approximate nearest neighbors and the random KD-trees on the Oxford data set. Thorough experimental results suggest the efficiency and effectiveness of the new scheme.", "paper_title": "W-Tree Indexing for Fast Visual Word Generation", "paper_id": "WOS:000318014300029"}