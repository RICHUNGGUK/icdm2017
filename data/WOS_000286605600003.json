{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multimodal_interaction"}, {"score": 0.0046993598473345395, "phrase": "multimedia_content"}, {"score": 0.004161553532799662, "phrase": "archiving_systems"}, {"score": 0.003107935254560724, "phrase": "user_interaction"}, {"score": 0.00303319936111073, "phrase": "multimedia_archiving_systems"}, {"score": 0.0029244418026475832, "phrase": "traditional_text_typing"}, {"score": 0.0028541057064952876, "phrase": "mouse_pointing"}, {"score": 0.0024963543716522087, "phrase": "different_kinds"}, {"score": 0.00218334762335187, "phrase": "supported_segmentation_techniques"}, {"score": 0.0021049977753042253, "phrase": "extensible_multimodal_interaction"}], "paper_keywords": ["Multimedia archival", " multimodal interaction", " segmentation", " annotation"], "paper_abstract": "Multimedia content is very rich in terms of meaning, and archiving systems need to be improved to consider such richness. This research proposes archiving improvements to extend the ways of describing content, and enhance user interaction with multimedia archiving systems beyond the traditional text typing and mouse pointing. These improvements consider a set of techniques to segment different kinds of media, a set of indexes to annotate the supported segmentation techniques and an extensible multimodal interaction to make multimedia archiving tasks more user friendly.", "paper_title": "Multi-domain framework for multimedia archiving using multimodal interaction", "paper_id": "WOS:000286605600003"}