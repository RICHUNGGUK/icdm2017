{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "visual_saliency"}, {"score": 0.00475070135279933, "phrase": "naturalistic_video_streams"}, {"score": 0.004687305496643216, "phrase": "naturalistic_stimuli"}, {"score": 0.004593787100061613, "phrase": "video_watching"}, {"score": 0.004412285905508977, "phrase": "functional_magnetic_resonance_imaging"}, {"score": 0.004237925318473508, "phrase": "real_and_dynamic_information"}, {"score": 0.00415333528095237, "phrase": "human_brain"}, {"score": 0.004016072233242585, "phrase": "everyday_life"}, {"score": 0.003780286517897356, "phrase": "sparsity-constrained_decoding_model"}, {"score": 0.003679969180334367, "phrase": "bottom-up_visual_saliency"}, {"score": 0.00344062888674746, "phrase": "brain_activity"}, {"score": 0.003371964891727417, "phrase": "fmri"}, {"score": 0.003238517900104573, "phrase": "sparsity_constraints"}, {"score": 0.0031738126998349775, "phrase": "visual_saliency_decoding"}, {"score": 0.0030278017562213265, "phrase": "biologically-plausible_computational_model"}, {"score": 0.002907992115184249, "phrase": "video_streams"}, {"score": 0.002811770047652563, "phrase": "sparse_representation_algorithm"}, {"score": 0.0027370835853738626, "phrase": "atomic_fmri_signal_dictionaries"}, {"score": 0.0025935941070969575, "phrase": "whole-brain_fmri_signals"}, {"score": 0.0024742098091226203, "phrase": "learned_atomic_dictionary"}, {"score": 0.0024247382451294255, "phrase": "quantified_video_saliency"}, {"score": 0.0023923066544220277, "phrase": "experimental_results"}, {"score": 0.0023287359930308864, "phrase": "temporal_visual_saliency"}, {"score": 0.002297585503415527, "phrase": "video_stream"}, {"score": 0.0021917966722180132, "phrase": "sparse_constraints"}, {"score": 0.0021049977753042253, "phrase": "fmri_decoding_models"}], "paper_keywords": ["Functional magnetic resonance imaging (fMRI) decoding", " naturalistic stimuli", " sparsity constraints", " visual saliency"], "paper_abstract": "Naturalistic stimuli such as video watching have been increasingly used in functional magnetic resonance imaging (fMRI)-based brain encoding and decoding studies since they can provide real and dynamic information that the human brain has to process in everyday life. In this paper, we propose a sparsity-constrained decoding model to explore whether bottom-up visual saliency in continuous video streams can be effectively decoded by brain activity recorded by fMRI, and to examine whether sparsity constraints can improve visual saliency decoding. Specifically, we use a biologically-plausible computational model to quantify the visual saliency in video streams, and adopt a sparse representation algorithm to learn the atomic fMRI signal dictionaries that are representative of the patterns of whole-brain fMRI signals. Sparse representation also links the learned atomic dictionary with the quantified video saliency. Experimental results show that the temporal visual saliency in video stream can be well decoded and the sparse constraints can improve the performance of fMRI decoding models.", "paper_title": "Sparsity-Constrained fMRI Decoding of Visual Saliency in Naturalistic Video Streams", "paper_id": "WOS:000356164500001"}