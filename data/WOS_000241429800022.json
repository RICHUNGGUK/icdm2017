{"auto_keywords": [{"score": 0.048296005549671464, "phrase": "fisher_kernels"}, {"score": 0.004519908617935935, "phrase": "human_computer_interaction"}, {"score": 0.004406994912939125, "phrase": "multimodal_environments"}, {"score": 0.0043150485532080065, "phrase": "great_variability"}, {"score": 0.0040334640350288, "phrase": "interpersonal_differences"}, {"score": 0.003965975628742746, "phrase": "recognition_task"}, {"score": 0.003850566273995209, "phrase": "sequence_data"}, {"score": 0.003818210967854446, "phrase": "processing_variable_length_sequences"}, {"score": 0.0037701851296383405, "phrase": "hand_gestures"}, {"score": 0.003738502710504415, "phrase": "hidden_markov_models"}, {"score": 0.0036450381529042103, "phrase": "natural_extension"}, {"score": 0.0035539019235553897, "phrase": "discriminative_methods"}, {"score": 0.0035091888798162176, "phrase": "support_vector_machines"}, {"score": 0.003407026489727146, "phrase": "model_based_approaches"}, {"score": 0.0033218213825698417, "phrase": "flexible_decision_boundaries"}, {"score": 0.0032938942910948096, "phrase": "better_classification_performance"}, {"score": 0.0032115093493071366, "phrase": "gesture_sequences"}, {"score": 0.0030399874838260886, "phrase": "discriminative_classifier"}, {"score": 0.002939007076062123, "phrase": "combined_classifier"}, {"score": 0.002914288956035066, "phrase": "generative_and_discriminative_classifiers"}, {"score": 0.00287759989638073, "phrase": "small_database"}, {"score": 0.002770273247998903, "phrase": "kalman_tracking"}, {"score": 0.0027009493171069763, "phrase": "center-of-mass_and_blob_tracking"}, {"score": 0.002600194073758015, "phrase": "blob_tracking"}, {"score": 0.00257831812581194, "phrase": "general_hand_shape"}, {"score": 0.002556625752785268, "phrase": "hand_motion"}, {"score": 0.002503187934017557, "phrase": "simple_center-of-mass_tracking"}, {"score": 0.002419995316129757, "phrase": "stereo_camera_setup"}, {"score": 0.002271372252250557, "phrase": "feature_level"}, {"score": 0.002242758902593467, "phrase": "error_rates"}, {"score": 0.0021049977753042253, "phrase": "classification_performance"}], "paper_keywords": [""], "paper_abstract": "Use of gestures extends Human Computer Interaction (HCI) possibilities in multimodal environments. However, the great variability in gestures, both in time, size, and position, as well as interpersonal differences, makes the recognition task difficult. With their power in modeling sequence data and processing variable length sequences, modeling hand gestures using Hidden Markov Models (HMM) is a natural extension. On the other hand, discriminative methods such as Support Vector Machines (SVM), compared to model based approaches such as HMMs, have flexible decision boundaries and better classification performance. By extracting features from gesture sequences via Fisher Kernels based on HMMs, classification can be done by a discriminative classifier. We compared the performance of this combined classifier with generative and discriminative classifiers on a small database of two handed gestures recorded with two cameras. We used Kalman tracking of hands from two cameras using center-of-mass and blob tracking. The results show that (i) blob tracking incorporates general hand shape with hand motion and performs better than simple center-of-mass tracking, and (ii) in a stereo camera setup, even if 3D reconstruction is not possible, combining 2D information from each camera at feature level decreases the error rates, and (iii) Fisher Score methodology combines the powers of generative and discriminative approaches and increases the classification performance.", "paper_title": "Recognizing two handed gestures with generative, discriminative and ensemble methods via Fisher kernels", "paper_id": "WOS:000241429800022"}