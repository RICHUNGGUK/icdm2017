{"auto_keywords": [{"score": 0.04550627957994422, "phrase": "multi-color_ordering"}, {"score": 0.015560954417193747, "phrase": "large_sparse_linear_systems"}, {"score": 0.015364719553104362, "phrase": "structured_grids"}, {"score": 0.013844892914990298, "phrase": "sparse_approximate_inverse"}, {"score": 0.012222447934488054, "phrase": "wavefront"}, {"score": 0.010515578827055108, "phrase": "multi-color_block_sor"}, {"score": 0.009641601037135872, "phrase": "interprocessor_communications"}, {"score": 0.00481495049065317, "phrase": "parallel_preconditioners"}, {"score": 0.004790306679000464, "phrase": "iterative_methods"}, {"score": 0.0047292449487169345, "phrase": "partial_differential_equations"}, {"score": 0.004585839050535886, "phrase": "point-ssor"}, {"score": 0.004469646630310921, "phrase": "incomplete_lu"}, {"score": 0.004423994518127831, "phrase": "wavefront_ordering"}, {"score": 0.004334078307677701, "phrase": "multi-color_block"}, {"score": 0.004064653055162238, "phrase": "two-dimensional_pde"}, {"score": 0.0036678472439508484, "phrase": "natural_order"}, {"score": 0.003493127223058947, "phrase": "simple_way"}, {"score": 0.0034308688638878286, "phrase": "order_n"}, {"score": 0.00325901518290063, "phrase": "natural_ordering"}, {"score": 0.003176333519010176, "phrase": "direct_sparse_matrix_solver"}, {"score": 0.003135780176908318, "phrase": "laplacian_matrix"}, {"score": 0.003119703729649559, "phrase": "sor_method"}, {"score": 0.003071965703296204, "phrase": "nondeteriorating_rate"}, {"score": 0.002986329509791943, "phrase": "block_version"}, {"score": 0.002925548148757916, "phrase": "spai"}, {"score": 0.0028807718824400697, "phrase": "least_squares_method"}, {"score": 0.0027860884734700595, "phrase": "independent_sets"}, {"score": 0.0027505037762786087, "phrase": "parallel_version"}, {"score": 0.0027363971333961967, "phrase": "arms._experiments"}, {"score": 0.0026875896756849258, "phrase": "five_two-dimensional_pdes"}, {"score": 0.00260593122498774, "phrase": "distributed_memory"}, {"score": 0.002279735045661163, "phrase": "multi-color"}, {"score": 0.0021487685525986094, "phrase": "best_performance"}, {"score": 0.0021049977753042253, "phrase": "small_number"}], "paper_keywords": ["partial differential equations", " sparse linear systems", " iterative methods", " parallel preconditioners", " distributed memory", " MPI (message passing interface)"], "paper_abstract": "In this paper we compare various parallel preconditioners such as Point-SSOR (Symmetric Successive OverRelaxation), ILU(0) (Incomplete LU) in the Wavefront ordering, ILU(0) in the Multi-color ordering, Multi-Color Block SOR (Successive OverRelaxation), SPAI (Sparse Approximate Inverse) and pARMS (Parallel Algebraic Recursive Multilevel Solver) for solving large sparse linear systems arising from two-dimensional PDE (Partial Differential Equation)s on structured grids. Point-SSOR is well-known, and ILU(0) is one of the most popular preconditioner, but it is inherently serial. ILU(0) in the Wavefront ordering maximizes the parallelism in the natural order, but the lengths of the wavefronts are often nonuniform. ILU(0) in the Multi-color ordering is a simple way of achieving a parallelism of the order N, where N is the order of the matrix, but its convergence rate often deteriorates as compared to that of natural ordering. We have chosen the Multi-Color Block SOR preconditioner combined with direct sparse matrix solver, since for the Laplacian matrix the SOR method is known to have a nondeteriorating rate of convergence when used with the Multi-Color ordering. By using block version we expect to minimize the interprocessor communications. SPAI computes the sparse approximate inverse directly by least squares method. Finally, ARMS is a preconditioner recursively exploiting the concept of independent sets and pARMS is the parallel version of ARMS. Experiments were conducted for the Finite Difference and Finite Element discretizations of five two-dimensional PDEs with large meshsizes up to a million on an IBM p595 machine with distributed memory. Our matrices are real positive, i.e., their real parts of the eigenvalues are positive. We have used GMRES(m) as our outer iterative method, so that the convergence of GMRES(m) for our test matrices are mathematically guaranteed. Interprocessor communications were done using MPI (Message Passing Interface) primitives. The results show that in general ILU(0) in the Multi-Color ordering and ILU(0) in the Wavefront ordering outperform the other methods but for symmetric and nearly symmetric 5-point matrices Multi-Color Block SOR gives the best performance, except for a few cases with a small number of processors.", "paper_title": "A performance comparison of the parallel preconditioners for iterative methods for large sparse linear systems arising from Partial Differential Equations on structured grids", "paper_id": "WOS:000259767300041"}