{"auto_keywords": [{"score": 0.03857891362648781, "phrase": "sarsa"}, {"score": 0.00481495049065317, "phrase": "connectionist_models_of_reinforcement"}, {"score": 0.004550029253278477, "phrase": "complex_problems"}, {"score": 0.004448169552315403, "phrase": "computational_models"}, {"score": 0.004398094237005956, "phrase": "human_performance"}, {"score": 0.003332210257373994, "phrase": "supervised_learning"}, {"score": 0.0032760377953971248, "phrase": "neural_network"}, {"score": 0.0031308163228919773, "phrase": "knowledge-based_neural_network"}, {"score": 0.002671263324230699, "phrase": "successful_solutions"}], "paper_keywords": ["Cognitive science", " learning systems", " neural networks", " problem-solving"], "paper_abstract": "We compared computational models and human performance on learning to solve a high-level, planning-intensive problem. Humans and models were subjected to three learning regimes: reinforcement, imitation, and instruction. We modeled learning by reinforcement (rewards) using SARSA, a softmax selection criterion and a neural network function approximator; learning by imitation using supervised learning in a neural network; and learning by instructions using a knowledge-based neural network. We had previously found that human participants who were told if their answers were correct or not (a reinforcement group) were less accurate than participants who watched demonstrations of successful solutions of the task (an imitation group) and participants who read instructions explaining how to solve the task. Furthermore, we had found that humans who learn by imitation and instructions performed more complex solution steps than those trained by reinforcement. Our models reproduced this pattern of results.", "paper_title": "Connectionist Models of Reinforcement, Imitation, and Instruction in Learning to Solve Complex Problems", "paper_id": "WOS:000208067900002"}