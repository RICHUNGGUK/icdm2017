{"auto_keywords": [{"score": 0.045314884531415765, "phrase": "blocking_methods"}, {"score": 0.043295135176914266, "phrase": "schema-based_configuration"}, {"score": 0.00481495049065317, "phrase": "schema-based_configurations_for_blocking_methods"}, {"score": 0.004701985831087475, "phrase": "entity_resolution"}, {"score": 0.004635477242873163, "phrase": "core_task"}, {"score": 0.00459165923324494, "phrase": "data_integration"}, {"score": 0.0043786774510943625, "phrase": "large_datasets"}, {"score": 0.004077508669922702, "phrase": "schema_information"}, {"score": 0.003944112858235306, "phrase": "high_distinctiveness"}, {"score": 0.003906804492585634, "phrase": "low_noise"}, {"score": 0.0038332390893263844, "phrase": "schema-agnostic_one"}, {"score": 0.003725470458263889, "phrase": "attribute_values"}, {"score": 0.0036207206487324506, "phrase": "latter_approach"}, {"score": 0.0035864603175592854, "phrase": "significant_potential"}, {"score": 0.003419943984098415, "phrase": "human_experts"}, {"score": 0.0033395980635636644, "phrase": "heterogeneous_data"}, {"score": 0.0032302647179383915, "phrase": "systematic_study"}, {"score": 0.002881793492919646, "phrase": "time_efficiency"}, {"score": 0.0026705669656375197, "phrase": "structured_data"}, {"score": 0.0026202187680903063, "phrase": "valuable_insights"}, {"score": 0.00258307991054107, "phrase": "internal_functionality"}, {"score": 0.0024747842618794255, "phrase": "novel_taxonomy"}, {"score": 0.0024051153560799335, "phrase": "schema-agnostic_configuration"}, {"score": 0.0022933216359142736, "phrase": "versatile_settings"}, {"score": 0.0022500695985527668, "phrase": "higher_computational_cost"}, {"score": 0.0022181655497912796, "phrase": "consistently_higher_recall"}, {"score": 0.002186712881521657, "phrase": "schema-based_one"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_blocking"}], "paper_keywords": [""], "paper_abstract": "Entity Resolution constitutes a core task for data integration that, due to its quadratic complexity, typically scales to large datasets through blocking methods. These can be configured in two ways. The schema-based configuration relies on schema information in order to select signatures of high distinctiveness and low noise, while the schema-agnostic one treats every token from all attribute values as a signature. The latter approach has significant potential, as it requires no fine-tuning by human experts and it applies to heterogeneous data. Yet, there is no systematic study on its relative performance with respect to the schema-based configuration. This work covers this gap by comparing analytically the two configurations in terms of effectiveness, time efficiency and scalability. We apply them to 9 established blocking methods and to 11 benchmarks of structured data. We provide valuable insights into the internal functionality of the blocking methods with the help of a novel taxonomy. Our studies reveal that the schema-agnostic configuration offers unsupervised and robust definition of blocking keys under versatile settings, trading a higher computational cost for a consistently higher recall than the schema-based one. It also enables the use of state-of-the-art blocking methods without schema knowledge.", "paper_title": "Schema-agnostic vs Schema-based Configurations for Blocking Methods on Homogeneous Data", "paper_id": "WOS:000386426200008"}