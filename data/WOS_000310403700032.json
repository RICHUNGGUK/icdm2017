{"auto_keywords": [{"score": 0.05003562475801577, "phrase": "graphical_lasso"}, {"score": 0.04364649756758876, "phrase": "sigma"}, {"score": 0.004665608609734034, "phrase": "widely-used_fast_algorithm"}, {"score": 0.004616859702338596, "phrase": "sparse_inverse_covariance_matrices"}, {"score": 0.004489327204473076, "phrase": "penalized_maximum_likelihood_problem"}, {"score": 0.004395984840790689, "phrase": "r_library"}, {"score": 0.004365307301469502, "phrase": "cran."}, {"score": 0.004041546659145336, "phrase": "sparse_inverse_covariance_matrix_estimate"}, {"score": 0.003848088904418221, "phrase": "graphical_model"}, {"score": 0.003768028741967194, "phrase": "intermediate_inputs"}, {"score": 0.003741712498615481, "phrase": "multivariate_procedures"}, {"score": 0.0037029871040910513, "phrase": "pca"}, {"score": 0.0036770999531955725, "phrase": "lda"}, {"score": 0.0036510458688713645, "phrase": "manova"}, {"score": 0.003525291235622844, "phrase": "covariance_matrix_estimate"}, {"score": 0.0033564619316337634, "phrase": "penalized_optimization_problem"}, {"score": 0.0033213460816510685, "phrase": "dual_sense"}, {"score": 0.003064013732721966, "phrase": "asymmetric_estimates"}, {"score": 0.002767696345005216, "phrase": "true_underlying_inverse_covariance_matrix"}, {"score": 0.002363474907331799, "phrase": "negative_or_complex_eigenvalues"}, {"score": 0.002149799391146313, "phrase": "possible_remedies"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Concentration model selection", " Glasso", " Graphical Gaussian models", " Graphical lasso", " l(1) regularization"], "paper_abstract": "The graphical lasso (glasso) is a widely-used fast algorithm for estimating sparse inverse covariance matrices. The glasso solves an l(1) penalized maximum likelihood problem and is available as an R library on CRAN. The output from the glasso, a regularized covariance matrix estimate (Sigma) over cap (glasso) and a sparse inverse covariance matrix estimate (Omega) over cap (glasso), not only identify a graphical model but can also serve as intermediate inputs into multivariate procedures such as PCA, LDA, MANOVA, and others. The glasso indeed produces a covariance matrix estimate (Sigma) over cap (glasso) which solves the l(1) penalized optimization problem in a dual sense; however, the method for producing (Omega) over cap (glasso) after this optimization is inexact and may produce asymmetric estimates. This problem is exacerbated when the amount of l(1) regularization that is applied is small, which in turn is more likely to occur if the true underlying inverse covariance matrix is not sparse. The lack of symmetry can potentially have consequences. First, it implies that (Sigma) over cap (-1)(glasso) not equal (Omega) over cap (glasso) and, second, asymmetry can possibly lead to negative or complex eigenvalues, rendering many multivariate procedures which may depend on (Omega) over cap (glasso) unusable. We demonstrate this problem, explain its causes, and propose possible remedies. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "A note on the lack of symmetry in the graphical lasso", "paper_id": "WOS:000310403700032"}