{"auto_keywords": [{"score": 0.04286314458219273, "phrase": "relevant_features"}, {"score": 0.015719716506582538, "phrase": "categorical_data"}, {"score": 0.0047464608267006395, "phrase": "embedded_modelling_approach"}, {"score": 0.00459039896577789, "phrase": "feature_selection"}, {"score": 0.004376273644295806, "phrase": "challenging_task"}, {"score": 0.004212157020917929, "phrase": "class_labels"}, {"score": 0.004054169947971483, "phrase": "categorical_feature_selection"}, {"score": 0.0036845490951857617, "phrase": "numerical_data"}, {"score": 0.0032074366230426727, "phrase": "finite_mixture_model"}, {"score": 0.003161740194257218, "phrase": "multinomial_distributions"}, {"score": 0.00305762327908599, "phrase": "latent_variables"}, {"score": 0.00290087451159631, "phrase": "model_parameters"}, {"score": 0.002791932344920906, "phrase": "expectation-maximization_algorithm"}, {"score": 0.002648768009464535, "phrase": "minimum_message_length_criterion"}, {"score": 0.002611010097359509, "phrase": "proposed_approach"}, {"score": 0.0024771000236931836, "phrase": "entropy_measure"}, {"score": 0.002406968743305622, "phrase": "mutual_information"}, {"score": 0.0023388183537341213, "phrase": "synthetic_data"}, {"score": 0.0022725931637071852, "phrase": "proposed_expectation-maximization_method"}, {"score": 0.002176747110119268, "phrase": "real_data"}, {"score": 0.0021354538918029265, "phrase": "official_statistics"}], "paper_keywords": ["cluster analysis", " finite mixtures models", " EM algorithm", " feature selection", " categorical features"], "paper_abstract": "Research on the problem of feature selection for clustering continues to develop. This is a challenging task, mainly due to the absence of class labels to guide the search for relevant features. Categorical feature selection for clustering has rarely been addressed in the literature, with most of the proposed approaches having focused on numerical data. In this work, we propose an approach to simultaneously cluster categorical data and select a subset of relevant features. Our approach is based on a modification of a finite mixture model (of multinomial distributions), where a set of latent variables indicate the relevance of each feature. To estimate the model parameters, we implement a variant of the expectation-maximization algorithm that simultaneously selects the subset of relevant features, using a minimum message length criterion. The proposed approach compares favourably with two baseline methods: a filter based on an entropy measure and a wrapper based on mutual information. The results obtained on synthetic data illustrate the ability of the proposed expectation-maximization method to recover ground truth. An application to real data, referred to official statistics, shows its usefulness.", "paper_title": "Feature selection for clustering categorical data with an embedded modelling approach", "paper_id": "WOS:000355958900009"}