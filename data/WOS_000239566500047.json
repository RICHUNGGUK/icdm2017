{"auto_keywords": [{"score": 0.02913332783498095, "phrase": "unlabeled_data"}, {"score": 0.00481495049065317, "phrase": "conditional_random_fields"}, {"score": 0.004757227624616643, "phrase": "automatic_image_annotation"}, {"score": 0.0047003310174949416, "phrase": "aia"}, {"score": 0.004478782833067256, "phrase": "effective_and_promising_solution"}, {"score": 0.004345706062641742, "phrase": "high-level_semantics"}, {"score": 0.004293584349522444, "phrase": "low-level_visual_features"}, {"score": 0.004165987300206134, "phrase": "inherent_ambiguity"}, {"score": 0.004116012194714212, "phrase": "image-label_mapping"}, {"score": 0.00399367108161192, "phrase": "training_examples"}, {"score": 0.0037597491055035895, "phrase": "robust_annotation_models"}, {"score": 0.003714629047818465, "phrase": "better_performance"}, {"score": 0.003080449000295983, "phrase": "unified_framework"}, {"score": 0.0029351141718104725, "phrase": "spatial_dependency"}, {"score": 0.0028823939507764238, "phrase": "neighboring_labels"}, {"score": 0.002813566267090177, "phrase": "semi-supervised_learning_techniques"}, {"score": 0.002680789041160613, "phrase": "joint_classification_performance"}, {"score": 0.0025697460140513932, "phrase": "medium-sized_image_collection"}, {"score": 0.0024932498388507084, "phrase": "corel_stock_photo_cds"}, {"score": 0.002448446849997207, "phrase": "experimental_results"}, {"score": 0.002389956401870098, "phrase": "annotation_performance"}, {"score": 0.002318799760022913, "phrase": "standard_crfs"}, {"score": 0.002222717552124615, "phrase": "proposed_unified_framework"}, {"score": 0.0021049977753042253, "phrase": "classification_accuracy"}], "paper_keywords": [""], "paper_abstract": "Automatic image annotation (AIA) has been proved to be an effective and promising solution to automatically deduce the high-level semantics from low-level visual features. Due to the inherent ambiguity of image-label mapping and the scarcity of training examples, it has become a challenge to systematically develop robust annotation models with better performance. In this paper, we try to attack the problem based on 2D CRFs (Conditional Random Fields) and semi-supervised learning which are seamlessly integrated into a unified framework. 2D CRFs can effectively capture the spatial dependency between the neighboring labels, while the semi-supervised learning techniques can exploit the unlabeled data to improve the joint classification performance. We conducted experiments on a medium-sized image collection including about 500 images from Corel Stock Photo CDs. The experimental results demonstrated that the annotation performance of this method outperforms standard CRFs, showing the effectiveness of the proposed unified framework and the feasibility of unlabeled data to help the classification accuracy.", "paper_title": "Semi-supervised learning for image annotation based on conditional random fields", "paper_id": "WOS:000239566500047"}