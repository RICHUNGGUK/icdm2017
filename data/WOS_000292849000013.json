{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "approximate_k-nn_search"}, {"score": 0.004722613498487908, "phrase": "digital_imaging_devices"}, {"score": 0.004692227830462433, "phrase": "image_databases"}, {"score": 0.004413096646892175, "phrase": "critical_issue"}, {"score": 0.004328432545135587, "phrase": "semantic_gap"}, {"score": 0.004044645056447888, "phrase": "content-based_image_retrieval"}, {"score": 0.003954229201647876, "phrase": "classic_scenario"}, {"score": 0.0038908817250961633, "phrase": "user_query"}, {"score": 0.003647442345566347, "phrase": "active_learning"}, {"score": 0.003612259264584205, "phrase": "powerful_technique"}, {"score": 0.0035087260813209593, "phrase": "query_concept"}, {"score": 0.0034748763852150465, "phrase": "relevance_feedback_loops"}, {"score": 0.0033861930947608207, "phrase": "strategically_selected_images"}, {"score": 0.003267925215811654, "phrase": "state-of-the-art_active_learning_methods"}, {"score": 0.0031233388358844188, "phrase": "retrieval_systems"}, {"score": 0.002880829737447174, "phrase": "scalability_limitations"}, {"score": 0.002862260172272785, "phrase": "active_learning_strategies"}, {"score": 0.002735572813553256, "phrase": "locality_sensitive_hashing"}, {"score": 0.002648520437064087, "phrase": "active_learning_strategy"}, {"score": 0.0025808721879758243, "phrase": "new_lsh_scheme"}, {"score": 0.002514947446797848, "phrase": "better_results"}, {"score": 0.0024987304152852873, "phrase": "image_retrieval_context"}, {"score": 0.0021883400011393564, "phrase": "exhaustive_search"}, {"score": 0.0021462652605453163, "phrase": "similar_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Image retrieval", " Active learning", " Relevance feedback", " Locality sensitive hashing", " Scalability", " Support vector machines"], "paper_abstract": "With the democratization of digital imaging devices, image databases exponentially grow. Thus, providing the user with a system for searching into these databases is a critical issue. However, bridging the semantic gap between which (semantic) concept(s) the user is looking for and the (semantic) content is quite difficult. In content-based image retrieval (CBIR) systems, a classic scenario is to formulate the user query, at first, with only one example (i.e. one image). In order to address this problem, active learning is a powerful technique which involves the user in interactively refining the query concept, through relevance feedback loops, by asking the user whether some strategically selected images are relevant or not. However, the complexity of state-of-the-art active learning methods is linear in the size of the database and thus dramatically slows down retrieval systems, when dealing with very large databases, which is no longer acceptable for users. In this article, we propose a strategy to overcome scalability limitations of active learning strategies by exploiting ultra fast k-nearest-neighbor (k-NN) methods, as locality sensitive hashing (LSH), and combining them with an active learning strategy dedicated to very large databases. We define a new LSH scheme adapted to chi(2) distance which often leads to better results in image retrieval context. We perform evaluation on databases between 5 K and 180 K images. The results show that our interactive retrieval system has a complexity almost constant in the size of the database. For a database of 180 K images, our system is 45 times faster than exhaustive search (linear scan) reaching similar accuracy. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "SALSAS: Sub-linear active learning strategy with approximate k-NN search", "paper_id": "WOS:000292849000013"}