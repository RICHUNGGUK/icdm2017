{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multiple_attribute-specific_subspaces"}, {"score": 0.0044702911400353535, "phrase": "point_classification_algorithm"}, {"score": 0.004388035083357706, "phrase": "multi-variate_data"}, {"score": 0.003446353878654566, "phrase": "single_images"}, {"score": 0.0030257422786589723, "phrase": "specified_distance"}, {"score": 0.0029699874949715367, "phrase": "attribute_target_values"}, {"score": 0.0027062100658653485, "phrase": "remaining_data_points"}, {"score": 0.0024429654627197393, "phrase": "final_coloring"}, {"score": 0.0021049977753042253, "phrase": "similar_visual_context"}], "paper_keywords": [""], "paper_abstract": "In this work we present a point classification algorithm for multi-variate data. Our method is based oil the concept of attribute subspaces, which are derived from a set of user specified attribute target values. Our classification approach enables users to visually distinguish regions of saliency through concurrent viewing of these subspaces in single images. We also allow a user to threshold the data according to a specified distance from attribute target values. Based on the degree of thresholding, the remaining data points are assigned radii of influence that are used for the final coloring. This limits the view to only those points that are most relevant, while maintaining a similar visual context.", "paper_title": "Concurrent viewing of multiple attribute-specific subspaces", "paper_id": "WOS:000257075000010"}