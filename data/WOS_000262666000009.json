{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "image_space"}, {"score": 0.03854097123604737, "phrase": "real_time"}, {"score": 0.00443308765153716, "phrase": "different_time"}, {"score": 0.004149429072483132, "phrase": "new_possiblities"}, {"score": 0.0031582637043009562, "phrase": "uncalibrated_and_unsynchronized_cameras"}, {"score": 0.0029805015010906013, "phrase": "novel_discontiniuity"}, {"score": 0.002931569771634119, "phrase": "image_deformation_model"}, {"score": 0.0028360962841331634, "phrase": "dense_correspondences"}, {"score": 0.00276653157720066, "phrase": "local_homographies"}, {"score": 0.0021401625519713577, "phrase": "human_motion_perception"}], "paper_keywords": [""], "paper_abstract": "The ability to interpolate between images taken at different time and viewpoints directly in image space opens up new possiblities. The goal of our work is to create plausible in-between images in real time without the need for an intermediate 3D reconstruction. This enables us to also interpolate between images recorded with uncalibrated and unsynchronized cameras. In our approach we use a novel discontiniuity preserving image deformation model to robustly estimate dense correspondences based on local homographies. Once correspondences have been computed we are able to render plausible in-between images in real time while properly handling occlusions. We discuss the relation of our approach to human motion perception and other image interpolation techniques.", "paper_title": "View and Time Interpolation in Image Space", "paper_id": "WOS:000262666000009"}