{"auto_keywords": [{"score": 0.004540734419151103, "phrase": "unknown_input_distribution"}, {"score": 0.004327981760540394, "phrase": "product_type"}, {"score": 0.003571751184289622, "phrase": "fixed_length"}, {"score": 0.00304321897427383, "phrase": "expected_running_time"}, {"score": 0.002947266048104005, "phrase": "input_distribution_d"}, {"score": 0.0025514745448798385, "phrase": "delaunay_triangulation"}, {"score": 0.0025109095718850376, "phrase": "planar_point"}, {"score": 0.002431699464104896, "phrase": "optimal_expected_limiting_complexity"}, {"score": 0.0023424328921363585, "phrase": "training_phase"}, {"score": 0.002244410443944976, "phrase": "input_distribution"}, {"score": 0.002185235873435714, "phrase": "stationary_regime"}], "paper_keywords": ["average case analysis", " Delaunay triangulation", " low entropy", " sorting"], "paper_abstract": "We investigate ways in which an algorithm can improve its expected performance by fine-tuning itself automatically with respect to an unknown input distribution D. We assume here that D is of product type. More precisely, suppose that we need to process a sequence I-1, I-2, ... of inputs I = (x(1), x(2), ... , x(n)) of some fixed length n, where each x(i) is drawn independently from some arbitrary, unknown distribution D-i. The goal is to design an algorithm for these inputs so that eventually the expected running time will be optimal for the input distribution D = Pi(i) D-i. We give such self-improving algorithms for two problems: (i) sorting a sequence of numbers and (ii) computing the Delaunay triangulation of a planar point set. Both algorithms achieve optimal expected limiting complexity. The algorithms begin with a training phase during which they collect information about the input distribution, followed by a stationary regime in which the algorithms settle to their optimized incarnations.", "paper_title": "SELF-IMPROVING ALGORITHMS", "paper_id": "WOS:000289974100006"}