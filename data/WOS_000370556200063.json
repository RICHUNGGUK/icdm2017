{"auto_keywords": [{"score": 0.032678754834654204, "phrase": "corral"}, {"score": 0.00481495049065317, "phrase": "data-parallel_jobs"}, {"score": 0.004575053987970206, "phrase": "network_congestion"}, {"score": 0.004536244367689415, "phrase": "big_data_jobs"}, {"score": 0.004497762477097628, "phrase": "cluster_management_frameworks"}, {"score": 0.004347057700479576, "phrase": "network_flows"}, {"score": 0.004201381218977942, "phrase": "job_input_data"}, {"score": 0.003891140864902669, "phrase": "large_fraction"}, {"score": 0.003858110309630846, "phrase": "production_jobs"}, {"score": 0.0037928847801943404, "phrase": "predictable_characteristics"}, {"score": 0.0029744042270542655, "phrase": "future_workloads"}, {"score": 0.002924074850256874, "phrase": "offline_schedule"}, {"score": 0.0027781249331615813, "phrase": "better_data_locality"}, {"score": 0.0026058621464926826, "phrase": "different_parts"}, {"score": 0.002444254652283002, "phrase": "apache_yarn"}, {"score": 0.00235213013487844, "phrase": "production_workloads"}, {"score": 0.0023123057299992587, "phrase": "yarn's_capacity_scheduler"}], "paper_keywords": ["Data-intensive applications", " Cluster schedulers", " Joint data and compute placement", " Cross-layer optimization"], "paper_abstract": "To reduce the impact of network congestion on big data jobs, cluster management frameworks use various heuristics to schedule compute tasks and/or network flows. Most of these schedulers consider the job input data fixed and greedily schedule the tasks and flows that are ready to run. However, a large fraction of production jobs are recurring with predictable characteristics, which allows us to plan ahead for them. Coordinating the placement of data and tasks of these jobs allows for significantly improving their network locality and freeing up bandwidth, which can be used by other jobs running on the cluster. With this intuition, we develop Corral, a scheduling framework that uses characteristics of future workloads to determine an offline schedule which (i) jointly places data and compute to achieve better data locality, and (ii) isolates jobs both spatially (by scheduling them in different parts of the cluster) and temporally, improving their performance. We implement Corral on Apache Yarn, and evaluate it on a 210 machine cluster using production workloads. Compared to Yarn's capacity scheduler, Corral reduces the makespan of these workloads up to 33% and the median completion time up to 56%, with 20-90% reduction in data transferred across racks.", "paper_title": "Network-Aware Scheduling for Data-Parallel Jobs: Plan When You Can", "paper_id": "WOS:000370556200063"}