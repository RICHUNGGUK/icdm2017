{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "activity_recognition"}, {"score": 0.0047273577269638725, "phrase": "unconstrained_videos"}, {"score": 0.004598933498016774, "phrase": "audio_and_image_processing"}, {"score": 0.004473982381245469, "phrase": "video_content"}, {"score": 0.0036553070575015344, "phrase": "video_sequences"}, {"score": 0.0033961782274326948, "phrase": "data_streams"}, {"score": 0.0033037970113095577, "phrase": "relevant_information"}, {"score": 0.0030695103543472908, "phrase": "video_context"}, {"score": 0.0030135741897058844, "phrase": "activity_recognition_model"}, {"score": 0.002825681384008326, "phrase": "audio_and_visual_features"}, {"score": 0.002723607240517261, "phrase": "feature_reduction"}, {"score": 0.002673957615079041, "phrase": "information_fusion"}, {"score": 0.0024842242921857705, "phrase": "video_based_decision_making"}, {"score": 0.002183938718432764, "phrase": "audio_data"}, {"score": 0.0021049977753042253, "phrase": "image_data"}], "paper_keywords": [""], "paper_abstract": "Combining audio and image processing for understanding video content has several benefits when compared to using each modality on their own. For the task of context and activity recognition in video sequences, it is important to explore both data streams to gather relevant information. In this paper we describe a video context and activity recognition model. Our work extracts a range of audio and visual features, followed by feature reduction and information fusion. We show that combining audio with video based decision making improves the quality of context and activity recognition in videos by 4% over audio data and 18% over image data.", "paper_title": "Audio and video feature fusion for activity recognition in unconstrained videos", "paper_id": "WOS:000241790900099"}