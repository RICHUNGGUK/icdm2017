{"auto_keywords": [{"score": 0.036480295477136604, "phrase": "visuo-motor_loop"}, {"score": 0.012229053643276065, "phrase": "action_recognition"}, {"score": 0.00481495049065317, "phrase": "sensory_processing"}, {"score": 0.004766388573192505, "phrase": "mirror_neuron_computational_modelling"}, {"score": 0.004647105813224402, "phrase": "hand-joint_covariation"}, {"score": 0.004507882471601552, "phrase": "grasping_actions"}, {"score": 0.004395040468458808, "phrase": "simplified_descriptions"}, {"score": 0.004241771072194993, "phrase": "small_sets"}, {"score": 0.004198965651975536, "phrase": "hand-joint_parameters"}, {"score": 0.004135562737140424, "phrase": "computational_model"}, {"score": 0.00409382470158851, "phrase": "mirror_mechanisms"}, {"score": 0.003991305899593133, "phrase": "mirror_neurons"}, {"score": 0.0038131738052230254, "phrase": "simplified_motor_information"}, {"score": 0.003587924960158317, "phrase": "grasping_action_recognition_processes"}, {"score": 0.0033759367489122716, "phrase": "iterated_use"}, {"score": 0.003341839487905525, "phrase": "mirror-coded_motor_information"}, {"score": 0.0031926001871260524, "phrase": "reach-to-grasp_actions"}, {"score": 0.002988685006809336, "phrase": "visual_inputs"}, {"score": 0.002840708910768261, "phrase": "recognition_procedures"}, {"score": 0.0027554538693034163, "phrase": "visual_processing"}, {"score": 0.002632332114727894, "phrase": "distinctive_feature"}, {"score": 0.0025146979283050923, "phrase": "direct_matching_hypothesis"}, {"score": 0.002342048999008582, "phrase": "computational_models"}, {"score": 0.0023066199295447686, "phrase": "mirror_neuron_activity"}, {"score": 0.002283298119790413, "phrase": "action_observation"}, {"score": 0.002248755794042486, "phrase": "final_outcome"}, {"score": 0.002226017732566121, "phrase": "computational_processes"}, {"score": 0.0021049977753042253, "phrase": "motor_systems"}], "paper_keywords": ["Mirror neurons", " Direct-matching hypothesis", " Motor knowledge", " Motor-driven sensory processing", " Grasping actions"], "paper_abstract": "Typical patterns of hand-joint covariation arising in the context of grasping actions enable one to provide simplified descriptions of these actions in terms of small sets of hand-joint parameters. The computational model of mirror mechanisms introduced here hypothesizes that mirror neurons are crucially involved in coding and making this simplified motor information available for both action recognition and control processes. In particular, grasping action recognition processes are modeled in terms of a visuo-motor loop enabling one to make iterated use of mirror-coded motor information. In simulation experiments concerning the classification of reach-to-grasp actions, mirror-coded information was found to simplify the processing of visual inputs and to improve action recognition results with respect to recognition procedures that are solely based on visual processing. The visuo-motor loop involved in action recognition is a distinctive feature of this model which is coherent with the direct matching hypothesis. Moreover, the visuo-motor loop sets the model introduced here apart from those computational models that identify mirror neuron activity in action observation with the final outcome of computational processes unidirectionally flowing from sensory (and usually visual) to motor systems.", "paper_title": "From motor to sensory processing in mirror neuron computational modelling", "paper_id": "WOS:000285989200005"}