{"auto_keywords": [{"score": 0.05007776289246189, "phrase": "continuous_hand_gesture_recognition"}, {"score": 0.04606376511999381, "phrase": "gesture_segmentation"}, {"score": 0.04479515183186425, "phrase": "meaningful_gestures"}, {"score": 0.044328060715159615, "phrase": "unintentional_movements"}, {"score": 0.035281305936450263, "phrase": "mcc"}, {"score": 0.025731546066714513, "phrase": "recognition_rate"}, {"score": 0.024391572394191634, "phrase": "proposed_features"}, {"score": 0.004728122501822142, "phrase": "natural_use"}, {"score": 0.00467677555573346, "phrase": "human_hand"}, {"score": 0.004316812490871324, "phrase": "end_points"}, {"score": 0.004132237700479874, "phrase": "formidable_challenge"}, {"score": 0.0040873354289955605, "phrase": "unconstrained_spatiotemporal_variations"}, {"score": 0.003941141575848601, "phrase": "successive_gestures"}, {"score": 0.0038559375376635047, "phrase": "hand_image_segmentation"}, {"score": 0.0038140261371648744, "phrase": "estimated_hand_motion_trajectory"}, {"score": 0.003745179888113379, "phrase": "actual_one"}, {"score": 0.0033696019683761274, "phrase": "gesture's_motion_chain_code"}, {"score": 0.0031099353574309606, "phrase": "ellipse_least-squares"}, {"score": 0.0030761074505030184, "phrase": "motion-trajectory_points"}, {"score": 0.0028702214190712036, "phrase": "conditional_random_fields"}, {"score": 0.00250789768689397, "phrase": "training_data"}, {"score": 0.0024715695446993107, "phrase": "testing_data"}, {"score": 0.002444668348634501, "phrase": "isolated_gestures"}, {"score": 0.0023657047082774286, "phrase": "feature_vector"}, {"score": 0.0022397131088479514, "phrase": "continuous_gestures"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Human-computer interaction (HCI)", " Gesture recognition", " Motion chain code (MCC)", " Conditional random fields (CRF)"], "paper_abstract": "Applications requiring the natural use of the human hand as a human-computer interface motivate research on continuous hand gesture recognition. Gesture recognition depends on gesture segmentation to locate the starting and end points of meaningful gestures while ignoring unintentional movements. Unfortunately, gesture segmentation remains a formidable challenge because of unconstrained spatiotemporal variations in gestures and the coarticulation and movement epenthesis of successive gestures. Furthermore, errors in hand image segmentation cause the estimated hand motion trajectory to deviate from the actual one. This research moves toward addressing these problems. Our approach entails using gesture spotting to distinguish meaningful gestures from unintentional movements. To avoid the effects of variations in a gesture's motion chain code (MCC), we propose instead to use a novel set of features: the (a) orientation and (b) length of an ellipse least-squares fitted to motion-trajectory points and (c) the position of the hand. The features are designed to support classification using conditional random fields. To evaluate the performance of the system, 10 participants signed 10 gestures several times each, providing a total of 75 instances per gesture. To train the system, 50 instances of each gesture served as training data and 25 as testing data. For isolated gestures, the recognition rate using the MCC as a feature vector was only 69.6 % but rose to 96.0 % using the proposed features, a 26.1 % improvement. For continuous gestures, the recognition rate for the proposed features was 88.9 %. These results show the efficacy of the proposed method.", "paper_title": "A novel set of features for continuous hand gesture recognition", "paper_id": "WOS:000343714200001"}