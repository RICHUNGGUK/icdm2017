{"auto_keywords": [{"score": 0.042326323148367415, "phrase": "envisor"}, {"score": 0.00481495049065317, "phrase": "panorama_construction"}, {"score": 0.004642105253191792, "phrase": "main_goals"}, {"score": 0.004574709094672837, "phrase": "anywhere_augmentation"}, {"score": 0.0044104497301196794, "phrase": "automatic_algorithms"}, {"score": 0.0043464021636703066, "phrase": "scene_acquisition"}, {"score": 0.004283280680222718, "phrase": "augmented_reality_systems"}, {"score": 0.0038946650372062783, "phrase": "online_construction"}, {"score": 0.0038380787059463075, "phrase": "environment_maps"}, {"score": 0.0037823114064881357, "phrase": "new_locations"}, {"score": 0.0035671997165370403, "phrase": "vision-based_frame"}, {"score": 0.0030587884803931964, "phrase": "hybrid_tracking"}, {"score": 0.002992313172550772, "phrase": "tracked_video"}, {"score": 0.002863652837038965, "phrase": "cubemap_frame"}, {"score": 0.002782631443186265, "phrase": "feedback"}, {"score": 0.002473325513637559, "phrase": "remaining_gaps"}, {"score": 0.002401875938287542, "phrase": "texture_diffusion"}, {"score": 0.0023496433751182162, "phrase": "resulting_environment_map"}, {"score": 0.002136087390959268, "phrase": "virtual_geometry"}, {"score": 0.0021049977753042253, "phrase": "remote_presence"}], "paper_keywords": ["Vision-based tracking", " Environment mapping", " Wearable computing", " Anywhere augmentation"], "paper_abstract": "One of the main goals of anywhere augmentation is the development of automatic algorithms for scene acquisition in augmented reality systems. In this paper, we present Envisor, a system for online construction of environment maps in new locations. To accomplish this, Envisor uses vision-based frame to frame and landmark orientation tracking for long-term, drift-free registration. For additional robustness, a gyroscope/compass orientation unit can optionally be used for hybrid tracking. The tracked video is then projected into a cubemap frame by frame. Feedback is presented to the user to help avoid gaps in the cubemap, while any remaining gaps are filled by texture diffusion. The resulting environment map can be used for a variety of applications, including shading of virtual geometry and remote presence. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "All around the map: Online spherical panorama construction", "paper_id": "WOS:000263999800009"}