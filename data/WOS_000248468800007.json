{"auto_keywords": [{"score": 0.04752959155799194, "phrase": "dissimilarity-based_classifiers"}, {"score": 0.04492262832868242, "phrase": "pattern_recognition"}, {"score": 0.00481495049065317, "phrase": "prototype_reduction_schemes"}, {"score": 0.0047846807459660376, "phrase": "dissimilarity-based_classification"}, {"score": 0.0046361494357125355, "phrase": "new_philosophy"}, {"score": 0.004616695177612296, "phrase": "pattern_classification"}, {"score": 0.004417267632253208, "phrase": "duin"}, {"score": 0.004371140471236982, "phrase": "refs"}, {"score": 0.004316252588345957, "phrase": "featureless_approach"}, {"score": 0.004035282762331904, "phrase": "dissimilarity_representations"}, {"score": 0.0040014674678590925, "phrase": "good_classifiers"}, {"score": 0.003984665807155269, "phrase": "pattern_recognition_lett"}, {"score": 0.0037964245233293153, "phrase": "d._thesis"}, {"score": 0.0037804805443877507, "phrase": "delft_university_of_technology"}, {"score": 0.0037646077506966833, "phrase": "delft"}, {"score": 0.0037104631549909587, "phrase": "prototype"}, {"score": 0.003460648034270165, "phrase": "feature_measurements"}, {"score": 0.003438862848980368, "phrase": "individual_patterns"}, {"score": 0.003395701636993945, "phrase": "suitable_dissimilarity_measure"}, {"score": 0.003269430616888197, "phrase": "class-conditional_distributions"}, {"score": 0.00322159890493599, "phrase": "bayes'_error"}, {"score": 0.003095257144856771, "phrase": "inter-pattern_dissimilarities"}, {"score": 0.002999012736727594, "phrase": "dissimilarity_space"}, {"score": 0.002887450071878095, "phrase": "novel_strategy"}, {"score": 0.0027741815554693126, "phrase": "dbc"}, {"score": 0.0027508996603059937, "phrase": "entire_data_set"}, {"score": 0.0027163495475545922, "phrase": "training_set"}, {"score": 0.0026822322021876127, "phrase": "smaller_representative_subset"}, {"score": 0.002609770322855842, "phrase": "random_selection"}, {"score": 0.002533916631159743, "phrase": "prototype_reduction_scheme"}, {"score": 0.0024602629420539253, "phrase": "dbc."}, {"score": 0.0023340085406417114, "phrase": "mahalanobis_distance"}, {"score": 0.0023192991767600106, "phrase": "dissimilarity-measurement_criterion"}, {"score": 0.002299830460180699, "phrase": "dbcs_classification_accuracy"}, {"score": 0.0022709326810964386, "phrase": "proposed_mechanism"}, {"score": 0.002256619934086924, "phrase": "classification_accuracy"}, {"score": 0.002232965087504122, "phrase": "\"conventional\"_approaches"}, {"score": 0.002195630875026716, "phrase": "artificial_data_sets"}, {"score": 0.0021726139494880653, "phrase": "resulting_dissimilarity_criterion"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["dissimilarity representation", " dissimilarity-based classification", " prototype reduction schemes (PRSs)", " Mahalanobis distances (MDs)"], "paper_abstract": "The aim of this paper is to present a strategy by which a new philosophy for pattern classification, namely that pertaining to dissimilarity-based classifiers (DBCs), can be efficiently implemented. This methodology, proposed by Duin and his co-authors (see Refs. [Experiments with a featureless approach to pattern recognition, Pattern Recognition Lett. 18 (1997) 1159-1166; Relational discriminant analysis, Pattern Recognition Lett. 20 (1999) 1175-1181; Dissimilarity representations allow for buillding good classifiers, Pattern Recognition Lett. 23 (2002) 943-956; Dissimilarity representations in pattern recognition, Concepts, theory and applications, Ph.D. Thesis, Delft University of Technology, Delft, The Netherlands, 2005; Prototype selection for dissimilarity-based classifiers, Pattern Recognition 39 (2006) 189-208]), is a way of defining classifiers between the classes, and is not based on the feature measurements of the individual patterns, but rather on a suitable dissimilarity measure between them. The advantage of this methodology is that since it does not operate on the class-conditional distributions, the accuracy can exceed the Bayes' error bound. The problem with this strategy is, however, the need to compute, store and process the inter-pattern dissimilarities for all the training samples, and thus, the accuracy of the classifier designed in the dissimilarity space is dependent on the methods used to achieve this. In this paper, we suggest a novel strategy to enhance the computation for all families of DBCs. Rather than compute, store and process the DBC based on the entire data set, we advocate that the training set be first reduced into a smaller representative subset. Also, rather than determine this subset on the basis of random selection, or clustering, etc., we advocate the use of a prototype reduction scheme (PRS), whose output yields the points to be utilized by the DBC. The rationale for this is explained in the paper. Apart from utilizing PRSs, in the paper we also propose simultaneously employing the Mahalanobis distance as the dissimilarity-measurement criterion to increase the DBCs classification accuracy. Our experimental results demonstrate that the proposed mechanism increases the classification accuracy when compared with the \"conventional\" approaches for samples involving real-life as well as artificial data sets-even though the resulting dissimilarity criterion is not symmetric. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "On using prototype reduction schemes to optimize dissimilarity-based classification", "paper_id": "WOS:000248468800007"}