{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "high-dimensional_spectral_features"}, {"score": 0.004725385523804256, "phrase": "pattern_recognition_methods"}, {"score": 0.004285702427563952, "phrase": "feature_selection_techniques"}, {"score": 0.004237666411136617, "phrase": "irrelevant_and_noisy_features"}, {"score": 0.004005410765048467, "phrase": "better_classification_performance"}, {"score": 0.0038721890530859578, "phrase": "novel_feature_selection_method"}, {"score": 0.003785836059995376, "phrase": "information-theoretic_framework"}, {"score": 0.003659890662429693, "phrase": "statistical_relation"}, {"score": 0.0035514484574435574, "phrase": "class_labels"}, {"score": 0.003407549468745519, "phrase": "ranking_single_features"}, {"score": 0.003043957650600757, "phrase": "different_estimation_methods"}, {"score": 0.0029984960344766705, "phrase": "density_estimation"}, {"score": 0.0029648446274266765, "phrase": "entropy_and_mutual_information"}, {"score": 0.0028021527740710508, "phrase": "multivariate_sets"}, {"score": 0.002678433668156676, "phrase": "spectral_graph_features"}, {"score": 0.0025989960809479104, "phrase": "existing_graph_classification_techniques"}, {"score": 0.0025124343366192954, "phrase": "unattributed_graphs"}, {"score": 0.0024287485834314027, "phrase": "spectral_feature"}, {"score": 0.0022105951175680856, "phrase": "selected_spectral_features"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Feature selection", " Pattern classification", " Information theory", " Mutual information", " Entropy", " Structure", " Spectral features"], "paper_abstract": "Pattern recognition methods often deal with samples consisting of thousands of features. Therefore, the reduction of their dimensionality becomes crucial to make the data sets tractable. Feature selection techniques remove the irrelevant and noisy features and select a subset of features which describe better the samples and produce a better classification performance. In this paper, we propose a novel feature selection method for supervised classification within an information-theoretic framework. Mutual information is exploited for measuring the statistical relation between a subset of features and the class labels of the samples. Traditionally it has been measured for ranking single features; however, in most data sets the features are not independent and their combination provides much more information about the class than the sum of their individual prediction power. We analyze the use of different estimation methods which bypass the density estimation and estimate entropy and mutual information directly from the set of samples. These methods allow us to efficiently evaluate multivariate sets of thousands of features. Within this framework we experiment with spectral graph features extracted from 3D shapes. Most of the existing graph classification techniques rely on the graph attributes. We use unattributed graphs to show what is the contribution of each spectral feature to graph classification. Apart from succeeding to classify graphs from shapes relying only on their structure, we test to what extent the set of selected spectral features are robust to perturbations of the dataset. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Information-theoretic selection of high-dimensional spectral features for structural recognition", "paper_id": "WOS:000314674100003"}