{"auto_keywords": [{"score": 0.02246846748295755, "phrase": "online_training"}, {"score": 0.00481495049065317, "phrase": "different_training_algorithms"}, {"score": 0.004674952036988355, "phrase": "radial_basis_functions"}, {"score": 0.004539060202211106, "phrase": "rbf"}, {"score": 0.004406994912939125, "phrase": "neural_networks"}, {"score": 0.003974349782102708, "phrase": "classical_training"}, {"score": 0.0036914757355166966, "phrase": "unsupervised_training"}, {"score": 0.003378385493203297, "phrase": "supervised_training"}, {"score": 0.002914288956035066, "phrase": "full_supervised_training"}, {"score": 0.0028293966058473476, "phrase": "gradient_descent"}, {"score": 0.0024405312482831646, "phrase": "fully_supervised_training"}, {"score": 0.0021682027434117095, "phrase": "batch_training"}], "paper_keywords": [""], "paper_abstract": "In this paper, we present experiments comparing different training algorithms for Radial Basis Functions (RBF) neural networks. In particular we compare the classical training which consist of an unsupervised training of centers followed by a supervised training of the weights at the output, with the full supervised training by gradient descent proposed recently in same papers. We conclude that a fully supervised training performs generally better. We also compare Batch training with Online training and we conclude that Online training suppose a reduction in the number of iterations.", "paper_title": "Training RBFs networks: A comparison among supervised and not supervised algorithms", "paper_id": "WOS:000241790100053"}