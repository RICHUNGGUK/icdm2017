{"auto_keywords": [{"score": 0.048799520930917564, "phrase": "multiple_kernel_regression"}, {"score": 0.04838011372739916, "phrase": "mixed_variables"}, {"score": 0.004814974089936647, "phrase": "metamodel"}, {"score": 0.0045404698551856125, "phrase": "metamodel-assisted_optimization"}, {"score": 0.00447937340641839, "phrase": "continuous_variables"}, {"score": 0.004359625030298944, "phrase": "additional_presence"}, {"score": 0.004320421465896323, "phrase": "categorical_data"}, {"score": 0.0040010534672646775, "phrase": "common_approach"}, {"score": 0.0037898820206470085, "phrase": "poor_approximation_results"}, {"score": 0.0036553070575015344, "phrase": "best_coding"}, {"score": 0.003525493807130663, "phrase": "accurate_and_flexible_metamodels"}, {"score": 0.0034780071331554003, "phrase": "special_attention"}, {"score": 0.0033242742850902295, "phrase": "distinct_nature"}, {"score": 0.0031917146566068245, "phrase": "multiple_kernel_regression_methodology"}, {"score": 0.0030644247579222333, "phrase": "separate_kernel_functions"}, {"score": 0.0029959082125682918, "phrase": "variable_type"}, {"score": 0.002915701586760994, "phrase": "advocated_approach"}, {"score": 0.0028505007899807446, "phrase": "six_analytical_benchmark_test_cases"}, {"score": 0.0027993885490232677, "phrase": "structural_responses"}, {"score": 0.0027616550517346066, "phrase": "rigid_frame"}, {"score": 0.002687702958515561, "phrase": "better_performances"}, {"score": 0.0024220634963019114, "phrase": "dummy_coding"}, {"score": 0.00237861522566195, "phrase": "multi-objective_surrogate-based_optimization"}, {"score": 0.0023253967212081626, "phrase": "rigid_frame_example"}, {"score": 0.002202469129781332, "phrase": "structural_design"}, {"score": 0.0021049977753042253, "phrase": "finite_element_simulations"}], "paper_keywords": ["Multiple kernel regression", " Mixed variables", " Metamodels", " Categorical variables", " Dummy coding"], "paper_abstract": "While studies in metamodel-assisted optimization predominantly involve continuous variables, this paper explores the additional presence of categorical data, representing for instance the choice of a material or the type of connection. The common approach consisting in mapping them onto integers might lead to inconsistencies or poor approximation results. Therefore, an investigation of the best coding is necessary; however, to build accurate and flexible metamodels, a special attention should also be devoted to the treatment of the distinct nature of the variables involved. Consequently, a multiple kernel regression methodology is proposed, since it allows for selecting separate kernel functions with respect to the variable type. The validation of the advocated approach is carried out on six analytical benchmark test cases and on the structural responses of a rigid frame. In all cases, better performances are obtained by multiple kernel regression with respect to its single kernel counterpart, thereby demonstrating the potential offered by this approach, especially in combination with dummy coding. Finally, multi-objective surrogate-based optimization is performed on the rigid frame example, firstly to illustrate the benefit of dealing with mixed variables for structural design, then to show the reduction in terms of finite element simulations obtained thanks to the metamodels.", "paper_title": "Metamodel-assisted optimization based on multiple kernel regression for mixed variables", "paper_id": "WOS:000336286800007"}