{"auto_keywords": [{"score": 0.049725544371589304, "phrase": "parallel_execution"}, {"score": 0.04937491786272553, "phrase": "continuous_queries"}, {"score": 0.03960170697908397, "phrase": "tuple_latency"}, {"score": 0.02854734054944413, "phrase": "dispatching_method"}, {"score": 0.00481495049065317, "phrase": "stream_operators"}, {"score": 0.0047090997998449095, "phrase": "data_stream"}, {"score": 0.004487635647709636, "phrase": "online_manner"}, {"score": 0.004356535752468849, "phrase": "data_stream_management_systems"}, {"score": 0.004276541976450121, "phrase": "single_processor_dsmss"}, {"score": 0.004213601332868765, "phrase": "data_stream_applications'_requirements"}, {"score": 0.0038548668648948044, "phrase": "performance_improvement"}, {"score": 0.0036734281414482735, "phrase": "event-driven_manner"}, {"score": 0.0036327808996444904, "phrase": "system_performance_reduction"}, {"score": 0.003579280847524597, "phrase": "consecutive_scheduling_instances"}, {"score": 0.0034875380341306468, "phrase": "continuous_scheduling_method"}, {"score": 0.003335683866508191, "phrase": "continuous_nature"}, {"score": 0.0033110234463504125, "phrase": "data_streams"}, {"score": 0.0032261342460565457, "phrase": "system_adaptivity"}, {"score": 0.0031551009669284545, "phrase": "multiprocessing_environment"}, {"score": 0.0030856268625708695, "phrase": "processing_nodes"}, {"score": 0.003006499028632742, "phrase": "partially-processed_tuples"}, {"score": 0.002951220859491642, "phrase": "minimum_workload"}, {"score": 0.0029077288662492894, "phrase": "next_operator"}, {"score": 0.0028436862612859896, "phrase": "operator_scheduling"}, {"score": 0.002515786966417755, "phrase": "petrinets"}, {"score": 0.002388337333984138, "phrase": "system_performance"}, {"score": 0.002309828105129336, "phrase": "tuple_loss"}, {"score": 0.002250549946875429, "phrase": "system_performance_parameters"}, {"score": 0.002128587147609539, "phrase": "high_adaptivity"}, {"score": 0.0021049977753042253, "phrase": "underlying_system"}], "paper_keywords": ["Operator scheduling", " Continuous queries", " Data stream", " Query plan", " Dispatching"], "paper_abstract": "Data stream is a continuous, rapid, time-varying sequence of data elements which should be processed in an online manner. These matters are under research in Data Stream Management Systems (DSMSs). Single processor DSMSs cannot satisfy data stream applications' requirements properly. Main shortcomings are tuple latency, tuple loss, and throughput. In our previous publications, we introduced parallel execution of continuous queries to overcome these problems via performance improvement, especially in terms of tuple latency. We scheduled operators in an event-driven manner which caused system performance reduction in periods between consecutive scheduling instances. In this paper, a continuous scheduling method (dispatching) is presented to be more compatible with the continuous nature of data streams as well as queries to improve system adaptivity and performance. In a multiprocessing environment, the dispatching method forces processing nodes (logical machines) to send partially-processed tuples to next machines with minimum workload to execute the next operator on them. So, operator scheduling is done continuously and dynamically for each tuple processed by each operator. The dispatching method is described, formally presented, and its correctness is proved. Also, it is modeled in PetriNets and is evaluated via simulation. Results show that the dispatching method significantly improves system performance in terms of tuple latency, throughput, and tuple loss. Furthermore, the fluctuation of system performance parameters (against variation of system and stream characteristics) diminishes considerably and leads to high adaptivity with the underlying system.", "paper_title": "Dispatching stream operators in parallel execution of continuous queries", "paper_id": "WOS:000308110100014"}