{"auto_keywords": [{"score": 0.047667240890459914, "phrase": "attribute_selection_approach"}, {"score": 0.04253339085581913, "phrase": "selected_attribute_subset"}, {"score": 0.041904013256512336, "phrase": "learning_algorithm"}, {"score": 0.004692227830462433, "phrase": "naive_bayes"}, {"score": 0.00450231514359539, "phrase": "remarkable_performance"}, {"score": 0.004410248125081398, "phrase": "attribute_selection"}, {"score": 0.004145143433523008, "phrase": "general_data_characteristics"}, {"score": 0.003757480190200645, "phrase": "black_box"}, {"score": 0.0033883824438527316, "phrase": "improved_naive_bayes_algorithm"}, {"score": 0.0033190180867511605, "phrase": "random_search"}, {"score": 0.003267925215811654, "phrase": "whole_space"}, {"score": 0.0028273061946184645, "phrase": "class_probability_estimation"}, {"score": 0.0026026666736474404, "phrase": "rsnb-cll."}, {"score": 0.00257586859792573, "phrase": "experimental_results"}, {"score": 0.0025230952890994236, "phrase": "large_number"}, {"score": 0.0024971144603069006, "phrase": "uci_datasets"}, {"score": 0.002420762293555924, "phrase": "classification_accuracy"}, {"score": 0.002395858002992426, "phrase": "acc"}, {"score": 0.0023225701080913388, "phrase": "roc_curve"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Naive Bayes", " Attribute selection", " Random search", " Classification", " Ranking", " Class probability estimation"], "paper_abstract": "Many approaches are proposed to improve Naive Bayes, among which the attribute selection approach has demonstrated remarkable performance. Algorithms for attribute selection fall into two broad categories: filters and wrappers. Filters use the general data characteristics to evaluate the selected attribute subset before the learning algorithm is run, while wrappers use the learning algorithm itself as a black box to evaluate the selected attribute subset. In this paper, we work on the attribute selection approach of wrapper and propose an improved Naive Bayes algorithm by carrying a random search through the whole space of attributes. We simply called it Randomly Selected Naive Bayes (RSNB). In order to meet the need of classification, ranking, and class probability estimation, we discriminatively design three different versions: RSNB-ACC, RSNB-AUC, and RSNB-CLL. The experimental results based on a large number of UCI datasets validate their effectiveness in terms of classification accuracy (ACC), area under the ROC curve (AUC), and conditional log likelihood (CLL), respectively. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Not so greedy: Randomly Selected Naive Bayes", "paper_id": "WOS:000305863300070"}