{"auto_keywords": [{"score": 0.04954033184026155, "phrase": "hadoop"}, {"score": 0.04420986046152407, "phrase": "mapreduce_cluster"}, {"score": 0.00481495049065317, "phrase": "efficient_task_assignments"}, {"score": 0.004680624753255133, "phrase": "mapreduce_paradigm"}, {"score": 0.00447341965028879, "phrase": "important_standard"}, {"score": 0.004423061344624088, "phrase": "large-scale_data-intensive_processing"}, {"score": 0.004109212945115815, "phrase": "multiple_users"}, {"score": 0.004062937864702115, "phrase": "different_types"}, {"score": 0.003627800727103479, "phrase": "shared_resources"}, {"score": 0.0035666632046674153, "phrase": "overall_system_performance"}, {"score": 0.0034867406208212146, "phrase": "job_response_times"}, {"score": 0.0032208091960514128, "phrase": "efficient_scheduling"}, {"score": 0.0030606302942851027, "phrase": "conventional_scheduling_algorithms"}, {"score": 0.0029249294679606656, "phrase": "good_average_response_times"}, {"score": 0.0027170943110836425, "phrase": "new_hadoop_scheduler"}, {"score": 0.0026113524778702624, "phrase": "workload_patterns"}, {"score": 0.0025673005153462707, "phrase": "average_job_response_times"}, {"score": 0.002495521662819317, "phrase": "resource_shares"}, {"score": 0.0024257447861185813, "phrase": "scheduling_algorithms"}, {"score": 0.002318127769195112, "phrase": "real_experimental_results"}, {"score": 0.002215274527909304, "phrase": "average_mapreduce_job_response_time"}, {"score": 0.002153316680437517, "phrase": "system_workloads"}, {"score": 0.0021049977753042253, "phrase": "existing_fifo_and_fair_schedulers"}], "paper_keywords": ["MapReduce", " hadoop", " schdeuling", " heavy-tailed workloads", " bursty workloads"], "paper_abstract": "The MapReduce paradigm and its open source implementation Hadoop are emerging as an important standard for large-scale data-intensive processing in both industry and academia. A MapReduce cluster is typically shared among multiple users with different types of workloads. When a flock of jobs are concurrently submitted to a MapReduce cluster, they compete for the shared resources and the overall system performance in terms of job response times, might be seriously degraded. Therefore, one challenging issue is the ability of efficient scheduling in such a shared MapReduce environment. However, we find that conventional scheduling algorithms supported by Hadoop cannot always guarantee good average response times under different workloads. To address this issue, we propose a new Hadoop scheduler, which leverages the knowledge of workload patterns to reduce average job response times by dynamically tuning the resource shares among users and the scheduling algorithms for each user. Both simulation and real experimental results from Amazon EC2 cluster show that our scheduler reduces the average MapReduce job response time under a variety of system workloads compared to the existing FIFO and Fair schedulers.", "paper_title": "LsPS: A Job Size-Based Scheduler for Efficient Task Assignments in Hadoop", "paper_id": "WOS:000371894200001"}