{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "social_recommender_systems"}, {"score": 0.01379733414792682, "phrase": "malicious_attacks"}, {"score": 0.010108050104383225, "phrase": "closely_correlated_items"}, {"score": 0.004713162564945179, "phrase": "user-contributed_data"}, {"score": 0.004663074596384574, "phrase": "users'_preference"}, {"score": 0.004515967518891287, "phrase": "social_networking_services"}, {"score": 0.004190438004831167, "phrase": "social_spammers"}, {"score": 0.0040150576454166306, "phrase": "noisy"}, {"score": 0.003986509098918949, "phrase": "non-malicious_users"}, {"score": 0.0038606630003037864, "phrase": "genuine_users"}, {"score": 0.0037924666577694222, "phrase": "untruthful_data"}, {"score": 0.003607834976869384, "phrase": "similarly-behaved_user_profiles"}, {"score": 0.003051073364818384, "phrase": "similar_scores"}, {"score": 0.0029971349193857093, "phrase": "effective_method"}, {"score": 0.002975826686621829, "phrase": "nnmu_detection"}, {"score": 0.002923214590192792, "phrase": "user's_\"self-contradictions"}, {"score": 0.0027413748388534025, "phrase": "self-contradiction_capturing"}, {"score": 0.0025984901976634726, "phrase": "slack_variables"}, {"score": 0.0025073851194697397, "phrase": "underlying_noise"}, {"score": 0.002480680078868508, "phrase": "test_user_profile"}, {"score": 0.0024022553322977165, "phrase": "proposed_method"}, {"score": 0.0023766673143502384, "phrase": "experimental_results"}, {"score": 0.0022933216359142736, "phrase": "real-world_nnmu_detection_scenarios"}, {"score": 0.0021659920594094407, "phrase": "recommendation_performance"}, {"score": 0.002127667143545464, "phrase": "detected_nnmus"}, {"score": 0.0021049977753042253, "phrase": "recommender_system"}], "paper_keywords": ["social recommendation", " noisy user detection", " collaborative filtering", " rating noise quantification"], "paper_abstract": "Social recommender systems largely rely on user-contributed data to infer users' preference. While this feature has enabled many interesting applications in social networking services, it also introduces unreliability to recommenders as users are allowed to insert data freely. Although detecting malicious attacks from social spammers has been studied for years, little work was done for detecting Noisy but Non-Malicious Users (NNMUs), which refers to those genuine users who may provide some untruthful data due to their imperfect behaviors. Unlike colluded malicious attacks that can be detected by finding similarly-behaved user profiles, NNMUs are more difficult to identify since their profiles are neither similar nor correlated from one another. In this article, we study how to detect NNMUs in social recommender systems. Based on the assumption that the ratings provided by a same user on closely correlated items should have similar scores, we propose an effective method for NNMU detection by capturing and accumulating user's \"self-contradictions\", i.e., the cases that a user provides very different rating scores on closely correlated items. We show that self-contradiction capturing can be formulated as a constrained quadratic optimization problem w.r.t. a set of slack variables, which can be further used to quantify the underlying noise in each test user profile. We adopt three real-world data sets to empirically test the proposed method. The experimental results show that our method (i) is effective in real-world NNMU detection scenarios, (ii) can significantly outperform other noisy-user detection methods, and (iii) can improve recommendation performance for other users after removing detected NNMUs from the recommender system.", "paper_title": "Noisy but non-malicious user detection in social recommender systems", "paper_id": "WOS:000325432800007"}