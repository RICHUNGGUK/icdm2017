{"auto_keywords": [{"score": 0.03476892074644285, "phrase": "auc"}, {"score": 0.026784696946313608, "phrase": "decision_support"}, {"score": 0.00481495049065317, "phrase": "local_data"}, {"score": 0.0047822773061914105, "phrase": "adaptive_order_menus"}, {"score": 0.004706895428234964, "phrase": "care_variability"}, {"score": 0.004397000006837371, "phrase": "complex_care"}, {"score": 0.004249756517301481, "phrase": "complementary_approach_-_using_bayesian_network"}, {"score": 0.004154332348800334, "phrase": "local_order-entry_data"}, {"score": 0.004051828608343507, "phrase": "expert_review"}, {"score": 0.003996983218174335, "phrase": "development_time"}, {"score": 0.003978866233891427, "phrase": "local_decision_support_content"}, {"score": 0.0038281374948654925, "phrase": "healthcare_system"}, {"score": 0.003716724243777879, "phrase": "greedy_equivalence_search_algorithm"}, {"score": 0.0036167509502276294, "phrase": "emergency_department"}, {"score": 0.00352746447572238, "phrase": "mental_state"}, {"score": 0.003503497128638099, "phrase": "intensive_care_unit"}, {"score": 0.0033554276520303935, "phrase": "hospital-simulation_methodology"}, {"score": 0.0033099773890926643, "phrase": "receiver-operator_curve"}, {"score": 0.0031628621880184114, "phrase": "similar_association-rule-mining_approach"}, {"score": 0.0031271133933467575, "phrase": "short_order_menu"}, {"score": 0.003091767402370757, "phrase": "next_order"}, {"score": 0.0030707512751243214, "phrase": "average_length"}, {"score": 0.003015401937358271, "phrase": "predictive_ability"}, {"score": 0.0029409171055888804, "phrase": "order_types"}, {"score": 0.002835838311928684, "phrase": "high_variance"}, {"score": 0.0028037753646260937, "phrase": "higher_auc"}, {"score": 0.002784711379909081, "phrase": "tighter_clusters"}, {"score": 0.002722093453065922, "phrase": "appropriate_contextual_data"}, {"score": 0.0026913130726432645, "phrase": "association_rule_mining_approach"}, {"score": 0.0026790983342162887, "phrase": "similar_performance"}, {"score": 0.002559951153813876, "phrase": "local_clinical_knowledge"}, {"score": 0.0025309995627197444, "phrase": "treatment_data"}, {"score": 0.002462841318533952, "phrase": "local_standards"}, {"score": 0.0023965141236111194, "phrase": "human-readable_treatment-diagnosis_networks"}, {"score": 0.0023586493263143553, "phrase": "human_expert"}, {"score": 0.002326669201839705, "phrase": "localized_cds_content"}, {"score": 0.0023108417343022537, "phrase": "bn_methodology"}, {"score": 0.0023003498123420237, "phrase": "transitive_associations"}, {"score": 0.0022899054175521626, "phrase": "co-varying_relationships"}, {"score": 0.0022743274702883456, "phrase": "existing_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Clinical Decision Support", " Data mining", " Bayesian analysis"], "paper_abstract": "Objective: Reducing care variability through guidelines has significantly benefited patients. Nonetheless, guideline-based Clinical Decision Support (CDS) systems are not widely implemented or used, are frequently out-of-date, and cannot address complex care for which guidelines do not exist. Here, we develop and evaluate a complementary approach - using Bayesian Network (BN) learning to generate adaptive, context-specific treatment menus based on local order-entry data. These menus can be used as a draft for expert review, in order to minimize development time for local decision support content. This is in keeping with the vision outlined in the US Health Information Technology Strategic Plan, which describes a healthcare system that learns from itself. Materials and methods: We used the Greedy Equivalence Search algorithm to learn four 50-node domain-specific BNs from 11,344 encounters: abdominal pain in the emergency department, inpatient pregnancy, hypertension in the Urgent Visit Clinic, and altered mental state in the intensive care unit. We developed a system to produce situation-specific, rank-ordered treatment menus from these networks. We evaluated this system with a hospital-simulation methodology and computed Area Under the Receiver-Operator Curve (AUC) and average menu position at time of selection. We also compared this system with a similar association-rule-mining approach. Results: A short order menu on average contained the next order (weighted average length 3.91-5.83 items). Overall predictive ability was good: average AUC above 0.9 for 25% of order types and overall average AUC .714-.844 (depending on domain). However, AUC had high variance (.50-.99). Higher AUC correlated with tighter clusters and more connections in the graphs, indicating importance of appropriate contextual data. Comparison with an Association Rule Mining approach showed similar performance for only the most common orders with dramatic divergence as orders are less frequent. Discussion and conclusion: This study demonstrates that local clinical knowledge can be extracted from treatment data for decision support. This approach is appealing because: it reflects local standards; it uses data already being captured; and it produces human-readable treatment-diagnosis networks that could be curated by a human expert to reduce workload in developing localized CDS content. The BN methodology captured transitive associations and co-varying relationships, which existing approaches do not. It also performs better as orders become less frequent and require more context. This system is a step forward in harnessing local, empirical data to enhance decision support. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Decision support from local data: Creating adaptive order menus from past clinician behavior", "paper_id": "WOS:000335429200009"}