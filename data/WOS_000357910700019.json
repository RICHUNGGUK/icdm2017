{"auto_keywords": [{"score": 0.04497733177139571, "phrase": "multi-label_data"}, {"score": 0.02322730111336098, "phrase": "relieff_algorithm"}, {"score": 0.010240040083641513, "phrase": "multi-label_learning_context"}, {"score": 0.005696594300490338, "phrase": "proposed_relieff_extensions"}, {"score": 0.004603525341738782, "phrase": "multi-label_learning"}, {"score": 0.004521566043596533, "phrase": "important_area"}, {"score": 0.004401342842183475, "phrase": "increasing_number"}, {"score": 0.0043619799095455415, "phrase": "modern_applications"}, {"score": 0.004114527599108729, "phrase": "single-label_data"}, {"score": 0.00384633057714983, "phrase": "machine_learning_algorithms"}, {"score": 0.0037272031155266556, "phrase": "feature_weighting"}, {"score": 0.003693846909452865, "phrase": "feature_selection"}, {"score": 0.0036443694410100507, "phrase": "important_feature_engineering_techniques"}, {"score": 0.0035794251590584563, "phrase": "beneficial_impact"}, {"score": 0.003531474887552889, "phrase": "machine_learning"}, {"score": 0.0030307927228223883, "phrase": "relieff-ml"}, {"score": 0.0030036501770192865, "phrase": "ppt-relieff"}, {"score": 0.0029767499830258754, "phrase": "rrelieff-ml."}, {"score": 0.002897482096228207, "phrase": "problem_transformation_method"}, {"score": 0.0028458096625791625, "phrase": "multi-label_problem"}, {"score": 0.0028076592725295646, "phrase": "single-label_problem"}, {"score": 0.0026962411675196213, "phrase": "classic_relieff_algorithm"}, {"score": 0.0025089420019955232, "phrase": "previous_relieff_extensions"}, {"score": 0.002387758958649797, "phrase": "preceding_extensions"}, {"score": 0.0023033100935570755, "phrase": "experimental_results"}, {"score": 0.00216263228969761, "phrase": "better_multi-label_learning"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multi-label learning", " ReliefF algorithm", " Feature weighting", " Feature selection", " Multi-label classification", " Label ranking"], "paper_abstract": "Multi-label learning has become an important area of research due to the increasing number of modern applications that contain multi-label data. The multi-label data are structured in a more complex way than single-label data. Consequently the development of techniques that allow the improvement in the performance of machine learning algorithms over multi-label data is desired. The feature weighting and feature selection algorithms are important feature engineering techniques which have a beneficial impact on the machine learning. The ReliefF algorithm is one of the most popular algorithms to feature estimation and it has proved its usefulness in several domains. This paper presents three extensions of the ReliefF algorithm for working in the multi-label learning context, namely ReliefF-ML, PPT-ReliefF and RReliefF-ML. PPT-ReliefF uses a problem transformation method to convert the multi-label problem into a single-label problem. ReliefF-ML and RReliefF-ML adapt the classic ReliefF algorithm in order to handle directly the multi-label data. The proposed ReliefF extensions are evaluated and compared with previous ReliefF extensions on 34 multi-label datasets. The results show that the proposed ReliefF extensions improve preceding extensions and overcome some of their drawbacks. The experimental results are validated using several nonparametric statistical tests and confirm the effectiveness of the proposal for a better multi-label learning. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Scalable extensions of the ReliefF algorithm for weighting and selecting features on the multi-label learning context", "paper_id": "WOS:000357910700019"}