{"auto_keywords": [{"score": 0.04665103656723687, "phrase": "svm"}, {"score": 0.00481495049065317, "phrase": "training_support_vector_machines"}, {"score": 0.004664352260912174, "phrase": "analog_neural_network_architecture"}, {"score": 0.004566567411073082, "phrase": "support_vector_machine"}, {"score": 0.003936910716320182, "phrase": "improved_version"}, {"score": 0.0035408501923902477, "phrase": "additional_parameters"}, {"score": 0.002863921785266393, "phrase": "dual_form"}, {"score": 0.0027159094186967247, "phrase": "multiple_solutions"}, {"score": 0.002416589459425828, "phrase": "simple_circuit_implementation"}, {"score": 0.0021049977753042253, "phrase": "empirical_results"}], "paper_keywords": ["Neural network", " Support vector machine", " Quadratic programming", " Analog circuits"], "paper_abstract": "An analog neural network architecture for support vector machine (SVM) learning is presented in this letter, which is an improved version of a model proposed recently in the literature with additional parameters. Compared with other models, this model has several merits. First, it can solve SVMs (in the dual form) which may have multiple solutions. Second, the structure of the model enables a simple circuit implementation. Third, the model converges faster than its predecessor as indicated by empirical results. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "A compact neural network for training support vector machines", "paper_id": "WOS:000303428700019"}