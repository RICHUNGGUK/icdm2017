{"auto_keywords": [{"score": 0.043470839348227264, "phrase": "emotional_states"}, {"score": 0.00481495049065317, "phrase": "judicial_courtrooms"}, {"score": 0.004583579470330216, "phrase": "recent_progress"}, {"score": 0.004508942069742167, "phrase": "judicial_proceedings_management"}, {"score": 0.0040192915527630995, "phrase": "affective_states"}, {"score": 0.003953806321226277, "phrase": "speech_signals"}, {"score": 0.003868142906199082, "phrase": "semantic_retrieval"}, {"score": 0.003826007045267751, "phrase": "multimedia_clips"}, {"score": 0.003702323283528696, "phrase": "deep_understanding"}, {"score": 0.003622088701900472, "phrase": "courtroom_debates"}, {"score": 0.0032819448594643853, "phrase": "real-world_human_emotions"}, {"score": 0.003228434077467506, "phrase": "courtroom_audio_recordings"}, {"score": 0.0030730639262332698, "phrase": "hierarchical_classification_system"}, {"score": 0.002989991779830814, "phrase": "risk_minimization_method"}, {"score": 0.002877438939246423, "phrase": "speech_signatures"}, {"score": 0.0027691111795848183, "phrase": "classification_approach"}, {"score": 0.0027239390917424898, "phrase": "multilayer_support_vector_machines"}, {"score": 0.002592784882557155, "phrase": "traditional_machine_learning_approaches"}, {"score": 0.002522662955545598, "phrase": "benchmark_datasets"}, {"score": 0.0024951467586005094, "phrase": "real_courtroom_recordings"}, {"score": 0.002388043660169452, "phrase": "proposed_technique"}, {"score": 0.002349073225500705, "phrase": "prediction_power"}, {"score": 0.0023107372754933887, "phrase": "traditional_approaches"}, {"score": 0.002285670635168985, "phrase": "svm"}, {"score": 0.0021994343316143125, "phrase": "naive_bayes"}, {"score": 0.002175436093794315, "phrase": "decision_trees_and_bayesian_networks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Emotion recognition", " Pattern recognition", " Application"], "paper_abstract": "Thanks to the recent progress in the judicial proceedings management, especially related to the introduction of audio/video recording facilities, the challenge of identification of emotional states can be tackled. Discovering affective states embedded into speech signals could help in semantic retrieval of multimedia clips, and therefore in a deep understanding of mechanisms behind courtroom debates and judges/jurors decision making processes. In this paper two main contributions are given: (1) the collection of real-world human emotions coming from courtroom audio recordings; (2) the investigation of a hierarchical classification system, based on a risk minimization method, able to recognize emotional states from speech signatures. The accuracy of the proposed classification approach - named Multilayer Support Vector Machines - has been evaluated by comparing its performance with traditional machine learning approaches, by using both benchmark datasets and real courtroom recordings. Results in recognition obtained by the proposed technique outperform the prediction power achieved by traditional approaches like SVM, k-Nearest Neighbors, Naive Bayes, Decision Trees and Bayesian Networks. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Emotional states in judicial courtrooms: An experimental investigation", "paper_id": "WOS:000295745800002"}