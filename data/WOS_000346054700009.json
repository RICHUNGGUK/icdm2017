{"auto_keywords": [{"score": 0.03934877046517645, "phrase": "training_data"}, {"score": 0.015214121792561831, "phrase": "point_cloud"}, {"score": 0.015016396886193575, "phrase": "large-scale_street_scenes"}, {"score": 0.00481495049065317, "phrase": "joint_segmentation"}, {"score": 0.004536862734384202, "phrase": "low-annotation_cost"}, {"score": 0.004389339243427964, "phrase": "novel_method"}, {"score": 0.0041084684278314305, "phrase": "large-scale_street_environment"}, {"score": 0.003896717568943166, "phrase": "intensive_labeling_cost"}, {"score": 0.003845500924733243, "phrase": "previous_works"}, {"score": 0.0036714667610391535, "phrase": "input_data"}, {"score": 0.0035993041437026225, "phrase": "automatic_generation"}, {"score": 0.003368816076401138, "phrase": "weak_priors"}, {"score": 0.0033025823350563087, "phrase": "street_environment"}, {"score": 0.0031950646670695546, "phrase": "filtering_scheme"}, {"score": 0.003132236287543072, "phrase": "mislabeled_training_samples"}, {"score": 0.0029706504420983896, "phrase": "binary_labeling_optimization_problem"}, {"score": 0.002912222095383313, "phrase": "conditional_random"}, {"score": 0.0028173769301594745, "phrase": "object_graph"}, {"score": 0.0027437235598539904, "phrase": "spatial_smoothness_preference"}, {"score": 0.002707620139970122, "phrase": "label_consistency"}, {"score": 0.0025849489224175548, "phrase": "final_parsing"}, {"score": 0.0025173564697303836, "phrase": "automatically_generated_training_data"}, {"score": 0.0024678216843278806, "phrase": "crf-based_parsing_method"}, {"score": 0.0023716501597131024, "phrase": "image_appearance"}, {"score": 0.0021049977753042253, "phrase": "city-scale_google_street_view_data"}], "paper_keywords": ["Segmentation", " street scene", " image", " point cloud"], "paper_abstract": "We propose a novel method for the parsing of images and scanned point cloud in large-scale street environment. The proposed method significantly reduces the intensive labeling cost in previous works by automatically generating training data from the input data. The automatic generation of training data begins with the initialization of training data with weak priors in the street environment, followed by a filtering scheme to remove mislabeled training samples. We formulate the filtering as a binary labeling optimization problem over a conditional random filed that we call object graph, simultaneously integrating spatial smoothness preference and label consistency between 2D and 3D. Toward the final parsing, with the automatically generated training data, a CRF-based parsing method that integrates the coordination of image appearance and 3D geometry is adopted to perform the parsing of large-scale street scenes. The proposed approach is evaluated on city-scale Google Street View data, with an encouraging parsing performance demonstrated.", "paper_title": "Joint Segmentation of Images and Scanned Point Cloud in Large-Scale Street Scenes With Low-Annotation Cost", "paper_id": "WOS:000346054700009"}