{"auto_keywords": [{"score": 0.049193598318116316, "phrase": "trajectory_analysis"}, {"score": 0.03896199846429051, "phrase": "foreground_map"}, {"score": 0.032514089580573335, "phrase": "spatial_graph"}, {"score": 0.00481495049065317, "phrase": "graph_partitioning"}, {"score": 0.004681971826924847, "phrase": "video_surveillance"}, {"score": 0.004552648949390462, "phrase": "moving_objects"}, {"score": 0.004510336430422002, "phrase": "long_range"}, {"score": 0.00436530211426514, "phrase": "background_clutter"}, {"score": 0.0042446888127531945, "phrase": "unified_approach"}, {"score": 0.004205226397573506, "phrase": "global_trajectory_analysis"}, {"score": 0.004108161406159407, "phrase": "traditional_frame-by-frame_tracking"}, {"score": 0.003920674807745575, "phrase": "short_sequence"}, {"score": 0.003884212965525665, "phrase": "video_frames"}, {"score": 0.003587616378156851, "phrase": "state-of-the-art_background_model"}, {"score": 0.0033603864623013733, "phrase": "graph_vertices"}, {"score": 0.003329117824699891, "phrase": "image_primitives"}, {"score": 0.0032674478600540477, "phrase": "composite_features"}, {"score": 0.003206916619690171, "phrase": "graph_representation"}, {"score": 0.0031036643805367487, "phrase": "joint_task"}, {"score": 0.0030319482153908037, "phrase": "temporal_graph_matching"}, {"score": 0.002853124436286832, "phrase": "bayesian_framework"}, {"score": 0.0027612315954598085, "phrase": "spatio-temporal_contexts"}, {"score": 0.002722758109991685, "phrase": "appearance_models"}, {"score": 0.002684819249720834, "phrase": "probabilistic_inference"}, {"score": 0.002622755848331379, "phrase": "data-driven_markov_chain_monte_carlo_algorithm"}, {"score": 0.002550165781755603, "phrase": "observed_frames"}, {"score": 0.002456486927713543, "phrase": "aperiodic_markov_chain"}, {"score": 0.0023662411481713682, "phrase": "solution_states"}, {"score": 0.002333258365963461, "phrase": "joint_space"}, {"score": 0.0021247934141234988, "phrase": "public_datasets"}, {"score": 0.0021049977753042253, "phrase": "visual_surveillance"}], "paper_keywords": ["Graph partitioning and matching", " multiple object tracking", " trajectory analysis", " video surveillance"], "paper_abstract": "In order to track moving objects in long range against occlusion, interruption, and background clutter, this paper proposes a unified approach for global trajectory analysis. Instead of the traditional frame-by-frame tracking, our method recovers target trajectories based on a short sequence of video frames, e.g., 15 frames. We initially calculate a foreground map at each frame obtained from a state-of-the-art background model. An attribute graph is then extracted from the foreground map, where the graph vertices are image primitives represented by the composite features. With this graph representation, we pose trajectory analysis as a joint task of spatial graph partitioning and temporal graph matching. The task can be formulated by maximizing a posteriori under the Bayesian framework, in which we integrate the spatio-temporal contexts and the appearance models. The probabilistic inference is achieved by a data-driven Markov chain Monte Carlo algorithm. Given a period of observed frames, the algorithm simulates an ergodic and aperiodic Markov chain, and it visits a sequence of solution states in the joint space of spatial graph partitioning and temporal graph matching. In the experiments, our method is tested on several challenging videos from the public datasets of visual surveillance, and it outperforms the state-of-the-art methods.", "paper_title": "Integrating Graph Partitioning and Matching for Trajectory Analysis in Video Surveillance", "paper_id": "WOS:000311363200014"}