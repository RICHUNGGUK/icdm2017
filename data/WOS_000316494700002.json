{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "complex-error_entropy"}, {"score": 0.004449045430179066, "phrase": "complex-valued_filter"}, {"score": 0.004322967486451877, "phrase": "information_theoretic_method"}, {"score": 0.004140490129683107, "phrase": "error_entropy_criterion"}, {"score": 0.004081385289516914, "phrase": "complex_domain"}, {"score": 0.003965684670332574, "phrase": "complex_error_entropy_criterion"}, {"score": 0.0031959843979467704, "phrase": "ebm_algorithm"}, {"score": 0.002708399936381754, "phrase": "complex_gradient_descent_approach"}, {"score": 0.0022298571016688335, "phrase": "complex-valued_linear_filtering"}, {"score": 0.0021509807762081145, "phrase": "nonlinear_channel_equalization"}], "paper_keywords": ["Complex-valued filtering", " entropy bound minimization", " minimization of complex-error entropy", " neural network"], "paper_abstract": "In this paper, we consider the training of complex-valued filter based on the information theoretic method. We first generalize the error entropy criterion to complex domain to present the complex error entropy criterion (CEEC). Due to the difficulty in estimating the entropy of complex-valued error directly, the entropy bound minimization (EBM) method is used to compute the upper bounds of the entropy of the complex-valued error, and the tightest bound selected by the EBM algorithm is used as the estimator of the complex-error entropy. Then, based on the minimization of complex-error entropy (MCEE) and the complex gradient descent approach, complex-valued learning algorithms for both the (linear) transverse filter and the (nonlinear) neural network are derived. The algorithms are applied to complex-valued linear filtering and complex-valued nonlinear channel equalization to demonstrate their effectiveness and advantages.", "paper_title": "Complex-Valued Filtering Based on the Minimization of Complex-Error Entropy", "paper_id": "WOS:000316494700002"}