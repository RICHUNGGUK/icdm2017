{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "automated_surveillance_tasks"}, {"score": 0.004776853267973129, "phrase": "camera_placement"}, {"score": 0.004720269202737973, "phrase": "enormous_impact"}, {"score": 0.004627441072541506, "phrase": "vision_systems"}, {"score": 0.004554488671294504, "phrase": "best_placement"}, {"score": 0.004140203942496321, "phrase": "task-specific_camera_placement"}, {"score": 0.00405873677211836, "phrase": "new_camera_placement_method"}, {"score": 0.003947358102140903, "phrase": "highest_resolution_images"}, {"score": 0.0037040785566765954, "phrase": "specified_task"}, {"score": 0.0034619440946558186, "phrase": "general_analytical_formulation"}, {"score": 0.0034208822062692127, "phrase": "observation_problem"}, {"score": 0.0033402088717816416, "phrase": "motion_statistics"}, {"score": 0.003248483521309273, "phrase": "observed_actions"}, {"score": 0.003197200793408836, "phrase": "aggregate_observability_measure"}, {"score": 0.0030602966787192745, "phrase": "multiple_cameras"}, {"score": 0.003036040409062437, "phrase": "aggregate_observability"}, {"score": 0.0029292375702719494, "phrase": "defined_area"}, {"score": 0.0028715299874549245, "phrase": "dynamic_and_unpredictable_environments"}, {"score": 0.0028037753646260937, "phrase": "interest_changes"}, {"score": 0.002578946584040053, "phrase": "internal_model"}, {"score": 0.0024006068621542642, "phrase": "camera_placement_solutions"}, {"score": 0.0022168460543913787, "phrase": "system's_optimized_camera_placement_solutions"}, {"score": 0.002147333949483224, "phrase": "indoor_and_outdoor_situations"}, {"score": 0.002130298466581199, "phrase": "robot-based_experimentation"}], "paper_keywords": ["camera networks", " robot/camera placement", " observability", " optimization", " sensor networks", " vision-based robotics"], "paper_abstract": "Camera placement has an enormous impact on the performance of vision systems, but the best placement to maximize performance depends on the purpose of the system. As a result, this paper focuses largely on the problem of task-specific camera placement. We propose a new camera placement method that optimizes views to provide the highest resolution images of objects and motions in the scene that are critical for the performance of some specified task (e.g. motion recognition, visual metrology, part identification, etc.). A general analytical formulation of the observation problem is developed in terms of motion statistics of a scene and resolution of observed actions resulting in an aggregate observability measure. The goal of this system is to optimize across multiple cameras the aggregate observability of the set of actions performed in a defined area. The method considers dynamic and unpredictable environments, where the subject of interest changes in time. It does not attempt to measure or reconstruct surfaces or objects, and does not use an internal model of the subjects for reference. As a result, this method differs significantly in its core formulation from camera placement solutions applied to problems such as inspection, reconstruction or the Art Gallery class of problems. We present tests of the system's optimized camera placement solutions using real-world data in both indoor and outdoor situations and robot-based experimentation using an all terrain robot vehicle-Jr robot in an indoor setting.", "paper_title": "Optimal camera placement for automated surveillance tasks", "paper_id": "WOS:000250139300004"}