{"auto_keywords": [{"score": 0.03951288245948403, "phrase": "on-chip_memory_access_traffic"}, {"score": 0.036551311068889855, "phrase": "memory_access_targets"}, {"score": 0.00481495049065317, "phrase": "memory_access_traffic"}, {"score": 0.004766683200410046, "phrase": "runtime_thread_migration"}, {"score": 0.004695183699894267, "phrase": "distributed_memory_systems"}, {"score": 0.00464811139983244, "phrase": "on-chip_distributed_memory_system"}, {"score": 0.0044870272550540415, "phrase": "massive_parallel_memory_accesses"}, {"score": 0.004419703921314433, "phrase": "future_many-core_processors"}, {"score": 0.004331501320993783, "phrase": "increasing_number"}, {"score": 0.004288059466938456, "phrase": "on-chip_cores"}, {"score": 0.004056769841308405, "phrase": "large_amount"}, {"score": 0.004016072233242585, "phrase": "on-chip_traffic"}, {"score": 0.003955787027818305, "phrase": "great_pressure"}, {"score": 0.003594369823549604, "phrase": "memory_access_behaviors"}, {"score": 0.003558294449586273, "phrase": "multi-threaded_applications"}, {"score": 0.003366233863411861, "phrase": "short_periods"}, {"score": 0.0032989853590079153, "phrase": "runtime_prediction"}, {"score": 0.0031845067058084583, "phrase": "great_mobility"}, {"score": 0.003152531962718477, "phrase": "long_periods"}, {"score": 0.0028498718992429825, "phrase": "novel_low-cost"}, {"score": 0.002821247621250663, "phrase": "distributed_thread_migration_algorithm"}, {"score": 0.0027788478707700274, "phrase": "thread_placement"}, {"score": 0.002709589081384597, "phrase": "benefit_estimation"}, {"score": 0.0025119730908615104, "phrase": "migration_requests"}, {"score": 0.0024247382451294255, "phrase": "migration_chains"}, {"score": 0.002400373755068185, "phrase": "simulation_results"}, {"score": 0.0023405257495466352, "phrase": "system_performance_speedup"}, {"score": 0.002282166507956957, "phrase": "average_memory_access_latency"}, {"score": 0.0021049977753042253, "phrase": "runtime_overheads"}], "paper_keywords": ["Predictability", " Thread migration", " On-chip distributed memory system and runtime algorithm"], "paper_abstract": "On-chip distributed memory system has become an attractive solution for massive parallel memory accesses found in future many-core processors. However, increasing number of on-chip cores and memory controllers inevitably introduce many remote memory accesses, which generate a large amount of on-chip traffic and put great pressure on the interconnection. This paper tries to optimize on-chip memory access traffic via runtime thread migration. We first analyze memory access behaviors in multi-threaded applications and find that the memory access targets and volumes are similar during short periods, which makes runtime prediction feasible. But the memory access targets exhibit great mobility during long periods, motivating us to dynamically move threads towards the data. Based on these observations, we propose a novel low-cost and distributed thread migration algorithm which adjusts thread placement in chains based on benefit estimation. We present details of the workflow, including the trigger and arbitration of migration requests and the procedures to determine the migration chains. Simulation results show that our algorithm achieves system performance speedup of 11.5 % and reduces average memory access latency by 11.0 %. It can find a few but effective thread migrations to optimize on-chip memory access traffic with acceptable hardware and runtime overheads.", "paper_title": "Optimizing memory access traffic via runtime thread migration for on-chip distributed memory systems", "paper_id": "WOS:000342454300026"}