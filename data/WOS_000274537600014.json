{"auto_keywords": [{"score": 0.04916809664432026, "phrase": "output_probability_computations"}, {"score": 0.048569884370968826, "phrase": "hmm-based_recognition_systems"}, {"score": 0.04797858309448136, "phrase": "store-based_block_parallel_processing"}, {"score": 0.029420333683948783, "phrase": "proposed_architecture"}, {"score": 0.028694156040506694, "phrase": "processing_elements"}, {"score": 0.004814977665536469, "phrase": "vlsi"}, {"score": 0.004401955895933783, "phrase": "fast_and_memory-efficient_vlsi_architecture"}, {"score": 0.004235938758522453, "phrase": "continuous_hidden_markov_models"}, {"score": 0.0038476708316022823, "phrase": "high-speed_vlsi_architectures"}, {"score": 0.0037262941538784094, "phrase": "low-power_dissipation"}, {"score": 0.0035627492415494216, "phrase": "mobile_embedded_systems"}, {"score": 0.0035173498506324476, "phrase": "capable_human_interfaces"}, {"score": 0.0032359856233193504, "phrase": "vlsi_architecture"}, {"score": 0.003054450075234415, "phrase": "hmm_states"}, {"score": 0.002977061391551631, "phrase": "accurate_recognition"}, {"score": 0.002901627749562029, "phrase": "conventional_stream-based_block_parallel_processing"}, {"score": 0.0025521085778978042, "phrase": "streambpp_architecture"}, {"score": 0.0024243586247372087, "phrase": "storebpp_architecture"}, {"score": 0.00236289633510808, "phrase": "vlsi_architectural_viewpoint"}, {"score": 0.00220177373403577, "phrase": "efficient_use"}, {"score": 0.0021322065604537617, "phrase": "input_feature_vectors"}, {"score": 0.0021049977753042253, "phrase": "intermediate_results"}], "paper_keywords": ["speech recognition", " hidden Markov model (HMM)", " VLSI architecture"], "paper_abstract": "In this paper, a fast and memory-efficient VLSI architecture for output probability computations of continuous Hidden Markov Models (HMMs) is presented. These computations are the most time-consuming part of HMM-based recognition systems. High-speed VLSI architectures with small registers and low-power dissipation are required for the development of mobile embedded systems with capable human interfaces. We demonstrate store-based block parallel processing (StoreBPP) for output probability computations and present a VLSI architecture that supports it. When the number of HMM states is adequate for accurate recognition, compared with conventional stream-based block parallel processing (StreamBPP) architectures, the proposed architecture requires fewer registers and processing elements and less processing time. The processing elements used in the StreamBPP architecture are identical to those used in the StoreBPP architecture. From a VLSI architectural viewpoint, a comparison shows the efficiency of the proposed architecture through efficient use of registers for storing input feature vectors and intermediate results during computation.", "paper_title": "A VLSI Architecture for Output Probability Computations of HMM-Based Recognition Systems with Store-Based Block Parallel Processing", "paper_id": "WOS:000274537600014"}