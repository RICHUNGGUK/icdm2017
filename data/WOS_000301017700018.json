{"auto_keywords": [{"score": 0.04492795963065823, "phrase": "input_space"}, {"score": 0.03166862986068805, "phrase": "target_value"}, {"score": 0.00481495049065317, "phrase": "discriminant_analysis"}, {"score": 0.00476323161560059, "phrase": "regression_problems"}, {"score": 0.004537254814246843, "phrase": "nonlinear_feature_extraction_method"}, {"score": 0.0041840994704406866, "phrase": "feature_extraction_method"}, {"score": 0.004007083686875716, "phrase": "linear_discriminant_analysis"}, {"score": 0.0037150687722055727, "phrase": "nonlinear_discriminant_analysis"}, {"score": 0.003635600104609725, "phrase": "so-called_kernel_trick"}, {"score": 0.003407214479510987, "phrase": "high-dimensional_feature_space"}, {"score": 0.0033163269450817716, "phrase": "nonlinear_transformations"}, {"score": 0.0032806521851034766, "phrase": "input_variables"}, {"score": 0.0030414140732789186, "phrase": "large_differences"}, {"score": 0.002928399649340438, "phrase": "small_differences"}, {"score": 0.0028348690177346448, "phrase": "feature_space"}, {"score": 0.002685558057339722, "phrase": "face_images"}, {"score": 0.0026280534600940137, "phrase": "perceivable_variation"}, {"score": 0.002436289099444074, "phrase": "face_alignment_problem"}, {"score": 0.0023970487263732737, "phrase": "complex_regression_problem"}, {"score": 0.002320449502337321, "phrase": "proposed_method"}, {"score": 0.002258485755625332, "phrase": "alignment_problems"}, {"score": 0.002222102813520549, "phrase": "better_performances"}, {"score": 0.0021745003291048356, "phrase": "conventional_linear_feature_extraction_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Regression", " Feature extraction", " Dimensionality reduction", " Discriminant analysis", " Kernel trick", " KDAr"], "paper_abstract": "In this paper, we propose a nonlinear feature extraction method for regression problems to reduce the dimensionality of the input space. Previously, a feature extraction method LDAr, a regressional version of the linear discriminant analysis, was proposed. In this paper, LDAr is generalized to a nonlinear discriminant analysis by using the so-called kernel trick. The basic idea is to map the input space into a high-dimensional feature space where the variables are nonlinear transformations of input variables. Then we try to maximize the ratio of distances of samples with large differences in the target value and those with small differences in the target value in the feature space. It is well known that the distribution of face images, under a perceivable variation in translation, rotation, and scaling, is highly nonlinear and the face alignment problem is a complex regression problem. We have applied the proposed method to various regression problems including face alignment problems and achieved better performances than those of conventional linear feature extraction methods. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Kernel discriminant analysis for regression problems", "paper_id": "WOS:000301017700018"}