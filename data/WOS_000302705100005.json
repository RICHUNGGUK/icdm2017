{"auto_keywords": [{"score": 0.026984168605458464, "phrase": "rkhs"}, {"score": 0.00481495049065317, "phrase": "adaptive_learning"}, {"score": 0.004721162131188487, "phrase": "kernel_hilbert_spaces_employing_wirtinger's_subgradients"}, {"score": 0.004583878086896926, "phrase": "wide_framework"}, {"score": 0.00447251540886613, "phrase": "learning_tasks"}, {"score": 0.004363846362238565, "phrase": "complex_valued_signal_processing"}, {"score": 0.004195418010131832, "phrase": "complex_reproducing_kernel_hilbert_space"}, {"score": 0.004053362743156545, "phrase": "learning_phase"}, {"score": 0.003820896867623235, "phrase": "complexification_trick"}, {"score": 0.003428665921276366, "phrase": "specific_system"}, {"score": 0.003378385493203297, "phrase": "desired_response"}, {"score": 0.0032319109979344184, "phrase": "adopted_loss_function"}, {"score": 0.0031377955308198634, "phrase": "analytic_form"}, {"score": 0.0030464123943266673, "phrase": "analytically_the_subgradients"}, {"score": 0.002899965889623787, "phrase": "wirtinger's_calculus"}, {"score": 0.0028715299874549245, "phrase": "complex_rkhs"}, {"score": 0.002640781900605126, "phrase": "memory_requirements"}, {"score": 0.0025638362414466278, "phrase": "almost_all_online_schemes"}, {"score": 0.002416589459425828, "phrase": "closed_balls"}, {"score": 0.0022777800735119405, "phrase": "proposed_framework"}, {"score": 0.0022443390559699974, "phrase": "non-linear_channel_identification_task"}, {"score": 0.0022113879114507577, "phrase": "non-linear_channel_equalization_problem"}, {"score": 0.0021363670305843403, "phrase": "equalization_scheme"}], "paper_keywords": ["Adaptive kernel learning", " complex kernels", " projection", " subgradient", " widely linear estimation", " Wirtinger's calculus"], "paper_abstract": "This paper presents a wide framework for non-linear online supervised learning tasks in the context of complex valued signal processing. The (complex) input data are mapped into a complex reproducing kernel Hilbert space (RKHS), where the learning phase is taking place. Both pure complex kernels and real kernels (via the complexification trick) can be employed. Moreover, any convex, continuous and not necessarily differentiable function can be used to measure the loss between the output of the specific system and the desired response. The only requirement is the subgradient of the adopted loss function to be available in an analytic form. In order to derive analytically the subgradients, the principles of the (recently developed) Wirtinger's calculus in complex RKHS are exploited. Furthermore, both linear and widely linear (in RKHS) estimation filters are considered. To cope with the problem of increasing memory requirements, which is present in almost all online schemes in RKHS, the sparsification scheme, based on projection onto closed balls, has been adopted. We demonstrate the effectiveness of the proposed framework in a non-linear channel identification task, a non-linear channel equalization problem and a quadrature phase shift keying equalization scheme, using both circular and non circular synthetic signal sources.", "paper_title": "Adaptive Learning in Complex Reproducing Kernel Hilbert Spaces Employing Wirtinger's Subgradients", "paper_id": "WOS:000302705100005"}