{"auto_keywords": [{"score": 0.040413010830249806, "phrase": "visual_dictionaries"}, {"score": 0.011373729349615743, "phrase": "low-level_features"}, {"score": 0.007669674861240243, "phrase": "describable_visual_attributes"}, {"score": 0.0062451604635214404, "phrase": "clustering_algorithm"}, {"score": 0.00481495049065317, "phrase": "textual_and_visual_attributes"}, {"score": 0.0047788144470247785, "phrase": "personal_traits"}, {"score": 0.0046369494511792845, "phrase": "ever-growing_attention"}, {"score": 0.0046021431217333824, "phrase": "scientific_community"}, {"score": 0.0045447095497782985, "phrase": "practical_applications"}, {"score": 0.004487989502479992, "phrase": "digital_forensics"}, {"score": 0.004343793943128486, "phrase": "public_space"}, {"score": 0.0040385352882334235, "phrase": "visual_searches"}, {"score": 0.003998142407002574, "phrase": "image_annotations"}, {"score": 0.003908723639118358, "phrase": "mid-level_image_representations"}, {"score": 0.0038309141193444015, "phrase": "visual_properties"}, {"score": 0.0037830687091647123, "phrase": "describable_attributes"}, {"score": 0.003698442219929622, "phrase": "machine_learning_techniques"}, {"score": 0.0036706546272761787, "phrase": "different_attributes"}, {"score": 0.003499433771969699, "phrase": "sparse-sampling_scheme"}, {"score": 0.0032844550295139984, "phrase": "method"}, {"score": 0.0030168610393007905, "phrase": "decision_score"}, {"score": 0.0025424177449894906, "phrase": "actual_number"}, {"score": 0.0024054633108541983, "phrase": "new_attributes"}, {"score": 0.0023933839684796994, "phrase": "experimental_results"}, {"score": 0.002345668721127675, "phrase": "retrieval_precision"}, {"score": 0.002258745901862197, "phrase": "combined_attributes"}, {"score": 0.0022081426275558313, "phrase": "rank_position"}, {"score": 0.0021970519740426493, "phrase": "complementary_results"}, {"score": 0.0021860169025888004, "phrase": "rank_fusion"}, {"score": 0.0021478278695820268, "phrase": "interesting_possible_combinations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Face search", " Attribute classifiers", " Rank fusion", " Visual dictionaries", " Dense-sampling characterization"], "paper_abstract": "Using personal traits for searching people is paramount in several application areas and has attracted an ever-growing attention from the scientific community over the past years. Some practical applications in the realm of digital forensics and surveillance include locating a suspect or finding missing people in a public space. In this paper, we aim at assigning describable visual attributes (e.g., white chubby male wearing glasses and with bangs) as labels to images to describe their appearance and performing visual searches without relying on image annotations during testing. For that, we create mid-level image representations for face images based on visual dictionaries linking visual properties in the images to describable attributes. In addition, we take advantage of machine learning techniques for combining different attributes and performing a query. First, we propose three methods for building the visual dictionaries. Method #1 uses a sparse-sampling scheme to obtain low-level features with a clustering algorithm to build the visual dictionaries. Method #2 uses dense-sampling to obtain low-level features and random selection to build the visual dictionaries while Method #3 uses dense-sampling to obtain low-level features followed by a clustering algorithm to build the visual dictionaries. Thereafter, we train 2-class classifiers for the describable visual attributes of interest which assign to each image a decision score used to obtain its ranking. For more complex queries (2+ attributes), we use three state-of-the-art approaches for combining the rankings: (1) product of probabilities, (2) rank aggregation and (3) rank position. To date, we have considered fifteen attribute classifiers and, consequently, their direct counterparts theoretically allowing 2(15) = 32,768 different combined queries (the actual number is smaller since some attributes are contradictory or mutually exclusive). Notwithstanding, the method is easily extensible to include new attributes. Experimental results show that Method #3 greatly improves retrieval precision for some attributes in comparison with other methods in the literature. Finally, for combined attributes, product of probabilities, rank aggregation and rank position yield complementary results for rank fusion and the final decision making suggesting interesting possible combinations for further work. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Visual words dictionaries and fusion techniques for searching people through textual and visual attributes", "paper_id": "WOS:000331854700009"}