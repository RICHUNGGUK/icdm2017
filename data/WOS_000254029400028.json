{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "neural_networks"}, {"score": 0.04911241438594345, "phrase": "time_delay"}, {"score": 0.04497972432687123, "phrase": "exponential_stability"}, {"score": 0.036588740387536144, "phrase": "new_criterion"}, {"score": 0.003807687328965365, "phrase": "lyapunov-krasovskii"}, {"score": 0.003581412258960711, "phrase": "delay_fractioning"}, {"score": 0.0030726480920918097, "phrase": "linear_matrix_inequality"}, {"score": 0.0021049977753042253, "phrase": "proposed_result"}], "paper_keywords": ["exponential stability", " linear matrix inequality (LMI)", " Lyapunov-Krasovskii functional", " neural network (NN)", " time delay"], "paper_abstract": "In this correspondence, the problem of exponential stability for neural networks with time delay is investigated. By introducing a novel Lyapunov-Krasovskii functional with the idea of delay fractioning, a new criterion of exponential stability is derived and then formulated in terms of a linear matrix inequality. This new criterion proves to be much less conservative than the most recent result, and the conservatism can be notably reduced as the fractioning goes thinner. An example is provided to demonstrate the advantage of the proposed result.", "paper_title": "New delay-dependent exponential stability for neural networks with time delay", "paper_id": "WOS:000254029400028"}