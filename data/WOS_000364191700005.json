{"auto_keywords": [{"score": 0.02954213749885248, "phrase": "different_views"}, {"score": 0.014808155046203099, "phrase": "target_domain"}, {"score": 0.014577052449016683, "phrase": "auxiliary_domains"}, {"score": 0.013221523292661842, "phrase": "multiple_perspectives"}, {"score": 0.01261123942117296, "phrase": "youtube"}, {"score": 0.009283458601789942, "phrase": "different_sources"}, {"score": 0.00481495049065317, "phrase": "multi-transfer"}, {"score": 0.004739056045644449, "phrase": "multiple_views"}, {"score": 0.004664352260912174, "phrase": "transfer_learning"}, {"score": 0.004576253356889219, "phrase": "learning_tasks"}, {"score": 0.00433553336181385, "phrase": "different_applications"}, {"score": 0.004294381488413906, "phrase": "text_mining"}, {"score": 0.004267163206961948, "phrase": "sentiment_analysis"}, {"score": 0.003978866233891427, "phrase": "multiple_sources"}, {"score": 0.003651456708091706, "phrase": "flickr"}, {"score": 0.0035824774777450112, "phrase": "google"}, {"score": 0.0035711211571970098, "phrase": "news"}, {"score": 0.003525861581971337, "phrase": "single_instance"}, {"score": 0.003144222265269426, "phrase": "collective_manner"}, {"score": 0.0030071857666598193, "phrase": "target_model_building"}, {"score": 0.0029037051302566942, "phrase": "transfer_learning_problem"}, {"score": 0.002885275573483437, "phrase": "transfer_learning_with_multiple_views"}, {"score": 0.0028037753646260937, "phrase": "different_probability_distributions"}, {"score": 0.0026560424475094396, "phrase": "simplistic_manner"}, {"score": 0.0026140878612307536, "phrase": "optimal_result"}, {"score": 0.002556459595882617, "phrase": "novel_algorithm"}, {"score": 0.002540228360655287, "phrase": "leverage_knowledge"}, {"score": 0.0024063484128685367, "phrase": "co-training_style_framework"}, {"score": 0.002338344706059989, "phrase": "distribution_differences"}, {"score": 0.0023234950796782376, "phrase": "different_domains"}, {"score": 0.0022940774859444724, "phrase": "empirical_studies"}, {"score": 0.0022434880661725493, "phrase": "proposed_approach"}, {"score": 0.002215081186105616, "phrase": "classification_accuracy"}, {"score": 0.0021870332034407817, "phrase": "different_kinds"}, {"score": 0.0021049977753042253, "phrase": "wiley_periodicals"}], "paper_keywords": ["transfer learning", " multi-view learning", " multiple data sources"], "paper_abstract": "Transfer learning, which aims to help learning tasks in a target domain by leveraging knowledge from auxiliary domains, has been demonstrated to be effective in different applications such as text mining, sentiment analysis, and so on. In addition, in many real-world applications, auxiliary data are described from multiple perspectives and usually carried by multiple sources. For example, to help classify videos on Youtube, which include three perspectives: image, voice and subtitles, one may borrow data from Flickr, Last. FM and Google News. Although any single instance in these domains can only cover a part of the views available on Youtube, the piece of information carried by them may compensate one another. If we can exploit these auxiliary domains in a collective manner, and transfer the knowledge to the target domain, we can improve the target model building from multiple perspectives. In this article, we consider this transfer learning problem as Transfer Learning with Multiple Views and Multiple Sources. As different sources may have different probability distributions and different views may compensate or be inconsistent with each other, merging all data in a simplistic manner will not give an optimal result. Thus, we propose a novel algorithm to leverage knowledge from different views and sources collaboratively, by letting different views from different sources complement each other through a co-training style framework, at the same time, it revises the distribution differences in different domains. We conduct empirical studies on several real-world datasets to show that the proposed approach can improve the classification accuracy by up to 8% against different kinds of state-of-the-art baselines. (C) 2014 Wiley Periodicals, Inc.", "paper_title": "Multi-Transfer: Transfer Learning with Multiple Views and Multiple Sources", "paper_id": "WOS:000364191700005"}