{"auto_keywords": [{"score": 0.03875660263192491, "phrase": "jit_compilation"}, {"score": 0.00481495049065317, "phrase": "-time_trace"}, {"score": 0.004745056850725867, "phrase": "parallel_task_farm"}, {"score": 0.004693300099911199, "phrase": "dynamic_binary_translator"}, {"score": 0.004659108142668152, "phrase": "dynamic_binary_translation"}, {"score": 0.004558012799538011, "phrase": "key_technology"}, {"score": 0.004524801966077539, "phrase": "cross-platform_virtualization"}, {"score": 0.004205660924155212, "phrase": "different_isa."}, {"score": 0.004129444994959103, "phrase": "dbt"}, {"score": 0.0038804410204616954, "phrase": "main_challenge"}, {"score": 0.0038380787059463075, "phrase": "frequently_executed_program_regions"}, {"score": 0.003754731210715724, "phrase": "highly_efficient_native_code"}, {"score": 0.003633079011725194, "phrase": "overall_execution_time"}, {"score": 0.0035934073774126856, "phrase": "jit_compiler"}, {"score": 0.003489714006817602, "phrase": "separate_thread"}, {"score": 0.003438990973529508, "phrase": "main_simulation_loop"}, {"score": 0.0032433414042726356, "phrase": "first_contribution"}, {"score": 0.0032079118323314424, "phrase": "generalized_trace_compilation_approach"}, {"score": 0.003161271802988128, "phrase": "frequently_executed_paths"}, {"score": 0.0030476078950483158, "phrase": "previous_approaches"}, {"score": 0.0030253688063143157, "phrase": "trace_compilation"}, {"score": 0.002927278301452369, "phrase": "second_contribution"}, {"score": 0.002905914725757534, "phrase": "jit_compilation_cost"}, {"score": 0.00284275228258112, "phrase": "concurrent_task_farm"}, {"score": 0.0027911639820564897, "phrase": "generalized_light-weight_tracing"}, {"score": 0.002730488910300527, "phrase": "parallel_jit_compilation"}, {"score": 0.002710557619357275, "phrase": "dynamic_work_scheduling"}, {"score": 0.002680932410366204, "phrase": "timely_and_efficient_processing"}, {"score": 0.00258449630918625, "phrase": "llvm"}, {"score": 0.0025190541346053405, "phrase": "arcompact_isa"}, {"score": 0.0024824048775201678, "phrase": "eembc"}, {"score": 0.0024642796422450755, "phrase": "bioperf"}, {"score": 0.002446297895484299, "phrase": "spec"}, {"score": 0.00234104879370883, "phrase": "standard_quad-core_intel_xeon_machine"}, {"score": 0.0023154527779996213, "phrase": "short-and_long-running_benchmarks"}, {"score": 0.002175594509651082, "phrase": "total_execution_time"}], "paper_keywords": ["Design", " experimentation", " measurement", " performance", " Dynamic binary translation", " just-in-time compilation", " parallelization", " task farm", " dynamic work scheduling"], "paper_abstract": "Dynamic Binary Translation (DBT) is the key technology behind cross-platform virtualization and allows software compiled for one Instruction Set Architecture (ISA) to be executed on a processor supporting a different ISA. Under the hood, DBT is typically implemented using Just-In-Time (JIT) compilation of frequently executed program regions, also called traces. The main challenge is translating frequently executed program regions as fast as possible into highly efficient native code. As time for JIT compilation adds to the overall execution time, the JIT compiler is often decoupled and operates in a separate thread independent from the main simulation loop to reduce the overhead of JIT compilation. In this paper we present two innovative contributions. The first contribution is a generalized trace compilation approach that considers all frequently executed paths in a program for JIT compilation, as opposed to previous approaches where trace compilation is restricted to paths through loops. The second contribution reduces JIT compilation cost by compiling several hot traces in a concurrent task farm. Altogether we combine generalized light-weight tracing, large translation units, parallel JIT compilation and dynamic work scheduling to ensure timely and efficient processing of hot traces. We have evaluated our industry-strength, LLVM-based parallel DBT implementing the ARCompact ISA against three benchmark suites (EEMBC, BIOPERF and SPEC CPU2006) and demonstrate speedups of up to 2.08 on a standard quad-core Intel Xeon machine. Across short-and long-running benchmarks our scheme is robust and never results in a slowdown. In fact, using four processors total execution time can be reduced by on average 11.5% over state-of-the-art decoupled, parallel (or asynchronous) JIT compilation.", "paper_title": "Generalized Just-In-Time Trace Compilation using a Parallel Task Farm in a Dynamic Binary Translator", "paper_id": "WOS:000294609500007"}