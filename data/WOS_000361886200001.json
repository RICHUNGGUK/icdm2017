{"auto_keywords": [{"score": 0.048929739366992464, "phrase": "least_squares"}, {"score": 0.00481495049065317, "phrase": "efficient_optimization"}, {"score": 0.004642604455537883, "phrase": "vector_regression"}, {"score": 0.004586531354697466, "phrase": "support_vector_regression"}, {"score": 0.004531147228187734, "phrase": "svr"}, {"score": 0.004212453011596424, "phrase": "labelled_training_data_vectors"}, {"score": 0.004136333933790974, "phrase": "generalization_performance"}, {"score": 0.004061584718427419, "phrase": "regression_function"}, {"score": 0.003964007795174772, "phrase": "svr_method"}, {"score": 0.003640516896245813, "phrase": "common_approach"}, {"score": 0.003574695610710444, "phrase": "suitable_values"}, {"score": 0.00342568771304873, "phrase": "cross_validation"}, {"score": 0.0033637374697995616, "phrase": "grid_search_method"}, {"score": 0.0033029038236817372, "phrase": "recent_works"}, {"score": 0.003089080923888397, "phrase": "bilevel_optimization_problem"}, {"score": 0.0028890603352364273, "phrase": "bilevel_problem"}, {"score": 0.0028367868542874763, "phrase": "single-level_nonlinear_programme"}, {"score": 0.0025578967205807843, "phrase": "objective_function"}, {"score": 0.002421499421848063, "phrase": "fast_standard_methods"}, {"score": 0.0023346234464901978, "phrase": "large_number"}, {"score": 0.0022236070278432575, "phrase": "computational_efficiency"}], "paper_keywords": ["support vector regression", " hyper-parameter", " model selection", " bilevel optimization"], "paper_abstract": "Support vector regression (SVR) comprises techniques for estimating functions based on a set of labelled training data vectors. The generalization performance of a regression function generated by an SVR method can highly depend on the choice of certain hyper-parameters like kernel parameters. A common approach to determine suitable values for the hyper-parameters is to use cross validation and a grid search method. In recent works the problem of optimizing the hyper-parameters has been modelled as bilevel optimization problem. For the case of least squares SVR we reformulate the bilevel problem into a single-level nonlinear programme with box constraints that only depends on the hyper-parameters. Moreover, we show how the objective function and its derivatives can be calculated efficiently so that fast standard methods for the optimization of a large number of hyper-parameters become applicable. Reliability and computational efficiency of the approach is demonstrated by means of several test problems.", "paper_title": "Efficient optimization of hyper-parameters for least squares support vector regression", "paper_id": "WOS:000361886200001"}