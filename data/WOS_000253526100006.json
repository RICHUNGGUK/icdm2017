{"auto_keywords": [{"score": 0.04716601103868718, "phrase": "linear_mapping"}, {"score": 0.04345330249344969, "phrase": "transformation-invariant_component_analysis"}, {"score": 0.042980055209087174, "phrase": "tca"}, {"score": 0.00481495049065317, "phrase": "dimensionality_reduction_techniques"}, {"score": 0.004733347359490221, "phrase": "principal_component_analysis"}, {"score": 0.0046797114400479135, "phrase": "factor_analysis"}, {"score": 0.00447115003744675, "phrase": "high-dimensional_data_samples"}, {"score": 0.004345525254560329, "phrase": "lower-dimensional_subspace"}, {"score": 0.004247579017673656, "phrase": "frey"}, {"score": 0.004199406257273994, "phrase": "jojic"}, {"score": 0.0038332390893263844, "phrase": "known_form"}, {"score": 0.003789763907758991, "phrase": "global_transformations"}, {"score": 0.0037042817107563785, "phrase": "parameter_estimation"}, {"score": 0.0032487508969192293, "phrase": "training_example"}, {"score": 0.002982203248352076, "phrase": "large-size_images"}, {"score": 0.0026911860082793697, "phrase": "rgb"}, {"score": 0.002527150892127982, "phrase": "efficient_algorithm"}, {"score": 0.0024700776739384977, "phrase": "computational_requirements"}, {"score": 0.002414290278501595, "phrase": "n_log_n."}, {"score": 0.0021784009230363627, "phrase": "video_textures"}, {"score": 0.0021291870676682406, "phrase": "object_recognition"}, {"score": 0.0021049977753042253, "phrase": "object_detection"}], "paper_keywords": ["TCA", " patch", " EM algorithm", " dimensionality reduction", " clustering"], "paper_abstract": "Dimensionality reduction techniques such as principal component analysis and factor analysis are used to discover a linear mapping between high-dimensional data samples and points in a lower-dimensional subspace. Previously, Frey and Jojic introduced transformation-invariant component analysis (TCA) to learn a linear mapping, invariant to a set of known form of global transformations. However, parameter estimation in that model using the previously-proposed expectation maximization (EM) algorithm required scalar operations in the order of N(2) where N is the dimensionality of each training example. This is prohibitive for many applications of interest such as modeling mid-to large-size images, where, for instance, N may be as high as 786432 (512 x 512 RGB image). In this paper, we present an efficient algorithm that reduces the computational requirements to order of N log N. With this speedup, we show the effectiveness of transformation-invariant component analysis in various applications including tracking, learning video textures, clustering, object recognition and object detection in images. Software for TCA can be downloaded from http://www.psi.toronto.edu/ fastTCA.htm.", "paper_title": "Fast transformation-invariant component analysis", "paper_id": "WOS:000253526100006"}