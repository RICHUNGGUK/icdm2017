{"auto_keywords": [{"score": 0.04425005070909833, "phrase": "pmog_model"}, {"score": 0.010419369909917502, "phrase": "blind_source_separation"}, {"score": 0.01009017842223369, "phrase": "gaussians"}, {"score": 0.009592913441132559, "phrase": "pmog"}, {"score": 0.006167339585186547, "phrase": "conventional_bss"}, {"score": 0.00481495049065317, "phrase": "gaussians_model"}, {"score": 0.004534527860385989, "phrase": "mog"}, {"score": 0.004431041346291019, "phrase": "projected_mixture"}, {"score": 0.003929689573550262, "phrase": "q_dimensional_vector_w"}, {"score": 0.003787108326100196, "phrase": "projected_variables"}, {"score": 0.003177154457204775, "phrase": "em_algorithm"}, {"score": 0.0027528751037412128, "phrase": "objective_function"}, {"score": 0.0026775328564629577, "phrase": "differential_entropy"}, {"score": 0.0025565050791036973, "phrase": "projected_sources"}, {"score": 0.0025096359514694523, "phrase": "flexible_mug_model"}, {"score": 0.002418453525649304, "phrase": "projection_vector_w."}, {"score": 0.0023522423291484212, "phrase": "conventional_bss_algorithms"}, {"score": 0.00229844995872581, "phrase": "non-gaussian_source_densities"}, {"score": 0.002164264600379492, "phrase": "computational_feasibility"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Blind Source Separation (BSS)", " Mixture of Gaussians (MOG)", " Independent Component Analysis (ICA)"], "paper_abstract": "We extend the mixtures of Gaussians (MOG) model to the projected mixture of Gaussians (PMOG) model. In the PMOG model, we assume that g dimensional input data points z(i) are projected by a q dimensional vector w into 1-D variables u(i). The projected variables ui are assumed to follow a 1-D MUG model. In the PMOG model, we maximize the likelihood of observing ui to find both the model parameters for the 1-D MUG as well as the projection vector w. First, we derive an EM algorithm for estimating the PMOG model. Next, we show how the PMOG model can be applied to the problem of blind source separation (BSS). In contrast to conventional BSS where an objective function based on an approximation to differential entropy is minimized, PMOG based BSS simply minimizes the differential entropy of projected sources by fitting a flexible MUG model in the projected 1-D space while simultaneously optimizing the projection vector w. The advantage of PMOG over conventional BSS algorithms is the more flexible fitting of non-Gaussian source densities without assuming near-Gaussianity (as in conventional BSS) and still retaining computational feasibility. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "PMOG: The projected mixture of Gaussians model with application to blind source separation", "paper_id": "WOS:000302514700004"}