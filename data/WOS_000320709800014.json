{"auto_keywords": [{"score": 0.04926219622874719, "phrase": "random_matrices"}, {"score": 0.00481495049065317, "phrase": "anisotropic_random_measurements"}, {"score": 0.004533427352547707, "phrase": "sparse_recovery_problems"}, {"score": 0.003816197777388722, "phrase": "recently_introduced_restricted_eigenvalue"}, {"score": 0.0031845067058084613, "phrase": "reduction_principle"}, {"score": 0.0028963961037320805, "phrase": "restricted_isometry"}, {"score": 0.0027741761880779535, "phrase": "low-dimensional_subspaces"}, {"score": 0.002437525632451029, "phrase": "dependent_entries"}, {"score": 0.0023346234464901978, "phrase": "sub-gaussian_rows"}, {"score": 0.002294686545883412, "phrase": "nontrivial_covariance_structure"}, {"score": 0.0021601997088758957, "phrase": "independent_rows"}, {"score": 0.0021049977753042253, "phrase": "uniformly_bounded_entries"}], "paper_keywords": ["Design matrices with uniformly bounded entries", " minimization", " restricted eigenvalue (RE) conditions", " sparsity", " sub-Gaussian random matrices"], "paper_abstract": "Random matrices are widely used in sparse recovery problems, and the relevant properties of matrices with i.i.d. entries are well understood. This paper discusses the recently introduced restricted eigenvalue (RE) condition, which is among the most general assumptions on the matrix, guaranteeing recovery. We prove a reduction principle showing that the RE condition can be guaranteed by checking the restricted isometry on a certain family of low-dimensional subspaces. This principle allows us to establish the RE condition for several broad classes of random matrices with dependent entries, including random matrices with sub-Gaussian rows and nontrivial covariance structure, as well as matrices with independent rows, and uniformly bounded entries.", "paper_title": "Reconstruction From Anisotropic Random Measurements", "paper_id": "WOS:000320709800014"}