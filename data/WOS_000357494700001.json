{"auto_keywords": [{"score": 0.02246846748295755, "phrase": "mpi"}, {"score": 0.00481495049065317, "phrase": "dual_xeon-phi_cluster"}, {"score": 0.004586531354697466, "phrase": "xeon-phi_coprocessor"}, {"score": 0.00450368324850566, "phrase": "truly_multicore_architecture"}, {"score": 0.004342430078306461, "phrase": "interconnection_speed"}, {"score": 0.004272718555706204, "phrase": "cpu."}, {"score": 0.004136333933790974, "phrase": "cache_memory"}, {"score": 0.004061584718427419, "phrase": "theoretical_performance"}, {"score": 0.003939980614608309, "phrase": "programming_flexibility"}, {"score": 0.0037075456471849892, "phrase": "parallelizing_applications"}, {"score": 0.0035965032173588753, "phrase": "computational_times"}, {"score": 0.0033637374697995616, "phrase": "geophysical_application"}, {"score": 0.0032431667821391044, "phrase": "gravimetric_tensor_components"}, {"score": 0.002735052488172277, "phrase": "design_factors"}, {"score": 0.002685558057339722, "phrase": "good_performance"}, {"score": 0.0025735173163957993, "phrase": "conventional_multicore"}, {"score": 0.002481200970201421, "phrase": "efficient_strategy"}, {"score": 0.002436289099444074, "phrase": "nested_parallelism"}, {"score": 0.002406799309495983, "phrase": "open_mp"}, {"score": 0.0022371907579775796, "phrase": "interconnected_xeon-phi_coprocessors"}], "paper_keywords": [""], "paper_abstract": "With at least 60 processing cores, the Xeon-Phi coprocessor is a truly multicore architecture, which consists of an interconnection speed among cores of 240GB/s, two levels of cache memory, a theoretical performance of 1.01 Tflops, and programming flexibility, all making the Xeon-Phi an excellent coprocessor for parallelizing applications that seek to reduce computational times. The objective of this work is to migrate a geophysical application designed to directly calculate the gravimetric tensor components and their derivatives and in this way research the performance of one and two Xeon-Phi coprocessors integrated on the same node and distributed in various nodes. This application allows the analysis of the design factors that drive good performance and compare the results against a conventional multicore CPU. This research shows an efficient strategy based on nested parallelism using Open MP, a design that in its outer structure acts as a controller of interconnected Xeon-Phi coprocessors while its interior is used for parallelyzing the loops. MPI is subsequently used to reduce the information among the nodes of the cluster.", "paper_title": "A Performance Study of a Dual Xeon-Phi Cluster for the Forward Modelling of Gravitational Fields", "paper_id": "WOS:000357494700001"}