{"auto_keywords": [{"score": 0.049469816714638924, "phrase": "word-sense_disambiguation"}, {"score": 0.00481495049065317, "phrase": "multi-relational_data_application"}, {"score": 0.004458722048888919, "phrase": "huge_amounts"}, {"score": 0.004401955895933783, "phrase": "structured_data"}, {"score": 0.004208881856146758, "phrase": "computational_biology"}, {"score": 0.004155283263388382, "phrase": "information_retrieval"}, {"score": 0.004076157223660074, "phrase": "natural_language_processing"}, {"score": 0.0038476708316022823, "phrase": "new_neural_network_architecture"}, {"score": 0.003750260412839128, "phrase": "multi-relational_graphs"}, {"score": 0.0036788184374592706, "phrase": "flexible_continuous_vector_space"}, {"score": 0.0035856674209019234, "phrase": "original_data"}, {"score": 0.003133844153806967, "phrase": "high_probabilities"}, {"score": 0.0030938932434437178, "phrase": "plausible_components"}, {"score": 0.0029391032882625473, "phrase": "competitive_performance"}, {"score": 0.002901627749562029, "phrase": "link_prediction"}, {"score": 0.002864628676257225, "phrase": "standard_datasets"}, {"score": 0.0026693851900137953, "phrase": "real-world_knowledge_base"}, {"score": 0.0023178219772486868, "phrase": "open-text_semantic_parsing"}, {"score": 0.0021597662797996843, "phrase": "structured_meaning_representation"}, {"score": 0.0021322065604537617, "phrase": "almost_any_sentence"}, {"score": 0.0021049977753042253, "phrase": "free_text"}], "paper_keywords": ["Neural networks", " Multi-relational data", " Word-sense disambiguation"], "paper_abstract": "Large-scale relational learning becomes crucial for handling the huge amounts of structured data generated daily in many application domains ranging from computational biology or information retrieval, to natural language processing. In this paper, we present a new neural network architecture designed to embed multi-relational graphs into a flexible continuous vector space in which the original data is kept and enhanced. The network is trained to encode the semantics of these graphs in order to assign high probabilities to plausible components. We empirically show that it reaches competitive performance in link prediction on standard datasets from the literature as well as on data from a real-world knowledge base (WordNet). In addition, we present how our method can be applied to perform word-sense disambiguation in a context of open-text semantic parsing, where the goal is to learn to assign a structured meaning representation to almost any sentence of free text, demonstrating that it can scale up to tens of thousands of nodes and thousands of types of relation.", "paper_title": "A semantic matching energy function for learning with multi-relational data Application to word-sense disambiguation", "paper_id": "WOS:000330616900006"}