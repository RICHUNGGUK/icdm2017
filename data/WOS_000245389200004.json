{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "factor_graphs"}, {"score": 0.04962396550254858, "phrase": "polynomial_time"}, {"score": 0.04917331388552706, "phrase": "sample_complexity"}, {"score": 0.014574931753677809, "phrase": "graphical_models"}, {"score": 0.013901568899383644, "phrase": "bounded_degree"}, {"score": 0.004612376827433774, "phrase": "computational_and_sample_complexity"}, {"score": 0.004073590964805314, "phrase": "polynomial_number"}, {"score": 0.004034841146538891, "phrase": "training_examples"}, {"score": 0.0036494864560524735, "phrase": "known_network_structure"}, {"score": 0.0036147562669032957, "phrase": "structure_learning"}, {"score": 0.0033806943112103397, "phrase": "bayesian_networks"}, {"score": 0.003348513474852869, "phrase": "markov_networks"}, {"score": 0.003161740194257218, "phrase": "standard_maximum_likelihood_estimation_algorithms"}, {"score": 0.0030140547908298404, "phrase": "underlying_network"}, {"score": 0.002687070469080394, "phrase": "generating_distribution"}, {"score": 0.002598543802992702, "phrase": "target_class"}], "paper_keywords": ["probabilistic graphical models", " parameter and structure learning", " factor graphs", " Markov networks", " Bayesian networks"], "paper_abstract": "We study the computational and sample complexity of parameter and structure learning in graphical models. Our main result shows that the class of factor graphs with bounded degree can be learned in polynomial time and from a polynomial number of training examples, assuming that the data is generated by a network in this class. This result covers both parameter estimation for a known network structure and structure learning. It implies as a corollary that we can learn factor graphs for both Bayesian networks and Markov networks of bounded degree, in polynomial time and sample complexity. Importantly, unlike standard maximum likelihood estimation algorithms, our method does not require inference in the underlying network, and so applies to networks where inference is intractable. We also show that the error of our learned model degrades gracefully when the generating distribution is not a member of the target class of networks. In addition to our main result, we show that the sample complexity of parameter learning in graphical models has an O(1) dependence on the number of variables in the model when using the KL-divergence normalized by the number of variables as the performance criterion.(1)", "paper_title": "Learning factor graphs in polynomial time and sample complexity", "paper_id": "WOS:000245389200004"}