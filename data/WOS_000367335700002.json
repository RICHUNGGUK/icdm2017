{"auto_keywords": [{"score": 0.03227078104988101, "phrase": "tensor"}, {"score": 0.00481495049065317, "phrase": "temporal_game_challenge_tailoring"}, {"score": 0.004769444094319619, "phrase": "digital_games"}, {"score": 0.004000741805312148, "phrase": "game_player"}, {"score": 0.003906804492585634, "phrase": "player_boredom"}, {"score": 0.0038332390893263844, "phrase": "challenge_tailoring"}, {"score": 0.0037610536973798113, "phrase": "general_problem"}, {"score": 0.00370780481244907, "phrase": "designer-intended_challenges"}, {"score": 0.0035189057079817285, "phrase": "temporal_player_performance"}, {"score": 0.0034690732089830045, "phrase": "appropriate_content"}, {"score": 0.0034037221513153566, "phrase": "challenge_tailoring_problem"}, {"score": 0.0033395980635636644, "phrase": "collaborative_filtering"}, {"score": 0.0031096747349602344, "phrase": "player_performance"}, {"score": 0.0029935730127943496, "phrase": "varying_player_abilities"}, {"score": 0.002909342017421165, "phrase": "generic_approach"}, {"score": 0.0027218799769229596, "phrase": "content_selection"}, {"score": 0.002683304054823427, "phrase": "player_skills"}, {"score": 0.0026452734009203764, "phrase": "designer-specified_level"}, {"score": 0.002570817338292482, "phrase": "model-performance_curves"}, {"score": 0.0024513404432665153, "phrase": "player_behavior"}, {"score": 0.002371018116266096, "phrase": "role-playing_game"}, {"score": 0.0022824314760583834, "phrase": "simulated_agents"}, {"score": 0.0022393843660697484, "phrase": "tensor_factorization_scales"}, {"score": 0.0022181655497912796, "phrase": "multiple_game-relevant_data_dimensions"}, {"score": 0.0021557052355026048, "phrase": "modestly_effective_game_adaptation"}, {"score": 0.0021049977753042253, "phrase": "divergent_player_learning_trends"}], "paper_keywords": ["Artificial intelligence", " constraint programming", " game adaptation", " games", " machine learning", " player modeling", " procedural content generation", " recommender systems"], "paper_abstract": "Digital games often center on a series of challenges designed to vary in difficulty over the course of the game. Designers, however, lack ways to ensure challenges are suitably tailored to the abilities of each game player, often resulting in player boredom or frustration. Challenge tailoring refers to the general problem of matching designer-intended challenges to player abilities. We present an approach to predict temporal player performance and select appropriate content to solve the challenge tailoring problem. Our temporal collaborative filtering approach-tensor factorization-captures similarities among players and the challenges they face to predict player performance on unseen, future challenges. Tensor factorization accounts for varying player abilities over time and is a generic approach capable of modeling many kinds of players. We use constraint solving to optimize content selection to match player skills to a designer-specified level of performance and present a model-performance curves-for designers to specify desired, temporally changing player behavior. We evaluate our approach in a role-playing game through two empirical studies of humans and one study using simulated agents. Our studies show tensor factorization scales in multiple game-relevant data dimensions, can be used for modestly effective game adaptation, and can predict divergent player learning trends.", "paper_title": "Temporal Game Challenge Tailoring", "paper_id": "WOS:000367335700002"}