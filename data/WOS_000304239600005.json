{"auto_keywords": [{"score": 0.04478003824655918, "phrase": "attentional_enhancement"}, {"score": 0.03812983798224722, "phrase": "attention-related_areas"}, {"score": 0.00481495049065317, "phrase": "dynamic_environment"}, {"score": 0.004676345706416371, "phrase": "visual_system"}, {"score": 0.004392565073466714, "phrase": "psychophysical_experiments"}, {"score": 0.004143196873246147, "phrase": "moving_objects"}, {"score": 0.003875424718379985, "phrase": "attentional_selection"}, {"score": 0.0038431888954930083, "phrase": "target_objects"}, {"score": 0.003763763153640936, "phrase": "feedforward-feedback_loop"}, {"score": 0.0037168948492715386, "phrase": "visual_cortical_hierarchy"}, {"score": 0.00347657813672945, "phrase": "early_visual_areas"}, {"score": 0.003292770855568091, "phrase": "common_oscillatory_signal"}, {"score": 0.003265365666305185, "phrase": "target_items"}, {"score": 0.0032381878248821383, "phrase": "excitatory_feedback"}, {"score": 0.0031448288291084, "phrase": "distractor_items"}, {"score": 0.0031186510842824626, "phrase": "inhibitory_feedback"}, {"score": 0.0030541531847589807, "phrase": "integrate-and-fire_neurons"}, {"score": 0.002978508766388785, "phrase": "simple_attentive_tracking_tasks"}, {"score": 0.0029291198314113608, "phrase": "previous_modeling_studies"}, {"score": 0.002856563331151566, "phrase": "temporal_tagging"}, {"score": 0.0028327783069076883, "phrase": "neural_activity"}, {"score": 0.0027167830773160203, "phrase": "higher_levels"}, {"score": 0.0025623050508233078, "phrase": "first_layer"}, {"score": 0.002530359917257626, "phrase": "neural_substrate"}, {"score": 0.002498812056838983, "phrase": "low_level_feature_processing"}, {"score": 0.002447101794397243, "phrase": "enhancement_mechanism"}, {"score": 0.0023864566654035924, "phrase": "based_object_tracking_algorithm"}, {"score": 0.0023079225317714815, "phrase": "tracking_performance"}, {"score": 0.0022226496830385304, "phrase": "target_features"}, {"score": 0.002158505888557746, "phrase": "faulty_correspondence_assignments"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Attention", " Neural synchrony", " Cortical oscillations", " Object tracking"], "paper_abstract": "The world is a dynamic environment hence it is important for the visual system to be able to deploy attention on moving objects and attentively track them. Psychophysical experiments indicate that processes of both attentional enhancement and inhibition are spatially focused on the moving objects; however the mechanisms of these processes are unknown. The studies indicate that the attentional selection of target objects is sustained via a feedforward-feedback loop in the visual cortical hierarchy and only the target objects are represented in attention-related areas. We suggest that feedback from the attention-related areas to early visual areas modulates the activity of neurons; establishes synchronization with respect to a common oscillatory signal for target items via excitatory feedback, and also establishes de-synchronization for distractor items via inhibitory feedback. A two layer computational neural network model with integrate-and-fire neurons is proposed and simulated for simple attentive tracking tasks. Consistent with previous modeling studies, we show that via temporal tagging of neural activity, distractors can be attentively suppressed from propagating to higher levels. However, simulations also suggest attentional enhancement of activity for distractors in the first layer which represents neural substrate dedicated for low level feature processing. Inspired by this enhancement mechanism, we developed a feature based object tracking algorithm with surround processing. Surround processing improved tracking performance by 57% in PETS 2001 dataset, via eliminating target features that are likely to suffer from faulty correspondence assignments. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Oscillatory synchronization model of attention to moving objects", "paper_id": "WOS:000304239600005"}