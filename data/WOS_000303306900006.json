{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "noisy_iris_images"}, {"score": 0.010140573842652784, "phrase": "iris_region"}, {"score": 0.004738472391439408, "phrase": "iris_image"}, {"score": 0.004708220751321872, "phrase": "unconstrained_conditions"}, {"score": 0.0046632033374901715, "phrase": "user_cooperation"}, {"score": 0.004618614357974438, "phrase": "image_quality"}, {"score": 0.004530705581549137, "phrase": "poor_focus"}, {"score": 0.004195418010131832, "phrase": "intra-individual_variations"}, {"score": 0.003985738225654119, "phrase": "new_iris_recognition_algorithm"}, {"score": 0.0038230844545071303, "phrase": "previous_works"}, {"score": 0.0036906305674695985, "phrase": "\"left_or_right_eye"}, {"score": 0.003608732492631878, "phrase": "eyelash_distribution"}, {"score": 0.0035286453655992904, "phrase": "iris_pattern"}, {"score": 0.003494866798828308, "phrase": "left_eye"}, {"score": 0.0034282732966589478, "phrase": "right_eye"}, {"score": 0.003330746760940307, "phrase": "iris_recognition"}, {"score": 0.003133844153806967, "phrase": "\"color_information"}, {"score": 0.003015508235745547, "phrase": "euclidean_distance"}, {"score": 0.002967526288858809, "phrase": "chi_square_distance"}, {"score": 0.0029109517286657486, "phrase": "hamming_distance"}, {"score": 0.002892787037787436, "phrase": "hd"}, {"score": 0.0028463059289874637, "phrase": "color_space_models"}, {"score": 0.0028190406955898822, "phrase": "yiq_yuv"}, {"score": 0.0028010099697963965, "phrase": "ycbcr"}, {"score": 0.0027830956972417146, "phrase": "hsi"}, {"score": 0.0027564303939865476, "phrase": "cmy._third"}, {"score": 0.0025034338848015166, "phrase": "iris_textures"}, {"score": 0.002378114613631841, "phrase": "weighted_sum_rule"}, {"score": 0.002347775213789611, "phrase": "final_matching_score"}, {"score": 0.0023252743521788876, "phrase": "experimental_results"}, {"score": 0.0023029886389559122, "phrase": "nice.ii_training_dataset"}, {"score": 0.0022374020089160084, "phrase": "decidability_value"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Noisy iris images", " Left or right eye", " Color information", " Textural information"], "paper_abstract": "When capturing an iris image under unconstrained conditions and without user cooperation, the image quality can be highly degraded by poor focus, off-angle view, motion blur, specular reflection (SR), and other artifacts. The noisy iris images increase the intra-individual variations, thus markedly degrading recognition accuracy. To overcome these problems, we propose a new iris recognition algorithm for noisy iris images. This research is novel in the following three ways compared to previous works. First, we propose the 1st step classification method which discriminates the \"left or right eye\" on the basis of the eyelash distribution and SR points. Since the iris pattern of the left eye differs from that of the right eye, the 1st step classification can enhance the accuracy of iris recognition. Second, the separability between intra- and inter-classes is increased by using the 2nd step classification based on the \"color information\" of the iris region. They are measured by using the Euclidean distance (ED), chi square distance (CSD), and hamming distance (HD) calculated with the color space models such as YIQ YUV, YCbCr, HSI, and CMY. Third, \"textural information\" of the iris region is used for the 3rd step classification. That is, the 1-D Gabor filter is applied to the red, green, and gray image channels to afford three sets of iris codes from iris textures and, consequently, three HD scores, which are then combined on the basis of the weighted SUM rule to produce a final matching score. The experimental results with the NICE.II training dataset (selected from UBIRIS.v2 database) showed that the decidability value (d') was 1.6398 (the fourth-highest rank). (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "New iris recognition method for noisy iris images", "paper_id": "WOS:000303306900006"}