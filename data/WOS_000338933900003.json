{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "hand_gesture"}, {"score": 0.004765788394931875, "phrase": "robot-assisted_surgery"}, {"score": 0.004668957916795845, "phrase": "direct_augmented_reality_interface"}, {"score": 0.004458189822972851, "phrase": "good_alternative"}, {"score": 0.004412654209742722, "phrase": "hepatic_resection"}, {"score": 0.004322967486451877, "phrase": "liver_tumors"}, {"score": 0.004235095881928715, "phrase": "accurate_needle_insertion"}, {"score": 0.004191829338769843, "phrase": "precise_hand-eye_coordination"}, {"score": 0.004002513373645485, "phrase": "rf_needle_navigation"}, {"score": 0.0038810583785936505, "phrase": "cooperative_surgical_robot_system"}, {"score": 0.003802135020791801, "phrase": "hand_gestures"}, {"score": 0.0037057255600764475, "phrase": "augmented_reality"}, {"score": 0.003574830654211291, "phrase": "robot-assisted_percutaneous_treatment"}, {"score": 0.0034841647157189985, "phrase": "robot-assisted_natural_ar_guidance_mechanism"}, {"score": 0.00332670230152448, "phrase": "ar_visual_guidance_information"}, {"score": 0.003292685392413911, "phrase": "surgeon's_experiences"}, {"score": 0.0032256881625734777, "phrase": "robotic_surgery"}, {"score": 0.003176333519010176, "phrase": "projector-based_ar_environment"}, {"score": 0.0030017207229983385, "phrase": "intraoperative_information"}, {"score": 0.002940626369102927, "phrase": "mobile_surgical_robot_system_implements"}, {"score": 0.002910545717767559, "phrase": "rf_needle_insertion_plans"}, {"score": 0.0028807718824400697, "phrase": "natural_hand_gestures"}, {"score": 0.0028076592725295646, "phrase": "intuitive_and_robust_method"}, {"score": 0.00266693888510356, "phrase": "proposed_system"}, {"score": 0.0025992391074270097, "phrase": "mannequin_model"}, {"score": 0.0025726416100664853, "phrase": "experimental_results"}, {"score": 0.002533253511622532, "phrase": "hand_gesture_guidance"}, {"score": 0.002443671484766342, "phrase": "surgical_robot"}, {"score": 0.0022738775158524793, "phrase": "needle_insertion"}, {"score": 0.0022390533383717715, "phrase": "human-robot_cooperative_mechanism"}, {"score": 0.0021709933368474223, "phrase": "precise_transcutaneous_ablation_therapy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ireland_ltd."}], "paper_keywords": ["Human-robot cooperation", " Augmented reality", " Augmented interaction", " Visual guidance", " Image-guided surgery", " Projector-camera system"], "paper_abstract": "Radiofrequency (RF) ablation is a good alternative to hepatic resection for treatment of liver tumors. However, accurate needle insertion requires precise hand-eye coordination and is also affected by the difficulty of RF needle navigation. This paper proposes a cooperative surgical robot system, guided by hand gestures and supported by an augmented reality (AR)-based surgical field, for robot-assisted percutaneous treatment. It establishes a robot-assisted natural AR guidance mechanism that incorporates the advantages of the following three aspects: AR visual guidance information, surgeon's experiences and accuracy of robotic surgery. A projector-based AR environment is directly overlaid on a patient to display preoperative and intraoperative information, while a mobile surgical robot system implements specified RF needle insertion plans. Natural hand gestures are used as an intuitive and robust method to interact with both the AR system and surgical robot. The proposed system was evaluated on a mannequin model. Experimental results demonstrated that hand gesture guidance was able to effectively guide the surgical robot, and the robot assisted implementation was found to improve the accuracy of needle insertion. This human-robot cooperative mechanism is a promising approach for precise transcutaneous ablation therapy. (C) 2013 Elsevier Ireland Ltd. All rights reserved.", "paper_title": "Hand gesture guided robot-assisted surgery based on a direct augmented reality interface", "paper_id": "WOS:000338933900003"}