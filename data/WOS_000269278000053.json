{"auto_keywords": [{"score": 0.0033283624928018177, "phrase": "design_decisions"}, {"score": 0.003071429173571846, "phrase": "human-generated_and_computer-generated_segmentations"}, {"score": 0.0028342734482926677, "phrase": "mesh_segmentation_algorithms"}, {"score": 0.0021049977753042253, "phrase": "non-local_shape_features"}], "paper_keywords": ["3D mesh segmentation", " 3D mesh analysis"], "paper_abstract": "This paper describes a benchmark for evaluation of 3D mesh segmentation algorithms. The benchmark comprises a data set with 4,300 manually generated segmentations for 380 surface meshes of 19 different object categories, and it includes software for analyzing 11 geometric properties of segmentations and producing 4 quantitative metrics for comparison of segmentations. The paper investigates the design decisions made in building the benchmark, analyzes properties of human-generated and computer-generated segmentations, and provides quantitative comparisons of 7 recently published mesh segmentation algorithms. Our results suggest that people are remarkably consistent in the way that they segment most 3D surface meshes, that no one automatic segmentation algorithm is better than the others for all types of objects, and that algorithms based on non-local shape features seem to produce segmentations that most closely resemble ones made by humans.", "paper_title": "A Benchmark for 3D Mesh Segmentation", "paper_id": "WOS:000269278000053"}