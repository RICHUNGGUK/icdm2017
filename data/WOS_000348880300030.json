{"auto_keywords": [{"score": 0.04942981937458461, "phrase": "dynamic_scenes"}, {"score": 0.00481495049065317, "phrase": "robust_object_detection"}, {"score": 0.004653339900995785, "phrase": "illumination-invariant_background_model"}, {"score": 0.00417160036938041, "phrase": "sudden_illumination_fluctuation"}, {"score": 0.0040591367766929344, "phrase": "burst_motion"}, {"score": 0.003949693102823493, "phrase": "previous_works"}, {"score": 0.0038170129089059013, "phrase": "co-occurrence_differential_increments"}, {"score": 0.0035648266669315943, "phrase": "non-stationary_background"}, {"score": 0.0034450303951025704, "phrase": "two-stage_training_framework"}, {"score": 0.0032616462517547477, "phrase": "joint_histograms"}, {"score": 0.0032173412933955117, "phrase": "co-occurrence_probability"}, {"score": 0.0030460403366412126, "phrase": "high_normalized_correlation_coefficient_values"}, {"score": 0.0029639009054971744, "phrase": "k-means"}, {"score": 0.0029436264166293317, "phrase": "clustering-based_spatial_sampling"}, {"score": 0.002805989498127897, "phrase": "supporting_pixels"}, {"score": 0.002730240935688002, "phrase": "background_model"}, {"score": 0.0026747708876640377, "phrase": "sensitive_criterion"}, {"score": 0.0025848074189353397, "phrase": "foreground_elements"}, {"score": 0.002447101794397243, "phrase": "aist-indoor"}, {"score": 0.0022696277881969896, "phrase": "robust_and_competitive_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Object detection", " Sudden illumination fluctuation", " Burst motion", " Background modeling", " Co-occurrence probability"], "paper_abstract": "An illumination-invariant background model for detecting objects in dynamic scenes is proposed. It is robust in the cases of sudden illumination fluctuation as well as burst motion. Unlike the previous works, it uses the co-occurrence differential increments of multiple pixel pairs to distinguish objects from a non-stationary background. We use a two-stage training framework to model the background. First, joint histograms of co-occurrence probability are employed to screen supporting pixels with high normalized correlation coefficient values; then, K-means clustering-based spatial sampling optimizes the spatial distribution of the supporting pixels; finally the background model maintains a sensitive criterion with few parameters to detect foreground elements. Experiments using several challenging datasets (PETS-2001, AIST-INDOOR, Wallflower and a real surveillance application) prove the robust and competitive performance of object detection in various indoor and outdoor environments. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Co-occurrence probability-based pixel pairs background model for robust object detection in dynamic scenes", "paper_id": "WOS:000348880300030"}