{"auto_keywords": [{"score": 0.033326594281654076, "phrase": "unnecessary_data_transfers"}, {"score": 0.00481495049065317, "phrase": "increasing_demand"}, {"score": 0.004753670676591174, "phrase": "low-power_and_high-performance_multimedia_embedded_systems"}, {"score": 0.004458722048888919, "phrase": "application_bandwidth_and_latency_requirements"}, {"score": 0.0043738432231020885, "phrase": "tight_power_budget"}, {"score": 0.0039729853486821995, "phrase": "full_advantage"}, {"score": 0.0038973170902076707, "phrase": "underlying_resources"}, {"score": 0.003798654583736764, "phrase": "power_and_performance_requirements"}, {"score": 0.0037024804835018373, "phrase": "multimake"}, {"score": 0.0034282732966589478, "phrase": "parallelism_opportunities"}, {"score": 0.0033845816848753073, "phrase": "code_transformations"}, {"score": 0.0032777653153451265, "phrase": "computational_load"}, {"score": 0.003054450075234415, "phrase": "application's_tasks"}, {"score": 0.003015508235745547, "phrase": "smaller_units"}, {"score": 0.002958021635132416, "phrase": "called_kernels"}, {"score": 0.0027920359090544107, "phrase": "different_processing_resources"}, {"score": 0.0026693851900137953, "phrase": "inter-kernel_data_reuse"}, {"score": 0.0025521085778978042, "phrase": "early_execution_edges"}, {"score": 0.0023934306706217797, "phrase": "system_throughput"}, {"score": 0.0023327662621414266, "phrase": "jpeg"}, {"score": 0.0021322065604537617, "phrase": "standard_mapping"}, {"score": 0.0021049977753042253, "phrase": "task-level_pipelining_approaches"}], "paper_keywords": ["Design", " Algorithms", " Performance", " Data reuse", " estimation", " multiprocessors", " pipelining", " scheduling", " scratchpad memory", " streaming applications", " task mapping"], "paper_abstract": "The increasing demand for low-power and high-performance multimedia embedded systems has motivated the need for effective solutions to satisfy application bandwidth and latency requirements under a tight power budget. As technology scales, it is imperative that applications are optimized to take full advantage of the underlying resources and meet both power and performance requirements. We propose MultiMaKe, an application mapping design flow capable of discovering and enabling parallelism opportunities via code transformations, efficiently distributing the computational load across resources, and minimizing unnecessary data transfers. Our approach decomposes the application's tasks into smaller units of computations called kernels, which are distributed and pipelined across the different processing resources. We exploit the ideas of inter-kernel data reuse to minimize unnecessary data transfers between kernels, early execution edges to drive performance, and kernel pipelining to increase system throughput. Our experimental results on JPEG and JPEG2000 show up to 97% off-chip memory access reduction, and up to 80% execution time reduction over standard mapping and task-level pipelining approaches.", "paper_title": "MultiMaKe: Chip-Multiprocessor Driven Memory-Aware Kernel Pipelining", "paper_id": "WOS:000209492400008"}