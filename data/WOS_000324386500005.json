{"auto_keywords": [{"score": 0.03591284955015773, "phrase": "mapreduce"}, {"score": 0.00481495049065317, "phrase": "byzantine_fault-tolerant_mapreduce"}, {"score": 0.004539005582217309, "phrase": "critical_data_processing"}, {"score": 0.004207230913063179, "phrase": "scientific_or_financial_simulation"}, {"score": 0.0031845067058084613, "phrase": "byzantine_fault-tolerant_mapreduce_framework"}, {"score": 0.0024926348205500715, "phrase": "twice_more_resources"}, {"score": 0.002450864311898833, "phrase": "hadoop_mapreduce"}, {"score": 0.0022713722522505592, "phrase": "alternative_solutions"}], "paper_keywords": ["Hadoop", " MapReduce", " Byzantine fault tolerance"], "paper_abstract": "MapReduce is often used for critical data processing, e. g., in the context of scientific or financial simulation. However, there is evidence in the literature that there are arbitrary (or Byzantine) faults that may corrupt the results of MapReduce without being detected. We present a Byzantine fault-tolerant MapReduce framework that can run in two modes: nonspeculative and speculative. We thoroughly evaluate experimentally the performance of these two versions of the framework, showing that they use around twice more resources than Hadoop MapReduce, instead of the three times more of alternative solutions. We believe this cost is acceptable for many critical applications.", "paper_title": "On the Performance of Byzantine Fault-Tolerant MapReduce", "paper_id": "WOS:000324386500005"}