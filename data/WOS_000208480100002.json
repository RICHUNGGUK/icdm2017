{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "line_emotion_recognition"}, {"score": 0.004430248457624686, "phrase": "emotion_recognition"}, {"score": 0.0043181530164057135, "phrase": "virtual_agents"}, {"score": 0.003922378980031565, "phrase": "reliable_on-line_recognition"}, {"score": 0.0038476708316022823, "phrase": "user's_affect"}, {"score": 0.0036788184374592706, "phrase": "turnwise_processing"}, {"score": 0.0035627492415494216, "phrase": "novel_approach"}, {"score": 0.0035173498506324476, "phrase": "on-line_emotion_recognition"}, {"score": 0.0034282732966589478, "phrase": "long_short-term_memory_recurrent_neural_networks"}, {"score": 0.003215295260684715, "phrase": "two-dimensional_valence-activation_continuum"}, {"score": 0.002864628676257225, "phrase": "low-level_signal_frames"}, {"score": 0.002738797804069541, "phrase": "speech_recognition"}, {"score": 0.0026865721000905235, "phrase": "statistical_functionals"}, {"score": 0.0026184796288543878, "phrase": "low-level_feature_contours"}, {"score": 0.002535779689260244, "phrase": "higher_level"}, {"score": 0.0024556852466581527, "phrase": "regression_outputs"}, {"score": 0.0023327506323251074, "phrase": "low-level_input_frame"}, {"score": 0.00220177373403577, "phrase": "linguistic_features"}, {"score": 0.0021597662797996843, "phrase": "signal_frame_level"}, {"score": 0.0021049977753042253, "phrase": "keyword_spotter"}], "paper_keywords": ["Continuous emotion recognition", " Recurrent neural nets", " Long short-term memory", " Affective databases"], "paper_abstract": "For many applications of emotion recognition, such as virtual agents, the system must select responses while the user is speaking. This requires reliable on-line recognition of the user's affect. However most emotion recognition systems are based on turnwise processing. We present a novel approach to on-line emotion recognition from speech using Long Short-Term Memory Recurrent Neural Networks. Emotion is recognised frame-wise in a two-dimensional valence-activation continuum. In contrast to current state-of-the-art approaches, recognition is performed on low-level signal frames, similar to those used for speech recognition. No statistical functionals are applied to low-level feature contours. Framing at a higher level is therefore unnecessary and regression outputs can be produced in real-time for every low-level input frame. We also investigate the benefits of including linguistic features on the signal frame level obtained by a keyword spotter.", "paper_title": "On-line emotion recognition in a 3-D activation-valence-time continuum using acoustic and linguistic cues", "paper_id": "WOS:000208480100002"}