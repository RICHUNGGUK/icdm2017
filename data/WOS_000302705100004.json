{"auto_keywords": [{"score": 0.031235092053115466, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "view-invariant_action_recognition"}, {"score": 0.004724020632103649, "phrase": "artificial_neural_networks"}, {"score": 0.004240116703465252, "phrase": "novel_representation"}, {"score": 0.004186534737631288, "phrase": "action_videos"}, {"score": 0.004055511503825102, "phrase": "spatially_related_human_body_posture_prototypes"}, {"score": 0.003903663808332582, "phrase": "fuzzy_distances"}, {"score": 0.00385431710959668, "phrase": "human_body_posture_prototypes"}, {"score": 0.0036864465771943933, "phrase": "invariant_action_representation"}, {"score": 0.003639835714755229, "phrase": "multilayer_perceptrons"}, {"score": 0.003548368289666932, "phrase": "action_classification"}, {"score": 0.0033295966773779174, "phrase": "multi-camera_setup"}, {"score": 0.0032666255024083983, "phrase": "arbitrary_number"}, {"score": 0.0030071857666598193, "phrase": "bayesian_framework"}, {"score": 0.002564613964408878, "phrase": "different_viewing_angles"}, {"score": 0.0025160740422447837, "phrase": "high_classification_performance"}, {"score": 0.002421726275597666, "phrase": "first_one"}, {"score": 0.002316105585203396, "phrase": "experimental_setups"}, {"score": 0.0021319959284827896, "phrase": "open_issues"}, {"score": 0.0021049977753042253, "phrase": "action_recognition"}], "paper_keywords": ["Bayesian frameworks", " fuzzy vector quantization", " human action recognition", " multilayer perceptrons"], "paper_abstract": "In this paper, a novel view invariant action recognition method based on neural network representation and recognition is proposed. The novel representation of action videos is based on learning spatially related human body posture prototypes using self organizing maps. Fuzzy distances from human body posture prototypes are used to produce a time invariant action representation. Multilayer perceptrons are used for action classification. The algorithm is trained using data from a multi-camera setup. An arbitrary number of cameras can be used in order to recognize actions using a Bayesian framework. The proposed method can also be applied to videos depicting interactions between humans, without any modification. The use of information captured from different viewing angles leads to high classification performance. The proposed method is the first one that has been tested in challenging experimental setups, a fact that denotes its effectiveness to deal with most of the open issues in action recognition.", "paper_title": "View-Invariant Action Recognition Based on Artificial Neural Networks", "paper_id": "WOS:000302705100004"}