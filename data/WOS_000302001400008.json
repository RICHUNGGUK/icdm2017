{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "inadequate_labeled_data"}, {"score": 0.004682414867878963, "phrase": "actual_and_challenging_issue"}, {"score": 0.0046046429665581555, "phrase": "cost-sensitive_models"}, {"score": 0.004378958522416482, "phrase": "plentiful_unlabeled_data"}, {"score": 0.00428222231579898, "phrase": "time_labeled_data"}, {"score": 0.003724034990158436, "phrase": "cost-sensitive_classifier"}, {"score": 0.0034630606658026595, "phrase": "expectation_maximization"}, {"score": 0.003348838095597268, "phrase": "first_method"}, {"score": 0.0031845067058084583, "phrase": "semi-supervised_classifier"}, {"score": 0.0030794433253250476, "phrase": "optimal_class_label"}, {"score": 0.0030282147475402736, "phrase": "test_example"}, {"score": 0.002977835845437357, "phrase": "class_probability"}, {"score": 0.002911961514073769, "phrase": "learning_model"}, {"score": 0.0028635111041882956, "phrase": "second_method"}, {"score": 0.0028316582436089064, "phrase": "cs-em"}, {"score": 0.0027382040767844093, "phrase": "misclassification_cost"}, {"score": 0.00269263690712392, "phrase": "probability_estimation_process"}, {"score": 0.0026330549554033876, "phrase": "extensive_experiments"}, {"score": 0.0024346858809238766, "phrase": "labeled_training_examples"}, {"score": 0.0022893422054387235, "phrase": "selected_uci_data"}, {"score": 0.002251227801482381, "phrase": "different_cost_ratios"}, {"score": 0.0022013916728990564, "phrase": "cost_ratio"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Cost-sensitive learning", " Classification", " Semi-supervised learning", " Expectation maximization"], "paper_abstract": "It is an actual and challenging issue to learn cost-sensitive models from those datasets that are with few labeled data and plentiful unlabeled data, because some time labeled data are very difficult, time consuming and/or expensive to obtain. To solve this issue, in this paper we proposed two classification strategies to learn cost-sensitive classifier from training datasets with both labeled and unlabeled data, based on Expectation Maximization (EM). The first method, Direct-EM, uses EM to build a semi-supervised classifier, then directly computes the optimal class label for each test example using the class probability produced by the learning model. The second method, CS-EM, modifies EM by incorporating misclassification cost into the probability estimation process. We conducted extensive experiments to evaluate the efficiency, and results show that when using only a small number of labeled training examples, the CS-EM outperforms the other competing methods on majority of the selected UCI data sets across different cost ratios, especially when cost ratio is high. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Cost-sensitive classification with inadequate labeled data", "paper_id": "WOS:000302001400008"}