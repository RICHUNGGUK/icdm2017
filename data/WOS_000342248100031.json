{"auto_keywords": [{"score": 0.03876353189850781, "phrase": "camera_velocity"}, {"score": 0.00481495049065317, "phrase": "visual_simultaneous_localization"}, {"score": 0.0047152877145889656, "phrase": "vslam"}, {"score": 0.0043367547691560175, "phrase": "unknown_environment"}, {"score": 0.004180809918117248, "phrase": "classic_methods"}, {"score": 0.0040942189695983185, "phrase": "extended_kalman_filter"}, {"score": 0.0038049789989278463, "phrase": "low_frame_rate_cameras"}, {"score": 0.0037261429556468217, "phrase": "sudden_changes"}, {"score": 0.003373334961160647, "phrase": "complex_movements"}, {"score": 0.003251920460276645, "phrase": "novel_vslam_approach"}, {"score": 0.0032180376288035296, "phrase": "conditional_simultaneous_localization"}, {"score": 0.0030220049006970317, "phrase": "camera_state_transition"}, {"score": 0.0029593432468318745, "phrase": "image_data"}, {"score": 0.0029284999172756103, "phrase": "optical_flow_constraints"}, {"score": 0.002897977113538355, "phrase": "epipolar_geometry"}, {"score": 0.0028527866590859967, "phrase": "prediction_stage"}, {"score": 0.002750056254309311, "phrase": "prediction_accuracy"}, {"score": 0.0026649432435828842, "phrase": "predefined_dynamic_models"}, {"score": 0.0026233771102489394, "phrase": "additional_computation"}, {"score": 0.00256895975568914, "phrase": "classic_vslam_approaches"}, {"score": 0.002542174767860791, "phrase": "c-slam"}, {"score": 0.0024377918036784336, "phrase": "high_computational_efficiency"}, {"score": 0.0023499703712897293, "phrase": "abrupt_changes"}, {"score": 0.002301211274459965, "phrase": "low_camera_frame_rate"}, {"score": 0.002206700502606511, "phrase": "experimental_results"}], "paper_keywords": ["Visual simultaneous localization and mapping", " Extended Kalman filter", " Conditional filtering", " Low frame rate"], "paper_abstract": "Visual simultaneous localization and mapping (VSLAM) is becoming increasingly popular in research and industry as a solution for mapping an unknown environment with moving cameras. However, classic methods such as the Extended Kalman Filter (EKF)-based VSLAM have two significant limitations: First, their robustness and accuracy drop dramatically when low frame rate cameras are used or sudden changes in camera velocity occur. Second, their dynamic models are expensive to build, or are too simple to simulate complex movements. In this paper, a novel VSLAM approach called conditional simultaneous localization and mapping (C-SLAM) is proposed in which camera state transition is derived from image data using optical flow constraints and epipolar geometry in the prediction stage. This improvement not only increases prediction accuracy but also replaces commonly used predefined dynamic models which require additional computation. Compared to classic VSLAM approaches, C-SLAM performs more accurately in prediction and has high computational efficiency, especially under conditions such as abrupt changes in camera velocity or low camera frame rate. Such advantages are supported by the experimental results and analysis presented in this paper. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Conditional simultaneous localization and mapping: A robust visual SLAM system", "paper_id": "WOS:000342248100031"}