{"auto_keywords": [{"score": 0.04242092921688311, "phrase": "pca"}, {"score": 0.004815071324382793, "phrase": "robust"}, {"score": 0.004404658750724105, "phrase": "robust_principal_component_analysis"}, {"score": 0.004254671386496732, "phrase": "also_cases"}, {"score": 0.003989487818395848, "phrase": "widely_applied_standard_statistical_method"}, {"score": 0.0037039021744127783, "phrase": "second-order_statistics"}, {"score": 0.0035600143547053287, "phrase": "gaussian_data"}, {"score": 0.003421697038352743, "phrase": "data_sets"}, {"score": 0.0033879628186273625, "phrase": "unknown_or_other_types"}, {"score": 0.003176626803985225, "phrase": "mean-square_representation_error"}, {"score": 0.00308357048262018, "phrase": "orthonormality_constraints"}, {"score": 0.0030081030319492343, "phrase": "quadratic_criteria"}, {"score": 0.0028768722873689432, "phrase": "long-tailed_distributions"}, {"score": 0.0027377579637003135, "phrase": "pca."}, {"score": 0.0026973310437053573, "phrase": "robust_methods"}, {"score": 0.002504011301105577, "phrase": "experimental_results"}, {"score": 0.002442693254693416, "phrase": "often_better_results"}, {"score": 0.002418587525752333, "phrase": "standard_pca"}, {"score": 0.0022452005651385095, "phrase": "incomplete_data"}, {"score": 0.002223039450439376, "phrase": "missing_values"}, {"score": 0.0021049977753042253, "phrase": "nonlinear_models"}], "paper_keywords": ["Principal component analysis", " robustness", " missing values", " gradient algorithms", " imputation method", " and nearest neighbor method"], "paper_abstract": "In this paper, we consider and introduce methods for robust principal component analysis (P CA), including also cases where there are missing values in the data. PCA is a widely applied standard statistical method for data preprocessing, compression, and analysis. It is based on the second-order statistics of the data and is optimal for Gaussian data, but it is often applied to data sets having unknown or other types of probability distributions. PCA can be derived from minimization of the mean-square representation error or maximization of variances under orthonormality constraints. However, these quadratic criteria are sensitive to outliers in the data and long-tailed distributions, which may considerably degrade the results given by PCA. We introduce robust methods for estimation of both the PCA eigenvectors directly or the PCA subspace spanned by them. Experimental results show that our methods provide often better results than standard PCA when outliers are present in the data. Furthermore, we extend our methods to incomplete data with missing values. The problems arising in such cases have several features typical for nonlinear models.", "paper_title": "ROBUST PCA METHODS FOR COMPLETE AND MISSING DATA", "paper_id": "WOS:000297179900001"}