{"auto_keywords": [{"score": 0.04934211582254907, "phrase": "knowledge_gathering"}, {"score": 0.048078039066526225, "phrase": "conceptual_framework"}, {"score": 0.047019075018547234, "phrase": "eye-tracking_data"}, {"score": 0.03800874215251104, "phrase": "knowledge_representation"}, {"score": 0.004777744121315302, "phrase": "visual_search"}, {"score": 0.004542780650208743, "phrase": "expert_knowledge"}, {"score": 0.004386887374401584, "phrase": "domain-specific_knowledge"}, {"score": 0.004302593474473502, "phrase": "visual_behaviour"}, {"score": 0.004171065188039856, "phrase": "complex_visual_tasks"}, {"score": 0.004075053556360943, "phrase": "relevant_insights"}, {"score": 0.004027876348834879, "phrase": "cognitive_strategies"}, {"score": 0.003904713104101532, "phrase": "visual_search_tasks"}, {"score": 0.003770633265791941, "phrase": "generic_feature_spaces"}, {"score": 0.0036411406244705557, "phrase": "selected_scheme"}, {"score": 0.003516079377293321, "phrase": "feature_space"}, {"score": 0.0033559647822437298, "phrase": "mathematical_construct"}, {"score": 0.0032786537599187125, "phrase": "perceptually_meaningful_visual_cues"}, {"score": 0.0031050953733360825, "phrase": "spatial_domain"}, {"score": 0.0030572112793962004, "phrase": "spatial_coordinates"}, {"score": 0.003021781956684419, "phrase": "gaze_points"}, {"score": 0.002917931350071647, "phrase": "proposed_conceptual_framework"}, {"score": 0.002839625463110821, "phrase": "visual_search_patterns"}, {"score": 0.0027741761880779535, "phrase": "stereotypical_visual_behaviour"}, {"score": 0.0025567271683947547, "phrase": "feature_domain"}, {"score": 0.002421291757425244, "phrase": "main_aspects"}, {"score": 0.002319918823705175, "phrase": "detailed_presentation"}, {"score": 0.0022664208122072657, "phrase": "practical_application"}, {"score": 0.00224013518726087, "phrase": "expert_knowledge_gathering"}, {"score": 0.002222780643552078, "phrase": "lung_radiology"}, {"score": 0.0021049977753042253, "phrase": "particular_functional_implementation"}], "paper_keywords": ["Visual attention", " Eye movements", " Feature domain", " Bottom-up and top-down processes", " Visual saliency"], "paper_abstract": "In this article, a conceptual framework developed to acquire expert knowledge from eye-tracking data of skilled individuals is presented. Domain-specific knowledge is acquired from the visual behaviour of subjects whose eye movements are recorded while solving complex visual tasks. It is argued that relevant insights into the cognitive strategies followed by the observers to solve the visual search tasks may be gained by analysing the eye-tracking data in generic feature spaces, which are at the basis of the selected scheme for knowledge representation. In this context, a feature space is a domain in which each dimension is defined as a mathematical construct, which may correspond to perceptually meaningful visual cues and which can take either numerical or categorical values. A special case of such feature spaces is the spatial domain in which the spatial coordinates of the gaze points define the dimensions of such domain. In the proposed conceptual framework, the definition of similarities between visual search patterns is essential to characterise the stereotypical visual behaviour of a group of observers, and thus expert knowledge. Furthermore, since knowledge representation is closely related to the feature domain in which the search is analysed, feature relevance measures become central to knowledge gathering, and the main aspects regarding their definition are discussed in this work. Following a detailed presentation of the conceptual framework, a practical application dealing with expert knowledge gathering in lung radiology is shown both as a proof of concept and also to illustrate a particular functional implementation of the framework.", "paper_title": "A Novel Framework for the Analysis of Eye Movements during Visual Search for Knowledge Gathering", "paper_id": "WOS:000292777700016"}