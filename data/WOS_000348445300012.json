{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "action_recognition"}, {"score": 0.040882934314756744, "phrase": "different_combination"}, {"score": 0.040365287558033626, "phrase": "semi-supervised_learning_method"}, {"score": 0.028825733577297008, "phrase": "mlhr"}, {"score": 0.0046738485441681485, "phrase": "computer_vision"}, {"score": 0.004643055780443262, "phrase": "multimedia_areas"}, {"score": 0.0045820747375409435, "phrase": "spatial_information"}, {"score": 0.004536862734384202, "phrase": "semantic_meaning"}, {"score": 0.004389339243427964, "phrase": "noisy_and_weakly_annotated_information"}, {"score": 0.004218602458288531, "phrase": "traditional_features"}, {"score": 0.004122077038067119, "phrase": "new_attempts"}, {"score": 0.00404109360612109, "phrase": "action_recognition_promising"}, {"score": 0.0032807941194429235, "phrase": "order_pooling"}, {"score": 0.003153041030690117, "phrase": "traditional_bag"}, {"score": 0.0029805015010906013, "phrase": "overall_performance"}, {"score": 0.00290259605431505, "phrase": "good_way"}, {"score": 0.0028549396580672417, "phrase": "coding_stage"}, {"score": 0.0028360962841331634, "phrase": "video_classification"}, {"score": 0.0027636537516598034, "phrase": "semi"}, {"score": 0.0027346529452880585, "phrase": "hierarchical_regression_algorithm"}, {"score": 0.002689746491842271, "phrase": "manifold_regularized_least_square_regression"}, {"score": 0.0026107601878587816, "phrase": "j_mach_learn_res"}, {"score": 0.00250073564820402, "phrase": "supervised_learning_methods"}, {"score": 0.0023795195973873636, "phrase": "real_world_action_recognition_problems"}, {"score": 0.002317295987732084, "phrase": "kth"}, {"score": 0.0022867816753560856, "phrase": "hmdb"}, {"score": 0.0022641658133181115, "phrase": "late_fusion"}, {"score": 0.002154392046210367, "phrase": "multi-kernel_learning"}, {"score": 0.0021049977753042253, "phrase": "multi-feature_problems"}], "paper_keywords": ["Semi-supervised learning", " Multi-feature fusion", " Second order pooling", " Video concept annotation", " Action recognition"], "paper_abstract": "Action recognition is one of the most difficult problems in computer vision and multimedia areas, since both spatial information and spatiotemporal semantic meaning should be taken into consideration. Moreover, the noisy and weakly annotated information make this task even harder. Nowadays, instead of the traditional features and classifiers, a lot of new attempts have made the task of action recognition promising. Noticing that there is no work on comparison of different combination of pooling and semi-supervised learning method under the same experiment setting, it would be interesting to apply different combination of pooling and semi-supervised learning method on both the synthetic and realistic action recognition datasets to see which combination or method performs better. In summary, we can obtain the following conclusions based on our experiments. Firstly, Second Order Pooling (Carreira et al. 2012) is worse than the traditional Bag of Words (Schmid and Mohr 1997; Dance et al. 2004) regarding to the overall performance in some dataset, but is a good way to speed up the coding stage of video classification with little sacrifice of performance. Secondly, Semi-supervised Hierarchical Regression Algorithm (MLHR) and Manifold Regularized Least Square Regression (MRLS) (Belkin et al. J Mach Learn Res 12:2399-2434, 2006) is better than some of the supervised learning methods (chi(2)-SVM, SVM-2K ( Farquhar et al. 2006)) in the real world action recognition problems which shares little available annotated information. Thirdly, for KTH, UCF50 and HMDB dataset, late fusion doesn't necessarily improve the performance. In comparison, MLHR, SVM-2K and Multi-kernel Learning is a more natural way to deal with multi-feature problems.", "paper_title": "Evaluation of semi-supervised learning method on action recognition", "paper_id": "WOS:000348445300012"}