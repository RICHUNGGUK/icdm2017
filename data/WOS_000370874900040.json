{"auto_keywords": [{"score": 0.036866004068638804, "phrase": "litmus_tests"}, {"score": 0.004815316573636744, "phrase": "gpu"}, {"score": 0.004392565073466714, "phrase": "graphics_processing_units"}, {"score": 0.00427550604912774, "phrase": "current_specifications"}, {"score": 0.003985487777785535, "phrase": "folklore_assumptions"}, {"score": 0.003675120438902734, "phrase": "large_empirical_study"}, {"score": 0.0036159990127332315, "phrase": "concurrent_behaviour"}, {"score": 0.0035771121569391916, "phrase": "deployed_gpus"}, {"score": 0.0032629585038738856, "phrase": "programming_guides"}, {"score": 0.0032278559855285945, "phrase": "vendor_documentation"}, {"score": 0.002881255933884771, "phrase": "stressful_workloads"}, {"score": 0.0027741761880779535, "phrase": "previously_elusive_weak_behaviours"}, {"score": 0.002714779217561487, "phrase": "folklore_beliefs"}, {"score": 0.002685558057339722, "phrase": "gpu_programming"}, {"score": 0.002613870237087035, "phrase": "official_tutorials"}, {"score": 0.002410058288617039, "phrase": "nvidia_gpu_hardware"}, {"score": 0.002198173002125907, "phrase": "sparc_relaxed_memory_order"}, {"score": 0.0021049977753042253, "phrase": "gpu_concurrency_hierarchy"}], "paper_keywords": ["memory consistency", " GPU", " Nvidia PTX", " OpenCL", " litmus testing", " test generation", " formal model"], "paper_abstract": "Concurrency is pervasive and perplexing, particularly on graphics processing units (GPUs). Current specifications of languages and hardware are inconclusive; thus programmers often rely on folklore assumptions when writing software. To remedy this state of affairs, we conducted a large empirical study of the concurrent behaviour of deployed GPUs. Armed with litmus tests (i.e. short concurrent programs), we questioned the assumptions in programming guides and vendor documentation about the guarantees provided by hardware. We developed a tool to generate thousands of litmus tests and run them under stressful workloads. We observed a litany of previously elusive weak behaviours, and exposed folklore beliefs about GPU programming-often supported by official tutorials-as false. As a way forward, we propose a model of Nvidia GPU hardware, which correctly models every behaviour witnessed in our experiments. The model is a variant of SPARC Relaxed Memory Order (RMO), structured following the GPU concurrency hierarchy.", "paper_title": "GPU Concurrency: Weak Behaviours and Programming Assumptions", "paper_id": "WOS:000370874900040"}