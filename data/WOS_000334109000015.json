{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "efficient_computational_framework"}, {"score": 0.004684157900507474, "phrase": "hashing_data"}, {"score": 0.004494570360108983, "phrase": "multiple_modalities"}, {"score": 0.004312622975366676, "phrase": "single_representation_space"}, {"score": 0.0038624981944755813, "phrase": "proposed_approach"}, {"score": 0.0035072146967082083, "phrase": "siamese_neural_network_architecture"}, {"score": 0.0033651019362620866, "phrase": "unified_treatment"}, {"score": 0.002851790448644913, "phrase": "existing_cross-modality_similarity_learning_approaches"}, {"score": 0.002518746501941657, "phrase": "binarized_linear_projections"}, {"score": 0.0023834640793589435, "phrase": "arbitrarily_complex_forms"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_hashing_approaches"}], "paper_keywords": ["Similarity-sensitive hashing", " metric learning", " feature descriptor", " neural network"], "paper_abstract": "We introduce an efficient computational framework for hashing data belonging to multiple modalities into a single representation space where they become mutually comparable. The proposed approach is based on a novel coupled siamese neural network architecture and allows unified treatment of intra-and inter-modality similarity learning. Unlike existing cross-modality similarity learning approaches, our hashing functions are not limited to binarized linear projections and can assume arbitrarily complex forms. We show experimentally that our method significantly outperforms state-of-the-art hashing approaches on multimedia retrieval tasks.", "paper_title": "Multimodal Similarity-Preserving Hashing", "paper_id": "WOS:000334109000015"}