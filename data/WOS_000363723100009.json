{"auto_keywords": [{"score": 0.04889532068804287, "phrase": "linear_ranksvm"}, {"score": 0.01423636708723291, "phrase": "existing_methods"}, {"score": 0.010243145976866923, "phrase": "gpu"}, {"score": 0.00481495049065317, "phrase": "gpu-accelerated_parallel_algorithms"}, {"score": 0.004551199992546761, "phrase": "widely_used_methods"}, {"score": 0.004274981117736524, "phrase": "trust_region"}, {"score": 0.004248294537944227, "phrase": "newton_method"}, {"score": 0.004195418945396429, "phrase": "tron"}, {"score": 0.004117329555194574, "phrase": "order-statistic_tree"}, {"score": 0.0037246656582642272, "phrase": "large-scale_data_sets"}, {"score": 0.0034332736827447654, "phrase": "large_amount"}, {"score": 0.0033905067962602515, "phrase": "data-intensive_computing"}, {"score": 0.0031646057802503526, "phrase": "great_computational_power"}, {"score": 0.003047776993499616, "phrase": "training_speed"}, {"score": 0.0028446460307503343, "phrase": "pswx-tron"}, {"score": 0.0028091907694771613, "phrase": "psy-tron"}, {"score": 0.0026384167183586015, "phrase": "gpu_architecture"}, {"score": 0.0025892330566358503, "phrase": "proposed_parallel_algorithms"}, {"score": 0.0023566987138026285, "phrase": "different_queries"}, {"score": 0.0023127544795063263, "phrase": "experimental_results"}, {"score": 0.0021857667493036786, "phrase": "proposed_algorithms"}, {"score": 0.0021049977753042253, "phrase": "impressive_training_speeds"}], "paper_keywords": ["Parallel computing", " GPU computing", " Linear rankSVM", " Learning to rank", " Trust region Newton method"], "paper_abstract": "Linear rankSVM is one of the widely used methods for learning to rank. The existing methods such as trust region Newton method (TRON) with order-statistic tree cannot perform efficiently when any one of them is exploited to deal with the large-scale data sets. It is observed that training the linear rankSVM with L2-loss requires a large amount of data-intensive computing, and therefore is feasible to make use of the great computational power of GPU to improve the training speed. In this paper, we propose two efficient parallel algorithms (named PSWX-TRON and PSY-TRON) to train the linear rankSVM with L2-loss on the GPU architecture. The proposed parallel algorithms can work efficiently on GPU if the training set is divided in terms of different queries. The experimental results show that compared with the existing methods, the proposed algorithms not only can obtain the impressive training speeds, but also can perform well in prediction.", "paper_title": "GPU-accelerated parallel algorithms for linear rankSVM", "paper_id": "WOS:000363723100009"}