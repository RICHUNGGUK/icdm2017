{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "stereoscopic_images"}, {"score": 0.009130307850048015, "phrase": "saliency_detection"}, {"score": 0.0057144934634156515, "phrase": "final_saliency_map"}, {"score": 0.00436890075128947, "phrase": "emerging_applications"}, {"score": 0.004321952227344232, "phrase": "stereoscopic_display"}, {"score": 0.00427550604912774, "phrase": "new_saliency_detection_models"}, {"score": 0.004229556887896042, "phrase": "salient_region_extraction"}, {"score": 0.004028796143006953, "phrase": "depth_feature"}, {"score": 0.003635600104609725, "phrase": "novel_stereoscopic_saliency_detection_framework"}, {"score": 0.00355782527287734, "phrase": "feature_contrast"}, {"score": 0.003057910095857785, "phrase": "discrete_cosine_transform_coefficients"}, {"score": 0.0030250067691601967, "phrase": "feature_contrast_calculation"}, {"score": 0.0029763124376934787, "phrase": "gaussian_model"}, {"score": 0.002928399649340438, "phrase": "spatial_distance"}, {"score": 0.0028968858148006823, "phrase": "image_patches"}, {"score": 0.0028043588777213533, "phrase": "local_and_global_contrast_calculation"}, {"score": 0.0027295084882654917, "phrase": "new_fusion_method"}, {"score": 0.0026423134393535265, "phrase": "feature_maps"}, {"score": 0.0024495111090152857, "phrase": "center_bias_factor"}, {"score": 0.0024231382864800173, "phrase": "human_visual_acuity"}, {"score": 0.0023841092222805253, "phrase": "important_characteristics"}, {"score": 0.002345707314211983, "phrase": "human_visual_system"}, {"score": 0.002234165013865669, "phrase": "experimental_results"}, {"score": 0.002198173002125909, "phrase": "tracking_databases"}, {"score": 0.0021627595586364724, "phrase": "superior_performance"}, {"score": 0.002127915423138391, "phrase": "proposed_model"}], "paper_keywords": ["Stereoscopic image", " 3D image", " stereoscopic saliency detection", " visual attention", " human visual acuity"], "paper_abstract": "Many saliency detection models for 2D images have been proposed for various multimedia processing applications during the past decades. Currently, the emerging applications of stereoscopic display require new saliency detection models for salient region extraction. Different from saliency detection for 2D images, the depth feature has to be taken into account in saliency detection for stereoscopic images. In this paper, we propose a novel stereoscopic saliency detection framework based on the feature contrast of color, luminance, texture, and depth. Four types of features, namely color, luminance, texture, and depth, are extracted from discrete cosine transform coefficients for feature contrast calculation. A Gaussian model of the spatial distance between image patches is adopted for consideration of local and global contrast calculation. Then, a new fusion method is designed to combine the feature maps to obtain the final saliency map for stereoscopic images. In addition, we adopt the center bias factor and human visual acuity, the important characteristics of the human visual system, to enhance the final saliency map for stereoscopic images. Experimental results on eye tracking databases show the superior performance of the proposed model over other existing methods.", "paper_title": "Saliency Detection for Stereoscopic Images", "paper_id": "WOS:000336792500001"}