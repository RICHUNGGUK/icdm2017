{"auto_keywords": [{"score": 0.004662427600500598, "phrase": "optimization-related_problems"}, {"score": 0.004011867299107537, "phrase": "existing_ones"}, {"score": 0.003802135020791801, "phrase": "computing_blocks"}, {"score": 0.0036422425344358037, "phrase": "dynamic_systems"}, {"score": 0.003378385493203297, "phrase": "distinguished_properties"}, {"score": 0.003034158379493625, "phrase": "variational_inequalities"}, {"score": 0.002969628818856786, "phrase": "related_optimization_problems"}, {"score": 0.0029064676523923886, "phrase": "mixed_linear_and_nonlinear_constraints"}, {"score": 0.0022696277881969896, "phrase": "alternative_choice"}, {"score": 0.0022213218042340735, "phrase": "circuits_implementation"}], "paper_keywords": ["Asymptotic stability", " global convergence", " linear programming (LP)", " optimization", " quadratic programming (QP)", " recurrent neural network (RNN)", " variational inequality"], "paper_abstract": "There exist many recurrent neural networks for solving optimization-related problems. In this paper, we present a method for deriving such networks from existing ones by changing connections between computing blocks. Although the dynamic systems may become much different, some distinguished properties may be retained. One example is discussed to solve variational inequalities and related optimization problems with mixed linear and nonlinear constraints. A new network is obtained from two classical models by this means, and its performance is comparable to its predecessors. Thus, an alternative choice for circuits implementation is offered to accomplish such computing tasks.", "paper_title": "An Alternative Recurrent Neural Network for Solving Variational Inequalities and Related Optimization Problems", "paper_id": "WOS:000270143800026"}