{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dimensionality_reduction"}, {"score": 0.049568154654955725, "phrase": "distributional_similarity"}, {"score": 0.004712726613162057, "phrase": "semi-supervised_learning"}, {"score": 0.004612662942073808, "phrase": "considerable_attention"}, {"score": 0.004563427013973105, "phrase": "machine_learning"}, {"score": 0.0043482604833437735, "phrase": "novel_diffusion_maps"}, {"score": 0.00409895142748329, "phrase": "data_representation"}, {"score": 0.0040334640350288, "phrase": "previous_work"}, {"score": 0.003926626018798576, "phrase": "similarity_metric_construction"}, {"score": 0.0038638811223100184, "phrase": "distributional_similarity_metric"}, {"score": 0.003741371936431574, "phrase": "geometric_relationship"}, {"score": 0.0035457302646174148, "phrase": "posterior_probability"}, {"score": 0.0031845067058084583, "phrase": "euclidean_distance"}, {"score": 0.003100085797251317, "phrase": "intrinsic_manifold"}, {"score": 0.002969628818856786, "phrase": "label-dependent_\"diffusion_distance"}, {"score": 0.0027543636132088332, "phrase": "original_space"}, {"score": 0.002681315076008658, "phrase": "local_manifold_structure"}, {"score": 0.0025822818714499795, "phrase": "different_classes"}, {"score": 0.0024868972942701604, "phrase": "encouraging_experimental_results"}, {"score": 0.002460295872115956, "phrase": "handwritten_digits"}, {"score": 0.0024339783012484032, "phrase": "yale_faces"}, {"score": 0.0024079476621196106, "phrase": "uci"}, {"score": 0.00234406029760526, "phrase": "weizmann"}, {"score": 0.0022213218042340735, "phrase": "classification_accuracy"}, {"score": 0.0021857667493036786, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Diffusion maps", " Manifold learning", " Label information", " Expectation-Maximization", " Distributional similarity"], "paper_abstract": "Semi-supervised learning has recently received considerable attention in machine learning. In this paper, we propose a novel diffusion maps based semi-supervised algorithm for dimensionality reduction, visualization and data representation. Unlike previous work which uses only geometric information for similarity metric construction, a distributional similarity metric is introduced to modify the geometric relationship of samples. This metric is defined using the posterior probability over the labels of each sample, which is learned through the Expectation-Maximization (EM) algorithm. The Euclidean distance between points on the intrinsic manifold learned by our proposed method is equal to the label-dependent \"diffusion distance\", which is modified by the distributional similarity related metric, in the original space. Our algorithm preserves the local manifold structure in addition to separating samples in different classes, thus facilitates the classification. Encouraging experimental results on handwritten digits, Yale faces, UCI data sets and the Weizmann data set show that the algorithm can improve the classification accuracy significantly. Crown Copyright (C) 2012 Published by Elsevier B.V. All rights reserved.", "paper_title": "A semi-supervised approach for dimensionality reduction with distributional similarity", "paper_id": "WOS:000313374500022"}