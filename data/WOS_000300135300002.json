{"auto_keywords": [{"score": 0.04496930556292013, "phrase": "mobile_images"}, {"score": 0.015719716506582538, "phrase": "mobile_visual_search"}, {"score": 0.012641655711243769, "phrase": "large_variations"}, {"score": 0.004630270043271386, "phrase": "popular_and_unique_image_retrieval_application"}, {"score": 0.004345085569121329, "phrase": "appearance_variations"}, {"score": 0.004219427915728969, "phrase": "state-of-the-art_image_retrieval_systems"}, {"score": 0.003940122359770492, "phrase": "visual_search"}, {"score": 0.003385480888810982, "phrase": "spatial_relationships"}, {"score": 0.0033524956061690868, "phrase": "visual_words"}, {"score": 0.0031767199435197243, "phrase": "novel_visual_search_method"}, {"score": 0.003130396338031522, "phrase": "feature_grouping"}, {"score": 0.003099888654615187, "phrase": "local_soft_match"}, {"score": 0.002966230968271199, "phrase": "visual_and_spatial_information"}, {"score": 0.0029229677574293725, "phrase": "first_features"}, {"score": 0.002880333728285514, "phrase": "query_image"}, {"score": 0.0028106505443369545, "phrase": "matched_visual_features"}, {"score": 0.002663208600887875, "phrase": "quantization_loss"}, {"score": 0.0026243534128245886, "phrase": "efficient_score_scheme"}, {"score": 0.0025608471909800076, "phrase": "inverted_file_index"}, {"score": 0.002511147699138714, "phrase": "vocabulary-guided_pyramid_kernels"}, {"score": 0.0024503741901918527, "phrase": "stanford_mobile_visual_search_database"}, {"score": 0.002333193766510394, "phrase": "proposed_method"}, {"score": 0.0023104373174118458, "phrase": "promising_improvement"}, {"score": 0.0022434880661725493, "phrase": "vocabulary_tree"}, {"score": 0.0021678232353129472, "phrase": "query_images"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Mobile visual search", " Mobile image", " Feature grouping", " Spatial information", " Local soft match"], "paper_abstract": "More powerful mobile devices stimulate mobile visual search to become a popular and unique image retrieval application. A number of challenges come up with such application, resulting from appearance variations in mobile images. Performance of state-of-the-art image retrieval systems is improved using bag-of-words approaches. However, for visual search by mobile images with large variations, there are at least two critical issues unsolved: (1) the loss of features discriminative power due to quantization; and (2) the underuse of spatial relationships among visual words. To address both issues, this paper presents a novel visual search method based on feature grouping and local soft match, which considers properties of mobile images and couples visual and spatial information consistently. First features of the query image are grouped using both matched visual features and their spatial relationships; and then grouped features are softly matched to alleviate quantization loss. An efficient score scheme is devised to utilize inverted file index and compared with vocabulary-guided pyramid kernels. Finally experiments on Stanford mobile visual search database and a collected database with more than one million images show that the proposed method achieves promising improvement over the approach with a vocabulary tree, especially when large variations exist in query images. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Feature grouping and local soft match for mobile visual search", "paper_id": "WOS:000300135300002"}