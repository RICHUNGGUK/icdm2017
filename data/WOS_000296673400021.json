{"auto_keywords": [{"score": 0.03492496914358158, "phrase": "proposed_algorithm"}, {"score": 0.015720083645063384, "phrase": "k-means"}, {"score": 0.012746888290896305, "phrase": "connecting_clusters"}, {"score": 0.004660702714929615, "phrase": "support_vector_clustering"}, {"score": 0.00407474190126995, "phrase": "complex_real-world_problems"}, {"score": 0.003976373766630594, "phrase": "large_proportion"}, {"score": 0.003944112858235306, "phrase": "noise_data_points"}, {"score": 0.003802135020791801, "phrase": "support_vector_and_k-means_based_hybrid_algorithm"}, {"score": 0.003710323357333052, "phrase": "svc."}, {"score": 0.003680212979775528, "phrase": "new_svc_training_method"}, {"score": 0.003562186600028245, "phrase": "gaussian_kernel_radius_function"}, {"score": 0.0035189057079817285, "phrase": "empirical_study"}, {"score": 0.003447932289587852, "phrase": "better_selection"}, {"score": 0.0034060348526709634, "phrase": "standard_deviation"}, {"score": 0.0033646448121751574, "phrase": "gaussian_kernel"}, {"score": 0.0032040376301815544, "phrase": "problem_complexity"}, {"score": 0.0031012349116334606, "phrase": "global_svc."}, {"score": 0.003076052206618737, "phrase": "refined_data_set"}, {"score": 0.0030017207229983385, "phrase": "kernel-based_k-means_algorithm"}, {"score": 0.0028467558213723697, "phrase": "removed_data_point"}, {"score": 0.0027218799769229596, "phrase": "local_svcs"}, {"score": 0.0026237858015040415, "phrase": "svc"}, {"score": 0.0025189177411152645, "phrase": "compact_and_arbitrary_organized_data_sets"}, {"score": 0.002350152413458658, "phrase": "mixture_models"}, {"score": 0.0023310544011985253, "phrase": "benchmark_data_sets"}, {"score": 0.0022933216359142736, "phrase": "uci_machine"}, {"score": 0.002283984048569816, "phrase": "learning_repository"}, {"score": 0.0022561982694417116, "phrase": "cluster_error_rate"}, {"score": 0.0021049977753042253, "phrase": "existing_svc_algorithms"}], "paper_keywords": ["data clustering", " kernel methods", " support vector clustering", " K-Means clustering"], "paper_abstract": "Support vector clustering (SVC), a recently developed unsupervised learning algorithm, has been successfully applied to solving many real-life data clustering problems. However, its effectiveness and advantages deteriorate when it is applied to solving complex real-world problems, e.g., those with large proportion of noise data points and with connecting clusters. This paper proposes a support vector and K-Means based hybrid algorithm to improve the performance of SVC. A new SVC training method is developed based on analysis of a Gaussian kernel radius function. An empirical study is conducted to guide better selection of the standard deviation of the Gaussian kernel. In the proposed algorithm, firstly, the outliers which increase problem complexity are identified and removed by training a global SVC. The refined data set is then clustered by a kernel-based K-Means algorithm. Finally, several local SVCs are trained for the clusters and then each removed data point is labeled according to the distance from it to the local SVCs. Since it exploits the advantages of both SVC and K-Means, the proposed algorithm is capable of clustering compact and arbitrary organized data sets and of increasing robustness to outliers and connecting clusters. Experiments are conducted on 2-D data sets generated by mixture models and benchmark data sets taken from the UCI machine learning repository. The cluster error rate is lower than 3.0% for all the selected data sets. The results demonstrate that the proposed algorithm compared favorably with existing SVC algorithms.", "paper_title": "A Support Vector and K-Means Based Hybrid Intelligent Data Clustering Algorithm", "paper_id": "WOS:000296673400021"}