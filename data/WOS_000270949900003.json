{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "distributed_computing_environment"}, {"score": 0.004481132747216135, "phrase": "distributed_input_data"}, {"score": 0.003951453722517865, "phrase": "privacy_concern"}, {"score": 0.00384633057714983, "phrase": "data_holder"}, {"score": 0.0037104876694493815, "phrase": "privacy_preservation_notion"}, {"score": 0.0036443694410100507, "phrase": "original_learning_algorithms"}, {"score": 0.0032132782979796895, "phrase": "important_learning_model"}, {"score": 0.0031559919178954644, "phrase": "multilayer_neural_networks"}, {"score": 0.0030171910207671205, "phrase": "privacy-preserving_two-party"}, {"score": 0.0027825094419000637, "phrase": "neural_network"}, {"score": 0.0024093494406195386, "phrase": "complete_correctness"}, {"score": 0.002366361492754389, "phrase": "security_analysis"}], "paper_keywords": ["Backpropagation", " learning", " neural network", " privacy"], "paper_abstract": "With the development of distributed computing environment, many learning problems now have to deal with distributed input data. To enhance cooperations in learning, it is important to address the privacy concern of each data holder by extending the privacy preservation notion to original learning algorithms. In this paper, we focus on preserving the privacy in an important learning model, multilayer neural networks. We present a privacy-preserving two-party distributed. algorithm of backpropagation which allows a neural network to be trained without requiring either party to reveal her data to the other. We provide complete correctness and security analysis of our algorithms. The effectiveness of our algorithms is verified by experiments on various real world data sets.", "paper_title": "Privacy-Preserving Backpropagation Neural Network Learning", "paper_id": "WOS:000270949900003"}