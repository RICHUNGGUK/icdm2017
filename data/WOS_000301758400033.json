{"auto_keywords": [{"score": 0.049657579458204655, "phrase": "robust_rotation-invariant_texture_classification"}, {"score": 0.026487627931405258, "phrase": "brodatz"}, {"score": 0.026033701006803824, "phrase": "umd"}, {"score": 0.025809375397976713, "phrase": "kth-tips."}, {"score": 0.00481495049065317, "phrase": "random_projections"}, {"score": 0.004330450801016359, "phrase": "proposed_sorted_random_projection"}, {"score": 0.004235793609579307, "phrase": "random_projection"}, {"score": 0.003946519058822334, "phrase": "straightforward_sorting_step"}, {"score": 0.003894512634265439, "phrase": "rotation_invariance"}, {"score": 0.003826231150275071, "phrase": "feature_extraction_stage"}, {"score": 0.003775803846431323, "phrase": "small_set"}, {"score": 0.003742554019950264, "phrase": "random_measurements"}, {"score": 0.003676926952533304, "phrase": "sorted_pixels"}, {"score": 0.003628460216207393, "phrase": "pixel_differences"}, {"score": 0.0035965032173588753, "phrase": "local_image_patches"}, {"score": 0.00354909279546064, "phrase": "rotation_invariant_random_features"}, {"score": 0.0034714553759044664, "phrase": "bag-of-words_model"}, {"score": 0.0033212215487678854, "phrase": "global_rotation_invariance"}, {"score": 0.0032774280543222843, "phrase": "proposed_unconventional_and_novel_random_features"}, {"score": 0.003149471116658739, "phrase": "sparse_nature"}, {"score": 0.003121719509312159, "phrase": "texture_images"}, {"score": 0.003066945490483524, "phrase": "traditional_feature_extraction_methods"}, {"score": 0.0030264946886983833, "phrase": "careful_design"}, {"score": 0.002999823428906084, "phrase": "complex_steps"}, {"score": 0.0029471818883482688, "phrase": "extensive_experiments"}, {"score": 0.002908306074124806, "phrase": "proposed_method"}, {"score": 0.0027214867658544384, "phrase": "lbp"}, {"score": 0.002697474061842142, "phrase": "wmfs"}, {"score": 0.0026384167183586015, "phrase": "lazebnik_et_al"}, {"score": 0.0026036031415940563, "phrase": "zhang_et_al"}, {"score": 0.0025578967205807843, "phrase": "texture_classification"}, {"score": 0.002535344521369057, "phrase": "five_databases"}, {"score": 0.002512991405306227, "phrase": "curet"}, {"score": 0.0024688721092430877, "phrase": "uiuc"}, {"score": 0.002382936364692606, "phrase": "significant_improvements"}, {"score": 0.002361923085067681, "phrase": "classification_accuracy"}, {"score": 0.0023307492812556204, "phrase": "consistently_good_results"}, {"score": 0.0022101055924375725, "phrase": "best_reported_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Texture classification", " Random projection", " Compressed sensing", " Feature extraction", " Image patches", " Rotation invariance", " Bag of words"], "paper_abstract": "This paper presents a simple, novel, yet very powerful approach for robust rotation-invariant texture classification based on random projection. The proposed sorted random projection maintains the strengths of random projection, in being computationally efficient and low-dimensional, with the addition of a straightforward sorting step to introduce rotation invariance. At the feature extraction stage, a small set of random measurements is extracted from sorted pixels or sorted pixel differences in local image patches. The rotation invariant random features are embedded into a bag-of-words model to perform texture classification, allowing us to achieve global rotation invariance. The proposed unconventional and novel random features are very robust, yet by leveraging the sparse nature of texture images, our approach outperforms traditional feature extraction methods which involve careful design and complex steps. We report extensive experiments comparing the proposed method to six state-of-the-art methods, RP, Patch, LBP, WMFS and the methods of Lazebnik et al. and Zhang et al., in texture classification on five databases: CUReT, Brodatz, UIUC, UMD and KTH-TIPS. Our approach leads to significant improvements in classification accuracy, producing consistently good results on each database, including what we believe to be the best reported results for Brodatz, UMD and KTH-TIPS. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Sorted random projections for robust rotation-invariant texture classification", "paper_id": "WOS:000301758400033"}