{"auto_keywords": [{"score": 0.037251025708521186, "phrase": "image_features"}, {"score": 0.00481495049065317, "phrase": "mobile_food_recognition_system"}, {"score": 0.004784795480627637, "phrase": "foodcam"}, {"score": 0.004550225097519697, "phrase": "user's_eating_habits"}, {"score": 0.0044372687709897446, "phrase": "image_recognition_methods"}, {"score": 0.004368093195599546, "phrase": "mobile_devices"}, {"score": 0.004327104321558231, "phrase": "proposed_method"}, {"score": 0.004299991387021304, "phrase": "real-time_food_image_recognition"}, {"score": 0.004127834058321831, "phrase": "existing_systems"}, {"score": 0.004025320909035849, "phrase": "image_recognition_server"}, {"score": 0.003975019199506057, "phrase": "food_items"}, {"score": 0.003756298824153418, "phrase": "food_item_recognition"}, {"score": 0.003721029388906273, "phrase": "indicated_bounding_boxes"}, {"score": 0.003594507685403249, "phrase": "food_item_region"}, {"score": 0.003571968614903263, "phrase": "grubcut"}, {"score": 0.0034073545850838, "phrase": "linear_svm."}, {"score": 0.003229914287184765, "phrase": "standard_bag"}, {"score": 0.0031695126964559235, "phrase": "color_histograms"}, {"score": 0.003129871835064893, "phrase": "kernel_feature_maps"}, {"score": 0.0030616859252873235, "phrase": "hog_patch_descriptor"}, {"score": 0.003032918641059871, "phrase": "color_patch_descriptor"}, {"score": 0.0030044208366869205, "phrase": "state-of-the-art_fisher_vector_representation"}, {"score": 0.0029021941361680637, "phrase": "food_regions"}, {"score": 0.0028749210987951677, "phrase": "higher_svm_output_score"}, {"score": 0.002777088408582301, "phrase": "estimated_direction"}, {"score": 0.002640682934273318, "phrase": "smartphone_camera"}, {"score": 0.0026158609712563737, "phrase": "recognition_process"}, {"score": 0.002510960575700234, "phrase": "standalone_mobile_application"}, {"score": 0.0024951987856762646, "phrase": "android_smartphones"}, {"score": 0.002456224752333807, "phrase": "multiple_cpu_cores"}, {"score": 0.002433132434417479, "phrase": "real-time_recognition"}, {"score": 0.002291827910789624, "phrase": "ground-truth_bounding_boxes"}, {"score": 0.002263149713143185, "phrase": "hog"}, {"score": 0.0022489295919084643, "phrase": "color_patches"}, {"score": 0.0022277818172421584, "phrase": "fisher_vector_coding"}, {"score": 0.0021655216339356693, "phrase": "positive_evaluation"}, {"score": 0.0021451564984201364, "phrase": "user_study"}, {"score": 0.002118299959412318, "phrase": "food_recording_system"}, {"score": 0.0021049977753042253, "phrase": "object_recognition"}], "paper_keywords": ["Food recognition", " Dietary recording", " Smartphone application", " Fisher vector", " Mobile image recognition"], "paper_abstract": "We propose a mobile food recognition system, FoodCam, the purposes of which are estimating calorie and nutrition of foods and recording a user's eating habits. In this paper, we propose image recognition methods which are suitable for mobile devices. The proposed method enables real-time food image recognition on a consumer smartphone. This characteristic is completely different from the existing systems which require to send images to an image recognition server. To recognize food items, a user draws bounding boxes by touching the screen first, and then the system starts food item recognition within the indicated bounding boxes. To recognize them more accurately, we segment each food item region by GrubCut, extract image features and finally classify it into one of the one hundred food categories with a linear SVM. As image features, we adopt two kinds of features: one is the combination of the standard bag-of-features and color histograms with chi(2) kernel feature maps, and the other is a HOG patch descriptor and a color patch descriptor with the state-of-the-art Fisher Vector representation. In addition, the system estimates the direction of food regions where the higher SVM output score is expected to be obtained, and it shows the estimated direction in an arrow on the screen in order to ask a user to move a smartphone camera. This recognition process is performed repeatedly and continuously. We implemented this system as a standalone mobile application for Android smartphones so as to use multiple CPU cores effectively for real-time recognition. In the experiments, we have achieved the 79.2 % classification rate for the top 5 category candidates for a 100-category food dataset with the ground-truth bounding boxes when we used HOG and color patches with the Fisher Vector coding as image features. In addition, we obtained positive evaluation by a user study compared to the food recording system without object recognition.", "paper_title": "FoodCam: A real-time food recognition system on a smartphone", "paper_id": "WOS:000358214900019"}