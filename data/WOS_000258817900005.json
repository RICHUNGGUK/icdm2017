{"auto_keywords": [{"score": 0.04573228268553137, "phrase": "arbitrary_expression"}, {"score": 0.038507729909938025, "phrase": "queried_feature_vector"}, {"score": 0.033457111690421336, "phrase": "model_translation"}, {"score": 0.00481495049065317, "phrase": "facial_expression_transformations"}, {"score": 0.004528156929805637, "phrase": "expression-invariant_face_recognition"}, {"score": 0.00445293569103488, "phrase": "input_face_image"}, {"score": 0.00423465514675998, "phrase": "new_face_image"}, {"score": 0.003960101604693806, "phrase": "feature_vector"}, {"score": 0.00389427992231721, "phrase": "active_appearance_model"}, {"score": 0.003724034990158436, "phrase": "facial_expression_state"}, {"score": 0.003561205990687285, "phrase": "facial_expression"}, {"score": 0.003348838095597268, "phrase": "facial_expression_vector"}, {"score": 0.003293142761521425, "phrase": "identified_expression_state"}, {"score": 0.003256526411907174, "phrase": "direct_or_indirect_facial_expression_transformation"}, {"score": 0.0029282926103224717, "phrase": "relative_expression_parameters"}, {"score": 0.002707741309851526, "phrase": "obtained_relative_expression_parameters"}, {"score": 0.0026330549554033876, "phrase": "face_recognition"}, {"score": 0.0025604233506352375, "phrase": "distance-based_matching_technique"}, {"score": 0.0024897902536499005, "phrase": "transformed_neutral_expression_feature_vector"}, {"score": 0.0023281003994670714, "phrase": "experimental_results"}, {"score": 0.002276566401216226, "phrase": "proposed_expression-invariant_face_recognition_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["active appearance model", " multi-linear model", " facial expression recognition", " facial expression transformation", " relative expression parameters", " expression-invariant face recognition"], "paper_abstract": "In this paper, we present a method of expression-invariant face recognition that transforms input face image with an arbitrary expression into its corresponding neutral facial expression image. When a new face image with an arbitrary expression is queried, it is represented by a feature vector using the active appearance model (AAM). Then, the facial expression state of the queried feature vector is identified by the facial expression recognizer. Next, the queried feature vector is transformed into the facial expression vector using the identified expression state via direct or indirect facial expression transformation, where former uses model translation directly to transform the expression, but the latter uses model translation to obtain relative expression parameters: shape difference and appearance ratio and transforms the expression indirectly by the obtained relative expression parameters. Then, the face recognition is performed by the distance-based matching technique, which matches the transformed neutral expression feature vector with the vectors in the gallery. which have only neutral expression. Experimental results show that the proposed expression-invariant face recognition method is very robust for a variety of expressions. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Expression-invariant face recognition by facial expression transformations", "paper_id": "WOS:000258817900005"}