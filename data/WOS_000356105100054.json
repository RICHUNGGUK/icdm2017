{"auto_keywords": [{"score": 0.04971747610320425, "phrase": "semantic_similarity"}, {"score": 0.00481495049065317, "phrase": "feature_fusion"}, {"score": 0.004724571550328985, "phrase": "present_study"}, {"score": 0.004671156704912419, "phrase": "new_algorithm"}, {"score": 0.004618342952383313, "phrase": "multi-feature_fusion"}, {"score": 0.004396267325338022, "phrase": "feature_distance"}, {"score": 0.004313713204732449, "phrase": "feature-annotation_space"}, {"score": 0.004232702713825967, "phrase": "distance_similarity_space"}, {"score": 0.004153207234462926, "phrase": "intrinsic_statistical_relationship"}, {"score": 0.004121826934975274, "phrase": "visual_and_semantic_information"}, {"score": 0.003953409087444568, "phrase": "multiple_features"}, {"score": 0.003908678575537341, "phrase": "potential_multimodal_properties"}, {"score": 0.0038207243221070166, "phrase": "traditional_feature"}, {"score": 0.003720600007408015, "phrase": "boundary_values"}, {"score": 0.0035685175471526823, "phrase": "scaling_method"}, {"score": 0.0034881908940439213, "phrase": "statistical_information"}, {"score": 0.003435643372146385, "phrase": "distance_space"}, {"score": 0.0033967510986397946, "phrase": "distance_vector"}, {"score": 0.0033582976109650608, "phrase": "image_pair"}, {"score": 0.0032578629307203097, "phrase": "anisotropic_gaussian_distribution"}, {"score": 0.003186876858421092, "phrase": "gaussian"}, {"score": 0.0030542703032534766, "phrase": "nearest-distance_images"}, {"score": 0.0028851913035322415, "phrase": "high_semantic_correlation"}, {"score": 0.0028525124381208705, "phrase": "visual_and_semantic_relationship"}, {"score": 0.0028095140358025, "phrase": "canonical_correlation_analysis"}, {"score": 0.0027776899345132193, "phrase": "canonical_correlation_coefficient"}, {"score": 0.0026438880533289893, "phrase": "annotation_score"}, {"score": 0.002555040841339798, "phrase": "proposed_multi-feature_fusion_method"}, {"score": 0.002459810433812049, "phrase": "feature_distances"}, {"score": 0.0023952639120005193, "phrase": "total_distance"}, {"score": 0.002350196395175188, "phrase": "nearest_neighbors"}, {"score": 0.0022369407711124775, "phrase": "esp_game"}, {"score": 0.0022115879730677, "phrase": "voc_pascal_datasets"}, {"score": 0.002153540857619362, "phrase": "existing_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Feature fusion", " Linear transform", " Nearest neighbor", " Semantic similarity", " Canonical correlation analysis"], "paper_abstract": "The present study developed a new algorithm based on multi-feature fusion and semantic similarity for image annotation. To study the relationship between feature distance and semantic similarity, the feature-annotation space is transformed into a distance similarity space. Therefore, the intrinsic statistical relationship between visual and semantic information can be studied. Re-scaling is necessary to fuse multiple features. The potential multimodal properties of image features mean that traditional feature re-scaling is based on boundary values, which are sensitive to outliers. Our proposed distance re-scaling method overcomes the drawbacks of using statistical information. In the distance space, each distance vector of an image pair is treated as a sample. The anisotropic Gaussian distribution is transformed into an isotropic Gaussian with a mean of zero and standard variance. The nearest-distance images are retrieved from this space. To select features of not only low distance correlations but also a high semantic correlation, the visual and semantic relationship is studied using canonical correlation analysis. The canonical correlation coefficient of the similarity and distance is found to connect closely with the annotation score of the feature. Experiments showed that the proposed multi-feature fusion method removed the effects of scale and the correlations of feature distances, so it could represent the total distance better and find the nearest neighbors. We tested our method using the Corel5K, IAPR-TC12, ESP Game, and VOC PASCAL datasets, which showed that it outperformed existing approaches. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Image annotation based on feature fusion and semantic similarity", "paper_id": "WOS:000356105100054"}