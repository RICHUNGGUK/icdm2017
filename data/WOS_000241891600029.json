{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "evolutionary_process"}, {"score": 0.03644451033122438, "phrase": "evolved_nn_ensemble"}, {"score": 0.0258678242431025, "phrase": "evolved_nn_ensembles"}, {"score": 0.00471228691115201, "phrase": "neural_network_ensembles"}, {"score": 0.0042004472903194616, "phrase": "neural_network"}, {"score": 0.003798231095121328, "phrase": "maxial_generation"}, {"score": 0.00333697550984782, "phrase": "whole_population"}, {"score": 0.0030171910207671205, "phrase": "nn_ensembles"}, {"score": 0.00278752137116301, "phrase": "different_performance"}, {"score": 0.0025568135952982345, "phrase": "alternative_solution"}, {"score": 0.002396371892825691, "phrase": "experimental_analyses"}, {"score": 0.0023451553255837317, "phrase": "n-fold_cross-validation"}], "paper_keywords": [""], "paper_abstract": "In practice, two criteria have often been used to stop the evolutionary process in evolving neural network (NN) ensembles. One criterion is to stop the evolution when the maxial generation is reached. The other criterion is to stop the evolution when the evolved NN ensemble, i.e., the whole population, is satisfactory according to a certain evaluation. This paper points out that NN ensembles evolved from these two criteria might not be robust by having different performance. In order to make the evolved NN ensemble more stable, an alternative solution is to combine a number of evolved NN ensembles. Experimental analyses based on n-fold cross-validation have been given to explain why the evolved NN ensembles could be very different and how such difference could disappear or be reduced in the combination.", "paper_title": "How to stop the evolutionary process in evolving neural network ensembles", "paper_id": "WOS:000241891600029"}