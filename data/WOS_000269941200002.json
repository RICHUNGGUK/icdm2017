{"auto_keywords": [{"score": 0.049442871815077706, "phrase": "low-level_usage_data"}, {"score": 0.00481495049065317, "phrase": "extensible_workspace"}, {"score": 0.0045946617913925755, "phrase": "user_interaction"}, {"score": 0.004503350877279651, "phrase": "demanding_task"}, {"score": 0.00447331713604276, "phrase": "existing_techniques"}, {"score": 0.004443482801729777, "phrase": "data_collection"}, {"score": 0.0041837333868790134, "phrase": "data_cleaning"}, {"score": 0.0037461743696712833, "phrase": "initial_data_analysis"}, {"score": 0.003671663469605366, "phrase": "specific_research_question"}, {"score": 0.0034684722988160637, "phrase": "collected_data"}, {"score": 0.0033206861608068025, "phrase": "solution_times"}, {"score": 0.0032546105164772995, "phrase": "process_conformances"}, {"score": 0.003043679504527297, "phrase": "keystroke_latencies"}, {"score": 0.0029931118601224612, "phrase": "workspace_creation"}, {"score": 0.00265292826903791, "phrase": "different_experiments"}, {"score": 0.002591403838835242, "phrase": "new_research_questions"}, {"score": 0.0023434465472518943, "phrase": "data_collection_instruments"}, {"score": 0.0022585847551229274, "phrase": "rapid_iterations"}, {"score": 0.0022061853706148945, "phrase": "data_preparation"}, {"score": 0.0021549990311897347, "phrase": "general_and_specific_data"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["empirical studies", " low-level usage data", " data analysis tool"], "paper_abstract": "Analysis of low-level usage data collected in empirical studies of user interaction is well known as a demanding task. Existing techniques for data collection and analysis are either application specific or data-driven. This paper presents a workspace for data cleaning, transformation and analysis of low-level usage data that we have developed and reports our experience with it. By its five-level architecture, the workspace makes a distinction between more general data that typically can be used in initial data analysis and the data answering a specific research question. The workspace was used in four studies and in total 6.5M user actions were collected from 238 participants. The collected data have been proven to be useful for: (i) validating solution times, (ii) validating process conformances, (iii) exploratory studies on program comprehension for understanding use of classes and documents and (iv) testing hypotheses on keystroke latencies. We have found workspace creation to be demanding in time. Particularly demanding were determining the context of actions and dealing with deficiencies. However, once these processes were understood, it was easy to reuse the workspace for different experiments and to extend it to answer new research questions. Based on our experience, we give a set of guidelines that might help in setting up studies, collecting and preparing data. We recommend that designers of data collection instruments add context to each action. Furthermore, we recommend rapid iterations starting early in the process of data preparation and analysis, and covering both general and specific data. Copyright (C) 2009 John Wiley & Sons, Ltd.", "paper_title": "Experience with an extensible workspace for analysis of low-level usage data", "paper_id": "WOS:000269941200002"}