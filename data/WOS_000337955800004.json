{"auto_keywords": [{"score": 0.03480869408409596, "phrase": "transform_kernels"}, {"score": 0.03170734640000662, "phrase": "proposed_method"}, {"score": 0.004753670676591174, "phrase": "adaptive_transforms"}, {"score": 0.0046943424425537296, "phrase": "transform"}, {"score": 0.0044873778175404475, "phrase": "spatial_redundancy"}, {"score": 0.004430248457624686, "phrase": "prediction_residuals"}, {"score": 0.004345909305473054, "phrase": "modern_video_coding_standards"}, {"score": 0.004181997052907647, "phrase": "residual_blocks"}, {"score": 0.0041287394089001405, "phrase": "diverse_characteristics"}, {"score": 0.004050116768809519, "phrase": "video_sequence"}, {"score": 0.003998531873723384, "phrase": "conventional_transform_methods"}, {"score": 0.003947601392882997, "phrase": "fixed_transform_kernels"}, {"score": 0.0038476708316022823, "phrase": "low_efficiency"}, {"score": 0.003608732492631878, "phrase": "novel_content_adaptive_transform_framework"}, {"score": 0.0034063576796640603, "phrase": "pixel_rearrangement"}, {"score": 0.003194736764837261, "phrase": "video_content"}, {"score": 0.003054450075234415, "phrase": "traditional_adaptive_transforms"}, {"score": 0.0028830690329478465, "phrase": "reconstructed_block"}, {"score": 0.0027212777001495176, "phrase": "transform_unit"}, {"score": 0.002635339648135844, "phrase": "spiral-scanning_method"}, {"score": 0.002535779689260244, "phrase": "transform_coefficients"}, {"score": 0.0025034338848015166, "phrase": "better_entropy"}, {"score": 0.0024556852466581527, "phrase": "experimental_results"}, {"score": 0.0024088451312725924, "phrase": "key_technical_area"}, {"score": 0.0022302306304023602, "phrase": "average_bitrate_reduction"}, {"score": 0.0021049977753042253, "phrase": "low-delay_configurations"}], "paper_keywords": ["Video coding", " transform coding", " 2D separable Karhunen-Loeve transform", " H.264/AVC"], "paper_abstract": "Transform has been widely used to remove spatial redundancy of prediction residuals in the modern video coding standards. However, since the residual blocks exhibit diverse characteristics in a video sequence, conventional transform methods with fixed transform kernels may result in low efficiency. To tackle this problem, we propose a novel content adaptive transform framework for the H.264/AVC-based video coding. The proposed method utilizes pixel rearrangement to dynamically adjust the transform kernels to adapt to the video content. In addition, unlike the traditional adaptive transforms, the proposed method obtains the transform kernels from the reconstructed block, and hence it consumes only one logic indicator for each transform unit. Moreover, a spiral-scanning method is developed to reorder the transform coefficients for better entropy coding. Experimental results on the Key Technical Area (KTA) platform show that the proposed method can achieve an average bitrate reduction of about 7.95% and 7.0% under all-intra and low-delay configurations, respectively.", "paper_title": "Efficient H.264/AVC Video Coding with Adaptive Transforms", "paper_id": "WOS:000337955800004"}