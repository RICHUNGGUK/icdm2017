{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "visual_sensor_networks"}, {"score": 0.044875504899816884, "phrase": "faulty_sensors"}, {"score": 0.04188956702114718, "phrase": "sensor_faults"}, {"score": 0.04074917841641471, "phrase": "distributed_solution"}, {"score": 0.004460703838987562, "phrase": "sensor_node"}, {"score": 0.004355415885815204, "phrase": "inaccurate_information"}, {"score": 0.00409310463335204, "phrase": "collaborative_target_localization_algorithm"}, {"score": 0.0038465304237380125, "phrase": "fault-tolerant_target_localization"}, {"score": 0.003773680962197766, "phrase": "so-called_certainty_map"}, {"score": 0.003702206069379459, "phrase": "potential_sensor_faults"}, {"score": 0.0036494864560524735, "phrase": "voting_mechanism"}, {"score": 0.0035632774896594524, "phrase": "threshold_value"}, {"score": 0.003300813776412652, "phrase": "analytical_study"}, {"score": 0.0032074366230426727, "phrase": "lower_and_upper_bounds"}, {"score": 0.0030140547908298404, "phrase": "localization_performance"}, {"score": 0.002942811795757911, "phrase": "small_value"}, {"score": 0.002699960312990493, "phrase": "camera_orientation"}, {"score": 0.00263612191603326, "phrase": "generative_image_model"}, {"score": 0.002549269480908849, "phrase": "detected_target_location"}, {"score": 0.002512926336312949, "phrase": "camera's_orientation"}, {"score": 0.0024534993283766332, "phrase": "camera_orientations"}, {"score": 0.0022725931637071852, "phrase": "real_experiments"}, {"score": 0.00220823903315848, "phrase": "proposed_method"}, {"score": 0.002166349705365602, "phrase": "localization_accuracy"}, {"score": 0.0021252533072727707, "phrase": "fault_detection"}, {"score": 0.0021049977753042253, "phrase": "correction_performance"}], "paper_keywords": ["Algorithms", " Performance", " Theory", " Scene analysis", " sensor fusion", " target localization", " fault tolerance", " visual sensor networks"], "paper_abstract": "Collaboration in visual sensor networks is essential not only to compensate for the limitations of each sensor node but also to tolerate inaccurate information generated by faulty sensors. This article focuses on the design of a collaborative target localization algorithm that is resilient to sensor faults. We first develop a distributed solution to fault-tolerant target localization based on a so-called certainty map. To tolerate potential sensor faults, a voting mechanism is adopted and a threshold value needs to be specified which is the key to the realization of the distributed solution. Analytical study is conducted to derive the lower and upper bounds for the threshold such that the probability of faulty sensors negatively impacts the localization performance is less than a small value. Second, we focus on the detection and correction of one type of sensor faults, error in camera orientation. We construct a generative image model in each camera based on the detected target location to estimate camera's orientation, detect inaccuracies in camera orientations and correct them before they cascade. Based on results obtained from both simulation and real experiments, we show that the proposed method is effective in localization accuracy as well as fault detection and correction performance.", "paper_title": "Collaborative Localization in Visual Sensor Networks", "paper_id": "WOS:000330625100001"}