{"auto_keywords": [{"score": 0.049766045322984266, "phrase": "lasso"}, {"score": 0.015718750429243724, "phrase": "adaptive_sparse_group"}, {"score": 0.014827218842487144, "phrase": "variable_selection"}, {"score": 0.0042508289538799905, "phrase": "natural_grouping_structures"}, {"score": 0.0032908057622663732, "phrase": "adaptive_lasso"}, {"score": 0.003247868216333148, "phrase": "adaptive_group"}, {"score": 0.0031019373572233706, "phrase": "bi-level_selection"}, {"score": 0.002943147037670826, "phrase": "improved_version"}, {"score": 0.00290473242917264, "phrase": "sparse_group"}, {"score": 0.002848048872614425, "phrase": "sgl"}, {"score": 0.0027741761880779535, "phrase": "data-dependent_weights"}, {"score": 0.0027200305495826797, "phrase": "selection_performance"}, {"score": 0.0026148807877309417, "phrase": "block_coordinate_descent_algorithm"}, {"score": 0.002464709648714996, "phrase": "satisfactory_performance"}, {"score": 0.0024007585788965655, "phrase": "individual_variables"}, {"score": 0.0023384629381463054, "phrase": "lower_false_discovery_rate"}, {"score": 0.0023079225317714815, "phrase": "mean_square_error"}, {"score": 0.0021896891011033105, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "household_healthcare_expenditure_data"}], "paper_keywords": ["adaptive sparse group Lasso", " bi-level", " penalized variable selection"], "paper_abstract": "Penalization has been extensively adopted for variable selection in regression. In some applications, covariates have natural grouping structures, where those in the same group have correlated measurements or related functions. Under such settings, variable selection should be conducted at both the group-level and within-group-level, that is, a bi-level selection. In this study, we propose the adaptive sparse group Lasso (adSGL) method, which combines the adaptive Lasso and adaptive group Lasso (GL) to achieve bi-level selection. It can be viewed as an improved version of sparse group Lasso (SGL) and uses data-dependent weights to improve selection performance. For computation, a block coordinate descent algorithm is adopted. Simulation shows that adSGL has satisfactory performance in identifying both individual variables and groups and lower false discovery rate and mean square error than SGL and GL. We apply the proposed method to the analysis of a household healthcare expenditure data set.", "paper_title": "Bi-level variable selection via adaptive sparse group Lasso", "paper_id": "WOS:000355538300016"}