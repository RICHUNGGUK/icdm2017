{"auto_keywords": [{"score": 0.04095863380675144, "phrase": "high_performance"}, {"score": 0.00481495049065317, "phrase": "shared_vector_coprocessors"}, {"score": 0.004727995968069753, "phrase": "wide_range"}, {"score": 0.004614483128885678, "phrase": "vector_coprocessor"}, {"score": 0.004449280529563265, "phrase": "sustained_data_parallelism"}, {"score": 0.004355645393953418, "phrase": "insufficient_vector_parallelism"}, {"score": 0.004289966839994858, "phrase": "dynamic_environments"}, {"score": 0.004123781267600542, "phrase": "high-performance_scientific"}, {"score": 0.004086350434865782, "phrase": "embedded_applications"}, {"score": 0.003988180913997414, "phrase": "efficient_use"}, {"score": 0.003964007795174772, "phrase": "on-chip_resources"}, {"score": 0.0037529131348732715, "phrase": "vector_sizes"}, {"score": 0.003651603914126771, "phrase": "diverse_computation_needs"}, {"score": 0.003574695610710444, "phrase": "versatile_design_framework"}, {"score": 0.003531474887552889, "phrase": "vector_coprocessor_sharing"}, {"score": 0.0035100601949451028, "phrase": "multiple_cores"}, {"score": 0.0034465894339710864, "phrase": "resource_utilization"}, {"score": 0.003384262486955773, "phrase": "reduced_area"}, {"score": 0.0030890818430877663, "phrase": "systemverilog"}, {"score": 0.0030239842475439814, "phrase": "substantially_improved_versions"}, {"score": 0.0029512611306191194, "phrase": "synthesized_rtl"}, {"score": 0.002933354468864442, "phrase": "higher_accuracy"}, {"score": 0.0028802818629647614, "phrase": "vector_coprocessor_sharing_policies"}, {"score": 0.0028541057064952876, "phrase": "dual-core_system"}, {"score": 0.002828166765606611, "phrase": "floating-point_performance"}, {"score": 0.0027854565462509095, "phrase": "power_consumption_metrics"}, {"score": 0.002751751956416832, "phrase": "fir_filtering"}, {"score": 0.0027351436647840726, "phrase": "fft"}, {"score": 0.0026937446571204653, "phrase": "lu_decomposition"}, {"score": 0.002677396270783542, "phrase": "sparse_matrix_vector_multiplication"}, {"score": 0.002644995764097807, "phrase": "coprocessor_sharing_policies"}, {"score": 0.002628942455803398, "phrase": "high_utilization"}, {"score": 0.002597126785932806, "phrase": "low_energy"}, {"score": 0.002511600086227215, "phrase": "best_performance"}, {"score": 0.0024437176947749014, "phrase": "vector_lane"}, {"score": 0.0023133947578541977, "phrase": "vector_resources"}, {"score": 0.002163491500079535, "phrase": "vector_length"}, {"score": 0.0021438155673297377, "phrase": "parallelism-oriented_coding_technique"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Vector coprocessor", " Coprocessor sharing", " Multicore", " FPGA prototyping"], "paper_abstract": "For a wide range of applications that make use of a vector coprocessor, its resources are not highly utilized due to the lack of sustained data parallelism, which often occurs due to insufficient vector parallelism or vector-length variations in dynamic environments. The motivation of our work stems from (a) the omnipresence of vector operations in high-performance scientific and emerging embedded applications; (b) the mandate for multicore designs to make efficient use of on-chip resources for low power and high performance; (c) the need to often handle a variety of vector sizes: and (d) vector kernels in application suites may have diverse computation needs. Our objective is to provide a versatile design framework that can facilitate vector coprocessor sharing among multiple cores in a manner that maximizes resource utilization while also yielding very high performance at reduced area and energy costs. We have previously proposed three basic shared vector coprocessor architectures based on coarse-grain temporal, fine-grain temporal, and vector lane sharing that were implemented in SystemVerilog [15]. Our new paper presents substantially improved versions of these architectures that are implemented in synthesized RTL for higher accuracy. We herein evaluate these vector coprocessor sharing policies for a dual-core system using the floating-point performance, resource utilization and power consumption metrics. Benchmarking for FIR filtering. FFT, matrix multiplication. LU decomposition and sparse matrix vector multiplication shows that these coprocessor sharing policies yield high utilization, high performance and low energy per operation. Fine-grain temporal sharing most often provides the best performance among the three policies; it is followed by vector lane and then coarse-grain temporal sharing. It is also shown that, per core exclusive access to the vector resources does not maximize their utilization. This benchmarking involves various scenarios for each application, where the scenarios differ in terms of the vector length and the parallelism-oriented coding technique. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Versatile design of shared vector coprocessors for multicores", "paper_id": "WOS:000309441900003"}