{"auto_keywords": [{"score": 0.04780597585803098, "phrase": "formal_experiments"}, {"score": 0.00481495049065317, "phrase": "replicated_controlled_experiments"}, {"score": 0.0046477357199085035, "phrase": "unit_testing"}, {"score": 0.004546174820239776, "phrase": "software_engineering"}, {"score": 0.003628460216207393, "phrase": "replication_practices"}, {"score": 0.003456132182564149, "phrase": "code_inspections"}, {"score": 0.00342568771304873, "phrase": "structural_unit_testing"}, {"score": 0.0033805214040814233, "phrase": "first_two_experiments"}, {"score": 0.003149471116658739, "phrase": "different_researchers"}, {"score": 0.003053402354907241, "phrase": "defect_detection_methods"}, {"score": 0.0029733865110222785, "phrase": "experimental_procedures"}, {"score": 0.00278237555651743, "phrase": "significant_differences"}, {"score": 0.0027456676902333304, "phrase": "original_experiment"}, {"score": 0.002351485871160907, "phrase": "context_factors"}, {"score": 0.0023307492812556204, "phrase": "software_engineering_experimentation"}, {"score": 0.002200337772403981, "phrase": "software_engineering_experiments"}, {"score": 0.0021049977753042253, "phrase": "reliable_and_repeatable_empirical_measures"}], "paper_keywords": ["Formal experiments", " Replication", " Reproduction", " Experiment design", " Code inspection", " Unit testing"], "paper_abstract": "In formal experiments on software engineering, the number of factors that may impact an outcome is very high. Some factors are controlled and change by design, while others are are either unforeseen or due to chance. This paper aims to explore how context factors change in a series of formal experiments and to identify implications for experimentation and replication practices to enable learning from experimentation. We analyze three experiments on code inspections and structural unit testing. The first two experiments use the same experimental design and instrumentation (replication), while the third, conducted by different researchers, replaces the programs and adapts defect detection methods accordingly (reproduction). Experimental procedures and location also differ between the experiments. Contrary to expectations, there are significant differences between the original experiment and the replication, as well as compared to the reproduction. Some of the differences are due to factors other than the ones designed to vary between experiments, indicating the sensitivity to context factors in software engineering experimentation. In aggregate, the analysis indicates that reducing the complexity of software engineering experiments should be considered by researchers who want to obtain reliable and repeatable empirical measures.", "paper_title": "Variation factors in the design and analysis of replicated controlled experiments Three (dis)similar studies on inspections versus unit testing", "paper_id": "WOS:000343910700007"}