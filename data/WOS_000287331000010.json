{"auto_keywords": [{"score": 0.03163537021432405, "phrase": "squarem"}, {"score": 0.00481495049065317, "phrase": "high-dimensional_optimization_algorithms"}, {"score": 0.004586531354697466, "phrase": "maximum_likelihood_estimation"}, {"score": 0.004454691230204595, "phrase": "em_or_mm_algorithm"}, {"score": 0.004326624385772596, "phrase": "excruciatingly_slow_convergence"}, {"score": 0.0038876302202924644, "phrase": "modern_high-dimensional_problems"}, {"score": 0.0032629585038738856, "phrase": "complicated_models"}, {"score": 0.003200045185608395, "phrase": "large_numbers"}, {"score": 0.003048001809453513, "phrase": "squared_iterative_methods"}, {"score": 0.002847184192715049, "phrase": "varadhan"}, {"score": 0.002792249613272514, "phrase": "roland"}, {"score": 0.0025829353063908256, "phrase": "new_quasi-newton_acceleration_scheme"}, {"score": 0.002320449502337321, "phrase": "overall_storage"}], "paper_keywords": ["Maximum likelihood", " Multivariate t", " Admixture models", " Imaging", " Generalized eigenvalues"], "paper_abstract": "In many statistical problems, maximum likelihood estimation by an EM or MM algorithm suffers from excruciatingly slow convergence. This tendency limits the application of these algorithms to modern high-dimensional problems in data mining, genomics, and imaging. Unfortunately, most existing acceleration techniques are ill-suited to complicated models involving large numbers of parameters. The squared iterative methods (SQUAREM) recently proposed by Varadhan and Roland constitute one notable exception. This paper presents a new quasi-Newton acceleration scheme that requires only modest increments in computation per iteration and overall storage and rivals or surpasses the performance of SQUAREM on several representative test problems.", "paper_title": "A quasi-Newton acceleration for high-dimensional optimization algorithms", "paper_id": "WOS:000287331000010"}