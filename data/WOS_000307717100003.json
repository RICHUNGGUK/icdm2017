{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "great_deal"}, {"score": 0.004779564521350969, "phrase": "research_work"}, {"score": 0.0045726187330434025, "phrase": "intrinsic_dimensionality"}, {"score": 0.004390764654147291, "phrase": "minimum_number"}, {"score": 0.00424734451992536, "phrase": "information_loss"}, {"score": 0.0040334640350288, "phrase": "generalization_capability"}, {"score": 0.004003798249233137, "phrase": "discriminant_methods"}, {"score": 0.00388729255686046, "phrase": "necessary_information"}, {"score": 0.003844478919573134, "phrase": "dimensionality_reduction_technique"}, {"score": 0.003802135020791801, "phrase": "neural_network_design"}, {"score": 0.0037463983616303786, "phrase": "hidden_units"}, {"score": 0.003705130724701598, "phrase": "encoding_middle_layer"}, {"score": 0.0035445401296650535, "phrase": "id_value"}, {"score": 0.003466865016432561, "phrase": "model_order"}, {"score": 0.003428665921276366, "phrase": "time_series"}, {"score": 0.0033411580268394732, "phrase": "reliable_time_series_predictions"}, {"score": 0.0031494088980556934, "phrase": "noisy_data"}, {"score": 0.0031032109441552287, "phrase": "underestimated_values"}, {"score": 0.0028293966058473476, "phrase": "theoretical_motivation"}, {"score": 0.0027571412070078703, "phrase": "underestimation_effect"}, {"score": 0.00266693888510356, "phrase": "statistical_properties"}, {"score": 0.0026472970609754095, "phrase": "manifold_neighborhoods"}, {"score": 0.0024860616730750158, "phrase": "proposed_techniques"}, {"score": 0.0024677487011556427, "phrase": "synthetic_and_real_datasets"}, {"score": 0.002422552850701705, "phrase": "objective_evaluation_measure"}, {"score": 0.0023260075698364087, "phrase": "art_algorithms"}, {"score": 0.0022665781920241245, "phrase": "proposed_methods"}, {"score": 0.0022168460543913787, "phrase": "reliable_estimates"}, {"score": 0.0021842976754894846, "phrase": "difficult_case"}, {"score": 0.002136367030584338, "phrase": "-linearly_embedded_manifolds"}, {"score": 0.0021049977753042253, "phrase": "high_id"}], "paper_keywords": ["Intrinsic dimensionality estimation", " Dimensionality reduction", " Manifold learning"], "paper_abstract": "Recently, a great deal of research work has been devoted to the development of algorithms to estimate the intrinsic dimensionality (id) of a given dataset, that is the minimum number of parameters needed to represent the data without information loss. id estimation is important for the following reasons: the capacity and the generalization capability of discriminant methods depend on it; id is a necessary information for any dimensionality reduction technique; in neural network design the number of hidden units in the encoding middle layer should be chosen according to the id of data; the id value is strongly related to the model order in a time series, that is crucial to obtain reliable time series predictions. Although many estimation techniques have been proposed in the literature, most of them fail on noisy data, or compute underestimated values when the id is sufficiently high. In this paper, after reviewing some of the most important id estimators related to our work, we provide a theoretical motivation of the bias that causes the underestimation effect, and we present two id estimators based on the statistical properties of manifold neighborhoods, which have been developed in order to reduce this effect. We exhaustively evaluate the proposed techniques on synthetic and real datasets, by employing an objective evaluation measure to compare their performance with those achieved by state of the art algorithms; the results show that the proposed methods are promising, and produce reliable estimates also in the difficult case of datasets drawn from non-linearly embedded manifolds, characterized by high id.", "paper_title": "Novel high intrinsic dimensionality estimators", "paper_id": "WOS:000307717100003"}