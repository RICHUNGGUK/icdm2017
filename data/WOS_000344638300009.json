{"auto_keywords": [{"score": 0.05005188413713693, "phrase": "particle_gibbs"}, {"score": 0.0495975492531742, "phrase": "ancestor_sampling"}, {"score": 0.04568097618078196, "phrase": "monte_carlo"}, {"score": 0.04467028405874575, "phrase": "markov"}, {"score": 0.040168709007025995, "phrase": "pgas"}, {"score": 0.028240524758873894, "phrase": "pgbs"}, {"score": 0.004723847090183984, "phrase": "particle_markov_chain_monte_carlo"}, {"score": 0.00459039896577789, "phrase": "systematic_way"}, {"score": 0.004439445472040688, "phrase": "monte_carlo_statistical_inference"}, {"score": 0.0043353149911490125, "phrase": "smc"}, {"score": 0.004073590964805314, "phrase": "new_pmcmc_algorithm"}, {"score": 0.003773680962197766, "phrase": "data_analyst"}, {"score": 0.0037199473428123175, "phrase": "off-the-shelf_class"}, {"score": 0.0032850648549389025, "phrase": "state-space_model"}, {"score": 0.0032382660477699695, "phrase": "ancestor_sampling_procedure"}, {"score": 0.003146652729098066, "phrase": "pgas_kernel"}, {"score": 0.003087017178815267, "phrase": "seemingly_few_particles"}, {"score": 0.003043031131345537, "phrase": "underlying_smc_sampler"}, {"score": 0.002887028262617443, "phrase": "computational_burden"}, {"score": 0.002791932344920906, "phrase": "smc._pgas"}, {"score": 0.0027129118211250336, "phrase": "existing_pg"}, {"score": 0.002687070469080394, "phrase": "backward_simulation"}, {"score": 0.0025737890313763407, "phrase": "separate_forward_and_backward_sweeps"}, {"score": 0.0024185182010749273, "phrase": "single_forward_sweep"}, {"score": 0.002316532084420729, "phrase": "inference_problems"}, {"score": 0.0022725931637071852, "phrase": "state-space_models"}, {"score": 0.0021354538918029286, "phrase": "bayesian_nonparametric"}, {"score": 0.0021049977753042253, "phrase": "general_probabilistic_graphical_models"}], "paper_keywords": ["particle Markov chain Monte Carlo", " sequential Monte Carlo", " Bayesian inference", " non-Markovian models", " state-space models"], "paper_abstract": "Particle Markov chain Monte Carlo (PMCMC) is a systematic way of combining the two main tools used for Monte Carlo statistical inference: sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC). We present a new PMCMC algorithm that we refer to as particle Gibbs with ancestor sampling (PGAS). PGAS provides the data analyst with an off-the-shelf class of Markov kernels that can be used to simulate, for instance, the typically high-dimensional and highly autocorrelated state trajectory in a state-space model. The ancestor sampling procedure enables fast mixing of the PGAS kernel even when using seemingly few particles in the underlying SMC sampler. This is important as it can significantly reduce the computational burden that is typically associated with using SMC. PGAS is conceptually similar to the existing PG with backward simulation (PGBS) procedure. Instead of using separate forward and backward sweeps as in PGBS, however, we achieve the same effect in a single forward sweep. This makes PGAS well suited for addressing inference problems not only in state-space models, but also in models with more complex dependencies, such as non-Markovian, Bayesian nonparametric, and general probabilistic graphical models.", "paper_title": "Particle Gibbs with Ancestor Sampling", "paper_id": "WOS:000344638300009"}