{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "unsupervised_learning"}, {"score": 0.0047563776685277314, "phrase": "local_learning"}, {"score": 0.004556901872357751, "phrase": "feature_selection"}, {"score": 0.004392565073466714, "phrase": "new_algorithm"}, {"score": 0.00428629884026304, "phrase": "informative_features"}, {"score": 0.004234129588974058, "phrase": "complex_structures"}, {"score": 0.0041316803676012155, "phrase": "high-dimensional_space"}, {"score": 0.0038862297330905836, "phrase": "human_learning"}, {"score": 0.0038154673253945003, "phrase": "complex_data_structures"}, {"score": 0.0036553070575015344, "phrase": "optimization_problem"}, {"score": 0.0035887342563437935, "phrase": "well-defined_objective_function"}, {"score": 0.0033961782274326948, "phrase": "iterative_approach"}, {"score": 0.0030789331635764122, "phrase": "gap_statistics"}, {"score": 0.002931569771634119, "phrase": "proposed_method"}, {"score": 0.002690406375639144, "phrase": "permutation_tests"}, {"score": 0.0026252106881752067, "phrase": "statistical_significance"}, {"score": 0.002530359917257626, "phrase": "data_structure"}, {"score": 0.0023079225317714815, "phrase": "seven_existing_methods"}, {"score": 0.0022382002476510573, "phrase": "synthetic_datasets"}, {"score": 0.002197379785587054, "phrase": "wide_variety"}, {"score": 0.0021441057555396013, "phrase": "cancer_microarray_gene_expression_datasets"}], "paper_keywords": ["Feature selection", " Unsupervised learning", " Clustering", " Manifold learning"], "paper_abstract": "We consider the problem of feature selection for unsupervised learning and develop a new algorithm capable of identifying informative features supporting complex structures embedded in a high-dimensional space. The development of the algorithm is inspired by human learning in detecting complex data structures. We formulate it as an optimization problem with a well-defined objective function, and solve the problem by using an iterative approach. The algorithm can be easily implemented and is computationally very efficient. We use gap statistics to estimate the parameters so that the proposed method is completely parameter-free. We also develop a scheme based on permutation tests to estimate the statistical significance of the presence of a data structure. We demonstrate the effectiveness and versatility of the algorithm by comparing it with seven existing methods on a set of synthetic datasets with a wide variety of structures and cancer microarray gene expression datasets. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Feature selection for unsupervised learning through local learning", "paper_id": "WOS:000349555500014"}