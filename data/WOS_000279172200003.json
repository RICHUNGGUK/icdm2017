{"auto_keywords": [{"score": 0.03260718419288335, "phrase": "unknown_error_rate"}, {"score": 0.00481495049065317, "phrase": "bayesian_credibility_intervals"}, {"score": 0.0047787596516662, "phrase": "classifier_error_rates"}, {"score": 0.00474283953918251, "phrase": "maximum_entropy_empirical_priors"}, {"score": 0.004448169552315403, "phrase": "patient_examples"}, {"score": 0.004414723336530117, "phrase": "robust_methods"}, {"score": 0.004381527499253281, "phrase": "performance_estimation"}, {"score": 0.004251210982670317, "phrase": "upper_bound"}, {"score": 0.004203343568960231, "phrase": "error_rate"}, {"score": 0.004156012879026324, "phrase": "single_classifier"}, {"score": 0.004062937864702115, "phrase": "bayesian_credibility_interval"}, {"score": 0.003956971099850658, "phrase": "conventional_holdout_test"}, {"score": 0.0038683363637006902, "phrase": "tightest_bounds"}, {"score": 0.0038247634489737142, "phrase": "conventional_bayesian_ci"}, {"score": 0.0037532257703888315, "phrase": "real_world_applications"}, {"score": 0.0037109446302945903, "phrase": "test_set_sizes"}, {"score": 0.0034806008137997337, "phrase": "cl"}, {"score": 0.003363830908814182, "phrase": "test_examples"}, {"score": 0.0031905286720361145, "phrase": "uniform_prior_density_distribution"}, {"score": 0.003142668996712078, "phrase": "complete_lack"}, {"score": 0.0031190082119319272, "phrase": "prior_knowledge"}, {"score": 0.002913895605074143, "phrase": "maximum_entropy"}, {"score": 0.002870173628745123, "phrase": "based_approach"}, {"score": 0.0028485585670146025, "phrase": "improved_prior_knowledge"}, {"score": 0.0028271058251633815, "phrase": "bayesian_cis"}, {"score": 0.0027741761880779535, "phrase": "biomedical_research"}, {"score": 0.0027532820796396713, "phrase": "clinical_practice"}, {"score": 0.0026411384812121503, "phrase": "refined_non-uniform_prior_density_distribution"}, {"score": 0.002543148295176345, "phrase": "empirical_results"}, {"score": 0.002476721068743341, "phrase": "non-overlapping_sets"}, {"score": 0.002202742267484358, "phrase": "bayesian_cl"}, {"score": 0.002153316680437517, "phrase": "designed_classifier"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Classifier design", " Performance evaluation", " Small sample learning", " Decision support system", " Diagnosis", " Prognosis"], "paper_abstract": "Objective: Successful use of classifiers that learn to make decisions from a set of patient examples require robust methods for performance estimation. Recently many promising approaches for determination of an upper bound for the error rate of a single classifier have been reported but the Bayesian credibility interval (Cl) obtained from a conventional holdout test still delivers one of the tightest bounds. The conventional Bayesian CI becomes unacceptably large in real world applications where the test set sizes are less than a few hundred. The source of this problem is that fact that the Cl is determined exclusively by the result on the test examples. In other words, there is no information at all provided by the uniform prior density distribution employed which reflects complete lack of prior knowledge about the unknown error rate. Therefore, the aim of the study reported here was to study a maximum entropy (ME) based approach to improved prior knowledge and Bayesian CIs, demonstrating its relevance for biomedical research and clinical practice. Method and material: It is demonstrated how a refined non-uniform prior density distribution can be obtained by means of the ME principle using empirical results from a few designs and tests using non-overlapping sets of examples. Results: Experimental results show that ME based priors improve the CIs when employed to four quite different simulated and two real world data sets. Conclusions: An empirically derived ME prior seems promising for improving the Bayesian Cl for the unknown error rate of a designed classifier. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Improving Bayesian credibility intervals for classifier error rates using maximum entropy empirical priors", "paper_id": "WOS:000279172200003"}