{"auto_keywords": [{"score": 0.046273829908275756, "phrase": "audio_signals"}, {"score": 0.023877351602378805, "phrase": "multiple_sensors"}, {"score": 0.00481495049065317, "phrase": "multichannel_online_blind_speech_dereverberation"}, {"score": 0.004716520738331953, "phrase": "static_observation_parameters"}, {"score": 0.004644014990871423, "phrase": "rao-blackwellized_particle_filter"}, {"score": 0.0043875257506180865, "phrase": "spectral_coloration"}, {"score": 0.004253618550301311, "phrase": "acoustic_signals"}, {"score": 0.004145143433523008, "phrase": "high-quality_audio_and_scene_analysis_applications"}, {"score": 0.003956784357357341, "phrase": "statistical_evidence"}, {"score": 0.003916098498242888, "phrase": "multiple_observations"}, {"score": 0.0037381083634085424, "phrase": "traditional_beamforming_techniques"}, {"score": 0.0036616109902631293, "phrase": "reverberant_reflections"}, {"score": 0.0036052633308076933, "phrase": "beam_path"}, {"score": 0.003405948098114941, "phrase": "room_impulse_response"}, {"score": 0.0032176163279340206, "phrase": "inverse_filtering"}, {"score": 0.003168079471049896, "phrase": "channel_estimate"}, {"score": 0.0031032109441552287, "phrase": "clean_speech_estimate"}, {"score": 0.0030083825666563898, "phrase": "non-minimum_phase_acoustic_impulse_responses"}, {"score": 0.0029164434911787187, "phrase": "multi-sensor_approach"}, {"score": 0.0026986685585382347, "phrase": "distorted_observations"}, {"score": 0.0026297428083782875, "phrase": "remaining_model_parameters"}, {"score": 0.00257586859792573, "phrase": "hypothesis_distributions"}, {"score": 0.0025361866386341796, "phrase": "particle_filter"}, {"score": 0.0024842242921857705, "phrase": "real-time_dereverberation"}, {"score": 0.0023711591828229736, "phrase": "single-sensor_blind_dereverberation"}, {"score": 0.002286781334850213, "phrase": "single-channel_approach"}, {"score": 0.0022168460543913787, "phrase": "performance_improvements"}, {"score": 0.0021049977753042253, "phrase": "synthetic_and_baseband_speech_examples"}], "paper_keywords": ["Blind dereverberation", " Multi-sensor processing", " Speech enhancement", " Kalman filter", " Particle filter", " Rao-Blackwellization", " Bayesian estimation"], "paper_abstract": "Room reverberation leads to reduced intelligibility of audio signals and spectral coloration of audio signals. Enhancement of acoustic signals is thus crucial for high-quality audio and scene analysis applications. Multiple sensors can be used to exploit statistical evidence from multiple observations of the same event to improve enhancement. Whilst traditional beamforming techniques suffer from interfering reverberant reflections with the beam path, other approaches to dereverberation often require at least partial knowledge of the room impulse response which is not available in practice, or rely on inverse filtering of a channel estimate to obtain a clean speech estimate, resulting in difficulties with non-minimum phase acoustic impulse responses. This paper proposes a multi-sensor approach to blind dereverberation in which both the source signal and acoustic channel are directly estimated from the distorted observations using their optimal estimators. The remaining model parameters are sampled from hypothesis distributions using a particle filter, thus facilitating real-time dereverberation. This approach was previously successfully applied to single-sensor blind dereverberation. In this paper, the single-channel approach is extended to multiple sensors. Performance improvements due to the use of multiple sensors are demonstrated on synthetic and baseband speech examples.", "paper_title": "Multichannel Online Blind Speech Dereverberation with Marginalization of Static Observation Parameters in a Rao-Blackwellized Particle Filter", "paper_id": "WOS:000289802900005"}