{"auto_keywords": [{"score": 0.045102893345792996, "phrase": "learner's_memory"}, {"score": 0.028057555137227238, "phrase": "bern_sense"}, {"score": 0.00481495049065317, "phrase": "temporary_memory"}, {"score": 0.004737579882204798, "phrase": "inductive_inference_framework"}, {"score": 0.00453113241842654, "phrase": "bounded_example_memory"}, {"score": 0.00436890075128947, "phrase": "new_model"}, {"score": 0.003700037700138249, "phrase": "example_x"}, {"score": 0.0030455297429878873, "phrase": "tent-learning_model"}, {"score": 0.0027854565462509095, "phrase": "tent_sense"}, {"score": 0.002674681176379472, "phrase": "k_examples"}, {"score": 0.0022738201751000865, "phrase": "tern_sense"}, {"score": 0.0022011501095573747, "phrase": "special_case"}, {"score": 0.0021569129153653777, "phrase": "infinite_languages"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Inductive inference", " Formal languages", " Incremental learning"], "paper_abstract": "In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bern) language learning model is considered. Intuitively, the new model constrains the learner's memory not only in how much data may be stored, but also in how long those data may be stored without being refreshed. More specifically, the model requires that, if the learner commits an example x to memory, and x is not presented to the learner again thereafter, then eventually the learner forgets x, i.e., eventually x no longer appears in the learner's memory. This model is called temporary example memory (Tem) learning. Many interesting results concerning the Tent-learning model are presented. For example, there exists a class of languages that can be identified by memorizing k + 1 examples in the Tent sense, but that cannot be identified by memorizing k examples in the Bern sense. On the other hand, there exists a class of languages that can be identified by memorizing just one example in the Bern sense, but that cannot be identified by memorizing any number of examples in the Tern sense. Results are also presented concerning the special case of learning classes of infinite languages. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Incremental learning with temporary memory", "paper_id": "WOS:000278954800010"}