{"auto_keywords": [{"score": 0.03346859346952941, "phrase": "u"}, {"score": 0.00481495049065317, "phrase": "free_random_matrices"}, {"score": 0.0047152877145889656, "phrase": "bernoulli-gaussian_complex_n-vector"}, {"score": 0.003988487841970088, "phrase": "random_q-sparse_vector"}, {"score": 0.0038854765143440965, "phrase": "square_random_matrix_u"}, {"score": 0.0037066895459425824, "phrase": "average_size"}, {"score": 0.0034088473318056537, "phrase": "resulting_vector_components"}, {"score": 0.003320756562046789, "phrase": "additive_gaussian_noise"}, {"score": 0.0032012284065895537, "phrase": "conventional_noisy_compressive_sampling_models"}, {"score": 0.003069867656852932, "phrase": "iid_components"}, {"score": 0.002873081814102129, "phrase": "guo"}, {"score": 0.0028527866590859967, "phrase": "haar_matrices"}, {"score": 0.002750056254309311, "phrase": "replica_method"}, {"score": 0.0027071661844502992, "phrase": "decoupling_principle"}, {"score": 0.0026810529383901284, "phrase": "verdu"}, {"score": 0.002542174767860791, "phrase": "information-theoretic_bounds"}, {"score": 0.002476424729269258, "phrase": "input-output_mutual_information"}, {"score": 0.0024377918036784336, "phrase": "support_recovery_error_rate"}, {"score": 0.0022653055209664284, "phrase": "large_deviation_approach"}, {"score": 0.002241679436497569, "phrase": "rangan_et_al"}, {"score": 0.0021049977753042253, "phrase": "thresholded_linear"}], "paper_keywords": ["Compressed sensing", " free probability", " random matrices", " rate-distortion theory", " sparse models", " support recovery"], "paper_abstract": "Consider a Bernoulli-Gaussian complex n-vector whose components are V-i = XiBi, with X-i similar to CN(0, P-x) and binary B-i mutually independent and iid across i. This random q-sparse vector is multiplied by a square random matrix U, and a randomly chosen subset, of average size np, p is an element of [0, 1], of the resulting vector components is then observed in additive Gaussian noise. We extend the scope of conventional noisy compressive sampling models where U is typically a matrix with iid components, to allow U satisfying a certain freeness condition. This class of matrices encompasses Haar matrices and other unitarily invariant matrices. We use the replica method and the decoupling principle of Guo and Verdu, as well as a number of information-theoretic bounds, to study the input-output mutual information and the support recovery error rate in the limit of n -> infinity. We also extend the scope of the large deviation approach of Rangan et al. and characterize the performance of a class of estimators encompassing thresholded linear MMSE and l(1) relaxation.", "paper_title": "Support Recovery With Sparsely Sampled Free Random Matrices", "paper_id": "WOS:000321925900011"}