{"auto_keywords": [{"score": 0.03179235022538005, "phrase": "greedy_policy"}, {"score": 0.011489344751756525, "phrase": "new_algorithm"}, {"score": 0.00481495049065317, "phrase": "adaptive_dynamic_programming"}, {"score": 0.004456044928556639, "phrase": "adaptive_dynamic_programming_technique"}, {"score": 0.004398872331144531, "phrase": "dual_heuristic_programming"}, {"score": 0.00409723267214392, "phrase": "critic_function"}, {"score": 0.003967021436047945, "phrase": "model_functions"}, {"score": 0.0038409332473902367, "phrase": "dhp"}, {"score": 0.0037188360359702182, "phrase": "control_problems"}, {"score": 0.0036710872046569532, "phrase": "large_and_continuous_state_spaces"}, {"score": 0.0034191818674096453, "phrase": "value-gradient_learning"}, {"score": 0.0033752674784204412, "phrase": "vgl"}, {"score": 0.00306334226516593, "phrase": "backpropagation_through_time_for_control"}, {"score": 0.0023958326775913165, "phrase": "general_smooth_nonlinear_function_approximator"}], "paper_keywords": ["Adaptive dynamic programming (ADP)", " backpropagation through time", " dual heuristic programming (DHP)", " neural networks", " value-gradient learning"], "paper_abstract": "We consider the adaptive dynamic programming technique called Dual Heuristic Programming (DHP), which is designed to learn a critic function, when using learned model functions of the environment. DHP is designed for optimizing control problems in large and continuous state spaces. We extend DHP into a new algorithm that we call Value-Gradient Learning, VGL (lambda), and prove equivalence of an instance of the new algorithm to Backpropagation Through Time for Control with a greedy policy. Not only does this equivalence provide a link between these two different approaches, but it also enables our variant of DHP to have guaranteed convergence, under certain smoothness conditions and a greedy policy, when using a general smooth nonlinear function approximator for the critic. We consider several experimental scenarios including some that prove divergence of DHP under a greedy policy, which contrasts against our proven-convergent algorithm.", "paper_title": "An Equivalence Between Adaptive Dynamic Programming With a Critic and Backpropagation Through Time", "paper_id": "WOS:000326940600015"}