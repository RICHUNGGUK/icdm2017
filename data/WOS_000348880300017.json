{"auto_keywords": [{"score": 0.039898883497906455, "phrase": "trl-ipa"}, {"score": 0.00481495049065317, "phrase": "representation_learning_based_image_patch_analysis"}, {"score": 0.0044870272550540415, "phrase": "novel_framework"}, {"score": 0.004442032546224076, "phrase": "text_identification"}, {"score": 0.003995876175614403, "phrase": "previous_text_identification_approaches"}, {"score": 0.0038379074449947067, "phrase": "binarized_images"}, {"score": 0.0036861605703168397, "phrase": "gray_level"}, {"score": 0.0036491673002304326, "phrase": "color_images"}, {"score": 0.003522579870903474, "phrase": "general_formulation"}, {"score": 0.003469676666252421, "phrase": "convergent_tensor_representation"}, {"score": 0.0032989853590079153, "phrase": "image_patches"}, {"score": 0.0031366648074858555, "phrase": "low_dimensional_representations"}, {"score": 0.003012560489169148, "phrase": "ctrl_algorithm"}, {"score": 0.002952356518921907, "phrase": "text_regions"}, {"score": 0.002922705896608178, "phrase": "new_coming_document_images"}, {"score": 0.002878785759716458, "phrase": "random_forest_classifier"}, {"score": 0.0028070431733705735, "phrase": "learned_tensor_subspace"}, {"score": 0.0027370835853738626, "phrase": "trl-ipa_framework"}, {"score": 0.0026554236621262515, "phrase": "recognition_problems"}, {"score": 0.0026023381988430666, "phrase": "handwritten_digits_recognition"}, {"score": 0.0025503112711036994, "phrase": "extensive_experiments"}, {"score": 0.0024493494346360415, "phrase": "text_identification_tasks"}, {"score": 0.0024247382451294255, "phrase": "experimental_results"}, {"score": 0.0023170054862555896, "phrase": "recognition_results"}, {"score": 0.0022706700510423954, "phrase": "handwritten_digits"}, {"score": 0.0022252591643049744, "phrase": "state-of-the-art_vector"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Tensor representation learning", " Convergence", " Ancient document understanding", " Text identification", " Text recognition"], "paper_abstract": "In this paper, we introduce a novel framework for text identification and recognition, called tensor representation learning based image patch analysis (TRL-IPA). Unlike most of previous text identification approaches, which can only be applied to binarized images, TRL-IPA can be directly applied to gray level and color images. TRL-IPA is built on a general formulation of the convergent tensor representation learning (CTRL) algorithms. In the implementation of TRL-IPA, image patches are represented in the form of tensors, while low dimensional representations of these tensors are learned via a CTRL algorithm. To identify text regions in new coming document images, a random forest classifier is trained in the learned tensor subspace. Moreover, the TRL-IPA framework can be straightforwardly applied to recognition problems, such as handwritten digits recognition. We conducted extensive experiments on ancient Chinese, Arabic and Cyrillic document images, to evaluate TRL-IPA on text identification tasks. Experimental results demonstrate its effectiveness and robustness. In addition, recognition results on images of handwritten digits show its advantage over state-of-the-art vector and tensor representation based approaches. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Tensor representation learning based image patch analysis for text identification and recognition", "paper_id": "WOS:000348880300017"}