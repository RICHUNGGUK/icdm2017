{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "robustness_issue"}, {"score": 0.004704187604192605, "phrase": "kernel_principal_component_analysis"}, {"score": 0.004438250823243621, "phrase": "new_robust_procedures"}, {"score": 0.004187284711626886, "phrase": "eigen-value_decomposition"}, {"score": 0.003904713104101532, "phrase": "proposed_procedures"}, {"score": 0.0036838048761094933, "phrase": "deviant_patterns"}, {"score": 0.0033952989364738353, "phrase": "data_contamination"}, {"score": 0.0033170847930578473, "phrase": "model_deviation"}, {"score": 0.0032406665327678616, "phrase": "theoretical_influence_functions"}, {"score": 0.0030572112793962004, "phrase": "numerical_examples"}, {"score": 0.002720785798036066, "phrase": "proposed_robust_method"}, {"score": 0.0026272523687965615, "phrase": "conventional_approach"}, {"score": 0.0021049977753042253, "phrase": "functional_principal_component_analysis"}], "paper_keywords": [""], "paper_abstract": "This letter discusses the robustness issue of kernel principal component analysis. A class of new robust procedures is proposed based on eigen-value decomposition of weighted covariance. The proposed procedures will place less weight on deviant patterns and thus be more resistant to data contamination and model deviation. Theoretical influence functions are derived, and numerical examples are presented as well. Both theoretical and numerical results indicate that the proposed robust method outperforms the conventional approach in the sense of being less sensitive to outliers. Our robust method and results also apply to functional principal component analysis.", "paper_title": "Robust Kernel Principal Component Analysis", "paper_id": "WOS:000271438800007"}