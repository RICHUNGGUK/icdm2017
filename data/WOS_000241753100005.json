{"auto_keywords": [{"score": 0.0349694581102903, "phrase": "euclidean"}, {"score": 0.00481495049065317, "phrase": "based_classification"}, {"score": 0.004730158389701481, "phrase": "information_theoretic_learning"}, {"score": 0.0039248128268720645, "phrase": "prototype_densities"}, {"score": 0.0038556354709511818, "phrase": "supervised_learning"}, {"score": 0.0034963129868796033, "phrase": "unsupervised_method"}, {"score": 0.0030868583963299698, "phrase": "original_algorithm"}, {"score": 0.002824005136794786, "phrase": "supervised_learning_method"}, {"score": 0.0027252240573281163, "phrase": "fuzzy_classification_algorithm"}, {"score": 0.00258347644721642, "phrase": "fuzzy_labels"}, {"score": 0.0022404162042797262, "phrase": "metric_adaptation"}, {"score": 0.0021620042653528846, "phrase": "vector_quantization"}, {"score": 0.0021049977753042253, "phrase": "new_approach"}], "paper_keywords": [""], "paper_abstract": "In this article we extend the (recently published) unsupervised information theoretic vector quantization approach based on the Cauchy-Schwarz-divergence for matching data and prototype densities to supervised learning and classification. In particular, first we generalize the unsupervised method to more general metrics instead of the Euclidean, as it was used in the original algorithm. Thereafter, we extend the model to a supervised learning method resulting in a fuzzy classification algorithm. Thereby, we allow fuzzy labels for both, data and prototypes. Finally, we transfer the idea of relevance learning for metric adaptation known from learning vector quantization to the new approach.", "paper_title": "Prototype based classification using information theoretic learning", "paper_id": "WOS:000241753100005"}