{"auto_keywords": [{"score": 0.0451714191801864, "phrase": "deepest_layer"}, {"score": 0.03691201522580903, "phrase": "semantic_hashing"}, {"score": 0.03248516173723115, "phrase": "query_document"}, {"score": 0.023828329639868986, "phrase": "tf-idf"}, {"score": 0.00481495049065317, "phrase": "deep_graphical_model"}, {"score": 0.0047292449487169345, "phrase": "word-count_vectors"}, {"score": 0.004617328272121826, "phrase": "large_set"}, {"score": 0.004401342842183475, "phrase": "latent_variables"}, {"score": 0.003999089046152065, "phrase": "latent_semantic_analysis"}, {"score": 0.0037664981403399064, "phrase": "small_number"}, {"score": 0.0037216229812089686, "phrase": "binary_variables"}, {"score": 0.0035687137873965684, "phrase": "graphical_model"}, {"score": 0.003361069456060196, "phrase": "memory_addresses"}, {"score": 0.0032618078775887077, "phrase": "similar_documents"}, {"score": 0.0031845067058084613, "phrase": "nearby_addresses"}, {"score": 0.0024604876113911173, "phrase": "locality_sensitive_hashing"}, {"score": 0.0023877589586497948, "phrase": "fastest_current_method"}, {"score": 0.0021821915946356168, "phrase": "higher_accuracy"}, {"score": 0.0021049977753042253, "phrase": "entire_document"}], "paper_keywords": ["Information retrieval", " Graphical models", " Unsupervised learning"], "paper_abstract": "We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs \"semantic hashing\": Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is Much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set. (C) 2008 Elsevier Inc. All rights reserved.", "paper_title": "Semantic hashing", "paper_id": "WOS:000268148700005"}