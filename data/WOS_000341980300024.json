{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "distributed_computing"}, {"score": 0.00415333528095237, "phrase": "common_relay_node"}, {"score": 0.00398916666053909, "phrase": "z._the_receiver"}, {"score": 0.0036553070575015344, "phrase": "possibly_related_observations"}, {"score": 0.0034638476252104706, "phrase": "average_number"}, {"score": 0.0028498718992429825, "phrase": "multiple_instances"}, {"score": 0.002700485592691974, "phrase": "entropy_region"}, {"score": 0.002646501671714952, "phrase": "probabilistic_graph"}, {"score": 0.002558909812664716, "phrase": "cartesian_representation"}, {"score": 0.0024084679931209514, "phrase": "natural_extension"}, {"score": 0.0023762535034673017, "phrase": "graph_entropy"}, {"score": 0.002344468886431959, "phrase": "general_properties"}, {"score": 0.0022668507535947976, "phrase": "graph_entropy_region"}, {"score": 0.0021479597698614355, "phrase": "special_cases"}, {"score": 0.0021049977753042253, "phrase": "distributed_computing_setup"}], "paper_keywords": ["Distributed source coding", " zero-error information theory", " graph entropy"], "paper_abstract": "Two remote senders observe X and Y, respectively, and can noiselessly send information via a common relay node to a receiver that observes Z. The receiver wants to compute a function f(X, Y, Z) of these possibly related observations, without error. We study the average number of bits that need to be conveyed to that end by each sender to the relay and by the relay to the receiver, in the limit of multiple instances. We relate these quantities to the entropy region of a probabilistic graph with respect to a Cartesian representation of its vertex set, which we define as a natural extension of graph entropy. General properties and bounds for the graph entropy region are derived, and mapped back to special cases of the distributed computing setup.", "paper_title": "Distributed Computing and the Graph Entropy Region", "paper_id": "WOS:000341980300024"}