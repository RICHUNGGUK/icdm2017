{"auto_keywords": [{"score": 0.03490036478529983, "phrase": "client_programs"}, {"score": 0.015719716506582538, "phrase": "data_refinement"}, {"score": 0.007877550934338241, "phrase": "instrumented_semantics"}, {"score": 0.0046161999598320486, "phrase": "common_approach"}, {"score": 0.004406994912939125, "phrase": "concrete_program"}, {"score": 0.004278807087784626, "phrase": "intended_abstract_pattern"}, {"score": 0.0035240305920962766, "phrase": "\"lifting_theorem"}, {"score": 0.0033926758710459866, "phrase": "abstract_and_concrete_modules"}, {"score": 0.003091767402370757, "phrase": "abstract_module"}, {"score": 0.002242758902593467, "phrase": "special_simulation_relations"}, {"score": 0.0022238834225283594, "phrase": "namely_growing_relations"}, {"score": 0.0021773853011112882, "phrase": "simulation_method"}, {"score": 0.0021049977753042253, "phrase": "lifting_theorem"}], "paper_keywords": ["Data refinement", " Separation logic", " Pointer aliasing", " Interference"], "paper_abstract": "Data refinement is a common approach to reasoning about programs, based on establishing that a concrete program indeed satisfies all the required properties imposed by an intended abstract pattern. Reasoning about programs in this setting becomes complex when use of pointers is assumed and, moreover, a well-known method for proving data refinement, namely the forward simulation method, becomes unsound in presence of pointers. The reason for unsoundness is the failure of the \"lifting theorem\" for simulations: that a simulation between abstract and concrete modules can be lifted to all client programs. The result is that simulation does not imply that a concrete can replace an abstract module in all contexts. Our diagnosis of this problem is that unsoundness is due to interference from the client programs. Rather than blame a module for the unsoundness of lifting simulations, our analysis places the blame on the client programs which cause the interference: when interference is not present, soundness is recovered. Technically, we present a novel instrumented semantics which is capable of detecting interference between a module and its client. With use of special simulation relations, namely growing relations, and interpreting the simulation method using the instrumented semantics, we obtain a lifting theorem. We then show situations under which simulation does indeed imply refinement.", "paper_title": "Blaming the client: on data refinement in the presence of pointers", "paper_id": "WOS:000282102100004"}