{"auto_keywords": [{"score": 0.04955461236891121, "phrase": "automatic_object_segmentation"}, {"score": 0.030876412953083392, "phrase": "rgb_information"}, {"score": 0.00481495049065317, "phrase": "rgb-d_cameras"}, {"score": 0.004684157900507474, "phrase": "fundamentally_difficult_problem"}, {"score": 0.004408729661992651, "phrase": "semantic_gaps"}, {"score": 0.00428892403807229, "phrase": "critical_role"}, {"score": 0.004241914481080374, "phrase": "object_segmentation"}, {"score": 0.003716273882758735, "phrase": "internal_texture_discontinuities"}, {"score": 0.003555902292752528, "phrase": "depth_and_rgb_frames"}, {"score": 0.0033465923623290034, "phrase": "depth_discontinuities"}, {"score": 0.003309877074892399, "phrase": "useful_information"}, {"score": 0.00325555555110395, "phrase": "object_boundaries"}, {"score": 0.0030808211830129304, "phrase": "depth_frames"}, {"score": 0.002713604305939145, "phrase": "different_response_time_of_the_rgb_and_depth_sensors"}, {"score": 0.0025963890234079333, "phrase": "combined_depth"}, {"score": 0.0024569466759289055, "phrase": "accurate_silhouette"}, {"score": 0.002363806685815014, "phrase": "large_dataset"}, {"score": 0.002224510044064184, "phrase": "qualitative_and_quantitative_evidences"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Boundary detection", " Object segmentation", " Trilateral filter", " Graph Cuts"], "paper_abstract": "Automatic object segmentation is a fundamentally difficult problem due to issues such as shadow, lighting, and semantic gaps. Edges play a critical role in object segmentation; however, it is almost impossible for the computer to know which edges correspond to object boundaries and which are caused by internal texture discontinuities. Active 3-D cameras, which provide streams of depth and RGB frames, are poised to become inexpensive and widespread. The depth discontinuities provide useful information for identifying object boundaries, which makes automatic object segmentation possible. However, the depth frames are extremely noisy. Also, the depth and RGB information often lose synchronization when the object is moving fast, due to different response time of the RGB and depth sensors. We show how to use the combined depth and RGB information to mitigate these problems and produce an accurate silhouette of the object. On a large dataset (24 objects with 1500 images), we provide both qualitative and quantitative evidences that our proposed techniques are effective. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Automatic objects segmentation with RGB-D cameras", "paper_id": "WOS:000333072500011"}