{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "gaussian_bayesian_networks"}, {"score": 0.004737579882204798, "phrase": "mutual_information"}, {"score": 0.004476399615305783, "phrase": "sensitivity_analysis"}, {"score": 0.004404445045826858, "phrase": "evidence_variables"}, {"score": 0.004161553532799662, "phrase": "posterior_probability_distribution"}, {"score": 0.004061584718427419, "phrase": "target_variable"}, {"score": 0.003964007795174772, "phrase": "bayesian_network"}, {"score": 0.003289534854212415, "phrase": "additional_information"}, {"score": 0.002707444334463544, "phrase": "shannon_entropy"}, {"score": 0.0026638482306228575, "phrase": "information_theory_measures"}, {"score": 0.0023776656246300063, "phrase": "better_result"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Entropy", " Evidence propagation", " Gaussian Bayesian network", " Mutual information", " Sensitivity analysis"], "paper_abstract": "We introduce a methodology for sensitivity analysis of evidence variables in Gaussian Bayesian networks. Knowledge of the posterior probability distribution of the target variable in a Bayesian network, given a set of evidence, is desirable. However, this evidence is not always determined; in fact, additional information might be requested to improve the solution in terms of reducing uncertainty. In this study we develop a procedure, based on Shannon entropy and information theory measures, that allows us to prioritize information according to its utility in yielding a better result. Some examples illustrate the concepts and methods introduced. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Sensitivity to evidence in Gaussian Bayesian networks using mutual information", "paper_id": "WOS:000337199200009"}