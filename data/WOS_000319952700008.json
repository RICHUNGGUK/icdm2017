{"auto_keywords": [{"score": 0.045314884531415765, "phrase": "adaboost"}, {"score": 0.00481495049065317, "phrase": "geometric_conversion_approach"}, {"score": 0.0047468516620285525, "phrase": "svms_base_learners"}, {"score": 0.004548253531664032, "phrase": "ensemble_learning"}, {"score": 0.004441517985511521, "phrase": "different_types"}, {"score": 0.003815064377019477, "phrase": "classification_problems"}, {"score": 0.003371508176308189, "phrase": "new_approach"}, {"score": 0.0031845067058084613, "phrase": "regression_sample"}, {"score": 0.0031393948330209224, "phrase": "binary_classification_sample"}, {"score": 0.0030949200330108156, "phrase": "geometric_point"}, {"score": 0.0029793675408245047, "phrase": "support_vector_machines"}, {"score": 0.002909342017421165, "phrase": "converted_classification_sample"}, {"score": 0.002854505078275351, "phrase": "separating_hypersurface_ensemble"}, {"score": 0.0027479040199262393, "phrase": "regression_function"}, {"score": 0.002708960273193547, "phrase": "original_regression_sample"}, {"score": 0.0025586128304269616, "phrase": "first_method"}, {"score": 0.002522344964242888, "phrase": "explicit_geometric_conversion"}, {"score": 0.002486589906779091, "phrase": "second_method"}, {"score": 0.0024513404432665153, "phrase": "implicit_geometric_conversion"}, {"score": 0.002359759876402679, "phrase": "binary_classification_samples"}, {"score": 0.002326304140277375, "phrase": "convergence_property"}, {"score": 0.0022933216359142736, "phrase": "standard_adaboost"}, {"score": 0.0022287497627555895, "phrase": "experimental_results"}, {"score": 0.0021659920594094407, "phrase": "proposed_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Boosting", " Ensemble learning", " Regression", " Support vector machines", " Support vector regression"], "paper_abstract": "Boosting is one of the most important developments in ensemble learning during the past decade. Among different types of boosting methods, AdaBoost is the earliest and the most prevailing one that receives lots of attention for its effectiveness and practicality. Hitherto the research on boosting is dominated by classification problems. Conversely, the extension of boosting to regression is not as successful as that on classification. In this paper, we propose a new approach to extending boosting to regression. This approach first converts a regression sample to a binary classification sample from a geometric point of view, and performs AdaBoost with support vector machines base learner on the converted classification sample. Then the separating hypersurface ensemble obtained from AdaBoost is equivalent to a regression function for the original regression sample. Based on this approach, two new boosting regression methods are presented. The first method adopts the explicit geometric conversion while the second method adopts the implicit geometric conversion. Since both these methods essentially run on the binary classification samples, the convergence property of the standard AdaBoost still holds for them. Experimental results validate the effectiveness of the proposed methods. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Boosting regression methods based on a geometric conversion approach: Using SVMs base learners", "paper_id": "WOS:000319952700008"}