{"auto_keywords": [{"score": 0.031263055009915615, "phrase": "second_family"}, {"score": 0.014110364056376676, "phrase": "prediction_intervals"}, {"score": 0.011720930116639619, "phrase": "first_family"}, {"score": 0.004816862262935012, "phrase": "input"}, {"score": 0.004691465925553365, "phrase": "supervised_regression"}, {"score": 0.004384960761826366, "phrase": "non-parametric_approaches"}, {"score": 0.004272456401437226, "phrase": "arbitrary_regression_models"}, {"score": 0.004206338218873218, "phrase": "supervised_learning_framework"}, {"score": 0.003771185758226876, "phrase": "general_case"}, {"score": 0.003380897678672156, "phrase": "total_prediction_error"}, {"score": 0.0032769720645483102, "phrase": "model's_error"}, {"score": 0.002674885993329912, "phrase": "target_regression_variable"}, {"score": 0.002633425544817301, "phrase": "sample's_nearest_neighbors"}, {"score": 0.0025657442830956017, "phrase": "large_set"}, {"score": 0.00253916011199984, "phrase": "artificial_and_real-world_datasets"}], "paper_keywords": ["Prediction intervals", " regression", " model validation", " data and knowledge visualization", " methodologies and tools"], "paper_abstract": "In this article we compare and put to test two families of non-parametric approaches to constructing prediction intervals for arbitrary regression models in the supervised learning framework. It is often assumed for the errors to be independent and identically distributed, but we focus on the general case when the errors may be input dependent. The first family of approaches is based on the idea of explaining the total prediction error as a sum of the model's error and the error caused by noise inherent to the data, so the two are estimated independently. The second family is based on the assumption of similarity of the data and these approaches estimate the prediction intervals of the target regression variable by using sample's nearest neighbors. Results on a large set of artificial and real-world datasets show that one method from the second family is superior to other methods. Approaches from the first family always form valid, yet not necessarily confirmatory prediction intervals, whereas approaches from the second family prove to be more time efficient.", "paper_title": "Input dependent prediction intervals for supervised regression", "paper_id": "WOS:000342556300007"}