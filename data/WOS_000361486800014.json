{"auto_keywords": [{"score": 0.04804050199975018, "phrase": "gaussian"}, {"score": 0.0063364378657203525, "phrase": "snr"}, {"score": 0.004543708337879809, "phrase": "fixed_independent_identically_distributed_inputs"}, {"score": 0.0043036848666438985, "phrase": "shamai"}, {"score": 0.004231983711356547, "phrase": "laroia"}, {"score": 0.0040656296649390486, "phrase": "input-output_mutual_information"}, {"score": 0.0039685202936462815, "phrase": "minimum_mean-square_error_decision-feedback_equalizer_receiver"}, {"score": 0.0036201167891046046, "phrase": "conjectured_bound"}, {"score": 0.0035336109352157763, "phrase": "general_conditions"}, {"score": 0.0031159081999910694, "phrase": "shamai-laroia_expression"}, {"score": 0.002883718207958817, "phrase": "natural_relaxation"}, {"score": 0.0028421434495262796, "phrase": "original_conjectured"}, {"score": 0.002760778494680823, "phrase": "relaxed_bound"}, {"score": 0.002655894070657161, "phrase": "finite_entropy_input"}, {"score": 0.002630299922281955, "phrase": "isi_channel"}, {"score": 0.002387507583705495, "phrase": "compound_channel_capacity"}, {"score": 0.0023644936731468252, "phrase": "quasiconvexity_arguments"}, {"score": 0.002319127685733821, "phrase": "new_simple_bounds"}, {"score": 0.002285674008055581, "phrase": "achievable_rate"}, {"score": 0.0021881743793875767, "phrase": "information-estimation_relations"}, {"score": 0.0021670777282518424, "phrase": "estimation-theoretic_bounds"}, {"score": 0.002135812692862058, "phrase": "key_role"}], "paper_keywords": ["Intersymbol interference", " Shamai-Laroia approximation", " MMSE", " mutual information", " decision-feedback equalization"], "paper_abstract": "We consider the discrete-time intersymbol interference (ISI) channel model, with additive Gaussian noise and fixed independent identically distributed inputs. In this setting, we investigate the expression put forth by Shamai and Laroia as a conjectured lower bound for the input-output mutual information after application of a minimum mean-square error decision-feedback equalizer receiver. A low-signal to noise ratio (SNR) expansion is used to prove that the conjectured bound does not hold under general conditions, and to characterize inputs for which it is particularly ill-suited. One such input is used to construct a counterexample, indicating that the Shamai-Laroia expression does not always bound even the achievable rate of the channel, thus excluding a natural relaxation of the original conjectured bound. However, this relaxed bound is then shown to hold for any finite entropy input and ISI channel, when the SNR is sufficiently high. We derive two conditions under which the relaxed bound holds, involving compound channel capacity and quasiconvexity arguments. Finally, new simple bounds for the achievable rate are proven, and compared with other known bounds. Information-estimation relations and estimation-theoretic bounds play a key role in establishing our results.", "paper_title": "Lower Bounds and Approximations for the Information Rate of the ISI Channel", "paper_id": "WOS:000361486800014"}