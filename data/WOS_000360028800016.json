{"auto_keywords": [{"score": 0.03751951230806167, "phrase": "adp"}, {"score": 0.00481495049065317, "phrase": "markov_jump_systems"}, {"score": 0.004466519142879166, "phrase": "optimal_online_control_method"}, {"score": 0.004392565073466714, "phrase": "discrete-time_nonlinear_markov_jump_systems"}, {"score": 0.00417793854311445, "phrase": "markov_chain"}, {"score": 0.004074574278425223, "phrase": "weighted_sum_technique"}, {"score": 0.003875424718379985, "phrase": "markov_jumping_problem"}, {"score": 0.0037795163893761027, "phrase": "optimal_control_problem"}, {"score": 0.0036248955128033084, "phrase": "adaptive_dynamic_programming"}, {"score": 0.0034476484413811987, "phrase": "online_learning"}, {"score": 0.003334309053314909, "phrase": "specific_learning_algorithm"}, {"score": 0.0032790397247488925, "phrase": "detailed_stability_analysis"}, {"score": 0.003092690568543981, "phrase": "performance_index_function_sequence"}, {"score": 0.002941389980674657, "phrase": "corresponding_admissible_control_input"}, {"score": 0.002728166176898539, "phrase": "adp_approach"}, {"score": 0.002682917193736698, "phrase": "online_learning_method"}, {"score": 0.002426717832834137, "phrase": "action_networks"}, {"score": 0.0022133711375320244, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Adaptive dynamic programming", " Neural network", " Markov jump systems", " Optimal control"], "paper_abstract": "In this paper, we propose an optimal online control method for discrete-time nonlinear Markov jump systems (MiSs). The Markov chain and the weighted sum technique are introduced to convert the Markov jumping problem into an optimal control problem. We then use adaptive dynamic programming (ADP) to accomplish online learning and control with specific learning algorithm and detailed stability analysis, including the convergence of the performance index function sequence and the existence of the corresponding admissible control input. Neural networks are applied to implement this ADP approach and online learning method is used to tune the weights of the critic and the action networks. Two different numerical examples are given to demonstrate the effectiveness of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A neural network based online learning and control approach for Markov jump systems", "paper_id": "WOS:000360028800016"}