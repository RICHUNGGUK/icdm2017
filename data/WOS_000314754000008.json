{"auto_keywords": [{"score": 0.027757680905002077, "phrase": "ndcg"}, {"score": 0.01231194543292566, "phrase": "base_rankers"}, {"score": 0.008315553421158299, "phrase": "rankagg"}, {"score": 0.00481495049065317, "phrase": "query_similarity"}, {"score": 0.0047559432344272, "phrase": "document_retrieval"}, {"score": 0.004555028829645471, "phrase": "supervised_rank_aggregation"}, {"score": 0.004362564831572539, "phrase": "ranking_performance"}, {"score": 0.004204054047427536, "phrase": "multiple_rankers"}, {"score": 0.003808845109556467, "phrase": "learned_weights"}, {"score": 0.003145417398038261, "phrase": "evaluation_measures"}, {"score": 0.002797121441432477, "phrase": "supervised_rank_aggregation_function"}, {"score": 0.0027120400060701034, "phrase": "aggregation_function"}, {"score": 0.002629539710839523, "phrase": "evaluation_measure"}, {"score": 0.0023527296826339225, "phrase": "better_ndcg_performance"}, {"score": 0.00230950802983053, "phrase": "linear_combination"}, {"score": 0.002239225269052105, "phrase": "experimental_results"}, {"score": 0.002198084195030656, "phrase": "benchmark_datasets"}, {"score": 0.0021049977753042253, "phrase": "baseline_approaches"}], "paper_keywords": ["Rank aggregation", " Query similarity", " Direct optimization of evaluation measures", " Learning to rank", " Document retrieval"], "paper_abstract": "This paper is concerned with supervised rank aggregation, which aims to improve the ranking performance by combining the outputs from multiple rankers. However, there are two main shortcomings in previous rank aggregation approaches. First, the learned weights for base rankers do not distinguish the differences among queries. This is suboptimal since queries vary significantly in terms of ranking. Besides, most current aggregation functions do not directly optimize the evaluation measures in ranking. In this paper, the differences among queries are taken into consideration, and a supervised rank aggregation function is proposed. This aggregation function is directly optimizing the evaluation measure NDCG, referred to as RankAgg.NDCG, We prove that RankAgg.NDCG can achieve better NDCG performance than the linear combination of the base rankers. Experimental results performed on benchmark datasets show our approach outperforms a number of baseline approaches.", "paper_title": "Supervised rank aggregation based on query similarity for document retrieval", "paper_id": "WOS:000314754000008"}