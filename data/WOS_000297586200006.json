{"auto_keywords": [{"score": 0.04909558158843681, "phrase": "pso"}, {"score": 0.00481495049065317, "phrase": "orthogonal_learning_particle_swarm_optimization"}, {"score": 0.004755353864362941, "phrase": "swarm_optimization"}, {"score": 0.004112020122418323, "phrase": "complex_problem_spaces"}, {"score": 0.00402748353567517, "phrase": "learning_strategies"}, {"score": 0.00396110232316167, "phrase": "previous_search_information"}, {"score": 0.003645192746918234, "phrase": "orthogonal_learning"}, {"score": 0.0034106416719768035, "phrase": "orthogonal_experimental_design"}, {"score": 0.003285380677401785, "phrase": "particle_swarm_optimization"}, {"score": 0.0032044314332538154, "phrase": "ol_strategy"}, {"score": 0.0031125001790084936, "phrase": "better_directions"}, {"score": 0.0029121251930855664, "phrase": "topological_structure"}, {"score": 0.0027020387992490367, "phrase": "olpsol_algorithms"}, {"score": 0.002646412155387084, "phrase": "new_learning_strategy"}, {"score": 0.0026135859312619875, "phrase": "new_algorithms"}, {"score": 0.0024149139610228887, "phrase": "art_evolutionary_algorithms"}, {"score": 0.0023849523850778807, "phrase": "experimental_results"}, {"score": 0.002306855521822739, "phrase": "proposed_learning_strategy"}, {"score": 0.002231310272815607, "phrase": "olpso"}, {"score": 0.0021492686054379755, "phrase": "faster_global_convergence"}, {"score": 0.0021314498639048085, "phrase": "higher_solution_quality"}, {"score": 0.0021049977753042253, "phrase": "stronger_robustness"}], "paper_keywords": ["Global optimization", " orthogonal experimental design (OED)", " orthogonal learning particle swarm optimization (OLPSO)", " particle swarm optimization (PSO)", " swarm intelligence"], "paper_abstract": "Particle swarm optimization (PSO) relies on its learning strategy to guide its search direction. Traditionally, each particle utilizes its historical best experience and its neighborhood's best experience through linear summation. Such a learning strategy is easy to use, but is inefficient when searching in complex problem spaces. Hence, designing learning strategies that can utilize previous search information (experience) more efficiently has become one of the most salient and active PSO research topics. In this paper, we proposes an orthogonal learning (OL) strategy for PSO to discover more useful information that lies in the above two experiences via orthogonal experimental design. We name this PSO as orthogonal learning particle swarm optimization (OLPSO). The OL strategy can guide particles to fly in better directions by constructing a much promising and efficient exemplar. The OL strategy can be applied to PSO with any topological structure. In this paper, it is applied to both global and local versions of PSO, yielding the OLPSO-G and OLPSOL algorithms, respectively. This new learning strategy and the new algorithms are tested on a set of 16 benchmark functions, and are compared with other PSO algorithms and some state of the art evolutionary algorithms. The experimental results illustrate the effectiveness and efficiency of the proposed learning strategy and algorithms. The comparisons show that OLPSO significantly improves the performance of PSO, offering faster global convergence, higher solution quality, and stronger robustness.", "paper_title": "Orthogonal Learning Particle Swarm Optimization", "paper_id": "WOS:000297586200006"}