{"auto_keywords": [{"score": 0.04806645810598007, "phrase": "dcsm"}, {"score": 0.04565922187614431, "phrase": "distinct_classes"}, {"score": 0.00481495049065317, "phrase": "decision_tree_construction"}, {"score": 0.004738078275822989, "phrase": "new_node_splitting_measure"}, {"score": 0.004662427600500598, "phrase": "distinct_class_based_splitting_measure"}, {"score": 0.004539005582217305, "phrase": "decision_tree_induction"}, {"score": 0.0036815763368083197, "phrase": "child_partition"}, {"score": 0.0035078427258024613, "phrase": "partition_increase"}, {"score": 0.003451766520526601, "phrase": "first_term_increases"}, {"score": 0.0033965836912510385, "phrase": "purer_partitions"}, {"score": 0.0032888418378433037, "phrase": "second_term"}, {"score": 0.0030834712590249863, "phrase": "total_number"}, {"score": 0.002890887778279196, "phrase": "purer_partition"}, {"score": 0.0027102997281261733, "phrase": "split_measure"}, {"score": 0.0025003054002226965, "phrase": "decision_trees"}, {"score": 0.002407941567598653, "phrase": "better_classification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Decision trees", " Node splitting measure", " Gini Index", " Gain Ratio"], "paper_abstract": "A new node splitting measure termed as distinct class based splitting measure (DCSM) for decision tree induction giving importance to the number of distinct classes in a partition has been proposed in this paper. The measure is composed of the product of two terms. The first term deals with the number of distinct classes in each child partition. As the number of distinct classes in a partition increase, this first term increases and thus Purer partitions are thus preferred. The second term decreases when there are more examples of a class compared to the total number of examples in the partition. The combination thus still favors purer partition. It is shown that the DCSM satisfies two important properties that a split measure should possess viz, convexity and well-behavedness. Results obtained over several datasets indicate that decision trees induced based on the DCSM provide better classification accuracy and are more compact (have fewer nodes) than trees induced using two of the most popular node splitting measures presently in use. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "A new node splitting measure for decision tree construction", "paper_id": "WOS:000278186700011"}