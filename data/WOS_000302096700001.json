{"auto_keywords": [{"score": 0.050071531816175296, "phrase": "information_functions"}, {"score": 0.040838917851158764, "phrase": "bernoulli"}, {"score": 0.004670896353428476, "phrase": "sensor_planning"}, {"score": 0.004614483128885678, "phrase": "target_classification"}, {"score": 0.004449280529563265, "phrase": "comparative_performance"}, {"score": 0.004238134740341528, "phrase": "canonical_target_classification_problem"}, {"score": 0.004186926251483987, "phrase": "five_sensor_models"}, {"score": 0.004012500850311087, "phrase": "classical_estimation_theory"}, {"score": 0.0038467171548414824, "phrase": "poisson"}, {"score": 0.003640516896245813, "phrase": "binomial_distributions"}, {"score": 0.003574695610710444, "phrase": "systematic_approach"}, {"score": 0.003384262486955773, "phrase": "expected_utility"}, {"score": 0.003343336516033681, "phrase": "future_sensor_measurements"}, {"score": 0.0033029038236817372, "phrase": "mutual_information"}, {"score": 0.0032630686704842333, "phrase": "renyi"}, {"score": 0.003203969242246567, "phrase": "kullback-leibler"}, {"score": 0.0028890603352364273, "phrase": "resulting_information-driven_strategies"}, {"score": 0.0025735173163957993, "phrase": "extensive_numerical_simulations"}, {"score": 0.002526938673434697, "phrase": "quadratic_entropy"}, {"score": 0.0023776656246300063, "phrase": "-classification_rates"}, {"score": 0.0022923586577645143, "phrase": "prior_information"}, {"score": 0.0022508572821818124, "phrase": "quadratic-entropy-driven_strategy"}, {"score": 0.0021569129153653777, "phrase": "false_alarms"}], "paper_keywords": ["Classification", " detection", " information driven", " information theory", " management", " optimal", " planning", " search", " sensor", " strategy", " target"], "paper_abstract": "This paper investigates the comparative performance of several information-driven search strategies and decision rules using a canonical target classification problem. Five sensor models are considered: one obtained from classical estimation theory and four obtained from Bernoulli, Poisson, binomial, and mixture-of-binomial distributions. A systematic approach is presented for deriving information functions that represent the expected utility of future sensor measurements from mutual information, Renyi divergence, Kullback-Leibler divergence, information potential, quadratic entropy, and the Cauchy-Schwarz distance. The resulting information-driven strategies are compared to direct-search, alert-confirm, task-driven (TS), and log-likelihood-ratio (LLR) search strategies. Extensive numerical simulations show that quadratic entropy typically leads to the most effective search strategy with respect to correct-classification rates. In the presence of prior information, the quadratic-entropy-driven strategy also displays the lowest rate of false alarms. However, when prior information is absent or very noisy, TS and LLR strategies achieve the lowest false-alarm rates for the Bernoulli, mixture-of-binomial, and classical sensor models.", "paper_title": "A Comparison of Information Functions and Search Strategies for Sensor Planning in Target Classification", "paper_id": "WOS:000302096700001"}