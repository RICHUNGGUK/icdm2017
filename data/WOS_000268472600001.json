{"auto_keywords": [{"score": 0.047728719573080294, "phrase": "individual_privacy"}, {"score": 0.032598867375888525, "phrase": "information_loss"}, {"score": 0.02623411995292378, "phrase": "minimality_attacks"}, {"score": 0.00481495049065317, "phrase": "data_publishing"}, {"score": 0.004513450434595191, "phrase": "recent_studies"}, {"score": 0.004261268957001927, "phrase": "different_kinds"}, {"score": 0.003611751858608048, "phrase": "data_publication"}, {"score": 0.0034841647157189985, "phrase": "extra_information"}, {"score": 0.0031730701021262155, "phrase": "known_mechanisms"}, {"score": 0.0023791769068748194, "phrase": "feasible_solution"}, {"score": 0.002262209824105154, "phrase": "practical_concerns"}, {"score": 0.0022298571016688335, "phrase": "real_datasets"}], "paper_keywords": ["Security", " Algorithms", " Experimentation", " Privacy preservation", " data publishing", " k-anonymity", " l-diversity", " minimality attack"], "paper_abstract": "Data publishing generates much concern over the protection of individual privacy. Recent studies consider cases where the adversary may possess different kinds of knowledge about the data. In this article, we show that knowledge of the mechanism or algorithm of anonymization for data publication can also lead to extra information that assists the adversary and jeopardizes individual privacy. In particular, all known mechanisms try to minimize information loss and such an attempt provides a loophole for attacks. We call such an attack a minimality attack. In this article, we introduce a model called m-confidentiality which deals with minimality attacks, and propose a feasible solution. Our experiments show that minimality attacks are practical concerns on real datasets and that our algorithm can prevent such attacks with very little overhead and information loss.", "paper_title": "Anonymization-Based Attacks in Privacy-Preserving Data Publishing", "paper_id": "WOS:000268472600001"}