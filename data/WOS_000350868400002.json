{"auto_keywords": [{"score": 0.04086471740870507, "phrase": "directory_structure"}, {"score": 0.039282223508626896, "phrase": "energy_requirements"}, {"score": 0.025048148237307832, "phrase": "coherence_network_traffic"}, {"score": 0.00481495049065317, "phrase": "dasc-dir"}, {"score": 0.004711694724000522, "phrase": "many-core_processors"}, {"score": 0.004644084911879363, "phrase": "future_many-core_processors"}, {"score": 0.004500891637057374, "phrase": "on-chip_storage"}, {"score": 0.004457722819680851, "phrase": "private_and_shared_caches"}, {"score": 0.004258233921732323, "phrase": "shared_memory"}, {"score": 0.004217382615990412, "phrase": "scalable_point"}, {"score": 0.004176921572698504, "phrase": "point_interconnection_network"}, {"score": 0.00409715552037496, "phrase": "cache_coherence"}, {"score": 0.003999578057088828, "phrase": "directory-based_protocol"}, {"score": 0.0036937016919398637, "phrase": "compressed_directory"}, {"score": 0.0035282825583750196, "phrase": "many-core_architectures"}, {"score": 0.003427632373165285, "phrase": "nuca_shared_cache"}, {"score": 0.003394722265343615, "phrase": "physical_mapping"}, {"score": 0.003305834275136569, "phrase": "round-robin_fashion"}, {"score": 0.0031730035365935653, "phrase": "corresponding_nuca_bank"}, {"score": 0.003104849179057156, "phrase": "cache_access_latency"}, {"score": 0.003067618280000169, "phrase": "on-chip_network_traffic"}, {"score": 0.0030235282484615228, "phrase": "area-_and_energy-efficient_compressed_directories"}, {"score": 0.0029657227799935065, "phrase": "coherence_event"}, {"score": 0.002923092970286497, "phrase": "degraded_performance"}, {"score": 0.0028672021562247962, "phrase": "efficient_and_low-overhead_coherence_directory"}, {"score": 0.0027719452656588795, "phrase": "distance-aware_round-robin_mapping_policy"}, {"score": 0.0025970576406249865, "phrase": "upper_bound"}, {"score": 0.0025473848376467074, "phrase": "memory_pages"}, {"score": 0.002535115422089855, "phrase": "cache_banks"}, {"score": 0.0024926348205500715, "phrase": "off-chip_accesses"}, {"score": 0.0024039809462972185, "phrase": "mapping_policy"}, {"score": 0.0022906498741695094, "phrase": "full-map_directory"}, {"score": 0.002274116256124247, "phrase": "typical_round-robin_physical_mapping_policy"}, {"score": 0.0021049977753042253, "phrase": "execution_time"}], "paper_keywords": ["Many-core CMPs", " Dynamic home assignment", " Compressed sharing codes", " Energy consumption", " Execution time", " Area overhead", " Network traffic"], "paper_abstract": "Current trends point toward future many-core processors being implemented using the hardware-managed, implicitly addressed, coherent caches memory model. With this memory model, all on-chip storage is used for private and shared caches that are kept coherent by hardware. Communication between cores is performed by writing to and reading from shared memory, and a scalable point-to-point interconnection network is in charge of transmitting messages. Cache coherence in this context is guaranteed by means of a directory-based protocol. Unfortunately, it has been previously shown that the directory structure required to keep track of sharers can restrict the scalability of these designs due its excessive area or energy requirements, or for a compressed directory, the increased coherence traffic that in some cases it could cause. On the other hand, in many-core architectures, memory blocks are commonly assigned to the banks of a NUCA shared cache by following a physical mapping. This mapping assigns blocks to cache banks in a round-robin fashion, thus neglecting the distance between the cores that more frequently access every block and the corresponding NUCA bank for the block. This issue impacts both cache access latency and the amount of on-chip network traffic generated and causes that some area- and energy-efficient compressed directories significantly increase the number of messages per coherence event, which finally translates into degraded performance. In this work we propose an efficient and low-overhead coherence directory which is built around two main ingredients: the first is the use of the distance-aware round-robin mapping policy, an OS-managed policy which tries to map the pages accessed by a core to its closest (local) bank, at the same time it introduces an upper bound on the deviation of the distribution of memory pages among cache banks, which lessens the number of off-chip accesses. The second is the utilization of a very compressed directory structure which takes advantage of this mapping policy to represent sharers in a very compact way without increasing coherence network traffic. Simulation results for a 32-core architecture demonstrate that compared to a full-map directory using the typical round-robin physical mapping policy, our proposal drastically reduces the size of the directory structure (and thus, its area and energy requirements); at the same time, it does not increase coherence network traffic and 6 % average savings in execution time are achieved.", "paper_title": "DASC-DIR: a low-overhead coherence directory for many-core processors", "paper_id": "WOS:000350868400002"}