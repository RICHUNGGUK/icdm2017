{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "distributed_memory_architectures"}, {"score": 0.015559161792155543, "phrase": "openmp"}, {"score": 0.012277900495683041, "phrase": "klcomp"}, {"score": 0.004691465925553365, "phrase": "emerging_industry_standard"}, {"score": 0.0046429592670444945, "phrase": "shared_memory_architectures"}, {"score": 0.004384960761826366, "phrase": "incremental_programming"}, {"score": 0.004339609346924681, "phrase": "message_passing"}, {"score": 0.004272456401437226, "phrase": "still_the_most_widely-used_programming_model"}, {"score": 0.003931402465972151, "phrase": "hot_spot"}, {"score": 0.0038106195546165574, "phrase": "openmp_system"}, {"score": 0.003542976343910816, "phrase": "shared_arrays\"_memory_model"}, {"score": 0.0034162643819889054, "phrase": "shared_array_recognition"}, {"score": 0.003345895878114341, "phrase": "inter-procedural_analysis"}, {"score": 0.0031107911390188055, "phrase": "nonlinear_references"}, {"score": 0.0029994894380575604, "phrase": "nine_benchmarks"}, {"score": 0.0029530125680590413, "phrase": "computational_fluid_dynamics"}, {"score": 0.0027169974137406148, "phrase": "average_scalability"}, {"score": 0.002674885993329912, "phrase": "klcomp_version"}, {"score": 0.002579140290642792, "phrase": "mpi_version"}, {"score": 0.002372935208038141, "phrase": "llcomp"}, {"score": 0.0022642601698943687, "phrase": "parallel_applications"}], "paper_keywords": ["parallel compiling", " high performance computing", " distributed memory architecture", " OpenMP", " irregular application"], "paper_abstract": "OpenMP is an emerging industry standard for shared memory architectures. While OpenMP has advantages on its ease of use and incremental programming, message passing is today still the most widely-used programming model for distributed memory architectures. How to effectively extend OpenMP to distributed memory architectures has been a hot spot. This paper proposes an OpenMP system, called KLCoMP, for distributed memory architectures. Based on the \"partially replicating shared arrays\" memory model, we propose an algorithm for shared array recognition based on the inter-procedural analysis, optimization technique based on the producer/consumer relationship, and communication generation technique for nonlinear references. We evaluate the performance on nine benchmarks which cover computational fluid dynamics, integer sorting, molecular dynamics, earthquake simulation, and computational chemistry. The average scalability achieved by KLCoMP version is close to that achieved by MPI version. We compare the performance of our translated programs with that of versions generated for Omni+SCASH, LLCoMP, and OpenMP(Purdue), and find that parallel applications (especially, irregular applications) translated by KLCoMP can achieve more effective performance than other versions.", "paper_title": "OpenMP compiler for distributed memory architectures", "paper_id": "WOS:000277417400005"}