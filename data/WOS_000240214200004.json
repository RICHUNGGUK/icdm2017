{"auto_keywords": [{"score": 0.03754487150281627, "phrase": "local_accesses"}, {"score": 0.015719716506582538, "phrase": "clustered_vliw_processor"}, {"score": 0.015541495633518422, "phrase": "word-interleaved_cache"}, {"score": 0.011285261158399828, "phrase": "memory_instructions"}, {"score": 0.009986715092531549, "phrase": "attraction_buffers"}, {"score": 0.004669180816745142, "phrase": "common_technique"}, {"score": 0.004597951649247307, "phrase": "wire_delay_problem"}, {"score": 0.004458722048888919, "phrase": "fully_distributed_architectures"}, {"score": 0.004390689303780405, "phrase": "register_file"}, {"score": 0.004340343873304156, "phrase": "functional_units"}, {"score": 0.00429057323623293, "phrase": "data_cache"}, {"score": 0.0039274105882136775, "phrase": "effective_instruction_scheduling_techniques"}, {"score": 0.0038526072615937203, "phrase": "vliw"}, {"score": 0.003650622777534568, "phrase": "variable_alignment"}, {"score": 0.003485913728272778, "phrase": "latency_assignment_process"}, {"score": 0.0034063576796640603, "phrase": "appropriate_latency"}, {"score": 0.003265175268104804, "phrase": "memory_consistency"}, {"score": 0.002977061391551631, "phrase": "attraction_buffer"}, {"score": 0.0029428772818833166, "phrase": "hardware_mechanism"}, {"score": 0.002897906501262407, "phrase": "data_replication"}, {"score": 0.002703869368554536, "phrase": "performance_results"}, {"score": 0.0026728137770370176, "phrase": "mediabench_benchmark_suite"}, {"score": 0.0026117657828249137, "phrase": "presented_techniques"}, {"score": 0.002465161736207254, "phrase": "mentioned_scheduling_techniques"}, {"score": 0.0024368411484675823, "phrase": "stall_time"}, {"score": 0.0021792693001152896, "phrase": "scheduling_heuristic"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["instruction scheduling", " modulo scheduling", " clustered VLIW processor", " distributed cache", " partitioned cache"], "paper_abstract": "Clustering is a common technique to overcome the wire delay problem incurred by the evolution of technology. Fully distributed architectures, where the register file, the functional units and the data cache are partitioned, are particularly effective to deal with these constraints and moreover they are very scalable. In this paper, effective instruction scheduling techniques for a word-interleaved cache clustered VLIW processor are presented. Such scheduling techniques rely on (i) loop unrolling and variable alignment to increase the fraction of local accesses, (ii) a latency assignment process to schedule memory instructions with an appropriate latency, and (iii) different heuristics to assign memory instructions to clusters. Memory consistency is guaranteed by constraining the assignment of memory instructions to clusters. In addition, the use of Attraction Buffers is also introduced. An Attraction Buffer is a hardware mechanism that allows some data replication in order to increase the number of local accesses and, in consequence, reduces stall time. Performance results for the Mediabench benchmark suite demonstrate the effectiveness of the presented techniques and mechanisms. The number of local accesses is increased by more than 25% by using the mentioned scheduling techniques, while stall time is reduced by more than 30% when Attraction Buffers are used. Finally, IPC results for such an architecture are 10% and 5% better compared to those of a clustered VLIW processor with a centralized/unified data cache depending on the scheduling heuristic, respectively. Copyright (c) 2006 John Wiley & Sons, Ltd.", "paper_title": "Instruction scheduling for a clustered VLIW processor with a word-interleaved cache", "paper_id": "WOS:000240214200004"}