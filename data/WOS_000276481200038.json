{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "artificial_neural_networks"}, {"score": 0.004650086856905758, "phrase": "considerable_time"}, {"score": 0.0043804319008535555, "phrase": "final_performance"}, {"score": 0.004337028108577593, "phrase": "initial_weights"}, {"score": 0.004230382915464492, "phrase": "hidden_nodes"}, {"score": 0.0041469500929423595, "phrase": "training_algorithm_rates"}, {"score": 0.004105850229681625, "phrase": "transfer_functions"}, {"score": 0.003984968827278219, "phrase": "manual_process"}, {"score": 0.003753738096719609, "phrase": "best_possible_set"}, {"score": 0.003716520760680603, "phrase": "neural_network_parameters"}, {"score": 0.003661382948704217, "phrase": "specific_problem"}, {"score": 0.003553540530701019, "phrase": "automatic_search_methodology"}, {"score": 0.003380791705551809, "phrase": "neural_networks"}, {"score": 0.0032975819773787985, "phrase": "evolution_strategies"}, {"score": 0.0031686717525002935, "phrase": "genetic_algorithms"}, {"score": 0.003075296862372287, "phrase": "global_search_module"}, {"score": 0.002925728709297618, "phrase": "local_searches"}, {"score": 0.00286795254228461, "phrase": "well-known_multilayer_perceptrons"}, {"score": 0.0027695759012721544, "phrase": "levenberg-marquardt"}, {"score": 0.002595698433525986, "phrase": "aforementioned_parameters"}, {"score": 0.0023609780669713288, "phrase": "proposed_method"}, {"score": 0.0021798257311714665, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Artificial neural networks", " Particle swarm optimization", " Evolutionary algorithms", " Memetic algorithms and hybrid intelligent systems"], "paper_abstract": "The use of artificial neural networks implies considerable time spent choosing a set of parameters that contribute toward improving the final performance. Initial weights, the amount of hidden nodes and layers, training algorithm rates and transfer functions are normally selected through a manual process of trial-and-error that often fails to find the best possible set of neural network parameters for a specific problem. This paper proposes an automatic search methodology for the optimization of the parameters and performance of neural networks relying on use of Evolution Strategies, Particle Swarm Optimization and concepts from Genetic Algorithms corresponding to the hybrid and global search module. There is also a module that refers to local searches, including the well-known Multilayer Perceptrons, Back-propagation and the Levenberg-Marquardt training algorithms. The methodology proposed here performs the search using the aforementioned parameters in an attempt to optimize the networks and performance. Experiments were performed and the results proved the proposed method to be better than trial-and-error and other methods found in the literature. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.", "paper_title": "A multi-objective memetic and hybrid methodology for optimizing the parameters and performance of artificial neural networks", "paper_id": "WOS:000276481200038"}