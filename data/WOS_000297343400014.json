{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "related_samples"}, {"score": 0.00795782400894167, "phrase": "relevant_samples"}, {"score": 0.007328542483453166, "phrase": "search_results"}, {"score": 0.004765482708043842, "phrase": "enhance_interactive_concept-based_video_search"}, {"score": 0.004644014990871423, "phrase": "main_challenges"}, {"score": 0.004596295252559861, "phrase": "interactive_concept-based_video_search"}, {"score": 0.004479120557712926, "phrase": "insufficient_relevant_samples"}, {"score": 0.004342430078306461, "phrase": "complex_semantics"}, {"score": 0.004209893377338457, "phrase": "\"related_samples"}, {"score": 0.004081385289516914, "phrase": "interactive_video_search"}, {"score": 0.003936389070602614, "phrase": "video_segments"}, {"score": 0.0036996627006622975, "phrase": "entire_query"}, {"score": 0.002931569771634119, "phrase": "visual_ranking_model"}, {"score": 0.002769395841379498, "phrase": "temporal_ranking_model"}, {"score": 0.0027126684113045756, "phrase": "temporal_relationship"}, {"score": 0.002684740763324991, "phrase": "related_and_relevant_samples"}, {"score": 0.002643386043540555, "phrase": "adaptive_fusion_method"}, {"score": 0.002445950676329976, "phrase": "extensive_experiments"}, {"score": 0.002358930421953132, "phrase": "youtube"}, {"score": 0.002298649369775623, "phrase": "experimental_results"}], "paper_keywords": ["Complex query", " concept-based video search", " interactive search", " related sample"], "paper_abstract": "One of the main challenges in interactive concept-based video search is the problem of insufficient relevant samples, especially for queries with complex semantics. In this paper, \"related samples\" are exploited to enhance interactive video search. The related samples refer to those video segments that are relevant to part of the query rather than the entire query. Compared to the relevant samples which may be rare, the related samples are usually plentiful and easy to find in search results. Generally, the related samples are visually similar and temporally neighboring to the relevant samples. Based on these two characters, we develop a visual ranking model that simultaneously exploits the relevant, related, and irrelevant samples, as well as a temporal ranking model to leverage the temporal relationship between related and relevant samples. An adaptive fusion method is then proposed to optimally explore these two ranking models to generate search results. We conduct extensive experiments on two real-world video datasets: TRECVID 2008 and YouTube datasets. As the experimental results show, our approach achieves at least 96% and 167% performance improvements against the state-of-the-art approaches on the TRECVID 2008 and YouTube datasets, respectively.", "paper_title": "Utilizing Related Samples to Enhance Interactive Concept-Based Video Search", "paper_id": "WOS:000297343400014"}