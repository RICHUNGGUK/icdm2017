{"auto_keywords": [{"score": 0.043327100792472296, "phrase": "latent_variables"}, {"score": 0.00481495049065317, "phrase": "backward_elimination"}, {"score": 0.004764435715755502, "phrase": "new_model_order_reduction_algorithm"}, {"score": 0.004714448392640623, "phrase": "best_double_mixture_model"}, {"score": 0.00463229351153731, "phrase": "probabilistic_latent_semantic_analysis"}, {"score": 0.004599833505496532, "phrase": "plsa"}, {"score": 0.0045355866228818514, "phrase": "double_structure_mixture_model"}, {"score": 0.004456534664975427, "phrase": "wide_application"}, {"score": 0.004394281902031765, "phrase": "web_mining"}, {"score": 0.004272361887713488, "phrase": "hidden_semantic_relations"}, {"score": 0.004227515355865597, "phrase": "observed_features"}, {"score": 0.003996133359116611, "phrase": "correct_number"}, {"score": 0.0038444185258456245, "phrase": "previous_researches"}, {"score": 0.0037773674108196376, "phrase": "latent_topics"}, {"score": 0.003672500644750565, "phrase": "invoked_classes"}, {"score": 0.003545487140867762, "phrase": "backward_elimination_approach"}, {"score": 0.0034713900276078786, "phrase": "unsupervised_order_selection"}, {"score": 0.003447035529485425, "phrase": "pisa."}, {"score": 0.0032697235411641695, "phrase": "needed_value"}, {"score": 0.0031234247639701134, "phrase": "elimination_process"}, {"score": 0.003101503914610488, "phrase": "proper_selection"}, {"score": 0.002931569771634119, "phrase": "final_performance"}, {"score": 0.002900756392266265, "phrase": "pruned_model"}, {"score": 0.0027806988302728633, "phrase": "new_combined_pruning_method"}, {"score": 0.0027417911324611917, "phrase": "best_options"}, {"score": 0.0026750045328382717, "phrase": "low_computational_cost"}, {"score": 0.002528379400564723, "phrase": "obtained_results"}, {"score": 0.0024581013157048926, "phrase": "optimized_number"}, {"score": 0.002398208426903865, "phrase": "better_clustering_performance"}, {"score": 0.0023646398663605493, "phrase": "conventional_model_selection_methods"}, {"score": 0.0022667208478315323, "phrase": "plsa_model"}, {"score": 0.002242879896352752, "phrase": "fixed_number"}, {"score": 0.002188219483646592, "phrase": "real_number"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Model selection", " Document clustering", " PLSA", " Bayesian information criterion (BIC)", " EM algorithm"], "paper_abstract": "Probabilistic latent semantic analysis (PLSA) is a double structure mixture model which has got a wide application in text and web mining. This method is capable of establishing hidden semantic relations among the observed features, using a number of latent variables. In this approach, the selection of the correct number of latent variables is critical. In the most of the previous researches, the number of latent topics was selected based on the number of invoked classes. This paper presents a method, based on backward elimination approach, which is capable of unsupervised order selection in PISA. This method starts with a model having a number of components more than the needed value, and then prunes the mixtures to reach their optimum size. During the elimination process, proper selection of some latent variables which must be deleted is the most essential problem, and its relation to the final performance of the pruned model is straightforward. To treat this problem, we introduce a new combined pruning method which selects the best options for removal, while keeping a low computational cost, at all. We conducted,some experiments on two datasets from Reuters-21578 corpus. The obtained results show that this algorithm leads to an optimized number of latent variables and in turn achieves better clustering performance compared to the conventional model selection methods. It also shows superiority over the case in which a PLSA model with a fixed number of latent variables, equal to the real number of clusters, is exploited. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Using backward elimination with a new model order reduction algorithm to select best double mixture model for document clustering", "paper_id": "WOS:000266851000033"}