{"auto_keywords": [{"score": 0.041743876102144445, "phrase": "local_discriminative_information"}, {"score": 0.02599806905685787, "phrase": "global_structure_information"}, {"score": 0.00481495049065317, "phrase": "structure-embedded_auc-svm._auc-svm"}, {"score": 0.004645111654880697, "phrase": "roc"}, {"score": 0.004390060342250211, "phrase": "decision_function"}, {"score": 0.004278807087784626, "phrase": "support_vector_sample_pairs"}, {"score": 0.0041490029730869345, "phrase": "support_vector_samples"}, {"score": 0.004106612344123407, "phrase": "svm._such_a_learning_paradigm"}, {"score": 0.0038810583785936505, "phrase": "support_vectors"}, {"score": 0.003782655283668953, "phrase": "overall_view"}, {"score": 0.0035382855372646164, "phrase": "global_distribution_information"}, {"score": 0.00332670230152448, "phrase": "high_computational_complexity"}, {"score": 0.003292685392413911, "phrase": "auc-svm"}, {"score": 0.0032256881625734777, "phrase": "large_number"}, {"score": 0.003192700856094016, "phrase": "training_sample_pairs"}, {"score": 0.002910545717767559, "phrase": "distribution_information"}, {"score": 0.0027789349951704177, "phrase": "distribution_information_loss"}, {"score": 0.002708399936381754, "phrase": "auc-svm_performance"}, {"score": 0.002585906251354904, "phrase": "novel_structure-embedded_auc-svm"}, {"score": 0.0024062532032402533, "phrase": "whole_data"}, {"score": 0.0023816257768353344, "phrase": "auc-svm."}, {"score": 0.002193447487477984, "phrase": "uniform_formulation"}, {"score": 0.0021487685525986094, "phrase": "better_generalization_performance"}, {"score": 0.0021267708018655493, "phrase": "comparative_experiments"}], "paper_keywords": ["Area Under the ROC Curve (AUC)", " Support Vector Machine (SVM)", " Support vector sample pair", " sampling", " structure information"], "paper_abstract": "AUC-SVM directly maximizes the area under the ROC curve (AUC) through minimizing its hinge loss relaxation, and the decision function is determined by those support vector sample pairs playing the same roles as the support vector samples in SVM. Such a learning paradigm generally emphasizes more on the local discriminative information just associated with these support vectors whereas hardly takes the overall view of data into account, thereby it may incur loss of the global distribution information in data favorable for classification. Moreover, due to the high computational complexity of AUC-SVM induced by the large number of training sample pairs quadratic in the number of samples, sampling is usually adopted, incurring a further loss of the distribution information in data. In order to compensate the distribution information loss and simultaneously boost the AUC-SVM performance, in this paper, we develop a novel structure-embedded AUC-SVM (SAUC-SVM for short) through embedding the global structure information in the whole data into AUC-SVM. With such an embedding, the proposed SAUC-SVM incorporates the local discriminative information and global structure information in data into a uniform formulation and consequently guarantees better generalization performance. Comparative experiments on both synthetic and real datasets confirm its effectiveness.", "paper_title": "STRUCTURE-EMBEDDED AUC-SVM", "paper_id": "WOS:000281194300001"}