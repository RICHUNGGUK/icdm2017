{"auto_keywords": [{"score": 0.03678155322201076, "phrase": "validation_error"}, {"score": 0.03636071503153037, "phrase": "network_size_curve"}, {"score": 0.028690285387344895, "phrase": "combined_method"}, {"score": 0.00481495049065317, "phrase": "feedforward_network_training"}, {"score": 0.004646258518859209, "phrase": "complexity_optimization"}, {"score": 0.004591345494188032, "phrase": "feedforward_networks"}, {"score": 0.004224627834741731, "phrase": "growing_scheme"}, {"score": 0.004076533120753605, "phrase": "new_hidden_units"}, {"score": 0.004028326293950714, "phrase": "full-trained_networks"}, {"score": 0.003910278811774747, "phrase": "non-heuristic_one-pass_pruning_technique"}, {"score": 0.0037731618765688584, "phrase": "orthogonal_least_squares"}, {"score": 0.003619235073669304, "phrase": "one-pass_approach"}, {"score": 0.0033898953358387075, "phrase": "combined_approach"}, {"score": 0.0031750418391373035, "phrase": "growing_process"}, {"score": 0.0030454408569868347, "phrase": "hidden_units"}, {"score": 0.0028865314258560214, "phrase": "least_useful_units"}, {"score": 0.002428617044669043, "phrase": "initial_weights"}, {"score": 0.002371424085814217, "phrase": "almost_monotonic_error"}], "paper_keywords": ["pruning", " cascade correlation", " back propagation", " output weight optimization-hidden weight optimization"], "paper_abstract": "In order to facilitate complexity optimization in feedforward networks, several algorithms are developed that combine growing and pruning. First, a growing scheme is presented which iteratively adds new hidden units to full-trained networks. Then, a non-heuristic one-pass pruning technique is presented, which utilizes orthogonal least squares. Based upon pruning, a one-pass approach is developed for generating the validation error versus network size curve. A combined approach is described in which networks are continually pruned during the growing process. As a result, the hidden units are ordered according to their usefulness, and the least useful units are eliminated. Examples show that networks designed using the combined method have less training and validation error than growing or pruning alone. The combined method exhibits reduced sensitivity to the initial weights and generates an almost monotonic error versus network size curve. It is shown to perform better than two well-known growing methods-constructive backpropagation and cascade correlation. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "An integrated growing-pruning method for feedforward network training", "paper_id": "WOS:000259121100044"}