{"auto_keywords": [{"score": 0.036590546733605435, "phrase": "ci_tests"}, {"score": 0.016235551229611657, "phrase": "conditioning_sets"}, {"score": 0.010612387000973441, "phrase": "markov_random_fields"}, {"score": 0.009775258806855279, "phrase": "bayesian_networks"}, {"score": 0.009003564184418136, "phrase": "large_sets"}, {"score": 0.008820267483170411, "phrase": "dependency_analysis_algorithms"}, {"score": 0.006317798523121021, "phrase": "two-phase_algorithm"}, {"score": 0.005423256442423844, "phrase": "true_bayesian_network"}, {"score": 0.0046970764288494764, "phrase": "linear_models"}, {"score": 0.004658426838467567, "phrase": "dependency_analysis"}, {"score": 0.004601045179623499, "phrase": "typical_approach"}, {"score": 0.004563182153397349, "phrase": "bayesian_network_learning"}, {"score": 0.00428892403807229, "phrase": "conditional_independence"}, {"score": 0.0042537112449197246, "phrase": "ci"}, {"score": 0.004115267130977749, "phrase": "independence_conditioning"}, {"score": 0.0036653985479652854, "phrase": "limited_samples"}, {"score": 0.0034165310204389682, "phrase": "exponential_rate"}, {"score": 0.0032916702592724217, "phrase": "running_time"}, {"score": 0.0029928611380840757, "phrase": "critical_step"}, {"score": 0.0026543514413663893, "phrase": "first_phase"}, {"score": 0.0025892330566358503, "phrase": "markov_random_field"}, {"score": 0.002515272856011004, "phrase": "close_approximation"}, {"score": 0.0024232694434408093, "phrase": "second_phase"}, {"score": 0.002373615081691254, "phrase": "redundant_edges"}, {"score": 0.002258546887303777, "phrase": "markov_blanket_information"}, {"score": 0.0021049977753042253, "phrase": "empirical_study"}], "paper_keywords": ["Bayesian networks", " causal modeling", " graphical models"], "paper_abstract": "Dependency analysis is a typical approach for Bayesian network learning, which infers the structures of Bayesian networks by the results of a series of conditional independence (CI) tests. In practice, testing independence conditioning on large sets hampers the performance of dependency analysis algorithms in terms of accuracy and running time for the following reasons. First, testing independence on large sets of variables with limited samples is not stable. Second, for most dependency analysis algorithms, the number of CI tests grows at an exponential rate with the sizes of conditioning sets, and the running time grows of the same rate. Therefore, determining how to reduce the number of CI tests and the sizes of conditioning sets becomes a critical step in dependency analysis algorithms. In this article, we address a two-phase algorithm based on the observation that the structures of Markov random fields are similar to those of Bayesian networks. The first phase of the algorithm constructs a Markov random field from data, which provides a close approximation to the structure of the true Bayesian network; the second phase of the algorithm removes redundant edges according to CI tests to get the true Bayesian network. Both phases use Markov blanket information to reduce the sizes of conditioning sets and the number of CI tests without sacrificing accuracy. An empirical study shows that the two-phase algorithm performs well in terms of accuracy and efficiency.", "paper_title": "Learning Bayesian Networks from Markov Random Fields: An Efficient Algorithm for Linear Models", "paper_id": "WOS:000310560600001"}