{"auto_keywords": [{"score": 0.04806645810598005, "phrase": "joint_dependency"}, {"score": 0.00481495049065317, "phrase": "minimum_redundancy_maximum_relevance_feature_selection_method"}, {"score": 0.004466519142879166, "phrase": "minimum_size"}, {"score": 0.004187917910692495, "phrase": "main_task"}, {"score": 0.00409895142748329, "phrase": "feature_selection"}, {"score": 0.0038846843242954935, "phrase": "minimal_subset"}, {"score": 0.0034890505116128606, "phrase": "target_variable"}, {"score": 0.003306559295382181, "phrase": "selected_variables"}, {"score": 0.002174041708084857, "phrase": "feature_selection_capability"}], "paper_keywords": ["Mutual information", " mRMR", " unsupervised learning", " support vector machines", " SINBAD covariates"], "paper_abstract": "Maximizing the joint dependency with a minimum size of variables is generally the main task of feature selection. For obtaining a minimal subset, while trying to maximize the joint dependency with the target variable, the redundancy among selected variables must be reduced to a minimum. In this paper, we propose a method based on recently popular minimum Redundancy-Maximum Relevance (mRMR) criterion. The experimental results show that instead of feeding the features themselves into mRMR, feeding the covariates improves the feature selection capability and provides more expressive variable subsets.", "paper_title": "Using covariates for improving the minimum Redundancy Maximum Relevance feature selection method", "paper_id": "WOS:000286035400004"}