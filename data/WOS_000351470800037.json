{"auto_keywords": [{"score": 0.03943498990941781, "phrase": "small_number"}, {"score": 0.032473372880921614, "phrase": "reliable_subspace_recovery"}, {"score": 0.03097982060329348, "phrase": "general_unions"}, {"score": 0.030156442529772363, "phrase": "special_case"}, {"score": 0.00481495049065317, "phrase": "subspace_recovery_from_structured_union_of_subspaces"}, {"score": 0.004781777766309739, "phrase": "lower_dimensional_signal_representation_schemes"}, {"score": 0.004603352344461032, "phrase": "single_vector_space"}, {"score": 0.004493275458211613, "phrase": "recently_developed_theory"}, {"score": 0.004462308985053246, "phrase": "compressive_sensing"}, {"score": 0.004236733825313407, "phrase": "orthonormal_basis"}, {"score": 0.003980984488865867, "phrase": "standard_sparsity_assumption"}, {"score": 0.003124437382827821, "phrase": "performance_bounds"}, {"score": 0.0030285690317007805, "phrase": "maximum_likelihood"}, {"score": 0.0027582072733520475, "phrase": "block_sparsity"}, {"score": 0.0026828233195176155, "phrase": "general_sampling_operators"}, {"score": 0.0026643006135750025, "phrase": "random_sampling_matrices"}, {"score": 0.002451908706776122, "phrase": "ml"}, {"score": 0.0023847032316716503, "phrase": "restricted_isometry_property"}, {"score": 0.0023518780693181796, "phrase": "complete_signal_recovery"}, {"score": 0.0022955150243239623, "phrase": "sparse_signals"}, {"score": 0.0022327484973125936, "phrase": "standard_sparsity"}, {"score": 0.002217326282120832, "phrase": "subspace_recovery"}, {"score": 0.002179234170770192, "phrase": "existing_results"}, {"score": 0.002164180792169302, "phrase": "sparse_support_recovery"}, {"score": 0.0021049977753042253, "phrase": "standard_sparsity_model"}], "paper_keywords": ["Maximum likelihood estimation", " union of linear subspaces", " subspace recovery", " compressive sensing", " block sparsity"], "paper_abstract": "Lower dimensional signal representation schemes frequently assume that the signal of interest lies in a single vector space. In the context of the recently developed theory of compressive sensing, it is often assumed that the signal of interest is sparse in an orthonormal basis. However, in many practical applications, this requirement may be too restrictive. A generalization of the standard sparsity assumption is that the signal lies in a union of subspaces. Recovery of such signals from a small number of samples has been studied recently in several works. Here, we consider the problem of only subspace recovery in which our goal is to identify the subspace (from the union) in which the signal lies using a small number of samples, in the presence of noise. More specifically, we derive performance bounds and conditions under which reliable subspace recovery is guaranteed using maximum likelihood (ML) estimation. We begin by treating general unions and then obtain the results for the special case in which the subspaces have structure leading to block sparsity. In our analysis, we treat both general sampling operators and random sampling matrices. With general unions, we show that under certain conditions, the number of measurements required for reliable subspace recovery in the presence of noise via ML is less than that implied using the restricted isometry property, which guarantees complete signal recovery. In the special case of block sparse signals, we quantify the gain achievable over standard sparsity in subspace recovery. Our results also strengthen existing results on sparse support recovery in the presence of noise under the standard sparsity model.", "paper_title": "Subspace Recovery From Structured Union of Subspaces", "paper_id": "WOS:000351470800037"}