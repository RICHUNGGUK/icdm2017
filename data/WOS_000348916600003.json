{"auto_keywords": [{"score": 0.035524421372478625, "phrase": "gbdt"}, {"score": 0.00481495049065317, "phrase": "web_search_ranking"}, {"score": 0.004768104290288521, "phrase": "noise_injection"}, {"score": 0.004430920292612374, "phrase": "labeling_cost"}, {"score": 0.004387793971765289, "phrase": "training_data_preparation"}, {"score": 0.004097389262726735, "phrase": "novel_active_learning-for-ranking_strategy"}, {"score": 0.0038074544783102226, "phrase": "gradient_boosting_decision_tree"}, {"score": 0.003520687960750365, "phrase": "major_commercial_search_engines"}, {"score": 0.0032714270066711835, "phrase": "decision_boundary"}, {"score": 0.00311510526624626, "phrase": "active_learning_strategy"}, {"score": 0.002995427206425849, "phrase": "proposed_strategy"}, {"score": 0.002852256089630964, "phrase": "sample_selection"}, {"score": 0.0028244513779243107, "phrase": "model_regularization"}, {"score": 0.002769650208851401, "phrase": "potentially_theoretical_guarantee"}, {"score": 0.0026372419109713923, "phrase": "performance_metrics"}, {"score": 0.0026115277372906805, "phrase": "ranking_overweight_the_top-ranked_items"}, {"score": 0.002511147699138714, "phrase": "selection_function"}, {"score": 0.002414616656410503, "phrase": "proposed_technique"}, {"score": 0.002321787726770895, "phrase": "wide_variety"}, {"score": 0.002276717177453959, "phrase": "substantial_experimental_results"}, {"score": 0.0022216045996270974, "phrase": "real-world_dataset"}], "paper_keywords": ["Algorithms", " Experimentation", " Theory", " Active learning", " noise injection", " ranking", " sensitivity sampling"], "paper_abstract": "Learning to rank has become increasingly important for many information retrieval applications. To reduce the labeling cost at training data preparation, many active sampling algorithms have been proposed. In this article, we propose a novel active learning-for-ranking strategy called ranking-based sensitivity sampling (RSS), which is tailored for Gradient Boosting Decision Tree (GBDT), a machine-learned ranking method widely used in practice by major commercial search engines for ranking. We leverage the property of GBDT that samples close to the decision boundary tend to be sensitive to perturbations and design the active learning strategy accordingly. We further theoretically analyze the proposed strategy by exploring the connection between the sensitivity used for sample selection and model regularization to provide a potentially theoretical guarantee w.r.t. the generalization capability. Considering that the performance metrics of ranking overweight the top-ranked items, item rank is incorporated into the selection function. In addition, we generalize the proposed technique to several other base learners to show its potential applicability in a wide variety of applications. Substantial experimental results on both the benchmark dataset and a real-world dataset have demonstrated that our proposed active learning strategy is highly effective in selecting the most informative examples.", "paper_title": "Active Learning for Web Search Ranking via Noise Injection", "paper_id": "WOS:000348916600003"}