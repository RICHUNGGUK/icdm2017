{"auto_keywords": [{"score": 0.027507999683207565, "phrase": "mgmr"}, {"score": 0.00481495049065317, "phrase": "mapreduce_framework"}, {"score": 0.004753194996637899, "phrase": "multi-gpu_systems"}, {"score": 0.004398872331144531, "phrase": "differentiated_price-performance"}, {"score": 0.0043144799365586375, "phrase": "scalable_high_performance_computing"}, {"score": 0.004259217160335752, "phrase": "mapreduce"}, {"score": 0.0041773934798743405, "phrase": "well-known_distributed_programming_model"}, {"score": 0.003967021436047945, "phrase": "large-scale_data_processing"}, {"score": 0.003816197777388722, "phrase": "commodity_cpus"}, {"score": 0.0034191818674096453, "phrase": "computation_power"}, {"score": 0.0033752674784204412, "phrase": "memory_bandwidth"}, {"score": 0.0030832123624449028, "phrase": "mapreduce_model"}, {"score": 0.0028715299874549245, "phrase": "single_gpu_model"}, {"score": 0.0027801631944598206, "phrase": "gpu_memory"}, {"score": 0.0027444334639134217, "phrase": "inefficient_atomic_operations"}, {"score": 0.0024586427394152196, "phrase": "multiple_gpus"}, {"score": 0.002411383506019635, "phrase": "large-scale_data"}, {"score": 0.0023497779149212737, "phrase": "gpu_memory_limitation"}, {"score": 0.002260301305523054, "phrase": "serial_atomic_operations"}, {"score": 0.0022312377180023282, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "large_data_sets"}], "paper_keywords": ["GPU", " MapReduce", " Large scale data processing", " Multi-GPUs"], "paper_abstract": "Graphics processors evolve rapidly and promise to support power-efficient, cost, differentiated price-performance, and scalable high performance computing. MapReduce is a well-known distributed programming model to ease the development of applications for large-scale data processing on a large number of commodity CPUs. When compared to CPUs, GPUs are an order of magnitude faster in terms of computation power and memory bandwidth, but they are harder to program. Although several studies have implemented the MapReduce model on GPUs, most of them are based on the single GPU model and bounded by a GPU memory with inefficient atomic operations. This paper focuses on the development of MGMR, a standalone MapReduce system that utilizes multiple GPUs to manage large-scale data processing beyond the GPU memory limitation, and also to eliminate serial atomic operations. Experimental results have demonstrated the effectiveness of MGMR in handling large data sets.", "paper_title": "Accelerating MapReduce framework on multi-GPU systems", "paper_id": "WOS:000336424400013"}