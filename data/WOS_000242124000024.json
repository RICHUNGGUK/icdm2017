{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "information-based_criterion"}, {"score": 0.004741167616693272, "phrase": "smooth_boosting_algorithms"}, {"score": 0.0037314328720368453, "phrase": "\"_scheme"}, {"score": 0.0035076666315744525, "phrase": "huge_data"}, {"score": 0.0034008496666026585, "phrase": "current_smooth_boosting_algorithms"}, {"score": 0.002476546030310661, "phrase": "new_smooth_boosting_algorithm"}, {"score": 0.002364172626241202, "phrase": "gini_index"}, {"score": 0.0021049977753042253, "phrase": "information-based_approaches"}], "paper_keywords": [""], "paper_abstract": "Smooth boosting algorithms are variants of boosting methods which handle only smooth distributions on the data. They are proved to be noise-tolerant and can be used in the \"boosting by filtering\" scheme, which is suitable for learning over huge data. However, current smooth boosting algorithms have rooms for improvements: Among non-smooth boosting algorithms, real AdaBoost or InfoBoost, can perform more efficiently than typical boosting algorithms by using an information-based criterion for choosing hypotheses. In this paper, we propose a new smooth boosting algorithm with another information-based criterion based on Gini index. we show that it inherits the advantages of two approaches, smooth boosting and information-based approaches.", "paper_title": "Smooth boosting using an information-based criterion", "paper_id": "WOS:000242124000024"}