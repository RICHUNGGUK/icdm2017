{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "fixed-rank_positive_semidefinite_matrices"}, {"score": 0.004312622975366672, "phrase": "regression_model"}, {"score": 0.004178935413340453, "phrase": "fixed-rank_positive_semidefinite_matrix"}, {"score": 0.003954837422946628, "phrase": "nonlinear_nature"}, {"score": 0.0038624981944755813, "phrase": "search_space"}, {"score": 0.0037133478610481994, "phrase": "high-dimensional_problems"}, {"score": 0.003626626504149897, "phrase": "mathematical_developments"}, {"score": 0.003459191419478298, "phrase": "gradient_descent_algorithms"}, {"score": 0.0033518704336033874, "phrase": "riemannian_geometry"}, {"score": 0.0030735451757603555, "phrase": "previous_contributions"}, {"score": 0.00281826552772148, "phrase": "range_space"}, {"score": 0.002752390133272192, "phrase": "learned_matrix"}, {"score": 0.002688050388891007, "phrase": "resulting_algorithms"}, {"score": 0.0026252106881752067, "phrase": "linear_complexity"}, {"score": 0.0025638362414466278, "phrase": "problem_size"}, {"score": 0.0025038930574283174, "phrase": "important_invariance_properties"}, {"score": 0.002407078478216306, "phrase": "proposed_algorithms"}, {"score": 0.0022777800735119405, "phrase": "distance_function"}, {"score": 0.0022070310530794097, "phrase": "positive_semidefinite_matrix"}, {"score": 0.0021724831184390192, "phrase": "good_performance"}, {"score": 0.0021049977753042253, "phrase": "classical_benchmarks"}], "paper_keywords": ["linear regression", " positive semidefinite matrices", " low-rank approximation", " Riemannian geometry", " gradient-based learning"], "paper_abstract": "The paper addresses the problem of learning a regression model parameterized by a fixed-rank positive semidefinite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of fixed-rank positive semidefinite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semidefinite matrix. Good performance is observed on classical benchmarks.", "paper_title": "Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach", "paper_id": "WOS:000288896800008"}