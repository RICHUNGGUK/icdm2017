{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "information-theoretic_limits"}, {"score": 0.004777917315737992, "phrase": "sparse_signal_recovery"}, {"score": 0.004704699244406775, "phrase": "sparse_measurement_matrices"}, {"score": 0.004526503177267299, "phrase": "support_set"}, {"score": 0.004474366340935036, "phrase": "sparse_signal"}, {"score": 0.004422827355213055, "phrase": "noisy_projections"}, {"score": 0.004338239182984759, "phrase": "measurement_matrices"}, {"score": 0.004031238480458909, "phrase": "ambient_signal_dimension_p"}, {"score": 0.0039694170761766226, "phrase": "signal_sparsity_k"}, {"score": 0.0038189638340666936, "phrase": "general_manner"}, {"score": 0.0036600192572132676, "phrase": "sharper_necessary_conditions"}, {"score": 0.0036318365746264127, "phrase": "exact_support_recovery"}, {"score": 0.0035076666315744525, "phrase": "previously_known_sufficient_conditions"}, {"score": 0.0034405207528624983, "phrase": "sharp_characterizations"}, {"score": 0.0033877275374263314, "phrase": "optimal_decoder"}, {"score": 0.0032216622984027558, "phrase": "sample_size"}, {"score": 0.00317221667574882, "phrase": "important_special_case"}, {"score": 0.0031477782772867655, "phrase": "linear_sparsity"}, {"score": 0.0030283730114326014, "phrase": "linear_scaling"}, {"score": 0.0028576796380512157, "phrase": "necessary_conditions"}, {"score": 0.0027706013216537042, "phrase": "asymptotically_reliable_recovery"}, {"score": 0.0027175263159330523, "phrase": "gamma-sparsified_measurement_matrices"}, {"score": 0.002476546030310661, "phrase": "nonzero_entries"}, {"score": 0.002419708657850547, "phrase": "general_scaling"}, {"score": 0.0022568866348667547, "phrase": "measurement_sparsity"}, {"score": 0.0022308329460335985, "phrase": "asymptotic_effect"}, {"score": 0.0021049977753042253, "phrase": "subset_recovery_problem"}], "paper_keywords": ["l(1)-Relaxation", " compressed sensing", " Fano's method", " high-dimensional statistical inference", " information-theoretic bounds", " sparse approximation", " sparse random matrices", " sparsity recovery", " subset selection", " support recovery"], "paper_abstract": "We study the information-theoretic limits of exactly recovering the support set of a sparse signal, using noisy projections defined by various classes of measurement matrices. Our analysis is high-dimensional in nature, in which the number of observations n, the ambient signal dimension p, and the signal sparsity k are all allowed to tend to infinity in a general manner. This paper makes two novel contributions. First, we provide sharper necessary conditions for exact support recovery using general (including non-Gaussian) dense measurement matrices. Combined with previously known sufficient conditions, this result yields sharp characterizations of when the optimal decoder can recover a signal for various scalings of the signal sparsity k and sample size, including the important special case of linear sparsity (k = circle minus(p)) using a linear scaling of observations (n = circle minus(p)). Our second contribution is to prove necessary conditions on the number of observations required for asymptotically reliable recovery using a class of gamma-sparsified measurement matrices, where the measurement sparsity parameter gamma(n,p,k) is an element of (0, 1] corresponds to the fraction of nonzero entries per row. Our analysis allows general scaling of the quadruplet (n,p,k,gamma), and reveals three different regimes, corresponding to whether measurement sparsity has no asymptotic effect, a minor effect, or a dramatic effect on the information-theoretic limits of the subset recovery problem.", "paper_title": "Information-Theoretic Limits on Sparse Signal Recovery: Dense versus Sparse Measurement Matrices", "paper_id": "WOS:000277880200038"}