{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "-embedding_prediction"}, {"score": 0.004733347359490221, "phrase": "cats_benchmark"}, {"score": 0.004600389726895716, "phrase": "general_strategy"}, {"score": 0.0044967055264893184, "phrase": "missing_data"}, {"score": 0.004420472010542188, "phrase": "cats_benchmark_time_series_prediction_competition"}, {"score": 0.004247560712327667, "phrase": "time-symmetric_embedding"}, {"score": 0.004175533280178052, "phrase": "time_series"}, {"score": 0.004104722208522451, "phrase": "use_of_a_one-shot_forecasting_for_each_missing_value_inside_the_gaps_from_distant-enough_delayed_and_forwarded_predictors"}, {"score": 0.0036001255166809793, "phrase": "multi-layer_perceptrons"}, {"score": 0.0033048445033866795, "phrase": "first_one"}, {"score": 0.003211883390828745, "phrase": "simultaneous_modeling"}, {"score": 0.0031573626285069157, "phrase": "large-_and_short-scale_dynamics_information"}, {"score": 0.0029148831519944358, "phrase": "second_one"}, {"score": 0.0028653893877383188, "phrase": "two-stage_strategy"}, {"score": 0.0027689017918347755, "phrase": "different_scales"}, {"score": 0.0026452734009203764, "phrase": "overall_behavior"}, {"score": 0.0026152363154073707, "phrase": "large_scales"}, {"score": 0.0025416235470290286, "phrase": "smooth_curve"}, {"score": 0.0024984517279573906, "phrase": "repeated_application"}, {"score": 0.0024560114164181765, "phrase": "savitzky-golay_filter"}, {"score": 0.002386869729952315, "phrase": "remaining_short-scale_variability"}, {"score": 0.0023329572140896237, "phrase": "bagged_mi-ps"}, {"score": 0.0023064582783867645, "phrase": "expected_error_levels"}, {"score": 0.002178400923036365, "phrase": "test_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["CATS benchmark", " time series analysis", " multilayer perceptrons", " ensembles"], "paper_abstract": "We present a general strategy for filling the missing data of the CATS benchmark time series prediction competition. Our approach builds upon a time-symmetric embedding of this time series and the use of a one-shot forecasting for each missing value inside the gaps from distant-enough delayed and forwarded predictors. In the extrapolation region we perform standard, non-iterated forward predictions. For modeling purposes we consider bagging of multi-layer perceptrons (MI-Ps). We discuss two different implementations of this strategy: The first one is based on a simultaneous modeling of both large- and short-scale dynamics information, using (suitably delayed and forwarded) original CATS values and their first differences as inputs to MLPs. The second one follows a two-stage strategy, in which behaviors at different scales are modeled separately. First, the overall behavior at large scales is fitted with a smooth curve obtained by repeated application of a Savitzky-Golay filter. Then, the remaining short-scale variability is approximated using bagged MI-Ps. Expected error levels for these two implementations are provided according to performance on test data. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Symmetric-embedding prediction of the CATS benchmark", "paper_id": "WOS:000247745000018"}