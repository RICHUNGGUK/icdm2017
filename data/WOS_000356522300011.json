{"auto_keywords": [{"score": 0.04845849110410781, "phrase": "photo-realistic_images"}, {"score": 0.015601229564909044, "phrase": "hlr_descriptor"}, {"score": 0.015425145384343777, "phrase": "appearance_gap"}, {"score": 0.012102405080367092, "phrase": "hlr"}, {"score": 0.010964160720164338, "phrase": "object_boundary_selection_algorithm"}, {"score": 0.00481495049065317, "phrase": "boundary_selection"}, {"score": 0.004598933498016774, "phrase": "fundamental_challenge"}, {"score": 0.004375789703278455, "phrase": "key_factor"}, {"score": 0.004211504818267892, "phrase": "retrieval_performance"}, {"score": 0.003991774582021095, "phrase": "new_line_segment-based_descriptor"}, {"score": 0.0037259623657693794, "phrase": "object_boundary_selection"}, {"score": 0.003531474887552889, "phrase": "piece-wise_line_segments"}, {"score": 0.0032585499655442404, "phrase": "noisy_edges"}, {"score": 0.003208999546225013, "phrase": "shaping_edges"}, {"score": 0.0031360786664165093, "phrase": "object_boundaries"}, {"score": 0.0031121406603482112, "phrase": "multiple_hypotheses"}, {"score": 0.0030414140732789186, "phrase": "hypothetical_edge_selection"}, {"score": 0.003006654007926993, "phrase": "selection_algorithm"}, {"score": 0.002938317647182056, "phrase": "best_combination"}, {"score": 0.0028715299874549245, "phrase": "retrieval_score"}, {"score": 0.00283870598459543, "phrase": "fast_method"}, {"score": 0.002731971103291716, "phrase": "false_matches"}, {"score": 0.002700738055025905, "phrase": "scoring_process"}, {"score": 0.0026596472456182707, "phrase": "spatial_and_coherent_aspects"}, {"score": 0.0025596276616952516, "phrase": "proposed_framework"}, {"score": 0.002540078552743003, "phrase": "public_datasets"}, {"score": 0.0025110337774260773, "phrase": "new_image_dataset"}, {"score": 0.0024258721867522707, "phrase": "sbir_evaluation_purposes"}, {"score": 0.0023798115577749225, "phrase": "proposed_hlr"}, {"score": 0.002290291401956985, "phrase": "shog"}, {"score": 0.002272794656458419, "phrase": "gf-hog"}, {"score": 0.0022382002476510573, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "sbir_performance"}], "paper_keywords": ["Large-scale sketch retrieval", " line segment-based descriptor", " object boundary selection"], "paper_abstract": "The appearance gap between sketches and photo-realistic images is a fundamental challenge in sketch-based image retrieval (SBIR) systems. The existence of noisy edges on photo-realistic images is a key factor in the enlargement of the appearance gap and significantly degrades retrieval performance. To bridge the gap, we propose a framework consisting of a new line segment-based descriptor named histogram of line relationship (HLR) and a new noise impact reduction algorithm known as object boundary selection. HLR treats sketches and extracted edges of photo-realistic images as a series of piece-wise line segments and captures the relationship between them. Based on the HLR, the object boundary selection algorithm aims to reduce the impact of noisy edges by selecting the shaping edges that best correspond to the object boundaries. Multiple hypotheses are generated for descriptors by hypothetical edge selection. The selection algorithm is formulated to find the best combination of hypotheses to maximize the retrieval score; a fast method is also proposed. To reduce the distraction of false matches in the scoring process, two constraints on spatial and coherent aspects are introduced. We tested the HLR descriptor and the proposed framework on public datasets and a new image dataset of three million images, which we recently collected for SBIR evaluation purposes. We compared the proposed HLR with state-of-the-art descriptors (SHoG, GF-HOG). The experimental results show that our HLR descriptor outperforms them. Combined with the object boundary selection algorithm, our framework significantly improves SBIR performance.", "paper_title": "Sketch-Based Image Retrieval Through Hypothesis-Driven Object Boundary Selection With HLR Descriptor", "paper_id": "WOS:000356522300011"}