{"auto_keywords": [{"score": 0.03825304220426715, "phrase": "iswgso"}, {"score": 0.00927693487412733, "phrase": "global_best_member"}, {"score": 0.00823044957411151, "phrase": "small_world_scheme"}, {"score": 0.00481495049065317, "phrase": "improved_small_world"}, {"score": 0.004719473826242326, "phrase": "neural_network_training"}, {"score": 0.004672444473700524, "phrase": "ammonia_synthesis"}, {"score": 0.004625881588444304, "phrase": "group_search_optimization"}, {"score": 0.004579786483433534, "phrase": "gso"}, {"score": 0.004488946121663966, "phrase": "efficient_algorithm"}, {"score": 0.0044219992735047954, "phrase": "global_optimization_problems"}, {"score": 0.004000396172153709, "phrase": "improved_group_search_optimization"}, {"score": 0.003785836059995376, "phrase": "scroungers'_behavior"}, {"score": 0.0036921366375716005, "phrase": "complex_network"}, {"score": 0.003240895431893266, "phrase": "local_best_member"}, {"score": 0.0029463123778313196, "phrase": "dynamic_probability_scheme"}, {"score": 0.002873331232538783, "phrase": "small_world_property"}, {"score": 0.0026516890043911836, "phrase": "different_problems"}, {"score": 0.0026120705848349055, "phrase": "numerical_examples"}, {"score": 0.0025219085140220773, "phrase": "satisfied_performance"}, {"score": 0.0024717881264735477, "phrase": "six_representative_algorithms"}, {"score": 0.002447101794397243, "phrase": "low_and_high_dimension"}, {"score": 0.0022810491620483737, "phrase": "neural_networks"}, {"score": 0.00223570488212345, "phrase": "soft_sensor_model"}, {"score": 0.0021912600076114033, "phrase": "outlet_ammonia_concentration"}, {"score": 0.0021693692831601745, "phrase": "fertilizer_plant"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Group search optimization", " Small world topology", " Neural network", " Ammonia synthesis"], "paper_abstract": "Group search optimization (GSO) is an efficient algorithm for solving global optimization problems, in which a group of scroungers move to global best member directly causing to premature convergence. In this paper, an improved group search optimization (ISWGSO) is proposed to increase the diversity of scroungers' behavior by introducing small world scheme in complex network. In ISWGSO, each scrounger selects a subset of members as its neighbors according to small world scheme, and evolves with the effects of global best member and local best member within neighbors at each iteration. Since the neighbors of each scrounger increases after each iteration, a dynamic probability scheme is designed to keep small world property of the scroungers. Moreover, factorial design (FD) approach is used to select parameters of ISWGSO for different problems. Some numerical examples show that ISWGSO can obtain a satisfied performance in comparison with six representative algorithms on low and high dimension over 23 benchmark functions. Finally, ISWGSO is applied to train the parameters of neural networks to build a soft sensor model for inferring the outlet ammonia concentration in fertilizer plant. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "A group search optimization based on improved small world and its application on neural network training in ammonia synthesis", "paper_id": "WOS:000309318200011"}