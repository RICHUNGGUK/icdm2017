{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "ucs"}, {"score": 0.004177049813981273, "phrase": "data_mining_tasks"}, {"score": 0.003941964605885606, "phrase": "univariate_classification_rule"}, {"score": 0.003623352647973122, "phrase": "large_number"}, {"score": 0.0035106041824568618, "phrase": "input_space"}, {"score": 0.0034738037330064885, "phrase": "artificial_neural_networks"}, {"score": 0.0031262984171100856, "phrase": "straightforward_task"}, {"score": 0.00291923164591297, "phrase": "novel_way"}, {"score": 0.002843284157126913, "phrase": "ucs."}, {"score": 0.002769304577201566, "phrase": "good_compromise"}, {"score": 0.0025994945418484935, "phrase": "simple_artificial_nn"}, {"score": 0.0025586903829811296, "phrase": "classifier's_action"}, {"score": 0.0023146962503449186, "phrase": "reasonable_level"}, {"score": 0.0022307779508260205, "phrase": "negative_correlation"}, {"score": 0.0021273284545701896, "phrase": "resultant_nn_ensemble"}, {"score": 0.002104999656268713, "phrase": "ncl"}], "paper_keywords": ["representations", " evolutionary computing and genetic algorithms", " neural nets", " rule-based processing", " data mining", " classification"], "paper_abstract": "UCS is a s (u) under bar pervised learning (c) under bar lassifier (s) under bar ystem that was introduced in 2003 for classification in data mining tasks. The representation of a rule in UCS as a univariate classification rule is straightforward for a human to understand. However, the system may require a large number of rules to cover the input space. Artificial neural networks ( NNs), on the other hand, normally provide a more compact representation. However, it is not a straightforward task to understand the network. In this paper, we propose a novel way to incorporate NNs into UCS. The approach offers a good compromise between compactness, expressiveness, and accuracy. By using a simple artificial NN as the classifier's action, we obtain a more compact population size, better generalization, and the same or better accuracy while maintaining a reasonable level of expressiveness. We also apply negative correlation learning ( NCL) during the training of the resultant NN ensemble. NCL is shown to improve the generalization of the ensemble.", "paper_title": "Neural-based learning classifier systems", "paper_id": "WOS:000251003300003"}