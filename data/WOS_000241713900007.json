{"auto_keywords": [{"score": 0.04935669810434817, "phrase": "smote"}, {"score": 0.013264346619373228, "phrase": "k-d_trees"}, {"score": 0.008850370743453781, "phrase": "smote_algorithm"}, {"score": 0.005586204314070585, "phrase": "box-assisted_search"}, {"score": 0.00481495049065317, "phrase": "nearest-neighbour_search_strategies"}, {"score": 0.004670722261414736, "phrase": "nearest-neighbour_searches"}, {"score": 0.004600228893803583, "phrase": "key_element"}, {"score": 0.004530794611704416, "phrase": "new_smote_algorithm"}, {"score": 0.00446240364863009, "phrase": "highly_skewed_datasets"}, {"score": 0.00441738161338662, "phrase": "machine_learning"}, {"score": 0.003871653343842317, "phrase": "key_consideration"}, {"score": 0.003606178185661875, "phrase": "empirical_investigations"}, {"score": 0.00349803055484394, "phrase": "k-d"}, {"score": 0.002943502888225748, "phrase": "brute-force_sequential_search_strategy"}, {"score": 0.0028551716387011637, "phrase": "order-of-magnitude_improvement"}, {"score": 0.0027554538693034163, "phrase": "sequential_search"}, {"score": 0.0026057256900479026, "phrase": "magnitude_improvement"}, {"score": 0.002414544068560716, "phrase": "increasing_dataset_size"}, {"score": 0.002203509076886664, "phrase": "increasing_degree"}, {"score": 0.0021049977753042253, "phrase": "neighbour_search_strategy"}], "paper_keywords": ["classification", " data mining", " machine learning", " nearest-neighbour", " oversampling", " performance testing", " resampling", " skewness"], "paper_abstract": "Nearest-neighbour searches are a key element of the new SMOTE algorithm for resampling highly skewed datasets for machine learning. However, at present no work has been done to determine the most efficient and scalable neighbour search to use in the SMOTE algorithm. This question will be a key consideration if SMOTE is to be deployed in extremely large, highly skewed datasets. This paper reports on empirical investigations of two fast neighbour search strategies, namely, K-D trees and box-assisted neighbour searches. The times required to oversample three well-known datasets with SMOTE using these two strategies are compared to each other as well as to the time required for a brute-force sequential search strategy. In general, an order-of-magnitude improvement in execution time is found from sequential search to K-D trees, and a further order-of-magnitude improvement is found from K-D trees to box-assisted search, indicating that the SMOTE algorithm scales best with increasing dataset size when box-assisted search is used. However, it is also observed that SMOTE scales best with an increasing degree of oversampling when K-D trees are used as the neighbour search strategy.", "paper_title": "Comparing nearest-neighbour search strategies in the SMOTE algorithm", "paper_id": "WOS:000241713900007"}