{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "good_probability_estimates"}, {"score": 0.004228016636379321, "phrase": "density_forecasting_models"}, {"score": 0.004073809704022463, "phrase": "machine_learning"}, {"score": 0.003852939975815287, "phrase": "multi-objective_problem"}, {"score": 0.003446353878654566, "phrase": "suitable_scoring_metrics"}, {"score": 0.0032292292848296617, "phrase": "popular_negative_log-likelihood"}, {"score": 0.002731500545019039, "phrase": "optimise_density_forecasting_models"}, {"score": 0.0025592969422491476, "phrase": "multi-objective_evolutionary_optimisation_framework"}, {"score": 0.0024658019116387845, "phrase": "better_density_forecasts"}, {"score": 0.002397923568994474, "phrase": "prediction_user's_perspective"}, {"score": 0.0021049977753042253, "phrase": "risk_management_problem"}], "paper_keywords": [""], "paper_abstract": "In this paper, we show that the optimisation of density forecasting models for regression in machine learning can be formulated as a multi-objective problem. We describe the two objectives of sharpness and calibration and suggest suitable scoring metrics for both. We use the popular negative log-likelihood as a measure of sharpness and the probability integral transform as a measure of calibration. To optimise density forecasting models under multiple criteria we introduce a multi-objective evolutionary optimisation framework that can produce better density forecasts from a prediction user's perspective. Our experiments show improvements over the state-of-the-art on a risk management problem.", "paper_title": "Making good probability estimates for regression", "paper_id": "WOS:000242308000050"}