{"auto_keywords": [{"score": 0.046985412940270525, "phrase": "representative_traces"}, {"score": 0.00481495049065317, "phrase": "hidden_markov_models"}, {"score": 0.004779406424192843, "phrase": "online_learning"}, {"score": 0.004726579360618152, "phrase": "modern_computer_systems"}, {"score": 0.004674333455266527, "phrase": "intermittent_behaviour"}, {"score": 0.004605565335682916, "phrase": "additional_loads"}, {"score": 0.004471035765089235, "phrase": "storage_disks"}, {"score": 0.004438019162720755, "phrase": "remote_servers"}, {"score": 0.0043404186974790706, "phrase": "real_data"}, {"score": 0.004229249483672165, "phrase": "stochastic_models"}, {"score": 0.00407533728096378, "phrase": "effective_solutions"}, {"score": 0.00403026082093352, "phrase": "input_model_parameters"}, {"score": 0.003956234229826621, "phrase": "typical_example"}, {"score": 0.003912469968653304, "phrase": "markov-modulated_poisson_process"}, {"score": 0.0037283301619292636, "phrase": "hidden_markov_model"}, {"score": 0.003566028957296066, "phrase": "bursty_behaviour"}, {"score": 0.003539671663910004, "phrase": "cyclic_patterns"}, {"score": 0.0034875380341306468, "phrase": "internet_traffic"}, {"score": 0.003448940584469061, "phrase": "underlying_properties"}, {"score": 0.0031317713853981064, "phrase": "data_sets"}, {"score": 0.0030514638431036714, "phrase": "online_learning_hmm"}, {"score": 0.0028649616584212026, "phrase": "hmm"}, {"score": 0.0028331500847209984, "phrase": "moving_average_technique"}, {"score": 0.0026012779346272848, "phrase": "multiple_discrete_traces"}, {"score": 0.002562929776267296, "phrase": "onlinehmm"}, {"score": 0.002543967677678384, "phrase": "data_processing_times"}, {"score": 0.0023270490574896804, "phrase": "original_data_points"}, {"score": 0.002309828105129336, "phrase": "hmm-generated_synthetic_traces"}, {"score": 0.002242206465278159, "phrase": "onlinehmm's_adapted_baum-welch_algorithm"}, {"score": 0.002176560171729638, "phrase": "waiting_times"}, {"score": 0.002152440300818582, "phrase": "queueing_model"}], "paper_keywords": ["HMM", " online learning", " adapted Baum-Welch", " autocorrelation", " MMPP"], "paper_abstract": "In modern computer systems, the intermittent behaviour of infrequent, additional loads affects performance. Often, representative traces of storage disks or remote servers can be scarce and obtaining real data is sometimes expensive. Therefore, stochastic models, through simulation and profiling, provide cheaper, effective solutions, where input model parameters are obtained. A typical example is the Markov-modulated Poisson process (MMPP), which can have its time index discretised to form a hidden Markov model (HMM). These models have been successful in capturing bursty behaviour and cyclic patterns of I/O operations and Internet traffic, using underlying properties of the discrete (or continuous) Markov chain. However, learning on such models can be cumbersome in terms of complexity through re-training on data sets. Thus, we provide an online learning HMM (OnlineHMM), which is composed of two existing variations of HMMs: first, a sliding HMM using a moving average technique to update its parameters \"on-the-fly\" and, secondly, a multi-input HMM capable of training on multiple discrete traces simultaneously. The OnlineHMM reduces data processing times significantly and thence synthetic workloads become computationally more cost effective. We measure the accuracy of reproducing representative traces through comparisons of moments and autocorrelation on original data points and HMM-generated synthetic traces. We present, analytically, the training steps saved through the OnlineHMM's adapted Baum-Welch algorithm and obtain, through simulation, mean waiting times of a queueing model. Finally, we conclude our work and offer model extensions for the future.", "paper_title": "Adapting Hidden Markov Models for Online Learning", "paper_id": "WOS:000365198300008"}