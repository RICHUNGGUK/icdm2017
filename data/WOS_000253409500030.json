{"auto_keywords": [{"score": 0.04832350902760219, "phrase": "mmu."}, {"score": 0.015360972322337789, "phrase": "memory_subsystem"}, {"score": 0.012826449796298356, "phrase": "spm"}, {"score": 0.008407854067343389, "phrase": "ideal_case"}, {"score": 0.00481495049065317, "phrase": "dynamic_data"}, {"score": 0.004770211811866158, "phrase": "memory_management"}, {"score": 0.004146716743362567, "phrase": "relatively_cheap_direct-mapped_data_cache"}, {"score": 0.004108164153832002, "phrase": "spm."}, {"score": 0.0040133278382101885, "phrase": "global_data"}, {"score": 0.003976007772514762, "phrase": "stack_pages"}, {"score": 0.003741712498615481, "phrase": "scratchpad_memory_manager"}, {"score": 0.003689628075766217, "phrase": "data_pages"}, {"score": 0.0036213041338584756, "phrase": "page_table"}, {"score": 0.003407839062159497, "phrase": "optimization_techniques"}, {"score": 0.003313592421224647, "phrase": "whole_program"}, {"score": 0.0032370412139943808, "phrase": "data_page_mapping"}, {"score": 0.0031475032122226, "phrase": "integer_linear_programming"}, {"score": 0.003003726508522467, "phrase": "ilp_model"}, {"score": 0.0029618842673339173, "phrase": "dynamic_call_graph"}, {"score": 0.0028799352389969443, "phrase": "memory_accesses"}, {"score": 0.002853124436286834, "phrase": "cache_misses"}, {"score": 0.002735522834514124, "phrase": "thirteen_embedded_applications"}, {"score": 0.00263505298504827, "phrase": "reference_system"}, {"score": 0.002456486927713543, "phrase": "global_and_stack_data"}, {"score": 0.0023223663501882917, "phrase": "total_system_energy_consumption"}, {"score": 0.0022686625017583387, "phrase": "performance_degradation"}, {"score": 0.0021347607855562102, "phrase": "energy_reduction"}, {"score": 0.0021049977753042253, "phrase": "reference_case"}], "paper_keywords": ["algorithms", " management", " measurement", " performance", " design", " experimentation", " compilers", " post-pass optimization", " demand paging", " scratchpad memory", " horizontally-partitioned memory"], "paper_abstract": "In this paper, we propose a dynamic scratchpad memory (SPM) management technique for a horizontally-partitioned memory subsystem with an MMU. The memory subsystem consists of a relatively cheap direct-mapped data cache and SPM. Our technique loads required global data and stack pages into the SPM on demand when a function is called. A scratchpad memory manager loads/unloads the data pages and maintains a page table for the MMU. Our approach is based on post-pass analysis and optimization techniques, and it handles the whole program including libraries. The data page mapping is determined by solving an integer linear programming (ILP) formulation that approximates our demand paging technique. The ILP model uses a dynamic call graph annotated with the number of memory accesses and/or cache misses obtained by profiling. We evaluate our technique on thirteen embedded applications. We compare the results to a reference system with a 4-way set associative data cache and the ideal case with the same 4-way cache and SPM, where all global and stack data is placed in the SPM. On average, our approach reduces the total system energy consumption by 8.1% with no performance degradation. This is equivalent to exploiting 60% of the room available in energy reduction between the reference case and the ideal case.", "paper_title": "Dynamic data scratchpad memory management for a memory subsystem with an MMU", "paper_id": "WOS:000253409500030"}