{"auto_keywords": [{"score": 0.039896298229707874, "phrase": "gpu"}, {"score": 0.03399561978229417, "phrase": "multiple_codewords"}, {"score": 0.004762202897268383, "phrase": "gpu._turbo"}, {"score": 0.004658426838467567, "phrase": "computationally_intensive_channel_code"}, {"score": 0.004506968388996092, "phrase": "current_and_up-coming_wireless_standards"}, {"score": 0.004457579615095599, "phrase": "general-purpose_graphics_processor_unit"}, {"score": 0.004408749967693552, "phrase": "gpgpu"}, {"score": 0.004312622975366672, "phrase": "programmable_commodity_processor"}, {"score": 0.004241914481080374, "phrase": "high_performance_computation_power"}, {"score": 0.003841263262252044, "phrase": "processing_power"}, {"score": 0.0037163053764280077, "phrase": "turbo"}, {"score": 0.0033465923623290034, "phrase": "computational_resources"}, {"score": 0.0030808211830129304, "phrase": "single_codeword"}, {"score": 0.0030470127429039497, "phrase": "multiple_cores"}, {"score": 0.002915437843874821, "phrase": "single_instruction_multiple_data"}, {"score": 0.0028834549200451864, "phrase": "simd"}, {"score": 0.0027286224888843956, "phrase": "shared_memory"}, {"score": 0.002639740960006001, "phrase": "concurrent_multiple_threads"}, {"score": 0.0025963890234079333, "phrase": "frequently_used_data"}, {"score": 0.0023768935613577985, "phrase": "high_snr_regime"}, {"score": 0.0022994427535192492, "phrase": "low_complexity_early_termination_scheme"}, {"score": 0.002261666793030715, "phrase": "average_extrinsic_llr_statistics"}, {"score": 0.002175913488493802, "phrase": "different_workload_partitioning_choices"}, {"score": 0.0021401625519713577, "phrase": "error_correction_performance"}, {"score": 0.0021049977753042253, "phrase": "decoder_throughput"}], "paper_keywords": ["GPGPU", " Turbo decoding", " Accelerator", " Parallel computing", " Wireless", " Error control codes", " Turbo codes"], "paper_abstract": "Turbo code is a computationally intensive channel code that is widely used in current and up-coming wireless standards. General-purpose graphics processor unit (GPGPU) is a programmable commodity processor that achieves high performance computation power by using many simple cores. In this paper, we present a 3GPP LTE compliant Turbo decoder accelerator that takes advantage of the processing power of GPU to offer fast Turbo decoding throughput. Several techniques are used to improve the performance of the decoder. To fully utilize the computational resources on GPU, our decoder can decode multiple codewords simultaneously, divide the workload for a single codeword across multiple cores, and pack multiple codewords to fit the single instruction multiple data (SIMD) instruction width. In addition, we use shared memory judiciously to enable hundreds of concurrent multiple threads while keeping frequently used data local to keep memory access fast. To improve efficiency of the decoder in the high SNR regime, we also present a low complexity early termination scheme based on average extrinsic LLR statistics. Finally, we examine how different workload partitioning choices affect the error correction performance and the decoder throughput.", "paper_title": "Implementation of a High Throughput 3GPP Turbo Decoder on GPU", "paper_id": "WOS:000296797400003"}