{"auto_keywords": [{"score": 0.0323688917290338, "phrase": "drss"}, {"score": 0.029204602169461535, "phrase": "learning_process"}, {"score": 0.00481495049065317, "phrase": "green_vehicular_delay"}, {"score": 0.004689462599037994, "phrase": "tolerant_networks"}, {"score": 0.0046018264570209765, "phrase": "opportunistic_communications"}, {"score": 0.004267287100135339, "phrase": "\"_mechanism"}, {"score": 0.004156012879026324, "phrase": "routing_schemes"}, {"score": 0.004124754315882517, "phrase": "vehicle_networks"}, {"score": 0.004062937864702115, "phrase": "varied_network_environment"}, {"score": 0.0039869632444468036, "phrase": "existing_dtn"}, {"score": 0.0039124037252916055, "phrase": "vehicular_dtns"}, {"score": 0.0036691380448651443, "phrase": "new_focus"}, {"score": 0.003641528016135388, "phrase": "green_communications"}, {"score": 0.0035065523764817143, "phrase": "network_performance"}, {"score": 0.003440945901489461, "phrase": "natural_climate"}, {"score": 0.00340217066797559, "phrase": "energy-efficient_communication_schemes"}, {"score": 0.003251376167695528, "phrase": "energy_consumption"}, {"score": 0.003226899588787952, "phrase": "heat_dissipation"}, {"score": 0.0031190082119319272, "phrase": "directional_routing"}, {"score": 0.003026127736667187, "phrase": "green_vehicle_dtns"}, {"score": 0.0029920129598858545, "phrase": "nash_q-learning_approach"}, {"score": 0.0029360049890445944, "phrase": "energy_efficiency"}, {"score": 0.0027846824619356583, "phrase": "routing_and_scheduling_problem"}, {"score": 0.0027325449069867222, "phrase": "geographic_routing"}, {"score": 0.0027119634978446895, "phrase": "flow_control"}, {"score": 0.0026813808976594183, "phrase": "optimal_direction"}, {"score": 0.002572158343938064, "phrase": "hybrid_method"}, {"score": 0.0025049752758014602, "phrase": "traffic_pattern"}, {"score": 0.002476721068743341, "phrase": "drss_algorithm"}, {"score": 0.0024487847651989128, "phrase": "possible_strategies"}, {"score": 0.0023225152126545067, "phrase": "desired_overall_objective"}, {"score": 0.002287646331988365, "phrase": "stochastic_non-cooperative_game"}, {"score": 0.00227040825063645, "phrase": "on-line_multi-commodity_routing_situations"}, {"score": 0.0022110892229209407, "phrase": "vehicular_dtn"}, {"score": 0.0021944267528581094, "phrase": "predetermined_mobility_model_show"}, {"score": 0.002169667676959813, "phrase": "good_energy_efficiency"}, {"score": 0.002153316680437517, "phrase": "learning_ability"}, {"score": 0.0021049977753042253, "phrase": "delivery_ratio"}], "paper_keywords": ["DTN", " Vehicular networks", " Energy-efficient", " Opportunistic routing", " Scheduling"], "paper_abstract": "The vehicle delay tolerant networks (DTNs) make opportunistic communications by utilizing the mobility of vehicles, where the node makes delay-tolerant based \"carry and forward\" mechanism to deliver the packets. The routing schemes for vehicle networks are challenging for varied network environment. Most of the existing DTN routing including routing for vehicular DTNs mainly focus on metrics such as delay, hop count and bandwidth, etc. A new focus in green communications is with the goal of saving energy by optimizing network performance and ultimately protecting the natural climate. The energy-efficient communication schemes designed for vehicular networks are imminent because of the pollution, energy consumption and heat dissipation. In this paper, we present a directional routing and scheduling scheme (DRSS) for green vehicle DTNs by using Nash Q-learning approach that can optimize the energy efficiency with the considerations of congestion, buffer and delay. Our scheme solves the routing and scheduling problem as a learning process by geographic routing and flow control toward the optimal direction. To speed up the learning process, our scheme uses a hybrid method with forwarding and replication according to traffic pattern. The DRSS algorithm explores the possible strategies, and then exploits the knowledge obtained to adapt its strategy and achieve the desired overall objective when considering the stochastic non-cooperative game in on-line multi-commodity routing situations. The simulation results of a vehicular DTN with predetermined mobility model show DRSS achieves good energy efficiency with learning ability, which can guarantee the delivery ratio within the delay bound.", "paper_title": "Directional routing and scheduling for green vehicular delay tolerant networks", "paper_id": "WOS:000316010900003"}