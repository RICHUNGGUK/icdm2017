{"auto_keywords": [{"score": 0.033466175629276194, "phrase": "ncl"}, {"score": 0.01221954013610041, "phrase": "negatively_correlated_experts"}, {"score": 0.011778004465570868, "phrase": "control_parameter"}, {"score": 0.00481495049065317, "phrase": "regularization_term"}, {"score": 0.004764220976404241, "phrase": "control_negative_correlation"}, {"score": 0.004590820632326585, "phrase": "accurate_neural_networks"}, {"score": 0.004400329132129292, "phrase": "negative_error_correlation"}, {"score": 0.0043080553835735825, "phrase": "generalization_ability"}, {"score": 0.004085713541752114, "phrase": "popular_combining_method"}, {"score": 0.004021267064832957, "phrase": "special_error_function"}, {"score": 0.003957833102043277, "phrase": "simultaneous_training"}, {"score": 0.003916098498242888, "phrase": "nn_experts"}, {"score": 0.00385431710959668, "phrase": "negatively_correlated_nn_experts"}, {"score": 0.003559675269411366, "phrase": "negative_correlation"}, {"score": 0.0031176485976102688, "phrase": "training_algorithm"}, {"score": 0.0029098743621130004, "phrase": "proposed_method"}, {"score": 0.0027159094186967247, "phrase": "error_function"}, {"score": 0.0025892330566358503, "phrase": "better_balance"}, {"score": 0.002561892963059385, "phrase": "bias-variance-covariance_trade-off"}, {"score": 0.0024423826953133844, "phrase": "proposed_hybrid_ensemble_method"}, {"score": 0.0024165896393190224, "phrase": "mnce"}, {"score": 0.002219790619936024, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "original_ensemble_methods"}], "paper_keywords": ["Neural networks ensemble", " Hybrid ensemble method", " Mixture of experts", " Negative correlation learning", " Mixture of negatively correlated experts"], "paper_abstract": "Combining accurate neural networks (NN) in the ensemble with negative error correlation greatly improves the generalization ability. Mixture of experts (ME) is a popular combining method which employs special error function for the simultaneous training of NN experts to produce negatively correlated NN experts. Although ME can produce negatively correlated experts, it does not include a control parameter like negative correlation learning (NCL) method to adjust this parameter explicitly. In this study, an approach is proposed to introduce this advantage of NCL into the training algorithm of ME, i.e., mixture of negatively correlated experts (MNCE). In this proposed method, the capability of a control parameter for NCL is incorporated in the error function of ME, which enables its training algorithm to establish better balance in bias-variance-covariance trade-off and thus improves the generalization ability. The proposed hybrid ensemble method, MNCE, is compared with their constituent methods, ME and NCL, in solving several benchmark problems. The experimental results show that our proposed ensemble method significantly improves the performance over the original ensemble methods.", "paper_title": "Incorporation of a Regularization Term to Control Negative Correlation in Mixture of Experts", "paper_id": "WOS:000305961900003"}