{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "graphical_models"}, {"score": 0.004508286991825192, "phrase": "sensor_network"}, {"score": 0.004190305872545087, "phrase": "strongest_reduction"}, {"score": 0.00411436400374349, "phrase": "medical_decision_making"}, {"score": 0.0038240605592708083, "phrase": "general_practice"}, {"score": 0.0037823114064881357, "phrase": "heuristic-guided_procedures"}, {"score": 0.0036198068824262464, "phrase": "first_efficient_optimal_algorithms"}, {"score": 0.0035153544006182834, "phrase": "probabilistic_graphical_models"}, {"score": 0.0033890026927890058, "phrase": "hidden_variables"}, {"score": 0.00336428077531883, "phrase": "hidden_markov_models"}, {"score": 0.0032196786163178107, "phrase": "optimal_subset"}, {"score": 0.0031267359296488118, "phrase": "optimal_conditional_observation_plan"}, {"score": 0.0030587884803931964, "phrase": "surprising_result"}, {"score": 0.002959617637433, "phrase": "efficient_algorithm"}, {"score": 0.0029380187414193653, "phrase": "chain_graphs"}, {"score": 0.0027405092973494293, "phrase": "optimizing_value"}, {"score": 0.0025562434609873335, "phrase": "information_objective_functions"}, {"score": 0.0024284249875593253, "phrase": "naive_bayes"}, {"score": 0.0022239665922395104, "phrase": "observation_selection"}, {"score": 0.0022077244919858218, "phrase": "multiple_sensors"}, {"score": 0.0021049977753042253, "phrase": "prototype_sensor_network_deployment"}], "paper_keywords": [""], "paper_abstract": "Many real-world decision making tasks require us to choose among several expensive observations. In a sensor network, for example, it is important to select the subset of sensors that is expected to provide the strongest reduction in uncertainty. In medical decision making tasks, one needs to select which tests to administer before deciding on the most effective treatment. It has been general practice to use heuristic-guided procedures for selecting observations. In this paper, we present the first efficient optimal algorithms for selecting observations for a class of probabilistic graphical models. For example, our algorithms allow to optimally label hidden variables in Hidden Markov Models (HMMs). We provide results for both selecting the optimal subset of observations, and for obtaining an optimal conditional observation plan. Furthermore we prove a surprising result: In most graphical models tasks, if one designs an efficient algorithm for chain graphs, such as HMMs, this procedure can be generalized to polytree graphical models. We prove that the optimizing value of information is NP(PP)-hard even for polytrees. It also follows from our results that just computing decision theoretic value of information objective functions, which are commonly used in practice, is a # P-complete problem even on Naive Bayes models (a simple special case of polytrees). In addition, we consider several extensions, such as using our algorithms for scheduling observation selection for multiple sensors. We demonstrate the effectiveness of our approach on several real-world datasets, including a prototype sensor network deployment for energy conservation in buildings.", "paper_title": "Optimal Value of Information in Graphical Models", "paper_id": "WOS:000268477000002"}