{"auto_keywords": [{"score": 0.04915532646265492, "phrase": "object_discrimination"}, {"score": 0.048248278211652, "phrase": "human_brains"}, {"score": 0.0451128146367674, "phrase": "spatio-temporal_activation_patterns"}, {"score": 0.042649152947461764, "phrase": "different_visual_objects"}, {"score": 0.04217208370496877, "phrase": "spatial_patterns"}, {"score": 0.035333597303071174, "phrase": "classification_accuracies"}, {"score": 0.00481495049065317, "phrase": "single-trial_eeg_signals"}, {"score": 0.004758987153057194, "phrase": "visual_object_recognition"}, {"score": 0.004667149874736771, "phrase": "fundamental_cognitive_function"}, {"score": 0.004471270242168067, "phrase": "analysis_approach"}, {"score": 0.004436545340717729, "phrase": "single-trial_electroencephalography"}, {"score": 0.003946766004066276, "phrase": "scalp_eeg"}, {"score": 0.003900853871728297, "phrase": "reconstructed_cortical_sources"}, {"score": 0.0038404642251010797, "phrase": "experiment_participants"}, {"score": 0.0037662852047763112, "phrase": "visual_objects"}, {"score": 0.0035245918797629804, "phrase": "single-trial_eeg"}, {"score": 0.003483573659272443, "phrase": "presented_visual_objects"}, {"score": 0.003298357357267836, "phrase": "quantitative_index"}, {"score": 0.0032472646337850073, "phrase": "spatial_differences"}, {"score": 0.0032094634756436595, "phrase": "brain_activations"}, {"score": 0.0030387767523076528, "phrase": "sources_levels"}, {"score": 0.00300339527261653, "phrase": "higher_classification_accuracies"}, {"score": 0.0029800360974218836, "phrase": "chance_rate"}, {"score": 0.002911039832825817, "phrase": "classification_results"}, {"score": 0.002888396879326153, "phrase": "temporally_non-overlapping_time_intervals"}, {"score": 0.002745438358145758, "phrase": "temporal_changes"}, {"score": 0.002681859084438076, "phrase": "temporal_distribution"}, {"score": 0.0026506222660465104, "phrase": "discriminative_information"}, {"score": 0.002619748321217153, "phrase": "eeg_responses"}, {"score": 0.0025892330566358503, "phrase": "present_pattern_extraction"}, {"score": 0.002519402443228795, "phrase": "computational_model"}, {"score": 0.002499798127196099, "phrase": "single-trial_eeg_data_analysis"}, {"score": 0.0023946630984825207, "phrase": "spatio-temporal_patterns"}, {"score": 0.0023760975028828276, "phrase": "eeg"}, {"score": 0.002311933249234786, "phrase": "discriminative_spatial_areas"}, {"score": 0.0022939396079753463, "phrase": "time_stages"}, {"score": 0.002154930852763048, "phrase": "humans'_cognitive_mechanisms"}, {"score": 0.0021049977753042253, "phrase": "computers'_processing_efficiency"}], "paper_keywords": ["EEG", " spatio-temporal pattern", " object recognition", " single-trial analysis", " visual information processing"], "paper_abstract": "Object discrimination is a fundamental cognitive function for human brains. In this study, we utilized an analysis approach for single-trial electroencephalography (EEG) to analyze the spatio-temporal activation patterns of visual objects processing in human brains, and attempted to apply it to discriminate different visual objects. The spatial patterns were respectively extracted from scalp EEG and the reconstructed cortical sources, while the experiment participants were perceiving 4 different categories of visual objects (faces, buildings, cats and cars). By classifying the patterns extracted from single-trial EEG, the presented visual objects could be discriminated by a computer, and the classification accuracies may provide a quantitative index to evaluate the spatial differences of the brain activations related to different visual objects. Our results demonstrated that the spatial patterns on both the scalp and the sources levels resulted in higher classification accuracies than chance rate. We also examined the classification results using temporally non-overlapping time intervals of different event-related potential (ERP) components. The temporal changes of classification accuracies may reflect the temporal distribution of the discriminative information in the EEG responses. The present pattern extraction and classification methods may compose a computational model for single-trial EEG data analysis in investigations of the spatio-temporal activation patterns for object recognition. These spatio-temporal patterns in EEG may be useful to identifying the discriminative spatial areas and time stages to improve the accuracies and efficiencies of object discrimination. In addition, investigating and utilizing humans' cognitive mechanisms of object recognition may improve computers' processing efficiency of visual information.", "paper_title": "Spatio-temporal pattern analysis of single-trial EEG signals recorded during visual object recognition", "paper_id": "WOS:000297709400006"}