{"auto_keywords": [{"score": 0.040650574499495426, "phrase": "nbsbc"}, {"score": 0.004815607935434171, "phrase": "bayesian"}, {"score": 0.004720717782144015, "phrase": "classification_problems"}, {"score": 0.0046650615456476155, "phrase": "prior_information"}, {"score": 0.004610058444728656, "phrase": "joint_relevance"}, {"score": 0.004046020290832207, "phrase": "predictive_model"}, {"score": 0.003904495523681369, "phrase": "novel_network-based_sparse_bayesian_classifier"}, {"score": 0.003738200814271716, "phrase": "feature_dependencies"}, {"score": 0.0035507457285983268, "phrase": "high-dimensional_feature_space"}, {"score": 0.0034674164050273568, "phrase": "available_training_data"}, {"score": 0.00344007531836105, "phrase": "approximate_bayesian_inference"}, {"score": 0.0033328427701162368, "phrase": "expectation_propagation"}, {"score": 0.0032934951320964276, "phrase": "nbsbc_method"}, {"score": 0.002680556511196791, "phrase": "excellent_predictive_performance"}, {"score": 0.002627985415362773, "phrase": "best_accuracy"}, {"score": 0.0024763626300729575, "phrase": "precipitation_data"}, {"score": 0.0024277864377045995, "phrase": "accurate_and_robust_rankings"}, {"score": 0.0023990982005125763, "phrase": "individual_features"}, {"score": 0.0023150468182777813, "phrase": "classification_problem"}, {"score": 0.002207530926563892, "phrase": "important_factor"}, {"score": 0.0021814396743238176, "phrase": "good_overall_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Network based classification", " Expectation propagation", " Spike and slab", " Markov random field", " Sparsity", " Feature selection"], "paper_abstract": "In some classification problems there is prior information about the joint relevance of groups of features. This knowledge can be encoded in a network whose nodes correspond to features and whose edges connect features that should be either both excluded or both included in the predictive model. In this paper, we introduce a novel network-based sparse Bayesian classifier (NBSBC) that makes use of the information about feature dependencies encoded in such a network to improve its prediction accuracy, especially in problems with a high-dimensional feature space and a limited amount of available training data. Approximate Bayesian inference is efficiently implemented in this model using expectation propagation. The NBSBC method is validated on four real-world classification problems from different domains of application: phonemes, handwritten digits, precipitation records and gene expression measurements. A comparison with state-of-the-art methods (support vector machine, network-based support vector machine and graph lasso) show that NBSBC has excellent predictive performance. It has the best accuracy in three of the four problems analyzed and ranks second in the modeling of the precipitation data. NBSBC also yields accurate and robust rankings of the individual features according to their relevance to the solution of the classification problem considered. The accuracy and stability of these estimates is an important factor in the good overall performance of this method. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Network-based sparse Bayesian classification", "paper_id": "WOS:000286561600014"}