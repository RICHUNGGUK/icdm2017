{"auto_keywords": [{"score": 0.04747975082880788, "phrase": "mc"}, {"score": 0.037932767334820226, "phrase": "intangible_costs"}, {"score": 0.03647358383160278, "phrase": "proposed_algorithm"}, {"score": 0.00481495049065317, "phrase": "waiting_cost"}, {"score": 0.004766388573192505, "phrase": "extant_multiple-cost-sensitive_learning_algorithms"}, {"score": 0.004600228893803583, "phrase": "misclassification_cost"}, {"score": 0.004241771072194993, "phrase": "new_learning_algorithm"}, {"score": 0.003991305899593133, "phrase": "tangible_costs"}, {"score": 0.003912748611166382, "phrase": "tc"}, {"score": 0.0034277338119963886, "phrase": "decision_trees"}, {"score": 0.003393115177189967, "phrase": "training_datasets"}, {"score": 0.0033588449972778004, "phrase": "missing_data"}, {"score": 0.0032088487124106936, "phrase": "different_units"}, {"score": 0.0031284221314354095, "phrase": "split_criterion"}, {"score": 0.0030500051941781034, "phrase": "cost-time_sensitive_decision_trees"}, {"score": 0.002943502888225748, "phrase": "intangible_cost"}, {"score": 0.002840708910768261, "phrase": "missing_values"}, {"score": 0.0028120022457134267, "phrase": "test_datasets"}, {"score": 0.002713788077665689, "phrase": "sequential_test"}, {"score": 0.002672750634553146, "phrase": "batch_test_strategy"}, {"score": 0.0025663181430010686, "phrase": "proposed_method"}, {"score": 0.002540377258232509, "phrase": "extensive_experiments"}, {"score": 0.0024766636161181544, "phrase": "uci_datasets"}, {"score": 0.0024516267507109753, "phrase": "different_missing_rates"}, {"score": 0.002414544068560716, "phrase": "experimental_results"}, {"score": 0.0023066199295447686, "phrase": "existing_ones"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Inductive learning", " Cost-sensitive learning", " Multiple-costs-sensitive learning"], "paper_abstract": "Extant multiple-cost-sensitive learning algorithms are usually designed for dealing with misclassification cost (MC) and test cost (TC) together. This paper outlines a new learning algorithm, called cost-time sensitive classification, designed for minimizing tangible costs (which includes TC and waiting cost (WC)) as well as maximizing the decrease of the intangible costs (also called MC). The proposed algorithm induces decision trees from training datasets with missing data, in which the costs are measured in different units. Firstly, a split criterion is proposed for building cost-time sensitive decision trees, aiming at possibly reducing the intangible cost. Then a hybrid test strategy, which can handle missing values in test datasets, is designed for combining the sequential test with the batch test strategy. To evaluate the efficiency of the proposed method, extensive experiments were conducted on the UCI datasets at different missing rates. The experimental results show that the proposed algorithm achieves better than the existing ones in terms of reducing the intangible costs when taking into account waiting costs. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Cost-sensitive classification with respect to waiting cost", "paper_id": "WOS:000278881300001"}