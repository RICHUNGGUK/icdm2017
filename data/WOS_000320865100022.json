{"auto_keywords": [{"score": 0.041953052650748286, "phrase": "emotion_recognition"}, {"score": 0.00481495049065317, "phrase": "speech_emotion_recognition"}, {"score": 0.004768378525561471, "phrase": "anova_feature_selection_method"}, {"score": 0.0046993598473345395, "phrase": "speech_signal"}, {"score": 0.004631335513513859, "phrase": "linguistic_information"}, {"score": 0.004411588377842043, "phrase": "modern_automatic_speech_recognition_systems"}, {"score": 0.004284755353695709, "phrase": "neutral_style_speech_recognition"}, {"score": 0.0039447744176901054, "phrase": "important_step"}, {"score": 0.003906586074865932, "phrase": "emotional_speech_recognition"}, {"score": 0.0037942165191367366, "phrase": "emotion_recognition_system"}, {"score": 0.003721098220825489, "phrase": "different_factors"}, {"score": 0.003579046565851265, "phrase": "emotional_states"}, {"score": 0.0035443861412929006, "phrase": "selected_features"}, {"score": 0.003493021648360933, "phrase": "also_the_type"}, {"score": 0.0033433365160336842, "phrase": "modular_neural-support_vector_machine"}, {"score": 0.0033111584955896134, "phrase": "svm"}, {"score": 0.003107935254560724, "phrase": "gaussian_mixture_model"}, {"score": 0.0030778231027679464, "phrase": "multi-layer_perceptron_neural_network"}, {"score": 0.0028471655497661528, "phrase": "variations_method"}, {"score": 0.002751751956416832, "phrase": "proposed_modular_scheme"}, {"score": 0.002685558057339722, "phrase": "comparative_study"}, {"score": 0.002659527314613792, "phrase": "different_features"}, {"score": 0.00259554612218815, "phrase": "individual_emotional_state"}, {"score": 0.0025085435314540837, "phrase": "recognition_performance"}, {"score": 0.0024842242921857705, "phrase": "empirical_results"}, {"score": 0.0023546121947302877, "phrase": "average_emotion_recognition_accuracy"}, {"score": 0.002242647404307089, "phrase": "proposed_modular_neural-svm_classifier"}, {"score": 0.0021049977753042253, "phrase": "simulated_monolithic_classifiers"}], "paper_keywords": ["Modular", " Neural network", " SVM", " ANOVA", " Speech emotion recognition"], "paper_abstract": "The speech signal consists of linguistic information and also paralinguistic one such as emotion. The modern automatic speech recognition systems have achieved high performance in neutral style speech recognition, but they cannot maintain their high recognition rate for spontaneous speech. So, emotion recognition is an important step toward emotional speech recognition. The accuracy of an emotion recognition system is dependent on different factors such as the type and number of emotional states and selected features, and also the type of classifier. In this paper, a modular neural-support vector machine (SVM) classifier is proposed, and its performance in emotion recognition is compared to Gaussian mixture model, multi-layer perceptron neural network, and C5.0-based classifiers. The most efficient features are also selected by using the analysis of variations method. It is noted that the proposed modular scheme is achieved through a comparative study of different features and characteristics of an individual emotional state with the aim of improving the recognition performance. Empirical results show that even by discarding 22% of features, the average emotion recognition accuracy can be improved by 2.2%. Also, the proposed modular neural-SVM classifier improves the recognition accuracy at least by 8% as compared to the simulated monolithic classifiers.", "paper_title": "Modular neural-SVM scheme for speech emotion recognition using ANOVA feature selection method", "paper_id": "WOS:000320865100022"}