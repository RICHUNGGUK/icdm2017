{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "monotonic_functions"}, {"score": 0.004739056045644449, "phrase": "previous_analyses"}, {"score": 0.00468912237497774, "phrase": "function_classes"}, {"score": 0.004639712384096822, "phrase": "linear_functions"}, {"score": 0.0038953958723049287, "phrase": "objective_value"}, {"score": 0.0034118234596993836, "phrase": "constant_c"}, {"score": 0.0032355864829403413, "phrase": "decisive_difference"}, {"score": 0.002658863179011018, "phrase": "upper_bound"}, {"score": 0.0024423826953133844, "phrase": "strictly_monotonic_function"}, {"score": 0.002231607958228148, "phrase": "constant_factor_change"}, {"score": 0.002196342933346204, "phrase": "mutation_probability"}, {"score": 0.0021049977753042253, "phrase": "constant_factor"}], "paper_keywords": ["Evolutionary algorithms", " pseudo-Boolean optimization", " runtime analysis", " computational complexity"], "paper_abstract": "Extending previous analyses on function classes like linear functions, we analyze how the simple (1+1) evolutionary algorithm optimizes pseudo-Boolean functions that are strictly monotonic. These functions have the property that whenever only 0-bits are changed to 1, then the objective value strictly increases. Contrary to what one would expect, not all of these functions are easy to optimize. The choice of the constant c in the mutation probability p(n) = c/n can make a decisive difference. We show that if c < 1, then the (1+1) EA finds the optimum of every such function in Theta(n log n) iterations. For c = 1, we can still prove an upper bound of O(n(3/2)). However, for c = 16, we present a strictly monotonic function such that the (1+1) EA with overwhelming probability needs 2(Omega(n)) iterations to find the optimum. This is the first time that we observe that a constant factor change of the mutation probability changes the runtime by more than a constant factor.", "paper_title": "Mutation Rate Matters Even When Optimizing Monotonic Functions", "paper_id": "WOS:000316061600001"}