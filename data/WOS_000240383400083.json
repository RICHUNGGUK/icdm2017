{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "text_classification"}, {"score": 0.04692465823812896, "phrase": "feature_selection"}, {"score": 0.004326624385772596, "phrase": "previous_researches"}, {"score": 0.004121275290411653, "phrase": "information_gain"}, {"score": 0.004041879818641576, "phrase": "mutual_information"}, {"score": 0.0038499929374478125, "phrase": "good_features"}, {"score": 0.0035616743422949766, "phrase": "new_approach"}, {"score": 0.003459191419478298, "phrase": "selection_-_dynamic_feature_selection"}, {"score": 0.0029602552900111433, "phrase": "different_measurements"}, {"score": 0.0028471655497661528, "phrase": "tuning_parameters"}, {"score": 0.002659527314613792, "phrase": "best_feature_set"}, {"score": 0.0025578967205807843, "phrase": "best_performance"}, {"score": 0.0022536005664642294, "phrase": "real-world_data"}, {"score": 0.0021464286727045623, "phrase": "proposed_dynamic_feature_selection"}, {"score": 0.0021049977753042253, "phrase": "traditional_feature_selection_methods"}], "paper_keywords": [""], "paper_abstract": "We study the problem of feature selection in text classification. Previous researches use only a measurement such as information gain, mutual information, chi-square for selecting good features. In this paper we propose a new approach to feature selection - dynamic feature selection. A new algorithm for feature selection is proposed. In this algorithm, by combining different measurements for features and tuning parameters, several feature subsets are generated, the best feature set which achieves the best performance from a classifier is obtained from those. Experiments dealing with the real-world data set show that the proposed dynamic feature selection outperforms traditional feature selection methods.", "paper_title": "Dynamic feature selection in text classification", "paper_id": "WOS:000240383400083"}