{"auto_keywords": [{"score": 0.047929617715279135, "phrase": "multi-classification_problems"}, {"score": 0.004817875140405343, "phrase": "domain"}, {"score": 0.0047057084749407485, "phrase": "support_vector_classifier"}, {"score": 0.004243862930012258, "phrase": "novel_classifier"}, {"score": 0.003916098498242888, "phrase": "proposed_classifier"}, {"score": 0.003697538418750941, "phrase": "bayesian_optimal_decision_theory"}, {"score": 0.0034512514926836667, "phrase": "decision_boundaries"}, {"score": 0.003334309053314909, "phrase": "posterior_probability_distributions"}, {"score": 0.003221316290858497, "phrase": "support_vector_domain_description"}, {"score": 0.002938317647182056, "phrase": "optimal_hyperplanes"}, {"score": 0.00283870598459543, "phrase": "two-class_support_vector_machines"}, {"score": 0.0026191799769765085, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["multi-class classification", " Kernel methods", " Bayes decision theory", " density estimation", " support vector domain description"], "paper_abstract": "In this paper, a novel classifier for multi-classification problems is proposed. The proposed classifier, based on the Bayesian optimal decision theory, tries to model the decision boundaries via the posterior probability distributions constructed from support vector domain description rather than to model them via the optimal hyperplanes constructed from two-class support vector machines. Experimental results show that the proposed method is more accurate and efficient for multi-classification problems. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "Domain described support vector classifier for multi-classification problems", "paper_id": "WOS:000241837300004"}