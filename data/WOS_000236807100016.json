{"auto_keywords": [{"score": 0.0453665111651286, "phrase": "coarse_depth_map"}, {"score": 0.031127679754225243, "phrase": "parallax_magnitude"}, {"score": 0.00481495049065317, "phrase": "robust_ego-motion_estimation"}, {"score": 0.004681226806682058, "phrase": "surface_parallax"}, {"score": 0.0045726187330434025, "phrase": "iterative_algorithm"}, {"score": 0.004301834610818624, "phrase": "parametric_surface_parallax_models"}, {"score": 0.004162703509434786, "phrase": "image_pair"}, {"score": 0.003916098498242888, "phrase": "digital_elevation_map"}, {"score": 0.0037188360359702182, "phrase": "global_ego-motion_constraint"}, {"score": 0.003666776809252461, "phrase": "local_brightness_constancy_constraint"}, {"score": 0.003598492288058048, "phrase": "estimated_camera_motion"}, {"score": 0.003548111729206587, "phrase": "available_depth_estimate"}, {"score": 0.0032756158688245, "phrase": "resulting_surface_parallax_field"}, {"score": 0.003229741076887151, "phrase": "epipolar_field"}, {"score": 0.003125175084962886, "phrase": "previous_motion_estimates"}, {"score": 0.0029816229984366374, "phrase": "depth_map_estimate"}, {"score": 0.0028715299874549245, "phrase": "constant_parallax_model"}, {"score": 0.0028446671971798596, "phrase": "cpm"}, {"score": 0.002778529097886437, "phrase": "smooth_parallax_field"}, {"score": 0.0025171669791790438, "phrase": "confidence_measures"}, {"score": 0.0024356148906608025, "phrase": "estimated_depth_values"}, {"score": 0.0023456351719724957, "phrase": "potentially_incorrect_depth_estimates"}, {"score": 0.002280333649167796, "phrase": "subsequent_iterations"}, {"score": 0.0022589720760078274, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_algorithm"}], "paper_keywords": ["direct methods", " surface parallax", " three-dimensional (3-D) modeling"], "paper_abstract": "We present an iterative algorithm for robustly estimating the ego-motion and refining and updating a coarse depth map using parametric surface parallax models and brightness derivatives extracted from an image pair. Given a coarse depth map acquired by a range-finder or extracted from a digital elevation map (DEM), ego-motion is estimated by combining a global ego-motion constraint and a local brightness constancy constraint. Using the estimated camera motion and the available depth estimate, motion of the three-dimensional (3-D) points is compensated. We utilize the fact that the resulting surface parallax field is an epipolar field, and knowing its direction from the previous motion estimates, estimate its magnitude and use it to refine the depth map estimate. The parallax magnitude is estimated using a constant parallax model (CPM) which assumes a smooth parallax field and a depth based parallax model (DBPM), which models the parallax magnitude using the given depth map. We obtain confidence measures for determining the accuracy of the estimated depth values which are used to remove regions with potentially incorrect depth estimates for robustly estimating ego-motion in subsequent iterations. Experimental results using both synthetic and real data (both indoor and outdoor sequences) illustrate the effectiveness of the proposed algorithm.", "paper_title": "Robust ego-motion estimation and 3-D model refinement using surface parallax", "paper_id": "WOS:000236807100016"}