{"auto_keywords": [{"score": 0.04920178434889582, "phrase": "time_series"}, {"score": 0.00481495049065317, "phrase": "perceptron_weights"}, {"score": 0.00466877910546307, "phrase": "eeg_classification"}, {"score": 0.004444037594955185, "phrase": "neural_network"}, {"score": 0.004178198896815672, "phrase": "percep_tro"}, {"score": 0.004152502093643003, "phrase": "n-based_learning"}, {"score": 0.004076352180903171, "phrase": "better_brain-wave_classification_rates"}, {"score": 0.0039040344230094164, "phrase": "optimal_filtering"}, {"score": 0.0025972447844047515, "phrase": "tikhonov-regularized_linear_model"}, {"score": 0.0025495426598675605, "phrase": "single-layer_neural_network"}, {"score": 0.0025027144548626975, "phrase": "linear-transfer_function"}, {"score": 0.0024116163689723354, "phrase": "tikhonov_regularization"}], "paper_keywords": ["EEG", " individual trials", " Tikhonov regularization", " neural network"], "paper_abstract": "The interpretation of weights in a neural network is seldom straightforward. Recently, we have shown percep tro n-based learning to yield better brain-wave classification rates than learning based on averaging and optimal filtering. By virtue of our implementation, we are able to interpret the weights as a time series and to relate them to prototypes generated by averaging. In this paper, some results of four closely related linear models are shown. They are based on averaging, averaging with filtering, Tikhonov regularization, and a single-layer neural network. We then introduce this interpretation for a Tikhonov-regularized linear model and a single-layer neural network with a linear-transfer function. We show, using Tikhonov regularization as an example, how such an interpretation can be used to gain insight into the mechanisms of various perceptron-based methods. (c) 2006 Elsevier B.V.. All rights reserved.", "paper_title": "Interpretation of perceptron weights as constructed time series for EEG classification", "paper_id": "WOS:000242602300038"}