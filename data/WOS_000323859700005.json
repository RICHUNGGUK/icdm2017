{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "counting_methods"}, {"score": 0.049675053299362525, "phrase": "university_rankings"}, {"score": 0.04907561130245922, "phrase": "paper_count"}, {"score": 0.048679801278110287, "phrase": "citation_count"}, {"score": 0.04327082016500875, "phrase": "institutional_level_research_evaluation"}, {"score": 0.034835313256726196, "phrase": "paper_counts"}, {"score": 0.030787368085973914, "phrase": "whole_counting"}, {"score": 0.004537631845923196, "phrase": "scientific_collaboration"}, {"score": 0.004404994123834589, "phrase": "multiple_authors"}, {"score": 0.004330941610682453, "phrase": "important_methodological_issue"}, {"score": 0.004276216827737399, "phrase": "based_research_evaluation"}, {"score": 0.0040298010803060495, "phrase": "existing_literatures"}, {"score": 0.003503497128638099, "phrase": "first_author"}, {"score": 0.0034299649219748513, "phrase": "corresponding_author"}, {"score": 0.00327356326590461, "phrase": "citation_counts"}, {"score": 0.0032321559007422087, "phrase": "subsequent_university_ranks"}, {"score": 0.0031777570808834213, "phrase": "counting_method_selection"}, {"score": 0.002956562077120703, "phrase": "paper_and_citation_counts"}, {"score": 0.002762423953243486, "phrase": "middle_range"}, {"score": 0.0026929458952693465, "phrase": "upper_or_lower_ranges"}, {"score": 0.0023708445073819277, "phrase": "middle_ranges"}, {"score": 0.0022626276288355432, "phrase": "straight_counting"}, {"score": 0.0022434880661725493, "phrase": "fractional_counting"}, {"score": 0.002224510044064184, "phrase": "better_choices"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Counting method", " University ranking", " Research evaluation", " Paper count", " Citation count"], "paper_abstract": "In an age of intensifying scientific collaboration, the counting of papers by multiple authors has become an important methodological issue in scientometric based research evaluation. Especially, how counting methods influence institutional level research evaluation has not been studied in existing literatures. In this study, we selected the top 300 universities in physics in the 2011 HEEACT Ranking as our study subjects. We compared the university rankings generated from four different counting methods (i.e. whole counting, straight counting using first author, straight counting using corresponding author, and fractional counting) to show how paper counts and citation counts and the subsequent university ranks were affected by counting method selection. The counting was based on the 1988-2008 physics papers records indexed in ISI WoS. We also observed how paper and citation counts were inflated by whole counting. The results show that counting methods affected the universities in the middle range more than those in the upper or lower ranges. Citation counts were also more affected than paper counts. The correlation between the rankings generated from whole counting and those from the other methods were low or negative in the middle ranges. Based on the findings, this study concluded that straight counting and fractional counting were better choices for paper count and citation count in the institutional level research evaluation. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "The influences of counting methods on university rankings based on paper count and citation count", "paper_id": "WOS:000323859700005"}