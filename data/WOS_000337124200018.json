{"auto_keywords": [{"score": 0.04889532068804289, "phrase": "recognition"}, {"score": 0.00481495049065317, "phrase": "fully_automatic_face_alignment"}, {"score": 0.0044219992735047954, "phrase": "intrinsic_structures"}, {"score": 0.0043560464825349275, "phrase": "human_face"}, {"score": 0.004227064760262924, "phrase": "in-plane_transformations"}, {"score": 0.004164007198843467, "phrase": "training_images"}, {"score": 0.004081385289516914, "phrase": "tipca"}, {"score": 0.004000396172153709, "phrase": "image_ensemble"}, {"score": 0.00392100783796804, "phrase": "optimal_eigenspace"}, {"score": 0.003766908559075843, "phrase": "mean_square_error"}, {"score": 0.0037106898330901534, "phrase": "aligned_images"}, {"score": 0.0035648266669315943, "phrase": "feret_facial_image_ensemble"}, {"score": 0.003459191419478298, "phrase": "mutual_promotion"}, {"score": 0.003424677513304057, "phrase": "image_alignment"}, {"score": 0.0033905067962602515, "phrase": "eigenspace_representation"}, {"score": 0.00327356326590461, "phrase": "optimized_coding"}, {"score": 0.003240895431893266, "phrase": "recognition_performance"}, {"score": 0.0031765314093444956, "phrase": "handcrafted_alignment"}, {"score": 0.003129096013910623, "phrase": "facial_landmarks"}, {"score": 0.003097865379563127, "phrase": "experimental_results"}, {"score": 0.0030363332738004454, "phrase": "state-of-the-art_invariant_descriptors"}, {"score": 0.0028446460307503343, "phrase": "oriented_gradient"}, {"score": 0.0027602925235474317, "phrase": "gabor_energy_filter"}, {"score": 0.002678433668156676, "phrase": "classification_methods"}, {"score": 0.0026252106881752067, "phrase": "sparse_representation"}, {"score": 0.0026120705848349055, "phrase": "based_classification"}, {"score": 0.0025473475682739784, "phrase": "support_vector_machine"}, {"score": 0.00242266141176955, "phrase": "tipca-aligned_faces"}, {"score": 0.002362620540317279, "phrase": "manually_eye-aligned_faces"}, {"score": 0.0022810491620483737, "phrase": "ground-truth_alignment"}, {"score": 0.0021262403223013242, "phrase": "face_coding"}, {"score": 0.0021049977753042253, "phrase": "face_recognition"}], "paper_keywords": ["Face alignment", " face coding", " face recognition", " eigenfaces", " principal component analysis"], "paper_abstract": "We develop a transform-invariant PCA (TIPCA) technique which aims to accurately characterize the intrinsic structures of the human face that are invariant to the in-plane transformations of the training images. Specially, TIPCA alternately aligns the image ensemble and creates the optimal eigenspace, with the objective to minimize the mean square error between the aligned images and their reconstructions. The learning from the FERET facial image ensemble of 1,196 subjects validates the mutual promotion between image alignment and eigenspace representation, which eventually leads to the optimized coding and recognition performance that surpasses the handcrafted alignment based on facial landmarks. Experimental results also suggest that state-of-the-art invariant descriptors, such as local binary pattern (LBP), histogram of oriented gradient (HOG), and Gabor energy filter (GEF), and classification methods, such as sparse representation based classification (SRC) and support vector machine (SVM), can benefit from using the TIPCA-aligned faces, instead of the manually eye-aligned faces that are widely regarded as the ground-truth alignment. Favorable accuracies against the state-of-the-art results on face coding and face recognition are reported.", "paper_title": "Transform-Invariant PCA: A Unified Approach to Fully Automatic Face Alignment, Representation, and Recognition", "paper_id": "WOS:000337124200018"}