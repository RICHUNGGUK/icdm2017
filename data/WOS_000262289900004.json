{"auto_keywords": [{"score": 0.03776568475420409, "phrase": "matlab"}, {"score": 0.00481495049065317, "phrase": "matrix_product_on_master-worker_platforms."}, {"score": 0.00468476935399643, "phrase": "efficient_parallel_matrix-product_algorithms"}, {"score": 0.004648222388468414, "phrase": "homogeneous_master-worker_platforms"}, {"score": 0.0041167185402778425, "phrase": "matrix_files"}, {"score": 0.003561017335579207, "phrase": "scilab_clients"}, {"score": 0.003397362086358944, "phrase": "initial_repository"}, {"score": 0.003203294948113915, "phrase": "large_problems"}, {"score": 0.003116551456858777, "phrase": "full_matrix_panels"}, {"score": 0.0030440661915657175, "phrase": "worker_memories"}, {"score": 0.002973261772253616, "phrase": "subsequent_updates"}, {"score": 0.0027060907634889734, "phrase": "square_block"}, {"score": 0.00268493828558848, "phrase": "matrix_elements"}, {"score": 0.0026535183547537655, "phrase": "square_blocks"}, {"score": 0.002531463482341473, "phrase": "blas_routines"}, {"score": 0.00238674051726235, "phrase": "efficient_algorithms"}, {"score": 0.0023680783509308525, "phrase": "resources_election"}, {"score": 0.002232675154416128, "phrase": "result_messages"}, {"score": 0.0021551702945512494, "phrase": "mpi_experiments"}], "paper_keywords": [""], "paper_abstract": "This paper is aimed at designing efficient parallel matrix-product algorithms for homogeneous master-worker platforms. While matrix-product is well-understood for homogeneous 2D-arrays of processors, there are two key hypotheses that render our work original and innovative: - Centralized data. We assume that all matrix files originate from, and must be returned to, the master. The master distributes both data and computations to the workers. Typically, our approach is useful in the context of speeding up MATLAB or SCILAB clients running on a server (which acts as the master and initial repository of files). - Limited memory. Because we investigate the parallelization of large problems, we cannot assume that full matrix panels can be stored in the worker memories and re-used for subsequent updates. The amount of memory available in each worker is expressed as a given number of buffers, where a buffer can store a square block of matrix elements. These square blocks are chosen so as to harness the power of Level 3 BLAS routines; they are of size 80 or 100 on most platforms. We have devised efficient algorithms for resources election (deciding which workers to enroll) and communication ordering (both for input and result messages), and we report a set of MPI experiments conducted on a platform at the University of Tennessee.", "paper_title": "REVISITING MATRIX PRODUCT ON MASTER-WORKER PLATFORMS", "paper_id": "WOS:000262289900004"}