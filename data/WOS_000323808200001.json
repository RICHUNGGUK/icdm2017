{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "noisy_data"}, {"score": 0.004784093722351956, "phrase": "multiple_classifier_systems"}, {"score": 0.004647655812642494, "phrase": "traditional_classifier_learning_algorithms"}, {"score": 0.004603042715684748, "phrase": "unique_classifier"}, {"score": 0.004558855900816642, "phrase": "training_data"}, {"score": 0.004316323233538682, "phrase": "data_corruptions"}, {"score": 0.0042748769561032325, "phrase": "learning_method"}, {"score": 0.0040866404150657005, "phrase": "noisy_training_data"}, {"score": 0.004008516312861836, "phrase": "interesting_method"}, {"score": 0.003957261767109878, "phrase": "individual_problems"}, {"score": 0.003770804164370454, "phrase": "thorough_empirical_studies"}, {"score": 0.0037225777441034936, "phrase": "different_types"}, {"score": 0.003616303279958699, "phrase": "noisy_environments"}, {"score": 0.0035815545681927665, "phrase": "noise_robustness"}, {"score": 0.003468110711566472, "phrase": "performance_results"}, {"score": 0.002895910285227502, "phrase": "varying_noise_robustness"}, {"score": 0.002777156434571452, "phrase": "large_collection"}, {"score": 0.0027593227272966186, "phrase": "noisy_datasets"}, {"score": 0.0026122745966589795, "phrase": "individual_classifiers"}, {"score": 0.002578826749477773, "phrase": "decisions_combination_method"}, {"score": 0.002386922774536045, "phrase": "final_system"}, {"score": 0.002252404639706065, "phrase": "global_performance"}, {"score": 0.00214610313234565, "phrase": "multiple_classifier_system"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Noisy data", " Class noise", " Attribute noise", " Multiple Classifier System", " Classification"], "paper_abstract": "Traditional classifier learning algorithms build a unique classifier from the training data. Noisy data may deteriorate the performance of this classifier depending on the degree of sensitiveness to data corruptions of the learning method. In the literature, it is widely claimed that building several classifiers from noisy training data and combining their predictions is an interesting method of overcoming the individual problems produced by noise in each classifier. This statement is usually not supported by thorough empirical studies considering problems with different types and levels of noise. Furthermore, in noisy environments, the noise robustness of the methods can be more important than the performance results themselves and, therefore, it must be carefully studied. This paper aims to reach conclusions on such aspects focusing on the analysis of the behavior, in terms of performance and robustness, of several Multiple Classifier Systems against their individual classifiers when these are trained with noisy data. In order to accomplish this study, several classification algorithms, of varying noise robustness, will be chosen and compared with respect to their combination on a large collection of noisy datasets. The results obtained show that the success of the Multiple Classifier Systems trained with noisy data depends on the individual classifiers chosen, the decisions combination method and the type and level of noise present in the dataset, but also on the way of creating diversity to build the final system. In most of the cases, they are able to outperform all their single classification algorithms in terms of global performance, even though their robustness results will depend on the way of introducing diversity into the Multiple Classifier System. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Tackling the problem of classification with noisy data using Multiple Classifier Systems: Analysis of the performance and robustness", "paper_id": "WOS:000323808200001"}