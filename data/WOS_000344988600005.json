{"auto_keywords": [{"score": 0.034819156943236694, "phrase": "regional_redundancy"}, {"score": 0.00481495049065317, "phrase": "adaptive_low-rank_approximation"}, {"score": 0.004626255242038005, "phrase": "image_priors"}, {"score": 0.004565007074039171, "phrase": "nonlocal_self-similarity"}, {"score": 0.004524624065803229, "phrase": "low-rank_approximation"}, {"score": 0.004425215632459868, "phrase": "powerful_tools"}, {"score": 0.004386063799793622, "phrase": "image_restoration"}, {"score": 0.004308791766002289, "phrase": "similar_patches"}, {"score": 0.004176813329075736, "phrase": "underlying_low-rank_structure"}, {"score": 0.004066898031169739, "phrase": "rank_minimization"}, {"score": 0.003770869401884267, "phrase": "wide_range"}, {"score": 0.003737485125097945, "phrase": "natural_images"}, {"score": 0.0034194194985380268, "phrase": "data-driven_and_parametric_way"}, {"score": 0.003329368827624161, "phrase": "new_measures"}, {"score": 0.0032706520949775065, "phrase": "nonlocal_patch_rank"}, {"score": 0.0032129675521135616, "phrase": "prior_leads"}, {"score": 0.0031703706626348507, "phrase": "adaptive_image_restoration_method"}, {"score": 0.002992195343569767, "phrase": "latent_fine_details"}, {"score": 0.002874726518572154, "phrase": "adaptive_low-rank"}, {"score": 0.0028492532869274743, "phrase": "sparse_matrix_approximation_algorithm"}, {"score": 0.0027989800906333784, "phrase": "estimated_nonlocal_rank"}, {"score": 0.002761856557698856, "phrase": "patch_matrix"}, {"score": 0.002629889135655667, "phrase": "\"denoise\"_quality"}, {"score": 0.00258347644721642, "phrase": "detail_recovery_step"}, {"score": 0.0025266078302900036, "phrase": "adaptive_joint_kernel_regression_algorithm"}, {"score": 0.002405853977978678, "phrase": "regression_group"}, {"score": 0.0022806798371116698, "phrase": "synthetic_and_real-world_images"}, {"score": 0.00221068461235127, "phrase": "image_deblurring"}, {"score": 0.0021910825909008946, "phrase": "super-resolution_tasks"}, {"score": 0.0021333110194180997, "phrase": "practical_outliers"}, {"score": 0.0021049977753042253, "phrase": "rain_drops"}], "paper_keywords": ["Image restoration", " parametric statistics", " context awareness", " regression analysis", " image coding"], "paper_abstract": "In recent years, image priors based on nonlocal self-similarity and low-rank approximation have been proven as powerful tools for image restoration. Many restoration methods group similar patches as a matrix and recover the underlying low-rank structure from the corrupted matrix via rank minimization. However, both the nonlocally redundant and low-rank properties are highly content dependent, and whether they can faithfully characterize a wide range of natural images still remains unclear. In this paper, we analyze these two properties and provide quantifications of them in a data-driven and parametric way, respectively, obtaining the new measures of regional redundancy and nonlocal patch rank. Leveraging these prior leads to an adaptive image restoration method with content-awareness. In particular, our method iteratively removes outliers and recovers latent fine details. To handle outliers, we propose an adaptive low-rank and sparse matrix approximation algorithm to encourage the estimated nonlocal rank in the patch matrix. The guidance of regional redundancy further gives rise to the \"denoise\" quality. In the detail recovery step, we propose an adaptive joint kernel regression algorithm using the redundancy measure to determine the confidence of each regression group. It also bridges the gap between our online and offline dictionary learning schemes. Experiments on synthetic and real-world images show the efficacy of our method in image deblurring and super-resolution tasks, especially when subject to practical outliers such as rain drops.", "paper_title": "Robust Image Restoration via Adaptive Low-Rank Approximation and Joint Kernel Regression", "paper_id": "WOS:000344988600005"}