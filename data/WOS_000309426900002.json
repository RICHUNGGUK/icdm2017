{"auto_keywords": [{"score": 0.030731841359398184, "phrase": "open_information_extraction"}, {"score": 0.00481495049065317, "phrase": "extracting_information_networks"}, {"score": 0.004740955718554292, "phrase": "blogosphere"}, {"score": 0.004525629293824217, "phrase": "information_networks"}, {"score": 0.004456044928556639, "phrase": "recognizable_entities"}, {"score": 0.004275650416511604, "phrase": "social_media_sites"}, {"score": 0.004145143433523008, "phrase": "state-of-the-art_natural_language_processing_tools"}, {"score": 0.003835972725191194, "phrase": "text-clustering_algorithms"}, {"score": 0.0036996627006622975, "phrase": "information_network"}, {"score": 0.0036052633308076933, "phrase": "new_term-weighting_scheme"}, {"score": 0.0033190180867511605, "phrase": "relation_extraction"}, {"score": 0.003168079471049896, "phrase": "standard_tf.df_scheme"}, {"score": 0.0030554300179552415, "phrase": "pruning_filter"}, {"score": 0.002977419551510206, "phrase": "effective_method"}, {"score": 0.0028273061946184645, "phrase": "curated_online_database"}, {"score": 0.002740885774408238, "phrase": "hand-crafted_evaluation_datasets"}, {"score": 0.0025361866386341796, "phrase": "realistic_conditions"}, {"score": 0.002408265305704217, "phrase": "extensive_experiments"}, {"score": 0.00226322835801988, "phrase": "accuracy_levels"}, {"score": 0.0022283519468680475, "phrase": "state-of-the-art_open_information_extraction_tools"}, {"score": 0.0021049977753042253, "phrase": "better_results"}], "paper_keywords": ["Algorithms", " Experimentation", " Performance", " open information extraction", " relation extraction", " named entities", " domain frequency", " clustering"], "paper_abstract": "We study the problem of automatically extracting information networks formed by recognizable entities as well as relations among them from social media sites. Our approach consists of using state-of-the-art natural language processing tools to identify entities and extract sentences that relate such entities, followed by using text-clustering algorithms to identify the relations within the information network. We propose a new term-weighting scheme that significantly improves on the state-of-the-art in the task of relation extraction, both when used in conjunction with the standard tf.df scheme and also when used as a pruning filter. We describe an effective method for identifying benchmarks for open information extraction that relies on a curated online database that is comparable to the hand-crafted evaluation datasets in the literature. From this benchmark, we derive a much larger dataset which mimics realistic conditions for the task of open information extraction. We report on extensive experiments on both datasets, which not only shed light on the accuracy levels achieved by state-of-the-art open information extraction tools, but also on how to tune such tools for better results.", "paper_title": "Extracting Information Networks from the Blogosphere", "paper_id": "WOS:000309426900002"}