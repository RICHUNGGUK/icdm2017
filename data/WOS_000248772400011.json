{"auto_keywords": [{"score": 0.04950097558699653, "phrase": "convolutive_mixtures"}, {"score": 0.03896845531319547, "phrase": "visual_information"}, {"score": 0.00481495049065317, "phrase": "speech_source_separation"}, {"score": 0.0046993598473345395, "phrase": "audio-visual_speech_source_separation"}, {"score": 0.004586531354697466, "phrase": "visual_speech_processing_techniques"}, {"score": 0.004342430078306461, "phrase": "source_separation_methods"}, {"score": 0.004161553532799662, "phrase": "speech_source"}, {"score": 0.003988180913997414, "phrase": "acoustic_signals"}, {"score": 0.003775803846431323, "phrase": "new_approach"}, {"score": 0.0036627245728600073, "phrase": "separation_methods"}, {"score": 0.003384262486955773, "phrase": "voice_activity_detector"}, {"score": 0.0033433424836298116, "phrase": "vad"}, {"score": 0.0032039415997394817, "phrase": "new_geometric_method"}, {"score": 0.003107935254560724, "phrase": "proposed_audiovisual_method"}, {"score": 0.0029422942175866057, "phrase": "real_spontaneous_speech_utterance"}, {"score": 0.0028890603352364273, "phrase": "difficult_case"}, {"score": 0.0027854565462509095, "phrase": "competing_sources"}, {"score": 0.002751751956416832, "phrase": "highly_non-stationary"}, {"score": 0.0026050445177883005, "phrase": "interference_ratios"}, {"score": 0.002526938673434697, "phrase": "wide_range"}, {"score": 0.002264607102799332, "phrase": "overall_process"}, {"score": 0.00218334762335187, "phrase": "previously_proposed_audio-visual_separation_schemes"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["speech source separation", " convolutive mixtures", " voice activity detector", " visual speech processing", " speech enhancement", " highly non-stationary environments"], "paper_abstract": "Audio-visual speech source separation consists in mixing visual speech processing techniques (e.g., lip parameters tracking) with source separation methods to improve the extraction of a speech source of interest from a mixture of acoustic signals. In this paper, we present a new approach that combines visual information with separation methods based on the sparseness of speech: visual information is used as a voice activity detector (VAD) which is combined with a new geometric method of separation. The proposed audiovisual method is shown to be efficient to extract a real spontaneous speech utterance in the difficult case of convolutive mixtures even if the competing sources are highly non-stationary. Typical gains of 18-20 dB in signal to interference ratios are obtained for a wide range of (2 x 2) and (3 x 3) mixtures. Moreover, the overall process is computationally quite simpler than previously proposed audio-visual separation schemes. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Visual voice activity detection as a help for speech source separation from convolutive mixtures", "paper_id": "WOS:000248772400011"}