{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "bayesian"}, {"score": 0.004717325943509345, "phrase": "canonical_circuits"}, {"score": 0.004558977045730675, "phrase": "parallelized_and_incremental_learning"}, {"score": 0.004316552692395911, "phrase": "bayesian_model"}, {"score": 0.0042579795015449005, "phrase": "parallelized_canonical_circuits"}, {"score": 0.0040040425282442125, "phrase": "cognitive_context"}, {"score": 0.003949693102823493, "phrase": "orthogonal_symbol_representations"}, {"score": 0.0037140731069193896, "phrase": "infinite_sensory_streams"}, {"score": 0.0035648266669315943, "phrase": "new_instance"}, {"score": 0.00332924643541238, "phrase": "last_seen_instance"}, {"score": 0.0032173412933955117, "phrase": "inherently_incremental_and_parallel_qualities"}, {"score": 0.002825251837733693, "phrase": "sensory_stream"}, {"score": 0.0027116246112603875, "phrase": "non-stationary_distributions"}, {"score": 0.0025076952838679082, "phrase": "metropolis-hastings"}, {"score": 0.002463906556781983, "phrase": "novel_bayesian_inference_method"}, {"score": 0.0023167153974120083, "phrase": "data_stream"}, {"score": 0.002238767763626708, "phrase": "particle_filters"}, {"score": 0.0021932609696277937, "phrase": "bayesian_neural_network_application"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Neocortical canonical circuits", " Bayesian brain", " Symbolic abstraction", " Incremental Metropolis-Hastings", " Data stream learning"], "paper_abstract": "We present a Bayesian model for parallelized canonical circuits in the neocortex, which can partition a cognitive context into orthogonal symbol representations. The model is capable of learning from infinite sensory streams, updating itself with every new instance and without having to keep instances older than the last seen instance per symbol. The inherently incremental and parallel qualities of the model, allow it to scale to any number of symbols as they appear in the sensory stream, and to transparently follow non-stationary distributions for existing symbols. These qualities are made possible in part by a novel Bayesian inference method, which can run Metropolis-Hastings incrementally on a data stream, and significantly outperforms particle filters in a Bayesian neural network application. (c) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A Bayesian model for canonical circuits in the neocortex for parallelized and incremental learning of symbol representations", "paper_id": "WOS:000356105100014"}