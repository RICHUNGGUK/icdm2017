{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "two-player_zero-sum_markov_games"}, {"score": 0.0044026610128451256, "phrase": "n-agent_reinforcement_learning"}, {"score": 0.004342535250083992, "phrase": "rl"}, {"score": 0.0042536217109111945, "phrase": "littman"}, {"score": 0.004025531820226182, "phrase": "multi-agent_reinforcement_learning"}, {"score": 0.0037834649508375544, "phrase": "machine_learning"}, {"score": 0.003459191419478298, "phrase": "two-agent_zero-sum_problems"}, {"score": 0.0032510690712452147, "phrase": "minimax-q_algorithm"}, {"score": 0.003140888248194296, "phrase": "rl_algorithms"}, {"score": 0.0026253228264228965, "phrase": "minimax"}, {"score": 0.002433452925361333, "phrase": "python"}, {"score": 0.0022710523337245337, "phrase": "optimal_mixed_policies"}, {"score": 0.0021490449563443025, "phrase": "surprisingly_simple_and_cheap_updating_rule"}], "paper_keywords": ["Reinforcement learning", " Q-Learning", " Markov games", " Two-player zero-sum games", " Multi-agent"], "paper_abstract": "Markov games is a framework which can be used to formalise n-agent reinforcement learning (RL). Littman (Markov games as a framework for multi-agent reinforcement learning, in: Proceedings of the 11th International Conference on Machine Learning (ICML-94), 1994.) uses this framework to model two-agent zero-sum problems and, within this context, proposes the minimax-Q algorithm. This paper reviews RL algorithms for two-player zero-sum Markov games and introduces a new, simple, fast. algorithm, called 2L(2).2L(2) is compared to several standard algorithms (Q-learning, Minimax and minimax-Q) implemented with the)ash library written in Python. The experiments show that 222 converges empirically to optimal mixed policies, as minimax-Q, but uses a surprisingly simple and cheap updating rule. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "2L(2), a simple reinforcement learning scheme for two-player zero-sum Markov games", "paper_id": "WOS:000264993200013"}