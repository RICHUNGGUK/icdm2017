{"auto_keywords": [{"score": 0.046448599314105624, "phrase": "answering_systems"}, {"score": 0.00481495049065317, "phrase": "lexical_and_surface_features"}, {"score": 0.004674952036988355, "phrase": "information_retrieval_systems"}, {"score": 0.004583878086896926, "phrase": "keyword_match"}, {"score": 0.004385367803204002, "phrase": "short_passages"}, {"score": 0.004342430078306461, "phrase": "direct_answers"}, {"score": 0.004154332348800334, "phrase": "whole_pages"}, {"score": 0.003954837422946628, "phrase": "manually_designed_hierarchies"}, {"score": 0.003916098498242888, "phrase": "question_types"}, {"score": 0.0037463983616303786, "phrase": "fixed_type"}, {"score": 0.003548905904860611, "phrase": "type_yield_keywords"}, {"score": 0.0035141291835319682, "phrase": "predictive_annotations"}, {"score": 0.0034118234596993836, "phrase": "indexed_answer_passages"}, {"score": 0.003247868216333148, "phrase": "machine_learning"}, {"score": 0.003168859801438632, "phrase": "simple_log-linear_model"}, {"score": 0.003091767402370757, "phrase": "feature_vectors"}, {"score": 0.0028016507334576216, "phrase": "lexical_network"}, {"score": 0.0027741761880779535, "phrase": "surface_context"}, {"score": 0.0027334673433027086, "phrase": "named_entity_extraction"}, {"score": 0.002640781900605126, "phrase": "direct_supervision"}, {"score": 0.0025638362414466278, "phrase": "fixed_entity_types"}, {"score": 0.0024891269874339553, "phrase": "log-linear_model"}, {"score": 0.0024405312482831646, "phrase": "candidate_passages"}, {"score": 0.002404706573379854, "phrase": "substantial_improvement"}, {"score": 0.0023694065215394593, "phrase": "mean_rank"}, {"score": 0.002323142666222693, "phrase": "first_answer"}, {"score": 0.0022665781920241245, "phrase": "model_parameters"}, {"score": 0.0022223176391038785, "phrase": "linguistic_artifacts"}, {"score": 0.0021049977753042253, "phrase": "better_annotation"}], "paper_keywords": [""], "paper_abstract": "Information retrieval systems, based on keyword match, are evolving to question answering systems that return short passages or direct answers to questions, rather than URLs pointing to whole pages. Most open-domain question answering systems depend on manually designed hierarchies of question types. A question is first classified to a fixed type, and then hand-engineered rules associated with the type yield keywords and/or predictive annotations that are likely to match indexed answer passages. Here we seek a more data-driven approach, assisted by machine learning. We propose a simple log-linear model over a pair of feature vectors, one derived from the question and the other derived from the a candidate passage. Features are extracted using a lexical network and surface context as in named entity extraction, except that there is no direct supervision available in the form of fixed entity types and their examples. Using the log-linear model, we filter candidate passages and see substantial improvement in the mean rank at which the first answer is found. The model parameters distill and reveal linguistic artifacts coupling questions and their answers, which can be used for better annotation and indexing.", "paper_title": "Discovering links between lexical and surface features in questions and answers", "paper_id": "WOS:000243032800008"}