{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "expressive_music_performances"}, {"score": 0.04939024695118498, "phrase": "monophonic_jazz_melodies"}, {"score": 0.004478308876320956, "phrase": "machine_learning_approach"}, {"score": 0.00393032656248792, "phrase": "expressive_performance"}, {"score": 0.0030267296900520217, "phrase": "acoustic_features"}, {"score": 0.0029830992938695007, "phrase": "monophonic_recordings"}, {"score": 0.002655894070657161, "phrase": "expressive_performance_rules"}, {"score": 0.002598652897946253, "phrase": "extracted_acoustic_features"}, {"score": 0.0023303871145705954, "phrase": "inexpressive_melody_descriptions"}, {"score": 0.0022801453935251503, "phrase": "induced_expressive_transformation_model"}, {"score": 0.0021049977753042253, "phrase": "expressive_transformation_model"}], "paper_keywords": ["machine learning", " expressive performance"], "paper_abstract": "In this paper we present a machine learning approach to modeling the knowledge applied by a musician when performing a score in order to produce an expressive performance of a piece. We describe a tool for both generating and explaining expressive music performances of monophonic Jazz melodies. The tool consists of three components: (a) a melodic transcription component which extracts a set of acoustic features from monophonic recordings, (b) a machine learning component which induce both an expressive transformation model and a set of expressive performance rules from the extracted acoustic features, and (c) a melody synthesis component which generates expressive monophonic output (MIDI or audio) from inexpressive melody descriptions using the induced expressive transformation model. We compare several machine learning techniques we have explored for inducing the expressive transformation model.", "paper_title": "A tool for generating and explaining expressive music performances of monophonic jazz melodies", "paper_id": "WOS:000239645600009"}