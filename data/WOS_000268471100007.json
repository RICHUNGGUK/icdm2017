{"auto_keywords": [{"score": 0.04441767029254781, "phrase": "program_versions"}, {"score": 0.03595039751104032, "phrase": "compiler_writer"}, {"score": 0.00481495049065317, "phrase": "compiler_optimizations"}, {"score": 0.004740126725341152, "phrase": "embedded_compilation"}, {"score": 0.00452252857066346, "phrase": "run_time_performance"}, {"score": 0.004487241576747549, "phrase": "self-tuned_libraries"}, {"score": 0.0044002186469797476, "phrase": "machine_learning"}, {"score": 0.004331811712726697, "phrase": "multiple_compiled_program_versions"}, {"score": 0.0041167185402778425, "phrase": "best_performance"}, {"score": 0.0036600862989330106, "phrase": "different_versions"}, {"score": 0.0032924448113309797, "phrase": "incorrect_results"}, {"score": 0.0030440661915657175, "phrase": "prior_works"}, {"score": 0.0029500270981001058, "phrase": "compiled_version"}, {"score": 0.0029040994533437903, "phrase": "fixed_number"}, {"score": 0.0027167292419065514, "phrase": "sequential_sampling_plan"}, {"score": 0.0023038997972591193, "phrase": "best_optimization_settings"}, {"score": 0.0022414566728770745, "phrase": "brute_force"}, {"score": 0.002223927963267319, "phrase": "constant_sampling_size_approach"}], "paper_keywords": ["Measurement", " Performance", " Iterative Compilation", " Statistics"], "paper_abstract": "Many problems in embedded compilation require one set of optimizations to be selected over another based on run time performance. Self-tuned libraries, iterative compilation and machine learning techniques all compare multiple compiled program versions. In each, program versions are timed to determine which has the best performance. The program needs to be run multiple times for each version because there is noise inherent in most performance measurements. The number of runs must be enough to compare different versions, despite the noise, but executing more than this will waste time and energy. The compiler writer must either risk taking too few runs, potentially getting incorrect results, or taking too many runs increasing the time for their experiments or reducing the number of program versions evaluated. Prior works choose constant size sampling plans where each compiled version is executed a fixed number of times without regard to the level of noise. In this paper we develop a sequential sampling plan which can automatically adapt to the experiment so that the compiler writer can have both confidence in the results and also be sure that no more runs were taken than were needed. We show that our system is able to correctly determine the best optimization settings with between 76% and 87% fewer runs than needed by a brute force, constant sampling size approach. We also compare our approach to JavaSTATS(10); we needed 77% to 89% fewer runs than it needed.", "paper_title": "Raced Profiles: Efficient Selection of Competing Compiler Optimizations", "paper_id": "WOS:000268471100007"}