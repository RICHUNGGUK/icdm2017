{"auto_keywords": [{"score": 0.049226991195811136, "phrase": "hand_gestures"}, {"score": 0.00481495049065317, "phrase": "hand_gesture_recognition_systems"}, {"score": 0.004628400269774981, "phrase": "commonly_used_human-computer_interfaces"}, {"score": 0.0042459818200777846, "phrase": "multimedia_applications"}, {"score": 0.004081385289516914, "phrase": "hand_gesture_recognition"}, {"score": 0.004037608759610068, "phrase": "human-computer_interaction_scenarios"}, {"score": 0.00397996666534913, "phrase": "natural_data"}, {"score": 0.003951453722517865, "phrase": "synthetic_data"}, {"score": 0.0038810583785936505, "phrase": "art_dictionaries"}, {"score": 0.0038119123317396954, "phrase": "single-pose_and_multiple-pose_gestures"}, {"score": 0.003598786417573615, "phrase": "data_types"}, {"score": 0.0035729944980593324, "phrase": "static_pose_videos"}, {"score": 0.0035473867669654174, "phrase": "gesture_execution_videos"}, {"score": 0.003459191419478298, "phrase": "eleven_users"}, {"score": 0.003397535839387366, "phrase": "time-of-flight_camera"}, {"score": 0.003361069456060196, "phrase": "synthetically_generated_gesture_images"}, {"score": 0.0033249931673591457, "phrase": "novel_collection"}, {"score": 0.0033011569787033297, "phrase": "critical_factors"}, {"score": 0.0031277316566463978, "phrase": "temporal_coherence"}, {"score": 0.002984794722633428, "phrase": "special_attention"}, {"score": 0.002931569771634119, "phrase": "scalability_factor"}, {"score": 0.002889672003089062, "phrase": "simple_method"}, {"score": 0.0028586409810976367, "phrase": "synthetic_generation"}, {"score": 0.0028381384547894865, "phrase": "depth_images"}, {"score": 0.0027181663098561066, "phrase": "new_dictionaries"}, {"score": 0.0026410082462069596, "phrase": "new_users"}, {"score": 0.0024399036842105205, "phrase": "presented_dataset"}, {"score": 0.002396371892825691, "phrase": "separability_study"}, {"score": 0.002370625627299064, "phrase": "pose-based_gestures"}, {"score": 0.0023033100935570755, "phrase": "resulting_corpus"}, {"score": 0.002135542806459067, "phrase": "significant_evaluation_scenario"}, {"score": 0.0021202154023229123, "phrase": "different_kinds"}, {"score": 0.0021049977753042253, "phrase": "hand_gesture_recognition_solutions"}], "paper_keywords": ["Hand gesture dataset", " Hand gesture recognition", " Pose-based", " Motion-based", " Human-computer interaction"], "paper_abstract": "The use of hand gestures offers an alternative to the commonly used human-computer interfaces (i.e. keyboard, mouse, gamepad, voice, etc.), providing a more intuitive way of navigating among menus and in multimedia applications. This paper presents a dataset for the evaluation of hand gesture recognition approaches in human-computer interaction scenarios. It includes natural data and synthetic data from several State of the Art dictionaries. The dataset considers single-pose and multiple-pose gestures, as well as gestures defined by pose and motion or just by motion. Data types include static pose videos and gesture execution videos-performed by a set of eleven users and recorded with a time-of-flight camera-and synthetically generated gesture images. A novel collection of critical factors involved in the creation of a hand gestures dataset is proposed: capture technology, temporal coherence, nature of gestures, representativeness, pose issues and scalability. Special attention is given to the scalability factor, proposing a simple method for the synthetic generation of depth images of gestures, making possible the extension of a dataset with new dictionaries and gestures without the need of recruiting new users, as well as providing more flexibility in the point-of-view selection. The method is validated for the presented dataset. Finally, a separability study of the pose-based gestures of a dictionary is performed. The resulting corpus, which exceeds in terms of representativity and scalability the datasets existing in the State Of Art, provides a significant evaluation scenario for different kinds of hand gesture recognition solutions.", "paper_title": "A natural and synthetic corpus for benchmarking of hand gesture recognition systems", "paper_id": "WOS:000334447600008"}