{"auto_keywords": [{"score": 0.047204374599249324, "phrase": "generalization_ability"}, {"score": 0.04635812308950541, "phrase": "gp"}, {"score": 0.041546884536821496, "phrase": "original_training_data"}, {"score": 0.028346932181690307, "phrase": "functional_complexity"}, {"score": 0.00481495049065317, "phrase": "gp_generalization"}, {"score": 0.0047468516620285525, "phrase": "variance-based_layered_learning_approach"}, {"score": 0.004613516457919661, "phrase": "new_method"}, {"score": 0.004483909657713567, "phrase": "genetic_programming"}, {"score": 0.0043786774510943625, "phrase": "symbolic_regression_problems"}, {"score": 0.004316722156877335, "phrase": "variance-based_layered"}, {"score": 0.00370780481244907, "phrase": "suitable_complexity_measure"}, {"score": 0.0036553070575015344, "phrase": "last_primitive_dataset"}, {"score": 0.0034037221513153566, "phrase": "evolution_process"}, {"score": 0.00332375606483146, "phrase": "first_layer"}, {"score": 0.003036595866130997, "phrase": "gp_engine"}, {"score": 0.002787406053363446, "phrase": "output_values"}, {"score": 0.002546466113418944, "phrase": "smoother_training_data"}, {"score": 0.0021049977753042253, "phrase": "obtained_solutions"}], "paper_keywords": ["Genetic programming", " Generalization", " Layered learning", " Overfitting", " Variance"], "paper_abstract": "This paper introduces a new method that improves the generalization ability of genetic programming (GP) for symbolic regression problems, named variance-based layered learning GP. In this approach, several datasets, called primitive training sets, are derived from the original training data. They are generated from less complex to more complex, for a suitable complexity measure. The last primitive dataset is still less complex than the original training set. The approach decomposes the evolution process into several hierarchical layers. The first layer of the evolution starts using the least complex (smoothest) primitive training set. In the next layers, more complex primitive sets are given to the GP engine. Finally, the original training data is given to the algorithm. We use the variance of the output values of a function as a measure of the functional complexity. This measure is utilized in order to generate smoother training data, and controlling the functional complexity of the solutions to reduce the overfitting. The experiments, conducted on four real-world and three artificial symbolic regression problems, demonstrate that the approach enhances the generalization ability of the GP, and reduces the complexity of the obtained solutions.", "paper_title": "Improving GP generalization: a variance-based layered learning approach", "paper_id": "WOS:000349966600003"}