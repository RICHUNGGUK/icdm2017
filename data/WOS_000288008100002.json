{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "neural_network"}, {"score": 0.004490552331642995, "phrase": "noisy_approximation"}, {"score": 0.004324985524216987, "phrase": "original_information"}, {"score": 0.004233119608341877, "phrase": "particular_example"}, {"score": 0.003990385737207714, "phrase": "vector_symbolic_architectures"}, {"score": 0.0037615180375561805, "phrase": "fixed-length_vector_representation"}, {"score": 0.003451766520526601, "phrase": "resulting_noisy_representation"}, {"score": 0.0031335830806256777, "phrase": "symbolic_manipulations"}, {"score": 0.003034158379493625, "phrase": "biologically_plausible_neurons"}, {"score": 0.002937879003671346, "phrase": "first_spiking_neuron_model"}, {"score": 0.002890887778279196, "phrase": "cleanup_process"}, {"score": 0.0027841357057119295, "phrase": "ideal_performance"}, {"score": 0.002724909017963099, "phrase": "neural_requirements"}, {"score": 0.0026242699269026204, "phrase": "distinct_symbols"}, {"score": 0.002460295872115956, "phrase": "biological_model"}, {"score": 0.0021975548867457623, "phrase": "full_neural_implementation"}, {"score": 0.002174041708084857, "phrase": "symbolic_reasoning"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Auto-associative memory", " Neural engineering framework", " Vector Symbolic Architectures", " Holographic reduced representation"], "paper_abstract": "Methods for \"cleaning up\" (or recognizing) states of a neural network are crucial for the functioning of many neural cognitive models. This process takes a noisy approximation of a state and recovers the original information. As a particular example, we consider the cleanup required for the use of Vector Symbolic Architectures, which provide a method for manipulating symbols using a fixed-length vector representation. To recognize the result of these manipulations, a mechanism for cleaning up the resulting noisy representation is needed, as this noise increases with the number of symbols being combined. While these symbolic manipulations have previously been modelled with biologically plausible neurons, this paper presents the first spiking neuron model of the cleanup process. We demonstrate that it approaches ideal performance and that the neural requirements scale linearly with the number of distinct symbols in the system. While this result is relevant for any biological model requiring cleanup, it is crucial for VSAs, as it completes the set of mechanisms needed to provide a full neural implementation of symbolic reasoning. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "A biologically realistic cleanup memory: Autoassociation in spiking neurons", "paper_id": "WOS:000288008100002"}