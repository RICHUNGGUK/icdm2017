{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "semantic_interpretation"}, {"score": 0.004337276328199398, "phrase": "human_activity"}, {"score": 0.004058180509184539, "phrase": "video_analysis_tasks"}, {"score": 0.0035525230119401153, "phrase": "integrated_system"}, {"score": 0.003419943984098415, "phrase": "natural_language_interpretation"}, {"score": 0.003051073364818384, "phrase": "low-level_image_components"}, {"score": 0.002909342017421165, "phrase": "object_tracking"}, {"score": 0.0027218799769229596, "phrase": "high-level_processes"}, {"score": 0.0026452734009203764, "phrase": "spatio-temporal_object_relationship_generation"}, {"score": 0.0024513404432665153, "phrase": "activity_reasoning"}, {"score": 0.002382329940096419, "phrase": "task-oriented_approach"}, {"score": 0.0021049977753042253, "phrase": "situation_context"}], "paper_keywords": ["Activity interpretation", " Cognitive vision", " System integration", " Semantic interpretation", " Task orientation"], "paper_abstract": "Interpretation of human activity is primarily known from surveillance and video analysis tasks and concerned with the persons alone. In this paper we present an integrated system that gives a natural language interpretation of activities where a person handles objects. The system integrates low-level image components such as hand and object tracking, detection and recognition, with high-level processes such as spatio-temporal object relationship generation, posture and gesture recognition, and activity reasoning. A task-oriented approach focuses processing to achieve near real-time and to react depending on the situation context. (C) 2008 Elsevier Inc. All rights reserved.", "paper_title": "Integrated vision system for the semantic interpretation of activities where a person handles objects", "paper_id": "WOS:000265424800002"}