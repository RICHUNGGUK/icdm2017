{"auto_keywords": [{"score": 0.03076620360242571, "phrase": "proposed_lip_reading_system"}, {"score": 0.00481495049065317, "phrase": "isolated_korean_word_recognition"}, {"score": 0.0047057084749407485, "phrase": "real-time_lip_reading_system"}, {"score": 0.004616560363089716, "phrase": "lip_detector"}, {"score": 0.0043258453436258405, "phrase": "isolated_korean_words"}, {"score": 0.0042928648367867835, "phrase": "lip_detection"}, {"score": 0.0038271712887391015, "phrase": "lip_tracking"}, {"score": 0.0037402558657576124, "phrase": "novel_two-stage_lip_tracking_method"}, {"score": 0.003683407561208816, "phrase": "model-based_lucas-kanade_feature_tracker"}, {"score": 0.0035997452281985465, "phrase": "outer_lip"}, {"score": 0.003531474887552889, "phrase": "fast_block"}, {"score": 0.0035179764329354877, "phrase": "matching_algorithm"}, {"score": 0.003438058620195309, "phrase": "inner_lip"}, {"score": 0.0034118234596993836, "phrase": "lip_activation_detection"}, {"score": 0.003347105144425849, "phrase": "neural_network_classifier"}, {"score": 0.003208999546225013, "phrase": "lip_motion_energy_function"}, {"score": 0.0031723302551782324, "phrase": "first_dominant_shape_feature"}, {"score": 0.0031240868074933078, "phrase": "last_step"}, {"score": 0.0031002400518251936, "phrase": "input_words"}, {"score": 0.0030067439234328424, "phrase": "hmm"}, {"score": 0.002984058246917683, "phrase": "ann"}, {"score": 0.002949598976902438, "phrase": "k-nn."}, {"score": 0.0027741761880779535, "phrase": "noisy_environments"}, {"score": 0.002711109302199029, "phrase": "potential_applicability"}, {"score": 0.002680114113899346, "phrase": "combined_system"}, {"score": 0.0026091594819333654, "phrase": "-vehicle_navigation_devices"}, {"score": 0.0025110337774260773, "phrase": "k-nn_classifier"}, {"score": 0.002325689073229477, "phrase": "person-dependent_tests"}, {"score": 0.0022640963589007457, "phrase": "person-independent_tests"}, {"score": 0.0022211005680689666, "phrase": "combined_audio-visual_asr_system"}, {"score": 0.002195702341957028, "phrase": "wcr"}, {"score": 0.0021539955106204354, "phrase": "noisy_environment"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Lip reading", " Two-stage lip tracking", " Word classifier", " Automatic speech recognition", " Audio-visual ASR"], "paper_abstract": "This paper proposes a real-time lip reading system (consisting of a lip detector, lip tracker, lip activation detector, and word classifier), which can recognize isolated Korean words. Lip detection is performed in several stages: face detection, eye detection, mouth detection, mouth end-point detection, and active appearance model (MM) fitting. Lip tracking is then undertaken via a novel two-stage lip tracking method, where the model-based Lucas-Kanade feature tracker is used to track the outer lip, and then a fast block matching algorithm is used to track the inner lip. Lip activation detection is undertaken through a neural network classifier, the input for which being a combination of the lip motion energy function and the first dominant shape feature. In the last step, input words are defined and recognized by three different classifiers: HMM, ANN, and K-NN. We combine the proposed lip reading system with an audio-only automatic speech recognition (ASR) system to improve the word recognition performance in the noisy environments. We then demonstrate the potential applicability of the combined system for use within hands free in-vehicle navigation devices. Results from experiments undertaken on 30 isolated Korean words using the K-NN classifier at a speed of 15 fps demonstrate that the proposed lip reading system achieves a 92.67% word correct rate (WCR) for person-dependent tests, and a 46.50% WCR for person-independent tests. Also, the combined audio-visual ASR system increases the WCR from 0% to 60% in a noisy environment. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Real-time lip reading system for isolated Korean word recognition", "paper_id": "WOS:000285233300006"}