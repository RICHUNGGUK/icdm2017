{"auto_keywords": [{"score": 0.04625542344475719, "phrase": "speech_recognition"}, {"score": 0.00481495049065317, "phrase": "word_recognition"}, {"score": 0.00477513738640734, "phrase": "windowed_bernoulli_hmms"}, {"score": 0.004735651915966323, "phrase": "hidden_markov_models"}, {"score": 0.004561950666122737, "phrase": "off-line_handwriting_recognition"}, {"score": 0.0042157995925335544, "phrase": "symbol_level"}, {"score": 0.004163587877500036, "phrase": "state-conditional_probability_density_functions"}, {"score": 0.00411214295811269, "phrase": "hmm"}, {"score": 0.004044251230868813, "phrase": "gaussian_mixtures"}, {"score": 0.003177892611195514, "phrase": "emission_probabilities"}, {"score": 0.0031254704616199614, "phrase": "bernoulli_mixtures"}, {"score": 0.003048449231088915, "phrase": "by-pass_feature_extraction"}, {"score": 0.0029733203800202303, "phrase": "discriminative_information"}, {"score": 0.0029121251930855664, "phrase": "feature_extraction"}, {"score": 0.0027934768366077397, "phrase": "recognition_model"}, {"score": 0.0027133032795773697, "phrase": "column_bit_vectors"}, {"score": 0.0026354246446771324, "phrase": "sliding_window"}, {"score": 0.0026135859312619875, "phrase": "adequate_width"}, {"score": 0.0025704485156071463, "phrase": "image_context"}, {"score": 0.0025385621498128243, "phrase": "horizontal_position"}, {"score": 0.0025070703395635133, "phrase": "word_image"}, {"score": 0.0024656866249273125, "phrase": "windowed_bernoulli_mixture_hmms"}, {"score": 0.0023849523850778807, "phrase": "well-known_iam"}, {"score": 0.0023651860741245347, "phrase": "rimes"}, {"score": 0.002335838283092986, "phrase": "latin_script"}, {"score": 0.002158233639156017, "phrase": "arabic_handwritten_words"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["HTR", " Bernoulli HMMs", " Latin", " Arabic", " Sliding window"], "paper_abstract": "Hidden Markov Models (HMMs) are now widely used for off-line handwriting recognition in many languages. As in speech recognition, they are usually built from shared, embedded HMMs at symbol level, where state-conditional probability density functions in each HMM are modeled with Gaussian mixtures. In contrast to speech recognition, however, it is unclear which kind of features should be used and, indeed, very different features sets are in use today. Among them, we have recently proposed to directly use columns of raw, binary image pixels, which are directly fed into embedded Bernoulli (mixture) HMMs, that is, embedded HMMs in which the emission probabilities are modeled with Bernoulli mixtures. The idea is to by-pass feature extraction and to ensure that no discriminative information is filtered out during feature extraction, which in some sense is integrated into the recognition model. In this work,, column bit vectors are extended by means of a sliding window of adequate width to better capture image context at each horizontal position of the word image. Using these windowed Bernoulli mixture HMMs, good results are reported on the well-known IAM and RIMES databases of Latin script, and in particular, state-of-the-art results are provided on the IfN/ENIT database of Arabic handwritten words. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Handwriting word recognition using windowed Bernoulli HMMs", "paper_id": "WOS:000327561000017"}