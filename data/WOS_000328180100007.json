{"auto_keywords": [{"score": 0.04114520030346539, "phrase": "speaker_individual_information"}, {"score": 0.029613664015831456, "phrase": "proposed_method"}, {"score": 0.015719716506582538, "phrase": "individual_information"}, {"score": 0.015307431265596982, "phrase": "speaker_information"}, {"score": 0.014039680636091113, "phrase": "linguistic_information"}, {"score": 0.011007955370746059, "phrase": "speaker_individuality"}, {"score": 0.010540469722911885, "phrase": "feature_extraction"}, {"score": 0.008539082312160981, "phrase": "mfcc"}, {"score": 0.004766683200410046, "phrase": "phoneme_effect_suppression_method"}, {"score": 0.004655924035639928, "phrase": "speech_signals"}, {"score": 0.0046092435167207095, "phrase": "key_procedure"}, {"score": 0.004563028873351776, "phrase": "individual_speaker_characteristics"}, {"score": 0.004427134352966977, "phrase": "speaker_recognition_system"}, {"score": 0.003949144559926685, "phrase": "potential_effects"}, {"score": 0.003805788648230075, "phrase": "speaker-specific_morphology"}, {"score": 0.003767599364361092, "phrase": "speech_organs"}, {"score": 0.0037299235424367787, "phrase": "english"}, {"score": 0.0037048466526978215, "phrase": "chinese"}, {"score": 0.0036799784824229583, "phrase": "korean"}, {"score": 0.003594369823549604, "phrase": "unvoiced_phonemes"}, {"score": 0.0035702793079311896, "phrase": "different_frequency_distributions"}, {"score": 0.0033832583769880576, "phrase": "nasal_sounds"}, {"score": 0.003131393466870228, "phrase": "new_feature_extraction_method"}, {"score": 0.0030278017562213265, "phrase": "phoneme-related_effects"}, {"score": 0.0029873281676201565, "phrase": "phoneme_alignment"}, {"score": 0.002917793073455365, "phrase": "filter_bank"}, {"score": 0.0028982239829450198, "phrase": "phoneme_effect_suppression"}, {"score": 0.0027278879752324157, "phrase": "gmm_speaker_models"}, {"score": 0.002709589081384597, "phrase": "speaker_identification_experiments"}, {"score": 0.002646501671714952, "phrase": "proposed_approach"}, {"score": 0.0026199146891406, "phrase": "mel_frequency_cepstrum_coefficient"}, {"score": 0.0025675372701474035, "phrase": "traditional_f-ratio"}, {"score": 0.0024909230668523825, "phrase": "proposed_feature"}, {"score": 0.002465895175961543, "phrase": "recognition_errors"}, {"score": 0.002344468886431959, "phrase": "ffcc."}, {"score": 0.0023131084326717755, "phrase": "automatic_phoneme_aligner"}, {"score": 0.0021479597698614355, "phrase": "manual_phoneme_alignment"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Speaker identification", " Frequency warping", " MFCC", " Speech production", " Phoneme-related effects"], "paper_abstract": "Feature extraction of speaker information from speech signals is a key procedure for exploring individual speaker characteristics and also the most critical part in a speaker recognition system, which needs to preserve individual information while attenuating linguistic information. However, it is difficult to separate individual from linguistic information in a given utterance. For this reason, we investigated a number of potential effects on speaker individual information that arise from differences in articulation due to speaker-specific morphology of the speech organs, comparing English, Chinese and Korean. We found that voiced and unvoiced phonemes have different frequency distributions in speaker information and these effects are consistent across the three languages, while the effect of nasal sounds on speaker individuality is language dependent. Because these differences are confounded with speaker individual information, feature extraction is negatively affected. Accordingly, a new feature extraction method is proposed to more accurately detect speaker individual information by suppressing phoneme-related effects, where the phoneme alignment is required once in constructing a filter bank for phoneme effect suppression, but is not necessary in processing feature extraction. The proposed method was evaluated by implementing it in GMM speaker models for speaker identification experiments. It is shown that the proposed approach outperformed both Mel Frequency Cepstrum Coefficient (MFCC) and the traditional F-ratio (FFCC). The use of the proposed feature has reduced recognition errors by 32.1-67.3% for the three languages compared with MFCC, and by 6.6-31% compared with FFCC. When combining an automatic phoneme aligner with the proposed method, the result demonstrated that the proposed method can detect speaker individuality with about the same accuracy as that based on manual phoneme alignment. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Detection of speaker individual information using a phoneme effect suppression method", "paper_id": "WOS:000328180100007"}