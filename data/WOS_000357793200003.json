{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "multi-state_selection_graph"}, {"score": 0.004602233424629559, "phrase": "multiple_foreground_video_co-segmentation"}, {"score": 0.0042591158963728665, "phrase": "category-independent_object_proposals"}, {"score": 0.003577414339646767, "phrase": "intra-video_coherence"}, {"score": 0.0033971539563683174, "phrase": "foreground_consistency"}, {"score": 0.003331915219811852, "phrase": "different_videos"}, {"score": 0.0032259472087775138, "phrase": "multiple_foregrounds"}, {"score": 0.002985130390111069, "phrase": "video_frame"}, {"score": 0.002927780883930371, "phrase": "multiple_labels"}, {"score": 0.0028530201960995896, "phrase": "different_objects"}, {"score": 0.002709161672473817, "phrase": "indicator_matrix"}, {"score": 0.002639968630788011, "phrase": "first_time"}, {"score": 0.0026060359255636444, "phrase": "accurate_handling"}, {"score": 0.0025394700487126414, "phrase": "common_foreground_objects"}, {"score": 0.002411383506019635, "phrase": "irrelevant_regions"}, {"score": 0.0023346234464901978, "phrase": "foreground_objects"}, {"score": 0.0022897425998475362, "phrase": "iterative_procedure"}, {"score": 0.0021462652605453163, "phrase": "comprehensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "object-based_multiple_foreground_video_co-segmentation_method"}], "paper_keywords": ["Video co-segmentation", " multiple foregrounds", " object-based segmentation"], "paper_abstract": "We present a technique for multiple foreground video co-segmentation in a set of videos. This technique is based on category-independent object proposals. To identify the foreground objects in each frame, we examine the properties of the various regions that reflect the characteristics of foregrounds, considering the intra-video coherence of the foreground as well as the foreground consistency among the different videos in the set. Multiple foregrounds are handled via a multi-state selection graph in which a node representing a video frame can take multiple labels that correspond to different objects. In addition, our method incorporates an indicator matrix that for the first time allows accurate handling of cases with common foreground objects missing in some videos, thus preventing irrelevant regions from being misclassified as foreground objects. An iterative procedure is proposed to optimize our new objective function. As demonstrated through comprehensive experiments, this object-based multiple foreground video co-segmentation method compares well with related techniques that co-segment multiple foregrounds.", "paper_title": "Object-Based Multiple Foreground Video Co-Segmentation via Multi-State Selection Graph", "paper_id": "WOS:000357793200003"}