{"auto_keywords": [{"score": 0.04978681999804709, "phrase": "multilabel_image_classification"}, {"score": 0.032267470298898815, "phrase": "mvmc"}, {"score": 0.012148431418468168, "phrase": "different_views"}, {"score": 0.01189284370699676, "phrase": "different_features"}, {"score": 0.00481495049065317, "phrase": "multiview_matrix_completion"}, {"score": 0.00461302961851157, "phrase": "web-based_image"}, {"score": 0.004598933498016774, "phrase": "analytics-based_applications"}, {"score": 0.004542976479682312, "phrase": "large-scale_image_retrieval"}, {"score": 0.004487697242654525, "phrase": "matrix_completion"}, {"score": 0.00446052125641263, "phrase": "mc"}, {"score": 0.004273196830970426, "phrase": "multilabel_classification"}, {"score": 0.004157058883925715, "phrase": "missing_data"}, {"score": 0.0041316803676012155, "phrase": "background_noise"}, {"score": 0.004068907083697369, "phrase": "label_space"}, {"score": 0.0038981499110532273, "phrase": "single-view_feature"}, {"score": 0.0037459885494311217, "phrase": "multiple_features"}, {"score": 0.0035997452281985465, "phrase": "long_vector"}, {"score": 0.003427540517249369, "phrase": "mc-based_image_classification"}, {"score": 0.0033241072942139568, "phrase": "mc_outputs"}, {"score": 0.0032336801561165113, "phrase": "transductive_multilabel_image_classification"}, {"score": 0.0031845067058084583, "phrase": "view_combination_weights"}, {"score": 0.003126481516783286, "phrase": "cross-validation_strategy"}, {"score": 0.003097865379563127, "phrase": "labeled_set"}, {"score": 0.00290473242917264, "phrase": "known_labels"}, {"score": 0.002851790448644913, "phrase": "predicted_labels"}, {"score": 0.002791239714439304, "phrase": "view_combination_coefficients"}, {"score": 0.0027572166867780275, "phrase": "learning_process"}, {"score": 0.002715268913787316, "phrase": "average_precision"}, {"score": 0.00269874325823964, "phrase": "ap"}, {"score": 0.00259320616168125, "phrase": "ranking-based_criteria"}, {"score": 0.0025459275963373496, "phrase": "multilabel_classification_system"}, {"score": 0.0025226117209113737, "phrase": "least_squares_loss_formulation"}, {"score": 0.0023798115577749225, "phrase": "ap_loss"}, {"score": 0.0023221248824337576, "phrase": "experimental_evaluation"}, {"score": 0.0021441057555396013, "phrase": "complementary_properties"}, {"score": 0.0021179540310789446, "phrase": "output-consistent_labels"}, {"score": 0.0021049977753042253, "phrase": "improved_multilabel_image_classification"}], "paper_keywords": ["Image classification", " transductive", " multi-label", " multi-view", " matrix completion", " average precision"], "paper_abstract": "There is growing interest in multilabel image classification due to its critical role in web-based image analytics-based applications, such as large-scale image retrieval and browsing. Matrix completion (MC) has recently been introduced as a method for transductive (semisupervised) multilabel classification, and has several distinct advantages, including robustness to missing data and background noise in both feature and label space. However, it is limited by only considering data represented by a single-view feature, which cannot precisely characterize images containing several semantic concepts. To utilize multiple features taken from different views, we have to concatenate the different features as a long vector. However, this concatenation is prone to over-fitting and often leads to very high time complexity in MC-based image classification. Therefore, we propose to weightedly combine the MC outputs of different views, and present the multiview MC (MVMC) framework for transductive multilabel image classification. To learn the view combination weights effectively, we apply a cross-validation strategy on the labeled set. In particular, MVMC splits the labeled set into two parts, and predicts the labels of one part using the known labels of the other part. The predicted labels are then used to learn the view combination coefficients. In the learning process, we adopt the average precision (AP) loss, which is particular suitable for multilabel image classification, since the ranking-based criteria are critical for evaluating a multilabel classification system. A least squares loss formulation is also presented for the sake of efficiency, and the robustness of the algorithm based on the AP loss compared with the other losses is investigated. Experimental evaluation on two real-world data sets (PASCAL VOC' 07 and MIR Flickr) demonstrate the effectiveness of MVMC for transductive (semisupervised) multilabel image classification, and show that MVMC can exploit complementary properties of different features and output-consistent labels for improved multilabel image classification.", "paper_title": "Multiview Matrix Completion for Multilabel Image Classification", "paper_id": "WOS:000353888100002"}