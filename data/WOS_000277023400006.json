{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "domain_maximum_likelihood_estimation"}, {"score": 0.0046993598473345395, "phrase": "naive_bayes_text_classification"}, {"score": 0.00453113241842654, "phrase": "naive_bayes_assumption"}, {"score": 0.004422325007817267, "phrase": "text_classification"}, {"score": 0.004061584718427419, "phrase": "maximum_likelihood_estimation"}, {"score": 0.003964007795174772, "phrase": "unknown_class-conditional_word_occurrence_probabilities"}, {"score": 0.003384262486955773, "phrase": "heuristic_parameter_smoothing_technique"}, {"score": 0.002685558057339722, "phrase": "parameter_domain"}, {"score": 0.0023776656246300063, "phrase": "constrained_domain"}, {"score": 0.0021049977753042253, "phrase": "iterative_algorithm"}], "paper_keywords": ["Maximum likelihood estimation", " Naive Bayes", " Text classification", " Parameter smoothing", " Karush-Kuhn-Tucker conditions"], "paper_abstract": "The naive Bayes assumption in text classification has the advantage of greatly simplifying maximum likelihood estimation of unknown class-conditional word occurrence probabilities. However, these estimates are usually modified by application of a heuristic parameter smoothing technique to avoid (over-fitted) null estimates. In this work, we advocate the reduction of the parameter domain instead of parameter smoothing. This leads to a constrained domain maximum likelihood estimation problem for which we provide an iterative algorithm that solves it optimally.", "paper_title": "Constrained domain maximum likelihood estimation for naive Bayes text classification", "paper_id": "WOS:000277023400006"}