{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "computational_models"}, {"score": 0.004143196873246147, "phrase": "explicit_mechanisms"}, {"score": 0.003771631577951067, "phrase": "computational_work"}, {"score": 0.0031845067058084583, "phrase": "manageable_concepts"}, {"score": 0.002953711377604328, "phrase": "kernel_architecture"}, {"score": 0.0028715299874549245, "phrase": "digital_implementation"}, {"score": 0.0026384167183586015, "phrase": "visual_illusions"}, {"score": 0.0022273034991008326, "phrase": "unstable_phenomenology"}, {"score": 0.0021049977753042253, "phrase": "ambiguous_necker_cube"}], "paper_keywords": ["computational consciousness", " phenomenology", " brain modeling"], "paper_abstract": "In this paper we argue that phenomenology needs to be supported by explicit mechanisms if one is to have computational models of consciousness. Computational work in this area is reviewed and a set of axioms that help to decompose being conscious into manageable concepts is evoked. This leads to a kernel architecture and a digital implementation which is shown to work in examples of visual illusions that are revealing of how the brain supports phenomenology. This model is used to address the unstable phenomenology related to observation of the ambiguous Necker cube.", "paper_title": "Phenomenology in computational models of consciousness", "paper_id": "WOS:000241565200002"}