{"auto_keywords": [{"score": 0.035645265997705546, "phrase": "joint_representation"}, {"score": 0.00481495049065317, "phrase": "dictionary_learning_for_stereo_image_representation"}, {"score": 0.004696608876994947, "phrase": "major_challenges"}, {"score": 0.004650086856905758, "phrase": "multi-view_imaging"}, {"score": 0.004424268136268051, "phrase": "intrinsic_geometry"}, {"score": 0.004358676214574977, "phrase": "visual_information"}, {"score": 0.004315487055548749, "phrase": "sparse_image_representations"}, {"score": 0.004272724011826495, "phrase": "overcomplete_geometric_dictionaries"}, {"score": 0.0040048667115255, "phrase": "multi-view_geometric_structure"}, {"score": 0.003753738096719609, "phrase": "good_dictionary"}, {"score": 0.0035358770665604657, "phrase": "new_method"}, {"score": 0.0034834098902271626, "phrase": "overcomplete_dictionaries"}, {"score": 0.003347259612209552, "phrase": "stereo_images"}, {"score": 0.0032486392192981944, "phrase": "sparse_stereo_image_model"}, {"score": 0.0032004205378150354, "phrase": "multi-view_correlation"}, {"score": 0.0031372369299648203, "phrase": "local_geometric_transforms"}, {"score": 0.0031061129850110994, "phrase": "dictionary_elements"}, {"score": 0.0028253682745674608, "phrase": "multi-view_geometry_constraint"}, {"score": 0.0027557911038816256, "phrase": "probabilistic_model"}, {"score": 0.0027148677103585985, "phrase": "ml_objective_function"}, {"score": 0.0026480044868438875, "phrase": "expectation-maximization_algorithm"}, {"score": 0.0025827837420330816, "phrase": "learning_algorithm"}, {"score": 0.0025191653363555193, "phrase": "omnidirectional_images"}, {"score": 0.00239657981537094, "phrase": "parametric_dictionary"}, {"score": 0.0023609780669713288, "phrase": "resulting_dictionaries"}, {"score": 0.002337537183727731, "phrase": "better_performance"}, {"score": 0.0022799458141165587, "phrase": "stereo_omnidirectional_images"}, {"score": 0.002234893735225432, "phrase": "improved_multi-view_feature_matching"}, {"score": 0.002126111716875142, "phrase": "dictionary_learning"}, {"score": 0.0021049977753042253, "phrase": "distributed_scene_representation"}], "paper_keywords": ["Dictionary learning", " multi-view imaging", " omnidirectional cameras", " sparse approximations"], "paper_abstract": "One of the major challenges in multi-view imaging is the definition of a representation that reveals the intrinsic geometry of the visual information. Sparse image representations with overcomplete geometric dictionaries offer a way to efficiently approximate these images, such that the multi-view geometric structure becomes explicit in the representation. However, the choice of a good dictionary in this case is far from obvious. We propose a new method for learning overcomplete dictionaries that are adapted to the joint representation of stereo images. We first formulate a sparse stereo image model where the multi-view correlation is described by local geometric transforms of dictionary elements (atoms) in two stereo views. A maximum-likelihood (ML) method for learning stereo dictionaries is then proposed, where a multi-view geometry constraint is included in the probabilistic model. The ML objective function is optimized using the expectation-maximization algorithm. We apply the learning algorithm to the case of omnidirectional images, where we learn scales of atoms in a parametric dictionary. The resulting dictionaries provide better performance in the joint representation of stereo omnidirectional images as well as improved multi-view feature matching. We finally discuss and demonstrate the benefits of dictionary learning for distributed scene representation and camera pose estimation.", "paper_title": "Dictionary Learning for Stereo Image Representation", "paper_id": "WOS:000288675500003"}