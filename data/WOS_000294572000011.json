{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "medical_concepts"}, {"score": 0.004781498797706604, "phrase": "clinical_texts"}, {"score": 0.00474827840031692, "phrase": "objective_a"}, {"score": 0.0047152877145889656, "phrase": "machine_learning_approach"}, {"score": 0.004633805690244912, "phrase": "medical_problems"}, {"score": 0.00450633982324153, "phrase": "electronic_medical_records"}, {"score": 0.004413036532585712, "phrase": "single_support_vector_machine_classifier"}, {"score": 0.004159164514510415, "phrase": "wikipedia"}, {"score": 0.0036809089768350496, "phrase": "relation_extraction_task"}, {"score": 0.0036425727071563965, "phrase": "gold_standard"}, {"score": 0.0030062165552187086, "phrase": "rich_set"}, {"score": 0.002832928222306059, "phrase": "medical_ontologies"}, {"score": 0.0027741761880779535, "phrase": "umls._future_studies"}, {"score": 0.002586972610351776, "phrase": "relation_discovery"}, {"score": 0.002542174767860791, "phrase": "joint_classification"}, {"score": 0.0024292886883655693, "phrase": "joint_learning"}, {"score": 0.002289180040240783, "phrase": "automatic_relation_extraction"}, {"score": 0.0022653055209664284, "phrase": "lexical_and_contextual_features"}, {"score": 0.0022105600003496225, "phrase": "relation_extraction"}, {"score": 0.0021951623041245897, "phrase": "medical_texts"}], "paper_keywords": [""], "paper_abstract": "Objective A supervised machine learning approach to discover relations between medical problems, treatments, and tests mentioned in electronic medical records. Materials and methods A single support vector machine classifier was used to identify relations between concepts and to assign their semantic type. Several resources such as Wikipedia, Word Net, General Inquirer, and a relation similarity metric inform the classifier. Results The techniques reported in this paper were evaluated in the 2010 i2b2 Challenge and obtained the highest F1 score for the relation extraction task. When gold standard data for concepts and assertions were available, F1 was 73.7, precision was 72.0, and recall was 75.3. F1 is defined as 2*Precision*Recall/(Precision+Recall). Alternatively, when concepts and assertions were discovered automatically, F1 was 48.4, precision was 57.6, and recall was 41.7. Discussion Although a rich set of features was developed for the classifiers presented in this paper, little knowledge mining was performed from medical ontologies such as those found in UMLS. Future studies should incorporate features extracted from such knowledge sources, which we expect to further improve the results. Moreover, each relation discovery was treated independently. Joint classification of relations may further improve the quality of results. Also, joint learning of the discovery of concepts, assertions, and relations may also improve the results of automatic relation extraction. Conclusion Lexical and contextual features proved to be very important in relation extraction from medical texts. When they are not available to the classifier, the F1 score decreases by 3.7%. In addition, features based on similarity contribute to a decrease of 1.1% when they are not available.", "paper_title": "Automatic extraction of relations between medical concepts in clinical texts", "paper_id": "WOS:000294572000011"}