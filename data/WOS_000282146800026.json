{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "pattern_analysis"}, {"score": 0.004542780650208743, "phrase": "meaningful_low-dimensional_representation"}, {"score": 0.0042859292226559535, "phrase": "subspace_learning_methods"}, {"score": 0.004138813595009761, "phrase": "useful_tools"}, {"score": 0.004090901264701185, "phrase": "feature_extraction"}, {"score": 0.004043541331944951, "phrase": "dimensionality_reduction"}, {"score": 0.003859500298805362, "phrase": "linear_subspace_learning_algorithms"}, {"score": 0.003375574760845742, "phrase": "novel_linear_discriminant_method"}, {"score": 0.0033170847930578473, "phrase": "marginal_discriminant_projections"}, {"score": 0.003129317057177867, "phrase": "marginal_subspace"}, {"score": 0.003039445153076014, "phrase": "existing_marginal_learning_method"}, {"score": 0.0029867619862229853, "phrase": "maladjusted_learning_problem"}, {"score": 0.002884111441153185, "phrase": "hierarchical_fuzzy_clustering_approach"}, {"score": 0.002817639725689939, "phrase": "discriminative_margin"}, {"score": 0.0027049694095434905, "phrase": "iterative_objective"}, {"score": 0.002566685388128598, "phrase": "proposed_method"}, {"score": 0.00249293148301837, "phrase": "well-known_curse"}, {"score": 0.0023654615987859402, "phrase": "presented_subspace_learning_framework"}, {"score": 0.002310915790114425, "phrase": "extensive_datasets"}, {"score": 0.002231441081806766, "phrase": "proposed_mdp"}, {"score": 0.002205560249972527, "phrase": "discriminative_learning"}, {"score": 0.0021799789348982516, "phrase": "recognition_tasks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Feature extraction", " Dimensionality reduction", " Maladjusted learning problem", " Hierarchical fuzzy clustering", " Curse of dimensionality"], "paper_abstract": "For pattern analysis and recognition, it is necessary to find the meaningful low-dimensional representation of data in general. In the past decades, subspace learning methods have been regarded as the useful tools for feature extraction and dimensionality reduction. Without loss of generality, the linear subspace learning algorithms can be explained as the enhancement of the affinity and repulsion of several data pairs. Based on this point of view, a novel linear discriminant method, termed Marginal Discriminant Projections (MDP), is proposed to learn the marginal subspace. Rather than the existing marginal learning method, the maladjusted learning problem is alleviated by adopting a hierarchical fuzzy clustering approach, where the discriminative margin can be found adaptively and the iterative objective optimization is avoided. In addition, the proposed method is immune from the well-known curse of dimensionality problem, with respect to the presented subspace learning framework. Experiments on extensive datasets demonstrate the effectiveness of the proposed MDP for discriminative learning and recognition tasks. (c) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Marginal discriminant projections: An adaptable margin discriminant approach to feature reduction and extraction", "paper_id": "WOS:000282146800026"}