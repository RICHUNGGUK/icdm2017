{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "message_delivery_latency"}, {"score": 0.0047563776685277314, "phrase": "direct-to-cache-transfer_techniques"}, {"score": 0.004473982381245469, "phrase": "key_obstacle"}, {"score": 0.004392565073466714, "phrase": "hardware_performance_limits"}, {"score": 0.004208282550386197, "phrase": "software_overhead"}, {"score": 0.0041316803676012155, "phrase": "significant_portion"}, {"score": 0.003982617095636925, "phrase": "message_copying"}, {"score": 0.003545024951402821, "phrase": "received_message"}, {"score": 0.003253560798692431, "phrase": "late-binding_mechanism"}, {"score": 0.0031747618267940155, "phrase": "address_translation"}, {"score": 0.003116913644889395, "phrase": "dedicated_cache"}, {"score": 0.0030601162942933665, "phrase": "fast_access"}, {"score": 0.003022825806274343, "phrase": "received_messages"}, {"score": 0.0028084079003212947, "phrase": "cache_transfer"}, {"score": 0.0027741761880779535, "phrase": "dtct"}, {"score": 0.002723607240517261, "phrase": "lazy_dtct"}, {"score": 0.002469032978674379, "phrase": "data_cache"}, {"score": 0.0023798115577749225, "phrase": "proposed_methods"}, {"score": 0.0022519745140925475, "phrase": "access_times"}, {"score": 0.002224510044064184, "phrase": "message_payloads"}, {"score": 0.002183938718432764, "phrase": "consuming_process"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Message Passing Interface (MPI)", " Memory hierarchy", " Cache", " Direct-to-Cache-Transfer policies"], "paper_abstract": "Communication overhead is the key obstacle to reaching hardware performance limits. The majority is associated with software overhead, a significant portion of which is attributed to message copying. To reduce this copying overhead, we have devised techniques that do not require to copy a received message in order for it to be bound to its final destination. Rather, a late-binding mechanism, which involves address translation and a dedicated cache, facilitates fast access to received messages by the consuming process/thread. We have introduced two policies namely Direct to Cache Transfer (DTCT) and lazy DTCT that determine whether a message after it is bound needs to be transferred into the data cache. We have studied the proposed methods in simulation and have shown their effectiveness in reducing access times to message payloads by the consuming process. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Hiding message delivery latency using Direct-to-Cache-Transfer techniques in message passing environments", "paper_id": "WOS:000272332600002"}