{"auto_keywords": [{"score": 0.0356683943368949, "phrase": "basis_matrices"}, {"score": 0.015202488690646058, "phrase": "object_appearance_model"}, {"score": 0.00481495049065317, "phrase": "incremental_discriminative_projective_non-negative_matrix_factorization"}, {"score": 0.004543708337879809, "phrase": "changing_illumination"}, {"score": 0.004478308876320956, "phrase": "large_pose"}, {"score": 0.004287680323820891, "phrase": "visual_tracking_algorithms"}, {"score": 0.0039685202936462815, "phrase": "significant_variation"}, {"score": 0.0038737214010638745, "phrase": "challenging_situations"}, {"score": 0.0036908381347418805, "phrase": "robust_tracking_algorithm"}, {"score": 0.003637669525737665, "phrase": "discriminative_projective_non-negative_matrix_factorization"}, {"score": 0.0035852640843794252, "phrase": "robust_inter-frame_matching_schema"}, {"score": 0.003350480663660326, "phrase": "non-negative_matrix_factorization"}, {"score": 0.003056169480391946, "phrase": "incremental_learning_method"}, {"score": 0.002925899335792914, "phrase": "robust_inter-frame_matching"}, {"score": 0.002855934865505357, "phrase": "delaunay_triangulation"}, {"score": 0.0027741761880779535, "phrase": "proposal_distribution"}, {"score": 0.0027474453262607834, "phrase": "particle_filter"}, {"score": 0.002630299922281955, "phrase": "template_matching"}, {"score": 0.0024578987081792405, "phrase": "discriminative_part"}, {"score": 0.0023990982005125763, "phrase": "proposed_method"}, {"score": 0.0023417010799384524, "phrase": "bayesian_inference_framework"}, {"score": 0.002319127685733821, "phrase": "visual_tracking"}, {"score": 0.002263639474937039, "phrase": "publicly_available_benchmarks"}, {"score": 0.002241816883550397, "phrase": "video_sequences"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual tracking", " Non-negative matrix factorization", " Speeded up robust features", " Delaunay triangulation", " Template matching"], "paper_abstract": "Visual tracking usually requires an object appearance model that is robust to changing illumination, partial occlusion, large pose and other factors encountered in video. Most existed visual tracking algorithms tend to drift away from targets and even fail in tracking them in presence of significant variation of the object appearance model or challenging situations. To address this issue, we propose a robust tracking algorithm based on discriminative projective non-negative matrix factorization and a robust inter-frame matching schema. The models of target and background are presented by the basis matrices of non-negative matrix factorization. In order to adapt the basis matrices to the variation of foreground and background during tracking, an incremental learning method is employed to update the basis matrices. A robust inter-frame matching by bidirectional method and Delaunay triangulation is adopted to improve the proposal distribution of particle filter, thus enhancing the performance of tracking. Template matching is used to correct the drift of the target if the result of discriminative part is unreliable. The proposed method is embedded into a Bayesian inference framework for visual tracking. Experiments on some publicly available benchmarks of video sequences demonstrate the effectiveness and robustness of our approach. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Robust visual tracking based on incremental discriminative projective non-negative matrix factorization", "paper_id": "WOS:000357751200022"}