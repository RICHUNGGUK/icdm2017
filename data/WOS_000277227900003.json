{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "universal_approximators"}, {"score": 0.00475070135279933, "phrase": "partial_monotonicity"}, {"score": 0.004624751696958501, "phrase": "neural_networks"}, {"score": 0.0045324756541157574, "phrase": "control_loops"}, {"score": 0.004471978831302331, "phrase": "safety-critical_domains"}, {"score": 0.00407042677958844, "phrase": "small_approximation_error"}, {"score": 0.003704797078215222, "phrase": "selected_input-output_relations"}, {"score": 0.0033718991936259038, "phrase": "control_laws"}, {"score": 0.0027370835853738626, "phrase": "universal_approximation_capabilities"}, {"score": 0.0026111116934081284, "phrase": "partially_monotone_functions"}, {"score": 0.002297585503415527, "phrase": "approximation_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Partial monotonicity", " Neural networks", " Robust modelling", " Reliable control", " Model predictive control"], "paper_abstract": "Neural networks applied in control loops and safety-critical domains have to meet more requirements than just the overall best function approximation. On the one hand, a small approximation error is required; on the other hand, the smoothness and the monotonicity of selected input-output relations have to be guaranteed. Otherwise, the stability of most of the control laws is lost. In this article we compare two neural network-based approaches incorporating partial monotonicity by structure, namely the Monotonic Multi-Layer Perceptron (MONMLP) network and the Monotonic MIN-MAX (MONMM) network. We show the universal approximation capabilities of both types of network for partially monotone functions. On a number of datasets, we investigate the advantages and disadvantages of these approaches related to approximation performance, training of the model and convergence. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Comparison of universal approximators incorporating partial monotonicity by structure", "paper_id": "WOS:000277227900003"}