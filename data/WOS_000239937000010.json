{"auto_keywords": [{"score": 0.05007786227983496, "phrase": "data-driven_multithreading"}, {"score": 0.04825250923342016, "phrase": "ddm"}, {"score": 0.04274460963753701, "phrase": "data_availability"}, {"score": 0.034279271425317136, "phrase": "ddm_implementation"}, {"score": 0.004768378525561471, "phrase": "conventional_microprocessors"}, {"score": 0.004411588377842043, "phrase": "off-the-shelf_microprocessors"}, {"score": 0.004305639197085793, "phrase": "nonblocking_multithreading_execution_model"}, {"score": 0.004243289764306128, "phrase": "internode_latency"}, {"score": 0.00386876598761639, "phrase": "cache_management_policies"}, {"score": 0.003392507399258166, "phrase": "cache_management_policy"}, {"score": 0.003359647377874098, "phrase": "cacheflow"}, {"score": 0.0031845067058084583, "phrase": "memory_mapped_hardware_module"}, {"score": 0.0030778231027679464, "phrase": "processor's_bus"}, {"score": 0.0029747028229638625, "phrase": "thread_scheduling"}, {"score": 0.0028890603352364273, "phrase": "thread_synchronization_unit"}, {"score": 0.002685558057339722, "phrase": "data-_driven_network"}, {"score": 0.0024842242921857705, "phrase": "regular_workstations"}, {"score": 0.002436289099444074, "phrase": "tsu."}, {"score": 0.002366110899738696, "phrase": "nine_scientific_applications"}], "paper_keywords": ["dataflow", " multithreading", " nonblocking threads", " cache prefetching", " multiprocessors", " network of workstations", " high performance computing"], "paper_abstract": "This paper describes the Data-Driven Multithreading (DDM) model and how it may be implemented using off-the-shelf microprocessors. Data-Driven Multithreading is a nonblocking multithreading execution model that tolerates internode latency by scheduling threads for execution based on data availability. Scheduling based on data availability can be used to exploit cache management policies that reduce significantly cache misses. Such policies include firing a thread for execution only if its data is already placed in the cache. We call this cache management policy the CacheFlow policy. The core of the DDM implementation presented is a memory mapped hardware module that is attached directly to the processor's bus. This module is responsible for thread scheduling and is known as the Thread Synchronization Unit (TSU). The evaluation of DDM was performed using simulation of the Data- Driven Network of Workstations ((DNOW)-N-2). (DNOW)-N-2 is a DDM implementation built out of regular workstations augmented with the TSU. The simulation was performed for nine scientific applications, seven of which belong to the SPLASH-2 suite. The results show that DDM can tolerate well both the communication and synchronization latency. Overall, for 16 and 32-node (DNOW)-N-2 machines the speedup observed was 14.4 and 26.0, respectively.", "paper_title": "Data-Driven Multithreading using conventional microprocessors", "paper_id": "WOS:000239937000010"}