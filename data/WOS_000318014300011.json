{"auto_keywords": [{"score": 0.03754363682447158, "phrase": "f-sift"}, {"score": 0.017839513719576424, "phrase": "sift"}, {"score": 0.004693300099911199, "phrase": "effective_local_keypoint_descriptor"}, {"score": 0.004221072004655573, "phrase": "directionally_sensitive_gradient_fields"}, {"score": 0.004159763048814389, "phrase": "flip_invariant"}, {"score": 0.00411436400374349, "phrase": "real-world_applications"}, {"score": 0.0038946650372062783, "phrase": "artificial_flipping"}, {"score": 0.0037961770933599135, "phrase": "symmetric_patterns"}, {"score": 0.0036866541358511005, "phrase": "new_descriptor"}, {"score": 0.003489714006817602, "phrase": "original_properties"}, {"score": 0.003315374849824563, "phrase": "dominant_curl"}, {"score": 0.003279160988534828, "phrase": "local_patch"}, {"score": 0.0031267364878692057, "phrase": "sift."}, {"score": 0.002863652837038965, "phrase": "copy_detection"}, {"score": 0.002770791022032813, "phrase": "flip_properties"}, {"score": 0.002730488910300527, "phrase": "rapid_filtering"}, {"score": 0.002710557619357275, "phrase": "weak_geometric_checking"}, {"score": 0.0026035011274172753, "phrase": "detection_accuracy"}, {"score": 0.002500662348528587, "phrase": "computational_cost"}, {"score": 0.002473325513637559, "phrase": "object_recognition"}, {"score": 0.0023756164484983874, "phrase": "flip_transformation"}, {"score": 0.0023324855762635616, "phrase": "seven_other_descriptors"}, {"score": 0.002306982970571251, "phrase": "object_detection"}, {"score": 0.0022158306933307685, "phrase": "symmetric_objects"}, {"score": 0.002175594509651082, "phrase": "different_kinds"}, {"score": 0.0021597049163247476, "phrase": "keypoint_detectors"}, {"score": 0.0021049977753042253, "phrase": "original_sift."}], "paper_keywords": ["Flip invariant scale-invariant feature transform (SIFT)", " geometric verification", " object detection", " video copy detection"], "paper_abstract": "Scale-invariant feature transform (SIFT) feature has been widely accepted as an effective local keypoint descriptor for its invariance to rotation, scale, and lighting changes in images. However, it is also well known that SIFT, which is derived from directionally sensitive gradient fields, is not flip invariant. In real-world applications, flip or flip-like transformations are commonly observed in images due to artificial flipping, opposite capturing viewpoint, or symmetric patterns of objects. This paper proposes a new descriptor, named flip-invariant SIFT (or F-SIFT), that preserves the original properties of SIFT while being tolerant to flips. F-SIFT starts by estimating the dominant curl of a local patch and then geometrically normalizes the patch by flipping before the computation of SIFT. We demonstrate the power of F-SIFT on three tasks: large-scale video copy detection, object recognition, and detection. In copy detection, a framework, which smartly indices the flip properties of F-SIFT for rapid filtering and weak geometric checking, is proposed. F-SIFT not only significantly improves the detection accuracy of SIFT, but also leads to a more than 50% savings in computational cost. In object recognition, we demonstrate the superiority of F-SIFT in dealing with flip transformation by comparing it to seven other descriptors. In object detection, we further show the ability of F-SIFT in describing symmetric objects. Consistent improvement across different kinds of keypoint detectors is observed for F-SIFT over the original SIFT.", "paper_title": "Flip-Invariant SIFT for Copy and Object Detection", "paper_id": "WOS:000318014300011"}