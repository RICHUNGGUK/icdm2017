{"auto_keywords": [{"score": 0.04539190749928413, "phrase": "gaussian_bayesian_network"}, {"score": 0.03037241111200185, "phrase": "network_output"}, {"score": 0.00481495049065317, "phrase": "block_parameter_perturbations"}, {"score": 0.004770211811866158, "phrase": "gaussian_bayesian_networks"}, {"score": 0.004468415400599571, "phrase": "model_inaccuracies"}, {"score": 0.004108161406159407, "phrase": "evidential_variables"}, {"score": 0.004032118497047498, "phrase": "kullback-leibler_divergence_measure"}, {"score": 0.0038661089070527424, "phrase": "evidence_propagation"}, {"score": 0.003812299519486331, "phrase": "original_network"}, {"score": 0.0036213041338584756, "phrase": "quantitative_parameters"}, {"score": 0.00329813918116714, "phrase": "sensitivity_analysis"}, {"score": 0.0032674478600540477, "phrase": "different_expressions"}, {"score": 0.0026105159490849364, "phrase": "proposed_perturbations"}, {"score": 0.0025741370320813968, "phrase": "robustness_analysis"}, {"score": 0.0024912073108138613, "phrase": "potential_uncertainties"}, {"score": 0.0023223663501882896, "phrase": "overall_sensitivity"}, {"score": 0.0022580713471027996, "phrase": "practical_examples"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Decision support system", " Gaussian Bayesian network", " Sensitivity analysis", " Robustness analysis"], "paper_abstract": "In this work we study the effects of model inaccuracies on the description of a Gaussian Bayesian network with a set of variables of interest and a set of evidential variables. Using the Kullback-Leibler divergence measure, we compare the output of two different networks after evidence propagation: the original network, and a network with perturbations representing uncertainties in the quantitative parameters. We describe two methods for analyzing the sensitivity and robustness of a Gaussian Bayesian network on this basis. In the sensitivity analysis, different expressions are obtained depending on which set of parameters is considered inaccurate. This fact makes it possible to determine the set of parameters that most strongly disturbs the network output. If all of the divergences are small, we can conclude that the network output is insensitive to the proposed perturbations. The robustness analysis is similar, but considers all potential uncertainties jointly. It thus yields only one divergence, which can be used to confirm the overall sensitivity of the network. Some practical examples of this method are provided, including a complex, real-world problem. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "The effect of block parameter perturbations in Gaussian Bayesian networks: Sensitivity and robustness", "paper_id": "WOS:000313774200028"}