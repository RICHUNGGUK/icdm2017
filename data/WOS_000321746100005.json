{"auto_keywords": [{"score": 0.03784144720028532, "phrase": "functional_representations"}, {"score": 0.00481495049065317, "phrase": "functional_representation"}, {"score": 0.0047761092701293474, "phrase": "neural_ish_images"}, {"score": 0.0046238380150870435, "phrase": "imaging_datasets"}, {"score": 0.004586531354697466, "phrase": "mammalian_brains"}, {"score": 0.004476399615305783, "phrase": "unprecedented_amounts"}, {"score": 0.004386637056030611, "phrase": "highly_complex_patterns"}, {"score": 0.0043512358455892, "phrase": "gene_expression"}, {"score": 0.004298666679374568, "phrase": "multiple_scales"}, {"score": 0.003916098498242888, "phrase": "meaningful_representation"}, {"score": 0.003806541299696042, "phrase": "extracted_patterns"}, {"score": 0.0035386420095120706, "phrase": "situ_hybridization"}, {"score": 0.003356923403930231, "phrase": "local_descriptors"}, {"score": 0.0029602552900111433, "phrase": "low-dimensional_space"}, {"score": 0.002900806476592644, "phrase": "meaningful_functional_annotations"}, {"score": 0.002865710140187219, "phrase": "resulting_representations"}, {"score": 0.0028195727965553367, "phrase": "ish_images"}, {"score": 0.002740607717745287, "phrase": "functional_categories"}, {"score": 0.0026638482306228575, "phrase": "genomic_set"}, {"score": 0.0026423134393535265, "phrase": "mouse_neural_ish_images"}, {"score": 0.0025167026017217926, "phrase": "spatial_expression_patterns"}, {"score": 0.0024963543716522087, "phrase": "high_accuracy"}, {"score": 0.002387337550919433, "phrase": "protein-protein_interactions"}, {"score": 0.0023680327896318915, "phrase": "cell-type_specificity"}, {"score": 0.002320449502337321, "phrase": "competing_methods"}, {"score": 0.0022923586577645143, "phrase": "global_correlations"}, {"score": 0.0022281257694320455, "phrase": "similar_expression_patterns"}, {"score": 0.0022101055924375725, "phrase": "gabaergic_neuronal_markers"}, {"score": 0.0021307975800397816, "phrase": "new_gene_function"}, {"score": 0.0021049977753042253, "phrase": "image-image_similarities"}], "paper_keywords": [""], "paper_abstract": "Motivation: High-spatial resolution imaging datasets of mammalian brains have recently become available in unprecedented amounts. Images now reveal highly complex patterns of gene expression varying on multiple scales. The challenge in analyzing these images is both in extracting the patterns that are most relevant functionally and in providing a meaningful representation that allows neuroscientists to interpret the extracted patterns. Results: Here, we present FuncISH-a method to learn functional representations of neural in situ hybridization (ISH) images. We represent images using a histogram of local descriptors in several scales, and we use this representation to learn detectors of functional (GO) categories for every image. As a result, each image is represented as a point in a low-dimensional space whose axes correspond to meaningful functional annotations. The resulting representations define similarities between ISH images that can be easily explained by functional categories. We applied our method to the genomic set of mouse neural ISH images available at the Allen Brain Atlas, finding that most neural biological processes can be inferred from spatial expression patterns with high accuracy. Using functional representations, we predict several gene interaction properties, such as protein-protein interactions and cell-type specificity, more accurately than competing methods based on global correlations. We used FuncISH to identify similar expression patterns of GABAergic neuronal markers that were not previously identified and to infer new gene function based on image-image similarities.", "paper_title": "FuncISH: learning a functional representation of neural ISH images", "paper_id": "WOS:000321746100005"}