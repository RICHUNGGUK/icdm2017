{"auto_keywords": [{"score": 0.03627888847486302, "phrase": "mars"}, {"score": 0.02253001929152539, "phrase": "svm"}, {"score": 0.00481495049065317, "phrase": "planetary_exploration"}, {"score": 0.004772668787820885, "phrase": "learning_techniques"}, {"score": 0.0047307566098891895, "phrase": "considerable_promise"}, {"score": 0.004689210758225518, "phrase": "common_visual_inspection_tasks"}, {"score": 0.004607205374689976, "phrase": "human_faces"}, {"score": 0.004580188715162227, "phrase": "cluttered_scenes"}, {"score": 0.00448686632980506, "phrase": "similar_techniques"}, {"score": 0.004305862702167419, "phrase": "geologic_landforms"}, {"score": 0.004280605517385785, "phrase": "planetary_images"}, {"score": 0.004059827743016726, "phrase": "perceptive_spacecraft"}, {"score": 0.004024150214304478, "phrase": "onboard_processing"}, {"score": 0.0039421123723827655, "phrase": "appropriate_actions"}, {"score": 0.0037830010278885437, "phrase": "neural_networks"}, {"score": 0.0037607992433574835, "phrase": "ensemble_methods"}, {"score": 0.0037387272682935686, "phrase": "support_vector_machines"}, {"score": 0.0037049974401620516, "phrase": "cstm"}, {"score": 0.0036732826889280487, "phrase": "continuously-scalable_template_models"}, {"score": 0.003566735116775593, "phrase": "ground-truthed_images"}, {"score": 0.003535375475035123, "phrase": "resulting_detectors"}, {"score": 0.003483718784873684, "phrase": "challenging_set"}, {"score": 0.003463267330414914, "phrase": "viking_orbiter_images"}, {"score": 0.0034227226677308337, "phrase": "roughly_one_thousand_craters"}, {"score": 0.00339262490894945, "phrase": "svm_approach"}, {"score": 0.0033727064185569396, "phrase": "normalized_image_patches"}, {"score": 0.0033332184113249444, "phrase": "localization_performance"}, {"score": 0.0032845057772800273, "phrase": "human_labelers"}, {"score": 0.0031986042942694255, "phrase": "boundary-based_approaches"}, {"score": 0.003161148227806404, "phrase": "hough_transform"}, {"score": 0.003114942418729772, "phrase": "run-time_cost"}, {"score": 0.0030784630179366353, "phrase": "svm_solution"}, {"score": 0.003051383242082058, "phrase": "standard_way"}, {"score": 0.0028938199455860836, "phrase": "window-by-window_basis"}, {"score": 0.0028015524797771066, "phrase": "support_vectors"}, {"score": 0.0027524673604095787, "phrase": "test_vectors"}, {"score": 0.002602618744142145, "phrase": "overlap-and-add_technique"}, {"score": 0.002519612567209806, "phrase": "sensor_data"}, {"score": 0.0025048067502866297, "phrase": "resource-constrained_environments"}, {"score": 0.0024320693637722335, "phrase": "exact_computation"}, {"score": 0.0024106618562440563, "phrase": "svm_decision_function"}, {"score": 0.00237539960152304, "phrase": "minimal_ram"}, {"score": 0.0021872315757161644, "phrase": "spatial_scanning"}, {"score": 0.0021488865854453073, "phrase": "reduced_set_methods"}, {"score": 0.0021049977753042253, "phrase": "multiplicative_gain"}], "paper_keywords": ["Support vector machines", " Convolution", " Run-time efficiency", " Overlap-and-add", " Crater detection"], "paper_abstract": "Machine learning techniques have shown considerable promise for automating common visual inspection tasks such as the detection of human faces in cluttered scenes. Here, we examine whether similar techniques can be used (or adapted) for the problem of automatically locating geologic landforms in planetary images gathered by spacecraft. Beyond enabling more efficient and comprehensive ground analysis of down-linked data, we are aiming toward perceptive spacecraft that use onboard processing to autonomously analyze their collected imagery and take appropriate actions. In our current study, we have employed various supervised learning algorithms, including neural networks, ensemble methods, support vector machines (SVM), and continuously-scalable template models (CSTM) to derive detectors for craters from ground-truthed images. The resulting detectors are evaluated on a challenging set of Viking Orbiter images of Mars containing roughly one thousand craters. The SVM approach with normalized image patches provides detection and localization performance closest to that of human labelers and is shown to be substantially superior to boundary-based approaches such as the Hough transform. However, the run-time cost in applying the SVM solution in the standard way (spatial scanning in which the SVM is applied to each patch of the image on a window-by-window basis) is too high due both to the number of support vectors required and the number of test vectors generated by sliding a window across the data. We have developed an implementation using FFTs and the overlap-and-add technique, which can be used to efficiently apply SVMs to sensor data in resource-constrained environments such as on a spacecraft. The technique allows exact computation of the SVM decision function over an image using minimal RAM (typically less than 5% of the size of the image) and only O(n(s) (log(2) d + 11)) real multiplications per pixel for spatial scanning. Our approach is complementary to reduced set methods providing (in theory) a multiplicative gain in performance.", "paper_title": "Onboard object recognition for planetary exploration", "paper_id": "WOS:000293297200004"}