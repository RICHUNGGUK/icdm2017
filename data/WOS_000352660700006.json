{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "storage_systems"}, {"score": 0.046800023565389516, "phrase": "energy_consumption"}, {"score": 0.0433312844265797, "phrase": "degradation_mode"}, {"score": 0.02944291751155286, "phrase": "active_nodes"}, {"score": 0.0047472380621488616, "phrase": "important_metric"}, {"score": 0.004614643339546038, "phrase": "energy_efficiency_systems"}, {"score": 0.004592906118487149, "phrase": "barroso"}, {"score": 0.004571269461883144, "phrase": "holzle"}, {"score": 0.004360412703519539, "phrase": "tradeoff_metric"}, {"score": 0.004309229446929411, "phrase": "normal_mode"}, {"score": 0.004228577663320847, "phrase": "node_failures"}, {"score": 0.004198722289738563, "phrase": "node_failure"}, {"score": 0.0041104097722516044, "phrase": "node_reconstruction"}, {"score": 0.003948613642680196, "phrase": "substantial_amount"}, {"score": 0.0038655412867795243, "phrase": "energy_efficiency"}, {"score": 0.003784209997115174, "phrase": "replication-based_storage"}, {"score": 0.003757480190200645, "phrase": "google_file_system"}, {"score": 0.0037397648997431238, "phrase": "sanjay_ghemawat"}, {"score": 0.003722132819035708, "phrase": "gobioff"}, {"score": 0.0036524288622623077, "phrase": "hadoop_distributed_file_system"}, {"score": 0.0036352070472201086, "phrase": "borthakur"}, {"score": 0.0035587046945919788, "phrase": "recovery_policy"}, {"score": 0.0033704091011525104, "phrase": "recovery_time"}, {"score": 0.003207173639414978, "phrase": "natural_problem"}, {"score": 0.0030881143614111552, "phrase": "energy_efficient_storage_system"}, {"score": 0.0029805015010906013, "phrase": "current_energy_proportional_solutions"}, {"score": 0.002897109710213723, "phrase": "mathematical_model"}, {"score": 0.002883439044844259, "phrase": "perfect_energy"}, {"score": 0.0027437235598539904, "phrase": "assigned_recovery_bandwidth"}, {"score": 0.002724323141343469, "phrase": "time_slot"}, {"score": 0.0026107601878587816, "phrase": "data_layouts"}, {"score": 0.002573965014439041, "phrase": "node_selection_algorithm"}, {"score": 0.002478353771216097, "phrase": "perp_results"}, {"score": 0.00243188506745801, "phrase": "current_popular_power_proportional_layouts"}, {"score": 0.0023750195916403117, "phrase": "house_cass_cluster"}, {"score": 0.002363806685815014, "phrase": "experimental_results"}, {"score": 0.0023030762175837377, "phrase": "perp"}, {"score": 0.0022706045233150795, "phrase": "maximum_recovery_policy"}, {"score": 0.002196609505859369, "phrase": "recovery_group_policy"}, {"score": 0.0021862435724140693, "phrase": "rabbit"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Performance", " Energy", " Recovery", " Data layout", " Power proportional"], "paper_abstract": "Most recently, an important metric called \"energy proportional\" is presented as a guideline for energy efficiency systems (Barroso and Holzle, 2007), which advocates that energy consumption should be in proportion to system performance/utilization. However, this tradeoff metric is only defined for normal mode where the system is functioning normally without node failures. When node failure occurs, the system enters degradation mode during which node reconstruction is initiated. This very process needs to wake/spin up a number of disks and takes a substantial amount of I/O bandwidth, which will not only compromise energy efficiency but also performance. Moreover, as in replication-based storage such as Google File System (Sanjay Ghemawat, Gobioff, 2003 [10]) and Hadoop Distributed File System (Borthakur, 2007), systems are adopting a recovery policy that defines a deadline for recovery rather than simply recovering the data as soon as possible. Given the flexibility of the recovery time, this makes it possible to reduce energy consumption with respect to the performance and recovery requirements. This raises a natural problem: how to balance the performance, energy, and recovery in degradation mode for an energy efficient storage system? Without considering the I/O bandwidth contention between recovery and performance, we find that the current energy proportional solutions cannot answer this question accurately. This paper presents a mathematical model named Perfect Energy, Recovery and Performance (PERP) which provides guidelines for provisioning the number of active nodes as well as the assigned recovery bandwidth at each time slot with respect to the performance and recovery constraints. To utilize PERP in storage systems, we take data layouts into consideration and propose a node selection algorithm named \"Gradual Increase/decrease\" Algorithm (GIA) to select the active nodes based on PERP results. We apply PERP and GIA to current popular power proportional layouts and test their effectiveness on a 25 nodes in-house CASS cluster. Experimental results validate that while meeting both performance and recovery constraints, PERP helps realize 25% power savings compared with maximum recovery policy from Sierra (Thereska et al., 2011) and 20% power savings compared with recovery group policy from Rabbit (Amur et al., 2010). (C) 2015 Published by Elsevier Inc.", "paper_title": "PERP: Attacking the balance among energy, performance and recovery in storage systems", "paper_id": "WOS:000352660700006"}