{"auto_keywords": [{"score": 0.040247258573975715, "phrase": "cluster_indicator_matrix"}, {"score": 0.03535741275361776, "phrase": "continuous_solution"}, {"score": 0.00481495049065317, "phrase": "-sample_extension"}, {"score": 0.004645959941491617, "phrase": "fundamental_research_problems"}, {"score": 0.0046046429665581555, "phrase": "data_mining"}, {"score": 0.004563691742821759, "phrase": "machine_learning"}, {"score": 0.004462892860919036, "phrase": "existing_clustering_methods"}, {"score": 0.004009074013302036, "phrase": "np-hard_problem"}, {"score": 0.0037827603118271757, "phrase": "practical_way"}, {"score": 0.003505908076430666, "phrase": "continuous_values"}, {"score": 0.003459191419478298, "phrase": "eigenvalue_decomposition"}, {"score": 0.002957919048133256, "phrase": "true_solution"}, {"score": 0.0027659126653647712, "phrase": "novel_clustering_algorithm"}, {"score": 0.0026095920086044145, "phrase": "additional_nonnegative_constraint"}, {"score": 0.0024401411219526774, "phrase": "effective_regularization_term"}, {"score": 0.0023021895404322767, "phrase": "mapping_function"}, {"score": 0.002271476019266231, "phrase": "cluster_labels"}, {"score": 0.002241171326888997, "phrase": "out-of-sample_test_data"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_clustering_algorithms"}], "paper_keywords": ["Nonnegative spectral clustering", " discriminative regularization", " out-of-sample"], "paper_abstract": "Data clustering is one of the fundamental research problems in data mining and machine learning. Most of the existing clustering methods, for example, normalized cut and k-means, have been suffering from the fact that their optimization processes normally lead to an NP-hard problem due to the discretization of the elements in the cluster indicator matrix. A practical way to cope with this problem is to relax this constraint to allow the elements to be continuous values. The eigenvalue decomposition can be applied to generate a continuous solution, which has to be further discretized. However, the continuous solution is probably mixing-signed. This result may cause it deviate severely from the true solution, which should be naturally nonnegative. In this paper, we propose a novel clustering algorithm, i.e., discriminative nonnegative spectral clustering, to explicitly impose an additional nonnegative constraint on the cluster indicator matrix to seek for a more interpretable solution. Moreover, we show an effective regularization term which is able to not only provide more useful discriminative information but also learn a mapping function to predict cluster labels for the out-of-sample test data. Extensive experiments on various data sets illustrate the superiority of our proposal compared to the state-of-the-art clustering algorithms.", "paper_title": "Discriminative Nonnegative Spectral Clustering with Out-of-Sample Extension", "paper_id": "WOS:000321261000007"}