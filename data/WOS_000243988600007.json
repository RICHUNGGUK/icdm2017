{"auto_keywords": [{"score": 0.033844004552095866, "phrase": "nnda"}, {"score": 0.010481850337601337, "phrase": "lda"}, {"score": 0.007868954527253419, "phrase": "class_densities"}, {"score": 0.00481495049065317, "phrase": "linear_discriminant_analysis"}, {"score": 0.004637478829869904, "phrase": "popular_feature_extraction_technique"}, {"score": 0.004579780586951551, "phrase": "statistical_pattern_recognition"}, {"score": 0.004328856052035968, "phrase": "small_sample_size_problem"}, {"score": 0.00422177384286051, "phrase": "high-dimensional_data"}, {"score": 0.003940706575253453, "phrase": "best_directions"}, {"score": 0.003795335309109018, "phrase": "gaussian_density"}, {"score": 0.0037246656582642272, "phrase": "common_covariance_matrix"}, {"score": 0.0033482708495261864, "phrase": "novel_nonparametric_linear_feature_extraction_method"}, {"score": 0.0030097975788892896, "phrase": "nearest_neighbor_classification"}, {"score": 0.0029169007179202164, "phrase": "important_discriminant_directions"}, {"score": 0.0027741761880779535, "phrase": "particular_parametric_family"}, {"score": 0.0025892330566358503, "phrase": "within-class_scatter_matrix"}, {"score": 0.002477998427152547, "phrase": "approximate_approach"}, {"score": 0.0022696277881969896, "phrase": "simulated_data"}, {"score": 0.0022413233627905696, "phrase": "real_world_data"}, {"score": 0.0021182494144182805, "phrase": "existing_variant"}, {"score": 0.0021049977753042253, "phrase": "lda_methods"}], "paper_keywords": ["nearest neighbor discriminant analysis", " Linear Discriminant Analysis", " non-parametric discriminant analysis"], "paper_abstract": "Linear Discriminant Analysis (LDA) is a popular feature extraction technique in statistical pattern recognition. However, it often suffers from the small sample size problem when dealing with high-dimensional data. Moreover, while LDA is guaranteed to find the best directions when each class has a Gaussian density with a common covariance matrix, it can fail if the class densities are more general. In this paper, a novel nonparametric linear feature extraction method, nearest neighbor discriminant analysis (NNDA), is proposed from the view of the nearest neighbor classification. NNDA finds the important discriminant directions without assuming the class densities belong to any particular parametric family. It does not depend on the nonsingularity of the within-class scatter matrix either. Then we give an approximate approach to optimize NNDA and an extension to k-NN. We apply NNDA to the simulated data and real world data, the results demonstrate that NNDA outperforms the existing variant LDA methods.", "paper_title": "Nearest neighbor discriminant analysis", "paper_id": "WOS:000243988600007"}