{"auto_keywords": [{"score": 0.04328923668126015, "phrase": "vl"}, {"score": 0.00471700544744796, "phrase": "fuzzy_c-means"}, {"score": 0.004434910775034831, "phrase": "effcm"}, {"score": 0.004380540407926982, "phrase": "object_vector"}, {"score": 0.003985166330358716, "phrase": "statistical_goodness"}, {"score": 0.003952513974962462, "phrase": "fit_test"}, {"score": 0.0036855132234738736, "phrase": "literal_clusters"}, {"score": 0.0034935290662899488, "phrase": "comparable_method"}, {"score": 0.0034506596895901003, "phrase": "remaining_case"}, {"score": 0.0033388871136347704, "phrase": "vl_relational_data"}, {"score": 0.003177958355586418, "phrase": "enerf"}, {"score": 0.0031132086055691214, "phrase": "last_case"}, {"score": 0.0030372426452745073, "phrase": "distinguished_features"}, {"score": 0.002999955539996569, "phrase": "progressive_sampling"}, {"score": 0.0029027394930867902, "phrase": "square_n_x_n_relation"}, {"score": 0.002831894638104635, "phrase": "n_x"}, {"score": 0.002740109776120878, "phrase": "statistical_test"}, {"score": 0.0026403934420630155, "phrase": "literal_non-euclidean_relational_fuzzy_c-means"}, {"score": 0.002461810159687652, "phrase": "relational_data"}, {"score": 0.002431570196486513, "phrase": "extension_phase"}, {"score": 0.0024017007954518065, "phrase": "third_case"}, {"score": 0.002285839246740627, "phrase": "object_data_cases"}, {"score": 0.0021049977753042253, "phrase": "wiley_periodicals"}], "paper_keywords": [""], "paper_abstract": "Different extensions of fuzzy c-means (FCM) clustering have been developed to approximate FCM clustering in very large (unloadable) image (eFFCM) and object vector (geFFCM) data. Both extensions share three phases: (1) progressive sampling of the VL data, terminated when a sample passes a statistical goodness of fit test; (2) clustering with (literal or exact) FCM; and (3) noniterative extension of the literal clusters to the remainder of the data set. This article presents a comparable method for the remaining case of interest, namely, clustering in VL relational data. We will propose and discuss each of the four phases of eNERF and our algorithm for this last case: (1) finding distinguished features that monitor progressive sampling, (2) progressively sampling a square N X N relation matrix R(N) until an n X n sample relation R(n) passes a statistical test, (3) clustering R(n) with literal non-Euclidean relational fuzzy c-means, and (4) extending the clusters in R(n) to the remainder of the relational data. The extension phase in this third case is not as straightforward as it was in the image and object data cases, but our numerical examples suggest that eNERF has the same approximation qualities that eFFCM and geFFCM do. (c) 2006 Wiley Periodicals, Inc.", "paper_title": "Approximate clustering in very large relational data", "paper_id": "WOS:000239069800002"}