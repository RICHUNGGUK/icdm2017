{"auto_keywords": [{"score": 0.048851194509091665, "phrase": "cloudview"}, {"score": 0.026531253014656277, "phrase": "large_number"}, {"score": 0.01918843665113233, "phrase": "local_nodes"}, {"score": 0.011965321767357219, "phrase": "global_information"}, {"score": 0.008713768692145006, "phrase": "massive_machine_maintenance_data"}, {"score": 0.008646381745294772, "phrase": "computing_cloud"}, {"score": 0.005815865180809094, "phrase": "case-base_updates"}, {"score": 0.00574088058095425, "phrase": "time_scale"}, {"score": 0.004715908063787721, "phrase": "novel_framework"}, {"score": 0.004465464025740838, "phrase": "industrial_machines"}, {"score": 0.0044192837023190445, "phrase": "cloud_computing_environment"}, {"score": 0.004217286731331736, "phrase": "proposed_framework"}, {"score": 0.004184526032558792, "phrase": "parallel_computing_capability"}, {"score": 0.004109066606425297, "phrase": "large-scale_distributed_batch_processing_infrastructure"}, {"score": 0.004014035333627087, "phrase": "case-based_reasoning"}, {"score": 0.003931402465972151, "phrase": "machine_fault_prediction"}, {"score": 0.003542976343910816, "phrase": "sensor_data"}, {"score": 0.0034700069041302003, "phrase": "case-base_creation_jobs"}, {"score": 0.0034162643819889054, "phrase": "parallel_data_processing_model"}, {"score": 0.0033721131656280095, "phrase": "failure_cases"}, {"score": 0.0032940691998512963, "phrase": "failure_information"}, {"score": 0.003102706253029739, "phrase": "real-time_sensor_data"}, {"score": 0.0029376803941247084, "phrase": "incipient_faults"}, {"score": 0.00291483082800388, "phrase": "local_processing"}, {"score": 0.0027240799841720957, "phrase": "new_cases"}, {"score": 0.002619748321217153, "phrase": "experimental_measurements"}, {"score": 0.002599365215003002, "phrase": "fault_predictions"}, {"score": 0.0024868131939261716, "phrase": "massive_machine_data_analysis"}, {"score": 0.002473895542219933, "phrase": "case-base_creation"}, {"score": 0.0023361440016375972, "phrase": "first_reported_use"}, {"score": 0.002317962367296038, "phrase": "cloud_architecture"}, {"score": 0.002305919776918934, "phrase": "maintenance_data_storage"}, {"score": 0.0022175679453857473, "phrase": "parallel_computing_capabilities"}, {"score": 0.0021831803612759855, "phrase": "local_decisions"}, {"score": 0.0021437334457067012, "phrase": "potential_data_bottlenecks"}, {"score": 0.0021049977753042253, "phrase": "maintenance_data"}], "paper_keywords": ["Fault prediction", " machine data analysis", " case-based reasoning", " cloud computing", " Hadoop", " MapReduce"], "paper_abstract": "We present a novel framework, CloudView, for storage, processing and analysis of massive machine maintenance data, collected from a large number of sensors embedded in industrial machines, in a cloud computing environment. This paper describes the architecture, design, and implementation of CloudView, and how the proposed framework leverages the parallel computing capability of a computing cloud based on a large-scale distributed batch processing infrastructure that is built of commodity hardware. A case-based reasoning (CBR) approach is adopted for machine fault prediction, where the past cases of failure from a large number of machines are collected in a cloud. A case-base of past cases of failure is created using the global information obtained from a large number of machines. CloudView facilitates organization of sensor data and creation of case-base with global information. Case-base creation jobs are formulated using the MapReduce parallel data processing model. CloudView captures the failure cases across a large number of machines and shares the failure information with a number of local nodes in the form of case-base updates that occur in a time scale of every few hours. At local nodes, the real-time sensor data from a group of machines in the same facility/plant is continuously matched to the cases from the case-base for predicting the incipient faults-this local processing takes a much shorter time of a few seconds. The case-base is updated regularly (in the time scale of a few hours) on the cloud to include new cases of failure, and these case-base updates are pushed from CloudView to the local nodes. Experimental measurements show that fault predictions can be done in real-time (on a timescale of seconds) at the local nodes and massive machine data analysis for case-base creation and updating can be done on a timescale of minutes in the cloud. Our approach, in addition to being the first reported use of the cloud architecture for maintenance data storage, processing and analysis, also evaluates several possible cloud-based architectures that leverage the advantages of the parallel computing capabilities of the cloud to make local decisions with global information efficiently, while avoiding potential data bottlenecks that can occur in getting the maintenance data in and out of the cloud.", "paper_title": "Analyzing Massive Machine Maintenance Data in a Computing Cloud", "paper_id": "WOS:000307824600003"}