{"auto_keywords": [{"score": 0.049509300669177574, "phrase": "mutual_information"}, {"score": 0.03210922632810699, "phrase": "output_class"}, {"score": 0.00481495049065317, "phrase": "direct_calculation"}, {"score": 0.004401342842183475, "phrase": "input_features"}, {"score": 0.004322967486451877, "phrase": "important_features"}, {"score": 0.0037216229812089686, "phrase": "better_generalization_performance"}, {"score": 0.0034841647157189985, "phrase": "feature_extraction_method"}, {"score": 0.0034220655476652683, "phrase": "classification_problems"}, {"score": 0.003361069456060196, "phrase": "proposed_algorithm"}, {"score": 0.0031845067058084583, "phrase": "linear_combinations"}, {"score": 0.0031277316566463978, "phrase": "original_features"}, {"score": 0.0028758391869611374, "phrase": "extracted_features"}, {"score": 0.002724696729311532, "phrase": "probability_density_estimation"}, {"score": 0.0026600905156986317, "phrase": "parzen_window_method"}, {"score": 0.0026126405272417783, "phrase": "greedy_algorithm"}, {"score": 0.0025660347613972573, "phrase": "gradient_descent_method"}, {"score": 0.00247529638625566, "phrase": "new_features"}, {"score": 0.0024311346712789553, "phrase": "computational_load"}, {"score": 0.0022486729928886885, "phrase": "proposed_method"}, {"score": 0.002143247921132179, "phrase": "better_or_comparable_performances"}, {"score": 0.0021049977753042253, "phrase": "conventional_feature_extraction_methods"}], "paper_keywords": ["feature extraction", " mutual information", " Parzen window", " gradient descent", " subspace method", " optimization", " classification"], "paper_abstract": "In many pattern recognition problems, it is desirable to reduce the number of input features by extracting important features related to the problems. By focusing on only the problem-relevant features, the dimension of features can be greatly reduced and thereby can result in a better generalization performance with less computational complexity. In this paper, we propose a feature extraction method for handling classification problems. The proposed algorithm is used to search for a set of linear combinations of the original features, whose mutual information with the output class can be maximized. The mutual information between the extracted features and the output class is calculated by using the probability density estimation based on the Parzen window method. A greedy algorithm using the gradient descent method is used to determine the new features. The computational load is proportional to the square of the number of samples. The proposed method was applied to several classification problems, which showed better or comparable performances than the conventional feature extraction methods.", "paper_title": "Feature extraction based on direct calculation of mutual information", "paper_id": "WOS:000251720000007"}