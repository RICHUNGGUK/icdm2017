{"auto_keywords": [{"score": 0.04087308818335134, "phrase": "non-matched_identities"}, {"score": 0.014475654310267658, "phrase": "population_diversity"}, {"score": 0.00481495049065317, "phrase": "automatic_face_recognition_performance"}, {"score": 0.0047650691627251825, "phrase": "intended_applications"}, {"score": 0.004732100994830163, "phrase": "automatic_face_recognition_systems"}, {"score": 0.0046184900568047565, "phrase": "demographic_diversity"}, {"score": 0.004586531354697466, "phrase": "formal_evaluations"}, {"score": 0.004293693193836074, "phrase": "racial_and_gender_demographics"}, {"score": 0.0040899006497687115, "phrase": "face_images"}, {"score": 0.003922907208353323, "phrase": "\"background\"_population_distribution"}, {"score": 0.003855347387268162, "phrase": "identity_matches"}, {"score": 0.0036595438031512217, "phrase": "top_performers"}, {"score": 0.003621588555525458, "phrase": "recent_us_government_competition"}, {"score": 0.0030226700832113942, "phrase": "match_threshold"}, {"score": 0.0029705677977833857, "phrase": "false_alarm_rate"}, {"score": 0.0029092257197427195, "phrase": "non-matched_identity_pairs"}, {"score": 0.0028590732866152118, "phrase": "second_experiment"}, {"score": 0.0027903049766389433, "phrase": "algorithm_performance"}, {"score": 0.0025225467103906314, "phrase": "identity_match_accuracy"}, {"score": 0.002479043701859468, "phrase": "non-match_identity_population"}, {"score": 0.0023529740798601015, "phrase": "non-match_distribution"}, {"score": 0.0021871503075921537, "phrase": "demographic_composition"}, {"score": 0.002149418970824546, "phrase": "background_population"}, {"score": 0.0021049977753042253, "phrase": "face_recognition_algorithms"}], "paper_keywords": ["Face recognition", " Algorithm evaluation", " Demographics"], "paper_abstract": "The intended applications of automatic face recognition systems include venues that vary widely in demographic diversity. Formal evaluations of algorithms do not commonly consider the effects of population diversity on performance. We document the effects of racial and gender demographics on estimates of the accuracy of algorithms that match identity in pairs of face images. In particular, we focus on the effects of the \"background\" population distribution of non-matched identities against which identity matches are compared. The algorithm we tested was created by fusing three of the top performers from a recent US Government competition. First, we demonstrate the variability of algorithm performance estimates when the population of non-matched identities was demographically \"yoked\" by race and/or gender (i.e., \"yoking\" constrains non-matched pairs to be of the same race or gender). We also report differences in the match threshold required to obtain a false alarm rate of .001 when demographic controls on the non-matched identity pairs varied. In a second experiment, we explored the effect on algorithm performance of progressively increasing population diversity. We found systematic, but non-general, effects when the balance between majority and minority populations of non-matched identities shifted. Third, we show that identity match accuracy differs substantially when the non-match identity population varied by race. Finally, we demonstrate the impact on performance when the non-match distribution consists of faces chosen to resemble a target face. The results from all experiments indicate the importance of the demographic composition and modeling of the background population in predicting the accuracy of face recognition algorithms. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Demographic effects on estimates of automatic face recognition performance", "paper_id": "WOS:000304181000005"}