{"auto_keywords": [{"score": 0.03966763833982911, "phrase": "ubm_weight_posterior_probability_supervectors"}, {"score": 0.00481495049065317, "phrase": "gender_recognition"}, {"score": 0.004782587436296574, "phrase": "acoustic_and_prosodic_level_information_fusion"}, {"score": 0.004686791459644141, "phrase": "novel_automatic_speaker_age"}, {"score": 0.004655285779819366, "phrase": "gender_identification_approach"}, {"score": 0.004608422081389008, "phrase": "seven_different_methods"}, {"score": 0.0045160988337296605, "phrase": "baseline_performance"}, {"score": 0.004351595642056769, "phrase": "mel-frequency_cepstral_coefficient"}, {"score": 0.004109023004472115, "phrase": "gmm_mean_supervectors"}, {"score": 0.003738502710504415, "phrase": "bhattacharyya_probability_product_kernel"}, {"score": 0.0034243271052114234, "phrase": "polynomial_expansion_coefficients"}, {"score": 0.0033898129842622536, "phrase": "syllable_level_prosodic_feature_contours"}, {"score": 0.0030943793545344495, "phrase": "energy_information"}, {"score": 0.003063180586734181, "phrase": "voiced_speech_segment"}, {"score": 0.002931569771634119, "phrase": "proposed_four_subsystems"}, {"score": 0.0028246207858247732, "phrase": "competitive_results"}, {"score": 0.0027961342030212353, "phrase": "different_age_and_gender_groups"}, {"score": 0.0027400176498756823, "phrase": "overall_classification_performance"}, {"score": 0.00266693888510356, "phrase": "seven_subsystems"}, {"score": 0.002640038329840458, "phrase": "score_level"}, {"score": 0.0026045914281028473, "phrase": "experiment_results"}, {"score": 0.0025436978068459565, "phrase": "test_set"}, {"score": 0.0024758420717852113, "phrase": "svm_baseline_system"}, {"score": 0.0024097920845706795, "phrase": "baseline_system"}, {"score": 0.0023774292521631093, "phrase": "challenge_committee"}, {"score": 0.002353441996629643, "phrase": "proposed_fusion_system"}, {"score": 0.002321834168782981, "phrase": "unweighted_accuracy"}, {"score": 0.0022984065518052476, "phrase": "age_task"}, {"score": 0.002259883463607508, "phrase": "gender_task"}, {"score": 0.0022370795358896784, "phrase": "development_set"}, {"score": 0.0022070310530794097, "phrase": "final_test_set"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Age recognition", " Gender recognition", " Prosodic features", " Pitch", " Harmonic structure", " Formant", " Polynomial expansion", " Maximum likelihood linear regression", " UBM weight posterior probability supervectors", " GMM", " SVM", " Sparse representation", " Score level fusion"], "paper_abstract": "The paper presents a novel automatic speaker age and gender identification approach which combines seven different methods at both acoustic and prosodic levels to improve the baseline performance. The three baseline subsystems are (1) Gaussian mixture model (GMM) based on mel-frequency cepstral coefficient (MFCC) features, (2) Support vector machine (SVM) based on GMM mean supervectors and (3) SVM based on 450-dimensional utterance level features including acoustic, prosodic and voice quality information. In addition, we propose four subsystems: (1) SVM based on UBM weight posterior probability supervectors using the Bhattacharyya probability product kernel, (2) Sparse representation based on UBM weight posterior probability supervectors, (3) SVM based on GMM maximum likelihood linear regression (MLLR) matrix supervectors and (4) SVM based on the polynomial expansion coefficients of the syllable level prosodic feature contours in voiced speech segments. Contours of pitch, time domain energy, frequency domain harmonic structure energy and formant for each syllable (segmented using energy information in the voiced speech segment) are considered for analysis in subsystem (4). The proposed four subsystems have been demonstrated to be effective and able to achieve competitive results in classifying different age and gender groups. To further improve the overall classification performance, weighted summation based fusion of these seven subsystems at the score level is demonstrated. Experiment results are reported on the development and test set of the 2010 Interspeech Paralinguistic Challenge aGender database. Compared to the SVM baseline system (3), which is the baseline system suggested by the challenge committee, the proposed fusion system achieves 5.6% absolute improvement in unweighted accuracy for the age task and 4.2% for the gender task on the development set. On the final test set, we obtain 3.1% and 3.8% absolute improvement. respectively. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Automatic speaker age and gender recognition using acoustic and prosodic level information fusion", "paper_id": "WOS:000311524800009"}