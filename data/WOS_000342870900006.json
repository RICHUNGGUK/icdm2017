{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "human_actions"}, {"score": 0.004733625412289433, "phrase": "video_streams"}, {"score": 0.004653667500876187, "phrase": "deeply_optimized_hough"}, {"score": 0.004421770937919324, "phrase": "human_activity_recognition"}, {"score": 0.0041657281535389615, "phrase": "temporal_localization"}, {"score": 0.003858110309630846, "phrase": "new_method"}, {"score": 0.0033660587983313536, "phrase": "new_hough_method"}, {"score": 0.0032810180076973806, "phrase": "previous_published_ones"}, {"score": 0.0032255172568437965, "phrase": "honeybee_dataset"}, {"score": 0.003117307618682836, "phrase": "deeper_optimization"}, {"score": 0.003038532168038565, "phrase": "hough_variables"}, {"score": 0.0028623555849897632, "phrase": "skeleton_features"}, {"score": 0.0023123057299992587, "phrase": "tum_dataset"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Human actions", " Segmentation", " Classification", " Video streams", " Hough"], "paper_abstract": "Most researches on human activity recognition do not take into account the temporal localization of actions. In this paper, a new method is designed to model both actions and their temporal domains. This method is based on a new Hough method which outperforms previous published ones on honeybee dataset thanks to a deeper optimization of the Hough variables. Experiments are performed to select skeleton features adapted to this method and relevant to capture human actions. With these features, our pipeline improves state-of-the-art performances on TUM dataset and outperforms baselines on several public datasets. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Simultaneous segmentation and classification of human actions in video streams using deeply optimized Hough transform", "paper_id": "WOS:000342870900006"}