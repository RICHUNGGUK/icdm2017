{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "non-overlapped_scenes"}, {"score": 0.004709193603747991, "phrase": "challenging_task"}, {"score": 0.004605748839642513, "phrase": "large_number"}, {"score": 0.004347256848088215, "phrase": "observed_object"}, {"score": 0.00421410521089045, "phrase": "different_cameras"}, {"score": 0.003977505904363489, "phrase": "variant_appearances"}, {"score": 0.003804550737731054, "phrase": "sophisticatedly_chosen_image_features"}, {"score": 0.003606866938661143, "phrase": "e.g._sift"}, {"score": 0.0032272929113113203, "phrase": "better_performance"}, {"score": 0.0030595112110658675, "phrase": "adaptive_feature-fusion_algorithm"}, {"score": 0.0029394074636168435, "phrase": "matching_accuracy"}, {"score": 0.0027618869745668017, "phrase": "sift"}, {"score": 0.0027252240573281163, "phrase": "exponential_models"}, {"score": 0.0026771333996253783, "phrase": "similarity_measure"}, {"score": 0.0026182085765020548, "phrase": "adaptive_fusion_algorithm"}, {"score": 0.0024930878032164757, "phrase": "collaborative_similarity_measure"}, {"score": 0.002321665383971456, "phrase": "object_appearances"}, {"score": 0.002290858045013009, "phrase": "multiple_factors"}, {"score": 0.002270546747744344, "phrase": "experimental_results"}, {"score": 0.00221068461235127, "phrase": "human_matching"}, {"score": 0.0021813467128927347, "phrase": "high_robustness"}, {"score": 0.0021049977753042253, "phrase": "previous_fusion_methods"}], "paper_keywords": ["Appearance features", " Feature fusion", " Object matching", " Non-overlapping scenes", " Performance evaluation"], "paper_abstract": "Object matching in non-overlapped scenes of multi-cameras is a challenging task, due to a large number of factors, e.g. complex backgrounds, illumination variance, pose of observed object, viewpoint and image resolutions of different cameras, shadows and occlusions. For an object, matching its observations with variant appearances in such context usually turns to evaluate their similarity over some sophisticatedly chosen image features. We observe that certain feature is usually robust to certain variance, e.g. SIFT is robust to the variance in viewpoint and scale. We mean that incorporating the abilities of a bag of such features would reach a better performance. Based on these observations and insights, we propose an adaptive feature-fusion algorithm. The algorithm, first, evaluates the matching accuracy of four sophisticatedly chosen and well validated features: color histogram, UV chromaticity, major color spectrum and SIFT, using exponential models of entropy as similarity measure. Second, an adaptive fusion algorithm is presented to fuse a bag of features for a collaborative similarity measure. Our approach is shown to be able to adaptively and dynamically reduce the variances of object appearances caused by multiple factors. Experimental results show that our approach applied to human matching reaches a high robustness and matching accuracy in comparison with the previous fusion methods.", "paper_title": "An Adaptive Feature-fusion Method for Object Matching over Non-overlapped Scenes", "paper_id": "WOS:000337792800007"}