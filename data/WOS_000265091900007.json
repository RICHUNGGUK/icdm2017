{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "iterated_prisoner's_dilemma"}, {"score": 0.004640079189342692, "phrase": "comparative_performance"}, {"score": 0.00430907756010007, "phrase": "different_environment_settings"}, {"score": 0.004101579688745222, "phrase": "memetic_adaptation_framework"}, {"score": 0.004001593118269276, "phrase": "ipd_strategies"}, {"score": 0.0039040344230094164, "phrase": "complementary_features"}, {"score": 0.0035369291417564606, "phrase": "directed_search"}, {"score": 0.0034720284451902083, "phrase": "evolving_strategies"}, {"score": 0.0034083145672246067, "phrase": "eventual_convergence"}, {"score": 0.0033664873319204027, "phrase": "good_strategy_traits"}, {"score": 0.003145417398038261, "phrase": "learning_strategies"}, {"score": 0.0030497740719977835, "phrase": "double-loop_incremental_learning_scheme"}, {"score": 0.0029207251108325006, "phrase": "classification_component"}, {"score": 0.002814454488050123, "phrase": "feedback_learning_mechanism"}, {"score": 0.0026953359825383646, "phrase": "evolutionary_process"}, {"score": 0.0026133424923929227, "phrase": "simulation_results"}, {"score": 0.00230950802983053, "phrase": "other's_weaknesses"}], "paper_keywords": ["Evolution", " genetic algorithm (GA)", " incremental learning (IL)", " prisoner's dilemma"], "paper_abstract": "This paper examines the comparative performance and adaptability of evolutionary, learning, and memetic strategies to different environment settings in the Iterated Prisoner's Dilemma (IPD). A memetic adaptation framework is developed for IPD strategies to exploit the complementary features of evolution and learning. In the paradigm, learning serves as a form of directed search to guide evolving strategies to attain eventual convergence towards good strategy traits, while evolution helps to minimize disparity in performance among learning strategies. Furthermore, a double-loop incremental learning scheme (ILS) that incorporates a classification component, probabilistic update of strategies and a feedback learning mechanism is proposed and incorporated into the evolutionary process. A series of simulation results verify that the two techniques, when employed together, are able to complement each (other's strengths and compensate for each other's weaknesses, leading to the formation of strategies that will adapt and thrive well in complex, dynamic environments.", "paper_title": "Evolution and Incremental Learning in the Iterated Prisoner's Dilemma", "paper_id": "WOS:000265091900007"}