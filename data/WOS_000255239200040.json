{"auto_keywords": [{"score": 0.048992899974696226, "phrase": "time-varying_delays"}, {"score": 0.00481495049065317, "phrase": "recurrent_neural_networks"}, {"score": 0.004494570360108983, "phrase": "lyapunov-krasovskii_functional_or_lyapunov-razumikhin_functional_method"}, {"score": 0.004053362743156545, "phrase": "new_method"}, {"score": 0.003697538418750941, "phrase": "general_recurrent_neural_networks"}, {"score": 0.003531474887552889, "phrase": "convex_optimization_method"}, {"score": 0.00307657476125683, "phrase": "local_exponential_stability_conditions"}, {"score": 0.0027741761880779535, "phrase": "linear_matrix_inequalities"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["recurrent neural networks", " time-varying delays", " domain of attraction", " local exponential stability", " Lyapunov-Razumikhin functional", " Lyapunov-Krasovskii functional", " linear matrix inequality"], "paper_abstract": "Based on Lyapunov-Krasovskii functional or Lyapunov-Razumikhin functional method and invariant set principle, we presented a new method to estimate the domain of attraction for general recurrent neural networks with time-varying delays. Convex optimization method is proposed to enlarge and estimate the domain of attraction. Local exponential stability conditions are derived, which can be expressed as linear matrix inequalities (LMIs) in terms of all the varying parameters and hence can be easily checked in both analysis and design. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "An estimation of the domain of attraction for recurrent neural networks with time-varying delays", "paper_id": "WOS:000255239200040"}