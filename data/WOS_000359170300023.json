{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "heterogeneous_feature_selection"}, {"score": 0.0042354707960660706, "phrase": "heterogeneous_data"}, {"score": 0.004058180509184539, "phrase": "continuous_and_categorical_variables"}, {"score": 0.0036727235025069828, "phrase": "dedicated_kernel"}, {"score": 0.0032302647179383915, "phrase": "recursive_feature_elimination_procedure"}, {"score": 0.003007846011394511, "phrase": "multiple_kernel_learning"}, {"score": 0.0022933216359142736, "phrase": "high-dimensional_classification_tasks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Heterogeneous feature selection", " Kernel methods", " Mixed data", " Multiple kernel learning", " Support vector machine", " Recursive feature elimination"], "paper_abstract": "This paper introduces two feature selection methods to deal with heterogeneous data that include continuous and categorical variables. We propose to plug a dedicated kernel that handles both kinds of variables into a Recursive Feature Elimination procedure using either a non-linear SVM or Multiple Kernel Learning. These methods are shown to offer state-of-the-art performances on a variety of high-dimensional classification tasks. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Kernel methods for heterogeneous feature selection", "paper_id": "WOS:000359170300023"}