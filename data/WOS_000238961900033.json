{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "kernel_functions"}, {"score": 0.048929739366992464, "phrase": "binary_regression"}, {"score": 0.004586531354697466, "phrase": "kernel-based_learning_algorithms"}, {"score": 0.0041112665381266315, "phrase": "appropriate_kernel_functions"}, {"score": 0.003223494720348768, "phrase": "bell-shaped_cosine_function"}, {"score": 0.002526938673434697, "phrase": "karhunen-loeve_expansion"}, {"score": 0.002183347623351868, "phrase": "principal_component"}, {"score": 0.0021049977753042253, "phrase": "correlation_operator"}], "paper_keywords": ["supervised learning", " regression", " kernel methods", " kernel functions", " Karhunen-Loeve expansion", " principal component analysis", " binary regression", " Gaussian kernel"], "paper_abstract": "Kernel-based learning algorithms have been successfully applied in various problem domains, given appropriate kernel functions. In this paper, we discuss the problem of designing kernel functions for binary regression and show that using a bell-shaped cosine function as a kernel function is optimal in some sense. The rationale of this result is based on the Karhunen-Loeve expansion, i.e., the optimal approximation to a set of functions is given by the principal component of the correlation operator of the functions.", "paper_title": "Constructing kernel functions for binary regression", "paper_id": "WOS:000238961900033"}