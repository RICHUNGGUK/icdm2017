{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "subject_cooperation"}, {"score": 0.04734309209813982, "phrase": "cooperative_subjects"}, {"score": 0.04534771172479731, "phrase": "gait_sequences"}, {"score": 0.040366363919436855, "phrase": "covariate_conditions"}, {"score": 0.004493275458211613, "phrase": "previous_work_gait_recognition"}, {"score": 0.0042809216371527785, "phrase": "similar_covariate_conditions"}, {"score": 0.004064478393319772, "phrase": "evaluation_procedure"}, {"score": 0.003967235882351874, "phrase": "gait_data"}, {"score": 0.003899199029692063, "phrase": "cooperative_manner"}, {"score": 0.0037148167062767096, "phrase": "gait_recognition_approaches"}, {"score": 0.003418719577853084, "phrase": "different_and_unknown_covariate_conditions"}, {"score": 0.0033023994098455457, "phrase": "existing_approaches"}, {"score": 0.002997269132281551, "phrase": "gait_recognition_system"}, {"score": 0.002895246938820814, "phrase": "gait_entropy_image"}, {"score": 0.0028161281608563267, "phrase": "automatic_feature_selection"}, {"score": 0.0027486699590262343, "phrase": "probe_gait_sequences"}, {"score": 0.002701474449898187, "phrase": "adaptive_component_and_discriminant_analysis"}, {"score": 0.0025735828740162223, "phrase": "robust_recognition"}, {"score": 0.00246877952076635, "phrase": "conventional_component"}, {"score": 0.0023600436133011425, "phrase": "casia"}, {"score": 0.0023114798074455453, "phrase": "distance_gait_database"}, {"score": 0.0022955150243239623, "phrase": "soton"}, {"score": 0.0022327484973125936, "phrase": "proposed_approach"}, {"score": 0.0022020103573658035, "phrase": "existing_techniques"}, {"score": 0.002149231173009159, "phrase": "variable_and_unknown_covariate_conditions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Biometrics", " Gait recognition", " Gait Energy Image", " Feature selection", " Adaptive Component and Discriminant", " Analysis"], "paper_abstract": "The strength of gait, compared to other biometrics, is that it does not require cooperative subjects. In previous work gait recognition approaches were evaluated using a gallery set consisting of gait sequences of people under similar covariate conditions (e.g. clothing, surface, carrying, and view conditions). This evaluation procedure, however, implies that the gait data are collected in a cooperative manner so that the covariate conditions are known a priori. In this work, gait recognition approaches are evaluated without the assumption on cooperative subjects, i.e. both the gallery and the probe sets consist of a mixture of gait sequences under different and unknown covariate conditions. The results indicate that the performance of the existing approaches would drop drastically under this more realistic experimental setup. We argue that selecting the most relevant gait features that are invariant to changes in gait covariate conditions is the key to develop a gait recognition system that works without subject cooperation. To this end. Gait Entropy Image (GEnl) is proposed to perform automatic feature selection on each pair of gallery and probe gait sequences. Moreover, an Adaptive Component and Discriminant Analysis (ACDA) is formulated which seamlessly integrates our feature selection method with subspace analysis for robust recognition, and importantly is computationally much more efficient compared to the conventional Component and Discriminant Analysis. Experiments are carried out on two comprehensive benchmarking databases: the CASIA database and the Southampton Human ID at a distance gait database (SOTON database). Our results demonstrate that the proposed approach significantly outperforms the existing techniques particularly when gait is captured with variable and unknown covariate conditions. (c) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Gait recognition without subject cooperation", "paper_id": "WOS:000282146800036"}