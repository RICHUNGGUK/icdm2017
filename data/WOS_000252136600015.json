{"auto_keywords": [{"score": 0.048734215142491696, "phrase": "heuristic_fuzzy_rules"}, {"score": 0.04840352423674947, "phrase": "bigram_markov_language_models"}, {"score": 0.04710194427159924, "phrase": "recognition_accuracy"}, {"score": 0.004815079207167975, "phrase": "chinese"}, {"score": 0.004613516457919661, "phrase": "statistical_language_models"}, {"score": 0.004483909657713567, "phrase": "optical_character_recognition"}, {"score": 0.004373480870285314, "phrase": "previous_systems"}, {"score": 0.004311598785718415, "phrase": "maximum_word"}, {"score": 0.004265760046406154, "phrase": "semantic_class_segmentation"}, {"score": 0.004205395707787349, "phrase": "language_models"}, {"score": 0.003902165732101058, "phrase": "longer_words"}, {"score": 0.003765525342866404, "phrase": "word_dependencies"}, {"score": 0.0036727235025069828, "phrase": "high_memory"}, {"score": 0.003544088803300751, "phrase": "novel_bigram_markov_language_model"}, {"score": 0.003395640013786862, "phrase": "large_word_preferences"}, {"score": 0.0033356305227059072, "phrase": "semantically_segmented_training_data"}, {"score": 0.0032766780632972363, "phrase": "trigram_models"}, {"score": 0.0032418062548293745, "phrase": "memory_requirement"}, {"score": 0.0031170783606525856, "phrase": "handheld_and_pocket_computers"}, {"score": 0.003029382820031577, "phrase": "major_future_application"}, {"score": 0.0030078460113945136, "phrase": "text_recognition_systems"}, {"score": 0.0029336622847544857, "phrase": "simple_language_model"}, {"score": 0.0029024303666003153, "phrase": "bigram_markov_model"}, {"score": 0.002780783274864117, "phrase": "novel_algorithm"}, {"score": 0.0025073851194697397, "phrase": "mobile_and_pocket_computer_applications"}, {"score": 0.0024281181691350085, "phrase": "experimental_results"}, {"score": 0.002368198542691635, "phrase": "mobile_phones"}, {"score": 0.002342972434255588, "phrase": "main_contribution"}, {"score": 0.002268891304166886, "phrase": "linguistic_rules"}, {"score": 0.0021893168527276105, "phrase": "crisp_recognition_system"}, {"score": 0.002150580119047236, "phrase": "low_computational_complexity"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["statistical language model", " Markov model", " heuristic", " fuzzy logic"], "paper_abstract": "Statistical language models are very useful tools to improve the recognition accuracy of optical character recognition (OCR) systems. In previous systems, segmentation by maximum word matching, semantic class segmentation, or trigram language models have been used. However, these methods have some disadvantages, such as inaccuracies due to a preference for longer words (which may be erroneous), failure to recognize word dependencies, complex semantic training data segmentation, and a requirement of high memory. To overcome these problems, we propose a novel bigram Markov language model in this paper. This type of model does not have large word preferences and does not require semantically segmented training data. Furthermore, unlike trigram models, the memory requirement is small. Thus, the scheme is suitable for handheld and pocket computers, which are expected to be a major future application of text recognition systems. However, due to a simple language model, the bigram Markov model alone can introduce more errors. Hence in this paper, a novel algorithm combining bigram Markov language models with heuristic fuzzy rules is described. It is found that the recognition accuracy is improved through the use of the algorithm, and it is well suited to mobile and pocket computer applications, including as we will show in the experimental results, the ability to run on mobile phones. The main contribution of this paper is to show how fuzzy techniques as linguistic rules can be used to enhance the accuracy of a crisp recognition system, and still have low computational complexity. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Efficient mobile phone Chinese optical character recognition systems by use of heuristic fuzzy rules and bigram Markov language models", "paper_id": "WOS:000252136600015"}