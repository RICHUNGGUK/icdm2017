{"auto_keywords": [{"score": 0.04682254053814278, "phrase": "irt"}, {"score": 0.00481495049065317, "phrase": "optimal_educational_tests"}, {"score": 0.004786821283037044, "phrase": "gmdh-based_item_ranking"}, {"score": 0.004648609688625397, "phrase": "key_role"}, {"score": 0.0046079260641779755, "phrase": "concise_and_informative_educational_tests"}, {"score": 0.0045143706249204905, "phrase": "item_response_theory"}, {"score": 0.004320213877598964, "phrase": "model_parameters"}, {"score": 0.004134372859330047, "phrase": "larger_item_banks"}, {"score": 0.0041102032028337366, "phrase": "machine-learning_techniques"}, {"score": 0.0040385352882334235, "phrase": "data-based_models"}, {"score": 0.0039218440805789965, "phrase": "examinees'_responses"}, {"score": 0.0038085117064624208, "phrase": "test_item_selection"}, {"score": 0.0037530749925749245, "phrase": "vast_amount"}, {"score": 0.0037093050169987947, "phrase": "feature_selection"}, {"score": 0.0036660436272785476, "phrase": "machine_learning"}, {"score": 0.003644601816390735, "phrase": "artificial_intelligence"}, {"score": 0.003591542373891629, "phrase": "high_data_dimensionality"}, {"score": 0.00353777735256751, "phrase": "gmdh"}, {"score": 0.0035288860880035985, "phrase": "novel_technique"}, {"score": 0.0035082436540296406, "phrase": "item_ranking"}, {"score": 0.0034268702387746106, "phrase": "group_method"}, {"score": 0.0031845067058084613, "phrase": "examinee's_true_ability_level"}, {"score": 0.003044828527806981, "phrase": "iif"}, {"score": 0.003038440237182784, "phrase": "optimum_input_features"}, {"score": 0.002994178996584381, "phrase": "available_inputs"}, {"score": 0.0028568174308720167, "phrase": "average_item_information_function"}, {"score": 0.0028069426877159642, "phrase": "pass-fail_ability_threshold"}, {"score": 0.0026546631773394416, "phrase": "optimum_item_subset"}, {"score": 0.002623669616798891, "phrase": "gmdh-based_ranking"}, {"score": 0.0025778546800417808, "phrase": "test_items"}, {"score": 0.0024667783849055634, "phrase": "randomly_selected_item_subset"}, {"score": 0.0023674192513753996, "phrase": "largest_values"}, {"score": 0.0023056642309229017, "phrase": "item_rankings"}, {"score": 0.0022787359717772976, "phrase": "proposed_approach"}, {"score": 0.0022323643840655646, "phrase": "neural_network_modeling"}, {"score": 0.0022192891418394514, "phrase": "popular_filter_type_feature_selection_methods"}, {"score": 0.0021550502873107654, "phrase": "wrapper_methods"}, {"score": 0.002142426911242168, "phrase": "genetic_search"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["GMDH algorithm", " Abductive networks", " Neural networks", " Machine learning", " Optimal test design", " Feature selection", " Feature ranking", " Educational measurements", " Item response theory", " Mutual information", " Filter methods", " Wrapper methods", " Genetic algorithms"], "paper_abstract": "Item ranking and selection plays a key role in constructing concise and informative educational tests. Traditional techniques based on the item response theory (IRT) have been used to automate this task, but they require model parameters to be determined a priori for each item and their application becomes more tedious with larger item banks. Machine-learning techniques can be used to build data-based models that relate the test result as output to the examinees' responses to various test items as inputs. With this approach, test item selection can benefit from the vast amount of literature on feature selection in many areas of machine learning and artificial intelligence that are characterized by high data dimensionality. This paper describes a novel technique for item ranking and selection using abductive network pass/fail classifiers based on the group method of data handling (GMDH). Experiments were carried out on a dataset consisting of the response of 2000 examinees to 45 test items together with the examinee's true ability level. The approach utilizes the ability of GMDH-based learning algorithms to automatically select optimum input features from a set of available inputs. Rankings obtained by iteratively applying this procedure are similar to those based on the average item information function (IIF) at the pass-fail ability threshold, IIF (theta = 0), and the average information gain (IG). An optimum item subset derived from the GMDH-based ranking contains only one third of the test items and performs pass/fail classification with 91.2% accuracy on a 500-case evaluation subset, compared to 86.8% for a randomly selected item subset of the same size and 92% for a subset of the 15 items having the largest values for IIF (theta = 0). Item rankings obtained with the proposed approach compare favorably with those obtained using neural network modeling and popular filter type feature selection methods, and the proposed approach is much faster than wrapper methods employing genetic search. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Constructing optimal educational tests using GMDH-based item ranking and selection", "paper_id": "WOS:000263372000054"}