{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "error_resilience"}, {"score": 0.04965333175972822, "phrase": "neural_networks"}, {"score": 0.04819193630515393, "phrase": "inexact_computing"}, {"score": 0.004729704116022601, "phrase": "designing_highly_energy_efficient_accelerators"}, {"score": 0.004383852039913171, "phrase": "energy_consumption"}, {"score": 0.004063186599879217, "phrase": "tolerable_amounts"}, {"score": 0.004027031316965272, "phrase": "application_accuracy"}, {"score": 0.003955679223407243, "phrase": "significant_resource_savings"}, {"score": 0.0035216195857272403, "phrase": "application-specified_integrated_circuits"}, {"score": 0.003397866151093552, "phrase": "asic_realizations"}, {"score": 0.0033525843225012918, "phrase": "narrow_application_scope"}, {"score": 0.0030520148188164084, "phrase": "resource_savings"}, {"score": 0.0028667159745494933, "phrase": "application_scope"}, {"score": 0.0028032928749970026, "phrase": "energy_savings"}, {"score": 0.002716844480081738, "phrase": "hardware_neural_networks"}, {"score": 0.002621297299343551, "phrase": "popular_candidate_accelerators"}, {"score": 0.00259793885118959, "phrase": "future_heterogeneous_multicore_platforms"}, {"score": 0.0025632898741546556, "phrase": "flexible_error_resilience_limits"}, {"score": 0.0024075916292945715, "phrase": "proposed_inexact_neural_network_accelerator"}, {"score": 0.0023125191783901367, "phrase": "corresponding_delay"}, {"score": 0.002291905937251069, "phrase": "area_savings"}, {"score": 0.0021720199689914464, "phrase": "existing_baseline_neural_network_implementation"}, {"score": 0.0021049977753042253, "phrase": "small_accuracy_loss"}], "paper_keywords": ["Accelerator architectures", " energy efficient", " hardware neuron network", " inexact computing"], "paper_abstract": "In recent years, inexact computing has been increasingly regarded as one of the most promising approaches for slashing energy consumption in many applications that can tolerate a certain degree of inaccuracy. Driven by the principle of trading tolerable amounts of application accuracy in return for significant resource savings-the energy consumed, the (critical path) delay, and the (silicon) area-this approach has been limited to application-specified integrated circuits (ASICs) so far. These ASIC realizations have a narrow application scope and are often rigid in their tolerance to inaccuracy, as currently designed; the latter often determining the extent of resource savings we would achieve. In this paper, we propose to improve the application scope, error resilience and the energy savings of inexact computing by combining it with hardware neural networks. These neural networks are fast emerging as popular candidate accelerators for future heterogeneous multicore platforms and have flexible error resilience limits owing to their ability to be trained. Our results in 65-nm technology demonstrate that the proposed inexact neural network accelerator could achieve 1.78-2.67x savings in energy consumption (with corresponding delay and area savings being 1.23 and 1.46x, respectively) when compared to the existing baseline neural network implementation, at the cost of a small accuracy loss (mean squared error increases from 0.14 to 0.20 on average).", "paper_title": "Leveraging the Error Resilience of Neural Networks for Designing Highly Energy Efficient Accelerators", "paper_id": "WOS:000358620700002"}