{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "unified_framework"}, {"score": 0.004458722048888919, "phrase": "decision_tree_ensembles"}, {"score": 0.0043738432231020885, "phrase": "classifier_ensembles"}, {"score": 0.0042495320879288615, "phrase": "active_area"}, {"score": 0.002948547333717581, "phrase": "original_database"}, {"score": 0.002432152706473349, "phrase": "extreme_cases"}], "paper_keywords": ["ensemble methods", " decision trees"], "paper_abstract": "Classifier ensembles is an active area of research within the machine learning community. One of the most successful techniques is bagging, where an algorithm (typically a decision tree inducer) is applied over several different training sets, obtained applying sampling with replacement to the original database. In this paper we define a framework where sampling with and without replacement can be viewed as the extreme cases of a more general process, and analyze the performance of the extension of bagging to such framework.", "paper_title": "On a unified framework for sampling with and without replacement in decision tree ensembles", "paper_id": "WOS:000242122400012"}