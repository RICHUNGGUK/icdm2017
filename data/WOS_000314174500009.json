{"auto_keywords": [{"score": 0.0376846417567489, "phrase": "coverage_goals"}, {"score": 0.012087658607118374, "phrase": "common_approach"}, {"score": 0.0047597635659244655, "phrase": "program_crashes"}, {"score": 0.004615656893404919, "phrase": "formal_specification"}, {"score": 0.004493130934067195, "phrase": "software_test's_outcome"}, {"score": 0.004441616106463486, "phrase": "common_scenario"}, {"score": 0.004407599980762272, "phrase": "software_testing"}, {"score": 0.004340343873304156, "phrase": "test_data"}, {"score": 0.004192730391924712, "phrase": "test_oracles"}, {"score": 0.0040971095888461045, "phrase": "difficult_task"}, {"score": 0.003988293689448734, "phrase": "small_yet_representative_test_sets"}, {"score": 0.0038526069752138196, "phrase": "code_coverage"}, {"score": 0.003735862292632131, "phrase": "fundamental_problem"}, {"score": 0.0033672608231654897, "phrase": "test_generation"}, {"score": 0.003058371727071558, "phrase": "novel_paradigm"}, {"score": 0.0030232568024943455, "phrase": "whole_test_suites"}, {"score": 0.002842655426951218, "phrase": "total_size"}, {"score": 0.002601727192945944, "phrase": "infeasible_targets"}, {"score": 0.0025130941721410558, "phrase": "novel_approach"}, {"score": 0.0024842242921857705, "phrase": "evosuite_tool"}, {"score": 0.002326767693352058, "phrase": "open_source_libraries"}, {"score": 0.00230003335593664, "phrase": "industrial_case_study"}, {"score": 0.002213112756450354, "phrase": "evosuite"}, {"score": 0.0021294699637639564, "phrase": "single_branches"}], "paper_keywords": ["Search-based software engineering", " length", " branch coverage", " genetic algorithm", " infeasible goal", " collateral coverage"], "paper_abstract": "Not all bugs lead to program crashes, and not always is there a formal specification to check the correctness of a software test's outcome. A common scenario in software testing is therefore that test data are generated, and a tester manually adds test oracles. As this is a difficult task, it is important to produce small yet representative test sets, and this representativeness is typically measured using code coverage. There is, however, a fundamental problem with the common approach of targeting one coverage goal at a time: Coverage goals are not independent, not equally difficult, and sometimes infeasible-the result of test generation is therefore dependent on the order of coverage goals and how many of them are feasible. To overcome this problem, we propose a novel paradigm in which whole test suites are evolved with the aim of covering all coverage goals at the same time while keeping the total size as small as possible. This approach has several advantages, as for example, its effectiveness is not affected by the number of infeasible targets in the code. We have implemented this novel approach in the EVOSUITE tool, and compared it to the common approach of addressing one goal at a time. Evaluated on open source libraries and an industrial case study for a total of 1,741 classes, we show that EVOSUITE achieved up to 188 times the branch coverage of a traditional approach targeting single branches, with up to 62 percent smaller test suites.", "paper_title": "Whole Test Suite Generation", "paper_id": "WOS:000314174500009"}