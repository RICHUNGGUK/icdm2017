{"auto_keywords": [{"score": 0.028906609734183148, "phrase": "super-turing_level"}, {"score": 0.00481495049065317, "phrase": "plastic_recurrent"}, {"score": 0.00468627326602559, "phrase": "computational_capabilities"}, {"score": 0.004623224002010226, "phrase": "biologically_inspired_neural_model"}, {"score": 0.004561019117546361, "phrase": "synaptic_weights"}, {"score": 0.004499647408293102, "phrase": "connectivity_pattern"}, {"score": 0.004110993414942228, "phrase": "mere_concept"}, {"score": 0.0036224139706218916, "phrase": "so-called_plastic_recurrent_neural_networks"}, {"score": 0.0034937647771945803, "phrase": "precise_super-turing_computational_power"}, {"score": 0.0034311578789991363, "phrase": "static_analog_neural_networks"}, {"score": 0.003294350220187021, "phrase": "rational_or_real_numbers"}, {"score": 0.0030922667860233603, "phrase": "bi-valued_updates"}, {"score": 0.0028634235895823594, "phrase": "basic_model"}, {"score": 0.0027741761880779535, "phrase": "turing_barrier"}, {"score": 0.0026157259734105, "phrase": "architectural_plasticity"}, {"score": 0.0025804616931593897, "phrase": "real_synaptic_weights"}, {"score": 0.00237861522566195, "phrase": "general_mechanism"}, {"score": 0.0022940375532231145, "phrase": "computational_and_dynamical_capabilities"}, {"score": 0.0022733662000757318, "phrase": "biological_neural_networks"}, {"score": 0.0021434588322608653, "phrase": "suitable_way"}, {"score": 0.0021049977753042253, "phrase": "brain-like_models"}], "paper_keywords": ["Neural networks", " plastic neural networks", " neural computation", " Turing machines", " Turing machines with advice", " super-Turing", " plasticity", " evolvability", " adaptability", " learning", " computational capabilities"], "paper_abstract": "We study the computational capabilities of a biologically inspired neural model where the synaptic weights, the connectivity pattern, and the number of neurons can evolve over time rather than stay static. Our study focuses on the mere concept of plasticity of the model so that the nature of the updates is assumed to be not constrained. In this context, we show that the so-called plastic recurrent neural networks (RNNs) are capable of the precise super-Turing computational power - as the static analog neural networks - irrespective of whether their synaptic weights are modeled by rational or real numbers, and moreover, irrespective of whether their patterns of plasticity are restricted to bi-valued updates or expressed by any other more general form of updating. Consequently, the incorporation of only bi-valued plastic capabilities in a basic model of RNNs suffices to break the Turing barrier and achieve the super-Turing level of computation. The consideration of more general mechanisms of architectural plasticity or of real synaptic weights does not further increase the capabilities of the networks. These results support the claim that the general mechanism of plasticity is crucially involved in the computational and dynamical capabilities of biological neural networks. They further show that the super-Turing level of computation reflects in a suitable way the capabilities of brain-like models of computation.", "paper_title": "THE SUPER-TURING COMPUTATIONAL POWER OF PLASTIC RECURRENT NEURAL NETWORKS", "paper_id": "WOS:000345514800003"}