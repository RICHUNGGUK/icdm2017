{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "approximate_bayesian_computation"}, {"score": 0.004661655108860597, "phrase": "abc"}, {"score": 0.004476399615305783, "phrase": "popular_technique"}, {"score": 0.00436890075128947, "phrase": "bayesian_inference"}, {"score": 0.004298666679374568, "phrase": "complex_models"}, {"score": 0.004028796143006953, "phrase": "abc_approximation"}, {"score": 0.003900257249255497, "phrase": "biased_filtering"}, {"score": 0.003806541299696042, "phrase": "hidden_markov_model"}, {"score": 0.0037150687722055727, "phrase": "likelihood_function"}, {"score": 0.003236596168242036, "phrase": "target_probability_density"}, {"score": 0.0028195727965553367, "phrase": "competing_methods"}, {"score": 0.002751751956416832, "phrase": "theoretical_bias"}, {"score": 0.00235843888868088, "phrase": "increased_computational_effort"}, {"score": 0.0022281257694320455, "phrase": "constrained_sequential_lasso"}, {"score": 0.0021922308351126746, "phrase": "portfolio_allocation"}], "paper_keywords": ["Approximate Bayesian computation", " Hidden Markov model", " Filtering", " Bias", " Sequential Monte Carlo"], "paper_abstract": "Approximate Bayesian computation (ABC) has become a popular technique to facilitate Bayesian inference from complex models. In this article we present an ABC approximation designed to perform biased filtering for a Hidden Markov Model when the likelihood function is intractable. We use a sequential Monte Carlo (SMC) algorithm to both fit and sample from our ABC approximation of the target probability density. This approach is shown to, empirically, be more accurate w.r.t. the original filter than competing methods. The theoretical bias of our method is investigated; it is shown that the bias goes to zero at the expense of increased computational effort. Our approach is illustrated on a constrained sequential lasso for portfolio allocation to 15 constituents of the FTSE 100 share index.", "paper_title": "Filtering via approximate Bayesian computation", "paper_id": "WOS:000310232000006"}