{"auto_keywords": [{"score": 0.041955245636141274, "phrase": "latent_variables"}, {"score": 0.015505893263073004, "phrase": "single_latent_variable"}, {"score": 0.010604363760820858, "phrase": "bayes_estimation"}, {"score": 0.009853459661251103, "phrase": "bayes_method"}, {"score": 0.00481495049065317, "phrase": "bayesian_estimation"}, {"score": 0.003911578552479064, "phrase": "underlying_processes"}, {"score": 0.0036328561748082138, "phrase": "estimation_accuracy"}, {"score": 0.0035994372026264478, "phrase": "observable_variables"}, {"score": 0.0035498822293046884, "phrase": "theoretical_analysis"}, {"score": 0.003358368814209542, "phrase": "previous_study"}, {"score": 0.0031918759137610523, "phrase": "joint_probability"}, {"score": 0.002909960617042717, "phrase": "maximum-likelihood_method"}, {"score": 0.0026899455459275575, "phrase": "present_paper"}, {"score": 0.0026284507395498897, "phrase": "asymptotic_expansions"}, {"score": 0.0025922289692173997, "phrase": "error_functions"}, {"score": 0.0024522530645471065, "phrase": "single-variable_estimations"}, {"score": 0.002418453525649304, "phrase": "statistical_regularity"}, {"score": 0.00229844995872581, "phrase": "bayes_and_maximum-likelihood_methods"}, {"score": 0.002164264600379492, "phrase": "multivariable_estimations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Unsupervised learning", " Hierarchical parametric models", " Latent variable", " Bayes estimation"], "paper_abstract": "In data science and machine learning, hierarchical parametric models, such as mixture models, are often used. They contain two kinds of variables: observable variables, which represent the parts of the data that can be directly measured, and latent variables, which represent the underlying processes that generate the data. Although there has been an increase in research on the estimation accuracy for observable variables, the theoretical analysis of estimating latent variables has not been thoroughly investigated. In a previous study, we determined the accuracy of a Bayes estimation for the joint probability of the latent variables in a dataset, and we proved that the Bayes method is asymptotically more accurate than the maximum-likelihood method. However, the accuracy of the Bayes estimation for a single latent variable remains unknown. In the present paper, we derive the asymptotic expansions of the error functions, which are defined by the Kullback-Leibler divergence, for two types of single-variable estimations when the statistical regularity is satisfied. Our results indicate that the accuracies of the Bayes and maximum-likelihood methods are asymptotically equivalent and clarify that the Bayes method is only advantageous for multivariable estimations. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Asymptotic accuracy of Bayesian estimation for a single latent variable", "paper_id": "WOS:000358969900002"}