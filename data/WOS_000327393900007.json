{"auto_keywords": [{"score": 0.04839718571524074, "phrase": "mvc"}, {"score": 0.009315022596706126, "phrase": "wmsn"}, {"score": 0.00481495049065317, "phrase": "multiview_video_coding_efficiency_for_wireless_multimedia_sensor_networks"}, {"score": 0.004720269202737973, "phrase": "empirical_model"}, {"score": 0.00446490613141384, "phrase": "separate_situations"}, {"score": 0.004257000695796238, "phrase": "wireless_multimedia_sensor_networks"}, {"score": 0.0041074234667687875, "phrase": "compression_performance"}, {"score": 0.003916098498242888, "phrase": "overlapping_fields"}, {"score": 0.003808619097554076, "phrase": "common_sensed_area"}, {"score": 0.0037336520904376687, "phrase": "different_views"}, {"score": 0.003588100032858716, "phrase": "geometrical_relationships"}, {"score": 0.0035455471410184404, "phrase": "relative_positions"}, {"score": 0.003517458289610994, "phrase": "different_cameras"}, {"score": 0.0033005860945173136, "phrase": "low-level_phenomena"}, {"score": 0.0030724971661719013, "phrase": "mvc_compression_gain"}, {"score": 0.0030119758165837625, "phrase": "single_view_video_coding"}, {"score": 0.0028037753646260937, "phrase": "low-complexity_estimator"}, {"score": 0.002705121052747945, "phrase": "low_inter-node_signaling_overhead"}, {"score": 0.0026307897899760383, "phrase": "compact_empirical_model"}, {"score": 0.002419798694301991, "phrase": "different_multiview_video_sequences"}, {"score": 0.0022977342663599042, "phrase": "typical_scenarios"}, {"score": 0.0022345720876241044, "phrase": "clustered_or_multi-hop_topologies"}, {"score": 0.0021218313648947926, "phrase": "cross-layer_clustering"}, {"score": 0.0021049977753042253, "phrase": "data_aggregation_procedures"}], "paper_keywords": ["Multiview video coding", " MVC efficiency model", " video sensor networks."], "paper_abstract": "We develop an empirical model of the Multiview Video Coding (MVC) performance that can be used to identify and separate situations when MVC is beneficial from cases when its use is detrimental in wireless multimedia sensor networks (WMSN). The model predicts the compression performance of MVC as a function of the correlation between cameras with overlapping fields of view. We define the common sensed area (CSA) between different views, and emphasize that it depends not only on geometrical relationships among the relative positions of different cameras, but also on various object-related phenomena, e. g., occlusions and motion, and on low-level phenomena such as variations in illumination. With these premises, we first experimentally characterize the relationship between MVC compression gain (with respect to single view video coding) and the CSA between views. Our experiments are based on the H. 264 MVC standard, and on a low-complexity estimator of the CSA that can be computed with low inter-node signaling overhead. Then, we propose a compact empirical model of the efficiency of MVC as a function of the CSA between views, and we validate the model with different multiview video sequences. Finally, we show how the model can be applied to typical scenarios in WMSN, i.e., to clustered or multi-hop topologies, and we show a few promising results of its application in the definition of cross-layer clustering and data aggregation procedures.", "paper_title": "An Empirical Model of Multiview Video Coding Efficiency for Wireless Multimedia Sensor Networks", "paper_id": "WOS:000327393900007"}