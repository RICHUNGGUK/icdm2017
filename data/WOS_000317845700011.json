{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "facial_expressions"}, {"score": 0.004725385523804256, "phrase": "image_snapshots"}, {"score": 0.004383406949799696, "phrase": "static_and_dynamic_recognition"}, {"score": 0.004301834610818624, "phrase": "basic_facial_expressions"}, {"score": 0.003807242767474929, "phrase": "texture-independent_scheme"}, {"score": 0.003701401653850141, "phrase": "facial_action_parameters"}, {"score": 0.003401148484767927, "phrase": "learned_facial_actions"}, {"score": 0.003306559295382181, "phrase": "different_facial_expressions"}, {"score": 0.0032449610741097992, "phrase": "time_series"}, {"score": 0.003038237581227068, "phrase": "dynamic_scheme"}, {"score": 0.002818013056816282, "phrase": "individual_snapshots"}, {"score": 0.0021049977753042253, "phrase": "vector_machines"}], "paper_keywords": ["Facial expression recognition", " Subspace learning", " Static and dynamic classifier", " Human machine interaction"], "paper_abstract": "This paper addresses the static and dynamic recognition of basic facial expressions. It has two main contributions. First, we introduce a view- and texture-independent scheme that exploits facial action parameters estimated by an appearance-based 3D face tracker. We represent the learned facial actions associated with different facial expressions by time series. Second, we compare this dynamic scheme with a static one based on analyzing individual snapshots and show that the former performs better than the latter. We provide evaluations of performance using three subspace learning techniques: linear discriminant analysis, non-parametric discriminant analysis and support vector machines.", "paper_title": "Texture-independent recognition of facial expressions in image snapshots and videos", "paper_id": "WOS:000317845700011"}