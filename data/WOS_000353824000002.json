{"auto_keywords": [{"score": 0.04354342309258674, "phrase": "model_quality"}, {"score": 0.03698689032046005, "phrase": "traditional_models"}, {"score": 0.03424015590946236, "phrase": "local_models"}, {"score": 0.00481495049065317, "phrase": "statistical_modeling"}, {"score": 0.004783105609960904, "phrase": "software_engineering_data"}, {"score": 0.004657808551825796, "phrase": "software_engineering"}, {"score": 0.004490842671590769, "phrase": "software_repositories"}, {"score": 0.004329835888760592, "phrase": "high_amount"}, {"score": 0.004188459638572375, "phrase": "detrimental_effect"}, {"score": 0.004092240621596351, "phrase": "recent_research"}, {"score": 0.003919350990355722, "phrase": "smaller_homogeneous_subsets"}, {"score": 0.003854809457075099, "phrase": "individual_statistical_models"}, {"score": 0.003704196857903231, "phrase": "high_variability"}, {"score": 0.003595097948724078, "phrase": "se_datasets"}, {"score": 0.0032757395605609923, "phrase": "potential_pitfalls"}, {"score": 0.003095806891672679, "phrase": "substantial_impact"}, {"score": 0.00293547027122617, "phrase": "full_advantage"}, {"score": 0.0029160193808720016, "phrase": "local_modeling"}, {"score": 0.002848947756758754, "phrase": "social_data"}, {"score": 0.0027834145465170292, "phrase": "global_modeling"}, {"score": 0.0027193846595965593, "phrase": "appropriate_subsets"}, {"score": 0.0025784931028501375, "phrase": "large_number"}, {"score": 0.002544422946205545, "phrase": "data_subsets"}, {"score": 0.0024776238724770524, "phrase": "hybrid_approach"}, {"score": 0.002461199256106623, "phrase": "local_and_traditional_global_modeling"}, {"score": 0.0024286751532861476, "phrase": "multivariate_adaptive_regression_splines"}, {"score": 0.0024127512918638025, "phrase": "mars"}, {"score": 0.00234142781099973, "phrase": "mars_models"}, {"score": 0.0022648286660146314, "phrase": "prior_calibration"}], "paper_keywords": ["Software metrics", " Statistical modeling", " Clustering"], "paper_abstract": "Much research in software engineering (SE) is focused on modeling data collected from software repositories. Insights gained over the last decade suggests that such datasets contain a high amount of variability in the data. Such variability has a detrimental effect on model quality, as suggested by recent research. In this paper, we propose to split the data into smaller homogeneous subsets and learn sets of individual statistical models, one for each subset, as a way around the high variability in such data. Our case study on a variety of SE datasets demonstrates that such local models can significantly outperform traditional models with respect to model fit and predictive performance. However, we find that analysts need to be aware of potential pitfalls when building local models: firstly, the choice of clustering algorithm and its parameters can have a substantial impact on model quality. Secondly, the data being modeled needs to have enough variability to take full advantage of local modeling. For example, our case study on social data shows no advantage of local over global modeling, as clustering fails to derive appropriate subsets. Lastly, the interpretation of local models can become very complex when there is a large number of variables or data subsets. Overall, we find that a hybrid approach between local and traditional global modeling, such as Multivariate Adaptive Regression Splines (MARS) combines the best of both worlds. MARS models are non-parametric and thus do not require prior calibration of parameters, are easily interpretable by analysts and outperform local, as well as traditional models out of the box in four out of five datasets in our case study.", "paper_title": "Towards improving statistical modeling of software engineering data: think locally, act globally!", "paper_id": "WOS:000353824000002"}