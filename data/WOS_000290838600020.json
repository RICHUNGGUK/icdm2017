{"auto_keywords": [{"score": 0.04614766352910894, "phrase": "sparse_bayesian_learning"}, {"score": 0.013178500413584586, "phrase": "density_estimation"}, {"score": 0.00481495049065317, "phrase": "variable_selection"}, {"score": 0.004713162564945179, "phrase": "quadratic_renyi_entropy"}, {"score": 0.004613516457919661, "phrase": "novel_sparse_kernel_density_estimation_method"}, {"score": 0.004357927940322685, "phrase": "random_iterative_dictionary_preprocessing"}, {"score": 0.004265760046406154, "phrase": "empirical_cumulative_distribution_function"}, {"score": 0.004175533280178052, "phrase": "response_vectors"}, {"score": 0.004087207102190335, "phrase": "sparse_weights"}, {"score": 0.0038332390893263844, "phrase": "proposed_iterative_dictionary"}, {"score": 0.003569451476205552, "phrase": "kernel_computations"}, {"score": 0.0034444213065548688, "phrase": "essential_step"}, {"score": 0.003051073364818384, "phrase": "proposed_method"}, {"score": 0.0029441472095672397, "phrase": "typical_parzen_kernel_density"}, {"score": 0.0024281181691350085, "phrase": "last_example"}, {"score": 0.0023766673143502384, "phrase": "friedman_data"}, {"score": 0.002342972434255588, "phrase": "housing_data"}, {"score": 0.0021971473452127126, "phrase": "proposed_feature_variables_selection_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Sparse kernel density estimation", " Sparse Bayesian learning", " Random iterative dictionary learning", " Quadratic Renyi entropy"], "paper_abstract": "A novel sparse kernel density estimation method is proposed based on the sparse Bayesian learning with random iterative dictionary preprocessing. Using empirical cumulative distribution function as the response vectors, the sparse weights of density estimation are estimated by sparse Bayesian learning. The proposed iterative dictionary learning algorithm is used to reduce the number of kernel computations, which is an essential step of the sparse Bayesian learning. With the sparse kernel density estimation, the quadratic Renyi entropy based normalized mutual information feature selection method is proposed. The simulation of three examples demonstrates that the proposed method is comparable to the typical Parzen kernel density estimations. And compared with other state-of-art sparse kernel density estimations, our method also has a shown very good performance as to the number of kernels required in density estimation. For the last example, the Friedman data and Housing data are used to show the property of the proposed feature variables selection method. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Sparse kernel density estimations and its application in variable selection based on quadratic Renyi entropy", "paper_id": "WOS:000290838600020"}