{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "mutual_information_maximization"}, {"score": 0.004642105253191792, "phrase": "new_linear_discriminant_analysis_method"}, {"score": 0.004378309349451268, "phrase": "mutual_information"}, {"score": 0.0043147264956783565, "phrase": "linearly_transformed_input_data"}, {"score": 0.004221072004655573, "phrase": "class_labels"}, {"score": 0.003952082333580496, "phrase": "kernel-based_estimate"}, {"score": 0.0037823114064881357, "phrase": "variable_kernel_size"}, {"score": 0.0035934073774126856, "phrase": "learning_algorithm"}, {"score": 0.003489714006817602, "phrase": "mutual_information_w.r.t"}, {"score": 0.0032196786163178107, "phrase": "first_one"}, {"score": 0.0031497178007011666, "phrase": "toy_problem"}, {"score": 0.0030143100083252516, "phrase": "transformation_vectors"}, {"score": 0.002948798472453167, "phrase": "original_input_space"}, {"score": 0.0028847066125323893, "phrase": "second_one"}, {"score": 0.0026613618933208467, "phrase": "cross-validation_tests"}, {"score": 0.0025468951021098717, "phrase": "uci_repository"}, {"score": 0.002298544073884724, "phrase": "class_separability"}, {"score": 0.002265095354846931, "phrase": "conventional_methods"}, {"score": 0.0021996478802839316, "phrase": "nonlinear_classification"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Discriminant analysis", " Mutual information", " Feature extraction"], "paper_abstract": "We present a new linear discriminant analysis method based on information theory, where the mutual information between linearly transformed input data and the class labels is maximized. First, we introduce a kernel-based estimate of mutual information with a variable kernel size. Furthermore, we devise a learning algorithm that maximizes the mutual information w.r.t. the linear transformation. Two experiments are conducted: the first one uses a toy problem to visualize and compare the transformation vectors in the original input space; the second one evaluates the performance of the method for classification by employing cross-validation tests on four datasets from the UCI repository. Various classifiers are investigated. Our results show that this method can significantly boost class separability over conventional methods, especially for nonlinear classification. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "A linear discriminant analysis method based on mutual information maximization", "paper_id": "WOS:000286561600013"}