{"auto_keywords": [{"score": 0.04773866258910522, "phrase": "prior_pac-bayes"}, {"score": 0.00481495049065317, "phrase": "pac-bayes_bounds"}, {"score": 0.004755054742217193, "phrase": "data_dependent_priors"}, {"score": 0.004301834610818624, "phrase": "tight_predictions"}, {"score": 0.004248294537944227, "phrase": "svms'_generalization"}, {"score": 0.003795335309109018, "phrase": "available_data"}, {"score": 0.003587235362628753, "phrase": "usual_pac-bayes_generalization"}, {"score": 0.0030097975788892896, "phrase": "separate_data"}, {"score": 0.002525074485615743, "phrase": "experimental_work"}, {"score": 0.0024625017739528096, "phrase": "new_bounds"}, {"score": 0.0023566987138026285, "phrase": "original_pac-bayes"}, {"score": 0.0021049977753042253, "phrase": "prior_svm_algorithm"}], "paper_keywords": ["PAC-Bayes bound", " support vector machine", " generalization capability prediction", " classification"], "paper_abstract": "This paper presents the prior PAC-Bayes bound and explores its capabilities as a tool to provide tight predictions of SVMs' generalization. The computation of the bound involves estimating a prior of the distribution of classifiers from the available data, and then manipulating this prior in the usual PAC-Bayes generalization bound. We explore two alternatives: to learn the prior from a separate data set, or to consider an expectation prior that does not need this separate data set. The prior PAC-Bayes bound motivates two SVM-like classification algorithms, prior SVM and eta-prior SVM, whose regularization term pushes towards the minimization of the prior PAC-Bayes bound. The experimental work illustrates that the new bounds can be significantly tighter than the original PAC-Bayes bound when applied to SVMs, and among them the combination of the prior PAC-Bayes bound and the prior SVM algorithm gives the tightest bound.", "paper_title": "PAC-Bayes Bounds with Data Dependent Priors", "paper_id": "WOS:000314529000002"}