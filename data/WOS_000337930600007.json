{"auto_keywords": [{"score": 0.049494570200460934, "phrase": "riemannian_manifolds"}, {"score": 0.015624504840535772, "phrase": "particle_filters"}, {"score": 0.014882971689762027, "phrase": "riemannian_manifold"}, {"score": 0.014792751878330486, "phrase": "visual_and_infrared_videos"}, {"score": 0.00481495049065317, "phrase": "nonlinear_dynamic_models"}, {"score": 0.004669314230331563, "phrase": "novel_online_domain-shift_appearance"}, {"score": 0.004472760779811399, "phrase": "video_scenarios"}, {"score": 0.004445362365289235, "phrase": "large_deformable_objects"}, {"score": 0.0044181310380945705, "phrase": "fast_out-of-plane_pose_changes"}, {"score": 0.004258195773502909, "phrase": "covariance_descriptors"}, {"score": 0.004206175629459691, "phrase": "visual_object_tracking"}, {"score": 0.004142502468675477, "phrase": "riemannian"}, {"score": 0.004041441391385147, "phrase": "spatially_insensitive_covariance_descriptors"}, {"score": 0.0038239045109853633, "phrase": "long-term_partial_occlusions"}, {"score": 0.0038004655673708016, "phrase": "large-size_deformable_objects"}, {"score": 0.0036854004736318197, "phrase": "proposed_method"}, {"score": 0.0035409897891004105, "phrase": "bayesian_formulation"}, {"score": 0.003423209685399778, "phrase": "appearance_particles"}, {"score": 0.003340011311961488, "phrase": "riemannian_mean"}, {"score": 0.003189408489240117, "phrase": "nonlinear_dynamic_model"}, {"score": 0.0031698463667614004, "phrase": "online_domain-shift_learning"}, {"score": 0.0030738153524707094, "phrase": "manifold_object_appearance"}, {"score": 0.0029898699347664635, "phrase": "criterion-based_partial_occlusion_handling_approach"}, {"score": 0.002908210365588114, "phrase": "object_bounding_box"}, {"score": 0.0028814877314661054, "phrase": "affine_parametric_shape"}, {"score": 0.0028550099401780803, "phrase": "manifold_appearance"}, {"score": 0.002734619281384385, "phrase": "gabor_features"}, {"score": 0.002709487386923251, "phrase": "partitioned_bounding_box"}, {"score": 0.00263546540607024, "phrase": "visual-band_videos"}, {"score": 0.0026192919458528597, "phrase": "thermal-infrared_videos"}, {"score": 0.0025792900811616474, "phrase": "proposed_tracker"}, {"score": 0.0024704972295365164, "phrase": "candidate_appearance_particles"}, {"score": 0.002432762217202045, "phrase": "vector_space"}, {"score": 0.0024103977660677677, "phrase": "candidate_box_particles"}, {"score": 0.002366282306226484, "phrase": "online_learning"}, {"score": 0.002308712197991419, "phrase": "tracking_drift"}, {"score": 0.0022525395705281083, "phrase": "robust_tracking_performance"}, {"score": 0.002231828204535298, "phrase": "proposed_scheme"}, {"score": 0.0021909737736168122, "phrase": "ten_existing_state-of-art_trackers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Domain-shift object learning", " Manifold appearance learning", " Visual object tracking", " Infrared object tracking", " Riemannian manifolds", " Covariance tracking", " Object partition", " Particle filters", " Occlusion handling", " Nonlinear dynamic model"], "paper_abstract": "This paper proposes a novel online domain-shift appearance learning and object tracking scheme on a Riemannian manifold for visual and infrared videos, especially for video scenarios containing large deformable objects with fast out-of-plane pose changes that could be accompanied by partial occlusions. Although Riemannian manifolds and covariance descriptors are promising for visual object tracking, the use of Riemannian mean from a window of observations, spatially insensitive covariance descriptors, fast significant out-of-plane (non-planar) pose changes, and long-term partial occlusions of large-size deformable objects in video limits the performance of such trackers. The proposed method tackles these issues with the following main contributions: (a) Proposing a Bayesian formulation on Riemannian manifolds by using particle filters on the manifold and using appearance particles in each time instant for computing the Riemannian mean, rather than using a window of observations. (b) Proposing a nonlinear dynamic model for online domain-shift learning on the manifold, where the model includes both manifold object appearance and its velocity. (c) Introducing a criterion-based partial occlusion handling approach in online learning. (d) Tracking object bounding box by using affine parametric shape modeling with manifold appearance embedded. (e) Incorporating spatial, frequency and orientation information in the covariance descriptor by extracting Gabor features in a partitioned bounding box. (f) Effectively applying to both visual-band videos and thermal-infrared videos. To realize the proposed tracker, two particle filters are employed: one is applied on the Riemannian manifold for generating candidate appearance particles and another is on vector space for generating candidate box particles. Further, tracking and online learning are performed in alternation to mitigate the tracking drift. Experiments on both visual and infrared videos have shown robust tracking performance of the proposed scheme. Comparisons and evaluations with ten existing state-of-art trackers provide further support to the proposed scheme. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Online domain-shift learning and object tracking based on nonlinear dynamic models and particle filters on Riemannian manifolds", "paper_id": "WOS:000337930600007"}