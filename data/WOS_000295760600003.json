{"auto_keywords": [{"score": 0.047144925784151935, "phrase": "unclassified_point"}, {"score": 0.016844419978232657, "phrase": "k_nearest_points"}, {"score": 0.00481495049065317, "phrase": "k_nearest_neighbor_equality"}, {"score": 0.0047395356621991935, "phrase": "equal_chance"}, {"score": 0.004665296491645837, "phrase": "existing_classes"}, {"score": 0.004592214823540993, "phrase": "nearest_neighbor_classification_method"}, {"score": 0.004379737380744606, "phrase": "nearest_case"}, {"score": 0.004265953661191515, "phrase": "previously_classified_points"}, {"score": 0.004089991141220082, "phrase": "underlying_joint_distribution"}, {"score": 0.004025885154716127, "phrase": "sample_points"}, {"score": 0.003799275066001196, "phrase": "k-nn_method"}, {"score": 0.003529149828147388, "phrase": "voting_criteria"}, {"score": 0.003312901888725435, "phrase": "k-nn_idea"}, {"score": 0.0029501745152877732, "phrase": "mean_distance"}, {"score": 0.0026689487424251907, "phrase": "final_selection_process"}, {"score": 0.0025452314655691165, "phrase": "nearest_neighbor_equality"}, {"score": 0.0024529757621396717, "phrase": "experimental_results"}, {"score": 0.002339246282204109, "phrase": "k-nne_algorithm"}, {"score": 0.0021957487795963666, "phrase": "current_list"}, {"score": 0.002172701452347454, "phrase": "distance_based_classifiers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Nearest neighbor", " Supervised classification", " Machine Learning", " Non-parametric pattern recognition"], "paper_abstract": "The nearest neighbor classification method assigns an unclassified point to the class of the nearest case of a set of previously classified points. This rule is independent of the underlying joint distribution of the sample points and their classifications. An extension to this approach is the k-NN method, in which the classification of the unclassified point is made by following a voting criteria within the k nearest points. The method we present here extends the k-NN idea, searching in each class for the k nearest points to the unclassified point, and classifying it in the class which minimizes the mean distance between the unclassified point and the k nearest points within each class. As all classes can take part in the final selection process, we have called the new approach k Nearest Neighbor Equality (k-NNE). Experimental results we obtained empirically show the suitability of the k-NNE algorithm, and its effectiveness suggests that it could be added to the current list of distance based classifiers. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "K Nearest Neighbor Equality: Giving equal chance to all existing classes", "paper_id": "WOS:000295760600003"}