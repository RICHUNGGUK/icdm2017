{"auto_keywords": [{"score": 0.01513334490403047, "phrase": "image_retrieval"}, {"score": 0.013551995711787694, "phrase": "sift_visual_word"}, {"score": 0.011950115921674262, "phrase": "false_positive_matches"}, {"score": 0.010140573842652784, "phrase": "binary_features"}, {"score": 0.00481495049065317, "phrase": "binary_embedding"}, {"score": 0.004778088905211055, "phrase": "large-scale_image_retrieval"}, {"score": 0.004669180816745142, "phrase": "crucial_step"}, {"score": 0.004340343873304156, "phrase": "matching_pair"}, {"score": 0.003897338526671862, "phrase": "sift"}, {"score": 0.003837817436476726, "phrase": "local_texture_feature"}, {"score": 0.003750260412839128, "phrase": "discriminative_power"}, {"score": 0.0037072310568610723, "phrase": "bow_model"}, {"score": 0.003485913728272778, "phrase": "multiple_binary_features"}, {"score": 0.003459191419478298, "phrase": "indexing_level"}, {"score": 0.00334144503360907, "phrase": "multi-idf_scheme"}, {"score": 0.003265175268104804, "phrase": "different_binary_features"}, {"score": 0.003202944392720772, "phrase": "inverted_file"}, {"score": 0.0031298260299218684, "phrase": "verification_methods"}, {"score": 0.003046621804854539, "phrase": "hamming_embedding"}, {"score": 0.002842655426951218, "phrase": "binary_color_feature"}, {"score": 0.002788454815865172, "phrase": "joint_integration"}, {"score": 0.0026728137770370176, "phrase": "visual_matching"}, {"score": 0.0025521085778978042, "phrase": "extensive_experiments"}, {"score": 0.0023357478549318102, "phrase": "baseline_approach"}, {"score": 0.0022911901892022847, "phrase": "large-scale_experiments"}, {"score": 0.002256155453630723, "phrase": "proposed_method"}, {"score": 0.0022388390432214415, "phrase": "acceptable_memory_usage"}, {"score": 0.002221655243524476, "phrase": "query_time"}, {"score": 0.002154226045704907, "phrase": "global_color_feature"}, {"score": 0.0021049977753042253, "phrase": "competitive_performance"}], "paper_keywords": ["Feature fusion", " coupled binary embedding", " multi-IDF", " image retrieval"], "paper_abstract": "Visual matching is a crucial step in image retrieval based on the bag-of-words (BoW) model. In the baseline method, two keypoints are considered as a matching pair if their SIFT descriptors are quantized to the same visual word. However, the SIFT visual word has two limitations. First, it loses most of its discriminative power during quantization. Second, SIFT only describes the local texture feature. Both drawbacks impair the discriminative power of the BoW model and lead to false positive matches. To tackle this problem, this paper proposes to embed multiple binary features at indexing level. To model correlation between features, a multi-IDF scheme is introduced, through which different binary features are coupled into the inverted file. We show that matching verification methods based on binary features, such as Hamming embedding, can be effectively incorporated in our framework. As an extension, we explore the fusion of binary color feature into image retrieval. The joint integration of the SIFT visual word and binary features greatly enhances the precision of visual matching, reducing the impact of false positive matches. Our method is evaluated through extensive experiments on four benchmark datasets (Ukbench, Holidays, DupImage, and MIR Flickr 1M). We show that our method significantly improves the baseline approach. In addition, large-scale experiments indicate that the proposed method requires acceptable memory usage and query time compared with other approaches. Further, when global color feature is integrated, our method yields competitive performance with the state-of-the-arts.", "paper_title": "Coupled Binary Embedding for Large-Scale Image Retrieval", "paper_id": "WOS:000340099800003"}