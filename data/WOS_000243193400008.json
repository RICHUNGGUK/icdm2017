{"auto_keywords": [{"score": 0.04551169820631223, "phrase": "som"}, {"score": 0.0157195485232107, "phrase": "self-organizing_maps"}, {"score": 0.009766165643151843, "phrase": "concave-convex_learning"}, {"score": 0.004595529592539951, "phrase": "different_ways"}, {"score": 0.004048860957751714, "phrase": "early_approaches"}, {"score": 0.003995226376780718, "phrase": "magnification_control"}, {"score": 0.003942299471749811, "phrase": "vector_quantization"}, {"score": 0.00378767277402891, "phrase": "different_approaches"}, {"score": 0.00368796111048085, "phrase": "ng."}, {"score": 0.0027313326394808853, "phrase": "ng"}, {"score": 0.0025892330566358503, "phrase": "control_mechanisms"}, {"score": 0.0025042115651986332, "phrase": "neural_algorithms"}, {"score": 0.0023739321566540682, "phrase": "ng_results"}, {"score": 0.002295964130868963, "phrase": "data_dimension"}, {"score": 0.002220551141101661, "phrase": "som_case"}, {"score": 0.0021049977753042253, "phrase": "one-dimensional_case"}], "paper_keywords": [""], "paper_abstract": "We consider different ways to control the magnification in self-organizing maps (SOM) and neural gas (NG). Starting from early approaches of magnification control in vector quantization, we then concentrate on different approaches for SOM and NG. We show that three structurally similar approaches can be applied to both algorithms that are localized learning, concave-convex learning, and winner-relaxing learning. Thereby, the approach of concave-convex learning in SOM is extended to a more general description, whereas the concave-convex learning for NG is new. In general, the control mechanisms generate only slightly different behavior comparing both neural algorithms. However, we emphasize that the NG results are valid for any data dimension, whereas in the SOM case, the results hold only for the one-dimensional case.", "paper_title": "Magnification control in self-organizing maps and neural gas", "paper_id": "WOS:000243193400008"}