{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "output_codes"}, {"score": 0.004722254884093624, "phrase": "accuracy-diversity_trade"}, {"score": 0.004653900688892822, "phrase": "ensemble_learning"}, {"score": 0.004411588377842043, "phrase": "supervised_and_unsupervised_learning"}, {"score": 0.004305639197085793, "phrase": "ensemble_sizes"}, {"score": 0.004141365648080381, "phrase": "additional_memory_usage"}, {"score": 0.004101281992566145, "phrase": "computational_overhead"}, {"score": 0.003925633992809873, "phrase": "pruning_algorithms"}, {"score": 0.003757480190200645, "phrase": "combinatorial_problem"}, {"score": 0.003685067218455088, "phrase": "exact_subset"}, {"score": 0.0035616743422949766, "phrase": "different_types"}, {"score": 0.003527181559366122, "phrase": "heuristic_algorithms"}, {"score": 0.00342568771304873, "phrase": "approximate_solution"}, {"score": 0.0033433365160336842, "phrase": "theoretical_guarantee"}, {"score": 0.003278878522165815, "phrase": "output_code"}, {"score": 0.0031536550157613974, "phrase": "well-known_ensemble_techniques"}, {"score": 0.003018468582368033, "phrase": "binary_base_learners"}, {"score": 0.002931569771634119, "phrase": "multiclass_data"}, {"score": 0.0028058765785670546, "phrase": "novel_approach"}, {"score": 0.002751751956416832, "phrase": "ecoc_matrix"}, {"score": 0.0026209522797963447, "phrase": "existing_pruning_methods"}, {"score": 0.002424450174817922, "phrase": "pruning_methods"}, {"score": 0.0021886732310288128, "phrase": "experimental_results"}], "paper_keywords": ["Ensemble learning", " Ensemble pruning", " Error Correcting Output Codes", " DC programming", " Support vector machines", " Integer programming"], "paper_abstract": "Ensemble learning is a method of combining learners to obtain more reliable and accurate predictions in supervised and unsupervised learning. However, the ensemble sizes are sometimes unnecessarily large which leads to additional memory usage, computational overhead and decreased effectiveness. To overcome such side effects, pruning algorithms have been developed; since this is a combinatorial problem, finding the exact subset of ensembles is computationally infeasible. Different types of heuristic algorithms have developed to obtain an approximate solution but they lack a theoretical guarantee. Error Correcting Output Code (ECOC) is one of the well-known ensemble techniques for multiclass classification which combines the outputs of binary base learners to predict the classes for multiclass data. In this paper, we propose a novel approach for pruning the ECOC matrix by utilizing accuracy and diversity information simultaneously. All existing pruning methods need the size of the ensemble as a parameter, so the performance of the pruning methods depends on the size of the ensemble. Our unparametrized pruning method is novel as being independent of the size of ensemble. Experimental results show that our pruning method is mostly better than other existing approaches.", "paper_title": "Pruning of Error Correcting Output Codes by optimization of accuracy-diversity trade off", "paper_id": "WOS:000361624700012"}