{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "reinforcement_learning"}, {"score": 0.004757643419056999, "phrase": "intrinsic_motivation"}, {"score": 0.004340263267055143, "phrase": "different_skills"}, {"score": 0.004305740330804528, "phrase": "different_times"}, {"score": 0.004220624516321415, "phrase": "autonomous_developmental_process"}, {"score": 0.004120694410890683, "phrase": "skill-acquisition_goal"}, {"score": 0.0038655854071187115, "phrase": "learned_skill"}, {"score": 0.003583002730249742, "phrase": "developmental_process"}, {"score": 0.003456427643307904, "phrase": "option_framework"}, {"score": 0.003178147973814818, "phrase": "motivational_state-spaces"}, {"score": 0.0025405019456703325, "phrase": "agent's_motivational_state"}, {"score": 0.0024506642262508735, "phrase": "sensed_states"}, {"score": 0.0022895278869126848, "phrase": "motivated_reinforcement_learning_agents"}, {"score": 0.002244178699939059, "phrase": "non-player_characters"}, {"score": 0.0022174005294867604, "phrase": "computer_game_scenario"}], "paper_keywords": ["Goal-lifecycle", " introspection", " motivation", " novelty", " reinforcement learning"], "paper_abstract": "Incorporating intrinsic motivation with reinforcement learning can permit agents to independently choose, which skills they will develop, or to change their focus of attention to learn different skills at different times. This implies an autonomous developmental process for skills in which a skill-acquisition goal is first identified, then a skill is learned to solve the goal. The learned skill may then be stored, reused, temporarily ignored or even permanently erased. This paper formalizes the developmental process for skills by proposing a goal-lifecycle using the option framework for motivated reinforcement learning agents. The paper shows how the goal-lifecycle can be used as a basis for designing motivational state-spaces that permit agents to reason introspectively and autonomously about when to learn skills to solve goals, when to activate skills, when to suspend activation of skills or when to delete skills. An algorithm is presented that simultaneously learns: 1) an introspective policy mapping motivational states to decisions that change the agent's motivational state, and 2) multiple option policies mapping sensed states and actions to achieve various domain-specific goals. Two variations of agents using this model are compared to motivated reinforcement learning agents without introspection for controlling non-player characters in a computer game scenario. Results show that agents using introspection can focus their attention on learning more complex skills than agents without introspection. In addition, they can learn these skills more effectively.", "paper_title": "Intrinsic Motivation and Introspection in Reinforcement Learning", "paper_id": "WOS:000312482700005"}