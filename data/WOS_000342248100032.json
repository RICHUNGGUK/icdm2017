{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "evolvable_block-based_neural_networks"}, {"score": 0.03889914125581374, "phrase": "system_latency"}, {"score": 0.03738416398077957, "phrase": "power_consumption"}, {"score": 0.004640079189342692, "phrase": "novel_optimization_method"}, {"score": 0.004564401713056939, "phrase": "multi-population_parallel_genetic_algorithm"}, {"score": 0.004527560189429828, "phrase": "ga"}, {"score": 0.0041696157492057, "phrase": "bbnns"}, {"score": 0.004034649282040889, "phrase": "classification_problems"}, {"score": 0.004001593118269276, "phrase": "promising_results"}, {"score": 0.0039362878637371574, "phrase": "existing_bbnn_architectures"}, {"score": 0.0034083145672246067, "phrase": "recurrent_modes"}, {"score": 0.0033664873319204027, "phrase": "bbnn_hardware_model"}, {"score": 0.003244050414264445, "phrase": "synchronous_architecture"}, {"score": 0.0032174507570710835, "phrase": "registered_outputs"}, {"score": 0.0030247625535682987, "phrase": "automated_layout"}, {"score": 0.0029876282026237207, "phrase": "neuron_block_interconnects"}, {"score": 0.0029509483926257645, "phrase": "bbnn_structure"}, {"score": 0.0029147175927233546, "phrase": "array_interconnect_algorithm"}, {"score": 0.0028553159147435424, "phrase": "proposed_latency-optimized_bbnn"}, {"score": 0.002740109776120878, "phrase": "mobile_devices"}, {"score": 0.0027176309244222, "phrase": "integrated_graphics_processing_units"}, {"score": 0.002651291854234327, "phrase": "hardware_implementation"}, {"score": 0.0023624435546097658, "phrase": "computational_cycle"}, {"score": 0.002295277579105177, "phrase": "presented_case_studies"}, {"score": 0.0022577559526646904, "phrase": "proposed_bbnn_model"}, {"score": 0.0022300169122921906, "phrase": "optimal_latency_value"}, {"score": 0.0021845387990972543, "phrase": "high_accuracy"}, {"score": 0.002157697367447098, "phrase": "previous_works"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Block-based neural networks (BbNNs)", " Latency optimization", " Genetic algorithms (GA)", " Neural network hardware"], "paper_abstract": "This paper proposes a novel optimization method that utilizes a multi-population parallel genetic algorithm (GA) to simultaneously optimize the structure and system latency of evolvable block-based neural networks (BbNNs). In the past, BbNNs have been successfully deployed for various kinds of classification problems with promising results. However, existing BbNN architectures do not explicitly model or optimize the latency of the system. Optimization of system latency is important, because it improves performance, reduces power consumption, and allows a more deterministic behavior that is needed for recurrent modes. The BbNN hardware model proposed in this paper is implemented as a synchronous architecture with registered outputs. This architecture will permit the system latency to be deterministic. To facilitate the automated layout of the neuron block interconnects within the BbNN structure, an array interconnect algorithm is presented. The proposed latency-optimized BbNN is implemented in hardware, and the architecture resembles mobile devices with integrated graphics processing units (GPUs). The hardware implementation is verified and analyzed using various case studies. The power consumption of our prototyping platform was measured, and it is shown that approximately 364 nJ of energy can be saved for every computational cycle (latency) reduced. All presented case studies show that the proposed BbNN model provides an optimal latency value while still matching the high accuracy reported in previous works. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Optimization of structure and system latency in evolvable block-based neural networks using genetic algorithm", "paper_id": "WOS:000342248100032"}