{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "object_detection"}, {"score": 0.010467296054447172, "phrase": "contiguous_outliers"}, {"score": 0.01032416807002673, "phrase": "low-rank_representation"}, {"score": 0.007016507631853174, "phrase": "complex_scenarios"}, {"score": 0.005321287803045368, "phrase": "decolor"}, {"score": 0.004555499634179394, "phrase": "fundamental_step"}, {"score": 0.004513631630494221, "phrase": "automated_video_analysis"}, {"score": 0.0042506731642425275, "phrase": "object_detectors"}, {"score": 0.004211594861013822, "phrase": "background_subtraction_techniques"}, {"score": 0.0041154571996523505, "phrase": "object_detector"}, {"score": 0.0040776175116589986, "phrase": "manually"}, {"score": 0.004058826900076531, "phrase": "labeled_examples"}, {"score": 0.00398452530840582, "phrase": "binary_classifier"}, {"score": 0.003929689573550262, "phrase": "background_subtraction"}, {"score": 0.0038756055612167942, "phrase": "training_sequence"}, {"score": 0.003734979290204709, "phrase": "background_model"}, {"score": 0.0035663245542174224, "phrase": "separate_training_phase"}, {"score": 0.003517223847512266, "phrase": "critical_task"}, {"score": 0.0033428820402140683, "phrase": "motion_information"}, {"score": 0.003281643474564305, "phrase": "motion-based_methods"}, {"score": 0.0031333949463567554, "phrase": "nonrigid_motion"}, {"score": 0.0031045562469735307, "phrase": "dynamic_background"}, {"score": 0.002883172383460653, "phrase": "unified_framework"}, {"score": 0.0026163210719740847, "phrase": "single_process"}, {"score": 0.00249805321224923, "phrase": "alternating_algorithm"}, {"score": 0.0023305762840188145, "phrase": "simulated_data"}, {"score": 0.0023091093387071593, "phrase": "real_sequences"}, {"score": 0.0021049977753042253, "phrase": "wide_range"}], "paper_keywords": ["Moving object detection", " low-rank modeling", " Markov Random Fields", " motion segmentation"], "paper_abstract": "Object detection is a fundamental step for automated video analysis in many vision applications. Object detection in a video is usually. performed by object detectors or background subtraction techniques. Often, an object detector requires Manually labeled examples to train a binary classifier, while background subtraction needs a training sequence that contains no objects to build a background model. To automate the analysis, object detection without a separate training phase becomes a critical task. People have tried to tackle this task by using motion information. But existing motion-based Methods are usually limited when coping with complex scenarios such as nonrigid motion and dynamic background. In this paper, we show that the above challenges can be addressed in a unified framework named, DEtecting Contiguous Outliers in the LOw-rank Representation (DECOLOR). This formulation integrates object detection and background learning into a single process of optimization, which can be solved by an alternating algorithm efficiently. We explain the relations between DECOLOR and other sparsity-based methods. Experiments on both simulated data and real sequences demonstrate that DECOLOR outperforms the state-of-the-art approaches and it can work effectively on a wide range of complex scenarios.", "paper_title": "Moving Object Detection by Detecting Contiguous Outliers in the Low-Rank Representation", "paper_id": "WOS:000314792900007"}