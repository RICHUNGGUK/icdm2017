{"auto_keywords": [{"score": 0.035942882705930206, "phrase": "classification_capability"}, {"score": 0.010743569171266914, "phrase": "privacy_requirement"}, {"score": 0.00481495049065317, "phrase": "classification_utility"}, {"score": 0.00466085208934021, "phrase": "practical_approach"}, {"score": 0.004424441580112395, "phrase": "major_objective"}, {"score": 0.004310752197635499, "phrase": "data_publishing"}, {"score": 0.00419997182602686, "phrase": "private_information"}, {"score": 0.003935267970727093, "phrase": "intended_applications"}, {"score": 0.0038092152998069786, "phrase": "classification_models"}, {"score": 0.0035923719610602245, "phrase": "data_generalization"}, {"score": 0.0031535341431377837, "phrase": "mutual_information"}, {"score": 0.0028412769256691, "phrase": "accurate_classification_models"}, {"score": 0.002351813899450668, "phrase": "experimental_results"}, {"score": 0.0023062508214156123, "phrase": "algorithm_iack"}, {"score": 0.002189009136006588, "phrase": "benchmark_utility-aware_data_anonymization_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Privacy", " Anonymization", " k-anonymity", " Classification", " Mutual information", " Kullback-Leibler divergence"], "paper_abstract": "Anonymization is a practical approach to protect privacy in data. The major objective of privacy preserving data publishing is to protect private information in data whereas data is still useful for some intended applications, such as building classification models. in this paper, we argue that data generalization in anonymization should be determined by the classification capability of data rather than the privacy requirement. We make use of mutual information for measuring classification capability for generalization, and propose two k-anonymity algorithms to produce anonymized tables for building accurate classification models. The algorithms generalize attributes to maximize the classification capability, and then suppress values by a privacy requirement k (IACk) or distributional constraints (IACc). Experimental results show that algorithm IACk supports more accurate classification models and is faster than a benchmark utility-aware data anonymization algorithm. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Information based data anonymization for classification utility", "paper_id": "WOS:000296124100002"}