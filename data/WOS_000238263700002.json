{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "boundary"}, {"score": 0.004747997855358171, "phrase": "view_synthesis"}, {"score": 0.004638462976078815, "phrase": "new_view_synthesis"}, {"score": 0.00453144352814823, "phrase": "important_application"}, {"score": 0.004146716743362567, "phrase": "unique_depth"}, {"score": 0.003920674807745575, "phrase": "object_boundaries"}, {"score": 0.003848088904418221, "phrase": "pixel_colors"}, {"score": 0.003741712498615481, "phrase": "background_colors"}, {"score": 0.003587616378156851, "phrase": "effect_results"}, {"score": 0.003504756881063581, "phrase": "\"cut-out\"_appearance"}, {"score": 0.0034398445347109396, "phrase": "seamless_view_interpolation"}, {"score": 0.0032370412139943808, "phrase": "occlusion_boundary"}, {"score": 0.0030747771905143273, "phrase": "multiple_views"}, {"score": 0.0030319482153908037, "phrase": "fully_automatic_alpha_matting"}, {"score": 0.0029618842673339173, "phrase": "stereo_depths"}, {"score": 0.002787181295054319, "phrase": "occlusion_boundaries"}, {"score": 0.0027483472371835865, "phrase": "sub-pixel_accuracy"}, {"score": 0.002684819249720834, "phrase": "initial_estimate"}, {"score": 0.0025862068041567934, "phrase": "curve_parameters"}, {"score": 0.002550165781755603, "phrase": "foreground_colors"}, {"score": 0.0024336086025284836, "phrase": "input_images"}, {"score": 0.0023662411481713704, "phrase": "strong_edges"}, {"score": 0.0023223663501882917, "phrase": "large_perturbations"}, {"score": 0.0022686625017583387, "phrase": "experimental_results"}, {"score": 0.0022058510091498666, "phrase": "high-quality_view_synthesis"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["multi-view stereo", " view synthesis", " image matting", " occlusion boundaries", " sub-pixel reconstruction", " 3D curves"], "paper_abstract": "In the last few years, new view synthesis has emerged as an important application of 3D stereo reconstruction. While the quality of stereo has improved, it is still imperfect, and a unique depth is typically assigned to every pixel. This is problematic at object boundaries, where the pixel colors are mixtures of foreground and background colors. Interpolating views without explicitly accounting for this effect results in objects with a \"cut-out\" appearance. To produce seamless view interpolation, we propose a method called boundary matting, which represents each occlusion boundary as a 3D curve. We show how this method exploits multiple views to perform fully automatic alpha matting and to simultaneously refine stereo depths at the boundaries. The key to our approach is the 3D representation of occlusion boundaries estimated to sub-pixel accuracy. Starting from an initial estimate derived from stereo, we optimize the curve parameters and the foreground colors near the boundaries. Our objective function maximizes consistency with the input images, favors boundaries aligned with strong edges, and damps large perturbations of the curves. Experimental results suggest that this method enables high-quality view synthesis with reduced matting artifacts. (c) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Boundary matting for view synthesis", "paper_id": "WOS:000238263700002"}