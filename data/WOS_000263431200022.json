{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "recursive"}, {"score": 0.004723322467153553, "phrase": "least_squares"}, {"score": 0.004633429997452688, "phrase": "vector_regression"}, {"score": 0.004501774379030109, "phrase": "reduced_technique"}, {"score": 0.004416079619543104, "phrase": "iterative_strategy"}, {"score": 0.004050116768809519, "phrase": "support_vector_regression"}, {"score": 0.003934970057482768, "phrase": "proposed_algorithm"}, {"score": 0.003643607569483598, "phrase": "target_function"}, {"score": 0.0035741900278634616, "phrase": "support_vectors"}, {"score": 0.0032777653153451265, "phrase": "whole_training"}, {"score": 0.002601727192945944, "phrase": "similar_generalization_performance"}, {"score": 0.00236289633510808, "phrase": "excellent_parsimoniousness"}, {"score": 0.0023178219772486868, "phrase": "numerical_experiments"}, {"score": 0.002273605493468005, "phrase": "benchmark_data_sets"}, {"score": 0.0021049977753042253, "phrase": "presented_algorithm"}], "paper_keywords": ["Least squares support vector regression", " Reduced technique", " Iterative strategy", " Parsimoniousness", " Classification"], "paper_abstract": "Combining reduced technique with iterative strategy, we propose a recursive reduced least squares support vector regression. The proposed algorithm chooses the data which make more contribution to target function as support vectors, and it considers all the constraints generated by the whole training set. Thus it acquires less support vectors, the number of which can be arbitrarily predefined, to construct the model with the similar generalization performance. In comparison with other methods, Our algorithm also gains excellent parsimoniousness. Numerical experiments on benchmark data sets confirm the validity and feasibility of the presented algorithm. In addition, this algorithm can be extended to classification. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "Recursive reduced least squares support vector regression", "paper_id": "WOS:000263431200022"}