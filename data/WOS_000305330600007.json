{"auto_keywords": [{"score": 0.03826559283990352, "phrase": "voting_classifier"}, {"score": 0.030580277430729972, "phrase": "emargin_theory"}, {"score": 0.00481495049065317, "phrase": "margin_explanation"}, {"score": 0.004457995891964028, "phrase": "empirical_success"}, {"score": 0.004274527415193801, "phrase": "important_theoretical_problem"}, {"score": 0.004215057618794356, "phrase": "machine_learning"}, {"score": 0.003985305257857655, "phrase": "margin_theory"}, {"score": 0.00379452936798156, "phrase": "upper_bounds"}, {"score": 0.003715579364728729, "phrase": "generalization_error"}, {"score": 0.0034398445347109396, "phrase": "training_data"}, {"score": 0.0033447157263095223, "phrase": "equilibrium_margin"}, {"score": 0.0031845067058084583, "phrase": "sharper_than_previously_well-known_margin_bounds"}, {"score": 0.0029688173975648173, "phrase": "extensive_experiments"}, {"score": 0.0027483472371835865, "phrase": "efficient_algorithm"}, {"score": 0.002653606593103781, "phrase": "boosting_classifier"}, {"score": 0.002456486927713543, "phrase": "new_voting_classifier"}, {"score": 0.002371783323468861, "phrase": "smaller_emargin_bound"}, {"score": 0.002149799391146313, "phrase": "new_classifier"}, {"score": 0.0021049977753042253, "phrase": "smaller_test_errors"}], "paper_keywords": ["boosting", " margin", " Emargin theory"], "paper_abstract": "Understanding the empirical success of boosting algorithms is an important theoretical problem in machine learning. One of the most influential works is the margin theory, which provides a series of upper bounds for the generalization error of any voting classifier in terms of the margins of the training data. Recently an equilibrium margin (Emargin) bound which is sharper than previously well-known margin bounds is proposed. In this paper, we conduct extensive experiments to test the Emargin theory. Specifically, we develop an efficient algorithm that, given a boosting classifier (or a voting classifier in general), learns a new voting classifier which usually has a smaller Emargin bound. We then compare the performances of the two classifiers and find that the new classifier often has smaller test errors, which agrees with what the Emargin theory predicts.", "paper_title": "Further results on the margin explanation of boosting: new algorithm and experiments", "paper_id": "WOS:000305330600007"}