{"auto_keywords": [{"score": 0.04962913836247387, "phrase": "virtual_characters"}, {"score": 0.010031057669450501, "phrase": "virtual_environments"}, {"score": 0.00481495049065317, "phrase": "inverse_motion_control"}, {"score": 0.0047026237903774895, "phrase": "sound_synthesis_application"}, {"score": 0.004658426838467567, "phrase": "percussion_motion"}, {"score": 0.004592905436175987, "phrase": "ever_growing_use"}, {"score": 0.00406214911915987, "phrase": "sounding_objects"}, {"score": 0.0038746849003761024, "phrase": "case_study"}, {"score": 0.003802135020791801, "phrase": "virtual_music_instruments"}, {"score": 0.003678414118674967, "phrase": "real-time_motion_control"}, {"score": 0.003475582268210954, "phrase": "virtual_music_performances"}, {"score": 0.003426640459083931, "phrase": "physics-based_simulation"}, {"score": 0.0033308077968426937, "phrase": "recent_approach"}, {"score": 0.0032223742018434856, "phrase": "motion-sound_interaction"}, {"score": 0.003073545175760353, "phrase": "original_captured_motion"}, {"score": 0.0030017207229983385, "phrase": "physically-enabled_environment"}, {"score": 0.0029454679553901613, "phrase": "virtual_percussionist"}, {"score": 0.002890266318361907, "phrase": "physics-based_sound_synthesis_algorithm"}, {"score": 0.002782938683493689, "phrase": "hybrid_inverse_motion_control"}, {"score": 0.0025678829712650437, "phrase": "upper-body_percussion_movements"}, {"score": 0.0024960069794216977, "phrase": "physics-based_sound_synthesis_model"}, {"score": 0.0023030731312573246, "phrase": "effective_way"}, {"score": 0.0022706045233150795, "phrase": "heterogenous_data"}, {"score": 0.0022280223816618736, "phrase": "sound_parameters"}, {"score": 0.0021049977753042253, "phrase": "resulting_virtual_percussion_performances"}], "paper_keywords": ["Physics-based computer animation", " Motion control", " Motion-sound interaction", " Sound synthesis"], "paper_abstract": "The ever growing use of virtual environments requires more and more engaging elements for enhancing user experiences. Specifically regarding sounding virtual environments, one promising option to achieve such realism and interactivity requirements is the use of virtual characters interacting with sounding objects. In this paper, we focus as a case study on virtual characters playing virtual music instruments. We address more specially the real-time motion control and interaction of virtual characters with their sounding environment for proposing engaging and compelling virtual music performances. Combining physics-based simulation with motion data is a recent approach to finely represent and modulate this motion-sound interaction, while keeping the realism and expressivity of the original captured motion. We propose a physically-enabled environment in which a virtual percussionist interacts with a physics-based sound synthesis algorithm. We introduce and extensively evaluate the Hybrid Inverse Motion Control (HIMC), a motion-driven hybrid control scheme dedicated to the synthesis of upper-body percussion movements. We also propose a physics-based sound synthesis model with which the virtual character can interact. Finally, we present an architecture offering an effective way to manage heterogenous data (motion and sound parameters) and feedback (visual and sound) that influence the resulting virtual percussion performances.", "paper_title": "Hybrid inverse motion control for virtual characters interacting with sound synthesis Application to percussion motion", "paper_id": "WOS:000302813300003"}