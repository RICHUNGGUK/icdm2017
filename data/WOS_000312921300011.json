{"auto_keywords": [{"score": 0.049324540543845184, "phrase": "grayscale_image_compression"}, {"score": 0.00481495049065317, "phrase": "systematic_development"}, {"score": 0.004776853267973129, "phrase": "fast_fuzzy_vector_quantization"}, {"score": 0.004590820632326585, "phrase": "learning_mechanism"}, {"score": 0.004518442937844318, "phrase": "fast_fuzzy_clustering-based_vector_quantizers"}, {"score": 0.004412000844879264, "phrase": "fuzzy_clustering"}, {"score": 0.004377077848734575, "phrase": "vector_quantization"}, {"score": 0.004156691746581458, "phrase": "high_computational_cost"}, {"score": 0.003823791479971016, "phrase": "specialized_strategies"}, {"score": 0.0037784540167266497, "phrase": "smooth_transition"}, {"score": 0.0037188360359702182, "phrase": "crisp_conditions"}, {"score": 0.0036167509502276294, "phrase": "enhanced_solution"}, {"score": 0.003248483521309273, "phrase": "specific_training_pattern"}, {"score": 0.0032099453192629976, "phrase": "second_one"}, {"score": 0.0031217859267564344, "phrase": "training_patterns"}, {"score": 0.0030724971661718983, "phrase": "design_process"}, {"score": 0.003036040409062437, "phrase": "sequential_implementation"}, {"score": 0.0029292375702719468, "phrase": "computational_cost"}, {"score": 0.002837451022172113, "phrase": "potential_risk"}, {"score": 0.0027594936602962075, "phrase": "first_module"}, {"score": 0.0027267406923803367, "phrase": "high_probability"}, {"score": 0.002694375425481759, "phrase": "small_and_badly_delineated_clusters"}, {"score": 0.002578946584040053, "phrase": "third_module"}, {"score": 0.002548331088496964, "phrase": "novel_cluster_distortion_equalization_process"}, {"score": 0.002468450551616404, "phrase": "small_clusters"}, {"score": 0.0024006068621542642, "phrase": "large_ones"}, {"score": 0.002279508335630797, "phrase": "better_local_minimum"}, {"score": 0.0022524395393089544, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Fast fuzzy vector quantization", " Codeword reduction", " Pattern reduction", " Codeword relocation", " Image compression"], "paper_abstract": "In this paper we propose a learning mechanism to systematically design fast fuzzy clustering-based vector quantizers. Although the utilization of fuzzy clustering in vector quantization is able to reduce the dependence on initialization, it finally obtains high computational cost. This problem has been investigated by many researchers. So far, the most widely used solution is to equip the quantizer with specialized strategies for the smooth transition from fuzzy to crisp conditions. Hereby, we propose an enhanced solution to that problem. In our contribution we combine three different learning modules. The first one concerns the reduction of the number of codewords that are affected by a specific training pattern. The second one acts to reduce the number of training patterns involved in the design process. The sequential implementation of the above two modules manages to significantly reduce the computational cost of the quantizer. However, the potential risk related to the implementation of the first module is the high probability to generate small and badly delineated clusters. To handle this problem we apply, in the third module, a novel cluster distortion equalization process, according to which the codewords of small clusters are moved to the neighborhood of large ones in order to increase their size and become more competitive, obtaining a better local minimum. The proposed algorithm is rigorously evaluated and compared to other sophisticated methods in terms of grayscale image compression. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "On the systematic development of fast fuzzy vector quantization for grayscale image compression", "paper_id": "WOS:000312921300011"}