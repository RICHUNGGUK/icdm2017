{"auto_keywords": [{"score": 0.049212993617288356, "phrase": "gaussian_kernel"}, {"score": 0.03765525632305312, "phrase": "generalization_capability"}, {"score": 0.004621148492564008, "phrase": "well-recognized_powerful_strategy"}, {"score": 0.004475798524102238, "phrase": "learning_machine"}, {"score": 0.0043947942344037105, "phrase": "regularization_schemes"}, {"score": 0.004103817210338686, "phrase": "different_q"}, {"score": 0.0040479661688863884, "phrase": "different_properties"}, {"score": 0.0039928721865882, "phrase": "deduced_estimators"}, {"score": 0.003814563533445401, "phrase": "smooth_estimator"}, {"score": 0.003660879039645457, "phrase": "sparse_estimator"}, {"score": 0.0035133644847622383, "phrase": "regularization_learning"}, {"score": 0.0031917943932454314, "phrase": "statistical_learning_theory"}, {"score": 0.0030771609361092164, "phrase": "coefficient_regularization_schemes"}, {"score": 0.0030352396244492604, "phrase": "sample-dependent_hypothesis_space"}, {"score": 0.0027573101010593863, "phrase": "upper_and_lower_bounds"}, {"score": 0.0024481198073210567, "phrase": "modeling_contexts"}, {"score": 0.0023386327847292805, "phrase": "strong_impact"}, {"score": 0.0021049977753042253, "phrase": "computational_complexity"}], "paper_keywords": [""], "paper_abstract": "Regularization is a well-recognized powerful strategy to improve the performance of a learning machine and l(q) regularization schemes with 0 < q < infinity are central in use. It is known that different q leads to different properties of the deduced estimators, say, l(2) regularization leads to a smooth estimator, while l(1) regularization leads to a sparse estimator. Then how the generalization capability of l(q) regularization learning varies with q is worthy of investigation. In this letter, we study this problem in the framework of statistical learning theory. Our main results show that implementing l(q) coefficient regularization schemes in the sample-dependent hypothesis space associated with a gaussian kernel can attain the same almost optimal learning rates for all 0 < q < infinity. That is, the upper and lower bounds of learning rates for l(q) regularization learning are asymptotically identical for all 0 < q < infinity. Our finding tentatively reveals that in some modeling contexts, the choice of q might not have a strong impact on the generalization capability. From this perspective, q can be arbitrarily specified, or specified merely by other nongeneralization criteria like smoothness, computational complexity or sparsity.", "paper_title": "Learning Rates of l(q) Coefficient Regularization Learning with Gaussian Kernel", "paper_id": "WOS:000341341300009"}