{"auto_keywords": [{"score": 0.02942033368394877, "phrase": "hmm-based_scores"}, {"score": 0.015719716506582538, "phrase": "confidence_measures"}, {"score": 0.014485609560573565, "phrase": "keyword_verification"}, {"score": 0.01191867880134377, "phrase": "acoustic-based_features"}, {"score": 0.004665764181113345, "phrase": "target_acoustic_units"}, {"score": 0.004592905436175987, "phrase": "specific_speech_segments"}, {"score": 0.004398331355940011, "phrase": "utterance_verification"}, {"score": 0.004081385289516914, "phrase": "resulting_scores"}, {"score": 0.004001828274595483, "phrase": "independent_measure"}, {"score": 0.003684213587410217, "phrase": "af_properties"}, {"score": 0.003584025547693833, "phrase": "mel-frequency_cepstral_coefficients"}, {"score": 0.003459191419478298, "phrase": "speech_processing"}, {"score": 0.0034185505275141077, "phrase": "recent_works"}, {"score": 0.0033651019362620866, "phrase": "linguistically_based_features"}, {"score": 0.00320970209394799, "phrase": "human_articulatory_process"}, {"score": 0.00314708280192844, "phrase": "speech_characteristics"}, {"score": 0.002943147037670826, "phrase": "proposed_af-based_measures"}, {"score": 0.0027307746993761035, "phrase": "keyword_verification_tasks"}, {"score": 0.0027093285574752457, "phrase": "children's_speech"}, {"score": 0.00266693888510356, "phrase": "computer-based_english"}, {"score": 0.0025436978068459565, "phrase": "proposed_measures"}, {"score": 0.002474447780553576, "phrase": "native_and_non-native_data"}, {"score": 0.0023600807990911145, "phrase": "training_condition"}, {"score": 0.002332322771009122, "phrase": "experimental_results"}, {"score": 0.002286781334850213, "phrase": "different_environments"}, {"score": 0.002242127152093798, "phrase": "af_scores"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": [""], "paper_abstract": "Confidence measures are computed to estimate the certainty that target acoustic units are spoken in specific speech segments. They are applied in tasks such as keyword verification or utterance verification. Because many of the confidence measures use the same set of models and features as in recognition, the resulting scores may not provide an independent measure of reliability. In this paper, we propose two articulatory feature (AF) based phoneme confidence measures that estimate the acoustic reliability based on the match in AF properties. While acoustic-based features, such as Mel-frequency cepstral coefficients (MFCC), are widely used in speech processing, some recent works have focus on linguistically based features, such as the articulatory features that relate directly to the human articulatory process which may better capture speech characteristics. The articulatory features can either replace or complement the acoustic-based features in speech processing. The proposed AF-based measures in this paper were evaluated, in comparison and in combination, with the HMM-based scores on phoneme and keyword verification tasks using children's speech collected for a computer-based English. pronunciation learning project. To fully evaluate their usefulness, the proposed measures and combinations were evaluated on both native and non-native data; and underfield test conditions that mis-matches with the training condition. The experimental results show that under the different environments, combinations of the AF scores with the HMM-based scores outperforms HMM-based scores alone on phoneme and keyword verification. (c) 2005 Elsevier Ltd. All rights reserved.", "paper_title": "Articulatory-feature-based confidence measures", "paper_id": "WOS:000240727800009"}