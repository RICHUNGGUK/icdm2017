{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "embedded_systems"}, {"score": 0.004706206193274572, "phrase": "incremental_compacting_garbage_collector"}, {"score": 0.004652754203582873, "phrase": "java_systems"}, {"score": 0.004513151518938864, "phrase": "equal_sized_pages"}, {"score": 0.004444921827311577, "phrase": "segregated_free_lists"}, {"score": 0.0044111930537670705, "phrase": "fast_allocation"}, {"score": 0.0041345962781234435, "phrase": "page_size"}, {"score": 0.003995226376780718, "phrase": "replication-based_incremental_compaction"}, {"score": 0.003687960013746783, "phrase": "large_chunk"}, {"score": 0.003659954070354848, "phrase": "free_space"}, {"score": 0.003536526698282596, "phrase": "evacuation_area"}, {"score": 0.0032396224508754387, "phrase": "replication-based_incremental_copying_collection"}, {"score": 0.0031422859551159506, "phrase": "evacuated_objects"}, {"score": 0.003071201732948199, "phrase": "extra_field"}, {"score": 0.0029789104204803137, "phrase": "hash_table"}, {"score": 0.0029450186031370245, "phrase": "forwarding_pointers"}, {"score": 0.0028893844749296863, "phrase": "garbage_collector"}, {"score": 0.0027495914857929584, "phrase": "memory_starvation"}, {"score": 0.002718301574682098, "phrase": "heap_sizes"}, {"score": 0.00266693888510356, "phrase": "maximum_amount"}, {"score": 0.002646665861584495, "phrase": "live_data"}, {"score": 0.002567099236341096, "phrase": "desktop_computer"}, {"score": 0.0024335561337016174, "phrase": "maximum_pause_time"}, {"score": 0.0022120914337992034, "phrase": "arm_processor"}, {"score": 0.002186904773823281, "phrase": "runtime_overhead"}, {"score": 0.0021049977753042253, "phrase": "mark-sweep_collector"}], "paper_keywords": ["Algorithms", " Performance", " Garbage Collection", " Compaction", " Fragmentation", " Embedded Systems", " Real-time Garbage Collection"], "paper_abstract": "We have developed an incremental compacting garbage collector for embedded Java systems. The collector divides the heap into equal sized pages and uses the segregated free lists for fast allocation. Collectors that have such a heap layout have a problem of fragmentation in allocating objects larger than the page size. We solve this problem by using the replication-based incremental compaction. The compactor evacuates all objects in one area, the evacuation area, of the heap, thereby creating a large chunk of free space. We developed an algorithm for choosing the evacuation area that effectively cures fragmentation. The compactor does not use any read-barriers. Instead, it uses a technique similar to the replication-based incremental copying collection. This needs forwarding pointers for all evacuated objects. Rather than introducing an extra field for each object, we use a hash table to store forwarding pointers. Evaluation of this garbage collector implemented in Sun's J2ME Java Virtual Machine showed that all the benchmarks used were able to run without memory starvation using the heap sizes of only 151%-286% of the maximum amount of live data plus 8 KB of the hash table. Experiments on a desktop computer, though it is not a platform for embedded systems, showed that the maximum pause time was shorter than 200 mu s, which was comparable to that of our implementation of the snapshot-at-the-beginning collector without compaction. On an ARM processor, the runtime overhead was 1%-16% with 8.0% on average compared to the mark-sweep collector.", "paper_title": "Improved Replication-Based Incremental Garbage Collection for Embedded Systems", "paper_id": "WOS:000280548600009"}