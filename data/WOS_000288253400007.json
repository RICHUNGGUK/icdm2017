{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "locally_constrained_line"}, {"score": 0.0046993598473345395, "phrase": "simple_yet_effective_learning_algorithm"}, {"score": 0.0046238380150870435, "phrase": "k_locally_constrained_line"}, {"score": 0.004263972370406983, "phrase": "pattern_classification"}, {"score": 0.003806541299696042, "phrase": "constrained_line"}, {"score": 0.003567455727660992, "phrase": "representational_capacity"}, {"score": 0.0034817084307034955, "phrase": "training_set"}, {"score": 0.0029126002350975634, "phrase": "training_subspaces"}, {"score": 0.002578745296475411, "phrase": "unknown_sample"}, {"score": 0.002397048726373276, "phrase": "experimental_results"}, {"score": 0.0021745003291048356, "phrase": "better_accuracy"}], "paper_keywords": ["Constrained line", " Representational capacity", " Nearest neighbor", " Pattern classification"], "paper_abstract": "A simple yet effective learning algorithm, k locally constrained line (k-LCL), is presented for pattern classification. In k-LCL, any two prototypes of the same class are extended to a constrained line (CL), through which the representational capacity of the training set is largely improved. Because each CL is adjustable in length, k-LCL can well avoid the \"intersecting\" of training subspaces in most traditional feature classifiers. Moreover, to speed up the calculation, k-LCL classifies an unknown sample focusing only on its local CLs in each class. Experimental results, obtained on both synthetic and real-world benchmark data sets, show that the proposed method has better accuracy and efficiency than most existing feature line methods.", "paper_title": "Pattern classification based on k locally constrained line", "paper_id": "WOS:000288253400007"}