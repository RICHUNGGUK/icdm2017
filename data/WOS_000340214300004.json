{"auto_keywords": [{"score": 0.04580095236402595, "phrase": "neuron's_threshold"}, {"score": 0.014781089264950758, "phrase": "intrinsic_plasticity"}, {"score": 0.011430016457234592, "phrase": "supergaussian_sources"}, {"score": 0.004814990536611104, "phrase": "sparseness"}, {"score": 0.00455585162011571, "phrase": "recent_model"}, {"score": 0.004477765573115626, "phrase": "hebbian_synaptic_plasticity"}, {"score": 0.0043106348117582915, "phrase": "sigmoidal_response_function"}, {"score": 0.004178522455099832, "phrase": "heavy-tailed_or_supergaussian_sources"}, {"score": 0.004022515690178811, "phrase": "exponential_output_distribution"}, {"score": 0.0037276938184125532, "phrase": "intrinsic_plasticity_mechanism"}, {"score": 0.0031352744329834676, "phrase": "subgaussian_sources"}, {"score": 0.0030496164547515565, "phrase": "fixed_sigmoidal_nonlinearity"}, {"score": 0.0030076664326204013, "phrase": "synaptic_strength_fixed-point_structure"}, {"score": 0.002976581914095474, "phrase": "two-dimensional_parameter_space"}, {"score": 0.002806391131610627, "phrase": "sub-_and_supergaussian-input-finding_regimes"}, {"score": 0.0026004698404274483, "phrase": "single_gaussian_source"}, {"score": 0.0025119200240696824, "phrase": "nongaussian_source"}, {"score": 0.0024859463164240603, "phrase": "neuron's_operating_point"}, {"score": 0.0023518780693181796, "phrase": "intrinsic_plasticity_mechanisms"}, {"score": 0.0023114798074455453, "phrase": "parameter_space"}, {"score": 0.002217326282120832, "phrase": "critical_boundaries"}, {"score": 0.0021417950504965997, "phrase": "neuron's_nonlinearity"}, {"score": 0.0021049977753042253, "phrase": "identical_receptive_field_refinement_dynamics"}], "paper_keywords": [""], "paper_abstract": "A recent model of intrinsic plasticity coupled to Hebbian synaptic plasticity proposes that adaptation of a neuron's threshold and gain in a sigmoidal response function to achieve a sparse, exponential output firing rate distribution facilitates the discovery of heavy-tailed or supergaussian sources in the neuron's inputs. We show that the exponential output distribution is irrelevant to these dynamics and that, furthermore, while sparseness is sufficient, it is not necessary. The intrinsic plasticity mechanism drives the neuron's threshold large and positive, and we prove that in such a regime, the neuron will find supergaussian sources; equally, however, if the threshold is large and negative (an antisparse regime), it will also find supergaussian sources. Away from such extremes, the neuron can also discover subgaussian sources. By examining a neuron with a fixed sigmoidal nonlinearity and considering the synaptic strength fixed-point structure in the two-dimensional parameter space defined by the neuron's threshold and gain, we show that this space is carved up into sub- and supergaussian-input-finding regimes, possibly with regimes of simultaneous stability of sub- and supergaussian sources or regimes of instability of all sources; a single gaussian source may also be stabilized by the presence of a nongaussian source. A neuron's operating point (essentially its threshold and gain coupled with its input statistics) therefore critically determines its computational repertoire. Intrinsic plasticity mechanisms induce trajectories in this parameter space but do not fundamentally modify it. Unless the trajectories cross critical boundaries in this space, intrinsic plasticity is irrelevant and the neuron's nonlinearity may be frozen with identical receptive field refinement dynamics.", "paper_title": "Sparseness, Antisparseness and Anything in Between: The Operating Point of a Neuron Determines Its Computational Repertoire", "paper_id": "WOS:000340214300004"}