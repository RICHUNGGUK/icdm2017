{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "sensor-enhanced_video_annotation"}, {"score": 0.026949501054725346, "phrase": "viewable_area"}, {"score": 0.004606843145343611, "phrase": "sensor-rich_world"}, {"score": 0.004506171772318298, "phrase": "digital_recording_devices"}, {"score": 0.004330450801016359, "phrase": "user's_ability"}, {"score": 0.004235793609579307, "phrase": "large_repository"}, {"score": 0.004161553532799662, "phrase": "video_files"}, {"score": 0.0040347380310668994, "phrase": "digital_recording_system"}, {"score": 0.003759142310009214, "phrase": "visual_images"}, {"score": 0.0032774280543222843, "phrase": "extrapolation_techniques"}, {"score": 0.0032057142600527, "phrase": "tagged_stream"}, {"score": 0.003013129637451091, "phrase": "particular_objects"}, {"score": 0.002934166052954463, "phrase": "detailed_experiments"}, {"score": 0.0026736945502820303, "phrase": "zero_error_rates"}, {"score": 0.0026501241093379786, "phrase": "static_objects"}, {"score": 0.002425524064992056, "phrase": "moving_camera"}, {"score": 0.002404136142279618, "phrase": "seva"}, {"score": 0.0021049977753042253, "phrase": "relatively_inexpensive_hardware"}], "paper_keywords": ["Algorithms", " Design", " Experimentation", " Video annotation", " sensor-enhanced", " location-based services", " context-based retrieval"], "paper_abstract": "In this article, we study how a sensor-rich world can be exploited by digital recording devices such as cameras and camcorders to improve a user's ability to search through a large repository of image and video files. We design and implement a digital recording system that records identities and locations of objects (as advertised by their sensors) along with visual images (as recorded by a camera). The process, which we refer to as Sensor-Enhanced Video Annotation (SEVA), combines a series of correlation, interpolation, and extrapolation techniques. It produces a tagged stream that later can be used to efficiently search for videos or frames containing particular objects or people. We present detailed experiments with a prototype of our system using both stationary and mobile objects as well as GPS and ultrasound. Our experiments show that: (i) SEVA has zero error rates for static objects, except very close to the boundary of the viewable area; (ii) for moving objects or a moving camera, SEVA only misses objects leaving or entering the viewable area by 1-2 frames; (iii) SEVA can scale to 10 fast-moving objects using current sensor technology; and (iv) SEVA runs online using relatively inexpensive hardware.", "paper_title": "SEVA: Sensor-Enhanced Video Annotation", "paper_id": "WOS:000270595600007"}