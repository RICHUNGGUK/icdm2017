{"auto_keywords": [{"score": 0.0393378573740974, "phrase": "audio_tracks"}, {"score": 0.00481495049065317, "phrase": "chord_progression_histogram"}, {"score": 0.004535124351828787, "phrase": "music_information_retrieval"}, {"score": 0.004463278123628969, "phrase": "critical_but_challenging_research_topic"}, {"score": 0.004392565073466714, "phrase": "real-time_online_search"}, {"score": 0.004087910779160781, "phrase": "relevant_songs"}, {"score": 0.004039221742250308, "phrase": "large-scale_dataset"}, {"score": 0.004007083686875716, "phrase": "music_audio_tracks"}, {"score": 0.003959353513286997, "phrase": "melody_similarity"}, {"score": 0.0036993855514735746, "phrase": "music_semantics"}, {"score": 0.003669941438286456, "phrase": "chord_progressions"}, {"score": 0.003611751858608048, "phrase": "audio_signals"}, {"score": 0.0035687137873965684, "phrase": "trained_music_rules"}, {"score": 0.003512123587588346, "phrase": "recognition_accuracy"}, {"score": 0.0033880439015902446, "phrase": "concise_chord_progression_histogram"}, {"score": 0.0032814236411444022, "phrase": "audio_track"}, {"score": 0.0032423089921154503, "phrase": "mid-level_feature"}, {"score": 0.003178147973814818, "phrase": "discriminative_capability"}, {"score": 0.0031402604946939743, "phrase": "audio_content"}, {"score": 0.0028529310661977577, "phrase": "dominant_chord_progressions"}, {"score": 0.0027631038845413393, "phrase": "hash_key"}, {"score": 0.002741091312632307, "phrase": "average_degradation"}, {"score": 0.0024604876113911173, "phrase": "retrieval_stage"}, {"score": 0.0024408799645640345, "phrase": "experimental_results"}, {"score": 0.0024117603727471654, "phrase": "large_dataset"}, {"score": 0.0023357913211723884, "phrase": "proposed_retrieval_algorithm"}, {"score": 0.0021389638834794136, "phrase": "optimal_performance"}, {"score": 0.0021049977753042253, "phrase": "exhaustive_sequence_comparison"}], "paper_keywords": ["Audio computing", " chord progression histogram", " locality sensitive hashing", " music-IR", " tree-structure."], "paper_abstract": "With more and more multimedia content made available on the Internet, music information retrieval is becoming a critical but challenging research topic, especially for real-time online search of similar songs from websites. In this paper we study how to quickly and reliably retrieve relevant songs from a large-scale dataset of music audio tracks according to melody similarity. Our contributions are two-fold: (i) Compact and accurate representation of audio tracks by exploiting music semantics. Chord progressions are recognized from audio signals based on trained music rules, and the recognition accuracy is improved by multi-probing. A concise chord progression histogram (CPH) is computed from each audio track as a mid-level feature, which retains the discriminative capability in describing audio content. (ii) Efficient organization of audio tracks according to their CPHs by using only one locality sensitive hash table with a tree-structure. A set of dominant chord progressions of each song is used as the hash key. Average degradation of ranks is further defined to estimate the similarity of two songs in terms of their dominant chord progressions, and used to control the number of probing in the retrieval stage. Experimental results on a large dataset with 74,055 music audio tracks confirm the scalability of the proposed retrieval algorithm. Compared to state-of-the-artmethods, our algorithm improves the accuracy of summarization and indexing, and makes a further step towards the optimal performance determined by an exhaustive sequence comparison.", "paper_title": "Scalable Content-Based Music Retrieval Using Chord Progression Histogram and Tree-Structure LSH", "paper_id": "WOS:000327393900020"}