{"auto_keywords": [{"score": 0.03062284688869159, "phrase": "name_variants"}, {"score": 0.00481495049065317, "phrase": "comprehensive_name"}, {"score": 0.004775531918452571, "phrase": "context_modeling"}, {"score": 0.004697655699119423, "phrase": "important_atomic_information_carriers"}, {"score": 0.004602085616330634, "phrase": "matching_names"}, {"score": 0.00445318311339027, "phrase": "important_issue"}, {"score": 0.004416713079266374, "phrase": "text_analysis"}, {"score": 0.004362564831572539, "phrase": "key_component"}, {"score": 0.004221379262804442, "phrase": "entity_linking"}, {"score": 0.003985166330358716, "phrase": "free_text"}, {"score": 0.0039040344230094164, "phrase": "knowledge_base"}, {"score": 0.003700709435644458, "phrase": "many-to-many_correspondence"}, {"score": 0.0035808664384880213, "phrase": "pseudonymity_and_polysemy_issues"}, {"score": 0.003422371752150812, "phrase": "large_numbers"}, {"score": 0.003394314924677555, "phrase": "loosely_arranged_features"}, {"score": 0.0033664873319204027, "phrase": "supervised_learning_frameworks"}, {"score": 0.0030497740719977835, "phrase": "comprehensive_modeling"}, {"score": 0.0030123335878664064, "phrase": "entity's_name"}, {"score": 0.0028553159147435424, "phrase": "query_name"}, {"score": 0.0028202559386070873, "phrase": "kb_title"}, {"score": 0.0027514186391258263, "phrase": "heterogeneous_aspects"}, {"score": 0.0026953359825383646, "phrase": "kb_context"}, {"score": 0.002629539710839523, "phrase": "entity_coreferences"}, {"score": 0.0025865679621853667, "phrase": "kb_documents"}, {"score": 0.002544296663333569, "phrase": "external_alias_resources"}, {"score": 0.0024116163689723354, "phrase": "focused_context"}, {"score": 0.0023430556582539805, "phrase": "recall-boosted_retrieval_method"}, {"score": 0.002323826502178581, "phrase": "efficient_candidate_entity_generation"}, {"score": 0.0021576973674470997, "phrase": "benchmark_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Entity linking", " Coreference", " Polysemy", " Pseudonymity", " Name modeling", " Context modeling"], "paper_abstract": "Names are important atomic information carriers in unstructured text. Matching names that refer to the same entities is an important issue in text analysis and a key component in many real world applications. Generally referred to as entity linking, it is defined as a task that aligns a name mentioned in free text to its corresponding entry in a Knowledge Base (KB). The difficulty of the task lies in the many-to-many correspondence between names and entities, causing the pseudonymity and polysemy issues. Existing work usually focuses on resolving polysemy by aggregating large numbers of loosely arranged features in supervised learning frameworks, with very few targeting the pseudonymity or both issues with the same depth. In this work, we tackle both issues by comprehensive modeling of an entity's name and context: we tackle the pseudonymity by modeling name variants on the query name and the KB title; and polysemy by modeling heterogeneous aspects of the query and KB context. Specially, we harness entity coreferences within query and KB documents together with the external alias resources for modeling name variants, and further use the name variants to identify focused context. Moreover, we propose a recall-boosted retrieval method for efficient candidate entity generation. Experimental results show that our proposed approach outperforms the state-of-the-art systems on the benchmark data. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Resolving polysemy and pseudonymity in entity linking with comprehensive name and context modeling", "paper_id": "WOS:000351965100002"}