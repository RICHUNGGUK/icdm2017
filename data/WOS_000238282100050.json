{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "conditional_random_fields"}, {"score": 0.04916809664432024, "phrase": "unlabeled_data"}, {"score": 0.03726682411720789, "phrase": "labeled_training_examples"}, {"score": 0.02816096792734159, "phrase": "labeled_and_unlabeled_data"}, {"score": 0.004633429997452688, "phrase": "limited_number"}, {"score": 0.004545240514015278, "phrase": "labeled_examples"}, {"score": 0.00433200902751133, "phrase": "probabilistic_approach"}, {"score": 0.004089239912167375, "phrase": "sequence_labeling_task"}, {"score": 0.004011366422179016, "phrase": "good_performance"}, {"score": 0.003643607569483598, "phrase": "human_effort"}, {"score": 0.003154012038613403, "phrase": "conditional_likelihood"}, {"score": 0.002527654365712841, "phrase": "extensive_experiments"}, {"score": 0.0023178219772486868, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "better_performance"}], "paper_keywords": [""], "paper_abstract": "Conditional random fields is a probabilistic approach which has been applied to sequence labeling task achieving good performance. We attempt to extend the model so that human effort in preparing labeled training examples can be reduced by considering unlabeled data. Instead of maximizing the conditional likelihood, we aim at maximizing the likelihood of the observation of the sequences from both of the labeled and unlabeled data. We have conducted extensive experiments in two different data sets to evaluate the performance. The experimental results show that our model learned from both labeled and unlabeled data has a better performance over the model learned by only considering labeled training examples.", "paper_title": "Training conditional random fields with unlabeled data and limited number of labeled examples", "paper_id": "WOS:000238282100050"}