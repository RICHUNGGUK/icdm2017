{"auto_keywords": [{"score": 0.04393033017315465, "phrase": "local_linear_manifolds"}, {"score": 0.015719716506582538, "phrase": "nonlinear_manifolds"}, {"score": 0.015053521096653599, "phrase": "self-organizing_framework"}, {"score": 0.004685012337701536, "phrase": "localized_linear_manifolds"}, {"score": 0.004459857205489101, "phrase": "neural_model"}, {"score": 0.004387225575447685, "phrase": "low-dimensional_nonlinear_manifolds"}, {"score": 0.004315771670213371, "phrase": "higher-dimensional_data_space"}, {"score": 0.00380511089035825, "phrase": "local_data_distributions"}, {"score": 0.0037226570791514184, "phrase": "new_distortion_measure"}, {"score": 0.0033363396054797044, "phrase": "mean_vector"}, {"score": 0.0032819448594643853, "phrase": "principal_subspace"}, {"score": 0.0030395624703152212, "phrase": "local_extremum"}, {"score": 0.0028932554846476718, "phrase": "new_mixture_model"}, {"score": 0.002709045632654716, "phrase": "online-learning_property"}, {"score": 0.002536534348967786, "phrase": "computational_efficiency"}, {"score": 0.0024951467586005094, "phrase": "paramount_importance"}, {"score": 0.0022359278646792153, "phrase": "handwritten_digit_images"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Self-organizing network", " Manifold learning", " Principal subspace", " Mixture of experts", " Dimension reduction"], "paper_abstract": "This paper presents a neural model which learns low-dimensional nonlinear manifolds embedded in higher-dimensional data space based on mixtures of local linear manifolds under a self-organizing framework. Compared to other similar networks, the local linear manifolds learned by our network have a more localized representation of local data distributions thanks to a new distortion measure, which removes confusion between sub-models that exists in many similar mixture models. Each neuron in the network asymptotically learns a mean vector and a principal subspace of the data in its local region. It is proved that there is no local extremum for each sub-model. Experiments show that the new mixture model is better adapted to nonlinear manifolds of various data distributions than other similar models. The online-learning property of this model is desirable when the data set is very large, when computational efficiency is of paramount importance, or when data are sequentially input. We further show an application of this model to recognition of handwritten digit images based on mixtures of local linear manifolds. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Learning nonlinear manifolds based on mixtures of localized linear manifolds under a self-organizing framework", "paper_id": "WOS:000268733700060"}