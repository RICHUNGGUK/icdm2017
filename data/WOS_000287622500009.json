{"auto_keywords": [{"score": 0.04312807803523186, "phrase": "individual_accuracy"}, {"score": 0.04158212266319735, "phrase": "mpoec"}, {"score": 0.035620716932052585, "phrase": "zero_coefficients"}, {"score": 0.03518680520456291, "phrase": "mpoec_approach"}, {"score": 0.032289029853923026, "phrase": "basis_functions"}, {"score": 0.00481495049065317, "phrase": "greedy_optimization"}, {"score": 0.004635701867952543, "phrase": "individual_error"}, {"score": 0.004425616928975799, "phrase": "ensemble_performances"}, {"score": 0.004333283735537634, "phrase": "\"kappa-error\"_diagram"}, {"score": 0.0040334640350288, "phrase": "new_method"}, {"score": 0.003999578057088828, "phrase": "matching_pursuit_optimization_ensemble_classifiers"}, {"score": 0.0036914757355166966, "phrase": "mpoec_method"}, {"score": 0.0036450381529042103, "phrase": "greedy_iterative_algorithm"}, {"score": 0.0035240305920962766, "phrase": "optimal_combination"}, {"score": 0.0034944094552943, "phrase": "entire_classifiers"}, {"score": 0.003421437601439154, "phrase": "similar_or_poor_classifiers"}, {"score": 0.003131178497790961, "phrase": "target_function"}, {"score": 0.003091767402370757, "phrase": "linear_combination"}, {"score": 0.002805597755796506, "phrase": "optimization_process"}, {"score": 0.002633355582628613, "phrase": "ensemble_individuals"}, {"score": 0.002461241017147324, "phrase": "selective_classifiers_ensemble_method"}, {"score": 0.0022906498741695094, "phrase": "kappa-error_diagrams"}, {"score": 0.0022051664509486206, "phrase": "proposed_method"}, {"score": 0.0021773853011112882, "phrase": "standard_ensemble_strategies"}, {"score": 0.0021590588269751816, "phrase": "evolutionary_ensemble"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Diversity", " Matching pursuit", " Greedy optimization", " Residual", " Selective ensemble", " Kappa-error diagram"], "paper_abstract": "Decreasing the individual error and increasing the diversity among classifiers are two crucial factors for improving ensemble performances. Nevertheless, the \"kappa-error\" diagram shows that enhancing the diversity is at the expense of reducing individual accuracy. Hence, a new method named Matching Pursuit Optimization Ensemble Classifiers (MPOEC) is proposed in this paper in order to balance the diversity and the individual accuracy. MPOEC method adopts a greedy iterative algorithm of matching pursuit to search for an optimal combination of entire classifiers, and eliminates some similar or poor classifiers by giving zero coefficients. In MPOEC approach, the coefficient of every classifier is gained by minimizing the residual between the target function and the linear combination of the basis functions, especially, when the basis functions are similar, their coefficients will be close to zeros in one iteration of the optimization process, which indicates that obtained coefficients of classifiers are based on the diversity among ensemble individuals. Because some classifiers are given zero coefficients, MPOEC approach may be also considered as a selective classifiers ensemble method. Experimental results show that MPOEC improves the performance compared with other methods. Furthermore, the kappa-error diagrams indicate that the diversity is increased by the proposed method compared with standard ensemble strategies and evolutionary ensemble. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Greedy optimization classifiers ensemble based on diversity", "paper_id": "WOS:000287622500009"}