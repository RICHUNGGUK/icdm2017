{"auto_keywords": [{"score": 0.04599283119366167, "phrase": "ran"}, {"score": 0.005223081309198142, "phrase": "learning_process"}, {"score": 0.00481495049065317, "phrase": "improved_resource"}, {"score": 0.004734038956773703, "phrase": "latent_semantic_feature_selection_approach"}, {"score": 0.004499334809770281, "phrase": "improved_learning_algorithm"}, {"score": 0.0044424917428102445, "phrase": "resource_allocating_network"}, {"score": 0.004349337717774093, "phrase": "text_categorization"}, {"score": 0.004258128672571261, "phrase": "promising_neural_network"}, {"score": 0.00422218060227958, "phrase": "single_hidden_layer_structure"}, {"score": 0.00416882434439484, "phrase": "radial_basis_function"}, {"score": 0.004046923261950549, "phrase": "clustering-based_method"}, {"score": 0.003978866233891427, "phrase": "initial_centers"}, {"score": 0.003928572641266562, "phrase": "hidden_layer"}, {"score": 0.0035634522350563107, "phrase": "novelty_criteria"}, {"score": 0.0033437537557378157, "phrase": "undesirable_noise_data"}, {"score": 0.0030847461428168614, "phrase": "preliminary_study_phase"}, {"score": 0.0030457198309616694, "phrase": "subsequent_study_phase"}, {"score": 0.0030071857666598193, "phrase": "former_phase"}, {"score": 0.0029691377785333872, "phrase": "preliminary_structure"}, {"score": 0.0028216858159564808, "phrase": "latter_phase"}, {"score": 0.002750721367040336, "phrase": "classification_accuracy"}, {"score": 0.0026363807171515255, "phrase": "higher_convergence_rate"}, {"score": 0.0025810006125483835, "phrase": "latent_semantic_feature_selection_method"}, {"score": 0.0024632148715152393, "phrase": "input_scale"}, {"score": 0.002391067964886602, "phrase": "latent_semantics"}, {"score": 0.0023507916951658455, "phrase": "extensive_experiments"}, {"score": 0.0021593396036472777, "phrase": "art_text_categorization_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Resource allocating network", " Novelty criteria", " Root mean square", " Least mean square", " Extended Kalman filter", " Semantic feature selection", " Neural network", " Text categorization"], "paper_abstract": "In this study we propose an improved learning algorithm based on resource allocating network (RAN) for text categorization. RAN is a promising neural network of single hidden layer structure based on radial basis function. We firstly use the means clustering-based method to determine the initial centers in the hidden layer. Such method can effectively overcome the limitation of local-optimal of clustering algorithms. Subsequently, in order to improve the novelty criteria of RAN, we propose a root mean square (RMS) sliding window method which can reduce the underlying influence of undesirable noise data. Through the further research on the learning process of RAN, we divide the learning process of RAN into a preliminary study phase and a subsequent study phase. The former phase initializes the preliminary structure of RAN and decreases the complexity of network, while the latter phase refines its learning ability and improves the classification accuracy. Such a compact network structure decreases the computational complexity and maintains the higher convergence rate. Moreover, a latent semantic feature selection method is utilized to organize documents. This method reduces the input scale of network, and reveals the latent semantics between features. Extensive experiments are conducted on two benchmark datasets, and the results demonstrate the superiority of our algorithm in comparison with state of the art text categorization algorithms. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Taking advantage of improved resource allocating network and latent semantic feature selection approach for automated text categorization", "paper_id": "WOS:000336411500017"}