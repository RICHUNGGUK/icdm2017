{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "runtime_monitoring"}, {"score": 0.004747429622531595, "phrase": "continuous_quality_assurance"}, {"score": 0.004714023408114857, "phrase": "web_services"}, {"score": 0.004408106853358092, "phrase": "current_monitoring_systems"}, {"score": 0.003950846696972114, "phrase": "collaborative_monitoring"}, {"score": 0.0038953958723049287, "phrase": "model-based_approach"}, {"score": 0.0038679618585498597, "phrase": "automatic_generating_sensors"}, {"score": 0.0036167509502276294, "phrase": "service_interface"}, {"score": 0.003207108833360533, "phrase": "ontology_model"}, {"score": 0.0031845067058084583, "phrase": "domain_concepts"}, {"score": 0.00316206336164649, "phrase": "usage_context"}, {"score": 0.00310664242361199, "phrase": "coverage_strategies"}, {"score": 0.0030630037175103032, "phrase": "specific_logic"}, {"score": 0.0029357204796552653, "phrase": "monitoring_sensors"}, {"score": 0.0028236828952575735, "phrase": "subject_and_assertion_sets"}, {"score": 0.0027741761880779535, "phrase": "ws-policy_standards"}, {"score": 0.002640114583897493, "phrase": "policy_engine"}, {"score": 0.002603012037901889, "phrase": "service_execution_engine"}, {"score": 0.002575526825728026, "phrase": "runtime_behavior_information"}, {"score": 0.002530359917257626, "phrase": "prototype_system"}, {"score": 0.0024772013657695896, "phrase": "eclipse_platform"}, {"score": 0.002391067964886602, "phrase": "process_execution"}, {"score": 0.00232431758517087, "phrase": "owl-s_execution_engine"}, {"score": 0.002307941088329585, "phrase": "soap"}, {"score": 0.00225144317399471, "phrase": "monitoring_results"}, {"score": 0.0022355610034493225, "phrase": "low_overhead"}, {"score": 0.002211947103318718, "phrase": "system_performance"}, {"score": 0.0021501863832966966, "phrase": "sensor_instrumentation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Web Services", " Runtime monitoring", " Model driven", " Policy enforcement"], "paper_abstract": "Runtime monitoring is necessary for continuous quality assurance of Web Services. Sensors are critical in runtime monitoring to capture the data and detect anomalies. However, sensors in Current monitoring systems are usually manually instrumented or hard-coded in the program. It is expensive to implement, and inflexible to change at runtime. The paper extends our previous research on collaborative monitoring and proposes a model-based approach for automatic generating sensors and enforcing policies, Web Services standards WSDL and OWL-S are taken as the models of service interface, workflow, and semantic. Sensors are generated based on the models from two perspectives: (1) dependency analysis of the data, operations, and services with respect to the ontology model of domain concepts and usage context; (2) coverage strategies to decide the specific logic and paths to cover and the data to capture by the monitoring sensors. Policies are defined as a 3-tuple of type, subject and assertion sets and are specified using WS-Policy standards. They are associated to the sensors and enforced at runtime by the policy engine that interoperates with service execution engine to communicate runtime behavior information and verification results. Prototype system is implemented based on the Eclipse platform where sensors are implemented as the listeners to the process execution and instrumented into the middleware including the OWL-S execution engine and SOAP engine. Experiments show that the monitoring results in low overhead of the system performance. reduced effort and enhanced flexibility of sensor instrumentation. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Model-based monitoring and policy enforcement of services", "paper_id": "WOS:000269293700004"}