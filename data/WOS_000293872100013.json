{"auto_keywords": [{"score": 0.04957462442669294, "phrase": "entropy_theory"}, {"score": 0.043447362577874626, "phrase": "component_network"}, {"score": 0.036146701610938206, "phrase": "enn"}, {"score": 0.00481495049065317, "phrase": "ensemble_neural_network"}, {"score": 0.004714023408114857, "phrase": "ensemble_neural_networks"}, {"score": 0.004542441734438654, "phrase": "neural_networks"}, {"score": 0.004064117897000019, "phrase": "single_feed-forward_network"}, {"score": 0.003978866233891427, "phrase": "back-propagation_learning_rule"}, {"score": 0.0038953958723049287, "phrase": "neural_network_architecture"}, {"score": 0.0038339398365449507, "phrase": "significant_influence"}, {"score": 0.0036359780843400625, "phrase": "proper_algorithm"}, {"score": 0.003559675269411366, "phrase": "enn_architecture"}, {"score": 0.0033402088717816446, "phrase": "component_networks"}, {"score": 0.0030847461428168614, "phrase": "best_structure"}, {"score": 0.0029098743621130004, "phrase": "automating_design_tool"}, {"score": 0.0028487656293168795, "phrase": "best_combining_weights"}, {"score": 0.0027159672205789645, "phrase": "friedman"}, {"score": 0.002575526825728026, "phrase": "proposed_ensemble_approach"}, {"score": 0.002508073621696602, "phrase": "entropy-based_enn"}, {"score": 0.00241658945942583, "phrase": "peak_particle_velocity"}, {"score": 0.002365815362517737, "phrase": "damage_criterion"}, {"score": 0.0023408288327263316, "phrase": "rock_mass"}, {"score": 0.0023038418282549274, "phrase": "computational_experiments"}, {"score": 0.0022434880661725493, "phrase": "proposed_entropy-based_enn"}, {"score": 0.002208035721125305, "phrase": "simple_averaging_enn"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Ensemble neural network", " Network architecture", " Entropy theory", " Peak particle velocity", " Network weight optimization", " Lagrange method"], "paper_abstract": "Ensemble neural networks (ENNs) are commonly used neural networks in many engineering applications due to their better generalization properties. An ENN usually includes several component networks in its structure, and each component network commonly uses a single feed-forward network trained with the back-propagation learning rule. As the neural network architecture has a significant influence on its generalization ability, it is crucial to develop a proper algorithm to determine the ENN architecture. In this paper, an ENN, which combines the component networks using the entropy theory, is proposed. The entropy-based ENN searches the best structure of each component network first, and employs entropy as an automating design tool to determine the best combining weights. Two analytical functions - the peak function and the Friedman function are used to assess the accuracy of the proposed ensemble approach. Then, the entropy-based ENN is applied to the modeling of peak particle velocity (PPV) damage criterion for rock mass. These computational experiments have verified that the proposed entropy-based ENN outperforms the simple averaging ENN and the single NN. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Design of ensemble neural network using entropy theory", "paper_id": "WOS:000293872100013"}