{"auto_keywords": [{"score": 0.028283332384069354, "phrase": "impressive_performance_speedup"}, {"score": 0.015719716506582538, "phrase": "ontology_matching"}, {"score": 0.01231933534284017, "phrase": "parallelism-enabled_platforms"}, {"score": 0.011621361574429981, "phrase": "matching_process"}, {"score": 0.004744748477093856, "phrase": "core_techniques"}, {"score": 0.004692766317526887, "phrase": "heterogeneity_resolution"}, {"score": 0.004624337472244542, "phrase": "knowledge-based_systems"}, {"score": 0.004506968388996092, "phrase": "excess_and_ever-evolving_nature"}, {"score": 0.004234129588974058, "phrase": "performance_bottlenecks"}, {"score": 0.004051501401100304, "phrase": "today's_desktop_and_cloud_platforms"}, {"score": 0.003992385826251404, "phrase": "parallelism-enabled_multicore_processors"}, {"score": 0.0038483286199081, "phrase": "effectiveness-independent_data"}, {"score": 0.0036958398682001015, "phrase": "complex_ontologies"}, {"score": 0.003433847524648519, "phrase": "finer-level_abstraction"}, {"score": 0.003408688677676014, "phrase": "independent_matching_requests"}, {"score": 0.003097865379563127, "phrase": "matching_space"}, {"score": 0.002985988377995789, "phrase": "oaei's_dataset"}, {"score": 0.0029100802280971065, "phrase": "diverse_domains"}, {"score": 0.002878140062594849, "phrase": "different_sizes"}, {"score": 0.00280496585980086, "phrase": "twenty_different_matching_tasks"}, {"score": 0.0027844017803674444, "phrase": "parallelism-enabled_desktop"}, {"score": 0.002763988044737562, "phrase": "microsoft_azure_public_cloud_platform"}, {"score": 0.002723607240517261, "phrase": "single-node_desktop_environment"}, {"score": 0.00244792069601419, "phrase": "single-node_cloud_environment"}, {"score": 0.0021049977753042253, "phrase": "desktop_and_cloud_platforms"}], "paper_keywords": ["Ontology matching", " Heterogeneity resolution", " Multithreading", " Parallel processing", " Parallel programming", " Semantic web"], "paper_abstract": "Ontology matching is among the core techniques used for heterogeneity resolution by information and knowledge-based systems. However, due to the excess and ever-evolving nature of data, ontologies are becoming large-scale and complex; consequently, leading to performance bottlenecks during ontology matching. In this paper, we present our performance-based ontology matching system. Today's desktop and cloud platforms are equipped with parallelism-enabled multicore processors. Our system benefits from this opportunity and provides effectiveness-independent data parallel ontology matching resolution over parallelism-enabled platforms. Our system decomposes complex ontologies into smaller, simpler, and scalable subsets depending upon the needs of matching algorithms. Matching process over these subsets is divided from granular to finer-level abstraction of independent matching requests, matching jobs, and matching tasks, running in parallel over parallelism-enabled platforms. Execution of matching algorithms is aligned for the minimization of the matching space during the matching process. We comprehensively evaluated our system over OAEI's dataset of fourteen real world ontologies from diverse domains, having different sizes and complexities. We have executed twenty different matching tasks over parallelism-enabled desktop and Microsoft Azure public cloud platform. In a single-node desktop environment, our system provides an impressive performance speedup of 4.1, 5.0, and 4.9 times for medium, large, and very large-scale ontologies. In a single-node cloud environment, our system provides an impressive performance speedup of 5.9, 7.4, and 7.0 times for medium, large, and very large-scale ontologies. In a multi-node (3 nodes) environment, our system provides an impressive performance speedup of 15.16 and 21.51 times over desktop and cloud platforms respectively.", "paper_title": "Performance-based ontology matching", "paper_id": "WOS:000358314000008"}