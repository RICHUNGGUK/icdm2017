{"auto_keywords": [{"score": 0.03636544963413303, "phrase": "ephemeral_disks"}, {"score": 0.004690583510896564, "phrase": "cloud_computing"}, {"score": 0.004569414098372132, "phrase": "scientific_community"}, {"score": 0.00448477700778838, "phrase": "high_performance_computing"}, {"score": 0.004451422960984676, "phrase": "hpc"}, {"score": 0.004352592156102578, "phrase": "novel_paradigm"}, {"score": 0.0040691889755318155, "phrase": "pay-per-use_basis"}, {"score": 0.003978866233891427, "phrase": "thorough_evaluation"}, {"score": 0.003637112258469488, "phrase": "different_layers"}, {"score": 0.003609989117581185, "phrase": "representative_benchmarks"}, {"score": 0.0035298229915690974, "phrase": "low-level_cloud_storage_devices"}, {"score": 0.003490448147575283, "phrase": "amazon"}, {"score": 0.00342568771304873, "phrase": "elastic_block_store"}, {"score": 0.0034001591168182554, "phrase": "ebs"}, {"score": 0.003324614337607016, "phrase": "local_and_distributed_file_systems"}, {"score": 0.003238620335304858, "phrase": "posix"}, {"score": 0.0032144564232099693, "phrase": "mpi-io"}, {"score": 0.0031312981393997355, "phrase": "scientific_workloads"}, {"score": 0.0029053368919259985, "phrase": "application_level"}, {"score": 0.0028195727965553367, "phrase": "cost_metrics"}, {"score": 0.0027569106820061707, "phrase": "experimental_results"}, {"score": 0.0027159094186967247, "phrase": "available_cloud_storage_devices"}, {"score": 0.002685558057339722, "phrase": "different_performance_characteristics"}, {"score": 0.002665511985052972, "phrase": "usage_constraints"}, {"score": 0.002427177130359851, "phrase": "optimal_configuration"}, {"score": 0.002268928296734176, "phrase": "tcp"}, {"score": 0.002235100569293439, "phrase": "nfs"}, {"score": 0.0021049977753042253, "phrase": "solid_state_drive"}], "paper_keywords": ["Cloud computing", " Virtualization", " I/O performance evaluation", " Network File System (NFS)", " MPI-IO", " Solid State Drive (SSD)"], "paper_abstract": "Cloud computing is currently being explored by the scientific community to assess its suitability for High Performance Computing (HPC) environments. In this novel paradigm, compute and storage resources, as well as applications, can be dynamically provisioned on a pay-per-use basis. This paper presents a thorough evaluation of the I/O storage subsystem using the Amazon EC2 Cluster Compute platform and the recent High I/O instance type, to determine its suitability for I/O-intensive applications. The evaluation has been carried out at different layers using representative benchmarks in order to evaluate the low-level cloud storage devices available in Amazon EC2, ephemeral disks and Elastic Block Store (EBS) volumes, both on local and distributed file systems. In addition, several I/O interfaces (POSIX, MPI-IO and HDF5) commonly used by scientific workloads have also been assessed. Furthermore, the scalability of a representative parallel I/O code has also been analyzed at the application level, taking into account both performance and cost metrics. The analysis of the experimental results has shown that available cloud storage devices can have different performance characteristics and usage constraints. Our comprehensive evaluation can help scientists to increase significantly (up to several times) the performance of I/O-intensive applications in Amazon EC2 cloud. An example of optimal configuration that can maximize I/O performance in this cloud is the use of a RAID 0 of 2 ephemeral disks, TCP with 9,000 bytes MTU, NFS async and MPI-IO on the High I/O instance type, which provides ephemeral disks backed by Solid State Drive (SSD) technology.", "paper_title": "Analysis of I/O Performance on an Amazon EC2 Cluster Compute and High I/O Platform", "paper_id": "WOS:000326838800001"}