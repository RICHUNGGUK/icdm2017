{"auto_keywords": [{"score": 0.04644054911903001, "phrase": "human_actions"}, {"score": 0.028851096418336997, "phrase": "stsp"}, {"score": 0.00481495049065317, "phrase": "spatio-temporal_oriented_energies"}, {"score": 0.004654928974748418, "phrase": "unified_representation"}, {"score": 0.0045855181084455444, "phrase": "spatio-temporal_steerable_pyramid"}, {"score": 0.00448332888936155, "phrase": "holistic_representation"}, {"score": 0.004399905285945236, "phrase": "video_sequence"}, {"score": 0.004318027255281003, "phrase": "spatio-temporal_volume"}, {"score": 0.004081385289516914, "phrase": "spatio-temporal_volumes"}, {"score": 0.0040508247605225214, "phrase": "band-passed_sub-volumes"}, {"score": 0.004005410765048467, "phrase": "spatio-temporal_laplacian_pyramid"}, {"score": 0.003916098498242888, "phrase": "multi-scale_analysis"}, {"score": 0.003828770052266183, "phrase": "spatio-temporal_patterns"}, {"score": 0.0036188435232325337, "phrase": "underlying_local_spatio-temporal_orientation_structures"}, {"score": 0.003511613254403125, "phrase": "three-dimensional_separable_steerable_filters"}, {"score": 0.003382017342396959, "phrase": "laplacian_pyramid"}, {"score": 0.003306559295382181, "phrase": "quad-rature_pair"}, {"score": 0.0030554300179552415, "phrase": "spatio-temporal_max_pooling_operation"}, {"score": 0.002953711377604328, "phrase": "adjacent_scales"}, {"score": 0.002920561105784389, "phrase": "spatio-temporal_neighbourhoods"}, {"score": 0.0028233196851239753, "phrase": "local_geometric_structure"}, {"score": 0.0026483647033436674, "phrase": "optical_flow"}, {"score": 0.002628506002255396, "phrase": "video_sequences"}, {"score": 0.0025892330566358503, "phrase": "unified_holistic_representation"}, {"score": 0.002502995662011305, "phrase": "multi-orientation_analysis"}, {"score": 0.0024105326885334962, "phrase": "informative_and_invariant_representation"}, {"score": 0.002347843727281585, "phrase": "extensive_experiments"}, {"score": 0.002321487111856032, "phrase": "kth"}, {"score": 0.0023040642263522505, "phrase": "ucf_sports"}, {"score": 0.0022441378838655712, "phrase": "unified_stsp"}, {"score": 0.0022273034991008326, "phrase": "comparable_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Action recognition", " Steerable filters", " Spatio-temporal oriented energies", " Spatio-temporal Laplacian pyramid"], "paper_abstract": "In this paper, we present a unified representation based on the spatio-temporal steerable pyramid (STSP) for the holistic representation of human actions. A video sequence is viewed as a spatio-temporal volume preserving all the appearance and motion information of an action in it. By decomposing the spatio-temporal volumes into band-passed sub-volumes, the spatio-temporal Laplacian pyramid provides an effective technique for multi-scale analysis of video sequences, and spatio-temporal patterns with different scales could be well localized and captured. To efficiently explore the underlying local spatio-temporal orientation structures at multiple scales, a bank of three-dimensional separable steerable filters are conducted on each of the sub-volume from the Laplacian pyramid. The outputs of the quad-rature pair of steerable filters are squared and summed to yield a more robust oriented energy representation. To be further invariant and compact, a spatio-temporal max pooling operation is performed between responses of the filtering at adjacent scales and over spatio-temporal neighbourhoods. In order to capture the appearance, local geometric structure and motion of an action, we apply the STSP on the intensity, 3D gradients and optical flow of video sequences, yielding a unified holistic representation of human actions. Taking advantage of multi-scale, multi-orientation analysis and feature pooling, STSP produces a compact but informative and invariant representation of human actions. We conduct extensive experiments on the KTH, UCF Sports and HMDB51 datasets, which shows the unified STSP achieves comparable results with the state-of-the-art methods. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Action recognition by spatio-temporal oriented energies", "paper_id": "WOS:000340315600019"}