{"auto_keywords": [{"score": 0.004661446705304497, "phrase": "deep_surrender"}, {"score": 0.0035965032173588753, "phrase": "colour_balance_modification_techniques"}, {"score": 0.003370565320453525, "phrase": "keyboard_playing"}, {"score": 0.0032629585038738856, "phrase": "vocal_timbre"}, {"score": 0.003107935254560724, "phrase": "live_performer"}, {"score": 0.002865710140187219, "phrase": "musical_feature_extraction_process"}, {"score": 0.0026423134393535265, "phrase": "control_system"}, {"score": 0.0022830706430588482, "phrase": "audio_and_visual_parameters"}, {"score": 0.0021049977753042253, "phrase": "artistic_motivations"}], "paper_keywords": [""], "paper_abstract": "In this paper we describe our responsive video performance, Deep Surrender, created using Cycling '74's Max/MSP and Jitter packages. Video parameters are manipulated in real-time, using chroma-keying and colour balance modification techniques to visualize the keyboard playing and vocal timbre of a live performer. We present the musical feature extraction process used to create a control system for the production, describe the mapping between audio and visual parameters, and discuss the artistic motivations behind the piece.", "paper_title": "Deep surrender: Musically controlled responsive video", "paper_id": "WOS:000239566000006"}