{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "gap_feature"}, {"score": 0.014654042696994444, "phrase": "gap"}, {"score": 0.014411728578234152, "phrase": "face_recognition"}, {"score": 0.014192306395463924, "phrase": "facial_model"}, {"score": 0.007946534331927584, "phrase": "proposed_method"}, {"score": 0.004596295252559861, "phrase": "novel_approach"}, {"score": 0.004525629293824217, "phrase": "grayscale_arranging_pairs"}, {"score": 0.004209893377338457, "phrase": "stable_point_pairs"}, {"score": 0.003936389070602614, "phrase": "input_facial_image"}, {"score": 0.0037965243835456214, "phrase": "intensity_relationship"}, {"score": 0.0037381083634085424, "phrase": "point_pairs"}, {"score": 0.0036052633308076933, "phrase": "current_face_recognition_algorithms"}, {"score": 0.003513264130359459, "phrase": "robust_holistic_feature"}, {"score": 0.003370907075333389, "phrase": "stable_intensity_relationship"}, {"score": 0.003336225354214798, "phrase": "multiple_point_pairs"}, {"score": 0.003234299589505403, "phrase": "great_invariance_property"}, {"score": 0.003201018846103988, "phrase": "facial_features"}, {"score": 0.0031354779851351287, "phrase": "high_robustness"}, {"score": 0.0030872017736888113, "phrase": "illumination_variations"}, {"score": 0.002977419551510206, "phrase": "holistic_information"}, {"score": 0.002931569771634119, "phrase": "entire_facial_image"}, {"score": 0.0028127163745564777, "phrase": "human_recognition_mechanism"}, {"score": 0.002726740692380339, "phrase": "novel_weighting_model"}, {"score": 0.002670884656785558, "phrase": "local_characteristics"}, {"score": 0.0025100713447593773, "phrase": "higher_accuracy"}, {"score": 0.002358917661465133, "phrase": "extended_yale_b_face"}, {"score": 0.002334628139216576, "phrase": "pie"}, {"score": 0.0022749744354271816, "phrase": "experimental_results"}, {"score": 0.0022053994402287925, "phrase": "outstanding_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Grayscale Arranging Pairs (GAP)", " Weighting model", " Holistic feature", " Face recognition"], "paper_abstract": "In this paper, we propose a novel approach based on Grayscale Arranging Pairs (GAP) for face recognition. A facial model is built by using the stable point pairs of the GAP feature. Then the similarity between the facial model and the input facial image is calculated by checking whether the intensity relationship of these point pairs is the same. Different from current face recognition algorithms, GAP is a robust holistic feature without losing its local property. By using a stable intensity relationship of multiple point pairs, the GAP feature shows a great invariance property of facial features, and exhibits high robustness to resist illumination variations. Meanwhile, it describes the holistic information in the entire facial image, which is more similar to the human recognition mechanism. In addition, a novel weighting model that exploits the local characteristics of faces is applied in the framework, leading to a higher accuracy in face recognition. We compare the proposed method with four other famous methods on the Extended Yale B face and PIE face databases. The experimental results showed that the proposed method provides outstanding results in recognizing faces. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Robust face recognition using the GAP feature", "paper_id": "WOS:000320477400004"}