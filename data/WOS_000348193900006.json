{"auto_keywords": [{"score": 0.05007813205043781, "phrase": "individual_differences"}, {"score": 0.04814050608144561, "phrase": "fer"}, {"score": 0.03755329046353704, "phrase": "structural_characteristics"}, {"score": 0.03699475738178648, "phrase": "texture_information"}, {"score": 0.004765482708043842, "phrase": "facial_structure"}, {"score": 0.004668059458774745, "phrase": "facial_expression_recognition"}, {"score": 0.004525629293824217, "phrase": "important_role"}, {"score": 0.004479120557712926, "phrase": "human-computer_interaction"}, {"score": 0.004410248125081398, "phrase": "recent_years"}, {"score": 0.004320055598195391, "phrase": "increasing_trend"}, {"score": 0.0038959121068990517, "phrase": "recognition_result"}, {"score": 0.003816197777388722, "phrase": "face_images"}, {"score": 0.0036427316134070007, "phrase": "changing_information"}, {"score": 0.003459191419478298, "phrase": "rich_important_clues"}, {"score": 0.003370907075333389, "phrase": "face_image"}, {"score": 0.0032176163279340206, "phrase": "great_importance"}, {"score": 0.0031845067058084583, "phrase": "machine_vision"}, {"score": 0.0030872017736888113, "phrase": "novel_fer_algorithm"}, {"score": 0.0029164434911787187, "phrase": "image_space"}, {"score": 0.002841971477743441, "phrase": "feature_points"}, {"score": 0.002769395841379498, "phrase": "active_appearance_model"}, {"score": 0.0026570998719084153, "phrase": "feature_point_distance_ratio_coefficient"}, {"score": 0.0026297428083782875, "phrase": "connection_angle_ratio_coefficient"}, {"score": 0.0026026666736474404, "phrase": "skin_deformation_energy_parameter"}, {"score": 0.002408265305704217, "phrase": "radial_basis_function_neural_network"}, {"score": 0.002310578855290687, "phrase": "fer._extensive_experimental_results"}, {"score": 0.0022749744354271816, "phrase": "cohn-kanade_database"}, {"score": 0.0022053994402287925, "phrase": "facial_expression_database"}, {"score": 0.0021714122348552747, "phrase": "significant_advantages"}, {"score": 0.002137947680862631, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "existing_ones"}], "paper_keywords": [""], "paper_abstract": "Facial expression recognition (FER) plays an important role in human-computer interaction. The recent years have witnessed an increasing trend of various approaches for the FER, but these approaches usually do not consider the effect of individual differences to the recognition result. When the face images change from neutral to a certain expression, the changing information constituted of the structural characteristics and the texture information can provide rich important clues not seen in either face image. Therefore it is believed to be of great importance for machine vision. This study proposes a novel FER algorithm by exploiting the structural characteristics and the texture information hiding in the image space. Firstly, the feature points are marked by an active appearance model. Secondly, three facial features, which are feature point distance ratio coefficient, connection angle ratio coefficient and skin deformation energy parameter, are proposed to eliminate the differences among the individuals. Finally, a radial basis function neural network is utilised as the classifier for the FER. Extensive experimental results on the Cohn-Kanade database and the Beihang University (BHU) facial expression database show the significant advantages of the proposed method over the existing ones.", "paper_title": "Facial expression recognition considering individual differences in facial structure and texture", "paper_id": "WOS:000348193900006"}