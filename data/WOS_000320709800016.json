{"auto_keywords": [{"score": 0.03729306928688609, "phrase": "snr"}, {"score": 0.011888717262576943, "phrase": "measurement_rate"}, {"score": 0.00481495049065317, "phrase": "approximate_sparsity_pattern_recovery"}, {"score": 0.004494570360108983, "phrase": "sparsity_pattern"}, {"score": 0.004301834610818624, "phrase": "unknown_sparse_vector"}, {"score": 0.00422177384286051, "phrase": "small_number"}, {"score": 0.004169226023596022, "phrase": "noisy_linear_measurements"}, {"score": 0.0040916230716372265, "phrase": "important_problem"}, {"score": 0.004040688646993605, "phrase": "compressed_sensing"}, {"score": 0.0038673406001234535, "phrase": "high-dimensional_setting"}, {"score": 0.003587235362628753, "phrase": "per-sample_signal-to-noise_ratio"}, {"score": 0.0032246835734680377, "phrase": "optimal_sparsity_pattern_estimate"}, {"score": 0.0031448288291084, "phrase": "constant_fraction"}, {"score": 0.003066945490483524, "phrase": "lower_bounds"}, {"score": 0.0029169007179202164, "phrase": "desired_fraction"}, {"score": 0.002671722386856879, "phrase": "unknown_vector"}, {"score": 0.002525074485615743, "phrase": "scaling_sense"}, {"score": 0.0022413233627905696, "phrase": "existing_achievable_bounds"}, {"score": 0.0021315842986705485, "phrase": "wide_variety"}, {"score": 0.0021049977753042253, "phrase": "practically_motivated_signal_models"}], "paper_keywords": ["Compressed sensing", " information-theoretic bounds", " random matrix theory", " sparsity", " support recovery"], "paper_abstract": "Recovery of the sparsity pattern (or support) of an unknown sparse vector from a small number of noisy linear measurements is an important problem in compressed sensing. In this paper, the high-dimensional setting is considered. It is shown that if the measurement rate and per-sample signal-to-noise ratio (SNR) are finite constants independent of the length of the vector, then the optimal sparsity pattern estimate will have a constant fraction of errors. Lower bounds on the measurement rate needed to attain a desired fraction of errors are given in terms of the SNR and various key parameters of the unknown vector. The tightness of the bounds in a scaling sense, as a function of the SNR and the fraction of errors, is established by comparison with existing achievable bounds. Near optimality is shown for a wide variety of practically motivated signal models.", "paper_title": "Approximate Sparsity Pattern Recovery: Information-Theoretic Lower Bounds", "paper_id": "WOS:000320709800016"}