{"auto_keywords": [{"score": 0.04898285994723956, "phrase": "electronic_health_records"}, {"score": 0.03979933391791906, "phrase": "multi-modal_strategy"}, {"score": 0.038486386105949885, "phrase": "optical_character_recognition"}, {"score": 0.00481495049065317, "phrase": "multi-modal_approaches"}, {"score": 0.004741167616693272, "phrase": "cataract_cases"}, {"score": 0.004405779372462873, "phrase": "genomic_association_studies"}, {"score": 0.0042552618754756934, "phrase": "large_amounts"}, {"score": 0.004222515162635615, "phrase": "clinical_data"}, {"score": 0.004173865018011237, "phrase": "expected_cost_efficiencies"}, {"score": 0.004141742095830515, "phrase": "subject_identification"}, {"score": 0.00398478333092707, "phrase": "ehr-based_algorithm"}, {"score": 0.0039085400187964196, "phrase": "age-related_cataracts"}, {"score": 0.003745881316228299, "phrase": "structured_database_querying"}, {"score": 0.003702702337768558, "phrase": "free-text_documents"}, {"score": 0.0036178264212372497, "phrase": "clinical_images"}, {"score": 0.0035761182400032487, "phrase": "cataract_subjects"}, {"score": 0.003548579306515579, "phrase": "related_cataract_attributes"}, {"score": 0.0035212516951180946, "phrase": "extensive_validation"}, {"score": 0.0034538466642399976, "phrase": "multi-modal_results"}, {"score": 0.003427246079774314, "phrase": "manual_chart_review"}, {"score": 0.003310047704590791, "phrase": "electronic_medical_records"}, {"score": 0.0031845067058084583, "phrase": "ehr-based_cataract_phenotyping_algorithm"}, {"score": 0.003075583447856341, "phrase": "positive_predictive_values"}, {"score": 0.002993439939273828, "phrase": "multi-modal_approach"}, {"score": 0.0029361086955646625, "phrase": "cataract_subject_attributes"}, {"score": 0.002846647336160784, "phrase": "single-mode_approaches"}, {"score": 0.0028138046006772593, "phrase": "high_ppv._components_of"}, {"score": 0.002792119634261638, "phrase": "cataract_algorithm"}, {"score": 0.0027175263159330523, "phrase": "similar_accuracy"}, {"score": 0.0026347074232350503, "phrase": "natural_language_processing"}, {"score": 0.0025347150832077175, "phrase": "similar_ppvs"}, {"score": 0.0024479627964740748, "phrase": "needed_information"}, {"score": 0.002410363090950055, "phrase": "clinical_documents"}, {"score": 0.0022222155739303035, "phrase": "ehr."}, {"score": 0.0021796224306652326, "phrase": "high_level"}, {"score": 0.0021213575697367148, "phrase": "multiple_ehrs"}, {"score": 0.0021049977753042253, "phrase": "institutional_boundaries"}], "paper_keywords": [""], "paper_abstract": "Objective There is increasing interest in using electronic health records (EHRs) to identify subjects for genomic association studies, due in part to the availability of large amounts of clinical data and the expected cost efficiencies of subject identification. We describe the construction and validation of an EHR-based algorithm to identify subjects with age-related cataracts. Materials and methods We used a multi-modal strategy consisting of structured database querying, natural language processing on free-text documents, and optical character recognition on scanned clinical images to identify cataract subjects and related cataract attributes. Extensive validation on 3657 subjects compared the multi-modal results to manual chart review. The algorithm was also implemented at participating electronic MEdical Records and GEnomics (eMERGE) institutions. Results An EHR-based cataract phenotyping algorithm was successfully developed and validated, resulting in positive predictive values (PPVs) >95%. The multi-modal approach increased the identification of cataract subject attributes by a factor of three compared to single-mode approaches while maintaining high PPV. Components of the cataract algorithm were successfully deployed at three other institutions with similar accuracy. Discussion A multi-modal strategy incorporating optical character recognition and natural language processing may increase the number of cases identified while maintaining similar PPVs. Such algorithms, however, require that the needed information be embedded within clinical documents. Conclusion We have demonstrated that algorithms to identify and characterize cataracts can be developed utilizing data collected via the EHR. These algorithms provide a high level of accuracy even when implemented across multiple EHRs and institutional boundaries.", "paper_title": "Importance of multi-modal approaches to effectively identify cataract cases from electronic health records", "paper_id": "WOS:000300768100016"}