{"auto_keywords": [{"score": 0.028759907234408705, "phrase": "google"}, {"score": 0.00481495049065317, "phrase": "videos_cast"}, {"score": 0.004777744121315302, "phrase": "text_retrieval"}, {"score": 0.004302593474473502, "phrase": "query_image"}, {"score": 0.004090901264701185, "phrase": "viewpoint_invariant_region_descriptors"}, {"score": 0.003859500298805362, "phrase": "partial_occlusion"}, {"score": 0.0038148090091532933, "phrase": "temporal_continuity"}, {"score": 0.0035024506353894644, "phrase": "efficient_retrieval"}, {"score": 0.003408512155673965, "phrase": "statistical_text_retrieval"}, {"score": 0.0033690254452595865, "phrase": "inverted_file_systems"}, {"score": 0.0032155857567170696, "phrase": "visual_analogy"}, {"score": 0.003010063382882408, "phrase": "final_ranking"}, {"score": 0.002952146666681891, "phrase": "spatial_layout"}, {"score": 0.00278497898719426, "phrase": "ranked_list"}, {"score": 0.002617059777997427, "phrase": "object_retrieval"}, {"score": 0.0025867180355950816, "phrase": "full-length_feature_films"}, {"score": 0.002566685388128598, "phrase": "groundhog_day"}, {"score": 0.002547099754611837, "phrase": "casablanca"}, {"score": 0.0024784363584530976, "phrase": "run_lola_run"}, {"score": 0.0023654615987859402, "phrase": "external_images"}, {"score": 0.002293014162421338, "phrase": "retrieval_performance"}, {"score": 0.0022576249214220187, "phrase": "different_quantizations"}, {"score": 0.00224013518726087, "phrase": "region_descriptors"}, {"score": 0.0021214346747442363, "phrase": "baseline_method"}, {"score": 0.0021049977753042253, "phrase": "standard_frame"}], "paper_keywords": ["Object recognition", " viewpoint and scale invariance", " text retrieval"], "paper_abstract": "We describe an approach to object retrieval that searches for and localizes all of the occurrences of an object in a video, given a query image of the object. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination, and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject those that are unstable. Efficient retrieval is achieved by employing methods from statistical text retrieval, including inverted file systems, and text and document frequency weightings. This requires a visual analogy of a word, which is provided here by vector quantizing the region descriptors. The final ranking also depends on the spatial layout of the regions. The result is that retrieval is immediate, returning a ranked list of shots in the manner of Google [6]. We report results for object retrieval on the full-length feature films \"Groundhog Day,\" \"Casablanca,\" and \" Run Lola Run,\" including searches from within the movie and specified by external images downloaded from the Internet. We investigate retrieval performance with respect to different quantizations of region descriptors and compare the performance of several ranking measures. Performance is also compared to a baseline method implementing standard frame to frame matching.", "paper_title": "Efficient Visual Search of Videos Cast as Text Retrieval", "paper_id": "WOS:000263396100002"}