{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "data_publishing"}, {"score": 0.004700027722284931, "phrase": "easy_and_economic_means"}, {"score": 0.004543708337879809, "phrase": "privacy_risk"}, {"score": 0.004478308876320956, "phrase": "major_concern"}, {"score": 0.004392565073466714, "phrase": "privacy_preservation"}, {"score": 0.004329331617724, "phrase": "major_task"}, {"score": 0.004287680323820891, "phrase": "data_sharing"}, {"score": 0.004026505114417176, "phrase": "large_number"}, {"score": 0.003987755561492638, "phrase": "data_publishing_models"}, {"score": 0.003744780941673966, "phrase": "high_privacy_requirement"}, {"score": 0.0035507457285983268, "phrase": "new_framework"}, {"score": 0.00328625950643742, "phrase": "sensitive_value"}, {"score": 0.0032389001343643064, "phrase": "published_data"}, {"score": 0.003056169480391946, "phrase": "public_knowledge"}, {"score": 0.0030121159909273897, "phrase": "semantic_meaning"}, {"score": 0.002855934865505357, "phrase": "published_data_set"}, {"score": 0.0027741761880779535, "phrase": "lower_confidence"}, {"score": 0.0023079225317714815, "phrase": "privacy-preserving_data_publishing"}, {"score": 0.002252701813819903, "phrase": "sound_semantic_protection"}, {"score": 0.0021670777282518424, "phrase": "higher_data_utility"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Privacy protection", " Data publishing", " Anonymization"], "paper_abstract": "Data publishing is an easy and economic means for data sharing, but the privacy risk is a major concern in data publishing. Privacy preservation is a major task in data sharing for organizations like bureau of statistics, and hospitals. While a large number of data publishing models and methods have been proposed, their utility is of concern when a high privacy requirement is imposed. In this paper, we propose a new framework for privacy preserving data publishing. We cap the belief of an adversary inferring a sensitive value in a published data set to as high as that of an inference based on public knowledge. The semantic meaning is that when an adversary sees a record in a published data set, s/he will have a lower confidence that the record belongs to a victim than not. We design a method integrating sampling and generalization to implement the model. We compare the method with some state-of-the-art methods on privacy-preserving data publishing experimentally, our proposed method provides sound semantic protection of individuals in data and, provides higher data utility. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A general framework for privacy preserving data publishing", "paper_id": "WOS:000327685800025"}