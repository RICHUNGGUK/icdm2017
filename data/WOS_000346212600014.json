{"auto_keywords": [{"score": 0.04451656632905737, "phrase": "real_time"}, {"score": 0.009720207702472148, "phrase": "streaming_data"}, {"score": 0.009071667057407478, "phrase": "cloud_data_center"}, {"score": 0.00481495049065317, "phrase": "healthcare_applications"}, {"score": 0.0047846807459660376, "phrase": "healthcare_scientific_applications"}, {"score": 0.004724708238414131, "phrase": "body_area_network"}, {"score": 0.004621551111118693, "phrase": "interconnected_sensors"}, {"score": 0.004563613939245774, "phrase": "health_status"}, {"score": 0.004449899743607532, "phrase": "biggest_challenges"}, {"score": 0.0042308653646339405, "phrase": "follow-up_data_analysis"}, {"score": 0.0041515244239033145, "phrase": "collected_big_data"}, {"score": 0.00408654006336477, "phrase": "status_reporting"}, {"score": 0.00406083086983316, "phrase": "record_tracking_purpose"}, {"score": 0.003997260449163666, "phrase": "efficient_cloud_platform"}, {"score": 0.0038608730929994696, "phrase": "data_applications"}, {"score": 0.003824487838437583, "phrase": "current_cloud_platform"}, {"score": 0.0036476222647061243, "phrase": "coarse-grained_compute_nodes"}, {"score": 0.003545439507880801, "phrase": "task-level_adaptive_mapreduce_framework"}, {"score": 0.0034789073740172324, "phrase": "generic_mapreduce_architecture"}, {"score": 0.0033707740216185815, "phrase": "consistent_running_loop_daemon"}, {"score": 0.003307508702661699, "phrase": "new_framework"}, {"score": 0.003276321257403678, "phrase": "scaling_capability"}, {"score": 0.0031148723927633955, "phrase": "compute-node_level"}, {"score": 0.0029241700853970013, "phrase": "effective_use"}, {"score": 0.002905752244360772, "phrase": "compute_resources"}, {"score": 0.0028511898481970595, "phrase": "first_step"}, {"score": 0.0027976491158911514, "phrase": "real_cloud"}, {"score": 0.0027278178983579085, "phrase": "workload_strength"}, {"score": 0.0026513335370556474, "phrase": "reduce_tasks"}, {"score": 0.002488966731071964, "phrase": "kalman"}, {"score": 0.0024421847638964947, "phrase": "unknown_workload_characteristics"}, {"score": 0.00238120499061399, "phrase": "kalman_filter_method"}, {"score": 0.0023144166368024603, "phrase": "real_streaming_data_workload_trace"}, {"score": 0.0022709326810964386, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Adaptive MapReduce", " Big data", " Healthcare scientific applications", " Kalman filter", " Parallel processing"], "paper_abstract": "Healthcare scientific applications, such as body area network, require of deploying hundreds of interconnected sensors to monitor the health status of a host. One of the biggest challenges is the streaming data collected by all those sensors, which needs to be processed in real time. Follow-up data analysis would normally involve moving the collected big data to a cloud data center for status reporting and record tracking purpose. Therefore, an efficient cloud platform with very elastic scaling capacity is needed to support such kind of real time streaming data applications. The current cloud platform either lacks of such a module to process streaming data, or scales in regard to coarse-grained compute nodes. In this paper, we propose a task-level adaptive MapReduce framework. This framework extends the generic MapReduce architecture by designing each Map and Reduce task as a consistent running loop daemon. The beauty of this new framework is the scaling capability being designed at the Map and Task level, rather than being scaled from the compute-node level. This strategy is capable of not only scaling up and down in real time, but also leading to effective use of compute resources in cloud data center. As a first step towards implementing this framework in real cloud, we developed a simulator that captures workload strength, and provisions the amount of Map and Reduce tasks just in need and in real time. To further enhance the framework, we applied two streaming data workload prediction methods, smoothing and Kalman filter, to estimate the unknown workload characteristics. We see 63.1% performance improvement by using the Kalman filter method to predict the workload. We also use real streaming data workload trace to test the framework. Experimental results show that this framework schedules the Map and Reduce tasks very efficiently, as the streaming data changes its arrival rate. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A task-level adaptive Map Reduce framework for real-time streaming data in healthcare applications", "paper_id": "WOS:000346212600014"}