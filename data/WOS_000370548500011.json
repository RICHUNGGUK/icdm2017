{"auto_keywords": [{"score": 0.03498048027388705, "phrase": "dead_storage"}, {"score": 0.03171939562914439, "phrase": "associated_logic"}, {"score": 0.004815112813718618, "phrase": "cache"}, {"score": 0.004695183699894267, "phrase": "processing_and_storage_speeds"}, {"score": 0.0043533862892678864, "phrase": "slower_memory_components"}, {"score": 0.004288059466938456, "phrase": "recent_studies"}, {"score": 0.00418134346679498, "phrase": "dead_data"}, {"score": 0.004036369952624852, "phrase": "significant_fraction"}, {"score": 0.0037993970934472243, "phrase": "slower_memory"}, {"score": 0.0034003686971964707, "phrase": "dynamic_storage_allocation"}, {"score": 0.003216804708106142, "phrase": "program's_storage-allocation_requests"}, {"score": 0.003058515297281172, "phrase": "favorable_circumstances"}, {"score": 0.0029374939071038146, "phrase": "full_speed"}, {"score": 0.0028498718992429825, "phrase": "cache's_normal_behavior"}, {"score": 0.002628747284714371, "phrase": "cache's_critical_path"}, {"score": 0.002563219920877287, "phrase": "cache's_performance"}, {"score": 0.0021917966722180132, "phrase": "hardware_implementation"}, {"score": 0.002137137933768807, "phrase": "cache_size"}], "paper_keywords": ["cache", " garbage collection", " reference counting"], "paper_abstract": "The disparity between processing and storage speeds can be bridged in part by reducing the traffic into and out of the slower memory components. Some recent studies reduce such traffic by determining dead data in cache, showing that a significant fraction of writes can be squashed before they make the trip toward slower memory. In this paper, we examine a technique for eliminating traffic in the other direction, specifically the traffic induced by dynamic storage allocation. We consider recycling dead storage in cache to satisfy a program's storage-allocation requests. We first evaluate the potential for recycling under favorable circumstances, where the associated logic can run at full speed with no impact on the cache's normal behavior. We then consider a more practical implementation, in which the associated logic executes independently from the cache's critical path. Here, the cache's performance is unfettered by recycling, but the operations necessary to determine dead storage and recycle such storage execute as time is available. Finally, we present the design and analysis of a hardware implementation that scales well with cache size without sacrificing too much performance.", "paper_title": "Recycling Trash in Cache", "paper_id": "WOS:000370548500011"}