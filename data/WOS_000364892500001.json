{"auto_keywords": [{"score": 0.04927465911141675, "phrase": "multi-scale_plasma_turbulence"}, {"score": 0.004615202066192795, "phrase": "plasma_turbulence_simulation_code"}, {"score": 0.004537631845923196, "phrase": "strong_scaling"}, {"score": 0.004312622975366676, "phrase": "multiple_spatio-temporal_scales"}, {"score": 0.004133627071344356, "phrase": "gyrokinetic_theory"}, {"score": 0.004098725744818192, "phrase": "huge_calculations"}, {"score": 0.003928572641266562, "phrase": "spectral_and_finite_difference_methods"}, {"score": 0.003813669883040509, "phrase": "multi-layer_domain_decomposition"}, {"score": 0.0037654565082218595, "phrase": "multi-dimensional_and_multi-species_problem"}, {"score": 0.003533347967582184, "phrase": "bi-section_bandwidth"}, {"score": 0.003400984514637656, "phrase": "simultaneous_point-to-point_communications"}, {"score": 0.003315499339103866, "phrase": "inter-node_communication_cost"}, {"score": 0.003245900020944865, "phrase": "pipelined_computation-communication_overlaps"}, {"score": 0.0030847461428168614, "phrase": "communication_cost"}, {"score": 0.0030071857666598193, "phrase": "pipeline_length"}, {"score": 0.0028823148390466334, "phrase": "mpi"}, {"score": 0.002857849698346116, "phrase": "load_imbalance"}, {"score": 0.0027274647129990524, "phrase": "gkv"}, {"score": 0.002704403349815203, "phrase": "excellent_strong_scaling"}, {"score": 0.0025591748412278174, "phrase": "theoretical_peak"}, {"score": 0.0023013968622710847, "phrase": "optimized_code"}, {"score": 0.002281930100792185, "phrase": "multi-scale_plasma_turbulence_simulations"}, {"score": 0.002196342933346204, "phrase": "cross-scale_interactions"}, {"score": 0.0021593396036472777, "phrase": "ion-scale_turbulence"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Gyrokinetics", " Computational fluid dynamics application", " Parallel scalability", " Spectral method", " Finite difference"], "paper_abstract": "Optimization techniques of a plasma turbulence simulation code GKV for improved strong scaling are presented. This work is motivated by multi-scale plasma turbulence extending over multiple spatio-temporal scales of electrons and ions, whose simulations based on the gyrokinetic theory require huge calculations of five-dimensional (5D) computational fluid dynamics by means of spectral and finite difference methods. First, we present the multi-layer domain decomposition of the multi-dimensional and multi-species problem, and segmented MPI-process mapping on 3D torus interconnects, which fully utilizes the bi-section bandwidth for data transpose and reduces the conflicts of simultaneous point-to-point communications. These techniques reduce the inter-node communication cost drastically. Second, pipelined computation-communication overlaps are implemented by using the OpenMP/MPI hybrid parallelization, which effectively mask the communication cost. Careful regulations of the pipeline length and of the thread granularity respectively suppress latencies of MPI, load imbalance and scheduling overheads of OpenMP. Thanks to the above optimizations, GKV achieves excellent strong scaling up to similar to 600k cores with high computational performance 782.4 TFlops (8.29% of the theoretical peak) and high effective parallelization rate similar to 99.99994% on K, which demonstrates its applicability and efficiency toward a million of cores. The optimized code realizes multi-scale plasma turbulence simulations covering electron and ion scales, and reveals cross-scale interactions of electron- and ion-scale turbulence. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Improved strong scaling of a spectral/finite difference gyrokinetic code for multi-scale plasma turbulence", "paper_id": "WOS:000364892500001"}