{"auto_keywords": [{"score": 0.04818186976728296, "phrase": "e-differential_privacy"}, {"score": 0.043452207739444165, "phrase": "relational_and_set-valued_data"}, {"score": 0.014129323549701497, "phrase": "existing_solutions"}, {"score": 0.011009552772500819, "phrase": "noise_addition"}, {"score": 0.00896471323330712, "phrase": "proposed_algorithm"}, {"score": 0.00481495049065317, "phrase": "sensitive_data"}, {"score": 0.0047292449487169345, "phrase": "useful_information"}, {"score": 0.0046659637258752535, "phrase": "existing_privacy_models"}, {"score": 0.004521566043596533, "phrase": "strongest_privacy_guarantees"}, {"score": 0.00438161736774803, "phrase": "adversary's_background_knowledge"}, {"score": 0.004096082254543022, "phrase": "privacy-preserving_manner"}, {"score": 0.00374399358035391, "phrase": "healthcare_data"}, {"score": 0.003677280504320639, "phrase": "proposed_approach"}, {"score": 0.003628024127607343, "phrase": "simple_yet_fundamental_switch"}, {"score": 0.003595552309967789, "phrase": "differentially_private_algorithm_design"}, {"score": 0.003499864176875713, "phrase": "possible_records"}, {"score": 0.0031702173541386888, "phrase": "raw_data"}, {"score": 0.0031277316566463978, "phrase": "probabilistic_way"}, {"score": 0.0029236680654022664, "phrase": "disclosed_data"}, {"score": 0.002820319063320601, "phrase": "decision_tree_induction_classifier"}, {"score": 0.002624423288947767, "phrase": "classification_analysis"}, {"score": 0.00257760787870709, "phrase": "resulting_utility"}, {"score": 0.0025202582748972122, "phrase": "output_domain_size"}, {"score": 0.002398529964696261, "phrase": "synthetic_data"}, {"score": 0.0023770362063833903, "phrase": "large_health_databases"}, {"score": 0.0023346234464901978, "phrase": "existing_techniques"}, {"score": 0.0022520496048464406, "phrase": "health_data"}, {"score": 0.002124036931047162, "phrase": "essential_information"}, {"score": 0.0021049977753042253, "phrase": "discriminative_analysis"}], "paper_keywords": [""], "paper_abstract": "Objective Privacy-preserving data publishing addresses the problem of disclosing sensitive data when mining for useful information. Among existing privacy models, e-differential privacy provides one of the strongest privacy guarantees and makes no assumptions about an adversary's background knowledge. All existing solutions that ensure e-differential privacy handle the problem of disclosing relational and set-valued data in a privacy-preserving manner separately. In this paper, we propose an algorithm that considers both relational and set-valued data in differentially private disclosure of healthcare data. Methods The proposed approach makes a simple yet fundamental switch in differentially private algorithm design: instead of listing all possible records (ie, a contingency table) for noise addition, records are generalized before noise addition. The algorithm first generalizes the raw data in a probabilistic way, and then adds noise to guarantee e-differential privacy. Results We showed that the disclosed data could be used effectively to build a decision tree induction classifier. Experimental results demonstrated that the proposed algorithm is scalable and performs better than existing solutions for classification analysis. Limitation The resulting utility may degrade when the output domain size is very large, making it potentially inappropriate to generate synthetic data for large health databases. Conclusions Unlike existing techniques, the proposed algorithm allows the disclosure of health data containing both relational and set-valued data in a differentially private manner, and can retain essential information for discriminative analysis.", "paper_title": "Privacy-preserving heterogeneous health data sharing", "paper_id": "WOS:000317477500010"}