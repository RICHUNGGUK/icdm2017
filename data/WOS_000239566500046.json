{"auto_keywords": [{"score": 0.04229669615013434, "phrase": "semantic_classes"}, {"score": 0.00481495049065317, "phrase": "cluster-based_index"}, {"score": 0.004721602309430702, "phrase": "high-dimensional_index"}, {"score": 0.00459393336391459, "phrase": "content-based_video_retrieval"}, {"score": 0.004452228677941085, "phrase": "video_database"}, {"score": 0.004005339423663657, "phrase": "visual_feature_distributions"}, {"score": 0.0039122637074546895, "phrase": "gaussian_mixture_model"}, {"score": 0.0037915057447460133, "phrase": "semantics_supervised_cluster_based_index_approach"}, {"score": 0.0037325304253359986, "phrase": "ssci"}, {"score": 0.003589046900483573, "phrase": "visual_features"}, {"score": 0.003547084456662448, "phrase": "entire_data_set"}, {"score": 0.0034646205853140558, "phrase": "modified_clustering_technique"}, {"score": 0.0032667240408191015, "phrase": "visual_feature_space"}, {"score": 0.00310435218261112, "phrase": "visual_feature_clue"}, {"score": 0.0029849474387154827, "phrase": "visual_feature"}, {"score": 0.0028365413717574544, "phrase": "ssci-based_nearest-neighbor"}, {"score": 0.0027060907634889734, "phrase": "first_phase"}, {"score": 0.0026431267487109543, "phrase": "query_example"}, {"score": 0.002612194827110595, "phrase": "cluster_index"}, {"score": 0.002541417196444962, "phrase": "smallest_distance"}, {"score": 0.002453221048083196, "phrase": "second_phase"}, {"score": 0.0024245061478930558, "phrase": "original_feature_vectors"}, {"score": 0.0023961265476627166, "phrase": "candidate_clusters"}, {"score": 0.0023588019302482367, "phrase": "approximate_nearest_neighbors"}, {"score": 0.0022769287097263564, "phrase": "ssci-based_approach"}, {"score": 0.0021049977753042253, "phrase": "sequential_search"}], "paper_keywords": ["high-dimensional index", " cluster", " video semantics", " video database"], "paper_abstract": "High-dimensional index is one of the most challenging tasks for content-based video retrieval (CBVR). Typically, in video database, there exist two kinds of clues for query: visual features and semantic classes. In this paper, we modeled the relationship between semantic classes and visual feature distributions of data set with the Gaussian mixture model (GMM), and proposed a semantics supervised cluster based index approach (briefly as SSCI) to integrate the advantages of both semantic classes and visual features. The entire data set is divided hierarchically by a modified clustering technique into many clusters until the objects within a cluster are not only close in the visual feature space but also within the same semantic class, and then an index entry including semantic clue and visual feature clue is built for each cluster. Especially, the visual feature vectors in a cluster are organized adjacently in disk. So the SSCI-based nearest-neighbor (NN) search can be divided into two phases: the first phase computes the distances between the query example and each cluster index and returns the clusters with the smallest distance, here namely candidate clusters; then the second phase retrieves the original feature vectors within the candidate clusters to gain the approximate nearest neighbors. Our experiments showed that for approximate searching the SSCI-based approach was faster than VA(+)-based approach; moreover, the quality of the result set was better than that of the sequential search in terms of semantics.", "paper_title": "Semantics supervised cluster-based index for video databases", "paper_id": "WOS:000239566500046"}