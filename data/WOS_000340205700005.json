{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "outlier_detection"}, {"score": 0.01649189810612293, "phrase": "imperfect_labels"}, {"score": 0.01554488590686055, "phrase": "likelihood_values"}, {"score": 0.009421785646644015, "phrase": "normal_data"}, {"score": 0.007423421898714075, "phrase": "limited_abnormal_examples"}, {"score": 0.004779085953614184, "phrase": "imperfect_data_labels"}, {"score": 0.004620957579769604, "phrase": "data_objects"}, {"score": 0.004451360793577698, "phrase": "normal_set"}, {"score": 0.004130535674260502, "phrase": "represented_model"}, {"score": 0.003919763262805793, "phrase": "limited_negative_examples"}, {"score": 0.003719705944877787, "phrase": "outlier_detection_data"}, {"score": 0.003543059748318891, "phrase": "traditional_ones"}, {"score": 0.0034643747383816164, "phrase": "novel_outlier_detection_approach"}, {"score": 0.0031666711243198992, "phrase": "input_data"}, {"score": 0.0030275252142439213, "phrase": "normal_and_abnormal_classes"}, {"score": 0.002916238693326477, "phrase": "first_step"}, {"score": 0.00286213454317036, "phrase": "pseudo_training_dataset"}, {"score": 0.002685558057339722, "phrase": "clustering_method"}, {"score": 0.002655544981260646, "phrase": "lof-based_method"}, {"score": 0.0025771355599741915, "phrase": "second_step"}, {"score": 0.00252930673503721, "phrase": "generated_likelihood_values"}, {"score": 0.0024916819803100635, "phrase": "svdd-based_learning_framework"}, {"score": 0.002436289099444074, "phrase": "global_outlier_detection"}, {"score": 0.0024000447011533078, "phrase": "local_and_global_outlier_detection"}, {"score": 0.002251911996999611, "phrase": "extensive_experiments"}, {"score": 0.002235095576913577, "phrase": "real_life_datasets"}, {"score": 0.00216907363015155, "phrase": "better_tradeoff"}, {"score": 0.002152874480615438, "phrase": "detection_rate"}, {"score": 0.0021367960510499575, "phrase": "false_alarm_rate"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_outlier_detection_approaches"}], "paper_keywords": ["Outlier detection", " data of uncertainty"], "paper_abstract": "The task of outlier detection is to identify data objects that are markedly different from or inconsistent with the normal set of data. Most existing solutions typically build a model using the normal data and identify outliers that do not fit the represented model very well. However, in addition to normal data, there also exist limited negative examples or outliers in many applications, and data may be corrupted such that the outlier detection data is imperfectly labeled. These make outlier detection far more difficult than the traditional ones. This paper presents a novel outlier detection approach to address data with imperfect labels and incorporate limited abnormal examples into learning. To deal with data with imperfect labels, we introduce likelihood values for each input data which denote the degree of membership of an example toward the normal and abnormal classes respectively. Our proposed approach works in two steps. In the first step, we generate a pseudo training dataset by computing likelihood values of each example based on its local behavior. We present kernel k-means clustering method and kernel LOF-based method to compute the likelihood values. In the second step, we incorporate the generated likelihood values and limited abnormal examples into SVDD-based learning framework to build a more accurate classifier for global outlier detection. By integrating local and global outlier detection, our proposed method explicitly handles data with imperfect labels and enhances the performance of outlier detection. Extensive experiments on real life datasets have demonstrated that our proposed approaches can achieve a better tradeoff between detection rate and false alarm rate as compared to state-of-the-art outlier detection approaches.", "paper_title": "An Efficient Approach for Outlier Detection with Imperfect Data Labels", "paper_id": "WOS:000340205700005"}