{"auto_keywords": [{"score": 0.045078781446073614, "phrase": "workflow_computation"}, {"score": 0.023227301113361, "phrase": "garbage_data"}, {"score": 0.009585437081404205, "phrase": "hpc_systems"}, {"score": 0.008431205573511546, "phrase": "future_computation"}, {"score": 0.006900963676431608, "phrase": "subsequent_computation"}, {"score": 0.005999500568741231, "phrase": "gdm"}, {"score": 0.004778594263962987, "phrase": "efficient_workflow_computation"}, {"score": 0.004514491994233911, "phrase": "attractive_platforms"}, {"score": 0.004090682761004765, "phrase": "intermediate_result_files"}, {"score": 0.0034096661914349577, "phrase": "multiple_instances"}, {"score": 0.0033455764382772754, "phrase": "common_data_products"}, {"score": 0.0032578629307203097, "phrase": "sharing_scheme"}, {"score": 0.0031845067058084583, "phrase": "historical_data"}, {"score": 0.002896167001212006, "phrase": "novel_approach"}, {"score": 0.002841701708055512, "phrase": "garbage_data_manager"}, {"score": 0.002643888053328987, "phrase": "batch_schedulers"}, {"score": 0.0024227171881502614, "phrase": "dataflow_graph"}, {"score": 0.0023235629819760018, "phrase": "inheritance_relationships"}, {"score": 0.0022972306948217548, "phrase": "different_instances"}, {"score": 0.0021865218861454256, "phrase": "data_reuse"}, {"score": 0.0021049977753042253, "phrase": "effective_way"}], "paper_keywords": ["data management", " concurrency and computation", " workflow scheduling", " garbage collection", " data sharing"], "paper_abstract": "High-performance computing (HPC) systems, including Clusters, Grids and the most recent Clouds, have emerged as attractive platforms to tackle various applications. One significant type of applications in the HPC systems is workflow computation, which has been applied in various scientific and engineering domains. The workflow computation frequently produces intermediate result files, which become garbage after being used and are usually cleaned up without making any contribution to future computation. In this paper, we argue that such garbage data could be useful in the future computation and should not be immediately cleaned up. This is because workflow computation usually contains multiple instances that may share some common data products produced in the past. This sharing scheme provides opportunities to reuse the historical data to speed-up subsequent computation and simplify re-computation due to faulty or crashed runs. To this end, we propose a novel approach, referred to as garbage data manager (GDM), for the workflow computation in HPC systems. The GDM organizes and manages the garbage data for batch schedulers to enhance the performance of subsequent computation. The essence of the GDM is to record the history of computation by constructing a dataflow graph on per instance (run) basis and set up inheritance relationships between the different instances of the same workflow, called run-tree, to achieve the data reuse. Our simulation results demonstrate that exploiting the garbage data is an effective way of improving the workflow computation.", "paper_title": "Reusing Garbage Data for Efficient Workflow Computation", "paper_id": "WOS:000350219300007"}