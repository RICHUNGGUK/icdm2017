{"auto_keywords": [{"score": 0.03951821898402553, "phrase": "cmfs"}, {"score": 0.01510736425708606, "phrase": "text_categorization"}, {"score": 0.010026806888727426, "phrase": "support_vector_machines"}, {"score": 0.00744915613482387, "phrase": "dia"}, {"score": 0.00481495049065317, "phrase": "comprehensive_measurement"}, {"score": 0.0045464538515249085, "phrase": "feature_selection"}, {"score": 0.004342430078306461, "phrase": "vector_space"}, {"score": 0.0038271712887391015, "phrase": "new_feature_selection_algorithm"}, {"score": 0.0032398798149196432, "phrase": "webkb"}, {"score": 0.0031481164109237636, "phrase": "naive_bayes"}, {"score": 0.0031122556978891536, "phrase": "nb"}, {"score": 0.0029552551661591988, "phrase": "experimental_results"}, {"score": 0.0028715299874549245, "phrase": "six_well-known_feature_selection_algorithms"}, {"score": 0.002680114113899346, "phrase": "information_gain"}, {"score": 0.0022296340517805125, "phrase": "nave_bayes_classifier"}, {"score": 0.0021541962163005753, "phrase": "ic"}, {"score": 0.002129405478719888, "phrase": "df"}, {"score": 0.0021049979320515244, "phrase": "ocfs"}], "paper_keywords": ["Feature selection", " Text categorization", " Support Vector Machines", " Naive Bayes"], "paper_abstract": "The feature selection, which can reduce the dimensionality of vector space without sacrificing the performance of the classifier, is widely used in text categorization. In this paper, we proposed a new feature selection algorithm, named CMFS, which comprehensively measures the significance of a term both in inter-category and intra-category. We evaluated CMFS on three benchmark document collections, 20-Newsgroups. Reuters-21578 and WebKB, using two classification algorithms, Naive Bayes (NB) and Support Vector Machines (SVMs). The experimental results, comparing CMFS with six well-known feature selection algorithms, show that the proposed method CMFS is significantly superior to Information Gain (IC), Chi statistic (CHI), Document Frequency (DF), Orthogonal Centroid Feature Selection (OCFS) and DIA association factor (DIA) when Nave Bayes classifier is used and significantly outperforms IC, DF, OCFS and DIA when Support Vector Machines are used. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "A new feature selection based on comprehensive measurement both in inter-category and intra-category for text categorization", "paper_id": "WOS:000305170900009"}