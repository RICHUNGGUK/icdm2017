{"auto_keywords": [{"score": 0.039108224572764534, "phrase": "non-manual_components"}, {"score": 0.03543600733238519, "phrase": "first_stage"}, {"score": 0.03488739830592305, "phrase": "second_stage"}, {"score": 0.00481495049065317, "phrase": "manual_signs"}, {"score": 0.004763565662615503, "phrase": "non-manual_signals"}, {"score": 0.0045879792359519375, "phrase": "sign_language_recognition"}, {"score": 0.00366185681714204, "phrase": "sequential_belief-based_fusion_technique"}, {"score": 0.003470358620464986, "phrase": "primary_importance"}, {"score": 0.0029064676523923886, "phrase": "belief_formalism"}, {"score": 0.0027543636132088332, "phrase": "sign_clusters"}, {"score": 0.0025003054002226965, "phrase": "sign_tutor_application"}, {"score": 0.0023566987138026285, "phrase": "baseline_system"}, {"score": 0.0023189818169615135, "phrase": "parallel_or_feature_fusion"}, {"score": 0.0022941723937662927, "phrase": "manual_and_non-manual_features"}, {"score": 0.0021857667493036786, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Sign language recognition", " Manual signs and non-manual signals", " Hidden Markov models", " Data fusion", " Belief functions"], "paper_abstract": "Most of the research on sign language recognition concentrates on recognizing only manual signs (hand gestures and shapes), discarding a very important component: the non-manual signals (facial expressions and head/shoulder motion). We address the recognition of signs with both manual and non-manual components using a sequential belief-based fusion technique. The manual components, which carry information of primary importance, are utilized in the first stage. The second stage, which makes use of non-manual components, is only employed if there is hesitation in the decision of the first stage. We employ belief formalism both to model the hesitation and to determine the sign clusters within which the discrimination takes place in the second stage. We have implemented this technique in a sign tutor application, Our results on the eNTERFACE'06 ASL database show an improvement over the baseline system which uses parallel or feature fusion of manual and non-manual features: we achieve an accuracy of 81.6%. Crown Copyright (C) 2008 Published by Elsevier Ltd. All rights reserved.", "paper_title": "A belief-based sequential fusion approach for fusing manual signs and non-manual signals", "paper_id": "WOS:000263431200020"}