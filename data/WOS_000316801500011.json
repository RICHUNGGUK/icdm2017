{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "smart_transparency"}, {"score": 0.0047707093928203, "phrase": "illustrative_visualization"}, {"score": 0.0047268728636719725, "phrase": "complex_flow_surfaces"}, {"score": 0.004555499634179394, "phrase": "underlying_neural_mechanisms"}, {"score": 0.004451546786101008, "phrase": "extensive_research"}, {"score": 0.004390312150344245, "phrase": "cognitive_sciences"}, {"score": 0.004211594861013822, "phrase": "visualization_techniques"}, {"score": 0.0041154571996523505, "phrase": "inner_structure"}, {"score": 0.004077616905584829, "phrase": "complex_transparent_shapes"}, {"score": 0.0038756055612167942, "phrase": "perception_research"}, {"score": 0.0037006243674469657, "phrase": "surface_transparency"}, {"score": 0.003616108223034427, "phrase": "transparent_geometry"}, {"score": 0.003468796799802612, "phrase": "visibility_culling"}, {"score": 0.0032514447965530354, "phrase": "correct_blending"}, {"score": 0.0030617935728586006, "phrase": "illustration_buffer"}, {"score": 0.0030196181347744372, "phrase": "novel_data_structure"}, {"score": 0.0028172726995962173, "phrase": "surface_layers"}, {"score": 0.002714943351733626, "phrase": "local_and_nonlocal_operators"}, {"score": 0.0025802660239538353, "phrase": "final_image"}, {"score": 0.0025096359514694523, "phrase": "current_graphics_hardware"}, {"score": 0.002429668083484833, "phrase": "available_graphics_memory"}, {"score": 0.0023198180380964305, "phrase": "efficient_algorithm"}, {"score": 0.0022878396720586044, "phrase": "nonlocal_transparency_enhancement"}, {"score": 0.0022563011263787847, "phrase": "expressive_renderings"}, {"score": 0.0022355167967736326, "phrase": "transparent_surfaces"}, {"score": 0.002204697943520258, "phrase": "controlled_quantitative_double_blind_user_study"}, {"score": 0.0021049977753042253, "phrase": "complex_transparent_surfaces"}], "paper_keywords": ["Illustrative rendering", " transparency", " flow visualization", " integral surface", " user study", " diffusion", " a-buffer", " illustration buffer", " perception"], "paper_abstract": "The perception of transparency and the underlying neural mechanisms have been subject to extensive research in the cognitive sciences. However, we have yet to develop visualization techniques that optimally convey the inner structure of complex transparent shapes. In this paper, we apply the findings of perception research to develop a novel illustrative rendering method that enhances surface transparency nonlocally. Rendering of transparent geometry is computationally expensive since many optimizations, such as visibility culling, are not applicable and fragments have to be sorted by depth for correct blending. In order to overcome these difficulties efficiently, we propose the illustration buffer. This novel data structure combines the ideas of the A and G-buffers to store a list of all surface layers for each pixel. A set of local and nonlocal operators is then used to process these depth-lists to generate the final image. Our technique is interactive on current graphics hardware and is only limited by the available graphics memory. Based on this framework, we present an efficient algorithm for a nonlocal transparency enhancement that creates expressive renderings of transparent surfaces. A controlled quantitative double blind user study shows that the presented approach improves the understanding of complex transparent surfaces significantly.", "paper_title": "Smart Transparency for Illustrative Visualization of Complex Flow Surfaces", "paper_id": "WOS:000316801500011"}