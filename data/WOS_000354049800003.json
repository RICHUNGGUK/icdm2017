{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "rgb-d_cameras"}, {"score": 0.011042993532015726, "phrase": "proposed_method"}, {"score": 0.008018461049439997, "phrase": "intensive_images"}, {"score": 0.00708142691660329, "phrase": "depth_error_elimination_method"}, {"score": 0.004748740786945996, "phrase": "rapid_spreading"}, {"score": 0.004619027561771169, "phrase": "wide_applications"}, {"score": 0.004290112502811656, "phrase": "extensive_research_efforts"}, {"score": 0.004192190072470619, "phrase": "rgb-d_camera-oriented_topics"}, {"score": 0.004077616905584829, "phrase": "quality_promotion"}, {"score": 0.004040123129261597, "phrase": "depth_videos"}, {"score": 0.00398452530840582, "phrase": "temporal_characteristic"}, {"score": 0.003822263046602146, "phrase": "limited_exposure_time"}, {"score": 0.003752275718257509, "phrase": "object_movement"}, {"score": 0.0036665842836420223, "phrase": "motion_blurs"}, {"score": 0.003517223847512266, "phrase": "obvious_artifacts"}, {"score": 0.0033739270918502285, "phrase": "corresponding_depth_frames"}, {"score": 0.0031625006830124512, "phrase": "time_series_analysis"}, {"score": 0.0030759821501544224, "phrase": "depth_images"}, {"score": 0.002909960617042717, "phrase": "erroneous_depths"}, {"score": 0.002843450389745497, "phrase": "motion_blur_detection"}, {"score": 0.0027913353347879507, "phrase": "time_series_analysis_model"}, {"score": 0.0026651772919894534, "phrase": "depth_image"}, {"score": 0.0026163210719740847, "phrase": "intensive_color_images"}, {"score": 0.002418453525649304, "phrase": "fake_boundaries"}, {"score": 0.0021843879253500894, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "error_regions"}], "paper_keywords": ["Algorithms", " Depth error", " depth video", " RGB-D cameras", " time series analysis"], "paper_abstract": "The rapid spreading of RGB-D cameras has led to wide applications of 3D videos in both academia and industry, such as 3D entertainment and 3D visual understanding. Under these circumstances, extensive research efforts have been dedicated to RGB-D camera-oriented topics. In these topics, quality promotion of depth videos with the temporal characteristic is emerging and important. Due to the limited exposure time of RGB-D cameras, object movement can easily lead to motion blurs in intensive images, which can further result in obvious artifacts (holes or fake boundaries) in the corresponding depth frames. With regard to this problem, we propose a depth error elimination method based on time series analysis to remove the artifacts in depth images. In this method, we first locate the regions with erroneous depths in intensive images by using motion blur detection based on a time series analysis model. This is based on the fact that the depth image is calculated by intensive color images that are captured synchronously by RGB-D cameras. Then, the artifacts, such as holes or fake boundaries, are fixed by a depth error elimination method. To evaluate the performance of the proposed method, we conducted experiments on 250 images. Experimental results demonstrate that the proposed method can locate the error regions correctly and eliminate these artifacts effectively. The quality of depth video can be improved significantly by using the proposed method.", "paper_title": "Depth Error Elimination for RGB-D Cameras", "paper_id": "WOS:000354049800003"}