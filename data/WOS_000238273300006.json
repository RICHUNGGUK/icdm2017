{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "guaranteed_descent"}, {"score": 0.00443308765153716, "phrase": "new_nonlinear_conjugate_gradient_scheme"}, {"score": 0.004014452814186653, "phrase": "descent_condition"}, {"score": 0.002931569771634119, "phrase": "line_search"}, {"score": 0.002789528662623221, "phrase": "wolfe_conditions"}, {"score": 0.0025257081555100556, "phrase": "convergence_behavior"}], "paper_keywords": ["algorithms", " conjugate gradient method", " convergence", " line search", " unconstrained optimization", " Wolfe conditions"], "paper_abstract": "Recently, a new nonlinear conjugate gradient scheme was developed which satisfies the descent condition g(k)(inverted perpendicular)dk <= - 7/8 parallel to g(k)parallel to(2) and which is globally convergent whenever the line search fulfills the Wolfe conditions. This article studies the convergence behavior of the algorithm; extensive numerical tests and comparisons with other methods for large-scale unconstrained optimization are given.", "paper_title": "Algorithm 851: CG DESCENT, a conjugate gradient method with guaranteed descent", "paper_id": "WOS:000238273300006"}