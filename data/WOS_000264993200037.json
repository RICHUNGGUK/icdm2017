{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "static_reservoir"}, {"score": 0.004758457292840376, "phrase": "nonlinear_regression_estimation"}, {"score": 0.0047026237903774895, "phrase": "reservoir_method"}, {"score": 0.004565876339189493, "phrase": "feed-forward_learning_machines"}, {"score": 0.004329630571352367, "phrase": "existing_experience"}, {"score": 0.004278807087784626, "phrase": "extreme_learning_machine"}, {"score": 0.004129873531628877, "phrase": "new_method"}, {"score": 0.00405735420159564, "phrase": "basic_idea"}, {"score": 0.0040097139701644165, "phrase": "support_vector_echo-state_machines"}, {"score": 0.0038930368103015467, "phrase": "internal_feedback_matrix"}, {"score": 0.0037797419108291227, "phrase": "feed-forward_usage"}, {"score": 0.003500313767208306, "phrase": "readout_weights"}, {"score": 0.0030017207229983385, "phrase": "proper_reservoir"}, {"score": 0.002914288956035066, "phrase": "gamma-c_plane"}, {"score": 0.002846175473457555, "phrase": "generalization_error_criterion"}, {"score": 0.0027961342030212353, "phrase": "outlier_suppression"}, {"score": 0.0027469703311742647, "phrase": "regularized_robust_regression"}, {"score": 0.00266693888510356, "phrase": "reservoir_feature_space"}, {"score": 0.0025587867729949037, "phrase": "efficient_algorithm"}, {"score": 0.0025286975935774245, "phrase": "large-scale_problems"}, {"score": 0.002426137929553724, "phrase": "cholesky_decomposition"}, {"score": 0.0023834640793589435, "phrase": "proposed_method"}, {"score": 0.0023139986108451967, "phrase": "classical_kernel_method"}, {"score": 0.002286781334850213, "phrase": "elm_method"}, {"score": 0.0021049977753042253, "phrase": "existing_methods"}], "paper_keywords": ["Reservoir method", " Extreme learning machine", " Feed-forward neural networks", " Support vector machines", " Kernel method"], "paper_abstract": "Reservoir method is applied to the feed-forward learning machines for nonlinear regression estimation. Inspired by the existing experience from extreme learning machine (ELM), the new method inherits the basic idea from support vector echo-state machines, but eliminates the internal feedback matrix to adapt for the feed-forward usage. Based on the analysis of nonlinearity in reservoir and regularization in readout weights, the parameters of input scaling and penalty regularization are taken as the hyper-parameters to characterize a static reservoir (ELM), and then a proper reservoir is identified on the gamma-C plane based on a generalization error criterion. For outlier suppression, the regularized robust regression is applied in the reservoir feature space, and it leads to an efficient algorithm for large-scale problems, which can be solved by Cholesky decomposition. The proposed method is compared with the classical kernel method and ELM method on several benchmark nonlinear regression datasets, and the results indicate the method is comparable with the existing methods. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "gamma-C plane and robustness in static reservoir for nonlinear regression estimation", "paper_id": "WOS:000264993200037"}