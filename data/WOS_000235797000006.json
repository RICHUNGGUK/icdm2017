{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "vector_quantization"}, {"score": 0.0038431888954930083, "phrase": "model_situation"}, {"score": 0.003334309053314909, "phrase": "gaussialls"}, {"score": 0.003197843245296877, "phrase": "on-line_learning"}, {"score": 0.003092690568543981, "phrase": "exact_mathernatical_description"}, {"score": 0.0030160945545795468, "phrase": "training_dynamics"}, {"score": 0.0028926147550022607, "phrase": "underlying_cost_function"}, {"score": 0.002682917193736698, "phrase": "typical_behavior"}, {"score": 0.002594652434287807, "phrase": "basic_lvq"}, {"score": 0.002551612225562499, "phrase": "unsupervised_vector_quantization"}, {"score": 0.0024065032567542107, "phrase": "learning_curves"}, {"score": 0.0023665766694993535, "phrase": "i.e._the_achievable_generalization_ability"}, {"score": 0.0022133711375320244, "phrase": "training_examples"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["learning vector quantization", " prototype-based classification", " winner-takes-all algorithms", " on-line learning", " competitive learning"], "paper_abstract": "Winner-Takes-All (WTA) prescriptions for learning vector quantization (LVQ) are studied in the framework of a model situation: two competing prototype vectors are updated according to a sequence of example data drawn from a mixture of Gaussialls. The theory of on-line learning allows for an exact mathernatical description of the training dynamics, even if an underlying cost function cannot be identified. We compare the typical behavior of several WTA schemes including basic LVQ and unsupervised vector quantization. The focus is on the learning curves, i.e. the achievable generalization ability as a function of the number of training examples. (c) 2005 Elsevier B.V. All rights reserved.", "paper_title": "Learning vector quantization: The dynamics of winner-takes-all algorithms", "paper_id": "WOS:000235797000006"}