{"auto_keywords": [{"score": 0.00305285084207725, "phrase": "virtual_ensemble"}, {"score": 0.0029020077365708966, "phrase": "midi_piece"}, {"score": 0.0024926348205500715, "phrase": "mobile_phone"}, {"score": 0.0023694065215394593, "phrase": "user's_hand_movement"}, {"score": 0.0022145052062614514, "phrase": "music_performance_style"}], "paper_keywords": ["Human-computer interaction", " Active music listening", " Movement expressivity"], "paper_abstract": "In this paper we describe the SAME networked platform for context-aware, experience-centric mobile music applications, and we present an implementation of the SAME active music listening paradigm: the Mobile Conductor. It allows the user to express herself in conducting a virtual ensemble playing a MIDI piece of music by means of her mobile phone. The mobile phone detects the user's hand movement and molds the music performance style by modulating its speed, volume, and intonation.", "paper_title": "Human movement expressivity for mobile active music listening", "paper_id": "WOS:000208506600004"}