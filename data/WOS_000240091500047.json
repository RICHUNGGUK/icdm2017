{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "kernel-based_one-class_classifier"}, {"score": 0.004586531354697466, "phrase": "one-class_classification"}, {"score": 0.004399349717218995, "phrase": "imbalance_data"}, {"score": 0.004104132253183181, "phrase": "better_performance"}, {"score": 0.004047500054405469, "phrase": "conventional_learning_schemes"}, {"score": 0.003991646181215783, "phrase": "parameter_optimization"}, {"score": 0.003909301559145041, "phrase": "significant_issue"}, {"score": 0.0038286491141253584, "phrase": "one-class_classifier"}, {"score": 0.003621588555525458, "phrase": "one-class_learning_scheme"}, {"score": 0.0034736499231079083, "phrase": "one-class_svm"}, {"score": 0.0031734538599865973, "phrase": "rejection_rate"}, {"score": 0.003107935254560724, "phrase": "one-class_specific_parameter"}, {"score": 0.0029193609786176632, "phrase": "improved_framework"}, {"score": 0.0028392545452904762, "phrase": "minority_target_class"}, {"score": 0.002685558057339722, "phrase": "classification_stage"}, {"score": 0.002575756583567029, "phrase": "majority_class"}, {"score": 0.0024704333220467393, "phrase": "generalization_performance"}, {"score": 0.002336655334451466, "phrase": "optimization_criteria"}, {"score": 0.002272501735900584, "phrase": "uci_and_reuters_text_data"}, {"score": 0.002149418970824546, "phrase": "one-class_classifiers"}], "paper_keywords": [""], "paper_abstract": "Applying one-class classification to the minorities in an imbalance data has been shown to have the potential to achieve better performance than conventional learning schemes. Parameter optimization is a significant issue when the one-class classifier is sensitive to the parameters. For one-class learning scheme with the kernel function as one-class SVM and SVDD, besides the parameters involved in the kernel, the rejection rate is another one-class specific parameter. In this paper, we proposed an improved framework in which the minority target class is used first for learning in the classification stage; then both minority and majority class are employed for estimating the generalization performance. This performance is set as the optimization criteria. Experiments on UCI and Reuters text data show that both of the parameter optimized one-class classifiers outperform the other standard one-class learning schemes.", "paper_title": "Parameter optimization of kernel-based one-class classifier on imbalance text learning", "paper_id": "WOS:000240091500047"}