{"auto_keywords": [{"score": 0.03822494903136867, "phrase": "ci"}, {"score": 0.00481495049065317, "phrase": "reduced-reference_assessment"}, {"score": 0.004773476989344654, "phrase": "perceived_image_quality"}, {"score": 0.00469159356595623, "phrase": "satisfactory_visual_experience"}, {"score": 0.004591202593942391, "phrase": "main_goals"}, {"score": 0.004551647527068771, "phrase": "present-day_electronic_multimedia_devices"}, {"score": 0.004138309011478741, "phrase": "video_signal"}, {"score": 0.00403221710768334, "phrase": "quality_control_mechanisms"}, {"score": 0.0038115535592184438, "phrase": "visual_quality"}, {"score": 0.0037623642073222547, "phrase": "incoming_signal"}, {"score": 0.0037138072936226, "phrase": "human_perception"}, {"score": 0.0035564156572789473, "phrase": "suitable_technology"}, {"score": 0.0034953361767153285, "phrase": "challenging_problem"}, {"score": 0.003450213580299164, "phrase": "present_research"}, {"score": 0.003405671497507337, "phrase": "augmented_version"}, {"score": 0.003361702510958392, "phrase": "basic_extreme_learning_machine"}, {"score": 0.0030693625816617044, "phrase": "visual_quality_assessment_problem"}, {"score": 0.003029722317983915, "phrase": "c-elm_model"}, {"score": 0.002863762666256937, "phrase": "conventional_multilayer_perceptron"}, {"score": 0.0025474814283429213, "phrase": "circular_input"}, {"score": 0.0024820711838337713, "phrase": "fruitful_properties"}, {"score": 0.0024393978073660757, "phrase": "basic_elm_framework"}, {"score": 0.0023974563359295043, "phrase": "proposed_framework"}, {"score": 0.0023767561522363367, "phrase": "c-elm"}, {"score": 0.0023460397258997525, "phrase": "actual_mapping"}, {"score": 0.0023257824499250653, "phrase": "visual_signals"}, {"score": 0.0023056996845692355, "phrase": "quality_scores"}, {"score": 0.002266051712795851, "phrase": "perceptual_mechanisms"}, {"score": 0.002207851585508636, "phrase": "recognized_benchmarks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Extreme learning machine", " Circular backpropagation", " Image quality assessment"], "paper_abstract": "Providing a satisfactory visual experience is one of the main goals for present-day electronic multimedia devices. All the enabling technologies for storage, transmission, compression, rendering should preserve, and possibly enhance, the quality of the video signal; to do so, quality control mechanisms are required. These mechanisms rely on systems that can assess the visual quality of the incoming signal consistently with human perception. Computational Intelligence (CI) paradigms represent a suitable technology to tackle this challenging problem. The present research introduces an augmented version of the basic Extreme Learning Machine (ELM), the Circular-ELM (C-ELM), which proves effective in addressing the visual quality assessment problem. The C-ELM model derives from the original Circular BackPropagation (CBP) architecture, in which the input vector of a conventional MultiLayer Perceptron (MLP) is augmented by one additional dimension, the circular input; this paper shows that C-ELM can actually benefit from the enhancement provided by the circular input without losing any of the fruitful properties that characterize the basic ELM framework. In the proposed framework, C-ELM handles the actual mapping of visual signals into quality scores, successfully reproducing perceptual mechanisms. Its effectiveness is proved on recognized benchmarks and for four different types of distortions. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Circular-ELM for the reduced-reference assessment of perceived image quality", "paper_id": "WOS:000313761500010"}