{"auto_keywords": [{"score": 0.049678920037479736, "phrase": "multi-voxel_pattern_analysis"}, {"score": 0.04736826786779843, "phrase": "mvpa"}, {"score": 0.041862767596091754, "phrase": "stimulus_conditions"}, {"score": 0.03303406036216322, "phrase": "mi"}, {"score": 0.00481495049065317, "phrase": "voxel_selection_framework"}, {"score": 0.004735651915966323, "phrase": "fmri_data"}, {"score": 0.004657653216262924, "phrase": "neural_response"}, {"score": 0.004619134710069517, "phrase": "visual_stimuli"}, {"score": 0.004486800020569973, "phrase": "functional_magnetic_resonance_imaging"}, {"score": 0.004358240019060018, "phrase": "emerging_approach"}, {"score": 0.0042864307215634756, "phrase": "neural_correlates"}, {"score": 0.004180919839686364, "phrase": "cognitive_states"}, {"score": 0.004077995480957875, "phrase": "neural_activity"}, {"score": 0.0035554096354423756, "phrase": "model_overfitting"}, {"score": 0.003368367923339975, "phrase": "classification_model"}, {"score": 0.0032446544415922615, "phrase": "robust_feature"}, {"score": 0.003151572886432253, "phrase": "mutual_information"}, {"score": 0.002960979624379786, "phrase": "informativeness_index"}, {"score": 0.0027934768366077397, "phrase": "experimental_conditions"}, {"score": 0.002657445352746803, "phrase": "standard_classification_algorithms"}, {"score": 0.002559775585192185, "phrase": "publicly-available_fmri_dataset"}, {"score": 0.0025385621498128243, "phrase": "object-level_representation"}, {"score": 0.002486292595645607, "phrase": "mvpa_performance"}, {"score": 0.0024656866249273125, "phrase": "haxby"}, {"score": 0.002404885278896803, "phrase": "computational_results"}, {"score": 0.0023261531529739916, "phrase": "pls"}, {"score": 0.0022877332844249065, "phrase": "classification_accuracy"}, {"score": 0.002158233639156017, "phrase": "highly_informative_voxels"}, {"score": 0.0021314498639048085, "phrase": "meaningful_insight"}, {"score": 0.0021049977753042253, "phrase": "functional-anatomic_relationship"}], "paper_keywords": ["Classification", " feature selection", " functional magnetic resonance imaging (fMRI)", " information theory", " multi-voxel pattern analysis (MVPA)", " partial least square (PLS)", " pattern recognition"], "paper_abstract": "Multi-voxel pattern analysis (MVPA) of functional magnetic resonance imaging (fMRI) data is an emerging approach for probing the neural correlates of cognition. MVPA allows cognitive states to be modeled as distributed patterns of neural activity and classified according to stimulus conditions. In practice, building a robust, generalizable classification model can be challenging because the number of voxels (features) far exceeds the number of stimulus instances/data observations. To avoid model overfitting, there is a need to select informative voxels before building a classification model. In this paper, we propose a robust feature (voxel) selection framework using mutual information (MI) and partial least square regression (PLS) to establish an informativeness index for prioritizing selection of voxels based on the degree of their association to the experimental conditions. We evaluated the robustness of our proposed framework by assessing performance of standard classification algorithms, when combined with our feature selection approach, in a publicly-available fMRI dataset of object-level representation widely used to benchmark MVPA performance (Haxby, 2001). The computational results suggest that our feature selection framework based on MI and PLS drastically improves the classification accuracy relative to those previously reported in the literature. Our results also suggest that highly informative voxels may provide meaningful insight into the functional-anatomic relationship of brain activity and stimulus conditions.", "paper_title": "Voxel Selection Framework in Multi-Voxel Pattern Analysis of fMRI Data for Prediction of Neural Response to Visual Stimuli", "paper_id": "WOS:000334667000012"}