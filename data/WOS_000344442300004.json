{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "k-plane"}, {"score": 0.004401342842183475, "phrase": "novel_algorithm"}, {"score": 0.004322967486451877, "phrase": "piecewise_linear_regression"}, {"score": 0.0041703614123283165, "phrase": "continuous_as_well_as_discontinuous_piecewise_linear_functions"}, {"score": 0.003677280504320636, "phrase": "linear_model"}, {"score": 0.0034841647157189985, "phrase": "proposed_algorithm"}, {"score": 0.0028586409810976367, "phrase": "special_case"}, {"score": 0.0027825094419000637, "phrase": "em_algorithm"}, {"score": 0.0027328817607818207, "phrase": "maximum_likelihood_estimation"}, {"score": 0.0026600905156986317, "phrase": "reasonable_probability_model"}, {"score": 0.002262209824105154, "phrase": "art_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Piecewise linear regression", " Cluster-wise linear regression", " Expectation maximization", " Mixture of experts"], "paper_abstract": "In this paper, we present a novel algorithm for piecewise linear regression which can learn continuous as well as discontinuous piecewise linear functions. The main idea is to repeatedly partition the data and learn a linear model in each partition. The proposed algorithm is similar in spirit to k-means clustering algorithm. We show that our algorithm can also be viewed as a special case of an EM algorithm for maximum likelihood estimation under a reasonable probability model. We empirically demonstrate the effectiveness of our approach by comparing its performance with that of the state of art algorithms on various datasets. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "K-plane regression", "paper_id": "WOS:000344442300004"}