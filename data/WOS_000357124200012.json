{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "runtime_specialization"}, {"score": 0.0070843217297636004, "phrase": "intel's_mkl_library"}, {"score": 0.004768104290288521, "phrase": "sparse_matrix-vector_multiplication"}, {"score": 0.004607686390487483, "phrase": "partial_information"}, {"score": 0.004518442937844318, "phrase": "run_time"}, {"score": 0.004366387782457736, "phrase": "input_data"}, {"score": 0.004057495982111461, "phrase": "highly_efficient_codes"}, {"score": 0.0037888687452790953, "phrase": "sparse_matrix-dense_vector_multiplication"}, {"score": 0.0036079110889031874, "phrase": "single_matrix"}, {"score": 0.0034187896011435245, "phrase": "five_methods"}, {"score": 0.0028244513779243107, "phrase": "code_generation"}, {"score": 0.002715912517764276, "phrase": "florida"}, {"score": 0.0026372419109713923, "phrase": "five_different_machines"}, {"score": 0.002523481637809674, "phrase": "specialized_code"}, {"score": 0.002333193766510394, "phrase": "average_speedup"}, {"score": 0.0021049977753042253, "phrase": "best_method"}], "paper_keywords": ["program specialization", " sparse matrix-vector multiplication", " performance evaluation"], "paper_abstract": "Runtime specialization optimizes programs based on partial information available only at run time. It is applicable when some input data is used repeatedly while other input data varies. This technique has the potential of generating highly efficient codes. In this paper, we explore the potential for obtaining speedups for sparse matrix-dense vector multiplication using runtime specialization, in the case where a single matrix is to be multiplied by many vectors. We experiment with five methods involving runtime specialization, comparing them to methods that do not (including Intel's MKL library). For this work, our focus is the evaluation of the speedups that can be obtained with runtime specialization without considering the overheads of the code generation. Our experiments use 23 matrices from the Matrix Market and Florida collections, and run on five different machines. In 94 of those 115 cases, the specialized code runs faster than any version without specialization. If we only use specialization, the average speedup with respect to Intel's MKL library ranges from 1.44x to 1.77x, depending on the machine. We have also found that the best method depends on the matrix and machine; no method is best for all matrices and machines.", "paper_title": "Optimization by Runtime Specialization for Sparse Matrix-Vector Multiplication", "paper_id": "WOS:000357124200012"}