{"auto_keywords": [{"score": 0.045100492615217626, "phrase": "similarity_function"}, {"score": 0.03843856552198327, "phrase": "score_values"}, {"score": 0.00481495049065317, "phrase": "meaningful_and_comparable_scores"}, {"score": 0.00443141503046841, "phrase": "data_values"}, {"score": 0.004251210982670317, "phrase": "similarity_score"}, {"score": 0.00409372989087314, "phrase": "data_instances"}, {"score": 0.003614124997453808, "phrase": "different_functions"}, {"score": 0.00340217066797559, "phrase": "different_similarity_functions"}, {"score": 0.0030033417337933625, "phrase": "matching_process"}, {"score": 0.0029249294679606656, "phrase": "raw_scores"}, {"score": 0.002861724241267107, "phrase": "precision"}, {"score": 0.0028271058251633815, "phrase": "widely_known_similarity"}, {"score": 0.0027741761880779535, "phrase": "clear_interpretation"}, {"score": 0.0027428939498108746, "phrase": "user's_point"}, {"score": 0.0026411384812121503, "phrase": "precision_values"}, {"score": 0.002458061764297103, "phrase": "small_dataset"}, {"score": 0.002366847878952636, "phrase": "different_datasets"}, {"score": 0.002287646331988365, "phrase": "existing_methods"}, {"score": 0.002169667676959813, "phrase": "adjusted_scores"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Similarity querying", " Data integration", " Data cleaning", " Entity resolution", " Deduplication"], "paper_abstract": "Approximate data matching aims at assessing whether two distinct instances of data represent the same real-world object. The comparison between data values is usually done by applying a similarity function which returns a similarity score. if this score surpasses a given threshold, both data instances are considered as representing the same real-world object. These score values depend on the algorithm that implements the function and have no meaning to the user. In addition, score values generated by different functions are not comparable. This will potentially lead to problems when the scores returned by different similarity functions need to be combined for computing the similarity between records. In this article, we propose that thresholds should be defined in terms of the precision that is expected from the matching process rather than in terms of the raw scores returned by the similarity function. Precision is a widely known similarity metric and has a clear interpretation from the user's point of view. Our approach defines mappings from score values to precision values, which we call adjusted scores. In order to obtain such mappings, our approach requires training over a small dataset. Experiments show that training can be reused for different datasets on the same domain. Our results also demonstrate that existing methods for combining scores for computing the similarity between records may be enhanced if adjusted scores are used. (c) 2009 Elsevier B.V. All rights reserved.", "paper_title": "A strategy for allowing meaningful and comparable scores in approximate matching", "paper_id": "WOS:000270621000002"}