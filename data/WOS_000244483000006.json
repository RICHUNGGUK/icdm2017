{"auto_keywords": [{"score": 0.033904538240131045, "phrase": "frequent_itemsets"}, {"score": 0.012556585001358377, "phrase": "deduction_rules"}, {"score": 0.00481495049065317, "phrase": "frequent_itemset_mining_algorithms"}, {"score": 0.0046238380150870435, "phrase": "monotonicity_principle"}, {"score": 0.004298666679374568, "phrase": "candidate_itemsets"}, {"score": 0.004195418010131832, "phrase": "expensive_counting_phase"}, {"score": 0.003289534854212415, "phrase": "condensed_representation"}, {"score": 0.0027517527755155876, "phrase": "ndi"}, {"score": 0.0025167026017217926, "phrase": "recent_other_proposals"}, {"score": 0.0024761702541879213, "phrase": "condensed_representations"}, {"score": 0.00235843888868088, "phrase": "real-life_datasets"}, {"score": 0.002246292543825748, "phrase": "ndi_representation"}, {"score": 0.0021394674440767124, "phrase": "frequent_non-derivable_itemsets"}, {"score": 0.0021049977753042253, "phrase": "useful_and_tractable_alternative"}], "paper_keywords": ["data mining", " itemsets", " condensed representation"], "paper_abstract": "All frequent itemset mining algorithms rely heavily on the monotonicity principle for pruning. This principle allows for excluding candidate itemsets from the expensive counting phase. In this paper, we present sound and complete deduction rules to derive bounds on the support of an itemset. Based on these deduction rules, we construct a condensed representation of all frequent itemsets, by removing those itemsets for which the support can be derived, resulting in the so called Non-Derivable Itemsets (NDI) representation. We also present connections between our proposal and recent other proposals for condensed representations of frequent itemsets. Experiments on real-life datasets show the effectiveness of the NDI representation, making the search for frequent non-derivable itemsets a useful and tractable alternative to mining all frequent itemsets.", "paper_title": "Non-derivable itemset mining", "paper_id": "WOS:000244483000006"}