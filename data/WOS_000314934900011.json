{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "feature_selection"}, {"score": 0.010126404457864443, "phrase": "proposed_framework"}, {"score": 0.004624751696958501, "phrase": "different_criteria"}, {"score": 0.00418134346679498, "phrase": "existing_selection_criteria"}, {"score": 0.004056769841308405, "phrase": "sample_similarity"}, {"score": 0.0038964032225585117, "phrase": "common_framework"}, {"score": 0.0037423521744765075, "phrase": "feature_selection_criteria"}, {"score": 0.003594369823549604, "phrase": "redundant_features"}, {"score": 0.0032989853590079153, "phrase": "new_\"similarity_preserving_feature_selection\"_framework"}, {"score": 0.0032494292163722065, "phrase": "explicit_and_rigorous_way"}, {"score": 0.003152531962718477, "phrase": "theoretical_analysis"}, {"score": 0.0028933521924166287, "phrase": "feature_redundancy"}, {"score": 0.002821247621250663, "phrase": "new_framework"}, {"score": 0.0027370835853738626, "phrase": "conventional_combinatorial_optimization_formulation"}, {"score": 0.0025892330566358503, "phrase": "sparse_multiple-output_regression_formulation"}, {"score": 0.0023642842046859274, "phrase": "proposed_formulations"}, {"score": 0.0022478501955483007, "phrase": "computational_complexity"}, {"score": 0.0021049977753042253, "phrase": "superior_feature_selection_performance"}], "paper_keywords": ["Feature selection", " similarity preserving", " redundancy removal", " multiple output regression", " sparse regularization"], "paper_abstract": "In the literature of feature selection, different criteria have been proposed to evaluate the goodness of features. In our investigation, we notice that a number of existing selection criteria implicitly select features that preserve sample similarity, and can be unified under a common framework. We further point out that any feature selection criteria covered by this framework cannot handle redundant features, a common drawback of these criteria. Motivated by these observations, we propose a new \"Similarity Preserving Feature Selection\" framework in an explicit and rigorous way. We show, through theoretical analysis, that the proposed framework not only encompasses many widely used feature selection criteria, but also naturally overcomes their common weakness in handling feature redundancy. In developing this new framework, we begin with a conventional combinatorial optimization formulation for similarity preserving feature selection, then extend it with a sparse multiple-output regression formulation to improve its efficiency and effectiveness. A set of three algorithms are devised to efficiently solve the proposed formulations, each of which has its own advantages in terms of computational complexity and selection performance. As exhibited by our extensive experimental study, the proposed framework achieves superior feature selection performance and attractive properties.", "paper_title": "On Similarity Preserving Feature Selection", "paper_id": "WOS:000314934900011"}