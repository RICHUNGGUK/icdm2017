{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "information_release"}, {"score": 0.0045607070754363245, "phrase": "personal_information"}, {"score": 0.004429388453288922, "phrase": "confidential_or_sensitive_fields"}, {"score": 0.004283913685201902, "phrase": "sensitive_field"}, {"score": 0.004230595706156783, "phrase": "selected_population"}, {"score": 0.004074574278425223, "phrase": "data_center"}, {"score": 0.00389164348807591, "phrase": "confidential_information"}, {"score": 0.003763763153640936, "phrase": "identification_information"}, {"score": 0.003670608022642996, "phrase": "decision_theory"}, {"score": 0.003579750245670577, "phrase": "privacy_protection"}, {"score": 0.0031579997262619758, "phrase": "privacy_leakage"}, {"score": 0.0030414140732789186, "phrase": "information_state"}, {"score": 0.002978508766388785, "phrase": "probability_distributions"}, {"score": 0.0029169007179202164, "phrase": "possible_confidential_values"}, {"score": 0.0027857990883821504, "phrase": "user's_knowledge_acquisition_behavior"}, {"score": 0.0027395968397212053, "phrase": "first_model"}, {"score": 0.002627407106087633, "phrase": "expected_gain"}, {"score": 0.0024065032567542107, "phrase": "potential_gain"}, {"score": 0.0023665766694993535, "phrase": "second_model"}, {"score": 0.0022413233627905696, "phrase": "private_information"}, {"score": 0.002158505888557746, "phrase": "possible_gain"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["data table", " decision logic", " information value", " privacy", " quantitative models"], "paper_abstract": "We assume that a database of personal information comprises records of individuals that contain confidential or sensitive fields. Queries about the distribution of a sensitive field within a selected population in the database can be submitted to the data center. However, the answers to the queries may leak confidential information about some individuals, even though no identification information is provided. Inspired by decision theory, we present two quantitative models for privacy protection in such a database query or linkage environment. One models the value of information from the viewpoint of the querier, while the other models the damage caused by and compensation for privacy leakage. In both models, we define the information state by a class of probability distributions on a set of possible confidential values. These states can be modified and refined by the user's knowledge acquisition behavior. In the first model, the value of information is defined as the expected gain of the querier, and privacy is protected by imposing costs on the answers to the queries to balance any potential gain. In the second model, the safety of information is guaranteed by ensuring that anyone misusing private information must pay more compensation than the value of the possible gain. (C) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Value versus damage of information release: A data privacy perspective", "paper_id": "WOS:000241500900004"}