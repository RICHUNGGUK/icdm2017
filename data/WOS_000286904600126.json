{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "best_suited_semantic_events"}, {"score": 0.004525088883501587, "phrase": "cognitive_surveillance"}, {"score": 0.004439445472040688, "phrase": "complex_events"}, {"score": 0.004397230847865867, "phrase": "selected_domains"}, {"score": 0.004132411680987228, "phrase": "massive_video_footage"}, {"score": 0.0034625012596827334, "phrase": "pixel_level"}, {"score": 0.003413183361838603, "phrase": "natural_language_requests"}, {"score": 0.003332537728389913, "phrase": "ontology-based_methodology"}, {"score": 0.0030285084113651035, "phrase": "specific_domain"}, {"score": 0.002873247913129334, "phrase": "textual_evidence"}, {"score": 0.002845883666777154, "phrase": "surveilled_video_sequences"}, {"score": 0.002661474607275484, "phrase": "knowledge_bases"}, {"score": 0.00263612191603326, "phrase": "event_description"}, {"score": 0.002549269480908849, "phrase": "obtained_models"}, {"score": 0.002488985155689794, "phrase": "event_detection"}, {"score": 0.0024652715040303416, "phrase": "different_image_sequences"}, {"score": 0.0024301229420875155, "phrase": "surveillance_domain"}, {"score": 0.002372649454733249, "phrase": "user-oriented_knowledge"}, {"score": 0.002327648608736437, "phrase": "existing_advanced_interfaces"}, {"score": 0.002305468528385778, "phrase": "video_indexing"}, {"score": 0.0022294857939412073, "phrase": "best_suited_events"}, {"score": 0.00220823903315848, "phrase": "video_understanding"}, {"score": 0.0021049977753042253, "phrase": "outdoor_and_indoor_scenes"}], "paper_keywords": ["Cognitive surveillance", " Event modeling", " Content-based video retrieval", " Ontologies", " Advanced user interfaces"], "paper_abstract": "State-of-the-art systems on cognitive surveillance identify and describe complex events in selected domains, thus providing end-users with tools to easily access the contents of massive video footage. Nevertheless, as the complexity of events increases in semantics and the types of indoor/outdoor scenarios diversify, it becomes difficult to assess which events describe better the scene, and how to model them at a pixel level to fulfill natural language requests. We present an ontology-based methodology that guides the identification, step-by-step modeling, and generalization of the most relevant events to a specific domain. Our approach considers three steps: (1) end-users provide textual evidence from surveilled video sequences; (2) transcriptions are analyzed top-down to build the knowledge bases for event description; and (3) the obtained models are used to generalize event detection to different image sequences from the surveillance domain. This framework produces user-oriented knowledge that improves on existing advanced interfaces for video indexing and retrieval, by determining the best suited events for video understanding according to end-users. We have conducted experiments with outdoor and indoor scenes showing thefts, chases, and vandalism, demonstrating the feasibility and generalization of this proposal. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Determining the best suited semantic events for cognitive surveillance", "paper_id": "WOS:000286904600126"}