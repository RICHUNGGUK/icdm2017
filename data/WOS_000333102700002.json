{"auto_keywords": [{"score": 0.02974455954978852, "phrase": "discriminative_information"}, {"score": 0.00481495049065317, "phrase": "discriminative_sparse_similarity_map"}, {"score": 0.004635701867952543, "phrase": "tracking_problem"}, {"score": 0.004444317282171449, "phrase": "evaluation_model"}, {"score": 0.003818210967854446, "phrase": "innovative_optimization_formulation"}, {"score": 0.0037861265016041813, "phrase": "multitask_reverse_sparse_representation_formulation"}, {"score": 0.003722761107761564, "phrase": "multiple_subsets"}, {"score": 0.0036759314172445934, "phrase": "whole_candidate"}, {"score": 0.003599182629885611, "phrase": "multiple_templates"}, {"score": 0.003568932067237836, "phrase": "minimum_error"}, {"score": 0.0035240305920962766, "phrase": "customized_apg_method"}, {"score": 0.0034359094594153304, "phrase": "optimum_solution"}, {"score": 0.0033926758710459866, "phrase": "matrix_form"}, {"score": 0.00284137141260141, "phrase": "cost-performance_ratio"}, {"score": 0.0027123819773059127, "phrase": "large_template"}, {"score": 0.0026782279715171866, "phrase": "multiple_positive_target_templates"}, {"score": 0.002633355582628613, "phrase": "negative_templates"}, {"score": 0.002600194073758015, "phrase": "laplacian_term"}, {"score": 0.002535115422089855, "phrase": "coefficients_similarity_level"}, {"score": 0.002482126086922683, "phrase": "candidates_similarities"}, {"score": 0.002389514188569084, "phrase": "pooling_approach"}, {"score": 0.0023003498123420237, "phrase": "dss_map"}, {"score": 0.002242758902593467, "phrase": "good_candidates"}, {"score": 0.0022238834225283594, "phrase": "bad_ones"}, {"score": 0.0021773853011112882, "phrase": "optimum_tracking_results"}, {"score": 0.0021590588269751816, "phrase": "plenty_experimental_evaluations"}, {"score": 0.0021408862709571615, "phrase": "challenging_image_sequences"}, {"score": 0.0021049977753042253, "phrase": "proposed_tracking_algorithm"}], "paper_keywords": ["Object tracking", " sparse representation", " appearance model"], "paper_abstract": "In this paper, we cast the tracking problem as finding the candidate that scores highest in the evaluation model based upon a matrix called discriminative sparse similarity map (DSS map). This map demonstrates the relationship between all the candidates and the templates, and it is constructed based on the solution to an innovative optimization formulation named multitask reverse sparse representation formulation, which searches multiple subsets from the whole candidate set to simultaneously reconstruct multiple templates with minimum error. A customized APG method is derived for getting the optimum solution (in matrix form) within several iterations. This formulation allows the candidates to be evaluated accurately in parallel rather than one-by-one like most sparsity-based trackers do and meanwhile considers the relationship between candidates, therefore it is more superior in terms of cost-performance ratio. The discriminative information containing in this map comes from a large template set with multiple positive target templates and hundreds of negative templates. A Laplacian term is introduced to keep the coefficients similarity level in accordance with the candidates similarities, thereby making our tracker more robust. A pooling approach is proposed to extract the discriminative information in the DSS map for easily yet effectively selecting good candidates from bad ones and finally get the optimum tracking results. Plenty experimental evaluations on challenging image sequences demonstrate that the proposed tracking algorithm performs favorably against the state-of-the-art methods.", "paper_title": "Visual Tracking via Discriminative Sparse Similarity Map", "paper_id": "WOS:000333102700002"}