{"auto_keywords": [{"score": 0.04429026938105162, "phrase": "individual_predictors"}, {"score": 0.0322430302584721, "phrase": "pareto_front"}, {"score": 0.030980468250983276, "phrase": "training_error"}, {"score": 0.00481495049065317, "phrase": "recurrent_neural_network_ensembles"}, {"score": 0.004527371799277529, "phrase": "better_generalization_performance"}, {"score": 0.004481132747216135, "phrase": "single_models"}, {"score": 0.003982011128052839, "phrase": "individual_model"}, {"score": 0.00368673793612343, "phrase": "hybrid_multiobjective_evolutionary_algorithm"}, {"score": 0.0035382855372646164, "phrase": "recurrent_neural_networks"}, {"score": 0.00332670230152448, "phrase": "individual_prediction_models"}, {"score": 0.003275807170434343, "phrase": "pareto_set"}, {"score": 0.003192700856094016, "phrase": "first_method"}, {"score": 0.0030017207229983385, "phrase": "second_one"}, {"score": 0.002851301751761804, "phrase": "knee_point"}, {"score": 0.0027223626424366207, "phrase": "final_method"}, {"score": 0.0025202612763551425, "phrase": "mackey-glass"}, {"score": 0.002494598764985903, "phrase": "sunspot"}, {"score": 0.0024311346712789553, "phrase": "training_algorithm"}, {"score": 0.0023331227492950422, "phrase": "final_two_selection_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Hybrid multi-objective evolutionary algorithms", " Time series prediction", " Ensembles", " Selection", " Recurrent neural networks"], "paper_abstract": "Ensembles have been shown to provide better generalization performance than single models. However, the creation, selection and combination of individual predictors is critical to the success of an ensemble, as each individual model needs to be both accurate and diverse. In this paper we present a hybrid multiobjective evolutionary algorithm that trains and optimizes the structure of recurrent neural networks for time series prediction. We then present methods of selecting individual prediction models from the Pareto set of solutions. The first method selects all individuals below a threshold in the Pareto front and the second one is based on the training error. Individuals near the knee point of the Pareto front are also selected and the final method selects individuals based on the diversity of the individual predictors. Results on two time series data sets, Mackey-Glass and Sunspot, show that the training algorithm is competitive with other algorithms and that the final two selection methods are better than selecting all individuals below a given threshold or based on the training error. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Evolutionary multi-objective generation of recurrent neural network ensembles for time series prediction", "paper_id": "WOS:000340982800030"}