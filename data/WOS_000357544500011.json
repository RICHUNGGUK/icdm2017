{"auto_keywords": [{"score": 0.03889065839041926, "phrase": "parsa"}, {"score": 0.015719714774698124, "phrase": "distributed_file_system"}, {"score": 0.004771435352180973, "phrase": "scientific_data_analysis"}, {"score": 0.0046432244185370605, "phrase": "key_component"}, {"score": 0.00460125407969429, "phrase": "nowadays_large_scale_simulations"}, {"score": 0.004497973025639345, "phrase": "rapidly_increasing_data_volume"}, {"score": 0.004417012437860011, "phrase": "high_structured_files"}, {"score": 0.004201774694043468, "phrase": "poor_performance"}, {"score": 0.0041637779492720295, "phrase": "traditional_architectures"}, {"score": 0.003996983218174335, "phrase": "new_framework"}, {"score": 0.0038194503801108324, "phrase": "high-throughput_and_scalable_scientific_analysis"}, {"score": 0.0036497740708342093, "phrase": "optimization_strategies"}, {"score": 0.0035677736570659813, "phrase": "logical_units"}, {"score": 0.0033937776228549557, "phrase": "block_replicas"}, {"score": 0.00334780964309978, "phrase": "network_reading"}, {"score": 0.0032135959043774085, "phrase": "data_reading"}, {"score": 0.003015401937358271, "phrase": "similar_interfaces"}, {"score": 0.00297454367746853, "phrase": "netcdf_operator"}, {"score": 0.0028293966058473476, "phrase": "climate_data"}, {"score": 0.002816556934231128, "phrase": "diagnostic_packages"}, {"score": 0.0026307897899760383, "phrase": "well-known_analysis_methods"}, {"score": 0.0025716240685409513, "phrase": "hadoop_distributed_file_system"}, {"score": 0.0025137856138000014, "phrase": "experimental_results"}, {"score": 0.0024797072773840704, "phrase": "high_efficiency"}, {"score": 0.002326669201839705, "phrase": "six_nodes_hadoop_cluster"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Data intensive computing", " Scientific data analysis", " Distributed file system"], "paper_abstract": "Scientific data analysis and visualization have become the key component for nowadays large scale simulations. Due to the rapidly increasing data volume and awkward I/O pattern among high structured files, known serial methods/tools cannot scale well and usually lead to poor performance over traditional architectures. In this paper, we propose a new framework: ParSA (parallel scientific data analysis) for high-throughput and scalable scientific analysis, with distributed file system. ParSA presents the optimization strategies for grouping and splitting logical units to utilize distributed I/O property of distributed file system, scheduling the distribution of block replicas to reduce network reading, as well as to maximize overlapping the data reading, processing, and transferring during computation. Besides, ParSA provides the similar interfaces as the NetCDF Operator (NCO), which is used in most of climate data diagnostic packages, making it easy to use this framework. We utilize ParSA to accelerate well-known analysis methods for climate models on Hadoop Distributed File System (HDFS). Experimental results demonstrate the high efficiency and scalability of ParSA, getting the maximum 1.3 GB/s throughput on a six nodes Hadoop cluster with five disks per node. Yet, it can only get 392 MB/s throughput on a RAID-6 storage node. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "ParSA: High-throughput scientific data analysis framework with distributed file system", "paper_id": "WOS:000357544500011"}