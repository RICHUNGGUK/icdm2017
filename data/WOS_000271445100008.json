{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "data_mining_method"}, {"score": 0.004772818068176176, "phrase": "decision_trees"}, {"score": 0.0045877173513910055, "phrase": "multimedia_domain"}, {"score": 0.004294962474996283, "phrase": "short-time_delay"}, {"score": 0.004020813632357377, "phrase": "different_data_mining_methods"}, {"score": 0.003968112038249246, "phrase": "main_contributions"}, {"score": 0.00376409764683147, "phrase": "inherent_validity"}, {"score": 0.0037311260623089436, "phrase": "diverse_features"}, {"score": 0.0036020923276404403, "phrase": "hierarchical_structure"}, {"score": 0.0035705347414368696, "phrase": "oblique_decision_trees"}, {"score": 0.003539252646181146, "phrase": "hodt"}, {"score": 0.003477505397536663, "phrase": "optimal_performances"}, {"score": 0.0034018288705284427, "phrase": "novel_context-based_state_transform"}, {"score": 0.003284145698220425, "phrase": "classification_results"}, {"score": 0.0032410683344688625, "phrase": "proposed_algorithm"}, {"score": 0.00303398491761013, "phrase": "music_files"}, {"score": 0.0027417911324611917, "phrase": "classification_rate"}, {"score": 0.002682081928174866, "phrase": "pure_and_high_snr"}, {"score": 0.002544017922741882, "phrase": "post-processing_st_strategy"}, {"score": 0.002499590390751339, "phrase": "system_performance"}, {"score": 0.0024559368099486647, "phrase": "low_snr_circumstances"}, {"score": 0.0023604768913655463, "phrase": "accuracy_rate"}, {"score": 0.0022687189700002254, "phrase": "proposed_system"}, {"score": 0.0022290883852844057, "phrase": "iwmops"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Real-time discrimination", " Optimal feature subset", " Hierarchical oblique decision tree", " State transform strategy"], "paper_abstract": "Nowadays the applications in multimedia domain require that the Speech/Music classifier has many other merits in addition to the accuracy, such as short-time delay and low complexity. Here, we endeavor to form a Speech/Music classifier by using different data mining methods. The main contributions of this paper are to obtain a system by analyzing the inherent validity of diverse features extracted from the audio, building a hierarchical structure of oblique decision trees (HODT) to maintain optimal performances, and applying a novel context-based state transform (ST) strategy to refine the classification results. The proposed algorithm is evaluated by a set of 5-11 min 702 audio files, which are made from 54 speech or music files according to different Signal-to-Noise Ratio (SNR) levels and diverse noise types. The experiment results show that our proposed classifier outperforms AMR-WB+ by achieving 97.9% and 95.9% in classification rate at the 10 ms frame level in pure and high SNR (> = 20 dB) environment, respectively. The post-processing ST strategy further enhances the system performance, particularly at low SNR circumstances (10 dB), with 5.6% tip in the accuracy rate. In addition, the complexity of the proposed system is lower than IWMOPS which make it easily adaptable to many scenarios. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "A combination of data mining method with decision trees building for Speech/Music discrimination", "paper_id": "WOS:000271445100008"}