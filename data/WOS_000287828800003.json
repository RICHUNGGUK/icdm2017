{"auto_keywords": [{"score": 0.03800340820588705, "phrase": "unusual_behaviour"}, {"score": 0.00481495049065317, "phrase": "unusual_behaviour_detection"}, {"score": 0.004772593750252861, "phrase": "intelligent_surveillance"}, {"score": 0.004688989566904871, "phrase": "typical_surveillance_installation"}, {"score": 0.004627244470096107, "phrase": "human_operator"}, {"score": 0.004506171772318298, "phrase": "large_array"}, {"score": 0.004407690586271672, "phrase": "suspicious_behaviour"}, {"score": 0.004235793609579307, "phrase": "information_overload"}, {"score": 0.004198510172614725, "phrase": "manual_surveillance"}, {"score": 0.0040347380310668994, "phrase": "human_fatigue"}, {"score": 0.003894512634265439, "phrase": "intelligent_vision-based_surveillance_system"}, {"score": 0.003759142310009214, "phrase": "detection_components"}, {"score": 0.00344087639309216, "phrase": "trajectory-based_unusual_behaviour_detection"}, {"score": 0.0033955105098235345, "phrase": "low-level_trajectory_features"}, {"score": 0.003306559295382181, "phrase": "control_points"}, {"score": 0.0032057142600527, "phrase": "recently_introduced_approach"}, {"score": 0.003135564707433078, "phrase": "higher-level_features"}, {"score": 0.002986575805559931, "phrase": "intentional_agents"}, {"score": 0.002832081745025006, "phrase": "agent's_trajectory"}, {"score": 0.00278237555651743, "phrase": "known_spatial_goals"}, {"score": 0.0027456676902333304, "phrase": "proposed_method"}, {"score": 0.0027094427948305515, "phrase": "original_goal-based_approach"}, {"score": 0.002615156460073562, "phrase": "spatial_scene_structure"}, {"score": 0.0025578967205807843, "phrase": "training_phase"}, {"score": 0.0025018875576502606, "phrase": "region_transition_model"}, {"score": 0.002447101794397243, "phrase": "normal_movement_patterns"}, {"score": 0.002425524064992056, "phrase": "spatial_regions"}, {"score": 0.002279702500235741, "phrase": "probabilistic_framework"}, {"score": 0.0022595974985992664, "phrase": "particle_filtering"}, {"score": 0.0022396694076443446, "phrase": "experimental_validation"}, {"score": 0.002161695357601592, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Video surveillance", " Behaviour understanding", " Trajectory analysis", " Anomaly detection"], "paper_abstract": "In a typical surveillance installation, a human operator has to constantly monitor a large array of video feeds for suspicious behaviour. As the number of cameras increases, information overload makes manual surveillance increasingly difficult, adding to other confounding factors such as human fatigue and boredom. The objective of an intelligent vision-based surveillance system is to automate the monitoring and event detection components of surveillance, alerting the operator only when unusual behaviour or other events of interest are detected. While most traditional methods for trajectory-based unusual behaviour detection rely on low-level trajectory features such as flow vectors or control points, this paper builds upon a recently introduced approach that makes use of higher-level features of intentionality. Individuals in the scene are modelled as intentional agents, and unusual behaviour is detected by evaluating the explicability of the agent's trajectory with respect to known spatial goals. The proposed method extends the original goal-based approach in three ways: first, the spatial scene structure is learned in a training phase; second, a region transition model is learned to describe normal movement patterns between spatial regions; and third. classification of trajectories in progress is performed in a probabilistic framework using particle filtering. Experimental validation on three published third-party datasets demonstrates the validity of the proposed approach. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Goal-based trajectory analysis for unusual behaviour detection in intelligent surveillance", "paper_id": "WOS:000287828800003"}