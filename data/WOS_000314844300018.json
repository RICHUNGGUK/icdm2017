{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "recurrent_neural_networks"}, {"score": 0.043069853910456694, "phrase": "neural_networks"}, {"score": 0.004223032986655664, "phrase": "global_stability"}, {"score": 0.003802135020791801, "phrase": "lie_algebra"}, {"score": 0.0036553070575015344, "phrase": "lyapunov_function"}, {"score": 0.0035141291835319682, "phrase": "integral_inequality_technique"}, {"score": 0.0032908057622663732, "phrase": "globally_asymptotic_stability"}, {"score": 0.002737960968372391, "phrase": "exponential_stability"}, {"score": 0.0023694065215394593, "phrase": "asymptotic_stability"}, {"score": 0.0022777800735119405, "phrase": "equilibrium_point"}], "paper_keywords": ["Neural networks (NN)", " Global asymptotic stability (GAS)", " Equilibrium point", " Delay", " Lie algebra"], "paper_abstract": "This paper considers the problem of global stability of neural networks with delays. By combining Lie algebra and the Lyapunov function with the integral inequality technique, we analyze the globally asymptotic stability of a class of recurrent neural networks with delays and give an estimate of the exponential stability. A few new sufficient conditions and criteria are proposed to ensure globally asymptotic stability of the equilibrium point of the neural networks. A few simulation examples are presented to demonstrate the effectiveness of the results and to improve feasibility.", "paper_title": "The globally asymptotic stability analysis for a class of recurrent neural networks with delays", "paper_id": "WOS:000314844300018"}