{"auto_keywords": [{"score": 0.03043530137242866, "phrase": "relyzer"}, {"score": 0.010425240831513723, "phrase": "transient_faults"}, {"score": 0.007839232859612286, "phrase": "application_fault_sites"}, {"score": 0.00481495049065317, "phrase": "application-level_fault_equivalence"}, {"score": 0.0047014216428514465, "phrase": "future_microprocessors"}, {"score": 0.004673458200854065, "phrase": "low-cost_solutions"}, {"score": 0.004563250218021092, "phrase": "failure-prone_devices"}, {"score": 0.0045225925147033205, "phrase": "promising_approach"}, {"score": 0.004468942661513215, "phrase": "hardware_faults"}, {"score": 0.004429121482144758, "phrase": "low-cost_monitors"}, {"score": 0.004402770481509365, "phrase": "software-level_symptoms"}, {"score": 0.004160092647083038, "phrase": "non-negligible_risk"}, {"score": 0.0040740829470571425, "phrase": "symptom_detectors"}, {"score": 0.004025732081831055, "phrase": "silent_data_corruptions"}, {"score": 0.003942489281950188, "phrase": "symptom-based_detectors"}, {"score": 0.003919022096381048, "phrase": "fault_injection_campaigns"}, {"score": 0.0038956940500396086, "phrase": "application_benchmarks"}, {"score": 0.0037362254649023225, "phrase": "hardware_site"}, {"score": 0.003669888501738697, "phrase": "application's_execution"}, {"score": 0.0035725770197245392, "phrase": "total_number"}, {"score": 0.0034778368609967754, "phrase": "standard_benchmark_suites"}, {"score": 0.0033755037617077483, "phrase": "possible_faults"}, {"score": 0.003355400119144156, "phrase": "previous_work"}, {"score": 0.003305661550005516, "phrase": "randomly_selected_sample"}, {"score": 0.0027631437773897967, "phrase": "small_subset"}, {"score": 0.002738480561968019, "phrase": "selective_fault_injections"}, {"score": 0.002689810805544938, "phrase": "novel_fault_pruning_techniques"}, {"score": 0.0026420037427645725, "phrase": "detailed_study"}, {"score": 0.002488684109969271, "phrase": "total_faults"}, {"score": 0.0024738490295633194, "phrase": "twelve_applications"}, {"score": 0.0024081753091661396, "phrase": "detailed_simulation"}, {"score": 0.0023302648796456452, "phrase": "fault_injection_simulations"}, {"score": 0.0023094564983770563, "phrase": "remaining_faults"}, {"score": 0.002288836569038507, "phrase": "sdc"}, {"score": 0.002254869347951942, "phrase": "entire_application"}, {"score": 0.0022280604516919417, "phrase": "relyzer's_techniques"}, {"score": 0.002188442250414479, "phrase": "fault_equivalence"}, {"score": 0.0021431085940929783, "phrase": "fault_outcomes"}], "paper_keywords": ["Design", " Experimentation", " Measurement", " Reliability", " Low-Cost Hardware Resiliency", " Hardware Reliability Evaluation", " Silent Data Corruption", " Transient Faults", " Architecture"], "paper_abstract": "Future microprocessors need low-cost solutions for reliable operation in the presence of failure-prone devices. A promising approach is to detect hardware faults by deploying low-cost monitors of software-level symptoms of such faults. Recently, researchers have shown these mechanisms work well, but there remains a non-negligible risk that several faults may escape the symptom detectors and result in silent data corruptions (SDCs). Most prior evaluations of symptom-based detectors perform fault injection campaigns on application benchmarks, where each run simulates the impact of a fault injected at a hardware site at a certain point in the application's execution (application fault site). Since the total number of application fault sites is very large (trillions for standard benchmark suites), it is not feasible to study all possible faults. Previous work therefore typically studies a randomly selected sample of faults. Such studies do not provide any feedback on the portions of the application where faults were not injected. Some of those instructions may be vulnerable to SDCs, and identifying them could allow protecting them through other means if needed. This paper presents Relyzer, an approach that systematically analyzes all application fault sites and carefully picks a small subset to perform selective fault injections for transient faults. Relyzer employs novel fault pruning techniques that prune faults that need detailed study by either predicting their outcomes or showing them equivalent to other faults. We find that Relyzer prunes about 99.78% of the total faults across twelve applications studied here, reducing the faults that require detailed simulation by 3 to 5 orders of magnitude for most of the applications. Fault injection simulations on the remaining faults can identify SDC causing faults in the entire application. Some of Relyzer's techniques rely on heuristics to determine fault equivalence. Our validation efforts show that Relyzer determines fault outcomes with 96% accuracy, averaged across all the applications studied here.", "paper_title": "Relyzer: Exploiting Application-Level Fault Equivalence to Analyze Application Resiliency to Transient Faults", "paper_id": "WOS:000209339300011"}