{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "scene_understanding"}, {"score": 0.03863960768893905, "phrase": "static_elements"}, {"score": 0.004737579882204798, "phrase": "essential_element"}, {"score": 0.004611369021812453, "phrase": "unknown_territory"}, {"score": 0.004561826854638056, "phrase": "mobile_robots"}, {"score": 0.0035578416745422814, "phrase": "slam"}, {"score": 0.0034442607586033657, "phrase": "external_or_global_localization_information"}, {"score": 0.0027592065435732955, "phrase": "fixed_monocular_camera"}, {"score": 0.0027001292153471202, "phrase": "dynamic_scene"}, {"score": 0.002198173002125909, "phrase": "co-ordination_and_steering_strategies"}, {"score": 0.0021049977753042253, "phrase": "estimated_parameters"}], "paper_keywords": ["Computational intelligence", " approximate reasoning", " compositional rule of inference", " operation risk", " symptom levels", " parametric membership functions"], "paper_abstract": "Scene understanding is an essential element for the exploration of unknown territory using mobile robots. In this regard, scene understanding refers to the identification and localization of elements within the scene. When the scene is dynamic or has objects that move around, they need to be characterized and discriminated from the static elements, which are essential for SLAM (Simultaneous Localization And Mapping) when external or global localization information is not available. We present techniques and algorithms to accomplish these goals with regard to a scenario where we have a co-operative of robots having three degrees of freedom (x, y, theta) and equipped with a fixed monocular camera, observing a dynamic scene. The strategy is to localize the static elements of the scene and then estimate the velocity and trajectory of moving objects. The latter is much more difficult to solve than the former. We also present co-ordination and steering strategies for reducing the errors associated with the estimated parameters.", "paper_title": "Towards scene understanding using a co-operative of robots", "paper_id": "WOS:000274861400010"}