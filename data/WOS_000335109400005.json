{"auto_keywords": [{"score": 0.044605401042099674, "phrase": "vsvc"}, {"score": 0.010540512915503258, "phrase": "svm."}, {"score": 0.00820445069080651, "phrase": "learning_data"}, {"score": 0.007383200740992303, "phrase": "different_probability_distributions"}, {"score": 0.006397703281887771, "phrase": "svm_technique"}, {"score": 0.00481495049065317, "phrase": "supervised_kernel-based_clustering"}, {"score": 0.004718897469501381, "phrase": "considerable_attention"}, {"score": 0.004659835253478786, "phrase": "superior_classification_performance"}, {"score": 0.004475736220464172, "phrase": "unknown_probability_distributions"}, {"score": 0.004386420328440248, "phrase": "real_problems"}, {"score": 0.004288059466938456, "phrase": "vicinal_support_vector_classifier"}, {"score": 0.004149847419767442, "phrase": "practical_applications"}, {"score": 0.004026208353551013, "phrase": "proposed_vsvc_method"}, {"score": 0.003975781274672803, "phrase": "new_vicinal_kernel_functions"}, {"score": 0.003916098498242888, "phrase": "supervised_clustering"}, {"score": 0.003886592615976175, "phrase": "kernel-induced_feature_space"}, {"score": 0.0037898298056558673, "phrase": "clustering_step"}, {"score": 0.003676877371758866, "phrase": "different_soft_vicinal_areas"}, {"score": 0.0036491673002304326, "phrase": "feature_space"}, {"score": 0.003594369823549604, "phrase": "vicinal_kernel_functions"}, {"score": 0.003558294449586273, "phrase": "training_step"}, {"score": 0.0034784385610845446, "phrase": "vicinal_risk_function"}, {"score": 0.0034261960050599063, "phrase": "vicinal_areas"}, {"score": 0.003391802784468911, "phrase": "skda_clustering_step"}, {"score": 0.003324045183887105, "phrase": "artificial_and_real_medical_datasets"}, {"score": 0.003274113838379828, "phrase": "better_classification_accuracy"}, {"score": 0.0032576367435351718, "phrase": "lower_computational_time"}, {"score": 0.003192550774552538, "phrase": "artificial_dataset"}, {"score": 0.0031684791285366315, "phrase": "non-separated_data"}, {"score": 0.003144588408756064, "phrase": "classification_accuracy"}, {"score": 0.0030895394261534776, "phrase": "different_cluster_numbers"}, {"score": 0.0029973957125353306, "phrase": "vsvc_training_time"}, {"score": 0.0028642924503126154, "phrase": "real_mammography_dataset"}, {"score": 0.0028426887945253373, "phrase": "best_classification_accuracy"}, {"score": 0.0027718432845580195, "phrase": "standard_svm"}, {"score": 0.002709589081384597, "phrase": "similar_performance_improvement"}, {"score": 0.0024993218789131437, "phrase": "learning_time"}, {"score": 0.00238226080268069, "phrase": "vsvc_results"}, {"score": 0.0023523750536537102, "phrase": "support_vectors"}, {"score": 0.00232286335198363, "phrase": "specified_cluster_number"}, {"score": 0.0022649435091175287, "phrase": "standard_svm._conclusion"}, {"score": 0.0022421810750821993, "phrase": "supervised_clustering_algorithm"}, {"score": 0.002202894673025544, "phrase": "sparse_but_effective_solution"}, {"score": 0.002137137933768807, "phrase": "training_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Support vector machines", " Kernel-based data clustering", " Supervised deterministic annealing", " Mammographic mass classification", " Biomedical data classification"], "paper_abstract": "Objective: Support vector machines (SVMs) have drawn considerable attention due to their high generalisation ability and superior classification performance compared to other pattern recognition algorithms. However, the assumption that the learning data is identically generated from unknown probability distributions may limit the application of SVMs for real problems. In this paper, we propose a vicinal support vector classifier (VSVC) which is shown to be able to effectively handle practical applications where the learning data may originate from different probability distributions. Methods: The proposed VSVC method utilises a set of new vicinal kernel functions which are constructed based on supervised clustering in the kernel-induced feature space. Our proposed approach comprises two steps. In the clustering step, a supervised kernel-based deterministic annealing (SKDA) clustering algorithm is employed to partition the training data into different soft vicinal areas of the feature space in order to construct the vicinal kernel functions. In the training step, the SVM technique is used to minimise the vicinal risk function under the constraints of the vicinal areas defined in the SKDA clustering step. Results: Experimental results on both artificial and real medical datasets show our proposed VSVC achieves better classification accuracy and lower computational time compared to a standard SVM. For an artificial dataset constructed from non-separated data, the classification accuracy of VSVC is between 95.5% and 96.25% (using different cluster numbers) which compares favourably to the 94.5% achieved by SVM. The VSVC training time is between 8.75 s and 17.83 s (for 2-8 clusters), considerable less than the 65.0 s required by SVM. On a real mammography dataset, the best classification accuracy of VSVC is 85.7% and thus clearly outperforms a standard SVM which obtains an accuracy of only 82.1%. A similar performance improvement is confirmed on two further real datasets, a breast cancer dataset (74.01% vs. 72.52%) and a heart dataset (84.77% vs. 83.81%), coupled with a reduction in terms of learning time (32.07 s vs. 92.08 s and 25.00 s vs. 53.31 s, respectively). Furthermore, the VSVC results in the number of support vectors being equal to the specified cluster number, and hence in a much sparser solution compared to a standard SVM. Conclusion: Incorporating a supervised clustering algorithm into the SVM technique leads to a sparse but effective solution, while making the proposed VSVC adaptive to different probability distributions of the training data. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Vicinal support vector classifier using supervised kernel-based clustering", "paper_id": "WOS:000335109400005"}