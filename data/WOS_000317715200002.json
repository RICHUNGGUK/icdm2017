{"auto_keywords": [{"score": 0.041030905463758836, "phrase": "surgical_field"}, {"score": 0.040650574499495426, "phrase": "video_monitor"}, {"score": 0.00481495049065317, "phrase": "minimally_invasive_arthroscopic_surgery"}, {"score": 0.004677372885331908, "phrase": "conventional_open_orthopedic_surgery_procedures"}, {"score": 0.004085333687668526, "phrase": "special_miniature_pencil-like_tools"}, {"score": 0.003799509133780117, "phrase": "virtual_reality_simulation"}, {"score": 0.0037087324991876727, "phrase": "traditional_surgical_training"}, {"score": 0.0036553070575015344, "phrase": "hundreds_years_old_apprentice-master_model"}, {"score": 0.0035852640843794252, "phrase": "real_patients"}, {"score": 0.0033667304423940893, "phrase": "virtual_surgical_field"}, {"score": 0.003334309053314909, "phrase": "significant_efforts"}, {"score": 0.00328625950643742, "phrase": "software_developers"}, {"score": 0.003070996252787868, "phrase": "photorealistic_visualization"}, {"score": 0.0030414140732789186, "phrase": "haptic_interaction"}, {"score": 0.002925899335792914, "phrase": "real_arthroscopic_images"}, {"score": 0.0028421434495262796, "phrase": "proposed_technique"}, {"score": 0.0027741761880779535, "phrase": "joint_cavity"}, {"score": 0.002530359917257626, "phrase": "real_time"}, {"score": 0.0024818194799172263, "phrase": "preprocessing_stage"}, {"score": 0.002446024708601971, "phrase": "proposed_approach"}, {"score": 0.0024107449502335583, "phrase": "arthroscopic_images"}, {"score": 0.002319127685733821, "phrase": "implicitly_defined_object_models"}, {"score": 0.002241816883550397, "phrase": "simulation_loop"}, {"score": 0.0021987994275190314, "phrase": "mixed_scene"}, {"score": 0.0021566056345478373, "phrase": "haptic_rendering"}, {"score": 0.0021254913611527455, "phrase": "scene_depth_map"}, {"score": 0.0021049977753042253, "phrase": "visual_display"}], "paper_keywords": ["Image-driven haptic interaction", " Virtual surgery simulation", " Tangible images", " Augmented reality"], "paper_abstract": "In recent years, minimally invasive arthroscopic surgery has replaced a number of conventional open orthopedic surgery procedures on joints. While this achieves a number of advantages for the patient, the surgeons have to learn very different skills, since the surgery is performed with special miniature pencil-like tools and cameras inserted through little incisions while observing the surgical field on video monitor. Therefore, virtual reality simulation becomes an alternative to traditional surgical training based on hundreds years old apprentice-master model that involves either real patients or increasingly difficult to procure cadavers. Normally, 3D simulation of the virtual surgical field requires significant efforts from the software developers but yet remains not always photorealistic. In contrast to this, for photorealistic visualization and haptic interaction with the surgical field we propose to use real arthroscopic images augmented with 3D object models. The proposed technique allows for feeling the joint cavity displayed on video monitor as real 3D objects rather than their images while various surgical procedures, such as menisectomy, are simulated in real time. In the preprocessing stage of the proposed approach, the arthroscopic images are stitched into panoramas and augmented with implicitly defined object models representing deformable menisci. In the simulation loop, depth information from the mixed scene is used for haptic rendering. The scene depth map and visual display are reevaluated only when the scene is modified.", "paper_title": "Image-driven virtual simulation of arthroscopy", "paper_id": "WOS:000317715200002"}