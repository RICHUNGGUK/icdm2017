{"auto_keywords": [{"score": 0.0471913809101942, "phrase": "test_sample"}, {"score": 0.00979340045938775, "phrase": "training_samples"}, {"score": 0.007152368807539886, "phrase": "conventional_and_inverse_representation"}, {"score": 0.006848696392865894, "phrase": "conventional_representation"}, {"score": 0.006660275825753262, "phrase": "linear_combination"}, {"score": 0.00474075475474847, "phrase": "representation-based_classification_methods"}, {"score": 0.004646777436732789, "phrase": "proposed_method"}, {"score": 0.0042921238100956174, "phrase": "expression_result"}, {"score": 0.0038737214010638745, "phrase": "novel_representation-based_classification_method"}, {"score": 0.003743487506598038, "phrase": "inverse_representation-based_classification"}, {"score": 0.003388909415044492, "phrase": "inverse_representation"}, {"score": 0.0033262524445013303, "phrase": "approximation_representation"}, {"score": 0.0032953582866530966, "phrase": "training_sample"}, {"score": 0.002855934865505357, "phrase": "theoretical_foundation"}, {"score": 0.0027426990589357937, "phrase": "first_time"}, {"score": 0.002708766459414734, "phrase": "basic_nature"}, {"score": 0.0026835920552084488, "phrase": "human_face"}, {"score": 0.0026013505538490223, "phrase": "new_training"}, {"score": 0.002585206414738808, "phrase": "test_samples"}, {"score": 0.0025532173213934422, "phrase": "new_samples"}, {"score": 0.002521623057264411, "phrase": "possible_appearance"}, {"score": 0.002414082940963702, "phrase": "higher_accuracy"}, {"score": 0.002233301265743633, "phrase": "naive_lrc"}, {"score": 0.0021580985506699105, "phrase": "cirlrc"}, {"score": 0.0021049980365496664, "phrase": "lrc."}], "paper_keywords": ["Face recognition", " pattern recognition", " representation-based classification"], "paper_abstract": "Representation-based classification methods are all constructed on the basis of the conventional representation, which first expresses the test sample as a linear combination of the training samples and then exploits the deviation between the test sample and the expression result of every class to perform classification. However, this deviation does not always well reflect the difference between the test sample and each class. With this paper, we propose a novel representation-based classification method for face recognition. This method integrates conventional and the inverse representation-based classification for better recognizing the face. It first produces conventional representation of the test sample, i.e., uses a linear combination of the training samples to represent the test sample. Then it obtains the inverse representation, i.e., provides an approximation representation of each training sample of a subject by exploiting the test sample and training samples of the other subjects. Finally, the proposed method exploits the conventional and inverse representation to generate two kinds of scores of the test sample with respect to each class and combines them to recognize the face. The paper shows the theoretical foundation and rationale of the proposed method. Moreover, this paper for the first time shows that a basic nature of the human face, i.e., the symmetry of the face can be exploited to generate new training and test samples. As these new samples really reflect some possible appearance of the face, the use of them will enable us to obtain higher accuracy. The experiments show that the proposed conventional and inverse representation-based linear regression classification (CIRLRC), an improvement to linear regression classification (LRC), can obtain very high accuracy and greatly outperforms the naive LRC and other state-of-the-art conventional representation based face recognition methods. The accuracy of CIRLRC can be 10% greater than that of LRC.", "paper_title": "Integrating Conventional and Inverse Representation for Face Recognition", "paper_id": "WOS:000342228100003"}