{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "university_quality"}, {"score": 0.004630626571109149, "phrase": "bayesian_hierarchical_latent_trait_model"}, {"score": 0.004482400730101345, "phrase": "eight_different_university_ranking_systems"}, {"score": 0.0042550030421781605, "phrase": "five_contributions"}, {"score": 0.0037112756920669593, "phrase": "different_systems"}, {"score": 0.003454687811707182, "phrase": "single_source"}, {"score": 0.002935393439834135, "phrase": "point_estimates"}, {"score": 0.0027501697136375555, "phrase": "quality_estimates"}, {"score": 0.0022763657774198184, "phrase": "ranking_system"}, {"score": 0.0021049977753042253, "phrase": "particular_countries"}], "paper_keywords": ["Latent trait models", " Bayesian models", " University rankings"], "paper_abstract": "This paper uses a Bayesian hierarchical latent trait model, and data from eight different university ranking systems, to measure university quality. There are five contributions. First, I find that ratings tap a unidimensional, underlying trait of university quality. Second, by combining information from different systems, I obtain more accurate ratings than are currently available from any single source. And rather than dropping institutions that receive only a few ratings, the model simply uses whatever information is available. Third, while most ratings focus on point estimates and their attendant ranks, I focus on the uncertainty in quality estimates, showing that the difference between universities ranked 50th and 100th, and 100th and 250th, is insignificant. Finally, by measuring the accuracy of each ranking system, as well as the degree of bias toward universities in particular countries, I am able to rank the rankings.", "paper_title": "Measuring university quality", "paper_id": "WOS:000359143200009"}