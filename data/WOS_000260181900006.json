{"auto_keywords": [{"score": 0.03774156611827689, "phrase": "ebi"}, {"score": 0.011386667369519968, "phrase": "target_node"}, {"score": 0.00481495049065317, "phrase": "bayesian_networks"}, {"score": 0.0047409388179452255, "phrase": "bayesian_network"}, {"score": 0.004596295252559861, "phrase": "accurate_predictions"}, {"score": 0.004525629293824217, "phrase": "erroneous_or_incomplete_evidence"}, {"score": 0.004320055598195391, "phrase": "existing_approaches"}, {"score": 0.004145143433523008, "phrase": "variable_interactions"}, {"score": 0.003855849747095327, "phrase": "explaining_bn_inferences"}, {"score": 0.0033883824438527316, "phrase": "influential_nodes"}, {"score": 0.003336225354214798, "phrase": "target's_markov_blanket"}, {"score": 0.0032176163279340206, "phrase": "markov_nodes"}, {"score": 0.003168079471049896, "phrase": "target's_parents"}, {"score": 0.0028127163745564777, "phrase": "intermediate_variable"}, {"score": 0.002684740763324991, "phrase": "evidence_values"}, {"score": 0.0025361866386341796, "phrase": "problem_domains"}, {"score": 0.0024971144603069006, "phrase": "mushroom_classification"}, {"score": 0.002471400498582011, "phrase": "water_purification"}, {"score": 0.002445950676329976, "phrase": "web_page"}, {"score": 0.0023346234464901978, "phrase": "high_quality"}, {"score": 0.002310578855290687, "phrase": "concise_and_comprehensible_explanations"}, {"score": 0.0022168460543913787, "phrase": "underlying_compensation_mechanism"}, {"score": 0.0021490449563443025, "phrase": "alternative_prediction_systems"}, {"score": 0.0021049977753042253, "phrase": "decision_tree"}], "paper_keywords": ["Bayesian networks", " Explanations", " Inferences", " Compensations", " Error values", " Missing values"], "paper_abstract": "While Bayesian network (BN) can achieve accurate predictions even with erroneous or incomplete evidence, explaining the inferences remains a challenge. Existing approaches fall short because they do not exploit variable interactions and cannot account for compensations during inferences. This paper proposes the Explaining BN Inferences (EBI) procedure for explaining how variables interact to reach conclusions. EBI explains the value of a target node in terms of the influential nodes in the target's Markov blanket under specific contexts, where the Markov nodes include the target's parents, children, and the children's other parents. Working back from the target node, EBI shows the derivation of each intermediate variable, and finally explains how missing and erroneous evidence values are compensated. We validated EBI on a variety of problem domains, including mushroom classification, water purification and web page recommendation. The experiments show that EBI generates high quality, concise and comprehensible explanations for BN inferences, in particular the underlying compensation mechanism that enables BN to outperform alternative prediction systems, such as decision tree.", "paper_title": "Explaining inferences in Bayesian networks", "paper_id": "WOS:000260181900006"}