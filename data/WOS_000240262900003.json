{"auto_keywords": [{"score": 0.015719716506582538, "phrase": "action_recognition"}, {"score": 0.004638602678192715, "phrase": "new_method"}, {"score": 0.004565007074039171, "phrase": "everyday_life_actions"}, {"score": 0.003973971215091993, "phrase": "binary_points"}, {"score": 0.003404244237372396, "phrase": "feature_vector"}, {"score": 0.0025109095718850376, "phrase": "relevancy_matrix"}, {"score": 0.0023051837161137674, "phrase": "case_basis"}, {"score": 0.002244410443944976, "phrase": "suggested_approach"}], "paper_keywords": [""], "paper_abstract": "In this study, a new method for recognizing everyday life actions is proposed. To enhance robustness, each sequence is characterized globally. Detection of moving areas is first performed on each image. All binary points form a volume in the three-dimensional (3D) space (x,y,t). This volume is characterized by its geometric 3D moments which are used to form a feature vector for the recognition. Action recognition is then carried out by employing two classifiers independently: a) a nearest center classifier, and b) an auto-associative neural network. The performance of these two is examined, separately. Based on this evaluation, these two classifiers are combined. For this purpose, a relevancy matrix is used to select between the results of the two classifiers, on a case by case basis. To validate the suggested approach, results are presented and compared to those obtained by using only one classifier.", "paper_title": "Combined classifiers for action recognition", "paper_id": "WOS:000240262900003"}