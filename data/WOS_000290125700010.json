{"auto_keywords": [{"score": 0.040801524583702814, "phrase": "hand_gestures"}, {"score": 0.00481495049065317, "phrase": "real_time_hand_gesture_vision_based_human-computer_interaction"}, {"score": 0.004577440795549049, "phrase": "human-computer_interaction"}, {"score": 0.004500891637057374, "phrase": "hand_gesture_vision"}, {"score": 0.004376131419366239, "phrase": "realistic_and_challenging_scenarios"}, {"score": 0.0041136473765874815, "phrase": "hybrid_approach"}, {"score": 0.003932654396285872, "phrase": "beginning_position"}, {"score": 0.0036553070575015344, "phrase": "offline_skin_model"}, {"score": 0.0035941231858949035, "phrase": "gaussian_mixture_models"}, {"score": 0.0035339597999254064, "phrase": "specific_hand_gesture"}, {"score": 0.0034359094594153304, "phrase": "adaboost_technique"}, {"score": 0.0032115093493071366, "phrase": "kernel_based_tracking"}, {"score": 0.0031577303835881964, "phrase": "semi-supervised_feature_selection_strategy"}, {"score": 0.003035711716881469, "phrase": "feature_subspaces"}, {"score": 0.002918394200972564, "phrase": "offline_hand_skin_cues"}, {"score": 0.0028857130140890787, "phrase": "online_foreground-background-classification_cues"}, {"score": 0.0027898428590137515, "phrase": "oriented_gradients"}, {"score": 0.002651960559564796, "phrase": "soft-decision_approach"}, {"score": 0.0025638362414466278, "phrase": "static_hand_gestures"}, {"score": 0.0024926348205500715, "phrase": "severe_ambiguity"}, {"score": 0.002450864311898833, "phrase": "hidden_markov_model"}, {"score": 0.0024370965602952496, "phrase": "based_dynamic_gestures"}, {"score": 0.0022906498741695094, "phrase": "superior_performance"}, {"score": 0.0022522565004588113, "phrase": "proposed_components"}, {"score": 0.0021773853011112882, "phrase": "whole_framework"}, {"score": 0.0021288561076024844, "phrase": "real-time_applications"}, {"score": 0.0021049977753042253, "phrase": "general_computing_platforms"}], "paper_keywords": ["vision based human computer interaction", " hand gesture recognition", " hand gesture detection", " discriminative kernel based tracking", " histogram of oriented gradients"], "paper_abstract": "This paper presents a robust framework of human-computer interaction from the hand gesture vision in the presence of realistic and challenging scenarios. To this end, several novel components are proposed. A hybrid approach is first proposed to automatically infer the beginning position of hand gestures of interest via jointly optimizing the regions given by an offline skin model trained from Gaussian mixture models and a specific hand gesture classifier trained from the Adaboost technique. To consistently track the hand in the context of using kernel based tracking, a semi-supervised feature selection strategy is further presented to choose the feature subspaces which appropriately represent the properties of offline hand skin cues and online foreground-background-classification cues. Taking the histogram of oriented gradients as the descriptor to represent hand gestures, a soft-decision approach is finally proposed for recognizing static hand gestures at the locations where severe ambiguity occurs and hidden Markov model based dynamic gestures are employed for interaction. Experiments on various real video sequences show the superior performance of the proposed components. In addition, the whole framework is applicable to real-time applications on general computing platforms.", "paper_title": "A Framework of Real Time Hand Gesture Vision Based Human-Computer Interaction", "paper_id": "WOS:000290125700010"}