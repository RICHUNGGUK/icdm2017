{"auto_keywords": [{"score": 0.04201891621603315, "phrase": "population_density_estimate"}, {"score": 0.00481495049065317, "phrase": "nearest_neighbor_density_estimates"}, {"score": 0.0046741260449047976, "phrase": "k-nearest_neighbors"}, {"score": 0.0045599093158915326, "phrase": "nonparametric_discriminant_analysis"}, {"score": 0.004492717291734985, "phrase": "classification_problems"}, {"score": 0.004448471107649881, "phrase": "optimal_values"}, {"score": 0.004254671386496732, "phrase": "cross-validated_misclassification_rates"}, {"score": 0.004150661689086371, "phrase": "cross-validation_techniques"}, {"score": 0.003911253966141701, "phrase": "classification_problem"}, {"score": 0.003853583126988071, "phrase": "optimum_value"}, {"score": 0.003472927015404464, "phrase": "cross-validated_error_rate"}, {"score": 0.0031453010852936334, "phrase": "good_choice"}, {"score": 0.003023047748772801, "phrase": "specific_observation"}, {"score": 0.002862648127577722, "phrase": "single_value"}, {"score": 0.002618278365749875, "phrase": "multiple_values"}, {"score": 0.0025289662786567896, "phrase": "final_decision"}, {"score": 0.002418587525752333, "phrase": "graphical_device"}, {"score": 0.0023476849595393872, "phrase": "classification_results"}, {"score": 0.0022675820982741347, "phrase": "related_statistical_uncertainties"}, {"score": 0.0021793698531006197, "phrase": "proposed_methodology"}, {"score": 0.0021049977753042253, "phrase": "benchmark_data_sets"}], "paper_keywords": ["bootstrap", " cross validation", " misclassification rate", " multiscale analysis", " posterior probability", " p-value", " weighted averaging"], "paper_abstract": "Density estimates based on k-nearest neighbors have useful applications in nonparametric discriminant analysis. In classification problems, optimal values of k are usually estimated by minimizing the cross-validated misclassification rates. However, these cross-validation techniques allow only one value of k for each population density estimate, while in a classification problem, the optimum value of k for a class may also depend on its competing population densities. Further, it is computationally difficult to minimize the cross-validated error rate when there are several competing populations. Moreover, in addition to depending on the entire training data set, a good choice of k should also depend on the specific observation to be classified. Therefore, instead of using a single value of k for each population density estimate, it is more useful in practice to consider the results for multiple values of k to arrive at the final decision. This paper presents one such approach along with a graphical device, which gives more information about classification results for various choices of k and the related statistical uncertainties present there. The utility of this proposed methodology has been illustrated I using some benchmark data sets.", "paper_title": "Multiscale classification using nearest neighbor density estimates", "paper_id": "WOS:000240756700014"}