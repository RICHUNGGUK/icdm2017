{"auto_keywords": [{"score": 0.037045008134528865, "phrase": "test_inputs"}, {"score": 0.03089696852197988, "phrase": "first_stage"}, {"score": 0.015719716506582538, "phrase": "test_case_similarity"}, {"score": 0.01516698557534916, "phrase": "blackbox_fuzzing"}, {"score": 0.01445968187980907, "phrase": "new_inputs"}, {"score": 0.014245388770482958, "phrase": "deep_program_semantics"}, {"score": 0.009008705736505574, "phrase": "second_stage"}, {"score": 0.004786002454145624, "phrase": "deep_fuzzing"}, {"score": 0.004671932143798307, "phrase": "software_vulnerabilities"}, {"score": 0.004588158931776543, "phrase": "program_source_code"}, {"score": 0.004533142516832776, "phrase": "well-formed_inputs"}, {"score": 0.004492311611857372, "phrase": "new_ones"}, {"score": 0.004203864747683794, "phrase": "deep_program_state"}, {"score": 0.0040057404099240424, "phrase": "input_validation_components"}, {"score": 0.003945754887845885, "phrase": "domain_knowledge"}, {"score": 0.003910193916677954, "phrase": "input_specifications"}, {"score": 0.0036700484729006136, "phrase": "whitebox"}, {"score": 0.0036369632227788076, "phrase": "heavy_analysis_techniques"}, {"score": 0.0033929894721242367, "phrase": "new_program_branches"}, {"score": 0.0032821417644980674, "phrase": "fundamental_challenges"}, {"score": 0.003252542052430779, "phrase": "unsolvable_constraints"}, {"score": 0.0031845067058084583, "phrase": "large_programs"}, {"score": 0.003155784719225786, "phrase": "path_explosion"}, {"score": 0.0030991131563500446, "phrase": "novel_fuzzing_approach"}, {"score": 0.0029707940194245216, "phrase": "fuzzing_process"}, {"score": 0.0028911146216534646, "phrase": "traditional_blackbox_fuzzing_approach"}, {"score": 0.0028563889983942215, "phrase": "test_data_generation"}, {"score": 0.0027881805415682437, "phrase": "novel_test_case_similarity"}, {"score": 0.0025775232150656467, "phrase": "combination_testing"}, {"score": 0.0025388705701873075, "phrase": "selected_test_inputs"}, {"score": 0.002404447017429959, "phrase": "shallow_program_paths"}, {"score": 0.0022909325048608054, "phrase": "deep_program_paths"}, {"score": 0.0022294468373088424, "phrase": "prototype_tool"}, {"score": 0.002222717552124615, "phrase": "simfuzz"}, {"score": 0.0021827653135510225, "phrase": "real_programs"}, {"score": 0.002156529381840657, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Fuzzing", " Software testing", " Software vulnerability"], "paper_abstract": "Fuzzing is widely used to detect software vulnerabilities. Blackbox fuzzing does not require program source code. It mutates well-formed inputs to produce new ones. However, these new inputs usually do not exercise deep program semantics since the possibility that they can satisfy the conditions of a deep program state is low. As a result, blackbox fuzzing is often limited to identify vulnerabilities in input validation components of a program. Domain knowledge such as input specifications can be used to mitigate these limitations. However, it is often expensive to obtain such knowledge in practice. Whitebox fuzzing employs heavy analysis techniques, i.e., dynamic symbolic execution, to systematically generate test inputs and explore as many paths as possible. It is powerful to explore new program branches so as to identify more vulnerabilities. However, it has fundamental challenges such as unsolvable constraints and is difficult to scale to large programs due to path explosion. This paper proposes a novel fuzzing approach that aims to produce test inputs to explore deep program semantics effectively and efficiently. The fuzzing process comprises two stages. At the first stage, a traditional blackbox fuzzing approach is applied for test data generation. This process is guided by a novel test case similarity metric. At the second stage, a subset of the test inputs generated at the first stage is selected based on the test case similarity metric. Then, combination testing is applied on these selected test inputs to further generate new inputs. As a result, less redundant test inputs, i.e., inputs that just explore shallow program paths, are created at the first stage, and more distinct test inputs, i.e., inputs that explore deep program paths, are produced at the second stage. A prototype tool SimFuzz is developed and evaluated on real programs, and the experimental results are promising. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "SimFuzz: Test case similarity directed deep fuzzing", "paper_id": "WOS:000297892900010"}