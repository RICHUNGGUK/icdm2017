{"auto_keywords": [{"score": 0.0351915666065727, "phrase": "hit_rate"}, {"score": 0.00481495049065317, "phrase": "dynamic_result_caching"}, {"score": 0.00471071771178029, "phrase": "search_engines"}, {"score": 0.00465944657565638, "phrase": "web_search_engines"}, {"score": 0.004459857205489101, "phrase": "previously_issued_queries"}, {"score": 0.004387225575447685, "phrase": "stored_results"}, {"score": 0.004292212137716459, "phrase": "document_summaries"}, {"score": 0.004063547375196532, "phrase": "final_search_result_page"}, {"score": 0.003910740988145338, "phrase": "alternative_strategy"}, {"score": 0.0033916328188225843, "phrase": "interesting_trade-off"}, {"score": 0.0032819448594643853, "phrase": "average_query_response_latency"}, {"score": 0.0030064251340251196, "phrase": "hybrid_result_caching_strategy"}, {"score": 0.0029573932605287947, "phrase": "dynamic_result_cache"}, {"score": 0.002846085629897683, "phrase": "html"}, {"score": 0.002679501909303057, "phrase": "realistic_cost_model"}, {"score": 0.0025786066704445304, "phrase": "different_result"}, {"score": 0.002564505790176378, "phrase": "prefetching_strategies"}, {"score": 0.002522662955545598, "phrase": "proposed_hybrid_cache"}, {"score": 0.0024815011359381692, "phrase": "baseline_html-only_cache"}, {"score": 0.002388043660169452, "phrase": "machine_learning_approach"}, {"score": 0.002349073225500705, "phrase": "singleton_queries"}, {"score": 0.0022482261385133617, "phrase": "query_stream"}, {"score": 0.002163535133532765, "phrase": "proposed_hybrid_result_caching_strategy"}, {"score": 0.0021049977753042253, "phrase": "singleton_query_predictor"}], "paper_keywords": ["Algorithms", " Experimentation", " Performance", " Web search engines", " dynamic result caching", " result prefetching"], "paper_abstract": "Web search engines are known to cache the results of previously issued queries. The stored results typically contain the document summaries and some data that is used to construct the final search result page returned to the user. An alternative strategy is to store in the cache only the result document IDs, which take much less space, allowing results of more queries to be cached. These two strategies lead to an interesting trade-off between the hit rate and the average query response latency. In this work, in order to exploit this trade-off, we propose a hybrid result caching strategy where a dynamic result cache is split into two sections: an HTML cache and a docID cache. Moreover, using a realistic cost model, we evaluate the performance of different result prefetching strategies for the proposed hybrid cache and the baseline HTML-only cache. Finally, we propose a machine learning approach to predict singleton queries, which occur only once in the query stream. We show that when the proposed hybrid result caching strategy is coupled with the singleton query predictor, the hit rate is further improved.", "paper_title": "Second Chance: A Hybrid Approach for Dynamic Result Caching and Prefetching in Search Engines", "paper_id": "WOS:000329437900003"}