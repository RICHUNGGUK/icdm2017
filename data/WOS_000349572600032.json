{"auto_keywords": [{"score": 0.04113670333751854, "phrase": "face_sequence"}, {"score": 0.03694396280494385, "phrase": "temporal_distribution"}, {"score": 0.00481495049065317, "phrase": "tv_series"}, {"score": 0.004257360656055417, "phrase": "uncontrolled_tv_series_videos"}, {"score": 0.004183137595671171, "phrase": "detected_faces"}, {"score": 0.003676811616723809, "phrase": "cluster_labels"}, {"score": 0.002941913249957503, "phrase": "global_sequence_alignment_algorithm"}, {"score": 0.0026781477395106993, "phrase": "name_sequence"}, {"score": 0.0025254115243261875, "phrase": "temporal_order_relationship"}, {"score": 0.002409503258044183, "phrase": "whole_video"}, {"score": 0.002298902547676131, "phrase": "real-world_videos"}, {"score": 0.0021805201234139475, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Face annotation", " Face naming", " Video analysis", " Sequence alignment"], "paper_abstract": "This paper describes a method for automatically tagging the names to the faces which are collected from uncontrolled TV series videos. The detected faces are firstly partitioned into several clusters. Then we construct a face sequence based on their occurrence order in the video and denote them by cluster labels. It can be assumed that the temporal distribution of the faces in the video roughly follows the temporal distribution of the names in the script. Hence, we propose to annotate the faces by video/script alignment. A global sequence alignment algorithm is employed to find the most probable faces in the face sequence matching to the names in the name sequence. The novelty lies in that we consider the temporal order relationship of the faces and names over the whole video and directly align two heterogeneous sequences. Experiments on real-world videos have demonstrated the effectiveness and efficiency of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Automatic face annotation in TV series by video/script alignment", "paper_id": "WOS:000349572600032"}