{"auto_keywords": [{"score": 0.04104853033981482, "phrase": "new_york"}, {"score": 0.033888802846295064, "phrase": "proposed_algorithm"}, {"score": 0.00481495049065317, "phrase": "sentence_retrieval"}, {"score": 0.004785682967399109, "phrase": "two-level_feature_matching"}, {"score": 0.004698938469311569, "phrase": "conventional_spoken_sentence_retrieval"}, {"score": 0.004599712603988837, "phrase": "large-vocabulary_continuous-speech_recognition"}, {"score": 0.004461568861657379, "phrase": "feature-based_speaker-dependent_ssr_algorithm"}, {"score": 0.004288139217156765, "phrase": "query_inputs"}, {"score": 0.004184766878267706, "phrase": "spoken_sentence_database"}, {"score": 0.004034343096452382, "phrase": "relevant_personal_spoken_sentence"}, {"score": 0.0038187460155038383, "phrase": "appropriate_query_input"}, {"score": 0.0036256778700153227, "phrase": "first_level"}, {"score": 0.003592630978298206, "phrase": "similar_frame_tagging_scheme"}, {"score": 0.0035382184560822437, "phrase": "possible_segments"}, {"score": 0.0035059659238897644, "phrase": "database_sentences"}, {"score": 0.0034423371331039464, "phrase": "user's_query_utterance"}, {"score": 0.0034005585921467875, "phrase": "second_level"}, {"score": 0.0033695566513755096, "phrase": "fine_similarity_evaluation"}, {"score": 0.0033083952949044173, "phrase": "possible_segment"}, {"score": 0.0032384375096920024, "phrase": "feature-based_comparison"}, {"score": 0.003169954314343514, "phrase": "acoustic_and_language_models"}, {"score": 0.0030934538358409216, "phrase": "effective_feature_selection"}, {"score": 0.003065243071851165, "phrase": "next_issue"}, {"score": 0.002982140436039972, "phrase": "conventional_met_frequency"}, {"score": 0.0027460713949639492, "phrase": "ssr._experimental_results"}, {"score": 0.0027127202051739608, "phrase": "retrieval_performance"}, {"score": 0.0025363803754268302, "phrase": "retrieval_precision"}, {"score": 0.0024979252889176756, "phrase": "feature-based_matching"}, {"score": 0.0023570261027098293, "phrase": "original_methods"}, {"score": 0.0021049977753042253, "phrase": "resource-limited_devices"}], "paper_keywords": ["audio low level descriptors", " matching algorithm", " MPEG-7", " spoken sentence retrieval", " feature-based comparison"], "paper_abstract": "Conventional spoken sentence retrieval (SSR) relies on a large-vocabulary continuous-speech recognition (LVCSR) system. This investigation proposes a feature-based speaker-dependent SSR algorithm using two-level matching. Users can speak keywords as the query inputs to get the similarity ranks from a spoken sentence database. For instance, if a user is looking for a relevant personal spoken sentence, \"October 12, I have a meeting in New York\" in the database, then the appropriate query input could be \"meeting\", \"New York\" or \"October\". In the first level, a Similar Frame Tagging scheme is proposed to locate possible segments of the database sentences that are similar to the user's query utterance. In the second level, a Fine Similarity Evaluation between the query and each possible segment is performed. Based on the feature-based comparison, the proposed algorithm does not require acoustic and language models, thus our SSR algorithm is language independent. Effective feature selection is the next issue in this paper. In addition to the conventional met frequency cepstrum coefficients (MFCCs), several MPEG-7 audio low-level descriptors (LLDs) are also used as the features to exploit their ability for SSR. Experimental results revealed that the retrieval performance using MPEG-7 audio LLDs was close to that of the MFCCs. The combination of MPEG-7 audio LLDs and the MFCCs could further improve the retrieval precision. Based on the feature-based matching, the proposed algorithm has the advantages of language independent and speaker dependent training free. Comparing to the original methods [10, 11], with only 0.026 similar to 0.05 precision decrease, the addition and multiplication numbers are reduced by around a factor of l(q) (frame number of query). It is particularly suitable for the use in resource-limited devices.", "paper_title": "Personal Spoken Sentence Retrieval Using Two-Level Feature Matching and MPEG-7 Audio LLDs", "paper_id": "WOS:000268197700016"}