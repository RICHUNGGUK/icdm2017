{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "instruction_streams"}, {"score": 0.009853459661251103, "phrase": "particular_branch_types"}, {"score": 0.004748740786945996, "phrase": "stream_fetch_engine"}, {"score": 0.0046834372388970405, "phrase": "high-performance_fetch_architecture"}, {"score": 0.004534517530868195, "phrase": "instruction_stream"}, {"score": 0.004270347498153512, "phrase": "taken_branch"}, {"score": 0.004211594861013822, "phrase": "next_taken_branch"}, {"score": 0.004134508282135594, "phrase": "multiple_basic_blocks"}, {"score": 0.0040215052006051235, "phrase": "long_length"}, {"score": 0.0037696519417841287, "phrase": "high_fetch_bandwidth"}, {"score": 0.003683565150278339, "phrase": "branch_predictor_access_latency"}, {"score": 0.003616108223034427, "phrase": "performance_results"}, {"score": 0.0035498822293046884, "phrase": "trace_cache"}, {"score": 0.0035010071030752883, "phrase": "lower_implementation_cost"}, {"score": 0.0033428820402140683, "phrase": "excellent_way"}, {"score": 0.0028172726995962173, "phrase": "good_strategy"}, {"score": 0.0027784560880013886, "phrase": "amdahl's_law"}, {"score": 0.0026899455459275575, "phrase": "multiple-stream_predictor"}, {"score": 0.0025802660239538353, "phrase": "branch_types"}, {"score": 0.0025447065763362984, "phrase": "single_streams"}, {"score": 0.0025212722607043546, "phrase": "long_virtual_streams"}, {"score": 0.0024522530645471065, "phrase": "prediction_table_access_latency"}, {"score": 0.0023741093119014436, "phrase": "additional_hardware_mechanisms"}, {"score": 0.0022772782536385717, "phrase": "high-performance_results"}, {"score": 0.002174303033371869, "phrase": "-art_fetch_architectures"}, {"score": 0.0021344259291927914, "phrase": "simpler_design"}], "paper_keywords": ["superscalar processor design", " instruction fetch", " branch prediction", " access latency", " code optimization"], "paper_abstract": "The stream fetch engine is a high-performance fetch architecture based on the concept of an instruction stream. We call a sequence of instructions from the target of a taken branch to the next taken branch, potentially containing multiple basic blocks, a stream. The long length of instruction streams makes it possible for the stream fetch engine to provide a high fetch bandwidth and to hide the branch predictor access latency, leading to performance results close to a trace cache at a lower implementation cost and complexity. Therefore, enlarging instruction streams is an excellent way to improve the stream fetch engine. In this paper, we present several hardware and software mechanisms focused on enlarging those streams that finalize at particular branch types. However, our results point out that focusing on particular branch types is not a good strategy due to Amdahl's law. Consequently, we propose the multiple-stream predictor, a novel mechanism that deals with all branch types by combining single streams into long virtual streams. This proposal tolerates the prediction table access latency without requiring the complexity caused by additional hardware mechanisms like prediction overriding. Moreover, it provides high-performance results which are comparable to state-of-the-art fetch architectures but with a simpler design that consumes less energy.", "paper_title": "Enlarging instruction streams", "paper_id": "WOS:000248891000005"}