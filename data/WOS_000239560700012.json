{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "combined_head"}, {"score": 0.004565007074039171, "phrase": "adaptive_appearance_models"}, {"score": 0.004374385639298755, "phrase": "human_heads"}, {"score": 0.0042820680211904235, "phrase": "video_sequences"}, {"score": 0.004169394481182493, "phrase": "great_number"}, {"score": 0.004038076978795421, "phrase": "human-computer_interaction"}, {"score": 0.0038079353103469865, "phrase": "real-time_tracker"}, {"score": 0.0035338315037521627, "phrase": "monocular_video_sequences"}, {"score": 0.0034777028461723198, "phrase": "developed_approach"}, {"score": 0.003422462630994095, "phrase": "online_appearance_models"}, {"score": 0.0033680968918579717, "phrase": "facial_texture"}, {"score": 0.002994859407965545, "phrase": "non-occluded_facial_texture_model"}, {"score": 0.002824005136794786, "phrase": "previous_approaches"}, {"score": 0.002794001681064862, "phrase": "eyelid_tracking"}, {"score": 0.002592693161475495, "phrase": "color_information"}, {"score": 0.0023549822490693344, "phrase": "eye_feature_extraction"}, {"score": 0.0022928991183989115, "phrase": "erroneous_results"}, {"score": 0.002256435842862802, "phrase": "eye_feature_detector"}, {"score": 0.002196944917134202, "phrase": "real_videos"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": [""], "paper_abstract": "The ability to detect and track human heads and faces in video sequences is useful in a great number of applications, such as human-computer interaction and gesture recognition. Recently, we have proposed a real-time tracker that simultaneously tracks the 3D head pose and facial actions associated with the lips and the eyebrows in monocular video sequences. The developed approach relies on Online Appearance Models where the facial texture is learned during the tracking. This paper extends our previous work in two directions. First, we show that by adopting a non-occluded facial texture model more accurate and stable 3D head pose parameters can be obtained. Second, unlike previous approaches to eyelid tracking, we show that the Online Appearance Models can be used for this purpose. Neither color information nor intensity edges are used by our proposed approach. Moreover, our eyelids tracking does not rely. on any eye feature extraction which may lead to erroneous results whenever the eye feature detector fails. Experiments on real videos show the feasibility and usefulness of the proposed approach.", "paper_title": "Combined head, lips, eyebrows, and eyelids tracking using adaptive appearance models", "paper_id": "WOS:000239560700012"}