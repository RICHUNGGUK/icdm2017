{"auto_keywords": [{"score": 0.044439418729708045, "phrase": "proposed_model"}, {"score": 0.00481495049065317, "phrase": "action_selection"}, {"score": 0.004753194996637899, "phrase": "spatial_memory"}, {"score": 0.0045726187330434025, "phrase": "covert_visual_attention"}, {"score": 0.004513957235071457, "phrase": "parallel_process"}, {"score": 0.004379977556546879, "phrase": "embodied_agent's_action_selection_process"}, {"score": 0.004159446063902181, "phrase": "multiple_covert_attention_hypothesis"}, {"score": 0.004053362743156545, "phrase": "concurrent_search"}, {"score": 0.0040186038781533946, "phrase": "multiple_objects"}, {"score": 0.003967021436047945, "phrase": "embodied_agent's_visual_field"}, {"score": 0.003865826699096508, "phrase": "active_vision_approach"}, {"score": 0.003767203575060969, "phrase": "action_selection_process"}, {"score": 0.0036395944934310524, "phrase": "visual_attention"}, {"score": 0.003592859432554987, "phrase": "by-need_way"}, {"score": 0.0035162927451540065, "phrase": "multiple_focuses"}, {"score": 0.0032398798149196432, "phrase": "proper_handling"}, {"score": 0.0031982609080278643, "phrase": "speed-accuracy_trade-off"}, {"score": 0.003037047249598515, "phrase": "global_spatiotemporal_visual_attention_policy"}, {"score": 0.002810292047426252, "phrase": "underlying_mechanisms"}, {"score": 0.0027150087516999047, "phrase": "well_known_formalism"}, {"score": 0.0026456667695073043, "phrase": "collective_foraging_strategies"}, {"score": 0.002622947550220266, "phrase": "social_insects"}, {"score": 0.0023650305205893353, "phrase": "parallel_visual_attention"}, {"score": 0.002294686545883412, "phrase": "experimental_results"}, {"score": 0.0022651818270925704, "phrase": "simulated_robot"}, {"score": 0.0022457226013538343, "phrase": "local_navigation"}, {"score": 0.002150900082318562, "phrase": "accurate_visual_attention"}, {"score": 0.002132420504803564, "phrase": "spatial_memories"}, {"score": 0.0021049977753042253, "phrase": "parsimonious_and_robust_way"}], "paper_keywords": ["Swarm cognition", " active vision", " visual attention", " action selection", " artificial life", " autonomous robots"], "paper_abstract": "This article reports a study on modeling covert visual attention as a parallel process that unfolds in synergy with the embodied agent's action selection process. The parallel nature of the proposed model is according to the multiple covert attention hypothesis and thus suitable for the concurrent search for multiple objects in the embodied agent's visual field. In line with the active vision approach, the interaction with the action selection process is exploited by the model to deploy visual attention in a by-need way. Additionally, the multiple focuses of attention considered in the proposed model interact in a way that their collective behavior robustly self-organizes for a proper handling of the speed-accuracy trade-off inherent to visual search tasks. Besides the self-organization of a global spatiotemporal visual attention policy, the model also produces parallel, sparse, and active spatial working memories, that is, local maps of the environment. The underlying mechanisms of the model are based on the well known formalism that describes the self-organization of collective foraging strategies in social insects. This metaphor is particularly interesting because of its similarities with the problem tackled in this article, that is, the one of parallel visual attention. This claim is validated by experimental results on a simulated robot performing local navigation, where the ability of the model to generate accurate visual attention and spatial memories in a parsimonious and robust way is shown.", "paper_title": "A swarm cognition realization of attention, action selection, and spatial memory", "paper_id": "WOS:000284206600004"}