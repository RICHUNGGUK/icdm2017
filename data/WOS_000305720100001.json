{"auto_keywords": [{"score": 0.036081868869661735, "phrase": "human_and_nonhuman_agents"}, {"score": 0.00481495049065317, "phrase": "first-line_defaults"}, {"score": 0.004765482708043842, "phrase": "second-line_conceptualization"}, {"score": 0.004456044928556639, "phrase": "previous_research"}, {"score": 0.004275650416511604, "phrase": "human_and_nonhuman_intelligence"}, {"score": 0.004039423410198574, "phrase": "intentional_goal-directed_behaviors"}, {"score": 0.0038758293658651237, "phrase": "present_study"}, {"score": 0.003201018846103988, "phrase": "five_scenarios"}, {"score": 0.0031032109441552287, "phrase": "intentional_and_nonintentional_actions"}, {"score": 0.0025625729433234623, "phrase": "short-response_time_participants"}, {"score": 0.0025100713447593773, "phrase": "first-line_default"}, {"score": 0.0024586427394152196, "phrase": "human_intentionality"}, {"score": 0.002310578855290687, "phrase": "deeper_second-line_reasoning"}, {"score": 0.0021714122348552747, "phrase": "human_agent"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Human-robot interaction", " Theory of mind"], "paper_abstract": "In the previous research, we demonstrated that people distinguish between human and nonhuman intelligence by assuming that humans are more likely to engage in intentional goal-directed behaviors than computers or robots. In the present study, we tested whether participants who respond relatively quickly when making predictions about an entity are more or less likely to distinguish between human and nonhuman agents on the dimension of intentionality. Participants responded to a series of five scenarios in which they chose between intentional and nonintentional actions for a human, a computer, and a robot. Results indicated that participants who chose quickly were more likely to distinguish human and nonhuman agents than participants who deliberated more over their responses. We suggest that the short-response time participants were employing a first-line default to distinguish between human intentionality and more mechanical nonhuman behavior, and that the slower, more deliberative participants engaged in deeper second-line reasoning that led them to change their predictions for the behavior of a human agent. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Distinguishing first-line defaults and second-line conceptualization in reasoning about humans, robots, and computers", "paper_id": "WOS:000305720100001"}