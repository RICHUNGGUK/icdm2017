{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "affective_analysis"}, {"score": 0.04019924384798349, "phrase": "spatial_features"}, {"score": 0.004686963264680882, "phrase": "video_classification"}, {"score": 0.004541918674719973, "phrase": "video_contents"}, {"score": 0.004226949670141375, "phrase": "novel_method"}, {"score": 0.0040050835356293365, "phrase": "facial_expression_recognition"}, {"score": 0.0038810583785936505, "phrase": "spatio-temporal_features"}, {"score": 0.0037608593980593035, "phrase": "haar-like_features"}, {"score": 0.0036443694410100507, "phrase": "features'_correlation"}, {"score": 0.003563370084662192, "phrase": "mid_classifier"}, {"score": 0.0034220655476652683, "phrase": "improved_adaboost_learning_algorithm"}, {"score": 0.0033160345607565565, "phrase": "temporal_feature_fusion"}, {"score": 0.0031559919178954644, "phrase": "time_dimension_variable"}, {"score": 0.0030171910207671205, "phrase": "facial_expressions"}, {"score": 0.00295008998986066, "phrase": "cohn-kanada_database_show"}, {"score": 0.0028586409810976367, "phrase": "promising_performance"}, {"score": 0.002820319063320601, "phrase": "viewers'_changing_facial_expressions"}, {"score": 0.0025892330566358503, "phrase": "affective_curves"}, {"score": 0.0025202582748972122, "phrase": "affection_changes"}, {"score": 0.002398529964696261, "phrase": "affective_sections"}, {"score": 0.0023033100935570755, "phrase": "recommendation_scores"}, {"score": 0.002282667669149476, "phrase": "experimental_results"}, {"score": 0.00216263228969761, "phrase": "recommendation_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Video classification", " Segmentation", " Recommendation", " Affective analysis", " Facial expression recognition", " Viewers", " Spatio-temporal feature fusion"], "paper_abstract": "Most previous works on video classification and recommendation were only based on video contents, without considering the affective analysis of viewers. In this paper, we presented a novel method to classify and recommend videos based on affective analysis, mainly on facial expression recognition of viewers, by fusing the spatio-temporal features. For spatial features, we integrate Haar-like features into compositional ones according to the features' correlation, and train a mid classifier. Then this process is embedded into the improved AdaBoost learning algorithm to obtain spatial features. And for temporal feature fusion, we adopt HDCRFs based on HCRFs by introducing a time dimension variable. The spatial features are embedded into HDCRFs to recognize facial expressions. Experiments on the Cohn-Kanada database show that the proposed method has a promising performance. Then viewers' changing facial expressions are collected frame by frame from the camera when they are watching videos. Finally, we draw affective curves which tell the process of affection changes. Through the curves, we segment each video into affective sections, classify videos into categories, and list recommendation scores. Experimental results on our collected database show that most subjects are satisfied with the classification and recommendation results. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Video classification and recommendation based on affective analysis of viewers", "paper_id": "WOS:000323851800014"}