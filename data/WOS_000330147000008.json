{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "time"}, {"score": 0.00457553517865013, "phrase": "conditional_mutual_information"}, {"score": 0.004483120978156604, "phrase": "variable_selection"}, {"score": 0.0040481944502103505, "phrase": "correlation_measures"}, {"score": 0.003807684498435389, "phrase": "proposed_algorithm"}, {"score": 0.0037307208089736835, "phrase": "exhaustive_exploration"}, {"score": 0.0036553070575015344, "phrase": "variable_subsets"}, {"score": 0.003581412258960711, "phrase": "real_data"}, {"score": 0.002718045523483502, "phrase": "discrete_data"}, {"score": 0.0026359661683151006, "phrase": "limited_number"}, {"score": 0.002453934333239467, "phrase": "medical_diagnostic_support"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Variable selection", " Conditional mutual information", " Discrete data", " Parallel algorithm"], "paper_abstract": "An algorithm is proposed for calculating correlation measures based on entropy. The proposed algorithm allows exhaustive exploration of variable subsets on real data. Its time efficiency is demonstrated by comparison against three other variable selection methods based on entropy using 8 data sets from various domains as well as simulated data. The method is applicable to discrete data with a limited number of values making it suitable for medical diagnostic support, DNA sequence analysis, psychometry and other domains. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Time-efficient estimation of conditional mutual information for variable selection in classification", "paper_id": "WOS:000330147000008"}