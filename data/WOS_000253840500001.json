{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "binary_translation"}, {"score": 0.049651030276363105, "phrase": "hardware_acceleration"}, {"score": 0.04307870925848092, "phrase": "source_level"}, {"score": 0.03718034097391593, "phrase": "memory_accesses"}, {"score": 0.0047292449487169345, "phrase": "multimedia_and_dsp_applications"}, {"score": 0.004521566043596533, "phrase": "application-specific_hardware"}, {"score": 0.004401342842183475, "phrase": "speculative_loop_pipelining_technique"}, {"score": 0.003916098498242888, "phrase": "popular_processors"}, {"score": 0.0037608593980593035, "phrase": "translated_code"}, {"score": 0.0034529760173586583, "phrase": "pipeline_parallelism"}, {"score": 0.0034220655476652683, "phrase": "memory_optimization_techniques"}, {"score": 0.0033914308417007316, "phrase": "perfect_dependence_information"}, {"score": 0.003198860258228543, "phrase": "binary_level"}, {"score": 0.0030307927228223883, "phrase": "memory_dependence_speculation"}, {"score": 0.002897482096228207, "phrase": "small_dependence_analysis_code"}, {"score": 0.0028076592725295646, "phrase": "runtime_values"}, {"score": 0.0027452053065200152, "phrase": "large_amount"}, {"score": 0.0026362590493392785, "phrase": "user_annotation"}, {"score": 0.0026009105281485888, "phrase": "experimental_results"}, {"score": 0.0025660347613972573, "phrase": "promising_speedup"}, {"score": 0.0023770362063833903, "phrase": "pipeline_fashion"}, {"score": 0.0023451553255837317, "phrase": "conservative_memory_analysis"}, {"score": 0.0022419349154472806, "phrase": "hardware_level_implementation"}, {"score": 0.0022218413146898887, "phrase": "fpga_devices"}, {"score": 0.0021920373388760314, "phrase": "comparable_clock_frequency"}, {"score": 0.0021723899772112423, "phrase": "power_consumption"}, {"score": 0.0021336208506092173, "phrase": "conservative_method"}, {"score": 0.0021049977753042253, "phrase": "significant_improvement"}], "paper_keywords": ["binary translation", " loop pipelining", " memory optimization", " reconfigurable computing"], "paper_abstract": "Multimedia and DSP applications have several computationally intensive kernels which are often offloaded and accelerated by application-specific hardware. This paper presents a speculative loop pipelining technique to overcome limitations of binary translation for hardware acceleration. Although many compilers have been developed at source level, it is desirable to translate the binary targeted to popular processors onto hardware for several practical benefits. However, the translated code can be less optimized. In particular, it is difficult to optimize memory accesses on binary to exploit pipeline parallelism since memory optimization techniques require perfect dependence information for correctness and efficiency. This information is not often available at binary level or even at the source level. Our technique synthesizes the pipeline with memory dependence speculation and postpones some phases of compilation by generating a small dependence analysis code or logic which makes use of runtime values. Such speculative optimization achieves the large amount of parallelism and does not depend on any user annotation. The experimental results show a promising speedup of up to 2.53 compared with the code in which memory accesses are not optimized in the pipeline fashion due to conservative memory analysis. In addition, we have evaluated our technique at hardware level implementation on FPGA devices and achieved comparable clock frequency and power consumption compared to a conservative method while achieving significant improvement in throughput.", "paper_title": "Speculative loop-pipelining in binary translation for hardware acceleration", "paper_id": "WOS:000253840500001"}