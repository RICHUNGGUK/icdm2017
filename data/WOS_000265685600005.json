{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "hmm_decoding"}, {"score": 0.004722898398399427, "phrase": "sequence_repetitions"}, {"score": 0.004544016163767266, "phrase": "dynamic_program_algorithms"}, {"score": 0.0043718794256931435, "phrase": "discrete_time-independent_hmms"}, {"score": 0.004222515162635615, "phrase": "viterbi's_decoding"}, {"score": 0.004190019394361629, "phrase": "training_algorithms"}, {"score": 0.0036038701178581403, "phrase": "repeated_substrings"}, {"score": 0.003562322256892338, "phrase": "observed_input_sequence"}, {"score": 0.0034008496666026585, "phrase": "sufficiently_small_substrings"}, {"score": 0.00317221667574882, "phrase": "run_length_encoding"}, {"score": 0.0031114800025365498, "phrase": "lempel-ziv"}, {"score": 0.0028356575042385156, "phrase": "viterbi's_algorithm"}, {"score": 0.0025445540632724893, "phrase": "slp"}, {"score": 0.0024861483053751476, "phrase": "bpe"}, {"score": 0.002410363090950055, "phrase": "hidden_states"}, {"score": 0.0023368833197343953, "phrase": "observed_sequence"}, {"score": 0.002265638487492082, "phrase": "compression_scheme"}, {"score": 0.0021213575697367148, "phrase": "parallel_implementation"}], "paper_keywords": ["HMM", " Viterbi", " Dynamic programming", " Compression"], "paper_abstract": "We present a method to speed up the dynamic program algorithms used for solving the HMM decoding and training problems for discrete time-independent HMMs. We discuss the application of our method to Viterbi's decoding and training algorithms (IEEE Trans. Inform. Theory IT-13: 260-269, 1967), as well as to the forward-backward and Baum-Welch ( Inequalities 3: 1-8, 1972) algorithms. Our approach is based on identifying repeated substrings in the observed input sequence. Initially, we show how to exploit repetitions of all sufficiently small substrings ( this is similar to the Four Russians method). Then, we describe four algorithms based alternatively on run length encoding (RLE), Lempel-Ziv (LZ78) parsing, grammar-based compression (SLP), and byte pair encoding (BPE). Compared to Viterbi's algorithm, we achieve speedups of Theta( log n) using the Four Russians method, Omega(r/log r) using RLE, Omega(log n/k) using LZ78, Omega(r/k) using SLP, and Omega(r) using BPE, where k is the number of hidden states, n is the length of the observed sequence and r is its compression ratio (under each compression scheme). Our experimental results demonstrate that our new algorithms are indeed faster in practice. We also discuss a parallel implementation of our algorithms.", "paper_title": "Speeding Up HMM Decoding and Training by Exploiting Sequence Repetitions", "paper_id": "WOS:000265685600005"}