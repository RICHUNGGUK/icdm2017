{"auto_keywords": [{"score": 0.03203766879664709, "phrase": "scc"}, {"score": 0.013235095980088294, "phrase": "classification_learning"}, {"score": 0.00481495049065317, "phrase": "traditional_pattern_recognition"}, {"score": 0.004596960835906736, "phrase": "class_information"}, {"score": 0.0043215158337835706, "phrase": "single_framework"}, {"score": 0.004271729935895193, "phrase": "important_problem"}, {"score": 0.0040002088320302935, "phrase": "sequential_or_two-step_manner"}, {"score": 0.0039085400187964196, "phrase": "clustering_learning"}, {"score": 0.003674192201248236, "phrase": "obtained_structural_information"}, {"score": 0.003534889186471058, "phrase": "simultaneous_optimality"}, {"score": 0.003284550970221379, "phrase": "subsequent_classification_learning"}, {"score": 0.0030994630902300133, "phrase": "simultaneous_learning_framework"}, {"score": 0.0028138046006772567, "phrase": "robust_classification"}, {"score": 0.002707033618304716, "phrase": "effective_and_transparent_classification_mechanism"}, {"score": 0.0026347074232350503, "phrase": "underlying_relationship"}, {"score": 0.0025151755329660837, "phrase": "bayesian_theory"}, {"score": 0.002486147565139633, "phrase": "cluster_posterior_probabilities"}, {"score": 0.002419708657850547, "phrase": "single_objective_function"}, {"score": 0.002382541887825168, "phrase": "clustering_process"}, {"score": 0.0023099082804523044, "phrase": "objective_function"}, {"score": 0.002283243905993669, "phrase": "effective_and_robust_clustering"}, {"score": 0.0022136307563123256, "phrase": "experimental_results"}], "paper_keywords": ["Structure in data", " Bayesian theory", " Clustering learning", " Classification learning", " Simultaneous classification and clustering learning"], "paper_abstract": "Traditional pattern recognition generally involves two tasks: unsupervised clustering and supervised classification. When class information is available, fusing the advantages of both clustering learning and classification learning into a single framework is an important problem worthy of study. To date, most algorithms generally treat clustering learning and classification learning in a sequential or two-step manner, i.e., first execute clustering learning to explore structures in data, and then perform classification learning on top of the obtained Structural information. However, such sequential algorithms cannot always guarantee the simultaneous optimality for both clustering and classification learning. In fact, the clustering learning in these algorithms just aids the subsequent classification learning and does not benefit from the latter. To overcome this problem, a simultaneous learning framework for clustering and classification (SCC) is presented in this paper. SCC aims to achieve three goals: (1) acquiring the robust classification and clustering simultaneously; (2) designing an effective and transparent classification mechanism: (3) revealing the underlying relationship between clusters and classes. To this end, with the Bayesian theory and the cluster posterior probabilities of classes, we define a single objective function to which the clustering process is directly embedded. By optimizing this objective function, the effective and robust clustering and classification results are achieved simultaneously. Experimental results on both synthetic and real-life datasets show that SCC achieves promising classification and clustering results at one time. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "A simultaneous learning framework for clustering and classification", "paper_id": "WOS:000265365500005"}