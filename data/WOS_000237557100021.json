{"auto_keywords": [{"score": 0.04897776997473009, "phrase": "bayesian_inference"}, {"score": 0.00481495049065317, "phrase": "efficient_combinatorial_optimization"}, {"score": 0.00475924837336259, "phrase": "graph_cuts"}, {"score": 0.004622783000449884, "phrase": "powerful_framework"}, {"score": 0.00451642066363115, "phrase": "statistically_learned_prior_knowledge"}, {"score": 0.004464156619275582, "phrase": "numerous_computer_vision_algorithms"}, {"score": 0.004361428012479218, "phrase": "bayesian_approach"}, {"score": 0.004187284711626886, "phrase": "markov_random_field_literature"}, {"score": 0.004114787982556699, "phrase": "resulting_combinatorial_optimization_problems"}, {"score": 0.003973523379376352, "phrase": "rather_inefficient_and_inexact_general_purpose_optimization_methods"}, {"score": 0.003904713104101532, "phrase": "simulated_annealing"}, {"score": 0.003726967166630923, "phrase": "global_optima"}, {"score": 0.0036411406244705557, "phrase": "cost_functions"}, {"score": 0.00357806560856829, "phrase": "binary-valued_variables"}, {"score": 0.0034956560177000656, "phrase": "graph_min-cuts"}, {"score": 0.0032406665327678616, "phrase": "statistical_learning"}, {"score": 0.0031111332159761344, "phrase": "efficient_optimization_schemes"}, {"score": 0.0029349892964423197, "phrase": "prior_information"}, {"score": 0.0027687904688616983, "phrase": "graph_cut_optimization"}, {"score": 0.0026119782818898193, "phrase": "prior_knowledge"}, {"score": 0.0022974765563692776, "phrase": "binary_textures"}, {"score": 0.0021049977753042253, "phrase": "statistically_learned_constraints"}], "paper_keywords": [""], "paper_abstract": "Bayesian inference provides a powerful framework to optimally integrate statistically learned prior knowledge into numerous computer vision algorithms. While the Bayesian approach has been successfully applied in the Markov random field literature, the resulting combinatorial optimization problems have been commonly treated with rather inefficient and inexact general purpose optimization methods such as Simulated Annealing. An efficient method to compute the global optima of certain classes of cost functions defined on binary-valued variables is given by graph min-cuts. In this paper, we propose to reconsider the problem of statistical learning for Bayesian inference in the context of efficient optimization schemes. Specifically, we address the question: Which prior information may be learned while retaining the ability to apply Graph Cut optimization? We provide a framework to learn and impose prior knowledge on the distribution of pairs and triplets of labels. As an illustration, we demonstrate that one can optimally restore binary textures from very noisy images with run-times on the order of a second while imposing hundreds of statistically learned constraints per pixel.", "paper_title": "Statistical priors for efficient combinatorial optimization via graph cuts", "paper_id": "WOS:000237557100021"}