{"auto_keywords": [{"score": 0.034722317120626484, "phrase": "vdd"}, {"score": 0.006052751550702505, "phrase": "dpcs"}, {"score": 0.00481495049065317, "phrase": "sram_caches"}, {"score": 0.0047520359450626565, "phrase": "spcs"}, {"score": 0.004475893575036647, "phrase": "nanoscale_process_variation"}, {"score": 0.004441616106463486, "phrase": "complex_ftvs_schemes"}, {"score": 0.0042250952759280225, "phrase": "high_overheads"}, {"score": 0.0039729853486821995, "phrase": "\"fault_inclusion_property"}, {"score": 0.003912335018240945, "phrase": "lightweight_fault_maps"}, {"score": 0.0038674532861321864, "phrase": "multiple_runtime_supply_voltages"}, {"score": 0.0037215192436590772, "phrase": "simple_and_low-overhead_ftvs_cache_architecture"}, {"score": 0.003608732492631878, "phrase": "multilevel_voltage"}, {"score": 0.0035673211706948576, "phrase": "optional_architectural_support"}, {"score": 0.0035399770257915466, "phrase": "power_gating"}, {"score": 0.0034326732528567826, "phrase": "low_voltages"}, {"score": 0.0033030907500120397, "phrase": "runtime_cache"}, {"score": 0.002886771283377607, "phrase": "cache_voltage"}, {"score": 0.002788454815865172, "phrase": "lower_static_power"}, {"score": 0.0027564303939865476, "phrase": "effective_cache_capacities"}, {"score": 0.0027247727563746694, "phrase": "recent_more_complex_ftvs_scheme"}, {"score": 0.002662541169311738, "phrase": "significantly_lower_overheads"}, {"score": 0.002532526438148958, "phrase": "competing_work"}, {"score": 0.0025034338848015166, "phrase": "fixed_target"}, {"score": 0.0023903596069939953, "phrase": "average_total_cache"}, {"score": 0.0022302306304023602, "phrase": "roughly_similar_energy_reduction"}, {"score": 0.0021376902861998865, "phrase": "dpcs_approaches"}], "paper_keywords": ["Design", " Performance", " Reliability"], "paper_abstract": "Fault-Tolerant Voltage-Scalable (FTVS) SRAM cache architectures are a promising approach to improve energy efficiency of memories in the presence of nanoscale process variation. Complex FTVS schemes are commonly proposed to achieve very low minimum supply voltages, but these can suffer from high overheads and thus do not always offer the best power/capacity trade-offs. We observe on our 45nm test chips that the \"fault inclusion property\" can enable lightweight fault maps that support multiple runtime supply voltages. Based on this observation, we propose a simple and low-overhead FTVS cache architecture for power/capacity scaling. Our mechanism combines multilevel voltage scaling with optional architectural support for power gating of blocks as they become faulty at low voltages. A static (SPCS) policy sets the runtime cache VDD once such that a only a few cache blocks may be faulty in order to minimize the impact on performance. We describe a Static Power/Capacity Scaling (SPCS) policy and two alternate Dynamic Power/Capacity Scaling (DPCS) policies that opportunistically reduce the cache voltage even further for more energy savings. This architecture achieves lower static power for all effective cache capacities than a recent more complex FTVS scheme. This is due to significantly lower overheads, despite the inability of our approach to match the min-VDD of the competing work at a fixed target yield. Over a set of SPEC CPU2006 benchmarks on two system configurations, the average total cache (system) energy saved by SPCS is 62% (22%), while the two DPCS policies achieve roughly similar energy reduction, around 79% (26%). On average, the DPCS approaches incur 2.24% performance and 6% area penalties.", "paper_title": "DPCS: Dynamic Power/Capacity Scaling for SRAM Caches in the Nanoscale Era", "paper_id": "WOS:000363004100002"}