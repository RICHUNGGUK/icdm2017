{"auto_keywords": [{"score": 0.04957680050135306, "phrase": "web_databases"}, {"score": 0.04160367592541749, "phrase": "similarity_model"}, {"score": 0.03644451033122438, "phrase": "ranking_functions"}, {"score": 0.004814964793316524, "phrase": "personalized"}, {"score": 0.004664983066310498, "phrase": "appropriate_workload"}, {"score": 0.004567596860086148, "phrase": "deep_web"}, {"score": 0.0045037997020733415, "phrase": "new_connotation"}, {"score": 0.004425299304063172, "phrase": "ranking_database_query_results"}, {"score": 0.004242411872706126, "phrase": "database_values"}, {"score": 0.0042126709243529275, "phrase": "query_logs"}, {"score": 0.004168448339217754, "phrase": "user_profiles"}, {"score": 0.004081385289516914, "phrase": "integrated_approach"}, {"score": 0.0038715697646612766, "phrase": "query-dependent_ranking"}, {"score": 0.0037906837773782, "phrase": "telang_et_al"}, {"score": 0.0037508743235608872, "phrase": "ieee_transactions"}, {"score": 0.0035705347414368696, "phrase": "important_component"}, {"score": 0.0033749889869455407, "phrase": "individual_user's_preferences"}, {"score": 0.0033044432971036652, "phrase": "specific_query"}, {"score": 0.0031677308747058187, "phrase": "prior_ranking_function"}, {"score": 0.0030153435879168634, "phrase": "good_quality"}, {"score": 0.002941913249957503, "phrase": "ranking_function"}, {"score": 0.0027417911324611917, "phrase": "appropriate_set"}, {"score": 0.0027225413530200505, "phrase": "user-query_pairs"}, {"score": 0.002528379400564723, "phrase": "novel_metric"}, {"score": 0.0024236964502593254, "phrase": "\"good\"_workload"}, {"score": 0.002398208426903865, "phrase": "absolute_value"}, {"score": 0.0023315400785212785, "phrase": "optimal_goodness"}, {"score": 0.0023070189467375374, "phrase": "combinatorially_explosive_problem"}, {"score": 0.0022507989506447413, "phrase": "heuristic_solution"}, {"score": 0.002188219483646592, "phrase": "acceptable_workload"}, {"score": 0.002157583854640276, "phrase": "static_as_well_as_a_dynamic_environment"}], "paper_keywords": ["Ranking", " Web databases", " Similarity model", " Workload"], "paper_abstract": "The emergence of the deep Web has given a new connotation to the concept of ranking database query results. Earlier approaches for ranking either resorted to analyzing frequencies of database values and query logs or establishing user profiles. In contrast, an integrated approach, based on the notion of a similarity model, for holistically supporting user- and query-dependent ranking has been recently proposed (Telang et al. in IEEE Transactions on Knowledge and Data Engineering (TKDE), 2011). An important component of this framework is a workload consisting of ranking functions, wherein each function represents an individual user's preferences towards the results of a specific query. At the time of answering a query for which no prior ranking function exists, the similarity model is employed, and is expected to ensure a good quality of ranking as long as a ranking function for a very similar user-query pair exists in this workload. In this paper, we address the problem of determining an appropriate set of user-query pairs to form a workload of ranking functions to support user- and query-dependent ranking for Web databases. We propose a novel metric, termed workload goodness, that quantifies the notion of a \"good\" workload into an absolute value. The process of finding such a workload of optimal goodness is a combinatorially explosive problem; therefore, we propose a heuristic solution, and advance three approaches for determining an acceptable workload, in a static as well as a dynamic environment. We discuss the effectiveness of our proposal analytically as well as experimentally over two Web databases.", "paper_title": "Personalized ranking in web databases: establishing and utilizing an appropriate workload", "paper_id": "WOS:000312716700002"}