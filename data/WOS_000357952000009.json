{"auto_keywords": [{"score": 0.039493331760101814, "phrase": "shared_llc"}, {"score": 0.015566631018521397, "phrase": "chip_multiprocessors"}, {"score": 0.004720606036240263, "phrase": "power_management"}, {"score": 0.0046741260449047976, "phrase": "large_last-level_caches"}, {"score": 0.004361276005140776, "phrase": "leakage_power"}, {"score": 0.0042336638794732255, "phrase": "significant_fraction"}, {"score": 0.0038919354605673104, "phrase": "entire_cache"}, {"score": 0.003507504253087326, "phrase": "different_design_choices"}, {"score": 0.003455765987713262, "phrase": "circuit-level_cache_organization"}, {"score": 0.0033050703534275717, "phrase": "low-overhead_runtime_mechanism"}, {"score": 0.0031609254971443888, "phrase": "llc."}, {"score": 0.00308357048262018, "phrase": "slice-based_cache_organization"}, {"score": 0.0029344771385297137, "phrase": "minimal_circuit_overhead"}, {"score": 0.002862648127577722, "phrase": "slice-based_organization"}, {"score": 0.0026839922027139967, "phrase": "spatial_and_temporal_cache_access_behavior"}, {"score": 0.0026443691099806003, "phrase": "low-overhead_sampling-based_hardware"}, {"score": 0.0025541693207036167, "phrase": "performance_penalties"}, {"score": 0.002442693254693416, "phrase": "cache_slice"}, {"score": 0.002394719113232821, "phrase": "data_migration_policies"}, {"score": 0.0023245146355917626, "phrase": "useful_data"}, {"score": 0.0022901862321082407, "phrase": "llc._results"}, {"score": 0.002234092591045251, "phrase": "eecache"}, {"score": 0.002147180332779021, "phrase": "negligible_hardware"}, {"score": 0.0021049977753042253, "phrase": "prior_work"}], "paper_keywords": ["Cache Memories", " Cache", " power management", " energy efficiency"], "paper_abstract": "Power management for large last-level caches (LLCs) is important in chip multiprocessors (CMPs), as the leakage power of LLCs accounts for a significant fraction of the limited on-chip power budget. Since not all workloads running on CMPs need the entire cache, portions of a large, shared LLC can be disabled to save energy. In this article, we explore different design choices, from circuit-level cache organization to microarchitectural management policies, to propose a low-overhead runtime mechanism for energy reduction in the large, shared LLC. We first introduce a slice-based cache organization that can shut down parts of the shared LLC with minimal circuit overhead. Based on this slice-based organization, part of the shared LLC can be turned off according to the spatial and temporal cache access behavior captured by low-overhead sampling-based hardware. In order to eliminate the performance penalties caused by flushing data before powering off a cache slice, we propose data migration policies to prevent the loss of useful data in the LLC. Results show that our energy-efficient cache design (EECache) provides 14.1% energy savings at only 1.2% performance degradation and consumes negligible hardware overhead compared to prior work.", "paper_title": "EECache: A Comprehensive Study on the Architectural Design for Energy-Efficient Last-Level Caches in Chip Multiprocessors", "paper_id": "WOS:000357952000009"}