{"auto_keywords": [{"score": 0.034829431648831774, "phrase": "implementation_structure"}, {"score": 0.0063405360272074445, "phrase": "representational_cognition"}, {"score": 0.00481495049065317, "phrase": "higher-order_adaptation"}, {"score": 0.00443141503046841, "phrase": "artificial_approximations"}, {"score": 0.004398094237005956, "phrase": "cognitive_evolution"}, {"score": 0.003956971099850658, "phrase": "representational_solutions"}, {"score": 0.0036830211726031946, "phrase": "second_order"}, {"score": 0.003627800727103479, "phrase": "causal_factors"}, {"score": 0.0035599338383885447, "phrase": "innate_and_acquired_forms"}, {"score": 0.0035467302140644846, "phrase": "simple_changes"}, {"score": 0.00340217066797559, "phrase": "\"black_box\"aeuro\"selection_works"}, {"score": 0.0033765627434550432, "phrase": "externally_visible_behaviour"}, {"score": 0.0030033417337933625, "phrase": "specific_modifications"}, {"score": 0.0027846824619356583, "phrase": "learning_ability"}, {"score": 0.0027325449069867222, "phrase": "direct_selection"}, {"score": 0.0025239898026543964, "phrase": "indirect_selection_effects"}, {"score": 0.002486103638234488, "phrase": "representational_implementations"}, {"score": 0.002458061764297103, "phrase": "structural_alignment"}, {"score": 0.0022194677375148063, "phrase": "computational_investigations"}, {"score": 0.0021049977753042253, "phrase": "purely_connectionist_ai."}], "paper_keywords": ["Representation", " Connectionism", " Second order learning", " Evolution of learning", " Evolution of mind", " Cognitive map"], "paper_abstract": "A theory of the evolution of mind cannot be complete without an explanation of how cognition became representational. Artificial approximations of cognitive evolution do not, in general, produce representational cognition. We take this as an indication that there is a gap in our understanding of what drives evolution towards representational solutions, and propose a theory to fill this gap. We suggest selection for learning and selection for second order learning as the causal factors driving the emergence of innate and acquired forms of representation, respectively. Cognition is commonly viewed as a \"black box\"aEuro\"selection works on externally visible behaviour alone, with little regard for implementation structure. Yet even if implementation structure is not constrained by selection on behaviour, implementation structure does affect how easy or difficult it is to make specific modifications to the behaviour. Hence selection for learning can affect the implementation structure of behaviour. Similarly, the implementation structure of learning ability itself is not under direct selection, but selection for second order learning can affect the implementation structure of first order learning. We argue that these indirect selection effects guide evolution towards representational implementations, as structural alignment between implementation structure and environment structure guarantees that simple changes in the environment can be met with simple changes in implementation. We illustrate the theory with examples of computational investigations, and discuss how the theory may help put representational cognition within reach of purely connectionist AI.", "paper_title": "Selection for Representation in Higher-Order Adaptation", "paper_id": "WOS:000350992600005"}