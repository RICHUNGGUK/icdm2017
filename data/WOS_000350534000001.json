{"auto_keywords": [{"score": 0.04407253113473033, "phrase": "elm"}, {"score": 0.00481495049065317, "phrase": "extreme_learning_machine"}, {"score": 0.004645057834614705, "phrase": "new_learning_framework"}, {"score": 0.004574085781766281, "phrase": "increasing_attractions"}, {"score": 0.004458189822972851, "phrase": "large-scale_computing"}, {"score": 0.004412654209742722, "phrase": "high-speed_signal_processing"}, {"score": 0.0040438338011467845, "phrase": "conventional_artificial_learning_techniques"}, {"score": 0.004002513373645485, "phrase": "biological_learning_mechanism"}, {"score": 0.0038810583785936505, "phrase": "machine_learning_techniques"}, {"score": 0.0038217146888983576, "phrase": "hidden_neurons"}, {"score": 0.00368673793612343, "phrase": "elm_theories"}, {"score": 0.0035932440062595252, "phrase": "\"random_hidden_neurons"}, {"score": 0.0034663083890589235, "phrase": "brain_learning_mechanisms"}, {"score": 0.003378385493203297, "phrase": "intuitive_sense"}, {"score": 0.003292685392413911, "phrase": "brain_learning"}, {"score": 0.003209152260950748, "phrase": "computing_power"}, {"score": 0.0030798711656591948, "phrase": "traditional_neural_networks"}, {"score": 0.003048370487544551, "phrase": "support_vector_machine"}, {"score": 0.002986329509791943, "phrase": "significant_advantages"}, {"score": 0.002940626369102927, "phrase": "fast_learning_speed"}, {"score": 0.002456272788591051, "phrase": "newly_derived_elm_theories"}, {"score": 0.0023331227492950422, "phrase": "ongoing_development"}, {"score": 0.002309242063033298, "phrase": "multilayer_feature_representation"}, {"score": 0.0022738775158524793, "phrase": "new_trends"}, {"score": 0.002250601866422547, "phrase": "elm-based_hierarchical_learning"}, {"score": 0.0021049977753042253, "phrase": "practical_advances"}], "paper_keywords": ["extreme learning machine", " fast learning", " high-speed and real-time signal processing", " large-scale computing", " big-data", " feature representation"], "paper_abstract": "Extreme learning machine (ELM), as a new learning framework, draws increasing attractions in the areas of large-scale computing, high-speed signal processing, artificial intelligence, and so on. ELM aims to break the barriers between the conventional artificial learning techniques and biological learning mechanism and represents a suite of machine learning techniques in which hidden neurons need not to be tuned. ELM theories and algorithms argue that \"random hidden neurons\" capture the essence of some brain learning mechanisms as well as the intuitive sense that the efficiency of brain learning need not rely on computing power of neurons. Thus, compared with traditional neural networks and support vector machine, ELM offers significant advantages such as fast learning speed, ease of implementation, and minimal human intervention. Due to its remarkable generalization performance and implementation efficiency, ELM has been applied in various applications. In this paper, we first provide an overview of newly derived ELM theories and approaches. On the other hand, with the ongoing development of multilayer feature representation, some new trends on ELM-based hierarchical learning are discussed. Moreover, we also present several interesting ELM applications to showcase the practical advances on this subject.", "paper_title": "Extreme learning machines: new trends and applications", "paper_id": "WOS:000350534000001"}