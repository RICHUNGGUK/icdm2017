{"auto_keywords": [{"score": 0.0491582995931868, "phrase": "derivative-free_optimization"}, {"score": 0.04616596452507493, "phrase": "objective_function"}, {"score": 0.027559932969777202, "phrase": "hessian"}, {"score": 0.00481495049065317, "phrase": "sparse_low_degree_interpolating_polynomials"}, {"score": 0.00468656988857138, "phrase": "interpolation-based_trust-region_methods"}, {"score": 0.004388796812234033, "phrase": "quadratic_polynomial_interpolation_models"}, {"score": 0.0042388570312522, "phrase": "basis_components"}, {"score": 0.00415777266387528, "phrase": "practical_applications"}, {"score": 0.003789561910103601, "phrase": "smooth_case"}, {"score": 0.0036884198249734863, "phrase": "hessian_matrix"}, {"score": 0.0035899674590142653, "phrase": "hessian_sparsity"}, {"score": 0.003562322256892338, "phrase": "existing_optimization_approaches"}, {"score": 0.0034806529881619454, "phrase": "sparsity_structure"}, {"score": 0.0032718761046588835, "phrase": "sparse_models"}, {"score": 0.0031968441980848436, "phrase": "sparse_recovery_theory"}, {"score": 0.0030283730114326014, "phrase": "sparse_vector"}, {"score": 0.002792119634261638, "phrase": "measurements_constraints"}, {"score": 0.002707033618304716, "phrase": "sparse_quadratic_polynomial_interpolation_models"}, {"score": 0.002554406040896888, "phrase": "interpolation_conditions"}, {"score": 0.002476546030310661, "phrase": "accurate_models"}, {"score": 0.002391779843744166, "phrase": "relatively_few_randomly_selected_sample_points"}, {"score": 0.00230098581403254, "phrase": "practical_interpolation-based_trust-region_method"}, {"score": 0.0021628142746829187, "phrase": "new_approach"}, {"score": 0.0021378442381693847, "phrase": "promising_numerical_performance"}, {"score": 0.0021049977753042253, "phrase": "general_case"}], "paper_keywords": ["Derivative-free optimization", " Interpolation-based trust-region methods", " Random sampling", " Sparse recovery", " Compressed sensing", " l(1)-Minimization"], "paper_abstract": "Interpolation-based trust-region methods are an important class of algorithms for Derivative-Free Optimization which rely on locally approximating an objective function by quadratic polynomial interpolation models, frequently built from less points than there are basis components. Often, in practical applications, the contribution of the problem variables to the objective function is such that many pairwise correlations between variables are negligible, implying, in the smooth case, a sparse structure in the Hessian matrix. To be able to exploit Hessian sparsity, existing optimization approaches require the knowledge of the sparsity structure. The goal of this paper is to develop and analyze a method where the sparse models are constructed automatically. The sparse recovery theory developed recently in the field of compressed sensing characterizes conditions under which a sparse vector can be accurately recovered from few random measurements. Such a recovery is achieved by minimizing the a\"\" (1)-norm of a vector subject to the measurements constraints. We suggest an approach for building sparse quadratic polynomial interpolation models by minimizing the a\"\" (1)-norm of the entries of the model Hessian subject to the interpolation conditions. We show that this procedure recovers accurate models when the function Hessian is sparse, using relatively few randomly selected sample points. Motivated by this result, we developed a practical interpolation-based trust-region method using deterministic sample sets and minimum a\"\" (1)-norm quadratic models. Our computational results show that the new approach exhibits a promising numerical performance both in the general case and in the sparse one.", "paper_title": "Computation of sparse low degree interpolating polynomials and their application to derivative-free optimization", "paper_id": "WOS:000306493800009"}