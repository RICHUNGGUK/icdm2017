{"auto_keywords": [{"score": 0.038589252731608154, "phrase": "cache_index_bits"}, {"score": 0.035820952656110384, "phrase": "index_bits"}, {"score": 0.00481495049065317, "phrase": "cache_indexing"}, {"score": 0.0047761092701293474, "phrase": "embedded_processors"}, {"score": 0.004737579882204798, "phrase": "cache_performance_optimization"}, {"score": 0.0046803650677267146, "phrase": "important_design_consideration"}, {"score": 0.0046238380150870435, "phrase": "high-performance_embedded_processors"}, {"score": 0.004567990533989851, "phrase": "general-purpose_microprocessors"}, {"score": 0.004422325007817267, "phrase": "application-specific_information"}, {"score": 0.0043512358455892, "phrase": "cache_performance"}, {"score": 0.004212453011596424, "phrase": "modified_cache_index_bits"}, {"score": 0.004161553532799662, "phrase": "conventional_index_bits"}, {"score": 0.004028796143006953, "phrase": "key_target"}, {"score": 0.004012500850311087, "phrase": "embedded_applications"}, {"score": 0.003947973513495612, "phrase": "number_of_conflict_misses"}, {"score": 0.003760527969356061, "phrase": "novel_fine-grained_cache_reconfiguration_technique"}, {"score": 0.003700037700138249, "phrase": "intra-program_reconfiguration"}, {"score": 0.0035819501337406596, "phrase": "changing_characteristics"}, {"score": 0.0035386420095120706, "phrase": "program_execution"}, {"score": 0.003329804436286295, "phrase": "dynamically_changes"}, {"score": 0.0032629585038738856, "phrase": "function_level"}, {"score": 0.003223494720348768, "phrase": "compiler-directed_and_fine-grained_approach"}, {"score": 0.003057910095857785, "phrase": "additional_hardware_support"}, {"score": 0.002984373546099842, "phrase": "potential_performance_degradation"}, {"score": 0.0029602552900111407, "phrase": "frequent_cache_invalidations"}, {"score": 0.002865710140187219, "phrase": "efficient_algorithm"}, {"score": 0.002831037222426215, "phrase": "target_functions"}, {"score": 0.0026638482306228575, "phrase": "drib"}, {"score": 0.0025682999078906936, "phrase": "cache_invalidations"}, {"score": 0.002506507889886399, "phrase": "new_cache_architecture"}, {"score": 0.0024362894621575604, "phrase": "tli"}, {"score": 0.00233936726307301, "phrase": "conflict_misses"}, {"score": 0.0023016843709107297, "phrase": "indexing_steps"}, {"score": 0.0022281257694320433, "phrase": "drip_approach"}, {"score": 0.0021922308351126746, "phrase": "tli_cache"}, {"score": 0.002148172508419683, "phrase": "cache_misses"}, {"score": 0.0021049977753042253, "phrase": "conventional_cache_indexing_technique"}], "paper_keywords": ["cache indexing", " cache organization", " dynamic reconfiguration", " embedded processor", " microprocessor architecture"], "paper_abstract": "Cache performance optimization is an important design consideration in building high-performance embedded processors. Unlike general-purpose microprocessors, embedded processors can take advantages of application-specific information in optimizing the cache performance. One of such examples is to use modified cache index bits (over conventional index bits) based on memory access traces from key target embedded applications so that the number of conflict misses can be reduced. In this paper, we present a novel fine-grained cache reconfiguration technique which allows an intra-program reconfiguration of cache index bits, thus better reflecting the changing characteristics of a program execution. The proposed technique, called dynamic reconfiguration of index bits (DRIB), dynamically changes cache index bits in the function level. This compiler-directed and fine-grained approach allows each function to be executed using its own optimal index, bits with no additional hardware support. In order to avoid potential performance degradation by frequent cache invalidations from reconfiguring cache index bits, we describe an efficient algorithm for selecting target functions whose cache index bits are reconfigured. Our algorithm ensures that the number of cache misses reduced by DRIB outnumbers the number of cache misses increased from cache invalidations. We also propose a new cache architecture, Two-Level Indexing (TLI) cache, which further reduces the number of conflict misses by intelligently dividing indexing steps into two stages. Our experimental results show that the DRIP approach combined with the TLI cache reduces the number of cache misses by 35% over the conventional cache indexing technique.", "paper_title": "Dynamic reconfiguration of cache indexing in embedded processors", "paper_id": "WOS:000245194600003"}