{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "attacker's_estimation_error"}, {"score": 0.004736045157669388, "phrase": "wide_variety"}, {"score": 0.004684157900507474, "phrase": "privacy_metrics"}, {"score": 0.004312622975366672, "phrase": "privacy-enhancing_technologies"}, {"score": 0.004103942174451674, "phrase": "concrete_systems"}, {"score": 0.004058951880810154, "phrase": "adversarial_models"}, {"score": 0.003757480190200645, "phrase": "better_understanding"}, {"score": 0.0036352070472201086, "phrase": "different_privacy_metrics"}, {"score": 0.0033465923623290034, "phrase": "system_designers"}, {"score": 0.0030638704739988595, "phrase": "theoretical_framework"}, {"score": 0.003030247482854539, "phrase": "privacy-preserving_systems"}, {"score": 0.002947790697936243, "phrase": "general_definition"}, {"score": 0.0028360962841331634, "phrase": "estimation_error"}, {"score": 0.0026838147966444783, "phrase": "private_information"}, {"score": 0.00240328454980006, "phrase": "well-known_metrics"}, {"score": 0.002363806685815014, "phrase": "common_perspective"}, {"score": 0.0022368274529152342, "phrase": "fundamental_results"}, {"score": 0.0021049977753042253, "phrase": "bayes_decision"}], "paper_keywords": ["Privacy", " Criteria", " Metrics", " Estimation", " Bayes decision theory", " Statistical disclosure control", " Anonymous communication systems", " Location-based services"], "paper_abstract": "A wide variety of privacy metrics have been proposed in the literature to evaluate the level of protection offered by privacy-enhancing technologies. Most of these metrics are specific to concrete systems and adversarial models and are difficult to generalize or translate to other contexts. Furthermore, a better understanding of the relationships between the different privacy metrics is needed to enable more grounded and systematic approach to measuring privacy, as well as to assist system designers in selecting the most appropriate metric for a given application. In this work, we propose a theoretical framework for privacy-preserving systems, endowed with a general definition of privacy in terms of the estimation error incurred by an attacker who aims to disclose the private information that the system is designed to conceal. We show that our framework permits interpreting and comparing a number of well-known metrics under a common perspective. The arguments behind these interpretations are based on fundamental results related to the theories of information, probability, and Bayes decision.", "paper_title": "On the measurement of privacy as an attacker's estimation error", "paper_id": "WOS:000316025700005"}