{"auto_keywords": [{"score": 0.04888338488077779, "phrase": "classification_system"}, {"score": 0.026072781012005317, "phrase": "different_contexts"}, {"score": 0.00481495049065317, "phrase": "operating_range"}, {"score": 0.003770185129638344, "phrase": "relative_costs"}, {"score": 0.0037070855410818986, "phrase": "different_types"}, {"score": 0.0028293966058473476, "phrase": "operating_characteristic_area"}, {"score": 0.0026222551419772867, "phrase": "clear_picture"}, {"score": 0.002556625752785268, "phrase": "performance_characteristics"}, {"score": 0.002195866991284673, "phrase": "relative_cost"}, {"score": 0.0021049977753042253, "phrase": "wide_range"}], "paper_keywords": [""], "paper_abstract": "The performance of a classification system depends on the context in which it will be used, including the prevalence of the classes and the relative costs of different types of errors. Metrics such as accuracy are limited to the context in which the experiment was originally carried out, and metrics such as sensitivity, specificity, and receiver operating characteristic area while independent of prevalence do not provide a clear picture of the performance characteristics of the system over different contexts. Graphing a prevalence-specific metric such as F-measure or the relative cost of errors over a wide range of prevalence allows a visualization of the performance of the system and a comparison of systems in different contexts.", "paper_title": "Visualizing the operating range of a classification system", "paper_id": "WOS:000306024100007"}