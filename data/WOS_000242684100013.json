{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "boundary_edge_selection"}, {"score": 0.043653872973370686, "phrase": "background_edges"}, {"score": 0.043338468186484846, "phrase": "edge_motion"}, {"score": 0.04119081773848916, "phrase": "boundary_edges"}, {"score": 0.02663449930898407, "phrase": "computed_contour"}, {"score": 0.004689462599037994, "phrase": "accurate_subject_tracking"}, {"score": 0.004584495834677719, "phrase": "subject_boundary_edges"}, {"score": 0.004532892812505505, "phrase": "video_stream"}, {"score": 0.004481868017991508, "phrase": "changing_background"}, {"score": 0.0040171817997972335, "phrase": "previous_step"}, {"score": 0.003882970272082245, "phrase": "normal_direction_derivative"}, {"score": 0.0038392331564122387, "phrase": "tracked_contour"}, {"score": 0.003810348067898898, "phrase": "accurate_tracking"}, {"score": 0.0036830211726031946, "phrase": "irrelevant_edges"}, {"score": 0.003614124997453808, "phrase": "boundary_edge_pixels"}, {"score": 0.003467040410632942, "phrase": "tracked_subject_motion"}, {"score": 0.003415047118340286, "phrase": "edge_motions"}, {"score": 0.003363830908814182, "phrase": "different_motion_directions"}, {"score": 0.003214730261140886, "phrase": "normal_contour_direction"}, {"score": 0.0031784960695034645, "phrase": "image_gradient_values"}, {"score": 0.00307221807606505, "phrase": "edge_pixels"}, {"score": 0.003049086085585051, "phrase": "large_gradient_values"}, {"score": 0.0030033417337933625, "phrase": "multi-level_canny_edge_maps"}, {"score": 0.0029471223246724204, "phrase": "proper_details"}, {"score": 0.0028919522313933525, "phrase": "multi-level_edge_maps"}, {"score": 0.0028164399450837465, "phrase": "tracked_object_boundary"}, {"score": 0.002795228413298423, "phrase": "complex_edges"}, {"score": 0.0027532820796396713, "phrase": "detail_level"}, {"score": 0.002722234804904997, "phrase": "edge_map"}, {"score": 0.0026113524778702624, "phrase": "final_routing"}, {"score": 0.0025335509856200433, "phrase": "detailed_contour"}, {"score": 0.0024395426929046415, "phrase": "strong_canny_edge_map"}, {"score": 0.0024120247307686084, "phrase": "strong_canny_edge"}, {"score": 0.0023579143175099324, "phrase": "dijkstra's_minimum_cost_routing"}, {"score": 0.0022876463319883634, "phrase": "proposed_tracking_approach"}, {"score": 0.0022278779300543548, "phrase": "complex-textured_scene"}, {"score": 0.002202742267484358, "phrase": "mobile_camera_environment"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["object contour tracking", " boundary edge selection", " optical flow", " contour normal direction", " multi-level edge map"], "paper_abstract": "In this paper, a novel method for accurate subject tracking, by selecting only tracked subject boundary edges in a video stream with a changing background and moving camera, is proposed. This boundary edge selection is achieved in two steps: (1) removing background edges using edge motion, and from the output of the previous step, (2) selecting boundary edges using a normal direction derivative of the tracked contour. Accurate tracking is based on reduction of the effects of irrelevant edges, by only selecting boundary edge pixels. In order to remove background edges using edge motion, the tracked subject motion is computed and edge motions and edges having different motion directions from the subjects are removed. In selecting boundary edges using the normal contour direction, the image gradient values on every edge pixel are computed, and edge pixels with large gradient values are selected. Multi-level Canny edge maps are used to obtain proper details of a scene. Multi-level edge maps allow tracking, even though the tracked object boundary has complex edges, since the detail level of an edge map for the scene can be adjusted. A process of final routing is deployed in order to obtain a detailed contour. The computed contour is improved by checking against a strong Canny edge map and hiring strong Canny edge pixels around the computed contour using Dijkstra's minimum cost routing. The experimental results demonstrate that the proposed tracking approach is robust enough to handle a complex-textured scene in a mobile camera environment. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "Accurate object contour tracking based on boundary edge selection", "paper_id": "WOS:000242684100013"}