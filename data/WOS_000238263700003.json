{"auto_keywords": [{"score": 0.047667240890459914, "phrase": "activity_analysis"}, {"score": 0.015719716506582538, "phrase": "multiple_levels"}, {"score": 0.0041666157975446564, "phrase": "multi-zoom_framework"}, {"score": 0.003757480190200645, "phrase": "detailed_and_coarse_views"}, {"score": 0.003531474887552889, "phrase": "epipolar_geometry"}, {"score": 0.0027837615811247963, "phrase": "zoom_levels"}], "paper_keywords": ["activity analysis", " action recognition", " multiple cameras", " multiple zoom", " multi zoom"], "paper_abstract": "In this paper, we present a multi-zoom framework for activity analysis in situations requiring combinations of both detailed and coarse views of the scene. The epipolar geometry is employed in several novel ways in the context of activity analysis. Detecting and tracking objects in time and consistently labeling these objects across zoom levels are two necessary tasks for such activity analysis. First, a multiview approach to automatically detect and track heads and hands in a scene is described. Then, by making use of epipolar, spatial, trajectory, and appearance constraints, objects are labeled consistently across cameras (zooms). Finally, we demonstrate how multiple levels of zoom can cooperate and complement each other to help solve problems related to activity analysis. (c) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Integrating multiple levels of zoom to enable activity analysis", "paper_id": "WOS:000238263700003"}