{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "fusing_auxiliary_imaging_information"}, {"score": 0.004712988631183401, "phrase": "potentially_effective_means"}, {"score": 0.004515467468684217, "phrase": "global_manner"}, {"score": 0.004344755264641137, "phrase": "available_auxiliary_information"}, {"score": 0.004289291421348352, "phrase": "imaging_condition"}, {"score": 0.004216434794603139, "phrase": "camera_location"}, {"score": 0.00418046991987597, "phrase": "global_positioning_system"}, {"score": 0.004056981775766071, "phrase": "inertial_measurement_unit"}, {"score": 0.003937126962709418, "phrase": "exif"}, {"score": 0.0030837288356760973, "phrase": "robust_rotation_averaging_algorithm"}, {"score": 0.003031287195944274, "phrase": "contaminated_epipolar_graph"}, {"score": 0.002954287204671032, "phrase": "robust_scene_reconstruction_algorithm"}, {"score": 0.002904040426340639, "phrase": "noisy_gps_data"}, {"score": 0.002879237498994052, "phrase": "camera_centers"}, {"score": 0.002746549549029177, "phrase": "estimated_inliers"}, {"score": 0.0027114323601885666, "phrase": "current_iteration"}, {"score": 0.0026767629720554397, "phrase": "optimization_process"}, {"score": 0.0025207284405252914, "phrase": "real_images"}, {"score": 0.0024884913795612707, "phrase": "unmanned_aerial_vehicle"}, {"score": 0.002467228805628948, "phrase": "streetview"}, {"score": 0.0023839754995935184, "phrase": "extensive_experimental_results"}, {"score": 0.002264321283759897, "phrase": "state-of-art_reconstruction_approaches"}, {"score": 0.0021049977753042253, "phrase": "large-scale_image_data_sets"}], "paper_keywords": ["Structure from motion", " auxiliary imaging information", " potential inlier", " 3D reconstruction"], "paper_abstract": "One of the potentially effective means for large-scale 3D scene reconstruction is to reconstruct the scene in a global manner, rather than incrementally, by fully exploiting available auxiliary information on the imaging condition, such as camera location by Global Positioning System (GPS), orientation by inertial measurement unit (or compass), focal length from EXIF, and so on. However, such auxiliary information, though informative and valuable, is usually too noisy to be directly usable. In this paper, we present an approach by taking advantage of such noisy auxiliary information to improve structure from motion solving. More specifically, we introduce two effective iterative global optimization algorithms initiated with such noisy auxiliary information. One is a robust rotation averaging algorithm to deal with contaminated epipolar graph, the other is a robust scene reconstruction algorithm to deal with noisy GPS data for camera centers initialization. We found that by exclusively focusing on the estimated inliers at the current iteration, the optimization process initialized by such noisy auxiliary information could converge well and efficiently. Our proposed method is evaluated on real images captured by unmanned aerial vehicle, StreetView car, and conventional digital cameras. Extensive experimental results show that our method performs similarly or better than many of the state-of-art reconstruction approaches, in terms of reconstruction accuracy and completeness, but is more efficient and scalable for large-scale image data sets.", "paper_title": "Efficient Large-Scale Structure From Motion by Fusing Auxiliary Imaging Information", "paper_id": "WOS:000358247700003"}