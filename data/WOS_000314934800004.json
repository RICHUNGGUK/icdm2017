{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "small_clusters"}, {"score": 0.004712463245074863, "phrase": "multicore_architectures"}, {"score": 0.0045726187330434025, "phrase": "dense_matrix_computations"}, {"score": 0.0040186038781533946, "phrase": "directed_acyclic_graph"}, {"score": 0.0038326698261576023, "phrase": "runtime_system"}, {"score": 0.003783471982265641, "phrase": "supermatrix"}, {"score": 0.003686935223424015, "phrase": "clear_separation"}, {"score": 0.003212074324593725, "phrase": "ad_hoc_runtime"}, {"score": 0.0029980260560551982, "phrase": "library_code"}, {"score": 0.0028715299874549245, "phrase": "computational_power"}, {"score": 0.0027741761880779535, "phrase": "impressive_performance"}, {"score": 0.00253400005142168, "phrase": "performance_results"}, {"score": 0.0025122373359090454, "phrase": "accelerated_clusters"}, {"score": 0.0024799423362011582, "phrase": "graphics_processors"}, {"score": 0.0023958326775913165, "phrase": "possible_step"}, {"score": 0.0023650305205893353, "phrase": "many-core_architectures"}, {"score": 0.002255431275670053, "phrase": "intel's_single-chip_cloud_computer"}, {"score": 0.002236069109939904, "phrase": "intel"}, {"score": 0.0022168460543913787, "phrase": "santa_clara"}, {"score": 0.002198097289846477, "phrase": "ca"}, {"score": 0.002178974325360454, "phrase": "usa"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["matrix computations", " novel parallel architectures", " automatic parallelization"], "paper_abstract": "The arrival of multicore architectures has generated an interest in reformulating dense matrix computations as algorithms-by-blocks, where submatrices are units of data and computations with those blocks are units of computation. Rather than directly executing such an algorithm, a directed acyclic graph is generated at runtime that is then scheduled by a runtime system such as SuperMatrix. The benefit is a clear separation of concerns between the library and the heuristics for scheduling. In this paper, we show that this approach can be taken one step further using the same methodology and an ad hoc runtime to map algorithms-by-blocks to small clusters. With no change to the library code, and the application that uses it, the computational power of such small clusters can be utilized. An impressive performance on a number of small clusters is reported. As a proof of the flexibility of the solution, we report performance results on accelerated clusters based on graphics processors. We believe this to be a possible step towards programming many-core architectures, as demonstrated by a port of the solution to Intel's Single-chip Cloud Computer (Intel, Santa Clara, CA, USA). Copyright (c) 2012 John Wiley & Sons, Ltd.", "paper_title": "Scheduling algorithms-by-blocks on small clusters", "paper_id": "WOS:000314934800004"}