{"auto_keywords": [{"score": 0.03986436747617021, "phrase": "artificial_neural_networks"}, {"score": 0.027432050097014566, "phrase": "memory_requirements"}, {"score": 0.00481495049065317, "phrase": "binary_correlation_matrix_memories"}, {"score": 0.004733901576706854, "phrase": "memory_constraints"}, {"score": 0.004680624753255133, "phrase": "matrix_memories"}, {"score": 0.004550029253278477, "phrase": "correlation_matrix_memories"}, {"score": 0.004398094237005956, "phrase": "active_area"}, {"score": 0.0040171817997972335, "phrase": "associative_rule_chaining_architecture"}, {"score": 0.0039050245929822354, "phrase": "austin_et_al"}, {"score": 0.0038392331564122387, "phrase": "international_conference"}, {"score": 0.0033893426032054366, "phrase": "time_complexity"}, {"score": 0.003332210257373994, "phrase": "tree_search"}, {"score": 0.0032208091960514128, "phrase": "branching_factor"}, {"score": 0.002552781867125423, "phrase": "cmm-based_applications"}, {"score": 0.0024257447861185813, "phrase": "arca"}, {"score": 0.0023713273141757326, "phrase": "enamel_interpreter"}, {"score": 0.002305014991156598, "phrase": "\"austin_et_al"}, {"score": 0.002105010001444309, "phrase": "matlab."}], "paper_keywords": ["Correlation matrix memory", " Associative memory", " Compact representation", " Domain specific language", " Rule chaining"], "paper_abstract": "Despite their relative simplicity, correlation matrix memories (CMMs) are an active area of research, as they are able to be integrated into more complex architectures such as the Associative Rule Chaining Architecture (ARCA) \"Austin et al. (International conference on artificial neural networks, pp 49-56, 2012)\". In this architecture, CMMs are used effectively in order to reduce the time complexity of a tree search from to -where is the branching factor and is the depth of the tree. This paper introduces the Extended Neural Associative Memory Language (ENAMeL)-a domain specific language developed to ease development of applications using CMMs. We discuss various considerations required while developing the language, and techniques used to reduce the memory requirements of CMM-based applications. Finally we show that the memory requirements of ARCA when using the ENAMeL interpreter compare favourably to our original results \"Austin et al. (International conference on artificial neural networks, pp 49-56, 2012)\" run in MATLAB.", "paper_title": "ENAMeL: A Language for Binary Correlation Matrix Memories Reducing the Memory Constraints of Matrix Memories", "paper_id": "WOS:000338700000001"}