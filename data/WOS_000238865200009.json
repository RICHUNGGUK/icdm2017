{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "global-local_artificial_neural_networks"}, {"score": 0.004642292792558686, "phrase": "hybrid_radial_basis_function"}, {"score": 0.004455409162867219, "phrase": "three-step_training_algorithm"}, {"score": 0.004374772264092067, "phrase": "global_search"}, {"score": 0.004335000368745273, "phrase": "gradient_descent_training"}, {"score": 0.004160435626849478, "phrase": "global_features"}, {"score": 0.004103817210338686, "phrase": "input-output_relationship"}, {"score": 0.0040479661688863884, "phrase": "local_detail"}, {"score": 0.0039928721865882, "phrase": "approximating_function"}, {"score": 0.0038849148160362257, "phrase": "efficient_function_approximation"}, {"score": 0.003832031470970347, "phrase": "separate_identification"}, {"score": 0.003561865840737996, "phrase": "particular_regions"}, {"score": 0.0035133644847622383, "phrase": "input_space"}, {"score": 0.003371773890338284, "phrase": "five_regression_tasks"}, {"score": 0.003310684108128973, "phrase": "synthetic_datasets"}, {"score": 0.003265591844292821, "phrase": "last_problem"}, {"score": 0.0032358709481309913, "phrase": "real-world_data"}, {"score": 0.0031917943932454314, "phrase": "wave_overtopping"}, {"score": 0.003063123420705719, "phrase": "hybrid_architecture"}, {"score": 0.002926212333939311, "phrase": "single_type"}, {"score": 0.0028470123663391126, "phrase": "square_errors"}, {"score": 0.002234031373581961, "phrase": "gradient_descent_optimization_step"}, {"score": 0.0021834945657804193, "phrase": "rbf_spreads"}, {"score": 0.002163600705898299, "phrase": "model_selection"}, {"score": 0.0021049977753042253, "phrase": "appropriate_stopping_criteria"}], "paper_keywords": ["global", " hybrid", " local", " overtopping", " regularization"], "paper_abstract": "We present a hybrid radial basis function (RBF) sigmoid neural network with a three-step training algorithm that utilizes both global search and gradient descent training. The algorithm used is intended to identify global features of an input-output relationship before adding local detail to the approximating function. It aims to achieve efficient function approximation through the separate identification of aspects of a relationship that are expressed universally from those that vary only within particular regions of the input space. We test the effectiveness of our method using five regression tasks; four use synthetic datasets while the last problem uses real-world data on the wave overtopping of seawalls. It is shown that the hybrid architecture is often superior to architectures containing neurons of a single type in several ways: lower mean square errors are often achievable using fewer hidden neurons and with less need for regularization. Our global-local artificial neural network (GL-ANN) is also seen to compare favorably with both perceptron radial basis net and regression tree derived RBFs. A number of issues concerning the training of GL-ANNs are discussed: the use of regularization, the inclusion of a gradient descent optimization step, the choice of RBF spreads, model selection, and the development of appropriate stopping criteria.", "paper_title": "On global-local artificial neural networks for function approximation", "paper_id": "WOS:000238865200009"}