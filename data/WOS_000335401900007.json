{"auto_keywords": [{"score": 0.04117275374122391, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "rapid_development"}, {"score": 0.004769444094319619, "phrase": "information_techniques"}, {"score": 0.00452670409375785, "phrase": "text_categorization"}, {"score": 0.004296264970612285, "phrase": "high-dimensionality_data"}, {"score": 0.004116440453049531, "phrase": "poor_performance"}, {"score": 0.004058180509184539, "phrase": "low_efficiency"}, {"score": 0.004000741805312148, "phrase": "traditional_learning_algorithms"}, {"score": 0.003962899903266524, "phrase": "pattern_classification"}, {"score": 0.0037432199549135826, "phrase": "discriminative_features"}, {"score": 0.0035022161192936234, "phrase": "increasing_attentions"}, {"score": 0.0031393948330209224, "phrase": "new_supervised_feature_selection_method"}, {"score": 0.003036595866130994, "phrase": "information_criteria"}, {"score": 0.0029511579080222137, "phrase": "main_characteristic"}, {"score": 0.0028140548269469934, "phrase": "maximal_relevance"}, {"score": 0.0027741761880779535, "phrase": "class_labels"}, {"score": 0.0027479040199262393, "phrase": "minimal_redundancy"}, {"score": 0.002708960273193547, "phrase": "selected_features"}, {"score": 0.0025586128304269616, "phrase": "agglomerative_way"}, {"score": 0.0022181655497912796, "phrase": "performance_evaluations"}, {"score": 0.0021557052355026048, "phrase": "proposed_method"}, {"score": 0.0021251363422701446, "phrase": "better_performance"}], "paper_keywords": ["clustering", " information entropy", " dimensionality reduction", " pattern classification", " feature selection"], "paper_abstract": "With the rapid development of information techniques, the dimensionality of data in many application domains, such as text categorization and bioinformatics, is getting higher and higher. The high-dimensionality data may bring many adverse situations, such as overfitting, poor performance, and low efficiency, to traditional learning algorithms in pattern classification. Feature selection aims at reducing the dimensionality of data and providing discriminative features for pattern learning algorithms. Due to its effectiveness, feature selection is now gaining increasing attentions from a variety of disciplines and currently many efforts have been attempted in this field. In this paper, we propose a new supervised feature selection method to pick important features by using information criteria. Unlike other selection methods, the main characteristic of our method is that it not only takes both maximal relevance to the class labels and minimal redundancy to the selected features into account, but also works like feature clustering in an agglomerative way. To measure the relevance and redundancy of feature exactly, two different information criteria, i.e., mutual information and coefficient of relevance, have been adopted in our method. The performance evaluations on 12 benchmark data sets show that the proposed method can achieve better performance than other popular feature selection methods in most cases.", "paper_title": "A NEW SUPERVISED FEATURE SELECTION METHOD FOR PATTERN CLASSIFICATION", "paper_id": "WOS:000335401900007"}