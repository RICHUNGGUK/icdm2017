{"auto_keywords": [{"score": 0.013890518009356747, "phrase": "document_contexts"}, {"score": 0.00629324261296054, "phrase": "estimated_preferences"}, {"score": 0.00481495049065317, "phrase": "hybrid_document-context"}, {"score": 0.004570634647887452, "phrase": "query_terms"}, {"score": 0.0041184131734368825, "phrase": "query_expansion_terms"}, {"score": 0.0039778030796649416, "phrase": "relevance_decisions"}, {"score": 0.003775803846431323, "phrase": "relevance_decision_preference"}, {"score": 0.0037366473207825234, "phrase": "document_context"}, {"score": 0.0036595438031512217, "phrase": "smoothing_techniques"}, {"score": 0.003609024170287396, "phrase": "language_models"}, {"score": 0.003534544738350291, "phrase": "zero_probabilities"}, {"score": 0.00342568771304873, "phrase": "different_types"}, {"score": 0.003401954670986958, "phrase": "aggregation_operators"}, {"score": 0.0033549790559972053, "phrase": "different_relevance_decision_principles"}, {"score": 0.0032067276476968032, "phrase": "retrospective_experiments"}, {"score": 0.003140524241432171, "phrase": "full_relevance_information"}, {"score": 0.002849146732780381, "phrase": "parameter_estimation"}, {"score": 0.002761340122199076, "phrase": "major_factors"}, {"score": 0.0027326751144684386, "phrase": "retrieval_effectiveness"}, {"score": 0.002584733102974067, "phrase": "probability_ranking_principle"}, {"score": 0.002479043701859468, "phrase": "different_trec"}, {"score": 0.0024704333220467393, "phrase": "ad_hoc_english_collections"}, {"score": 0.0023529740798601015, "phrase": "aggregate_relevance_principle"}, {"score": 0.002248899833549883, "phrase": "estimating_probabilities"}, {"score": 0.002202427244004817, "phrase": "relevant_documents"}, {"score": 0.0021795515361987144, "phrase": "better_retrieval_effectiveness"}, {"score": 0.002149418970824546, "phrase": "entire_relevant_documents"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["information retrieval", " model", " theory", " retrospective experiment"], "paper_abstract": "This paper describes our novel retrieval model that is based on contexts of query terms in documents (i.e., document contexts). Our model is novel because it explicitly takes into account of the document contexts instead of implicitly using the document contexts to find query expansion terms. Our model is based on simulating a user making relevance decisions, and it is a hybrid of various existing effective models and techniques. It estimates the relevance decision preference of a document context as the log-odds and uses smoothing techniques as found in language models to solve the problem of zero probabilities. It combines these estimated preferences of document contexts using different types of aggregation operators that comply with different relevance decision principles (e.g., aggregate relevance principle). Our model is evaluated using retrospective experiments (i.e.,, with full relevance information), because such experiments can (a) reveal the potential of our model, (b) isolate the problems of the model from those of the parameter estimation, (c) provide information about the major factors affecting the retrieval effectiveness of the model, and (d) show that whether the model obeys the probability ranking principle. Our model is promising as its mean average precision is 60-80% in our experiments using different TREC ad hoc English collections and the NTCIR-5 ad hoc Chinese collection. Our experiments showed that (a) the operators that are consistent with aggregate relevance principle were effective in combining the estimated preferences, and (b) that estimating probabilities using the contexts in the relevant documents can produce better retrieval effectiveness than using the entire relevant documents. (c) 2006 Elsevier Ltd. All rights reserved.", "paper_title": "A retrospective study of a hybrid document-context based retrieval model", "paper_id": "WOS:000246869800011"}