{"auto_keywords": [{"score": 0.03161900101969589, "phrase": "cache-based_model"}, {"score": 0.00481495049065317, "phrase": "memory_models"}, {"score": 0.004775531918452571, "phrase": "chip_multiprocessors"}, {"score": 0.004640079189342692, "phrase": "on-chip_memory"}, {"score": 0.004602085616330634, "phrase": "chip_multiprocessor"}, {"score": 0.004489952932659799, "phrase": "hardware-managed_coherent_caches"}, {"score": 0.00445318311339027, "phrase": "software-managed_streaming_memory"}, {"score": 0.004344662696228875, "phrase": "direct_comparison"}, {"score": 0.00388800655625083, "phrase": "energy_consumption"}, {"score": 0.0038561471948364723, "phrase": "bandwidth_requirements"}, {"score": 0.003808845109556467, "phrase": "latency_tolerance"}, {"score": 0.0037776319581225046, "phrase": "general-purpose_cmps"}, {"score": 0.0036855132234738736, "phrase": "data-parallel_applications"}, {"score": 0.0034935290662899488, "phrase": "streaming_models"}, {"score": 0.003257432325797907, "phrase": "better_bandwidth"}, {"score": 0.0030623570435946977, "phrase": "hardware_prefetching"}, {"score": 0.0029509483926257645, "phrase": "streaming_advantage"}, {"score": 0.002831894638104635, "phrase": "sufficient_advantage"}, {"score": 0.0027856252557826467, "phrase": "memory_systems"}, {"score": 0.0027514186391258263, "phrase": "on-chip_memory_structures"}, {"score": 0.0025865679621853667, "phrase": "programming_model_level"}, {"score": 0.0024017007954518065, "phrase": "bandwidth_optimizations"}, {"score": 0.002333421318779658, "phrase": "stream_programming"}, {"score": 0.0022484715639779153, "phrase": "hardware_guarantees"}, {"score": 0.0021049977753042253, "phrase": "application's_code"}], "paper_keywords": ["Performance", " Design", " Chip multiprocessors", " cache coherence", " streaming memory", " parallel programming", " locality optimizations"], "paper_abstract": "There are two competing models for the on-chip memory in Chip Multiprocessor (CMP) systems: hardware-managed coherent caches and software-managed streaming memory. This paper performs a direct comparison of the two models under the same set of assumptions about technology, area, and computational capabilities. The goal is to quantify how and when they differ in terms of performance, energy consumption, bandwidth requirements, and latency tolerance for general-purpose CMPs. We demonstrate that for data-parallel applications on systems with up to 16 cores, the cache-based and streaming models perform and scale equally well. For certain applications with little data reuse, streaming scales better due to better bandwidth use and macroscopic software prefetching. However, the introduction of techniques such as hardware prefetching and nonallocating stores to the cache-based model eliminates the streaming advantage. Overall, our results indicate that there is not sufficient advantage in building streaming memory systems where all on-chip memory structures are explicitly managed. On the other hand, we show that streaming at the programming model level is particularly beneficial, even with the cache-based model, as it enhances locality and creates opportunities for bandwidth optimizations. Moreover, we observe that stream programming is actually easier with the cache-based model because the hardware guarantees correct, best-effort execution even when the programmer cannot fully regularize an application's code.", "paper_title": "Comparative Evaluation of Memory Models for Chip Multiprocessors", "paper_id": "WOS:000261844300001"}