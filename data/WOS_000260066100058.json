{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "largest_and_smallest_generalized_eigenvalue"}, {"score": 0.004642604455537883, "phrase": "continuous_recurrent_neural_network_model"}, {"score": 0.004161553532799662, "phrase": "symmetric_positive_pair"}, {"score": 0.003822003373331997, "phrase": "convergence_properties"}, {"score": 0.003685067218455088, "phrase": "extremum_eigenvalues"}, {"score": 0.003553026104767151, "phrase": "liapunov"}, {"score": 0.0032629585038738856, "phrase": "generalized_eigen-decomposition_theorem"}, {"score": 0.002685558057339722, "phrase": "smallest_generalized_eigenvalue"}, {"score": 0.002348883765159185, "phrase": "invariant_norm_property"}, {"score": 0.0022923586577645143, "phrase": "numerical_simulation"}, {"score": 0.0021049977753042253, "phrase": "proposed_model"}], "paper_keywords": ["Recurrent neural network", " Generalized eigenvalue", " Real symmetric matrix", " Convergence"], "paper_abstract": "A continuous recurrent neural network model is presented for computing the largest and smallest generalized eigenvalue of a symmetric positive pair (A,B). Convergence properties to the extremum eigenvalues based upon Liapunov functional with the help of the generalized eigen-decomposition theorem is obtained. Compared with other existing models, this model is also suitable for computing the smallest generalized eigenvalue simply by replacing A by -A as well as maintaining invariant norm property. Numerical simulation further shows the effectiveness of the proposed model. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Recurrent neural network model for computing largest and smallest generalized eigenvalue", "paper_id": "WOS:000260066100058"}