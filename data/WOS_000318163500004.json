{"auto_keywords": [{"score": 0.047510470298773616, "phrase": "chain_rule"}, {"score": 0.014095845429388937, "phrase": "von_neumann_entropy"}, {"score": 0.00481495049065317, "phrase": "smooth_min-"}, {"score": 0.004710034964411281, "phrase": "max-entropies"}, {"score": 0.004408853124470979, "phrase": "shannon"}, {"score": 0.004081385289516914, "phrase": "total_entropy"}, {"score": 0.0035755653799043, "phrase": "central_importance"}, {"score": 0.0034975571855450343, "phrase": "information_theory"}, {"score": 0.002931569771634119, "phrase": "one-shot_information_theory"}, {"score": 0.00280496585980086, "phrase": "entropy_measures"}, {"score": 0.00240328454980006, "phrase": "standard_chain_rule"}, {"score": 0.0021520139248317333, "phrase": "smooth_entropies"}], "paper_keywords": ["Chain rules", " one-shot information theory", " smooth entropy"], "paper_abstract": "The chain rule for the Shannon and von Neumann entropy, which relates the total entropy of a system to the entropies of its parts, is of central importance to information theory. Here, we consider the chain rule for the more general smooth min- and max-entropies, used in one-shot information theory. For these entropy measures, the chain rule no longer holds as an equality. However, the standard chain rule for the von Neumann entropy is retrieved asymptotically when evaluating the smooth entropies for many identical and independently distributed states.", "paper_title": "Chain Rules for Smooth Min- and Max-Entropies", "paper_id": "WOS:000318163500004"}