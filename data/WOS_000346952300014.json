{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "statistically_significant_features"}, {"score": 0.004761494044422926, "phrase": "random_forests"}, {"score": 0.00470862827326028, "phrase": "embedded_feature_selection"}, {"score": 0.004428139418750855, "phrase": "random_forest"}, {"score": 0.00400459716272594, "phrase": "statistical_sense"}, {"score": 0.00389427992231721, "phrase": "statistical_procedure"}, {"score": 0.003829548069657859, "phrase": "variable_importance"}, {"score": 0.003405472159599442, "phrase": "new_importance_index"}, {"score": 0.003348838095597268, "phrase": "relevant_variables"}, {"score": 0.0032383707002544755, "phrase": "variable_ranking"}, {"score": 0.0031490944606172152, "phrase": "breiman's_importance_index"}, {"score": 0.0030794433253250476, "phrase": "permutation_test"}, {"score": 0.0029945352738604742, "phrase": "additional_benefit"}, {"score": 0.002895721231882758, "phrase": "forest_voting_process"}, {"score": 0.0026626797255348287, "phrase": "false_discovery_rate"}, {"score": 0.0026330549554033876, "phrase": "practical_experiments"}, {"score": 0.002574788013427524, "phrase": "synthetic_and_real_data"}, {"score": 0.0025461386232786356, "phrase": "low_and_high-dimensional_datasets"}, {"score": 0.0025178072071268534, "phrase": "binary_or_multi-class_problems"}, {"score": 0.0024346858809238766, "phrase": "proposed_technique"}, {"score": 0.0023675132064088803, "phrase": "recent_alternatives"}, {"score": 0.0023151088048303705, "phrase": "computational_complexity"}, {"score": 0.002276566401216226, "phrase": "selection_process"}, {"score": 0.002176887956041267, "phrase": "similar_performances"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Feature selection", " Tree ensembles", " Significance tests", " High-dimensional data analysis"], "paper_abstract": "Embedded feature selection can be performed by analyzing the variables used in a Random Forest. Such a multivariate selection takes into account the interactions between variables but is not straightforward to interpret in a statistical sense. We propose a statistical procedure to measure variable importance that tests if variables are significantly useful in combination with others in a forest. We show experimentally that this new importance index correctly identifies relevant variables. The top of the variable ranking is largely correlated with Breiman's importance index based on a permutation test. Our measure has the additional benefit to produce p-values from the forest voting process. Such p-values offer a very natural way to decide which features are significantly relevant while controlling the false discovery rate. Practical experiments are conducted on synthetic and real data including low and high-dimensional datasets for binary or multi-class problems. Results show that the proposed technique is effective and outperforms recent alternatives by reducing the computational complexity of the selection process by an order of magnitude while keeping similar performances. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Inferring statistically significant features from random forests", "paper_id": "WOS:000346952300014"}