{"auto_keywords": [{"score": 0.04788368904917638, "phrase": "multiple_agents"}, {"score": 0.00481495049065317, "phrase": "strategic_capability-learning"}, {"score": 0.004780334370089564, "phrase": "improved_multiagent_collaboration"}, {"score": 0.004745965928357563, "phrase": "ad_hoc_environments"}, {"score": 0.0046276016230633495, "phrase": "distributed_collaboration"}, {"score": 0.004544859094594241, "phrase": "ad_hoc"}, {"score": 0.004383766516923386, "phrase": "multiagent_task_execution_scenario"}, {"score": 0.0039623243082901214, "phrase": "different_sets"}, {"score": 0.003712964709503484, "phrase": "decision-making_problem"}, {"score": 0.0033196177202591843, "phrase": "current_tasks"}, {"score": 0.0032250366795039715, "phrase": "human_learning_theory"}, {"score": 0.0031331419276289306, "phrase": "appropriate_capabilities"}, {"score": 0.0029893477597041493, "phrase": "dynamic_nature"}, {"score": 0.0028936710552719806, "phrase": "experimental_results"}, {"score": 0.002862462250995423, "phrase": "repast_agent_simulator_show"}, {"score": 0.002811191663575046, "phrase": "appropriate_learning_strategy"}, {"score": 0.0027808699346360656, "phrase": "overall_utility"}, {"score": 0.0023718560142554634, "phrase": "expert_agent"}, {"score": 0.002222365485177405, "phrase": "intelligent_utility"}, {"score": 0.0021049977753042253, "phrase": "learning_decision"}], "paper_keywords": ["Ad hoc networks", " collaborative work", " learning", " multiagent systems"], "paper_abstract": "We consider the problem of distributed collaboration among multiple agents in an ad hoc setting. We have analyzed this problem within a multiagent task execution scenario, in which every task requires collaboration among multiple agents to get completed. Tasks are also ad hoc in the sense that they appear dynamically and require different sets of expertise or capabilities from agents for completion. We model collaboration within this framework as a decision-making problem in which agents have to determine what capabilities to learn and from which agents to learn them so that they can form teams that have the capabilities required to perform the current tasks satisfactorily. Our proposed technique refers to principles from human learning theory to enable an agent to strategically select appropriate capabilities to learn from other agents. We also use two openness parameters to model the dynamic nature of tasks and agents in the environment. Experimental results within the Repast agent simulator show that by using the appropriate learning strategy, the overall utility of the agents improves considerably. The performance of the agents and their utilities are also dependent on the repetitiveness of tasks and reencounter with agents within the environment. Our results also show that the agents that are able to learn more capabilities from another expert agent outperform the agents who learn only one capability at a time from many agents, and agents who use an intelligent utility maximizing strategy to choose which capabilities to learn outperform the agents who randomly make the learning decision.", "paper_title": "Strategic Capability-Learning for Improved Multiagent Collaboration in Ad Hoc Environments", "paper_id": "WOS:000342278500003"}