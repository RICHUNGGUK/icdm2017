{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "human_multimodal_dialogue_strategies"}, {"score": 0.030958856924928054, "phrase": "human_wizard_behaviour"}, {"score": 0.004661868629458321, "phrase": "different_machine_learning_methods"}, {"score": 0.0045765783794477505, "phrase": "feature_selection_techniques"}, {"score": 0.004349955692802962, "phrase": "automated_dialogue_systems"}, {"score": 0.004153647187175639, "phrase": "wizard-of-oz_study"}, {"score": 0.0041154571996523505, "phrase": "different_human_'wizards"}, {"score": 0.00398452530840582, "phrase": "clarification_request"}, {"score": 0.003929689573550262, "phrase": "multimodal_manner"}, {"score": 0.0037177622939493084, "phrase": "data_collection"}, {"score": 0.0036665842836420223, "phrase": "coding_scheme"}, {"score": 0.0036328561748082138, "phrase": "annotated_corpus"}, {"score": 0.003517223847512266, "phrase": "multimodal_annotations"}, {"score": 0.0033739270918502285, "phrase": "uniform_multimodal_dialogue_strategy"}, {"score": 0.0032514447965530354, "phrase": "multiple_features"}, {"score": 0.0032066653632708965, "phrase": "dialogue_context"}, {"score": 0.0031479142819948007, "phrase": "generic_features"}, {"score": 0.002991823455621222, "phrase": "dialogue_systems"}, {"score": 0.0028698706191651155, "phrase": "weighted_f-score"}, {"score": 0.00274017282519193, "phrase": "majority_baseline"}, {"score": 0.002640636493247601, "phrase": "learned_strategy"}, {"score": 0.0025212722607043546, "phrase": "automatic_dialogue_systems"}, {"score": 0.002429668083484833, "phrase": "automatic_optimization_methods"}, {"score": 0.0023851187337905412, "phrase": "reinforcement_learning"}, {"score": 0.0022458849724980904, "phrase": "small_initial_wizard-of-oz_data_sets"}, {"score": 0.0021843879253500894, "phrase": "feature_engineering"}, {"score": 0.002154272413276506, "phrase": "essential_step"}, {"score": 0.0021245712108461227, "phrase": "dialogue_strategies"}], "paper_keywords": [""], "paper_abstract": "We investigate the use of different machine learning methods in combination with feature selection techniques to explore human multimodal dialogue strategies and the use of those strategies for automated dialogue systems. We learn policies from data collected in a Wizard-of-Oz study where different human 'wizards' decide whether to ask a clarification request in a multimodal manner or else to use speech alone. We first describe the data collection, the coding scheme and annotated corpus, and the validation of the multimodal annotations. We then show that there is a uniform multimodal dialogue strategy across wizards, which is based on multiple features in the dialogue context. These are generic features, available at runtime, which can be implemented in dialogue systems. Our prediction models (for human wizard behaviour) achieve a weighted f-score of 88.6 per cent (which is a 25.6 per cent improvement over the majority baseline). We interpret and discuss the learned strategy. We conclude that human wizard behaviour is not optimal for automatic dialogue systems, and argue for the use of automatic optimization methods, such as Reinforcement Learning. Throughout the investigation we also discuss the issues arising from using small initial Wizard-of-Oz data sets, and we show that feature engineering is an essential step when learning dialogue strategies From such limited data.", "paper_title": "Learning human multimodal dialogue strategies", "paper_id": "WOS:000278491200002"}