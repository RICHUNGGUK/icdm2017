{"auto_keywords": [{"score": 0.04707791482366765, "phrase": "different_depths"}, {"score": 0.015589188592772307, "phrase": "single_photograph"}, {"score": 0.015416809394805346, "phrase": "uncalibrated_conventional_camera"}, {"score": 0.00995120029310177, "phrase": "edge_regions"}, {"score": 0.008389919304168528, "phrase": "focal_plane"}, {"score": 0.008343067890535304, "phrase": "user_interaction"}, {"score": 0.00481495049065317, "phrase": "digital_multi-focusing"}, {"score": 0.00462919213721188, "phrase": "-in-focus_images"}, {"score": 0.004413193567592802, "phrase": "low-end_hand-held_cameras"}, {"score": 0.004242868712089958, "phrase": "challenging_multi-focusing_problem"}, {"score": 0.004090577229368418, "phrase": "existing_multi-focusing_approaches"}, {"score": 0.00397714507836836, "phrase": "deconvolution_process"}, {"score": 0.0038559853156801094, "phrase": "ringing_artifacts"}, {"score": 0.003823584649521733, "phrase": "focused_region"}, {"score": 0.003802135020791801, "phrase": "low_depth"}, {"score": 0.0036966717141736355, "phrase": "novel_systematic_approach"}, {"score": 0.0035339597999254064, "phrase": "optical_explanation"}, {"score": 0.00350425549695367, "phrase": "local_smooth_assumption"}, {"score": 0.00345530020388352, "phrase": "new_point-to-point_defocus_model"}, {"score": 0.0033688919177039863, "phrase": "input_image"}, {"score": 0.003303177222901723, "phrase": "defocus_blur"}, {"score": 0.003148854910240482, "phrase": "sharp_edge"}, {"score": 0.003113601003720005, "phrase": "rough_blur_map"}, {"score": 0.0030614565460256897, "phrase": "blur_amount"}, {"score": 0.002993282431300233, "phrase": "guided_image_filter"}, {"score": 0.002943147037670826, "phrase": "blur_value"}, {"score": 0.002893848939571513, "phrase": "whole_image"}, {"score": 0.002861441830192181, "phrase": "refined_blur_map"}, {"score": 0.0027741761880779535, "phrase": "all-in-focus_photograph"}, {"score": 0.0026594392054760806, "phrase": "depth_map"}, {"score": 0.0026370661343466354, "phrase": "blur_map"}, {"score": 0.002506715532901322, "phrase": "binary_graph_cut_algorithm"}, {"score": 0.0024302416436559867, "phrase": "binary_graph"}, {"score": 0.0023362681721994477, "phrase": "camera_parameters"}, {"score": 0.002245920320149954, "phrase": "new_multi-focusing_algorithm"}, {"score": 0.0021408862709571615, "phrase": "high_quality_depth_maps"}, {"score": 0.0021288561076024844, "phrase": "multi-focusing_results"}, {"score": 0.0021049977753042253, "phrase": "previous_approaches"}], "paper_keywords": ["Defocus blur", " depth estimation", " image restoration", " multi-focusing"], "paper_abstract": "The demand to restore all-in-focus images from defocused images and produce photographs focused at different depths is emerging in more and more cases, such as low-end hand-held cameras and surveillance cameras. In this paper, we manage to solve this challenging multi-focusing problem with a single image taken with an uncalibrated conventional camera. Different from all existing multi-focusing approaches, our method does not need to include a deconvolution process, which is quite time-consuming and will cause ringing artifacts in the focused region and low depth-of-field. This paper proposes a novel systematic approach to realize multi-focusing from a single photograph. First of all, with the optical explanation for the local smooth assumption, we present a new point-to-point defocus model. Next, the blur map of the input image, which reflects the amount of defocus blur at each pixel in the image, is estimated by two steps. 1) With the sharp edge prior, a rough blur map is obtained by estimating the blur amount at the edge regions. 2) The guided image filter is applied to propagate the blur value from the edge regions to the whole image by which a refined blur map is obtained. Thus far, we can restore the all-in-focus photograph from a defocused input. To further produce photographs focused at different depths, the depth map from the blur map must be derived. To eliminate the ambiguity over the focal plane, user interaction is introduced and a binary graph cut algorithm is used. So we introduce user interaction and use a binary graph cut algorithm to eliminate the ambiguity over the focal plane. Coupled with the camera parameters, this approach produces images focused at different depths. The performance of this new multi-focusing algorithm is evaluated both objectively and subjectively by various test images. Both results demonstrate that this algorithm produces high quality depth maps and multi-focusing results, outperforming the previous approaches.", "paper_title": "Digital Multi-Focusing From a Single Photograph Taken With an Uncalibrated Conventional Camera", "paper_id": "WOS:000324382700022"}