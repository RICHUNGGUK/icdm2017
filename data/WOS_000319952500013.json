{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "distributed_online_classification"}, {"score": 0.00388828234270598, "phrase": "generalization_ability"}, {"score": 0.0037789720824759503, "phrase": "distributed_online_learning_algorithms"}, {"score": 0.0036727235025069828, "phrase": "stationary_and_non-stationary_environments"}, {"score": 0.0030078460113945136, "phrase": "connected_network"}, {"score": 0.0027610089418453614, "phrase": "performance_advantage"}, {"score": 0.002570817338292482, "phrase": "individual_non-cooperative_processing"}, {"score": 0.0024281181691350085, "phrase": "extensive_simulations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Distributed stochastic optimization", " Diffusion adaptation", " Non-stationary data", " Tracking", " Classification", " Risk function", " Loss function", " Excess risk"], "paper_abstract": "In this work, we analyze the generalization ability of distributed online learning algorithms under stationary and non-stationary environments. We derive bounds for the excess-risk attained by each node in a connected network of learners and study the performance advantage that diffusion has over individual non-cooperative processing. We conduct extensive simulations to illustrate the results. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "On distributed online classification in the midst of concept drifts", "paper_id": "WOS:000319952500013"}