{"auto_keywords": [{"score": 0.043891862951523725, "phrase": "acoustic_localization"}, {"score": 0.00481495049065317, "phrase": "real-world_robots"}, {"score": 0.004766090327062509, "phrase": "autonomous_human_robot_interaction"}, {"score": 0.004669845451682529, "phrase": "artificial_audition_module"}, {"score": 0.004392565073466714, "phrase": "verbal_and_non-verbal_auditory_inputs"}, {"score": 0.003946195919158241, "phrase": "multiple_persons"}, {"score": 0.003906116922372891, "phrase": "auditory_events"}, {"score": 0.0036740168936985314, "phrase": "auditory_tasks"}, {"score": 0.0036181717017041387, "phrase": "speech_enhancement"}, {"score": 0.003581412258960711, "phrase": "speech_recognition"}, {"score": 0.0034911335714333507, "phrase": "microphone_arrays"}, {"score": 0.003403122817578447, "phrase": "efficient_and_commonly_applied_approach"}, {"score": 0.0031845067058084583, "phrase": "simulated_environments"}, {"score": 0.0030569913145731408, "phrase": "real-world_conditions"}, {"score": 0.002831462722290752, "phrase": "imperfect_frequency_response"}, {"score": 0.0027883885425383534, "phrase": "array_microphones"}, {"score": 0.002690406375639144, "phrase": "robot's_shape"}, {"score": 0.0026630475331025955, "phrase": "surface_material"}, {"score": 0.002556359086441866, "phrase": "signal's_phase_information"}, {"score": 0.0024918548761791435, "phrase": "novel_pre-processing_step"}, {"score": 0.002367676766637248, "phrase": "proposed_approach"}, {"score": 0.002331641523873951, "phrase": "localization_performance"}, {"score": 0.0023079225317714815, "phrase": "joint_noisy"}, {"score": 0.002284444272376043, "phrase": "reverberant_conditions"}, {"score": 0.0022382002476510573, "phrase": "humanoid_robot"}, {"score": 0.0022041312401435346, "phrase": "multiple_speakers"}, {"score": 0.0021705796895687864, "phrase": "real-world_environment"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Microphone arrays", " Acoustic localization", " Time delay estimation", " Steered response power", " Phase spectrum enhancement"], "paper_abstract": "Autonomous human robot interaction ultimately requires an artificial audition module that allows the robot to process and interpret a combination of verbal and non-verbal auditory inputs. A key component of such a module is the acoustic localization. The acoustic localization not only enables the robot to simultaneously localize multiple persons and auditory events of interest in the environment, but also provides input to auditory tasks such as speech enhancement and speech recognition. The use of microphone arrays in robots is an efficient and commonly applied approach to the localization problem. In this paper, moving away from simulated environments, we look at the acoustic localization under real-world conditions and limitations. Our approach proposes a series of enhancements, taking into account the imperfect frequency response of the array microphones and addressing the influence of the robot's shape and surface material. Motivated by the importance of the signal's phase information, we introduce a novel pre-processing step for enhancing the acoustic localization. Results show that the proposed approach improves the localization performance in joint noisy and reverberant conditions and allows a humanoid robot to locate multiple speakers in a real-world environment. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Robust speaker localization for real-world robots", "paper_id": "WOS:000357222100008"}