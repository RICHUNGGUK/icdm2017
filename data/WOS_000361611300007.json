{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "scalable_video_quality_enhancement"}, {"score": 0.04774633807425784, "phrase": "low_quality_frames"}, {"score": 0.042021602109550533, "phrase": "previous_algorithms"}, {"score": 0.03920077607219174, "phrase": "scale_and_rotation_transforms"}, {"score": 0.004530023871441992, "phrase": "high_quality_ones"}, {"score": 0.0044800522651664695, "phrase": "scalable_video_bitstreams"}, {"score": 0.004430629452265786, "phrase": "time-varying_qualities"}, {"score": 0.004357511171877593, "phrase": "key_problem"}, {"score": 0.004099542199088835, "phrase": "high_quality"}, {"score": 0.0039433581938239926, "phrase": "block-based_motion_estimation"}, {"score": 0.003588291565092195, "phrase": "motion_estimation_results"}, {"score": 0.0034134024569847264, "phrase": "pixel-based_outlier-free_motion_estimation_algorithm"}, {"score": 0.00321114539085481, "phrase": "motion_vector"}, {"score": 0.0029380909574836587, "phrase": "neighboring_pixels"}, {"score": 0.002857605453835429, "phrase": "markov_random_field_model"}, {"score": 0.002794802975530612, "phrase": "motion_estimation_accuracy"}, {"score": 0.0025570607111118793, "phrase": "scale-invariant_feature"}, {"score": 0.0023788319661581696, "phrase": "spatial_scalability"}, {"score": 0.0023525345110929326, "phrase": "quality_scalability"}, {"score": 0.00230080652063411, "phrase": "experimental_results"}, {"score": 0.0021763973978248005, "phrase": "proposed_algorithm"}, {"score": 0.002152332983488664, "phrase": "better_correspondence"}, {"score": 0.0021049977753042253, "phrase": "simultaneous_introduction"}], "paper_keywords": ["motion estimation", " scalable video coding", " video super resolution"], "paper_abstract": "Scalable video quality enhancement refers to the process of enhancing low quality frames using high quality ones in scalable video bitstreams with time-varying qualities. A key problem in the enhancement is how to search for correspondence between high quality and low quality frames. Previous algorithms usually use block-based motion estimation to search for correspondences. Such an approach can hardly estimate scale and rotation transforms and always introduces outliers to the motion estimation results. In this paper, we propose a pixel-based outlier-free motion estimation algorithm to solve this problem. In our algorithm, the motion vector for each pixel is calculated with respect to estimate translation, scale, and rotation transforms. The motion relationships between neighboring pixels are considered via the Markov random field model to improve the motion estimation accuracy. Outliers are detected and avoided by taking both blocking effects and matching percentage in scale-invariant feature transform field into consideration. Experiments are conducted in two scenarios that exhibit spatial scalability and quality scalability, respectively. Experimental results demonstrate that, in comparison with previous algorithms, the proposed algorithm achieves better correspondence and avoids the simultaneous introduction of outliers, especially for videos with scale and rotation transforms.", "paper_title": "A pixel-based outlier-free motion estimation algorithm for scalable video quality enhancement", "paper_id": "WOS:000361611300007"}