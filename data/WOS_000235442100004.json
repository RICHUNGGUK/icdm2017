{"auto_keywords": [{"score": 0.03710335083466446, "phrase": "ies."}, {"score": 0.00481495049065317, "phrase": "aesthetic_intention"}, {"score": 0.0047820521205253035, "phrase": "interactive_evolution"}, {"score": 0.004749377457292245, "phrase": "interactive_evolutionary_systems"}, {"score": 0.004589307360976108, "phrase": "large_numbers"}, {"score": 0.004557943646825813, "phrase": "alternative_designs"}, {"score": 0.004098221047046135, "phrase": "evolutionary_process"}, {"score": 0.004014728271095809, "phrase": "visual_aesthetic_intentions"}, {"score": 0.0038793218280304825, "phrase": "limited_size"}, {"score": 0.003839594092937135, "phrase": "computer_screen"}, {"score": 0.0038133343544929648, "phrase": "fuzzy_nature"}, {"score": 0.0037872535287644103, "phrase": "aesthetic_evaluations"}, {"score": 0.0037100724714897084, "phrase": "mutation-driven_and_divergent_process"}, {"score": 0.0036095967013657906, "phrase": "standard_evolutionary_algorithms"}, {"score": 0.003404998261799824, "phrase": "computational_framework"}, {"score": 0.0033241495608238884, "phrase": "higher_level"}, {"score": 0.0032675746199502614, "phrase": "additional_actions"}, {"score": 0.003135679861067472, "phrase": "neural_network_based_learning_mechanism"}, {"score": 0.002988496107817795, "phrase": "ies._grnn"}, {"score": 0.0029578641378775633, "phrase": "user's_aesthetic_evaluations"}, {"score": 0.002927545222513142, "phrase": "interactive_evolutionary_process"}, {"score": 0.0027805362553564336, "phrase": "aesthetic_appeals"}, {"score": 0.002742592804749034, "phrase": "corresponding_designs"}, {"score": 0.0027144744718498102, "phrase": "learning_mechanism"}, {"score": 0.0025255346035867564, "phrase": "tedious_work"}, {"score": 0.00236591959343317, "phrase": "parametric_tuning"}, {"score": 0.0023497148309861303, "phrase": "facial_characters"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["interactive evolutionary systems", " genetic algorithm", " aesthetic intention", " artificial neural networks"], "paper_abstract": "Interactive Evolutionary Systems (IES) are capable of generating and evolving large numbers of alternative designs. When using such systems, users are continuously required to interact with the system by making evaluations and selections of the designs that are being generated and evolved. The evolutionary process is therefore led by the visual aesthetic intentions of the user. However, due to the limited size of the computer screen and fuzzy nature of aesthetic evaluations, evolution is usually a mutation-driven and divergent process. The convergent mechanisms typically found in standard Evolutionary Algorithms are more difficult to achieve with IES. To address this problem, this paper presents a computational framework that creates an IES with a higher level of convergence without requiring additional actions from the user. This can be achieved by incorporating a Neural Network based learning mechanism, called a General Regression Neural Network (GRNN), into an IES. GRNN analyses the user's aesthetic evaluations during the interactive evolutionary process and is thereby able to approximate their implicit aesthetic intentions. The approximation is a regression of aesthetic appeals conditioned on the corresponding designs. This learning mechanism allows the framework to infer which designs the users may find desirable. For the users, this reduces the tedious work of evaluating and selecting designs. Experiments have been conducted using the framework to support the process of parametric tuning of facial characters. In this paper we analyze the performance of our approach and discuss the issues that we believe are essential for improving the usability and efficiency of IES. (c) 2005 Elsevier Ltd. All rights reserved.", "paper_title": "Capturing aesthetic intention during interactive evolution", "paper_id": "WOS:000235442100004"}