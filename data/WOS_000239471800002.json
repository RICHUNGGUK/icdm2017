{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "evaluative_arguments"}, {"score": 0.004724365740062236, "phrase": "natural_human_communication"}, {"score": 0.0046797114400479135, "phrase": "countless_situations"}, {"score": 0.004296264970612285, "phrase": "on-line_systems"}, {"score": 0.004255639740735269, "phrase": "personal_advisors"}, {"score": 0.004162328961227939, "phrase": "pressing_need"}, {"score": 0.004122964978180509, "phrase": "general_and_testable_computational_models"}, {"score": 0.004032551494961167, "phrase": "previous_research"}, {"score": 0.0037969755088553326, "phrase": "specific_aspects"}, {"score": 0.0037610536973798113, "phrase": "generation_process"}, {"score": 0.0037019348293573675, "phrase": "proposed_approaches"}, {"score": 0.0034526191487098093, "phrase": "complete_computational_model"}, {"score": 0.0033875770020590796, "phrase": "content_selection"}, {"score": 0.003313236365209158, "phrase": "argumentation_strategy"}, {"score": 0.003261133560558666, "phrase": "argumentation_theory"}, {"score": 0.0031895588542135245, "phrase": "natural_language"}, {"score": 0.0031294568052050186, "phrase": "previous_work"}, {"score": 0.0031096747349602344, "phrase": "computational_linguistics"}, {"score": 0.003051073364818384, "phrase": "key_knowledge_source"}, {"score": 0.0029935730127943496, "phrase": "quantitative_model"}, {"score": 0.0029746473344900784, "phrase": "user_preferences"}, {"score": 0.002927853422094123, "phrase": "critical_aspects"}, {"score": 0.0028364561005358377, "phrase": "evaluation_framework"}, {"score": 0.0027392018850028706, "phrase": "real_users"}, {"score": 0.002570817338292482, "phrase": "computational_model"}, {"score": 0.0024826484631019167, "phrase": "evaluative_argument"}, {"score": 0.0024591303299708604, "phrase": "addressee's_preferences"}, {"score": 0.0023448318062933527, "phrase": "second_hypothesis"}, {"score": 0.0022643957465558287, "phrase": "first_hypothesis"}, {"score": 0.0022076314894741394, "phrase": "independent_testing"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["natural language generation", " user tailoring", " preferences", " empirical evaluation"], "paper_abstract": "Evaluative arguments are pervasive in natural human communication. In countless situations people attempt to advise or persuade their interlocutors that something is desirable (vs. undesirable) or right (vs. wrong). With the proliferation of on-line systems serving as personal advisors and assistants, there is a pressing need to develop general and testable computational models for generating and presenting evaluative arguments. Previous research on generating evaluative arguments has been characterized by two major limitations. First, researchers have tended to focus only on specific aspects of the generation process. Second, the proposed approaches were not empirically tested. The research presented in this paper addresses both limitations. We have designed and implemented a complete computational model for generating evaluative arguments. For content selection and organization, we devised an argumentation strategy based on guidelines from argumentation theory. For expressing the content in natural language, we extended and integrated previous work in computational linguistics on generating evaluative arguments. The key knowledge source for both tasks is a quantitative model of user preferences. To empirically test critical aspects of our generation model, we have devised and implemented an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users. Within the framework, we have performed an experiment to test two basic hypotheses on which the design of the computational model is based; namely, that our proposal for tailoring an evaluative argument to the addressee's preferences increases its effectiveness, and that differences in conciseness significantly influence argument effectiveness. The second hypothesis was confirmed in the experiment. In contrast, the first hypothesis was only marginally confirmed. However, independent testing by other researchers has recently provided further support for this hypothesis. (C) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Generating and evaluating evaluative arguments", "paper_id": "WOS:000239471800002"}