{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-touch_selection"}, {"score": 0.004617949594931096, "phrase": "mobile_multi-touch_input"}, {"score": 0.004575272950516775, "phrase": "large-scale_visualization_displays"}, {"score": 0.0044702911400353535, "phrase": "mobile_multi-touch_interface"}, {"score": 0.00383508177668219, "phrase": "fundamental_interaction_problem"}, {"score": 0.003678023470672862, "phrase": "multiple_positions"}, {"score": 0.0036271080216837286, "phrase": "large_room"}, {"score": 0.0034303736977646135, "phrase": "hand-held_multi-touch_device"}, {"score": 0.003336031521101184, "phrase": "physical_space"}, {"score": 0.0032745778756077693, "phrase": "large_display"}, {"score": 0.0030825404960282713, "phrase": "current_data"}, {"score": 0.0029838294169759663, "phrase": "multi-touch_gestures"}, {"score": 0.0029152570900178956, "phrase": "progressive_refinement"}, {"score": 0.0028087949095629955, "phrase": "single_complex_input"}, {"score": 0.0027062100658653485, "phrase": "small_mobile_multi-touch_input_space"}, {"score": 0.0024543571925896073, "phrase": "social_scientists"}, {"score": 0.0022258906408344973, "phrase": "new_domain-specific_insights"}, {"score": 0.0021646022201798247, "phrase": "future_developers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Multi-touch", " Progressive refinement", " 3D user interface", " Mobile device", " 3D tracking", " Ray casting", " Selection"], "paper_abstract": "We present a mobile multi-touch interface for selecting, querying, and visually exploring data visualized on large, high-resolution displays. Although emerging large (e.g., similar to 10 m wide), high-resolution displays provide great potential for visualizing dense, complex datasets, their utility is often limited by a fundamental interaction problem - the need to interact with data from multiple positions around a large room. Our solution is a selection and querying interface that combines a hand-held multi-touch device with 6 degree-of-freedom tracking in the physical space that surrounds the large display. The interface leverages context from both the user's physical position in the room and the current data being visualized in order to interpret multi-touch gestures. It also utilizes progressive refinement, favoring several quick approximate gestures as opposed to a single complex input in order to most effectively map the small mobile multi-touch input space to the large display wall. The approach is evaluated through two interdisciplinary visualization applications: a multi-variate data visualization for social scientists, and a visual database querying tool for biochemistry. The interface was effective in both scenarios, leading to new domain-specific insights and suggesting valuable guidance for future developers. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Scaling up multi-touch selection and querying: Interfaces and applications for combining mobile multi-touch input with large-scale visualization displays", "paper_id": "WOS:000309695200005"}