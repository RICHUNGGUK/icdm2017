{"auto_keywords": [{"score": 0.04901721310106573, "phrase": "lockable_instruction_cache"}, {"score": 0.04866820578070978, "phrase": "multitasking_real-time_systems"}, {"score": 0.030660592326805094, "phrase": "static_locking"}, {"score": 0.027282810051933958, "phrase": "cache_size"}, {"score": 0.00481495049065317, "phrase": "wcet_computation"}, {"score": 0.004501584662320018, "phrase": "wcet"}, {"score": 0.004271953920234395, "phrase": "worst_case"}, {"score": 0.004161553532799662, "phrase": "variable_latency_hardware"}, {"score": 0.0040997480534580065, "phrase": "instruction_cache_memories"}, {"score": 0.004008749730113699, "phrase": "lesser_extent"}, {"score": 0.003964007795174772, "phrase": "line_buffers"}, {"score": 0.003890540531028228, "phrase": "fetch_path"}, {"score": 0.003861534816807933, "phrase": "commercial_processors"}, {"score": 0.0037899595175206143, "phrase": "cache_replacement"}, {"score": 0.00366443843576107, "phrase": "cache_behavior"}, {"score": 0.003583067515485425, "phrase": "cache-locking_methods"}, {"score": 0.003516635512391528, "phrase": "good_selection"}, {"score": 0.0034773669221269594, "phrase": "memory_lines"}, {"score": 0.003299813878412728, "phrase": "ilp-based_method"}, {"score": 0.0032507647824680684, "phrase": "best_lines"}, {"score": 0.003154836091281154, "phrase": "instruction_cache"}, {"score": 0.0031195948946937378, "phrase": "context_switch"}, {"score": 0.002788066194685293, "phrase": "spatial_locality"}, {"score": 0.0027466028572379455, "phrase": "line_buffer"}, {"score": 0.0026160472919135444, "phrase": "dynamic_locking_systems"}, {"score": 0.0024546155360991567, "phrase": "computation_time"}, {"score": 0.002364338228716365, "phrase": "possible_paths"}, {"score": 0.0022773736136311056, "phrase": "large_codes"}, {"score": 0.002251911996999611, "phrase": "relatively_short_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["WCET", " Instruction cache-locking", " Line-buffer"], "paper_abstract": "In multitasking real-time systems it is required to compute the WCET of each task and also the effects of interferences between tasks in the worst case. This is very complex with variable latency hardware, such as instruction cache memories, or, to a lesser extent, the line buffers usually found in the fetch path of commercial processors. Some methods disable cache replacement so that it is easier to model the cache behavior. The difficulty in these cache-locking methods lies in obtaining a good selection of the memory lines to be locked into cache. In this paper, we propose an ILP-based method to select the best lines to be loaded and locked into the instruction cache at each context switch (dynamic locking), taking into account both intra-task and inter-task interferences, and we compare it with static locking. Our results show that, without cache, the spatial locality captured by a line buffer doubles the performance of the processor. When adding a lockable instruction cache, dynamic locking systems are schedulable with a cache size between 12.5% and 50% of the cache size required by static locking. Additionally, the computation time of our analysis method is not dependent on the number of possible paths in the task. This allows its to analyze large codes in a relatively short time (100 KB with 10(65) paths in less than 3 min). (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Improving the WCET computation in the presence of a lockable instruction cache in multitasking real-time systems", "paper_id": "WOS:000293939100003"}