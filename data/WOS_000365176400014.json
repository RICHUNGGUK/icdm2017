{"auto_keywords": [{"score": 0.033400976917232233, "phrase": "multi-agent_learning"}, {"score": 0.00481495049065317, "phrase": "evolutionary_dynamics_of_multi-agent_learning"}, {"score": 0.004676173016967478, "phrase": "multiple_autonomous_agents"}, {"score": 0.004608284537368354, "phrase": "highly_dynamic_and_non-deterministic_environments"}, {"score": 0.004442824994700736, "phrase": "automated_financial_markets"}, {"score": 0.0044104497301196794, "phrase": "smart_grids"}, {"score": 0.004283280680222718, "phrase": "sheer_number"}, {"score": 0.004039792863335641, "phrase": "optimal_behaviour"}, {"score": 0.0036731870109004993, "phrase": "new_situations"}, {"score": 0.003528244907944199, "phrase": "reinforcement_learning"}, {"score": 0.003476963781647026, "phrase": "single_and_multi-agent_settings"}, {"score": 0.003315374849824563, "phrase": "wide_range"}, {"score": 0.0032196786163178107, "phrase": "important_challenge"}, {"score": 0.003115307756631991, "phrase": "qualitative_insights"}, {"score": 0.003081272473508291, "phrase": "resulting_system_dynamics"}, {"score": 0.0029813748433158032, "phrase": "evolutionary_game_theory"}, {"score": 0.002905914725757534, "phrase": "multi-agent_learning_dynamics"}, {"score": 0.0028014064098604093, "phrase": "dynamical_models"}, {"score": 0.0026035011274172753, "phrase": "new_learning_algorithms"}, {"score": 0.00253758084385033, "phrase": "evolutionary_game_theoretic_tools"}, {"score": 0.0024915167458844914, "phrase": "evolutionary_models"}, {"score": 0.002437339565360659, "phrase": "complex_strategic_interactions"}, {"score": 0.00234104879370883, "phrase": "automated_trading"}, {"score": 0.002323953608863511, "phrase": "stock_markets"}, {"score": 0.002306982970571251, "phrase": "collision_avoidance"}, {"score": 0.002290135975651888, "phrase": "multi-robot_systems"}, {"score": 0.0021518035978153878, "phrase": "evolutionary_dynamics"}, {"score": 0.0021049977753042253, "phrase": "main_results"}], "paper_keywords": [""], "paper_abstract": "The interaction of multiple autonomous agents gives rise to highly dynamic and non-deterministic environments, contributing to the complexity in applications such as automated financial markets, smart grids, or robotics. Due to the sheer number of situations that may arise, it is not possible to foresee and program the optimal behaviour for all agents beforehand. Consequently, it becomes essential for the success of the system that the agents can learn their optimal behaviour and adapt to new situations or circumstances. The past two decades have seen the emergence of reinforcement learning, both in single and multi-agent settings, as a strong, robust and adaptive learning paradigm. Progress has been substantial, and a wide range of algorithms are now available. An important challenge in the domain of multi-agent learning is to gain qualitative insights into the resulting system dynamics. In the past decade, tools and methods from evolutionary game theory have been successfully employed to study multi-agent learning dynamics formally in strategic interactions. This article surveys the dynamical models that have been derived for various multi-agent reinforcement learning algorithms, making it possible to study and compare them qualitatively. Furthermore, new learning algorithms that have been introduced using these evolutionary game theoretic tools are reviewed. The evolutionary models can be used to study complex strategic interactions. Examples of such analysis are given for the domains of automated trading in stock markets and collision avoidance in multi-robot systems. The paper provides a roadmap on the progress that has been achieved in analysing the evolutionary dynamics of multi-agent learning by highlighting the main results and accomplishments.", "paper_title": "Evolutionary Dynamics of Multi-Agent Learning: A Survey", "paper_id": "WOS:000365176400014"}