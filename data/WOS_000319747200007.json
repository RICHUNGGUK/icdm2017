{"auto_keywords": [{"score": 0.044857284553732626, "phrase": "teragrid"}, {"score": 0.004498046936495544, "phrase": "wow"}, {"score": 0.004367108655796158, "phrase": "lifetimeaeuro\"lau_tzu"}, {"score": 0.0043367547691560175, "phrase": "large-scale_grid_computing_projects"}, {"score": 0.00418810762179987, "phrase": "vast_amounts"}, {"score": 0.00396075511616602, "phrase": "potentially_long_job_queues"}, {"score": 0.0038116231917604054, "phrase": "user's_work"}, {"score": 0.0034088473318056537, "phrase": "local_resources"}, {"score": 0.0033851312604425516, "phrase": "on-demand_resources"}, {"score": 0.0032012284065895537, "phrase": "remote_access"}, {"score": 0.0031678720736808574, "phrase": "environment_configuration"}, {"score": 0.003069867656852932, "phrase": "small_groups"}, {"score": 0.002974886152979993, "phrase": "grid_infrastructures"}, {"score": 0.002954180291607795, "phrase": "low_administrative_overhead"}, {"score": 0.002872783899731766, "phrase": "similar_objectives"}, {"score": 0.0028132076314202606, "phrase": "decentralized_system_organization"}, {"score": 0.0027936239349923464, "phrase": "user_access"}, {"score": 0.0027741761880779535, "phrase": "job_submission"}, {"score": 0.002697726021470387, "phrase": "grid_membership"}, {"score": 0.0026696020591118344, "phrase": "certificate_management"}, {"score": 0.002524473047010871, "phrase": "wide_area_overlay_network"}, {"score": 0.002395571076685383, "phrase": "mature_system"}, {"score": 0.0023133055945761235, "phrase": "architectural_description"}, {"score": 0.0022105600003496225, "phrase": "\"grid_appliance"}, {"score": 0.002172266188075892, "phrase": "case_study"}, {"score": 0.0021496083700137305, "phrase": "quantitative_analysis"}], "paper_keywords": ["Grid", " Cluster", " P2P", " Parallel applications", " VPN", " Cloud"], "paper_abstract": "Give a man a fish, feed him for a day. Teach a man to fish, feed him for a lifetimeaEuro\"Lau Tzu. Large-scale grid computing projects such as TeraGrid and Open Science Grid provide researchers vast amounts of compute resources but with requirements that could limit access, delay results due to potentially long job queues, and involve environments and policies that might affect a user's work flow. In many scenarios and in particular with the advent of Infrastructure-as-a-Service (IaaS) cloud computing, individual users and communities can benefit from less restrictive, dynamic systems that include a combination of local resources and on-demand resources provisioned by one or more IaaS provider. These types of scenarios benefit from flexibility in deploying resources, remote access, and environment configuration. In this paper, we address how small groups can dynamically create, join, and manage grid infrastructures with low administrative overhead. Our work distinguishes itself from other projects with similar objectives by enabling a combination of decentralized system organization and user access for job submission in addition to a web 2.0 interfaces for managing grid membership and automate certificate management. These components contribute to the design of the \"Grid Appliance,\" an implementation of a wide area overlay network of virtual workstations (WOW), which has developed over the past six years into a mature system with several deployments and many users. In addition to an architectural description, this paper contains lessons learned during the development and deployment of \"Grid Appliance\" systems and a case study backed by quantitative analysis that verifies the utility of our approach.", "paper_title": "Experiences with self-organizing, decentralized grids using the grid appliance", "paper_id": "WOS:000319747200007"}