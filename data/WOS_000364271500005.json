{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "effective_method"}, {"score": 0.0043793594257092805, "phrase": "different_times"}, {"score": 0.004320421465896323, "phrase": "different_groups"}, {"score": 0.004204904449336037, "phrase": "different_images"}, {"score": 0.00414830454375092, "phrase": "different_displays"}, {"score": 0.004092463367307375, "phrase": "observers'_eye-movement_data"}, {"score": 0.0039028500843175024, "phrase": "cielab"}, {"score": 0.0034780071331554003, "phrase": "visual_fields"}, {"score": 0.0034311578789991363, "phrase": "counting_methods"}, {"score": 0.00338493754743055, "phrase": "observer_variability"}, {"score": 0.003141598480804135, "phrase": "fixation_maps"}, {"score": 0.0029355502535757696, "phrase": "eye_movements"}, {"score": 0.0024607296642187824, "phrase": "entire_image"}, {"score": 0.0022682274656069643, "phrase": "eye-tracking_data"}, {"score": 0.002192522697738122, "phrase": "image_quality"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Region of interest", " Image quality assessment", " Eye movement", " Eye-tracking device"], "paper_abstract": "The aim of this study is to develop an effective method to analyze regions of interest (ROIs). Two experiments were conducted at different times using different groups of observers with different images on different displays. Observers' eye-movement data were collected. Fixation maps showing CIELAB L* values were created. The Delta L* values between the two maps were used to quantify differences in visual fields, counting methods, observer variability and repeatability between the two experiments. The results showed that fixation maps can be used to effectively analyze the distribution of eye movements between images. The Delta L* value calculated for two fixation maps is easy to understand and computes differences based only on ROIs more effectively than differences based on the entire image. The results from the two experiments were consistent, indicating that eye-tracking data are robust for evaluating image quality. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Identifying regions of interest in reading an image", "paper_id": "WOS:000364271500005"}