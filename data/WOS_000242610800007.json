{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "speech_movements"}, {"score": 0.004605258779434384, "phrase": "novel_method"}, {"score": 0.004537401559396022, "phrase": "speech_animation"}, {"score": 0.004470539706227421, "phrase": "low_quality_videos"}, {"score": 0.0042336638794732255, "phrase": "animated_faces"}, {"score": 0.004089475312474684, "phrase": "small_set"}, {"score": 0.003815607281455725, "phrase": "unsupervised_learning_process"}, {"score": 0.0034901729647741353, "phrase": "learning_process"}, {"score": 0.0032241994368246065, "phrase": "video_speech_movements"}, {"score": 0.003176626803985225, "phrase": "low-dimensional_manifold"}, {"score": 0.003023047748772801, "phrase": "low-dimensional_space"}, {"score": 0.002862648127577722, "phrase": "lsomap-based_learning_method"}, {"score": 0.0027650234530228897, "phrase": "speech_video_space"}, {"score": 0.0024793019587009035, "phrase": "limited_number"}, {"score": 0.0023130151703068444, "phrase": "skull_movement_recovery_method"}, {"score": 0.002278856202878812, "phrase": "simple_anatomical_structures"}, {"score": 0.002223039450439376, "phrase": "local_mouth_movements"}, {"score": 0.0022010965931147735, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "small_number"}], "paper_keywords": ["facial animation", " speech synchronization", " visual speech synthesis", " pe rfo rmance-driven animation", " machine learning"], "paper_abstract": "We present a novel method for transferring speech animation recorded in low quality videos to high resolution 3D face models. The basic idea is to synthesize the animated faces by an interpolation based on a small set of 3D key face shapes which span a 3D face space. The 3D key shapes are extracted by an unsupervised learning process in 2D video space to form a set of 2D visemes which are then mapped to the 3D face space. The learning process consists of two main phases: 1) Isomap-based nonlinear dimensionality reduction to embed the video speech movements into a low-dimensional manifold and 2) K-means clustering in the low-dimensional space to extract 2D key viseme frames. Our main contribution is that we use the lsomap-based learning method to extract intrinsic geometry of the speech video space and thus to make it possible to define the 3D key viseme shapes. To do so, we need only to capture a limited number of 3D key face models by using a general 3D scanner. Moreover, we also develop a skull movement recovery method based on simple anatomical structures to enhance 3D realism in local mouth movements. Experimental results show that our method can achieve realistic 3D animation effects with a small number of 3D key face models.", "paper_title": "Transferring of speech movements from video to 3D face space", "paper_id": "WOS:000242610800007"}