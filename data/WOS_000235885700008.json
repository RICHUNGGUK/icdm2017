{"auto_keywords": [{"score": 0.048868122179027085, "phrase": "linear_interpolation"}, {"score": 0.0482733743041587, "phrase": "maximum_entropy"}, {"score": 0.04191047267508905, "phrase": "test_point"}, {"score": 0.004815055610395946, "phrase": "nonparametric"}, {"score": 0.004430248457624686, "phrase": "entail_estimation"}, {"score": 0.004345909305473054, "phrase": "conditional_probabilities"}, {"score": 0.004263168852219819, "phrase": "relative_frequencies"}, {"score": 0.003750260412839128, "phrase": "learning_algorithm"}, {"score": 0.0033845816848753073, "phrase": "theoretical_properties"}, {"score": 0.0033200826267264383, "phrase": "lime_algorithm"}, {"score": 0.0032777653153451265, "phrase": "lime_weights"}, {"score": 0.0032359856233193504, "phrase": "exponential_form"}, {"score": 0.002977061391551628, "phrase": "additive_noise"}, {"score": 0.0028830690329478465, "phrase": "bias_reduction"}, {"score": 0.002378114613631841, "phrase": "related_maximum_entropy_problem"}, {"score": 0.002347775213789611, "phrase": "lime_simulation_results"}, {"score": 0.0021876814398268775, "phrase": "pipeline_integrity_classification_problem"}, {"score": 0.0021322065604537617, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "practical_value"}], "paper_keywords": ["nonparametric statistics", " probabilistic algorithms", " pattern recognition", " maximum entropy", " linear interpolation"], "paper_abstract": "Nonparametric neighborhood methods for learning entail estimation of class conditional probabilities based on relative frequencies of samples that are \"near-neighbors\" of a test point. We propose and explore the behavior of a learning algorithm that uses linear interpolation and the principle of maximum entropy (LIME). We consider some theoretical properties of the LIME algorithm: LIME weights have exponential form; the estimates are consistent; and the estimates are robust to additive noise. In relation to bias reduction, we show that near-neighbors contain a test point in their convex hull asymptotically. The common linear interpolation solution used for regression on grids or look-up-tables is shown to solve a related maximum entropy problem. LIME simulation results support use of the method, and performance on a pipeline integrity classification problem demonstrates that the proposed algorithm has practical value.", "paper_title": "Nonparametric supervised learning by linear interpolation with maximum entropy", "paper_id": "WOS:000235885700008"}