{"auto_keywords": [{"score": 0.04949646829078057, "phrase": "representative_selection"}, {"score": 0.036229190503611196, "phrase": "gkm"}, {"score": 0.007272823520220607, "phrase": "classic_k-means"}, {"score": 0.00481495049065317, "phrase": "nonlinear_manifold_clustering"}, {"score": 0.00461302961851157, "phrase": "nonlinear_manifold_structure"}, {"score": 0.004529093447865156, "phrase": "lower_dimension"}, {"score": 0.004081385289516914, "phrase": "manifold_characteristics"}, {"score": 0.0038862297330905836, "phrase": "corresponding_learning_algorithms"}, {"score": 0.0037231102027070724, "phrase": "manifold_structure"}, {"score": 0.0034804536625952596, "phrase": "graph-based_k-means_algorithm"}, {"score": 0.0032336801561165113, "phrase": "global_information"}, {"score": 0.0031942814007173254, "phrase": "data_geometric_distribution"}, {"score": 0.0030789331635764122, "phrase": "intrinsic_manifold_structure"}, {"score": 0.0030414140732789186, "phrase": "appropriate_data_clustering"}, {"score": 0.0025615908073796027, "phrase": "kernel_k-means"}, {"score": 0.002336414425972225, "phrase": "widespread_appearance"}, {"score": 0.0023079225317714815, "phrase": "manifold_structures"}, {"score": 0.0022797772939670063, "phrase": "real_world_problems"}, {"score": 0.002224510044064184, "phrase": "promising_potential"}, {"score": 0.002183938718432764, "phrase": "manifold-distributed_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["k-means", " Manifold clustering", " Random walk", " Graph learning"], "paper_abstract": "Many real-world applications expose the nonlinear manifold structure of the lower dimension rather than its high-dimensional input space. This greatly challenges most existing clustering and representative selection algorithms which do not take the manifold characteristics into consideration. The performance of the corresponding learning algorithms can be greatly improved if the manifold structure is considered. In this paper, we propose a graph-based k-means algorithm, GKM, which bears the simplicity of classic k-means while incorporating global information of data geometric distribution. GKM fully exploits the intrinsic manifold structure for appropriate data clustering and representative selection. GKM is evaluated on both synthetic and real-life data sets and achieves very impressive results compared to the state-of-the-art approaches, including classic k-means, kernel k-means, spectral clustering, and clustering through ranking and for representative selection. Given the widespread appearance of manifold structures in real world problems, GKM shows promising potential for partitioning manifold-distributed data. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A novel graph-based k-means for nonlinear manifold clustering and representative selection", "paper_id": "WOS:000340982800012"}