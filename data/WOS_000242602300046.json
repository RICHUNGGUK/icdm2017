{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "straightforward_generalization"}, {"score": 0.003370565320453525, "phrase": "regularizing_parameter"}, {"score": 0.0031079352545607267, "phrase": "upper_bound"}, {"score": 0.0029602552900111433, "phrase": "training_classification_error"}, {"score": 0.002397048726373276, "phrase": "simple_extension"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["LVQ1 algorithm", " nearest neighbour classifiers", " online gradient descent", " newton optimization", " pattern recognition"], "paper_abstract": "This paper introduces a straightforward generalization of the well-known LVQ1 algorithm for nearest neighbour classifiers that includes the standard LVQ1 and tile k-means algorithms as special cases. It is based on a regularizing parameter that monotonically decreases the upper bound of the training classification error towards a minimum. Experiments using 10 real data sets show the utility of this simple extension of LVQ1. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "The regularized LVQ1 algorithm", "paper_id": "WOS:000242602300046"}