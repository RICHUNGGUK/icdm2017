{"auto_keywords": [{"score": 0.0482620528308253, "phrase": "virtual_machines"}, {"score": 0.022751265472919394, "phrase": "tpcm"}, {"score": 0.010612387000973441, "phrase": "parallel_computing"}, {"score": 0.00872431715835001, "phrase": "tpcs"}, {"score": 0.007799065408330318, "phrase": "user_space"}, {"score": 0.005890424183018742, "phrase": "tpcs_scheduler"}, {"score": 0.0047310525657970615, "phrase": "task_mapper"}, {"score": 0.004567596860086148, "phrase": "application-aware_virtual_machine_scheduler_tpcs"}, {"score": 0.0044408896450445125, "phrase": "high_performance"}, {"score": 0.00440976345264104, "phrase": "virtual_computing_systems"}, {"score": 0.004302522426263979, "phrase": "mapping_tasks"}, {"score": 0.004227515355865597, "phrase": "virtual_machine_mapping_algorithm"}, {"score": 0.004197878397604354, "phrase": "vmma"}, {"score": 0.004081385289516914, "phrase": "load_balance"}, {"score": 0.003817456968395921, "phrase": "application-driven_scheduling"}, {"score": 0.003724566354526513, "phrase": "guest_os_kernel"}, {"score": 0.0035082436540296406, "phrase": "guest_os"}, {"score": 0.0033988361874354306, "phrase": "xen_hypervisor"}, {"score": 0.0033044432971036652, "phrase": "progress_statuses"}, {"score": 0.003223995503078124, "phrase": "underlying_kernel"}, {"score": 0.0031455000569352454, "phrase": "virtual_machine_scheduling_policy"}, {"score": 0.002983652306921617, "phrase": "completion_time"}, {"score": 0.002941913249957503, "phrase": "resource_utilization"}, {"score": 0.0029212625534156037, "phrase": "experimental_results"}, {"score": 0.002600661525224505, "phrase": "shorter_time"}, {"score": 0.0025194861926779223, "phrase": "task_progress"}, {"score": 0.002282755117032059, "phrase": "parallel_tasks"}, {"score": 0.0022192891418394514, "phrase": "higher_resource_utilization"}, {"score": 0.0021049977753042253, "phrase": "present_algorithms"}], "paper_keywords": ["Virtual machine", " Virtualization", " Application-aware", " Parallel computing", " Virtual machine mapping", " Credit algorithm", " Virtual machine scheduling"], "paper_abstract": "We design a task mapper TPCM for assigning tasks to virtual machines, and an application-aware virtual machine scheduler TPCS oriented for parallel computing to achieve a high performance in virtual computing systems. To solve the problem of mapping tasks to virtual machines, a virtual machine mapping algorithm (VMMA) in TPCM is presented to achieve load balance in a cluster. Based on such mapping results, TPCS is constructed including three components: a middleware supporting an application-driven scheduling, a device driver in the guest OS kernel, and a virtual machine scheduling algorithm. These components are implemented in the user space, guest OS, and the CPU virtualization subsystem of the Xen hypervisor, respectively. In TPCS, the progress statuses of tasks are transmitted to the underlying kernel from the user space, thus enabling virtual machine scheduling policy to schedule based on the progress of tasks. This policy aims to exchange completion time of tasks for resource utilization. Experimental results show that TPCM can mine the parallelism among tasks to implement the mapping from tasks to virtual machines based on the relations among subtasks. The TPCS scheduler can complete the tasks in a shorter time than can Credit and other schedulers, because it uses task progress to ensure that the tasks in virtual machines complete simultaneously, thereby reducing the time spent in pending, synchronization, communication, and switching. Therefore, parallel tasks can collaborate with each other to achieve higher resource utilization and lower overheads. We conclude that the TPCS scheduler can overcome the shortcomings of present algorithms in perceiving the progress of tasks, making it better than schedulers currently used in parallel computing.", "paper_title": "Task mapper and application-aware virtual machine scheduler oriented for parallel computing", "paper_id": "WOS:000301344100001"}