{"auto_keywords": [{"score": 0.04617122112854065, "phrase": "kslpda"}, {"score": 0.02270506833835658, "phrase": "feature_extraction"}, {"score": 0.007985432706895822, "phrase": "data-dependent_kernel"}, {"score": 0.005186077039386851, "phrase": "lpp"}, {"score": 0.00481495049065317, "phrase": "kernel_self-optimized"}, {"score": 0.004777917315737992, "phrase": "locality_preserving_discriminant_analysis"}, {"score": 0.004491678520807451, "phrase": "kernel_self-optimized_locality_preserving_discriminant_analysis"}, {"score": 0.003702702337768558, "phrase": "optimal_expansion"}, {"score": 0.003534889186471058, "phrase": "proposed_kernel_self-optimization_method"}, {"score": 0.0032972747743006603, "phrase": "optimal_projection_matrix"}, {"score": 0.003246672441842787, "phrase": "dimensionality_reduction"}, {"score": 0.0031477782772867655, "phrase": "optimal_parameters"}, {"score": 0.0029361086955646625, "phrase": "constraint_optimization_equation"}, {"score": 0.002846647336160784, "phrase": "maximum_margin_criterion"}, {"score": 0.002802941205762953, "phrase": "fisher_criterion"}, {"score": 0.0027386335451725762, "phrase": "empirical_feature_space"}, {"score": 0.0025151755329660837, "phrase": "comparative_experiments"}, {"score": 0.002419797252744636, "phrase": "pca"}, {"score": 0.002382624043668433, "phrase": "lda"}, {"score": 0.0022222152430170254, "phrase": "lpp._crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Locality preserving projection", " Kernel Self-optimized Locality Preserving", " Discriminant Analysis", " Kernel method", " Feature extraction"], "paper_abstract": "We propose Kernel Self-optimized Locality Preserving Discriminant Analysis (KSLPDA) for feature extraction and recognition. The procedure of KSLPDA is divided into two stages, i.e., one is to solve the optimal expansion of the data-dependent kernel with the proposed kernel self-optimization method, and the second is to seek the optimal projection matrix for dimensionality reduction. Since the optimal parameters of data-dependent kernel are achieved automatically through solving the constraint optimization equation, based on maximum margin criterion and Fisher criterion in the empirical feature space, KSLPDA works well on feature extraction for classification. The comparative experiments show that KSLPDA outperforms PCA, LDA, LPP, supervised LPP and kernel supervised LPP. Crown Copyright (C) 2011 Published by Elsevier B.V. All rights reserved.", "paper_title": "Kernel Self-optimized Locality Preserving Discriminant Analysis for feature extraction and recognition", "paper_id": "WOS:000296212400032"}