{"auto_keywords": [{"score": 0.03318201413262534, "phrase": "word_fragments"}, {"score": 0.008861457108886042, "phrase": "n-gram_models"}, {"score": 0.00481495049065317, "phrase": "morph_language_models"}, {"score": 0.004747622217683036, "phrase": "finnish"}, {"score": 0.0046593017130868, "phrase": "speech_recognition"}, {"score": 0.004466519142879166, "phrase": "traditional_word-based_language_modeling"}, {"score": 0.004281678802569817, "phrase": "distinct_word_forms"}, {"score": 0.004066076430818046, "phrase": "language_models"}, {"score": 0.003615443704375908, "phrase": "language_modeling"}, {"score": 0.003581620064675766, "phrase": "sub-word_units"}, {"score": 0.003531474887552889, "phrase": "whole_words"}, {"score": 0.0034171734618737436, "phrase": "considerable_improvements"}, {"score": 0.0033851984021896287, "phrase": "speech_recognition_performance"}, {"score": 0.0031845067058084583, "phrase": "language-independent_algorithm"}, {"score": 0.003095923814666088, "phrase": "unsupervised_manner"}, {"score": 0.0027395968397212053, "phrase": "language_modeling_and_speech_recognition_experiments"}, {"score": 0.0023566987138026285, "phrase": "grammatical_rules"}, {"score": 0.0021049977753042253, "phrase": "decoding_process"}], "paper_keywords": [""], "paper_abstract": "In the speech recognition of highly inflecting or compounding languages, the traditional word-based language modeling is problematic. As the number of-distinct word forms can grow very large, it becomes difficult to train language models that are both effective and cover the words of the language well. In the literature, several methods have been proposed for basing the language modeling on sub-word units instead of whole words. However, to our knowledge, considerable improvements in speech recognition performance have not been reported. In this article, we present a language-independent algorithm for discovering word fragments in an unsupervised manner from text. The algorithm uses the Minimum Description Length principle to find an inventory of word fragments that is compact but models the. training text effectively. Language modeling and speech recognition experiments show that n-gram models built over these fragments perform better than n-gram models based on words. In two Finnish recognition tasks, relative error rate reductions between 12% and 31% are obtained. In addition, our experiments suggest that word fragments obtained using grammatical rules do not outperform the fragments discovered from text. We also present our recognition system and discuss how utilizing fragments instead of words affects the decoding process. (c) 2005 Elsevier Ltd. All rights reserved.", "paper_title": "Unlimited vocabulary speech recognition with morph language models applied to Finnish", "paper_id": "WOS:000240727800008"}