{"auto_keywords": [{"score": 0.030094085269933755, "phrase": "similar_images"}, {"score": 0.00481495049065317, "phrase": "salient_features"}, {"score": 0.004696608876994947, "phrase": "existing_image_search_systems"}, {"score": 0.004424268136268051, "phrase": "content-based_image_retrieval"}, {"score": 0.004024863549087511, "phrase": "surrounding_contexts"}, {"score": 0.003945467978172845, "phrase": "web_pages"}, {"score": 0.003753738096719609, "phrase": "semantic_description"}, {"score": 0.00367967106192446, "phrase": "image_content"}, {"score": 0.0035183010916001664, "phrase": "annotation_watermarking_system"}, {"score": 0.0034317185678527672, "phrase": "text_descriptions"}, {"score": 0.003121636289442593, "phrase": "two-dimensional_code"}, {"score": 0.003014576010931602, "phrase": "discrete_wavelet_transform"}, {"score": 0.002769568481822277, "phrase": "cbir_techniques"}, {"score": 0.0027420820738468577, "phrase": "embedded_annotations"}, {"score": 0.0026217213613095322, "phrase": "global_features"}, {"score": 0.0025827837420330816, "phrase": "color_ratios"}, {"score": 0.0025571463140118805, "phrase": "dominant_sub-image_colors"}, {"score": 0.002420611343093316, "phrase": "scale-invariant_feature_transform"}, {"score": 0.0023259039577313294, "phrase": "similarity_matching"}, {"score": 0.0022573076362326135, "phrase": "good_effectiveness"}, {"score": 0.002234893735225432, "phrase": "reasonable_processing_time"}, {"score": 0.0022127018991294047, "phrase": "practical_systems"}, {"score": 0.002168975681697056, "phrase": "good_accuracy"}, {"score": 0.0021049977753042253, "phrase": "relevant_tags"}], "paper_keywords": ["Image Annotation", " CBIR", " Annotation watermarking", " SIFT", " QR code"], "paper_abstract": "Existing image search systems allow users to search images by keywords, or by example images through content-based image retrieval (CBIR). On the other hand, users might learn more relevant textual information about an image from its text captions or surrounding contexts within documents or Web pages. Without such contexts, it's difficult to extract semantic description directly from the image content. In this paper, we propose an annotation watermarking system for users to embed text descriptions, and retrieve more relevant textual information from similar images. First, tags associated with an image are converted by two-dimensional code and embedded into the image by discrete wavelet transform (DWT). Next, for images without annotations, similar images can be obtained by CBIR techniques and embedded annotations can be extracted. Specifically, we use global features such as color ratios and dominant sub-image colors for preliminary filtering. Then, local features such as Scale-Invariant Feature Transform (SIFT) descriptors are extracted for similarity matching. This design can achieve good effectiveness with reasonable processing time in practical systems. Our experimental results showed good accuracy in retrieving similar images and extracting relevant tags from similar images.", "paper_title": "An Image Retrieving Scheme Using Salient Features and Annotation Watermarking", "paper_id": "WOS:000333159800013"}