{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "cross_domain"}, {"score": 0.004584495834677719, "phrase": "increasing_attention"}, {"score": 0.00443141503046841, "phrase": "machine_learning"}, {"score": 0.004398094237005956, "phrase": "information_retrieval"}, {"score": 0.004156012879026324, "phrase": "user-given_query"}, {"score": 0.004109212945115815, "phrase": "human-labeled_training_dataset"}, {"score": 0.0040171817997972335, "phrase": "general_learning"}, {"score": 0.0039124037252916055, "phrase": "training_and_test_data"}, {"score": 0.0036691380448651443, "phrase": "real_world_applications"}, {"score": 0.0035198224928307854, "phrase": "labeled_training_data"}, {"score": 0.0033511469200347907, "phrase": "test_data"}, {"score": 0.0032884384364324395, "phrase": "new_problem"}, {"score": 0.0030033417337933625, "phrase": "ranking_model"}, {"score": 0.0029807267909921628, "phrase": "target_domain"}, {"score": 0.002913895605074143, "phrase": "outdated_or_out-of-domain_data"}, {"score": 0.002837811982066224, "phrase": "source_domain_data"}, {"score": 0.002763709443278514, "phrase": "formal_definition"}, {"score": 0.002591681512611419, "phrase": "knowledge_transfer"}, {"score": 0.002572158343938064, "phrase": "feature_level"}, {"score": 0.002552781867125423, "phrase": "instance_level"}, {"score": 0.0024395426929046415, "phrase": "basic_learner"}, {"score": 0.0023225152126545067, "phrase": "benchmark_datasets"}, {"score": 0.002305014991156598, "phrase": "document_retrieval"}, {"score": 0.0022447938263410023, "phrase": "feature-level_transfer_method"}, {"score": 0.0022110892229209407, "phrase": "steady_improvements"}, {"score": 0.002169667676959813, "phrase": "different_datasets"}, {"score": 0.002137088643982437, "phrase": "instance-level_transfer_method"}, {"score": 0.0021049977753042253, "phrase": "varying_performance"}], "paper_keywords": ["Information retrieval", " Learning to rank", " Knowledge transfer", " Ranking SVM"], "paper_abstract": "Recently, learning to rank technology is attracting increasing attention from both academia and industry in the areas of machine learning and information retrieval. A number of algorithms have been proposed to rank documents according to the user-given query using a human-labeled training dataset. A basic assumption behind general learning to rank algorithms is that the training and test data are drawn from the same data distribution. However, this assumption does not always hold true in real world applications. For example, it can be violated when the labeled training data become outdated or originally come from another domain different from its counterpart of test data. Such situations bring a new problem, which we define as cross domain learning to rank. In this paper, we aim at improving the learning of a ranking model in target domain by leveraging knowledge from the outdated or out-of-domain data (both are referred to as source domain data). We first give a formal definition of the cross domain learning to rank problem. Following this, two novel methods are proposed to conduct knowledge transfer at feature level and instance level, respectively. These two methods both utilize Ranking SVM as the basic learner. In the experiments, we evaluate these two methods using data from benchmark datasets for document retrieval. The results show that the feature-level transfer method performs better with steady improvements over baseline approaches across different datasets, while the instance-level transfer method comes out with varying performance depending on the dataset used.", "paper_title": "Knowledge transfer for cross domain learning to rank", "paper_id": "WOS:000278621400004"}