{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "state-of-the-art_data_mining_techniques"}, {"score": 0.00462919213721188, "phrase": "complex_data_relationships"}, {"score": 0.004431149592844886, "phrase": "top_classification_techniques"}, {"score": 0.004354315061804687, "phrase": "predictive_power"}, {"score": 0.003903269701018361, "phrase": "comprehensible_rule_sets"}, {"score": 0.0038692638652494697, "phrase": "complex_models"}, {"score": 0.0036553070575015344, "phrase": "new_rule_extraction_technique"}, {"score": 0.0035918768194006735, "phrase": "active_learning"}, {"score": 0.0035141291835319682, "phrase": "artificial_data_points"}, {"score": 0.0034835017385881385, "phrase": "training_data"}, {"score": 0.003453140302583322, "phrase": "low_confidence"}, {"score": 0.003408091901859624, "phrase": "output_score"}, {"score": 0.0032764307492734145, "phrase": "black-box_model"}, {"score": 0.0032336801561165113, "phrase": "main_novelty"}, {"score": 0.003191485583025302, "phrase": "proposed_method"}, {"score": 0.003108735847242537, "phrase": "pedagogical_approach"}, {"score": 0.0030547611342112693, "phrase": "architectural_assumptions"}, {"score": 0.0030148941188459987, "phrase": "underlying_model"}, {"score": 0.002898378776839434, "phrase": "black-box_technique"}, {"score": 0.0027985846558073457, "phrase": "rule_format"}, {"score": 0.002737960968372391, "phrase": "chosen_underlying_rule_induction_technique"}, {"score": 0.002690406375639144, "phrase": "large-scale_empirical_study"}, {"score": 0.002530359917257626, "phrase": "artificial_neural_networks"}, {"score": 0.002508284945907166, "phrase": "support_vector_machines"}, {"score": 0.002475532161577715, "phrase": "random_forests"}, {"score": 0.0024218895273910943, "phrase": "varying_size"}, {"score": 0.0023079225317714815, "phrase": "generated_rules"}, {"score": 0.0022777800735119405, "phrase": "black-box_models"}, {"score": 0.0021610874773389075, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "traditional_rule_induction_techniques"}], "paper_keywords": ["Active learning", " comprehensibility", " neural network", " random forest (RF)", " rule extraction", " support vector machine (SVM)"], "paper_abstract": "Many of the state-of-the-art data mining techniques introduce nonlinearities in their models to cope with complex data relationships effectively. Although such techniques are consistently included among the top classification techniques in terms of predictive power, their lack of transparency renders them useless in any domain where comprehensibility is of importance. Rule-extraction algorithms remedy this by distilling comprehensible rule sets from complex models that explain how the classifications are made. This paper considers a new rule extraction technique, based on active learning. The technique generates artificial data points around training data with low confidence in the output score, after which these are labeled by the black-box model. The main novelty of the proposed method is that it uses a pedagogical approach without making any architectural assumptions of the underlying model. It can therefore be applied to any black-box technique. Furthermore, it can generate any rule format, depending on the chosen underlying rule induction technique. In a large-scale empirical study, we demonstrate the validity of our technique to extract trees and rules from artificial neural networks, support vector machines, and random forests, on 25 data sets of varying size and dimensionality. Our results show that not only do the generated rules explain the black-box models well (thereby facilitating the acceptance of such models), the proposed algorithm also performs significantly better than traditional rule induction techniques in terms of accuracy as well as fidelity.", "paper_title": "Active Learning-Based Pedagogical Rule Extraction", "paper_id": "WOS:000363242800005"}