{"auto_keywords": [{"score": 0.04036754417187563, "phrase": "cpu-gpu_communication"}, {"score": 0.027217304358135155, "phrase": "cgcm"}, {"score": 0.00481495049065317, "phrase": "gpu_communication_management"}, {"score": 0.0047497818863130835, "phrase": "optimization"}, {"score": 0.004643594260262632, "phrase": "performance_benefits"}, {"score": 0.004576763709613412, "phrase": "gpu_parallelism"}, {"score": 0.004318881178805575, "phrase": "performance_potential"}, {"score": 0.004046020290832207, "phrase": "gpu_parallelizations"}, {"score": 0.0037087324991876727, "phrase": "communications_problems"}, {"score": 0.0035507457285983268, "phrase": "first_fully_automatic_system"}, {"score": 0.003424225677958491, "phrase": "cpu-gpu_communcation"}, {"score": 0.0032546105164772995, "phrase": "cpu-gpu_communication_manager"}, {"score": 0.0030709962527878656, "phrase": "run-time_library"}, {"score": 0.0029615198132465236, "phrase": "compiler_transformations"}, {"score": 0.002655894070657161, "phrase": "static_compile-time_analyses"}, {"score": 0.002598652897946253, "phrase": "programmer-supplied_annotations"}, {"score": 0.0025242409510332527, "phrase": "manual_gpu_parallelizations"}, {"score": 0.0023817332409567403, "phrase": "automatic_gpu_parallelizations"}, {"score": 0.002230984431056064, "phrase": "gpu_parallelization"}, {"score": 0.002182881082103045, "phrase": "whole_program_geomean_speedup"}, {"score": 0.0021049977753042253, "phrase": "best_sequential_cpu-only_execution"}], "paper_keywords": ["Algorithms", " Experimentation", " Performance", " GPU", " communication", " management", " optimization"], "paper_abstract": "The performance benefits of GPU parallelism can be enormous, but unlocking this performance potential is challenging. The applicability and performance of GPU parallelizations is limited by the complexities of CPU-GPU communication. To address these communications problems, this paper presents the first fully automatic system for managing and optimizing CPU-GPU communcation. This system, called the CPU-GPU Communication Manager (CGCM), consists of a run-time library and a set of compiler transformations that work together to manage and optimize CPU-GPU communication without depending on the strength of static compile-time analyses or on programmer-supplied annotations. CGCM eases manual GPU parallelizations and improves the applicability and performance of automatic GPU parallelizations. For 24 programs, CGCM-enabled automatic GPU parallelization yields a whole program geomean speedup of 5.36x over the best sequential CPU-only execution.", "paper_title": "Automatic CPU-GPU Communication Management and Optimization", "paper_id": "WOS:000294609500013"}