{"auto_keywords": [{"score": 0.044889326611916164, "phrase": "action_recognition"}, {"score": 0.014641000077659207, "phrase": "still_images"}, {"score": 0.011189624691057488, "phrase": "proposed_approach"}, {"score": 0.008713768692145006, "phrase": "person_description"}, {"score": 0.007600534031240362, "phrase": "single_body_part"}, {"score": 0.004768012159430855, "phrase": "challenging_problem"}, {"score": 0.004736973212570135, "phrase": "computer_vision"}, {"score": 0.0039579160185689325, "phrase": "significant_variations"}, {"score": 0.0038431888954930083, "phrase": "real-world_images"}, {"score": 0.003768550679591666, "phrase": "semantic_pyramid_approach"}, {"score": 0.003210652026669616, "phrase": "pretrained_state-of-the-art_upper-body"}, {"score": 0.003066945490483524, "phrase": "multiple_bounding_boxes"}, {"score": 0.0030369955065974222, "phrase": "body_part_detector"}, {"score": 0.0029779674919563734, "phrase": "simple_method"}, {"score": 0.0029392523663327253, "phrase": "best_candidate_bounding_box"}, {"score": 0.0028821186265508597, "phrase": "feature_extraction"}, {"score": 0.0028353540399641336, "phrase": "extracted_features"}, {"score": 0.002708399936381754, "phrase": "single_representation"}, {"score": 0.0026297965957221554, "phrase": "gender_recognition"}], "paper_keywords": ["Gender recognition", " action recognition", " pyramid representation", " bag-of-words"], "paper_abstract": "Person description is a challenging problem in computer vision. We investigated two major aspects of person description: 1) gender and 2) action recognition in still images. Most state-of-the-art approaches for gender and action recognition rely on the description of a single body part, such as face or full-body. However, relying on a single body part is suboptimal due to significant variations in scale, viewpoint, and pose in real-world images. This paper proposes a semantic pyramid approach for pose normalization. Our approach is fully automatic and based on combining information from full-body, upper-body, and face regions for gender and action recognition in still images. The proposed approach does not require any annotations for upper-body and face of a person. Instead, we rely on pretrained state-of-the-art upper-body and face detectors to automatically extract semantic information of a person. Given multiple bounding boxes from each body part detector, we then propose a simple method to select the best candidate bounding box, which is used for feature extraction. Finally, the extracted features from the full-body, upper-body, and face regions are combined into a single representation for classification. To validate the proposed approach for gender recognition, experiments are performed on three large data sets namely: 1) human attribute; 2) head-shoulder; and 3) proxemics. For action recognition, we perform experiments on four data sets most used for benchmarking action recognition in still images: 1) Sports; 2) Willow; 3) PASCAL VOC 2010; and 4) Stanford-40. Our experiments clearly demonstrate that the proposed approach, despite its simplicity, outperforms state-of-the-art methods for gender and action recognition.", "paper_title": "Semantic Pyramids for Gender and Action Recognition", "paper_id": "WOS:000340094000003"}