{"auto_keywords": [{"score": 0.033595611304883546, "phrase": "joint-specific_hmms"}, {"score": 0.010016709891002186, "phrase": "body_joints"}, {"score": 0.004815022356293929, "phrase": "hmm"}, {"score": 0.004751419645257496, "phrase": "human_activity_recognition"}, {"score": 0.0047262415242538105, "phrase": "stereo_posture_image_sequence"}, {"score": 0.004639159282212062, "phrase": "stereo_camera-based_novel_approach"}, {"score": 0.004446065049564053, "phrase": "hidden_markov_models"}, {"score": 0.004352539814771422, "phrase": "body_joint_angles"}, {"score": 0.004227132853636806, "phrase": "stereo_video_information"}, {"score": 0.004127208288457274, "phrase": "human_posture"}, {"score": 0.004083555803143928, "phrase": "stereo_camera"}, {"score": 0.004029636266402555, "phrase": "joint_angles"}, {"score": 0.003976425844082854, "phrase": "discriminant_feature_extraction"}, {"score": 0.003831130857788212, "phrase": "traditional_approach"}, {"score": 0.0037206907808927, "phrase": "unnecessary_joint_features"}, {"score": 0.0034906177145305403, "phrase": "body_joint_motion_information"}, {"score": 0.003371972121469904, "phrase": "freedom_values"}, {"score": 0.0033097596691947593, "phrase": "current_frame"}, {"score": 0.0032314503787831336, "phrase": "new_way"}, {"score": 0.0032057598719267594, "phrase": "human_activities"}, {"score": 0.0031466043322866347, "phrase": "motion_information"}, {"score": 0.0031050177923315587, "phrase": "next_frame"}, {"score": 0.0030721434170160474, "phrase": "freedom_information"}, {"score": 0.0030315379838336334, "phrase": "time-sequential_distinguished_activity_video_frames"}, {"score": 0.002944079663176723, "phrase": "joint_features"}, {"score": 0.0028591372344443154, "phrase": "discrete_symbols"}, {"score": 0.002747231491970157, "phrase": "different_activities"}, {"score": 0.0026893455480701297, "phrase": "activity_class"}, {"score": 0.0026608603558321816, "phrase": "time-sequential_body_joint_features"}, {"score": 0.002570345349576604, "phrase": "trained_joint-specific_hmms"}, {"score": 0.0024048209203996595, "phrase": "body_joint_features"}, {"score": 0.0023793421855407746, "phrase": "corresponding_activities"}, {"score": 0.002298381568771641, "phrase": "highest_likelihood"}, {"score": 0.002280092127862092, "phrase": "summed_likelihoods"}, {"score": 0.0021966429368447354, "phrase": "active_body_joints"}, {"score": 0.0021791613158909694, "phrase": "superior_recognition_performance"}, {"score": 0.0021503332345216273, "phrase": "augmented_joint_angle_feature-based_single_hmm"}, {"score": 0.0021049977753042253, "phrase": "traditional_silhouette-based_approaches"}], "paper_keywords": ["Human activity recognition", " Stereo image", " Depth information", " Hidden Markov Models"], "paper_abstract": "In this paper, a stereo camera-based novel approach for Human Activity Recognition (HAR) is presented using robust 3-D human body joint features and joint-specific Hidden Markov Models (HMMs). At first, body joint angles are estimated by co-registering a 3-D body model to the stereo video information (i.e., 3-D depth) of a human posture acquired by a stereo camera. Conventionally, all joint angles are augmented followed by discriminant feature extraction from them and a HMM is modeled for each activity. Although the traditional approach is straight forward and easy to implement but dependent to unnecessary joint features which are not even used in the activity. In this study, we focus on individual 3-D body joints rather than all joints together and body joint motion information in next frame is also considered in addition to the degree of freedom values (i.e., joint angles in current frame) of a joint. We propose a new way of modeling human activities and derive joint-specific HMMs. Based on motion information of the joints in next frame and degree of freedom information of body joints in the time-sequential distinguished activity video frames, the different activity classes are determined first. Each joint features are then mapped into codewords to generate a sequence of discrete symbols for joint-specific HMM. Then, joint-specific HMMs are trained according to their use in different activities. For testing, after determining the activity class based on the time-sequential body joint features, the discrete symbol sequence from each joint is applied to the trained joint-specific HMMs of the activities from that class only. Thus, for all body joints, the likelihoods of all activities are obtained by applying all body joint features and then, likelihoods for corresponding activities are summed up. Finally, one activity has been chosen with the highest likelihood from the summed likelihoods. Using joint-specific HMMs (i.e., multiple HMMs for an activity based on active body joints), superior recognition performance is obtained than the augmented joint angle feature-based single HMM for an activity as well as the traditional silhouette-based approaches.", "paper_title": "3-D body joint-specific HMM-based approach for human activity recognition from stereo posture image sequence", "paper_id": "WOS:000365446600012"}