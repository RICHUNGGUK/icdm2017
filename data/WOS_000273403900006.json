{"auto_keywords": [{"score": 0.04748639526774138, "phrase": "summary_statistics"}, {"score": 0.00481495049065317, "phrase": "approximate_bayesian_computation"}, {"score": 0.004739056045644449, "phrase": "approximate_bayesian_inference"}, {"score": 0.004342430078306461, "phrase": "complex_problems"}, {"score": 0.0032614317990293695, "phrase": "machine-learning_approach"}, {"score": 0.003109390330476147, "phrase": "posterior_density"}, {"score": 0.002964415652865295, "phrase": "new_method"}, {"score": 0.0028944757265206332, "phrase": "nonlinear_conditional_heteroscedastic_regression"}, {"score": 0.0025892330566358503, "phrase": "importance_sampling"}, {"score": 0.00252812242767189, "phrase": "new_algorithm"}, {"score": 0.002429451930463481, "phrase": "state-of-the-art_approximate_bayesian_methods"}, {"score": 0.002279508335630797, "phrase": "computational_burden"}, {"score": 0.0021731423856364003, "phrase": "statistical_genetics"}, {"score": 0.0021049977753042253, "phrase": "queueing_model"}], "paper_keywords": ["Likelihood-free inference", " Curse of dimensionality", " Feed forward neural networks", " Heteroscedasticity", " Coalescent models", " Approximate Bayesian computation", " Conditional density estimation", " Implicit statistical models", " Importance sampling", " Non-linear regression", " Indirect inference"], "paper_abstract": "Approximate Bayesian inference on the basis of summary statistics is well-suited to complex problems for which the likelihood is either mathematically or computationally intractable. However the methods that use rejection suffer from the curse of dimensionality when the number of summary statistics is increased. Here we propose a machine-learning approach to the estimation of the posterior density by introducing two innovations. The new method fits a nonlinear conditional heteroscedastic regression of the parameter on the summary statistics, and then adaptively improves estimation using importance sampling. The new algorithm is compared to the state-of-the-art approximate Bayesian methods, and achieves considerable reduction of the computational burden in two examples of inference in statistical genetics and in a queueing model.", "paper_title": "Non-linear regression models for Approximate Bayesian Computation", "paper_id": "WOS:000273403900006"}