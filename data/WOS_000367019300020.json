{"auto_keywords": [{"score": 0.042986545468841085, "phrase": "false_matches"}, {"score": 0.015369634007014186, "phrase": "novel_method"}, {"score": 0.012956854304154912, "phrase": "point_matching"}, {"score": 0.008818828266836411, "phrase": "affine_transformations"}, {"score": 0.00481495049065317, "phrase": "local_feature_analysis"}, {"score": 0.004676038405185284, "phrase": "affine_transformation_estimation"}, {"score": 0.004645714863712397, "phrase": "image_regions"}, {"score": 0.004511663118269957, "phrase": "proposed_method"}, {"score": 0.004395742407834023, "phrase": "large_amounts"}, {"score": 0.004367228576339114, "phrase": "point_matches"}, {"score": 0.004338898899247236, "phrase": "highly_accurate_localization"}, {"score": 0.00419997182602686, "phrase": "matched_region"}, {"score": 0.003986844722309844, "phrase": "low_computational_demand"}, {"score": 0.0038717306726380233, "phrase": "computer_vision"}, {"score": 0.0037599278182081056, "phrase": "object_detection"}, {"score": 0.003735522846193052, "phrase": "object_tracking"}, {"score": 0.003639471039860495, "phrase": "major_challenge"}, {"score": 0.0035574466515880337, "phrase": "large_numbers"}, {"score": 0.0035343512834706417, "phrase": "accurate_matches"}, {"score": 0.0035114053248663335, "phrase": "corresponding_scene_locations"}, {"score": 0.003488607816047529, "phrase": "different_geometric_and_radiometric_conditions"}, {"score": 0.003376813851525222, "phrase": "recent_publications"}, {"score": 0.003311458758488674, "phrase": "affine_transformation_model"}, {"score": 0.0032899551003641152, "phrase": "local_regions"}, {"score": 0.003257960296952439, "phrase": "particularly_suitable_approach"}, {"score": 0.0032053233533168362, "phrase": "affine_invariant_methods"}, {"score": 0.003012919635505122, "phrase": "derived_affine_estimations"}, {"score": 0.0029933487820771217, "phrase": "limited_accuracy"}, {"score": 0.0028879529188983524, "phrase": "region_expansion"}, {"score": 0.002859856368059419, "phrase": "region_matches"}, {"score": 0.0027057145726287427, "phrase": "accurate_estimation"}, {"score": 0.0026274936167233515, "phrase": "matching_locations"}, {"score": 0.0026104197983396367, "phrase": "initially_detected_matches"}, {"score": 0.002585016334273749, "phrase": "suggested_method"}, {"score": 0.002568217828414509, "phrase": "improved_localization"}, {"score": 0.002543224008253855, "phrase": "detected_matches"}, {"score": 0.0025021056497407765, "phrase": "local_transformation_estimations"}, {"score": 0.002477753633057247, "phrase": "crucial_part"}, {"score": 0.00242184774931214, "phrase": "geometric_verification"}, {"score": 0.0023672002840029517, "phrase": "local_region_matches"}, {"score": 0.002268955084689299, "phrase": "improved_estimations"}, {"score": 0.002210529584311044, "phrase": "tentative_matches"}, {"score": 0.002189009136006588, "phrase": "efficient_way"}, {"score": 0.0021049977753042253, "phrase": "correct_matches"}], "paper_keywords": ["point matching", " feature matching", " affine transformation", " outlier rejection"], "paper_abstract": "We present a novel method for affine transformation estimation of image regions. We illustrate the benefits of using the proposed method in three realms: (1) locating large amounts of point matches with highly accurate localization; (2) producing very accurate affine transformation estimations of for each matched region; (3) effectively rejecting false matches. We show that this is achievable with low computational demand. Point matching is one of the most fundamental tasks in computer vision, being used extensively in applications such as object detection, object tracking, and structure from motion. The major challenge in point matching is to preserve large numbers of accurate matches between corresponding scene locations under different geometric and radiometric conditions, while keeping the number of false matches small. Recent publications have shown that applying the affine transformation model on local regions is a particularly suitable approach for point matching. Yet affine invariant methods are not used extensively for two reasons. First, these methods are computationally demanding; second, the derived affine estimations have limited accuracy. In this work, we propose a novel method of region expansion that enhances region matches detected by any state-of-the-art method. The method is based on accurate estimation of affine transformations, which is used to predict matching locations beyond initially detected matches. The suggested method achieves improved localization of the detected matches. The accuracy of local transformation estimations plays a crucial part in tasks that are based on geometric verification. We prove that expansion beyond local region matches is crucial for obtaining much more accurate local transformation estimations than previously possible. We utilize the improved estimations of affine transformations in order to locally verify tentative matches in an efficient way. We systematically reject false matches, while improving the localization of correct matches that are usually rejected by state-of-the-art methods.", "paper_title": "Geometric Expansion for Local Feature Analysis and Matching", "paper_id": "WOS:000367019300020"}