{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "enumeration_queries"}, {"score": 0.004270178957872099, "phrase": "query_processing"}, {"score": 0.004092937456065441, "phrase": "data_gathering"}, {"score": 0.0037073529462522403, "phrase": "closed_world_assumption"}, {"score": 0.0036553070575015344, "phrase": "relational_query_semantics"}, {"score": 0.003310813458610484, "phrase": "even_simple_queries"}, {"score": 0.00310664242361199, "phrase": "query_progress_monitoring"}, {"score": 0.0028944757265206332, "phrase": "crowdsourced_data"}, {"score": 0.002735194789581153, "phrase": "crowdsourcing_systems"}, {"score": 0.0025664295665392203, "phrase": "statistical_tools"}, {"score": 0.0024772013657695896, "phrase": "systems_developers"}, {"score": 0.002408052242408488, "phrase": "query_completeness"}, {"score": 0.002275477757478827, "phrase": "query_execution"}, {"score": 0.0022434880661725493, "phrase": "crowdsourcing_strategies"}, {"score": 0.0021049977753042253, "phrase": "popular_crowdsourcing_platform"}], "paper_keywords": ["Database design", " modeling and management", " user interfaces"], "paper_abstract": "Hybrid human/computer database systems promise to greatly expand the usefulness of query processing by incorporating the crowd for data gathering and other tasks. Such systems raise many implementation questions. Perhaps the most fundamental issue is that the closed world assumption underlying relational query semantics does not hold in such systems. As a consequence, the meaning of even simple queries can be called into question. Furthermore, query progress monitoring becomes difficult due to non-uniformities in the arrival of crowdsourced data and peculiarities of how people work in crowdsourcing systems. To address these issues, we develop statistical tools that enable users and systems developers to reason about query completeness. These tools can also help drive query execution and crowdsourcing strategies. We evaluate our techniques using experiments on a popular crowdsourcing platform.", "paper_title": "Crowdsourcing Enumeration Queries: Estimators and Interfaces", "paper_id": "WOS:000355937800006"}