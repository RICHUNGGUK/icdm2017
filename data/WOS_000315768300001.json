{"auto_keywords": [{"score": 0.033201756509144524, "phrase": "siso_nns"}, {"score": 0.013514457071887198, "phrase": "computational_costs"}, {"score": 0.00481495049065317, "phrase": "parallel_optimized_learning_for_neural_networks"}, {"score": 0.00477190623242136, "phrase": "mimo_applications"}, {"score": 0.004708056866527125, "phrase": "automatic_and_optimized_approach"}, {"score": 0.004645057834614705, "phrase": "multivariate_functions"}, {"score": 0.004461051943902492, "phrase": "single-input-single-output"}, {"score": 0.004322967486451877, "phrase": "neural_networks"}, {"score": 0.0041891398413899435, "phrase": "often_the_learning_time"}, {"score": 0.004023120753104693, "phrase": "effective_use"}, {"score": 0.003987126862293129, "phrase": "mimo_nns"}, {"score": 0.0038985392250620483, "phrase": "miso_neural_model"}, {"score": 0.0038119123317396954, "phrase": "single_mimo_nn"}, {"score": 0.003677280504320636, "phrase": "proposed_method"}, {"score": 0.0032132782979796895, "phrase": "miso_nn"}, {"score": 0.003044455555031339, "phrase": "multidimensional_single_value_decomposition"}, {"score": 0.002936849401568391, "phrase": "general_approach"}, {"score": 0.002897482096228207, "phrase": "learning_optimization"}, {"score": 0.0025660347613972573, "phrase": "suitable_learning_conditions"}, {"score": 0.0025089420019955232, "phrase": "siso_nn"}, {"score": 0.0024311346712789553, "phrase": "limited_training_data"}, {"score": 0.002387758958649797, "phrase": "significant_decrease"}, {"score": 0.002313701040445819, "phrase": "parallel_architecture"}, {"score": 0.0022218413146898887, "phrase": "presented_approach"}, {"score": 0.0021723899772112423, "phrase": "automatic_conversion"}, {"score": 0.0021529183360603434, "phrase": "mimo_nn"}, {"score": 0.0021049977753042253, "phrase": "parallel-optimized_siso_nns"}], "paper_keywords": ["networks", " multivariate function decomposition", " learning optimization", " parallel computing", " genetic algorithms"], "paper_abstract": "An automatic and optimized approach based on multivariate functions decomposition is presented to face Multi-Input-Multi-Output (MIMO) applications by using Single-Input-Single-Output (SISO) feed-forward Neural Networks (NNs). Indeed, often the learning time and the computational costs are too large for an effective use of MIMO NNs. Since performing a MISO neural model by starting from a single MIMO NN is frequently adopted in literature, the proposed method introduces three other steps: 1) a further decomposition; 2) a learning optimization; 3) a parallel training to speed up the process. Starting from a MISO NN, a collection of SISO NNs can be obtained by means a multidimensional Single Value Decomposition (SVD). Then, a general approach for the learning optimization of SISO NNs is applied. It is based on the observation that the performances of SISO NNs improve in terms of generalization and robustness against noise under suitable learning conditions. Thus, each SISO NN is trained and optimized by using limited training data that allow a significant decrease of computational costs. Moreover, a parallel architecture can be easily implemented. Consequently, the presented approach allows to perform an automatic conversion of MIMO NN into a collection of parallel-optimized SISO NNs. Experimental results will be suitably shown.", "paper_title": "Automatic and Parallel Optimized Learning for Neural Networks performing MIMO Applications", "paper_id": "WOS:000315768300001"}