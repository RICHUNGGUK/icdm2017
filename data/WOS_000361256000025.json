{"auto_keywords": [{"score": 0.04902194563396072, "phrase": "deep_neural_networks"}, {"score": 0.031862565675836, "phrase": "based_systems"}, {"score": 0.013646142908380676, "phrase": "chinese"}, {"score": 0.010183610320574495, "phrase": "experimental_results"}, {"score": 0.007798680725607094, "phrase": "multiple_modeling_units"}, {"score": 0.00481495049065317, "phrase": "comparative_study"}, {"score": 0.004750873844061641, "phrase": "acoustic_modeling_units"}, {"score": 0.004666756595735701, "phrase": "large_vocabulary_chinese_speech_recognition"}, {"score": 0.004502943680955863, "phrase": "different_acoustic_modeling_units"}, {"score": 0.004063186599879217, "phrase": "based_acoustic_modeling_method"}, {"score": 0.0038338299812503, "phrase": "current_lvcsr_research"}, {"score": 0.0037827603118271757, "phrase": "previous_work"}, {"score": 0.0036991458715587163, "phrase": "independent_and_context_dependent_dnns"}, {"score": 0.003459191419478298, "phrase": "basic_modeling_units"}, {"score": 0.003367611042980526, "phrase": "based_lvcsr_systems"}, {"score": 0.002905454531687249, "phrase": "best_performance"}, {"score": 0.00269263690712392, "phrase": "clustered_states"}, {"score": 0.0025291018422967083, "phrase": "different_properties"}, {"score": 0.0024075916292945715, "phrase": "multi-task_learning_strategy"}, {"score": 0.0023125191783901367, "phrase": "dnns_training_procedure"}, {"score": 0.0022112700457629494, "phrase": "multi-task_learning"}, {"score": 0.002181766829493483, "phrase": "individual_modeling_unit"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Deep neural networks", " Multi-task learning", " Chinese automatic speech recognition", " Acoustic modeling units", " Syllable"], "paper_abstract": "This paper compared the performance of different acoustic modeling units in deep neural networks (DNNs) based large vocabulary continuous speech recognition (LVCSR) systems for Chinese. Recently, the deep neural networks based acoustic modeling method has achieved very competitive performance for many speech recognition tasks, and has become the focus of current LVCSR research. Some previous work have studied the context independent and context dependent DNNs based acoustic models. For Chinese, a syllabic language, the choice of basic modeling units under the background of DNNs based LVCSR systems is a very important issue. Three basic modeling units, syllables, initial/finals, phones, are discussed and compared. Experimental results show that, in the DNNs based systems, the context dependent (CD) phones obtain the best performance, and the context independent (Cl) syllables have the similar performance with the CD initial/finals. How the number of clustered states impacts on the performance of DNNs based systems is also discussed, which showed different properties from the GMMs based systems. Besides, through introducing the multi-task learning strategy, these multiple modeling units can be combined in the DNNs training procedure. The experimental results indicate that combining these multiple modeling units using multi-task learning outperforms each individual modeling unit. (C) 2015 Published by Elsevier B.V.", "paper_title": "A comparative study on selecting acoustic modeling units in deep neural networks based large vocabulary Chinese speech recognition", "paper_id": "WOS:000361256000025"}