{"auto_keywords": [{"score": 0.04117203761734825, "phrase": "au"}, {"score": 0.00481495049065317, "phrase": "facial_action_units_recognition."}, {"score": 0.004769788530328504, "phrase": "theoretical_point"}, {"score": 0.004710227709931926, "phrase": "hidden_markov_models"}, {"score": 0.0046368166127362925, "phrase": "dynamic_bayesian_networks"}, {"score": 0.004465243405240743, "phrase": "different_challenges"}, {"score": 0.004395633639958821, "phrase": "different_manner"}, {"score": 0.004286498418857255, "phrase": "comparative_analysis"}, {"score": 0.004221244620434399, "phrase": "ekman"}, {"score": 0.004033234255129624, "phrase": "friesen"}, {"score": 0.0038534853154928985, "phrase": "facs"}, {"score": 0.003651477256755136, "phrase": "extensive_palette"}, {"score": 0.0036285822640427525, "phrase": "facial_expressions"}, {"score": 0.0033753504302443346, "phrase": "best_methodology"}, {"score": 0.0032914631538239003, "phrase": "common_basis"}, {"score": 0.0030520667324977473, "phrase": "relative_performance"}, {"score": 0.0029389598856744436, "phrase": "different_region"}, {"score": 0.002838954179574289, "phrase": "different_optical_flow_estimation_methods"}, {"score": 0.002777088408582301, "phrase": "aus_classification"}, {"score": 0.002725131817708033, "phrase": "facial_expression_recognition_process"}, {"score": 0.0026910337912859268, "phrase": "even_one_emotion"}, {"score": 0.0025588443155279855, "phrase": "analyzed_problem"}, {"score": 0.0024951987856762646, "phrase": "cohn-kanade_database"}, {"score": 0.002372606268769639, "phrase": "classification_methods"}, {"score": 0.002357710902984216, "phrase": "similar_results"}, {"score": 0.00227743851871825, "phrase": "facial_aus"}, {"score": 0.002234808936443945, "phrase": "non-fixed_sampling"}, {"score": 0.002213793650525558, "phrase": "htk"}, {"score": 0.0021792054532842682, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "special_task"}], "paper_keywords": ["Hidden Markov Models", " Dynamic Bayesian Networks", " Facial Action Units Recognition", " Facial Action Coding System"], "paper_abstract": "From a theoretical point of view, Hidden Markov Models (HMMs) and Dynamic Bayesian Networks (DBNs) are similar, still in practice they pose different challenges and perform in a different manner. In this study we present a comparative analysis of the two spatial-temporal classification methods: HMMs and DBNs applied to the Facial Action Units (AUs) recognition problem. The Facial Action Coding System (FACS) developed by Ekman and Friesen decomposes the face into 46 AUs, each AU being related to the contraction of one or more specific facial muscles. FACS proved its applicability to facial behavior modeling, enabling the recognition of an extensive palette of facial expressions. Even though a lot has been published on this theme, it is still difficult to draw a conclusion regarding the best methodology to follow, as there is no common basis for comparison and sometimes no argument is given why a certain classification method was chosen. Therefore, our main contributions reside in discussing and comparing the relative performance of the two proposed classifiers (HMMs vs. DBNs) and also of different Region of Interest (ROT) selections proposed by us and different optical flow estimation methods. We can consider our automatic system towards AUs classification an important step in the facial expression recognition process, given that even one emotion can be expressed in different. ways, fact that suggests the complexity of the analyzed problem. The experiments were performed on the Cohn-Kanade database and showed that under the same conditions regarding initialization, labeling, and sampling, both classification methods produced similar results, achieving the same recognition rate of 89% for the classification of facial AUs. Still, by enabling non-fixed sampling and using HTK, HMMs rendered a better performance of 93% suggesting that they are better suited for the special task of AUs recognition.", "paper_title": "A COMPARATIVE STUDY OF HMMS AND DBNS APPLIED TO FACIAL ACTION UNITS RECOGNITION", "paper_id": "WOS:000286684200004"}