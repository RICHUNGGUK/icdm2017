{"auto_keywords": [{"score": 0.04117729234560256, "phrase": "gpu"}, {"score": 0.00481495049065317, "phrase": "gpu_systems"}, {"score": 0.004743594110762319, "phrase": "processing_units"}, {"score": 0.004650086856905758, "phrase": "large_array"}, {"score": 0.004604023526673226, "phrase": "parallel_processing_cores"}, {"score": 0.004446349752828045, "phrase": "streaming_computation_patterns"}, {"score": 0.004358676214574977, "phrase": "graphics_applications"}, {"score": 0.0040854526743211396, "phrase": "unfavorable_data_layout_and_poor_computation-to-communication_ratios"}, {"score": 0.0037537380967196123, "phrase": "performance-driven_code_generation_framework"}, {"score": 0.0036980501827538455, "phrase": "general_purpose_streaming_applications"}, {"score": 0.0035891316580885665, "phrase": "automated_framework"}, {"score": 0.003448863509392547, "phrase": "gpu_pipeline"}, {"score": 0.003397683082821229, "phrase": "unique_memory_hierarchy"}, {"score": 0.0032004205378150354, "phrase": "streamit_programming_language_compiler"}, {"score": 0.0030906666356950887, "phrase": "maximized_performance"}, {"score": 0.002984665318717504, "phrase": "generated_code"}, {"score": 0.0028966970007550798, "phrase": "on-chip_memory_hierarchy"}, {"score": 0.0028394925080958205, "phrase": "heterogeneous_mix"}, {"score": 0.0027834145465170292, "phrase": "memory_access"}, {"score": 0.002687922713487696, "phrase": "conventional_wisdom"}, {"score": 0.0026612444314342023, "phrase": "gpu_programming"}, {"score": 0.0025827837420330816, "phrase": "large_number"}, {"score": 0.0025571463140118805, "phrase": "homogeneous_threads"}, {"score": 0.0024693979425773993, "phrase": "efficient_stream_graph"}, {"score": 0.002408565679880478, "phrase": "larger_applications"}, {"score": 0.0023609780669713288, "phrase": "best_performance"}, {"score": 0.0022460727898764216, "phrase": "complex_applications"}, {"score": 0.002223770196464436, "phrase": "multiple_gpus"}, {"score": 0.0021907299375981356, "phrase": "highly_effective_parallel_execution_scheme"}, {"score": 0.0021049977753042253, "phrase": "significant_speedup"}], "paper_keywords": ["GPU", " multi-GPU", " scalable", " streaming application", " streamIt"], "paper_abstract": "Graphics processing units leverage on a large array of parallel processing cores to boost the performance of the streaming computation patterns frequently found in graphics applications. Unfortunately, while many other general purpose applications also exhibit streaming behavior, they possess unfavorable data layout and poor computation-to-communication ratios that may penalize any straight-forward GPU implementation. In this paper we describe a performance-driven code generation framework that maps general purpose streaming applications onto GPU systems. This automated framework takes into account the idiosyncrasies of the GPU pipeline and the unique memory hierarchy. The framework has been implemented as a back-end to the StreamIt programming language compiler. Several key features in this framework ensure maximized performance and scalability. First, the generated code increases the effectiveness of the on-chip memory hierarchy by employing a heterogeneous mix of compute and memory access threads. Our scheme goes against the conventional wisdom of GPU programming which is to use a large number of homogeneous threads. Second, we utilise an efficient stream graph partitioning algorithm to handle larger applications and achieve the best performance under the given on-chip memory constraints. Lastly, the framework maps complex applications onto multiple GPUs using a highly effective parallel execution scheme. Our comprehensive experiments show its scalability and significant speedup compared to a previous state-of-the-art solution.", "paper_title": "Mapping Streaming Applications onto GPU Systems", "paper_id": "WOS:000342179000016"}