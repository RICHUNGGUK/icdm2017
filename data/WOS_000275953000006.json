{"auto_keywords": [{"score": 0.0346777204973957, "phrase": "message_sizes"}, {"score": 0.00481495049065317, "phrase": "high_performance"}, {"score": 0.004600389726895716, "phrase": "explicit_finite_element_analysis"}, {"score": 0.004445739135694758, "phrase": "point-to-point_interprocessor_communication"}, {"score": 0.004175533280178052, "phrase": "multicore_architectures"}, {"score": 0.004104722208522451, "phrase": "large_performance_variability"}, {"score": 0.004035107125458193, "phrase": "shared_caches"}, {"score": 0.0039216854691927865, "phrase": "interprocessor_communication"}, {"score": 0.0038332390893263844, "phrase": "solution_phase"}, {"score": 0.003683213029483699, "phrase": "high_degree"}, {"score": 0.003559284776569813, "phrase": "explicit_time_integration_operators"}, {"score": 0.003459191419478298, "phrase": "point-to-point_communication"}, {"score": 0.0033427754823819157, "phrase": "communication_library_implementations"}, {"score": 0.0031754329320561317, "phrase": "flexible_software_design"}, {"score": 0.003016442355995592, "phrase": "preliminary_performance_tests"}, {"score": 0.0029148831519944358, "phrase": "optimal_combination"}, {"score": 0.0028490783932465288, "phrase": "performance_differences"}, {"score": 0.0028167336373711494, "phrase": "point-to-point_messaging"}, {"score": 0.0026152363154073707, "phrase": "mpi_communication_calls"}, {"score": 0.002216054733102974, "phrase": "message_size"}, {"score": 0.0021908807203548345, "phrase": "nearly_linear_scalability_results"}, {"score": 0.0021659920594094407, "phrase": "explicit_time_integration"}, {"score": 0.0021049977753042253, "phrase": "design_techniques"}], "paper_keywords": ["High-performance and scalability", " Parallel computation", " Explicit finite elements"], "paper_abstract": "Parallel, explicit finite element analysis is based almost exclusively on point-to-point interprocessor communication. However, point-to-point communication on multicore architectures results in large performance variability because of shared caches and sockets. The interprocessor communication required during the solution phase must be designed to achieve a high degree of scalability and performance for explicit time integration operators. An analysis of point-to-point communication on different hardware platforms, communication library implementations, and message sizes demonstrates the need for a flexible software design that allows for optimization. Autotuning modules and preliminary performance tests are necessary to identify the optimal combination of calls. Performance differences of point-to-point messaging on multicore machines are illustrated with a test that uses combinations of MPI communication calls. The differences are apparent when cache and sockets are shared among the cores and for message sizes up to 1.5 MB. Alternative communication schemes are shown to perform faster depending on the architecture and message size. Nearly linear scalability results for explicit time integration are demonstrated using the design techniques.", "paper_title": "Interprocessor communication for high performance, explicit time integration", "paper_id": "WOS:000275953000006"}