{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "navigation_strategies"}, {"score": 0.004621148492564008, "phrase": "new_computational_model"}, {"score": 0.004496280772084575, "phrase": "cue-guided_navigation_strategies"}, {"score": 0.004179480763003705, "phrase": "separate_memory_systems"}, {"score": 0.003956558420993431, "phrase": "learning_algorithms"}, {"score": 0.003814563533445401, "phrase": "cue-guided_strategy"}, {"score": 0.003611034322786669, "phrase": "visible_goal"}, {"score": 0.003545625043276134, "phrase": "path-planning_strategy"}, {"score": 0.0034813964296826973, "phrase": "place-cell-based_graph-search_algorithm"}, {"score": 0.003265591844292821, "phrase": "strategy_selection_mechanism"}, {"score": 0.0032358709481309913, "phrase": "td-learning_rule"}, {"score": 0.003063123420705719, "phrase": "novel_criterion"}, {"score": 0.0030352396244492604, "phrase": "strategy_selection"}, {"score": 0.002953097497434808, "phrase": "goal-oriented_movements"}, {"score": 0.0028995712226514746, "phrase": "different_strategies"}, {"score": 0.0028210902750714075, "phrase": "selection_criterion"}, {"score": 0.002769950045729965, "phrase": "\"common_currency"}, {"score": 0.0026582395558737855, "phrase": "td-learning_and_planning_strategies"}, {"score": 0.0025744696954056404, "phrase": "navigational_tasks"}, {"score": 0.002551022760887132, "phrase": "continuous_state_and_action_spaces"}, {"score": 0.00243694486220507, "phrase": "rat_behavior"}, {"score": 0.002244277924422011, "phrase": "competitive_and_cooperative_interactions"}, {"score": 0.0021438877099090262, "phrase": "relative_influence"}, {"score": 0.0021243539405631866, "phrase": "different_types"}, {"score": 0.0021049977753042253, "phrase": "sensory_cues"}], "paper_keywords": ["Computational model", " Spatial navigation", " Strategy switch", " Parallel memory systems", " Action selection"], "paper_abstract": "In this article, we describe a new computational model of switching between path-planning and cue-guided navigation strategies. It is based on three main assumptions: (i) the strategies are mediated by separate memory systems that learn independently and in parallel; (ii) the learning algorithms are different in the two memory systems-the cue-guided strategy uses a temporal-difference (TD) learning rule to approach a visible goal, whereas the path-planning strategy relies on a place-cell-based graph-search algorithm to learn the location of a hidden goal; (iii) a strategy selection mechanism uses TD-learning rule to choose the most successful strategy based on past experience. We propose a novel criterion for strategy selection based on the directions of goal-oriented movements suggested by the different strategies. We show that the selection criterion based on this \"common currency\" is capable of choosing the best among TD-learning and planning strategies and can be used to solve navigational tasks in continuous state and action spaces. The model has been successfully applied to reproduce rat behavior in two water-maze tasks in which the two strategies were shown to interact. The model was used to analyze competitive and cooperative interactions between different strategies during these tasks as well as relative influence of different types of sensory cues.", "paper_title": "Path planning versus cue responding: a bio-inspired model of switching between navigation strategies", "paper_id": "WOS:000281667700004"}