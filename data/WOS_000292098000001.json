{"auto_keywords": [{"score": 0.027387565941403923, "phrase": "derivative_information"}, {"score": 0.004686963264680882, "phrase": "r_function"}, {"score": 0.0046242451772036145, "phrase": "evolutionary_algorithm_methods"}, {"score": 0.004303591748086452, "phrase": "optimization_problems"}, {"score": 0.0034841647157189985, "phrase": "model's_parameters"}, {"score": 0.0031845067058084583, "phrase": "optimization_methods"}, {"score": 0.003085813569061001, "phrase": "objective_function"}, {"score": 0.002936849401568391, "phrase": "multiple_local_optima"}, {"score": 0.0027825094419000637, "phrase": "derivative-based_method"}, {"score": 0.0025316254589087973, "phrase": "pure_genetic_algorithms"}, {"score": 0.0024421008630165046, "phrase": "local_hill_climbing"}, {"score": 0.0022419349154472806, "phrase": "search_space"}, {"score": 0.0021529183360603434, "phrase": "parallel_processing"}, {"score": 0.0021336208506092173, "phrase": "multiple_cpus"}, {"score": 0.0021049977753042253, "phrase": "single_machine"}], "paper_keywords": ["genetic algorithm", " evolutionary program", " optimization", " parallel computing", " R"], "paper_abstract": "genoud is an R function that combines evolutionary algorithm methods with a derivative-based (quasi-Newton) method to solve difficult optimization problems. genoud may also be used for optimization problems for which derivatives do not exist. genoud solves problems that are nonlinear or perhaps even discontinuous in the parameters of the function to be optimized. When the function to be optimized (for example, a log-likelihood) is nonlinear in the model's parameters, the function will generally not be globally concave and may have irregularities such as saddlepoints or discontinuities. Optimization methods that rely on derivatives of the objective function may be unable to find any optimum at all. Multiple local optima may exist, so that there is no guarantee that a derivative-based method will converge to the global optimum. On the other hand, algorithms that do not use derivative information (such as pure genetic algorithms) are for many problems needlessly poor at local hill climbing. Most statistical problems are regular in a neighborhood of the solution. Therefore, for some portion of the search space, derivative information is useful. The function supports parallel processing on multiple CPUs on a single machine or a cluster of computers.", "paper_title": "Genetic Optimization Using Derivatives: The rgenoud Package for R", "paper_id": "WOS:000292098000001"}