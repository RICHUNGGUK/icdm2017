{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "lasso"}, {"score": 0.004645057834614705, "phrase": "least_squares"}, {"score": 0.004114527599108729, "phrase": "robustness_properties"}, {"score": 0.003969250376327401, "phrase": "robust_optimization_problem"}, {"score": 0.003677280504320639, "phrase": "physical_property"}, {"score": 0.003531474887552889, "phrase": "principled_selection"}, {"score": 0.0033011569787033297, "phrase": "convex_optimization_problems"}, {"score": 0.0032277611129050234, "phrase": "different_uncertainty_sets"}, {"score": 0.0030307927228223883, "phrase": "different_properties"}, {"score": 0.0026600905156986317, "phrase": "specific_results"}, {"score": 0.002612640527241776, "phrase": "standard_sparsity_results"}, {"score": 0.00257760787870709, "phrase": "different_geometric_intuition"}, {"score": 0.00247529638625566, "phrase": "robust_optimization_formulation"}, {"score": 0.0024311346712789553, "phrase": "kernel_density_estimation"}, {"score": 0.0021049977753042253, "phrase": "algorithmic_stability"}], "paper_keywords": ["Lasso", " regression", " regularization", " robustness", " sparsity", " stability", " statistical learning"], "paper_abstract": "Lasso, or l(1) regularized least squares, has been explored extensively for its remarkable sparsity properties. In this paper it is shown that the solution to Lasso, in addition to its sparsity, has robustness properties: it is the solution to a robust optimization problem. This has two important consequences. First, robustness provides a connection of the regularizer to a physical property, namely, protection from noise. This allows a principled selection of the regularizer, and in particular, generalizations of Lasso that also yield convex optimization problems are obtained by considering different uncertainty sets. Second, robustness can itself be used as an avenue for exploring different properties of the solution. In particular, it is shown that robustness of the solution explains why the solution is sparse. The analysis as well as the specific results obtained differ from standard sparsity results, providing different geometric intuition. Furthermore, it is shown that the robust optimization formulation is related to kernel density estimation, and based on this approach, a proof that Lasso is consistent is given, using robustness directly. Finally, a theorem is proved which states that sparsity and algorithmic stability contradict each other, and hence Lasso is not stable.", "paper_title": "Robust Regression and Lasso", "paper_id": "WOS:000278812000041"}