{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "spectral_clustering"}, {"score": 0.0047152877145889656, "phrase": "sdd_solvers"}, {"score": 0.0041589926969138585, "phrase": "complex_shapes"}, {"score": 0.004072851768196397, "phrase": "intrinsic_manifold_structure"}, {"score": 0.003988487841970088, "phrase": "large_and_high_dimensional_spaces"}, {"score": 0.003629882559085245, "phrase": "expensive_computational_cost"}, {"score": 0.003373334961160647, "phrase": "graph_laplacian_matrix"}, {"score": 0.0027645030021576926, "phrase": "original_laplacian_matrix"}, {"score": 0.002651015392318126, "phrase": "recently_introduced_near-linear_time_solver"}, {"score": 0.002289180040240783, "phrase": "proposed_approach"}, {"score": 0.002241679436497571, "phrase": "better_clustering_quality"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_approximate_spectral_clustering_methods"}], "paper_keywords": ["Spectral clustering", " Resistance distance", " SDD solver", " Random projection"], "paper_abstract": "The promise of spectral clustering is that it can help detect complex shapes and intrinsic manifold structure in large and high dimensional spaces. The price for this promise is the expensive computational cost for computing the eigen-decomposition of the graph Laplacian matrix-so far a necessary subroutine for spectral clustering. In this paper we bypass the eigen-decomposition of the original Laplacian matrix by leveraging the recently introduced near-linear time solver for symmetric diagonally dominant (SDD) linear systems and random projection. Experiments on several synthetic and real datasets show that the proposed approach has better clustering quality and is faster than the state-of-the-art approximate spectral clustering methods.", "paper_title": "A scalable approach to spectral clustering with SDD solvers", "paper_id": "WOS:000351510500006"}