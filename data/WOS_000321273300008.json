{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "monte-carlo_tree_search"}, {"score": 0.04454153022265076, "phrase": "momcts"}, {"score": 0.004622450915803531, "phrase": "multi-objective_reinforcement_learning"}, {"score": 0.003966388754366831, "phrase": "multi-objective_sequential_decision_making"}, {"score": 0.003581412258960711, "phrase": "hypervolume_indicator"}, {"score": 0.0034733518170738517, "phrase": "pareto_dominance_reward"}, {"score": 0.0033685408148574846, "phrase": "momcts_approaches"}, {"score": 0.0031682817605340028, "phrase": "morl_state"}, {"score": 0.0029196116767956273, "phrase": "two-objective_deep_sea_treasure_problem"}, {"score": 0.002831462722290752, "phrase": "three-objective_resource_gathering_problem"}, {"score": 0.002453934333239467, "phrase": "np-hard_grid_scheduling_problem"}, {"score": 0.002331641523873951, "phrase": "momcts_performance"}, {"score": 0.0021049977753042253, "phrase": "higher_computational_cost"}], "paper_keywords": ["Reinforcement learning", " Monte-Carlo Tree Search", " Multi-objective optimization", " Sequential decision making"], "paper_abstract": "Concerned with multi-objective reinforcement learning (MORL), this paper presents MOMCTS, an extension of Monte-Carlo Tree Search to multi-objective sequential decision making, embedding two decision rules respectively based on the hypervolume indicator and the Pareto dominance reward. The MOMCTS approaches are firstly compared with the MORL state of the art on two artificial problems, the two-objective Deep Sea Treasure problem and the three-objective Resource Gathering problem. The scalability of MOMCTS is also examined in the context of the NP-hard grid scheduling problem, showing that the MOMCTS performance matches the (non-RL based) state of the art albeit with a higher computational cost.", "paper_title": "Hypervolume indicator and dominance reward based multi-objective Monte-Carlo Tree Search", "paper_id": "WOS:000321273300008"}