{"auto_keywords": [{"score": 0.0408640933377538, "phrase": "megablocks"}, {"score": 0.015719716506582538, "phrase": "binary_acceleration"}, {"score": 0.015385260603799238, "phrase": "memory_accesses"}, {"score": 0.004462105963334103, "phrase": "embedded_applications"}, {"score": 0.004389912080394437, "phrase": "reconfigurable_processing_unit"}, {"score": 0.004135010810625326, "phrase": "general_purpose_processor"}, {"score": 0.003937459891461576, "phrase": "repetitive_instruction_sequences"}, {"score": 0.0037493114715625784, "phrase": "instruction_traces"}, {"score": 0.0036886073959526396, "phrase": "customized_rpu_implementations"}, {"score": 0.0034742854447532678, "phrase": "memory-sharing_mechanism"}, {"score": 0.0034180189629740426, "phrase": "concurrent_accesses"}, {"score": 0.003362660648932244, "phrase": "entire_address_space"}, {"score": 0.003308195943172624, "phrase": "gpp's_data_memory"}, {"score": 0.0031845067058084583, "phrase": "memory_access_handling"}, {"score": 0.0028096571309126923, "phrase": "gpp"}, {"score": 0.002764122268094908, "phrase": "rpu"}, {"score": 0.002704554429386671, "phrase": "original_binaries"}, {"score": 0.0026607205525625995, "phrase": "input_application"}, {"score": 0.002575167114383286, "phrase": "concept_prototype"}, {"score": 0.0025472634689904772, "phrase": "geometric_mean_speedups"}, {"score": 0.0022595316565074304, "phrase": "previous_version"}, {"score": 0.002186849855560281, "phrase": "geometric_mean_speedup_improvements"}], "paper_keywords": ["Design", " Performance", " Validation", " Experimentation", " Reconfigurable processor", " memory access", " Megablock", " instruction trace", " MicroBlaze", " hardware acceleration", " FPGA", " hardware/software architectures"], "paper_abstract": "This article presents a reconfigurable hardware/software architecture for binary acceleration of embedded applications. A Reconfigurable Processing Unit (RPU) is used as a coprocessor of the General Purpose Processor (GPP) to accelerate the execution of repetitive instruction sequences called Megablocks. A toolchain detects Megablocks from instruction traces and generates customized RPU implementations. The implementation of Megablocks with memory accesses uses a memory-sharing mechanism to support concurrent accesses to the entire address space of the GPP's data memory. The scheduling of load/store operations and memory access handling have been optimized to minimize the latency introduced by memory accesses. The system is able to dynamically switch the execution between the GPP and the RPU when executing the original binaries of the input application. Our proof-of-concept prototype achieved geometric mean speedups of 1.60x and 1.18x for, respectively, a set of 37 benchmarks and a subset considering the 9 most complex benchmarks. With respect to a previous version of our approach, we achieved geometric mean speedup improvements from 1.22 to 1.53 for the 10 benchmarks previously used.", "paper_title": "A Reconfigurable Architecture for Binary Acceleration of Loops with Memory Accesses", "paper_id": "WOS:000350529900002"}