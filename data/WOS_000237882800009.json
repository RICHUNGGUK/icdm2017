{"auto_keywords": [{"score": 0.04732125269149571, "phrase": "kullback-leibler_information"}, {"score": 0.015719716506582538, "phrase": "state-space_model_selection"}, {"score": 0.010017026259605094, "phrase": "bias_adjustment"}, {"score": 0.00881552821755608, "phrase": "true_parameters"}, {"score": 0.004720792132470776, "phrase": "hurvich"}, {"score": 0.004689815744913282, "phrase": "shumway"}, {"score": 0.004643739045724374, "phrase": "tsai"}, {"score": 0.004508155639663496, "phrase": "autoregressive_model_selection"}, {"score": 0.004478567563654688, "phrase": "small_samples"}, {"score": 0.004449183720422562, "phrase": "biometrika"}, {"score": 0.004290901837174206, "phrase": "\"improved\"_variant"}, {"score": 0.004248718518635191, "phrase": "akaike_information_criterion"}, {"score": 0.004084088479191021, "phrase": "akaike"}, {"score": 0.003938740137673181, "phrase": "maximum_likelihood_principle"}, {"score": 0.0038616499489536123, "phrase": "information_theory"}, {"score": 0.00383628868871796, "phrase": "akademia_kiado"}, {"score": 0.0036633621826101894, "phrase": "kullback"}, {"score": 0.0036153760112398485, "phrase": "information_theory_and_statistics"}, {"score": 0.003591628451860015, "phrase": "dover"}, {"score": 0.0035680320746705064, "phrase": "new_york"}, {"score": 0.0034751895536268953, "phrase": "fitted_model"}, {"score": 0.0034183895670057717, "phrase": "true_model"}, {"score": 0.0033625148111740984, "phrase": "aici_proceeds"}, {"score": 0.0033184711049370425, "phrase": "expected_information"}, {"score": 0.003264224201388006, "phrase": "first_term"}, {"score": 0.003221463787552773, "phrase": "empirical_log_likelihood"}, {"score": 0.003147972261878234, "phrase": "biased_estimator"}, {"score": 0.003086311260099341, "phrase": "second_term"}, {"score": 0.003035847903759329, "phrase": "exact_computation"}, {"score": 0.00294707794932759, "phrase": "true_model_parameters"}, {"score": 0.0028893405654376826, "phrase": "practical_applications"}, {"score": 0.0028514769721161063, "phrase": "fitted_models"}, {"score": 0.0028234043335210895, "phrase": "candidate_class"}, {"score": 0.002574328937802055, "phrase": "monte_carlo_simulations"}, {"score": 0.0025489778320184255, "phrase": "conveniently_chosen_simulation_parameters"}, {"score": 0.002474408907166139, "phrase": "simulation_results"}, {"score": 0.002339442939538852, "phrase": "model_selection_criterion"}, {"score": 0.0021900332274791827, "phrase": "effective_tool"}, {"score": 0.0021470954708827125, "phrase": "appropriate_dimension"}, {"score": 0.002105002791163301, "phrase": "elsevier"}], "paper_keywords": ["AIC", " Kullback-Leibler information", " Kullback's directed divergence", " state-space model", " time series analysis"], "paper_abstract": "Following the work of Hurvich, Shumway, and Tsai [1990, Improved estimators of Kullback-Leibler information for autoregressive model selection in small samples. Biometrika 77, 709-719], we propose an \"improved\" variant of the Akaike information criterion, AICi, for state-space model selection. The variant is based on Akaike's [ 1973, Information theory and an extension of maximum likelihood principle. Second International Symposium on Information Theory, Akademia Kiado, pp. 267-281] objective of estimating the Kullback-Leibler information [Kullback, 1968, Information Theory and Statistics. Dover, New York] between the densities corresponding to the fitted model and the generating or true model. The development of AICi proceeds by decomposing the expected information into two terms. The first term suggests that the empirical log likelihood can be used to form a biased estimator of the information, the second term provides the bias adjustment. Exact computation of the bias adjustment requires the values of the true model parameters, which are inaccessible in practical applications. Yet for fitted models in the candidate class that are correctly specified or overfit, the adjustment is asymptotically independent of the true parameters. Thus, in certain settings, the adjustment may be estimated via Monte Carlo simulations by using conveniently chosen simulation parameters as proxies for the true parameters. We present simulation results to evaluate the performance of AICi both as an estimator of the Kullback-Leibler information and as a model selection criterion. Our results indicate that AICi estimates the information with less bias than traditional AIC. Furthermore, AICi serves as an effective tool for selecting a model of appropriate dimension. (C) 2005 Elsevier B.V All rights reserved.", "paper_title": "An improved Akaike information criterion for state-space model selection", "paper_id": "WOS:000237882800009"}