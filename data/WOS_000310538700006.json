{"auto_keywords": [{"score": 0.030600209224547807, "phrase": "affordance_field"}, {"score": 0.00481495049065317, "phrase": "egocentric_fields"}, {"score": 0.004764542405129454, "phrase": "autonomous_navigation"}, {"score": 0.004544127927346964, "phrase": "general_framework"}, {"score": 0.004243552607799184, "phrase": "high-level_behaviors"}, {"score": 0.0035665344993417603, "phrase": "scalar_fields"}, {"score": 0.0034555479218891638, "phrase": "agent's_local_space"}, {"score": 0.0034013521529056715, "phrase": "egocentric_property"}, {"score": 0.003278167066287366, "phrase": "local_space-time_plan"}, {"score": 0.003226744277130179, "phrase": "better_parallel_scalability"}, {"score": 0.0031761255583359726, "phrase": "global_fields_approach"}, {"score": 0.0030772505522663612, "phrase": "perception_fields"}, {"score": 0.0030130446986008277, "phrase": "fitness_measure"}, {"score": 0.0029657683623403085, "phrase": "possible_action"}, {"score": 0.002783945062714816, "phrase": "optimal_value"}, {"score": 0.002697245874076643, "phrase": "agent's_steering_decision"}, {"score": 0.0025858215477025117, "phrase": "linear_space-time_prediction_model"}, {"score": 0.0024659480471085405, "phrase": "multicore_systems"}, {"score": 0.0023516185395256505, "phrase": "comprehensive_suite"}, {"score": 0.002326938965568362, "phrase": "test_cases"}, {"score": 0.0022904032758108775, "phrase": "steerbench"}, {"score": 0.0022544399432457164, "phrase": "autonomous_virtual_pedestrians"}, {"score": 0.0021957487795963666, "phrase": "path_planning"}, {"score": 0.002172701452347454, "phrase": "unknown_environments"}, {"score": 0.0021049977753042253, "phrase": "high-level_responses"}], "paper_keywords": ["Affordance", " Egocentric", " Steering", " Space-time planning"], "paper_abstract": "In this paper, we propose a general framework for local path-planning and steering that can be easily extended to perform high-level behaviors. Our framework is based on the concept of affordances: the possible ways an agent can interact with its environment. Each agent perceives the environment through a set of vector and scalar fields that are represented in the agent's local space. This egocentric property allows us to efficiently compute a local space-time plan and has better parallel scalability than a global fields approach. We then use these perception fields to compute a fitness measure for every possible action, defined as an affordance field. The action that has the optimal value in the affordance field is the agent's steering decision. We propose an extension to a linear space-time prediction model for dynamic collision avoidance and present our parallelization results on multicore systems. We analyze and evaluate our framework using a comprehensive suite of test cases provided in SteerBench and demonstrate autonomous virtual pedestrians that perform steering and path planning in unknown environments along with the emergence of high-level responses to never seen before situations.", "paper_title": "Parallelized egocentric fields for autonomous navigation", "paper_id": "WOS:000310538700006"}