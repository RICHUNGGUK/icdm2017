{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "convex_quadratic_optimization"}, {"score": 0.004684157900507474, "phrase": "new_neural_network"}, {"score": 0.004556901872357751, "phrase": "quadratic_optimization"}, {"score": 0.004234129588974058, "phrase": "proposed_network"}, {"score": 0.0037921662574137535, "phrase": "bound_constraints"}, {"score": 0.003689053436223376, "phrase": "optimization_variables"}, {"score": 0.003459191419478298, "phrase": "lagrangian_approach"}, {"score": 0.0033037970113095577, "phrase": "partial_dual_method"}, {"score": 0.002931569771634119, "phrase": "dynamic_evolution"}, {"score": 0.0027741761880779535, "phrase": "steady-state_solutions"}, {"score": 0.0026986685585382347, "phrase": "necessary_and_sufficient_conditions"}, {"score": 0.00257735013358606, "phrase": "circuit_implementation"}, {"score": 0.0024389277933858054, "phrase": "existing_solutions"}, {"score": 0.0022041312401435346, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "simulation_examples"}], "paper_keywords": ["Analog circuits", " Lagrangian networks", " mathematical programming", " quadratic optimization", " recurrent neural networks"], "paper_abstract": "A new neural network for convex quadratic optimization is presented in this brief. The proposed network can handle both equality and inequality constraints, as well as bound constraints on the optimization variables. It is based on the Lagrangian approach, but exploits a partial dual method in order to keep the number of variables at minimum. The dynamic evolution is globally convergent and the steady-state solutions satisfy the necessary and sufficient conditions of optimality. The circuit implementation is simpler with respect to existing solutions for the same class of problems. The validity of the proposed approach is verified through some simulation examples.", "paper_title": "Quasi-Lagrangian Neural Network for Convex Quadratic Optimization", "paper_id": "WOS:000260119900012"}