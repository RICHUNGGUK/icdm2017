{"auto_keywords": [{"score": 0.04617579725696764, "phrase": "visual_fields"}, {"score": 0.03718034097391595, "phrase": "visual_rays"}, {"score": 0.00481495049065317, "phrase": "linear_quasi"}, {"score": 0.004797225036013284, "phrase": "-parallax_sfm"}, {"score": 0.004761968711051715, "phrase": "laterally-placed_eyes"}, {"score": 0.004709567162738894, "phrase": "large_class"}, {"score": 0.004674952036988355, "phrase": "visual_systems"}, {"score": 0.004623503587186056, "phrase": "biological_world"}, {"score": 0.0045726187330434025, "phrase": "multiple_eyes"}, {"score": 0.004539005582217309, "phrase": "simultaneous_motion"}, {"score": 0.004278807087784626, "phrase": "lateral_eyes"}, {"score": 0.004185108816866677, "phrase": "compound_eyes"}, {"score": 0.0040783736687590635, "phrase": "feature_correspondences"}, {"score": 0.0037325918533747953, "phrase": "organizational_possibility"}, {"score": 0.0036778708850237814, "phrase": "eye_topography"}, {"score": 0.0032558762499901727, "phrase": "translation_recovery"}, {"score": 0.003196292402522254, "phrase": "parsimonious_visual_processing"}, {"score": 0.003161065111494053, "phrase": "quasi-parallax_term"}, {"score": 0.0028085616610192456, "phrase": "individual_epipolar_constraints"}, {"score": 0.0026966744704447275, "phrase": "different_and_appropriate_aspects"}, {"score": 0.0026472970609754095, "phrase": "motion_recovery"}, {"score": 0.0024768883044869023, "phrase": "gold_standard_solution"}, {"score": 0.0024405312482831646, "phrase": "bundle_adjustment"}, {"score": 0.002422810305133378, "phrase": "ba"}, {"score": 0.0023606625824479956, "phrase": "better_fisher_information_matrix"}, {"score": 0.0023346234464901978, "phrase": "lateral_eye_pair"}, {"score": 0.0022834017104377525, "phrase": "superior_experimental_performance"}, {"score": 0.0022415745160585146, "phrase": "narrow_field"}, {"score": 0.0021601997088758957, "phrase": "comparable_performances"}, {"score": 0.0021049977753042253, "phrase": "nonlinear_ba_method"}], "paper_keywords": ["Ego-motion estimation based on optical flow", " Quasi-parallax terms", " Lateral camera pairs", " Compound eyes"], "paper_abstract": "A large class of visual systems in the biological world often has multiple eyes in simultaneous motion and yet has little or no overlap in the visual fields between the eyes. These systems include the lateral eyes found in many vertebrates and the compound eyes in insects. Instead of computing feature correspondences between the eyes, which might not even be possible due to the lack of overlap in the visual fields, we exploit the organizational possibility offered by the eye topography. In particular, we leverage on the pair of visual rays that are parallel to each other but opposite in direction, and compute what we call the quasi-parallax for translation recovery. Besides resulting in parsimonious visual processing, the quasi-parallax term also enhances the information pick-up for the translation, as it is almost rotation-free. The rotation is subsequently recovered from a pencil of visual rays using the individual epipolar constraints of each camera. As a result of using these different and appropriate aspects of visual rays for motion recovery, our method is numerically more effective in disambiguating the translation and rotation. In comparison to the gold standard solution obtained by the bundle adjustment (BA) technique, our method has a better Fisher information matrix for a lateral eye pair, as well as a superior experimental performance under the case of narrow field of view. For other eye configurations, the two methods achieve comparable performances, with our linear method slightly edging the nonlinear BA method when there exists imperfection in the calibration.", "paper_title": "Linear Quasi-Parallax SfM Using Laterally-Placed Eyes", "paper_id": "WOS:000266037900002"}