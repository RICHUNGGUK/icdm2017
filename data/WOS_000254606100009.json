{"auto_keywords": [{"score": 0.041463602643680264, "phrase": "static_speech_segment"}, {"score": 0.015569904490498027, "phrase": "cmn."}, {"score": 0.014700102325088251, "phrase": "conventional_short-term_spectrum"}, {"score": 0.013527620668861201, "phrase": "short-term_spectrum"}, {"score": 0.01344135589991743, "phrase": "cmn"}, {"score": 0.00481495049065317, "phrase": "short-term_and_long-term_spectrum_based_position-dependent_cmn"}, {"score": 0.004602233424629559, "phrase": "channel_impulse_response"}, {"score": 0.004528551999851654, "phrase": "short-term_spectral_analysis_window"}, {"score": 0.00447045328907701, "phrase": "cepstral_mean_normalization"}, {"score": 0.004190904630161064, "phrase": "robust_speech_recognition_method"}, {"score": 0.0037188360359702182, "phrase": "long-term_cepstral_analysis"}, {"score": 0.003635676878573833, "phrase": "long_reverberation"}, {"score": 0.003531474887552889, "phrase": "long-term_spectrum"}, {"score": 0.003486123304074186, "phrase": "cepstral_distance"}, {"score": 0.0034636656250083744, "phrase": "neighboring_frames"}, {"score": 0.003133451532433272, "phrase": "static_and_non-static_speech_segments"}, {"score": 0.0030832123624449028, "phrase": "corresponding_cepstral_means"}, {"score": 0.0030435998319355883, "phrase": "previous_study"}, {"score": 0.0029947969419015868, "phrase": "environmentally_robust_speech_recognition_method"}, {"score": 0.0029658905122290536, "phrase": "position-dependent_cmn"}, {"score": 0.002899519426587381, "phrase": "channel_distortion"}, {"score": 0.0028715299874549245, "phrase": "speaker_position"}, {"score": 0.0027982016314450717, "phrase": "conventional_cmn."}, {"score": 0.002717937009041744, "phrase": "short-term_and_long-term_spectrum"}, {"score": 0.0026314443645799913, "phrase": "variable_term_spectrum"}, {"score": 0.0026144780997686464, "phrase": "pdcmn"}, {"score": 0.002597620940221604, "phrase": "vt-pdcmn"}, {"score": 0.0025312694615202786, "phrase": "speaker_variations"}, {"score": 0.00250682585023182, "phrase": "position-dependent_cepstral_mean"}, {"score": 0.0024826176951198166, "phrase": "average_speaker_characteristics"}, {"score": 0.0024035955457586103, "phrase": "conventional_cmn"}, {"score": 0.002304606411453748, "phrase": "limited_vocabulary"}, {"score": 0.0022749744354271816, "phrase": "distant-talking_isolated_word_recognition"}, {"score": 0.00222403027114726, "phrase": "proposed_method"}, {"score": 0.002202547013259953, "phrase": "relative_error_reduction_rate"}, {"score": 0.0021049977753042253, "phrase": "pdcmn."}], "paper_keywords": ["robust speech recognition", " distant-talking environment", " CMN", " long-term spectrum"], "paper_abstract": "In a distant-talking environment, the length of channel impulse response is longer than the short-term spectral analysis window. Conventional short-term spectrum based Cepstral Mean Normalization (CMN) is therefore, not effective under these conditions. In this paper, we propose a robust speech recognition method by combining a short-term spectrum based CMN with a long-term one. We assume that a static speech segment (such as a vowel, for example) affected by reverberation, can be modeled by a long-term cepstral analysis. Thus, the effect of long reverberation on a static speech segment may be compensated by the long-term spectrum based CMN. The cepstral distance of neighboring frames is used to discriminate the static speech segment (long-term spectrum) and the non-static speech segment (short-term spectrum). The cepstra of the static and non-static speech segments are normalized by the corresponding cepstral means. In a previous study, we proposed an environmentally robust speech recognition method based on Position-Dependent CMN (PDCMN) to compensate for channel distortion depending on speaker position, and which is more efficient than conventional CMN. In this paper, the concept of combining short-term and long-term spectrum based CMN is extended to PDCMN. We call this Variable Term spectrum based PDCMN (VT-PDCMN). Since PDCMN/VT-PDCMN cannot normalize speaker variations because a position-dependent cepstral mean contains the average speaker characteristics over all speakers, we also combine PDCMN/VT-PDCMN with conventional CMN in this study. We conducted the experiments based on our proposed method using limited vocabulary (100 words) distant-talking isolated word recognition in a real environment. The proposed method achieved a relative error reduction rate of 60.9% over the conventional short-term spectrum based CMN and 30.6% over the short-term spectrum based PDCMN.", "paper_title": "Robust speech recognition by combining short-term and long-term spectrum based position-dependent CMN with conventional CMN", "paper_id": "WOS:000254606100009"}