{"auto_keywords": [{"score": 0.034804455095609727, "phrase": "pbc"}, {"score": 0.00476323161560059, "phrase": "passivity-based_control"}, {"score": 0.004298666679374568, "phrase": "multi-domain_systems"}, {"score": 0.004206767038617782, "phrase": "micro-electro-mechanical_systems"}, {"score": 0.004161553532799662, "phrase": "passivity-based_control_synthesis"}, {"score": 0.004028796143006953, "phrase": "partial_differential_equations"}, {"score": 0.003675120438902734, "phrase": "control_law"}, {"score": 0.0035771121569391916, "phrase": "unknown_parameter_vector"}, {"score": 0.0034817084307034955, "phrase": "actor_critic_reinforcement"}, {"score": 0.0033888405252810927, "phrase": "key_advantages"}, {"score": 0.003124790943886441, "phrase": "control_design_procedure"}, {"score": 0.002881255933884771, "phrase": "ph_model"}, {"score": 0.0028043588777213533, "phrase": "learning_process"}, {"score": 0.0027295084882654917, "phrase": "physical_meaning"}, {"score": 0.0026423134393535265, "phrase": "learned_control_law"}, {"score": 0.002530359917257626, "phrase": "learning-based_pbc_method"}, {"score": 0.0024231382864800173, "phrase": "experimental_results"}, {"score": 0.0023841092222805253, "phrase": "two-degree-of-freedom_manipulator"}, {"score": 0.002234165013865669, "phrase": "feedback_regulation"}, {"score": 0.0021745003291048356, "phrase": "model_uncertainties"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Passivity-based control", " Port-Hamiltonian systems", " Reinforcement learning", " Robotics"], "paper_abstract": "Passivity-based control (PBC) is commonly used for the stabilization of port-Hamiltonian (PH) systems. The PH framework is suitable for multi-domain systems, for example mechatronic devices or micro-electro-mechanical systems. Passivity-based control synthesis for PH systems involves solving partial differential equations, which can be cumbersome. Rather than explicitly solving these equations, in our approach the control law is parameterized and the unknown parameter vector is learned using an actor critic reinforcement learning algorithm. The key advantages of combining learning with PBC are: (i) the complexity of the control design procedure is reduced, (ii) prior knowledge about the system, given in the form of a PH model, speeds up the learning process, (iii) physical meaning can be attributed to the learned control law. In this paper we extended the learning-based PBC method to a regulation problem and present the experimental results for a two-degree-of-freedom manipulator. We show that the learning algorithm is capable of achieving feedback regulation in the presence of model uncertainties. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Passivity-based reinforcement learning control of a 2-DOF manipulator arm", "paper_id": "WOS:000347499900010"}