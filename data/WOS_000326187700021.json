{"auto_keywords": [{"score": 0.047651645695987184, "phrase": "lbs"}, {"score": 0.00481495049065317, "phrase": "accurate_mobile_visual_localization"}, {"score": 0.00474953919834177, "phrase": "mobile_applications"}, {"score": 0.004596138053721412, "phrase": "ubiquitous_location-based_services"}, {"score": 0.0045212970824266485, "phrase": "increasing_popularity"}, {"score": 0.004459857205489101, "phrase": "fundamental_problem"}, {"score": 0.004387225575447685, "phrase": "traditional_localization_methods"}, {"score": 0.0043275996751051034, "phrase": "wireless_signals"}, {"score": 0.004292212137716459, "phrase": "phone-captured_images"}, {"score": 0.0042338720545681855, "phrase": "significant_interest"}, {"score": 0.004130842663662047, "phrase": "embedded_sensors"}, {"score": 0.003975515793563275, "phrase": "real_geographic_scene_contexts"}, {"score": 0.003910740988145338, "phrase": "novel_approach"}, {"score": 0.0038893838564184107, "phrase": "mobile_visual_localization"}, {"score": 0.003784328428527216, "phrase": "rough_gps_position"}, {"score": 0.003743102131902864, "phrase": "proposed_approach"}, {"score": 0.003682100144121148, "phrase": "complete_set"}, {"score": 0.0036320225018459263, "phrase": "scene_geo-context"}, {"score": 0.003602302241898501, "phrase": "real_locations"}, {"score": 0.0035630518377071916, "phrase": "perhaps_more_importantly_the_captured_scene"}, {"score": 0.0035049738376240567, "phrase": "viewing_direction"}, {"score": 0.003429001377800255, "phrase": "image_localization"}, {"score": 0.0033454923523807668, "phrase": "large-scale_image_retrieval"}, {"score": 0.003264010423431402, "phrase": "scene_clusters"}, {"score": 0.003246173672295418, "phrase": "joint_geo-visual_clustering"}, {"score": 0.0030479035434928616, "phrase": "visual_vocabulary_tree_structure"}, {"score": 0.002998197231744409, "phrase": "database_image"}, {"score": 0.002981808717396183, "phrase": "prior_knowledge"}, {"score": 0.0029573932605287947, "phrase": "novel_location-based_codebook_weighting_scheme"}, {"score": 0.002861708609922034, "phrase": "discriminative_power"}, {"score": 0.0027843339377323878, "phrase": "better_image_retrieval_performance"}, {"score": 0.0027615309527078903, "phrase": "query_image"}, {"score": 0.0026942333853202556, "phrase": "image_retrieval_results"}, {"score": 0.0026430237246954373, "phrase": "real-world_map"}, {"score": 0.0025295891681459755, "phrase": "user's_location"}, {"score": 0.0024210112323786374, "phrase": "particular_note"}, {"score": 0.0023749823753904204, "phrase": "localization_results"}, {"score": 0.002175436093794315, "phrase": "user_studies"}, {"score": 0.002116577422058574, "phrase": "ideal_rendezvous"}, {"score": 0.0021049977753042253, "phrase": "mobile_users"}], "paper_keywords": ["Algorithms", " Performance", " Design", " Experimentation", " Mobile visual localization", " geo-tagging", " scene reconstruction", " location-based services"], "paper_abstract": "Mobile applications are becoming increasingly popular. More and more people are using their phones to enjoy ubiquitous location-based services (LBS). The increasing popularity of LBS creates a fundamental problem: mobile localization. Besides traditional localization methods that use GPS or wireless signals, using phone-captured images for localization has drawn significant interest from researchers. Photos contain more scene context information than the embedded sensors, leading to a more precise location description. With the goal being to accurately sense real geographic scene contexts, this article presents a novel approach to mobile visual localization according to a given image (typically associated with a rough GPS position). The proposed approach is capable of providing a complete set of more accurate parameters about the scene geo-context including the real locations of both the mobile user and perhaps more importantly the captured scene, as well as the viewing direction. To figure out how to make image localization quick and accurate, we investigate various techniques for large-scale image retrieval and 2D-to-3D matching. Specifically, we first generate scene clusters using joint geo-visual clustering, with each scene being represented by a reconstructed 3D model from a set of images. The 3D models are then indexed using a visual vocabulary tree structure. Taking geo-tags of the database image as prior knowledge, a novel location-based codebook weighting scheme proposed to embed this additional information into the codebook. The discriminative power of the codebook is enhanced, thus leading to better image retrieval performance. The query image is aligned with the models obtained from the image retrieval results, and eventually registered to a real-world map. We evaluate the effectiveness of our approach using several large-scale datasets and achieving estimation accuracy of a user's location within 13 meters, viewing direction within 12 degrees, and viewing distance within 26 meters. Of particular note is our showcase of three novel applications based on localization results: (1) an on-the-spot tour guide, (2) collaborative routing, and (3) a sight-seeing guide. The evaluations through user studies demonstrate that these applications are effective in facilitating the ideal rendezvous for mobile users.", "paper_title": "Robust and Accurate Mobile Visual Localization and Its Applications", "paper_id": "WOS:000326187700021"}