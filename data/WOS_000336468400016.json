{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "mobile_service_robot"}, {"score": 0.03928806278633859, "phrase": "artificial_labels"}, {"score": 0.032847171362098505, "phrase": "semantic_map"}, {"score": 0.02825278976725957, "phrase": "spatial_semantic_hybrid_map"}, {"score": 0.004707188147442449, "phrase": "map_building"}, {"score": 0.004381527499253281, "phrase": "mission_planning"}, {"score": 0.004251210982670317, "phrase": "structural_information"}, {"score": 0.004140354220982935, "phrase": "self_localization"}, {"score": 0.0040171817997972335, "phrase": "deeper_knowledge"}, {"score": 0.003927203683176278, "phrase": "higher_degrees"}, {"score": 0.0037674258625824113, "phrase": "qr_code"}, {"score": 0.0036691380448651443, "phrase": "semantic_concepts"}, {"score": 0.0035599338383885447, "phrase": "indoor_environments"}, {"score": 0.0034279721355412285, "phrase": "semantic_recognition"}, {"score": 0.0033511469200347907, "phrase": "robot's_vision"}, {"score": 0.003325921766364862, "phrase": "semantic_knowledge"}, {"score": 0.003226899588787952, "phrase": "semantic_representations"}, {"score": 0.003026127736667187, "phrase": "navigation_abilities"}, {"score": 0.002958281631770322, "phrase": "spatial_modeling_method"}, {"score": 0.002837811982066224, "phrase": "function_area"}, {"score": 0.0028058141911641225, "phrase": "global_topological_map"}, {"score": 0.0027741761880779535, "phrase": "spectrum_clustering_algorithm"}, {"score": 0.0027017308406240563, "phrase": "topological_representations"}, {"score": 0.0026212437316947197, "phrase": "hybrid_map"}, {"score": 0.002591681512611419, "phrase": "'semantic''_path_planning"}, {"score": 0.002486103638234488, "phrase": "based_robot_localization"}, {"score": 0.00243033541656411, "phrase": "hybrid_map's_practicability"}, {"score": 0.0022963142779850562, "phrase": "human_point"}, {"score": 0.0022447938263410023, "phrase": "robot_environments"}, {"score": 0.0022110892229209407, "phrase": "high-level_reasonable_service_path"}, {"score": 0.0021778895748464024, "phrase": "function-driven_navigation"}, {"score": 0.0021614767508781048, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Artificial label", " QR code", " Semantic representation", " Hybrid map", " Service robot"], "paper_abstract": "In a mobile service robot, map building is a basis for navigation that allows the robot to perform a given task. When robots carry on mission planning and execution, they not only need structural information about the environment to navigation and self localization, but also need to possess a deeper knowledge to endow a robot with higher degrees of autonomy and intelligence. In this paper, the QR code based artificial labels are used to provide semantic concepts and relations of objects and rooms in indoor environments, which can solve the complexity and limitations of semantic recognition and scene understanding only with robot's vision. Semantic knowledge offered by artificial labels is obtained to incarnate semantic representations of the environment, which are formed as the semantic map. In order to maintain the navigation abilities of the robot, the spatial modeling method of a human is imitated to describe the relations of function area as a global topological map by the spectrum clustering algorithm. The semantic map is combined with topological representations to build a spatial semantic hybrid map. Using the hybrid map, ''semantic'' path planning, the elementary management of objects, and the context based robot localization are studied to show the hybrid map's practicability. The results of several experiments show that the spatial semantic hybrid map comes up to capture the human point-of-view of robot environments, enable a high-level reasonable service path, and achieve function-driven navigation. Crown Copyright (C) 2013 Published by Elsevier B.V. All rights reserved.", "paper_title": "Spatial semantic hybrid map building and application of mobile service robot", "paper_id": "WOS:000336468400016"}