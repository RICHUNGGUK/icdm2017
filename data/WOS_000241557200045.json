{"auto_keywords": [{"score": 0.04029481107137658, "phrase": "io"}, {"score": 0.00481495049065317, "phrase": "high-level_parallel_io"}, {"score": 0.003449972561293443, "phrase": "pure_mpi-io_implementation"}, {"score": 0.0031006232333900055, "phrase": "raw_transfer_bandwidth"}, {"score": 0.0029789104204803137, "phrase": "api_issues"}, {"score": 0.0028619616432896005, "phrase": "data_preparation"}, {"score": 0.0027865506182608263, "phrase": "call_overhead"}, {"score": 0.0025042115651986332, "phrase": "access_pattern"}, {"score": 0.002405853977978678, "phrase": "parallel_io"}, {"score": 0.0023424328921363585, "phrase": "unstructured_grid_applications"}, {"score": 0.0021049977753042253, "phrase": "hardest_patterns"}], "paper_keywords": ["MPI", " parallel IO", " HDF5", " parallel netcdf"], "paper_abstract": "For this poster, the usability of the two most common IO libraries for parallel IO was evaluated, and compared against a pure MPI-IO implementation. Instead of solely focusing on the raw transfer bandwidth achieved, API issues such as data preparation and call overhead were also taken into consideration. The access pattern resulting from parallel IO in unstructured grid applications, which is also one of the hardest patterns to optimize, was examined.", "paper_title": "On the usability of high-level parallel IO in unstructured grid simulations", "paper_id": "WOS:000241557200045"}