{"auto_keywords": [{"score": 0.041243598317218425, "phrase": "wm"}, {"score": 0.015719652428206398, "phrase": "relational_knowledge"}, {"score": 0.004761850836420121, "phrase": "neural_binders"}, {"score": 0.004709333998298903, "phrase": "long_time"}, {"score": 0.004683292152590589, "phrase": "connectionist_architectures"}, {"score": 0.004606023493393774, "phrase": "propositional_fixation"}, {"score": 0.004430629452265786, "phrase": "sophisticated_symbolic_information"}, {"score": 0.004321403813654565, "phrase": "novel_approach"}, {"score": 0.004285594361623147, "phrase": "full_integration"}, {"score": 0.004261885692956071, "phrase": "symbolic_al"}, {"score": 0.004226567346165507, "phrase": "connectionist_paradigm"}, {"score": 0.004099542199088835, "phrase": "artificial_neural_networks"}, {"score": 0.004020694957098141, "phrase": "boltzmann_machines"}, {"score": 0.003987367359722647, "phrase": "neural_architecture"}, {"score": 0.0039543149184722804, "phrase": "working_memory"}, {"score": 0.0036995343538355234, "phrase": "large_relational_knowledge-base"}, {"score": 0.0036384371764476386, "phrase": "compact_variable_binding_mechanism"}, {"score": 0.0034803820954524296, "phrase": "kb_items"}, {"score": 0.0034134024569847264, "phrase": "wm."}, {"score": 0.0033570147767493746, "phrase": "non-trivial_predicate_unification_problems"}, {"score": 0.00321114539085481, "phrase": "graph-like_structures"}, {"score": 0.003158088307044493, "phrase": "activation_pattern"}, {"score": 0.0031318883844936294, "phrase": "neural_network"}, {"score": 0.0030461102500649773, "phrase": "attractor-based_anns"}, {"score": 0.0029957718120653238, "phrase": "constraint_satisfaction"}, {"score": 0.0028895324165046166, "phrase": "weighted_constraints"}, {"score": 0.002833891290347501, "phrase": "relational_graphs"}, {"score": 0.0028181909702080584, "phrase": "neural_activation"}, {"score": 0.0024526718637463574, "phrase": "central_control"}, {"score": 0.0024121165531533545, "phrase": "unit_failures"}, {"score": 0.002385452024255879, "phrase": "previous_connectionist_suggestions"}, {"score": 0.0022880528191813105, "phrase": "simple_underlying_computational_principle"}, {"score": 0.0021604445371562575, "phrase": "al"}, {"score": 0.0021049977753042253, "phrase": "human_reasoning"}], "paper_keywords": ["Neuro-symbolic integration", " Binding problem", " Unification", " Inference", " Artificial Neural Networks", " Predicate logic"], "paper_abstract": "For a long time, connectionist architectures have been criticized for having propositional fixation, lack of compositionality and, in general, for their weakness in representing sophisticated symbolic information and processing it. This work offers a novel approach that allows full integration of symbolic Al with the connectionist paradigm. We show how to encode and process relational knowledge using Artificial Neural Networks (ANNs), such as Boltzmann Machines. The neural architecture uses a working memory (WM), consisting of pools of \"binders\", and a long-term synaptic-memory that can store a large relational knowledge-base (KB). A compact variable binding mechanism is proposed which dynamically allocates ensembles of neurons when a query is clamped; retrieving KB items till a solution emerges in the WM. We illustrate the proposal through non-trivial predicate unification problems: knowledge items are only retrieved into the WM upon need, and unified, graph-like structures emerge at equilibrium as an activation pattern of the neural network. Our architecture is based on the fact that some attractor-based ANNs may be viewed as performing constraint satisfaction, where, at equilibrium, fixed-points maximally satisfy a set of weighted constraints. We show how to encode relational graphs as neural activation in WM and how to use constraints that are encoded in synapses, in order to retrieve and process such complex structures. Both procedural (the unification algorithm) and declarative knowledge (logic formulae) are first expressed as constraints and then used to generate (or learn) weighted synaptic connections. The architecture has no central control and is inherently robust to unit failures. Contrary to previous connectionist suggestions, this approach is expressive, compact, accurate, and goal directed. The mechanism is universal and has a simple underlying computational principle. As such, it may be further adapted for applications that combine the advantages of both connectionist and traditional symbolic Al and may be used in modeling aspects of human reasoning. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Representing, binding, retrieving and unifying relational knowledge using pools of neural binders", "paper_id": "WOS:000209359800013"}