{"auto_keywords": [{"score": 0.035749859347247795, "phrase": "backward_model_refinement"}, {"score": 0.00481495049065317, "phrase": "neural_network_construction"}, {"score": 0.004690694501758065, "phrase": "neural_networks"}, {"score": 0.004545793387330536, "phrase": "linear-in-the-parameters_models"}, {"score": 0.004314127287770832, "phrase": "model_selection_problem"}, {"score": 0.004246947739596565, "phrase": "compact_model"}, {"score": 0.004115697805448384, "phrase": "subset_selection_algorithms"}, {"score": 0.004072851768196397, "phrase": "forward_selection_methods"}, {"score": 0.003785115566529808, "phrase": "suboptimal_models"}, {"score": 0.0036489343475053187, "phrase": "local_minimum"}, {"score": 0.0035361001070845677, "phrase": "two-stage_fast_recursive_algorithm"}, {"score": 0.003085989256759819, "phrase": "unified_two-stage_orthogonal_least_squares_methods"}, {"score": 0.0030220049006970317, "phrase": "fast_recursive-based_methods"}, {"score": 0.0029284999172756103, "phrase": "tsfra"}, {"score": 0.0028378798711397235, "phrase": "new_simplified_relationship"}, {"score": 0.002750056254309311, "phrase": "backward_stages"}, {"score": 0.0027071661844502992, "phrase": "repetitive_computations"}, {"score": 0.0026649432435828842, "phrase": "inherent_orthogonal_properties"}, {"score": 0.0026233771102489416, "phrase": "least_squares_methods"}, {"score": 0.0025555322596460036, "phrase": "new_term"}, {"score": 0.0024377918036784336, "phrase": "computational_demand"}, {"score": 0.002362320344521919, "phrase": "error_reduction_ratio_criterion"}, {"score": 0.002337684811187166, "phrase": "effective_and_efficient_forward_and_backward_subset_selection_procedures"}, {"score": 0.002206700502606511, "phrase": "improved_model_compactness"}, {"score": 0.0021609076467365247, "phrase": "proposed_technique"}, {"score": 0.0021049977753042253, "phrase": "popular_methods"}], "paper_keywords": ["Backward model refinement", " computational complexity", " forward selection", " linear-in-the-parameters model", " orthogonal least square (OLS)"], "paper_abstract": "A number of neural networks can be formulated as the linear-in-the-parameters models. Training such networks can be transformed to a model selection problem where a compact model is selected from all the candidates using subset selection algorithms. Forward selection methods are popular fast subset selection approaches. However, they may only produce suboptimal models and can be trapped into a local minimum. More recently, a two-stage fast recursive algorithm (TSFRA) combining forward selection and backward model refinement has been proposed to improve the compactness and generalization performance of the model. This paper proposes unified two-stage orthogonal least squares methods instead of the fast recursive-based methods. In contrast to the TSFRA, this paper derives a new simplified relationship between the forward and the backward stages to avoid repetitive computations using the inherent orthogonal properties of the least squares methods. Furthermore, a new term exchanging scheme for backward model refinement is introduced to reduce computational demand. Finally, given the error reduction ratio criterion, effective and efficient forward and backward subset selection procedures are proposed. Extensive examples are presented to demonstrate the improved model compactness constructed by the proposed technique in comparison with some popular methods.", "paper_title": "Two-Stage Orthogonal Least Squares Methods for Neural Network Construction", "paper_id": "WOS:000358224200003"}