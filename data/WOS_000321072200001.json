{"auto_keywords": [{"score": 0.029397702016443556, "phrase": "nitro"}, {"score": 0.010156685379942786, "phrase": "different_cores"}, {"score": 0.010108970060205027, "phrase": "experimental_results"}, {"score": 0.00481495049065317, "phrase": "multicore_processors"}, {"score": 0.004724622856856568, "phrase": "processor_architectures"}, {"score": 0.004691186518512389, "phrase": "multiple_cores"}, {"score": 0.004614081478934359, "phrase": "different_behavior"}, {"score": 0.004277359615286959, "phrase": "future_technologies"}, {"score": 0.00401236106110633, "phrase": "power_saving"}, {"score": 0.003993394845843522, "phrase": "power_budget_mechanisms"}, {"score": 0.003817610937998009, "phrase": "initial_analysis"}, {"score": 0.00378159764053533, "phrase": "legacy_power_saving_techniques"}, {"score": 0.0037282113054951027, "phrase": "power_budget"}, {"score": 0.0037105832468804123, "phrase": "thread-independent_and_multi-programmed_workloads"}, {"score": 0.0036236808387677456, "phrase": "parallel_shared-memory_applications"}, {"score": 0.0035725158840297275, "phrase": "single_core"}, {"score": 0.0033749549418032833, "phrase": "synchronization_points"}, {"score": 0.003319411530369619, "phrase": "negative_impact"}, {"score": 0.0033037099853128523, "phrase": "global_performance"}, {"score": 0.0032263057510551123, "phrase": "power_token_balancing"}, {"score": 0.0031581888200437106, "phrase": "external_power_constraint"}, {"score": 0.0030623293444434047, "phrase": "ptb"}, {"score": 0.003026226041815386, "phrase": "predefined_power_budget"}, {"score": 0.0029905553340033716, "phrase": "original_peak_power"}, {"score": 0.002955304277081627, "phrase": "dvfs."}, {"score": 0.002941319518835868, "phrase": "total_energy"}, {"score": 0.002791779231329709, "phrase": "novel_mechanism"}, {"score": 0.0027005897576795105, "phrase": "critical_section"}, {"score": 0.0025330295341397333, "phrase": "execution_time"}, {"score": 0.002521038339625905, "phrase": "lock-intensive_applications"}, {"score": 0.002461926406033419, "phrase": "selected_program_phases"}, {"score": 0.002392814382568583, "phrase": "total_execution_time"}, {"score": 0.0023311634030822527, "phrase": "thermal_effects"}, {"score": 0.002309139952095626, "phrase": "different_cmp_configurations"}, {"score": 0.002298206194070811, "phrase": "realistic_power_numbers"}, {"score": 0.0022073303906817734, "phrase": "temperature_gradient"}, {"score": 0.002191669798405392, "phrase": "signal_reliability"}, {"score": 0.0021351902267935726, "phrase": "average_and_peak_temperatures"}, {"score": 0.0021200403678753245, "phrase": "studied_benchmarks"}, {"score": 0.0021049977753042253, "phrase": "peak_power_budget"}], "paper_keywords": ["Power consumption", " Power budget", " Power tokens", " Chip multiprocessor"], "paper_abstract": "Nowadays the market is dominated by processor architectures that employ multiple cores per chip. These architectures have different behavior depending on the applications running on the processor (parallel, multiprogrammed, sequential), but all happen to meet what is called the power and temperature wall. For future technologies (less than 22 nm) and a fixed die size, it is still uncertain the percentage of processor that can be simultaneously powered on. Power saving and power budget mechanisms can be useful to precisely control the amount of power been dissipated by the processor. After an initial analysis we discover that legacy power saving techniques work properly for matching a power budget in thread-independent and multi-programmed workloads, but not in parallel workloads. When running parallel shared-memory applications sacrificing some performance in a single core (thread) in order to be more energy-efficient can unintentionally delay the rest of cores (threads) due to synchronization points (locks/barriers), having a negative impact on global performance. In order to solve this problem we propose power token balancing (PTB) aimed at accurately matching an external power constraint by balancing the power consumed among the different cores. Experimental results show that PTB matches more accurately a predefined power budget (50 % of the original peak power) than other mechanisms like DVFS. The total energy consumed over the budget is reduced to only 8 % for a 16-core CMP with only a 3 % energy increase (overhead). We also introduce a novel mechanism named \"Nitro\". Nitro will overclock the core that enters a critical section (delimited by locks) in order to free the lock as soon as possible. Experimental results have shown that Nitro is able to reduce the execution time of lock-intensive applications in more than 4 % by overclocking the frequency by 15 % in selected program phases over a period of time that represents a 22 % of the total execution time. We conclude the work with an analysis of the thermal effects of PTB in different CMP configurations using realistic power numbers and heatsink/fan configurations. Results show how PTB not only balances temperature between the different cores, reducing temperature gradient and increasing signal reliability, but also allows a reduction of 28-30 % of both average and peak temperatures for the studied benchmarks when a peak power budget of 50 % is exceeded.", "paper_title": "Efficient inter-core power and thermal balancing for multicore processors", "paper_id": "WOS:000321072200001"}