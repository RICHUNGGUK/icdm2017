{"auto_keywords": [{"score": 0.04444288300280286, "phrase": "opencl"}, {"score": 0.025134166021594833, "phrase": "dynamic_energy"}, {"score": 0.00481495049065317, "phrase": "disciplined_memory_model"}, {"score": 0.004547438494330851, "phrase": "broad_computing_spectrum"}, {"score": 0.004294724955301414, "phrase": "high-performance_computing_server"}, {"score": 0.004184526032558792, "phrase": "de_facto_standard_programming_environment"}, {"score": 0.004141238989360548, "phrase": "general-purpose_computing"}, {"score": 0.004098397888277889, "phrase": "graphics_processing_units"}, {"score": 0.003598705020845104, "phrase": "ever_increasing_memory_bandwidth_pressure"}, {"score": 0.003434085751246066, "phrase": "on-chip_caches"}, {"score": 0.002983916676307492, "phrase": "large_on-chip_caches"}, {"score": 0.0027169974137406148, "phrase": "opencl_memory_model"}, {"score": 0.002633425544817301, "phrase": "gpu_region-"}, {"score": 0.0026061419474030633, "phrase": "energy-efficient_non-inclusive_cache_hierarchy"}, {"score": 0.0024868131939261716, "phrase": "green_cache"}, {"score": 0.0021831803612759855, "phrase": "leakage_energy"}, {"score": 0.002127046102734894, "phrase": "practically_no_performance_degradation"}, {"score": 0.0021049977753042253, "phrase": "off-chip_access_increases"}], "paper_keywords": ["OpenCL", " GPU", " cache"], "paper_abstract": "As various graphics processing unit architectures are deployed across broad computing spectrum from a hand-held or embedded device to a high-performance computing server, OpenCL becomes the de facto standard programming environment for general-purpose computing on graphics processing units. Unlike its CPU counterpart, OpenCL has several distinct features such as its disciplined memory model, which is partially inherited from conventional 3D graphics programming models. On the other hand, due to ever increasing memory bandwidth pressure and low power requirement, the capacity of on-chip caches in GPUs keeps increasing over time. Given such trends, we believe that we have interesting programming model/architecture co-optimization opportunities, in particular, how to energy-efficiently utilize large on-chip caches for GPUs. In this paper, as a showcase, we study the characteristics of the OpenCL memory model and propose a technique called GPU Region-aware energy-efficient non-inclusive cache hierarchy, or GREEN cache hierarchy. With the GREEN cache, our simulation results show that we can save 56 percent of dynamic energy in the L1 cache, 39 percent of dynamic energy in the L2 cache, and 50 percent of leakage energy in the L2 cache with practically no performance degradation and off-chip access increases.", "paper_title": "GREEN Cache: Exploiting the Disciplined Memory Model of OpenCL on GPUs", "paper_id": "WOS:000362743300012"}