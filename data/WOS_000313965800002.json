{"auto_keywords": [{"score": 0.037977670313304526, "phrase": "eda"}, {"score": 0.007152360358701901, "phrase": "spoken_term_detection"}, {"score": 0.00585040808620148, "phrase": "complex_decision_tasks"}, {"score": 0.005573623416715236, "phrase": "oov_terms"}, {"score": 0.004770089441503382, "phrase": "std"}, {"score": 0.004659735493429681, "phrase": "spoken_terms"}, {"score": 0.004637972270967348, "phrase": "audio_archives"}, {"score": 0.004584005829642029, "phrase": "robust_confidence_estimation"}, {"score": 0.004263091467493893, "phrase": "multi-layer_perceptrons"}, {"score": 0.004144961421882705, "phrase": "good_performance"}, {"score": 0.004115941833566188, "phrase": "discriminative_confidence"}, {"score": 0.004030091505277862, "phrase": "continuous_objective_functions"}, {"score": 0.0038818490196679085, "phrase": "substantial_performance_reduction"}, {"score": 0.0037830956477986222, "phrase": "high_diversity"}, {"score": 0.003765411269138144, "phrase": "term_properties"}, {"score": 0.0037215597979390076, "phrase": "complicated_decision_boundary"}, {"score": 0.003652453313329249, "phrase": "new_discriminative_confidence_estimation_approach"}, {"score": 0.0036268693010639485, "phrase": "evolutionary_discriminant_analysis"}, {"score": 0.0035180527664242667, "phrase": "classification_error"}, {"score": 0.0033648390499758664, "phrase": "heterogeneous_projection_functions"}, {"score": 0.003349103271790891, "phrase": "classification_strategies"}, {"score": 0.003333440836347026, "phrase": "decision_making"}, {"score": 0.00329460339777516, "phrase": "highly_flexible_classifier"}, {"score": 0.003203223774661634, "phrase": "evolutionary_strategy"}, {"score": 0.0031510902885753212, "phrase": "local_minima"}, {"score": 0.003114370751209526, "phrase": "eda-based_confidence"}, {"score": 0.003092544098916454, "phrase": "state-of-the-art_phoneme-based_std_system"}, {"score": 0.0030709061083696158, "phrase": "english"}, {"score": 0.0030138097155536854, "phrase": "phoneme_speech_recognition_system"}, {"score": 0.002964749834519905, "phrase": "phoneme_sequences"}, {"score": 0.0029370739583123736, "phrase": "enquiry_terms"}, {"score": 0.0029028410828943834, "phrase": "test_corpora"}, {"score": 0.00287574145667595, "phrase": "speech_data"}, {"score": 0.0028555824153862234, "phrase": "individual_head-mounted_microphones"}, {"score": 0.0027959474175388507, "phrase": "icsi"}, {"score": 0.002782869758611083, "phrase": "nist"}, {"score": 0.0027698434116077636, "phrase": "isl"}, {"score": 0.0027568822475659556, "phrase": "ldc"}, {"score": 0.002686669790089476, "phrase": "experimental_results"}, {"score": 0.00260598817208936, "phrase": "confidence_measurement"}, {"score": 0.00244032678338226, "phrase": "classification_performance"}, {"score": 0.002411869707120481, "phrase": "equal_error_rate"}, {"score": 0.002400580501048716, "phrase": "eer"}, {"score": 0.002295920688567822, "phrase": "inv_terms"}, {"score": 0.002180411261696925, "phrase": "std_performance"}, {"score": 0.002144888554843472, "phrase": "significant_relative_improvement"}, {"score": 0.0021049977753042253, "phrase": "average_term-weighted_value"}], "paper_keywords": ["Spoken term detection", " Confidence measurement", " Evolutionary discriminant analysis"], "paper_abstract": "Spoken term detection (STD) is the task of searching for occurrences of spoken terms in audio archives. It relies on robust confidence estimation to make a hit/false alarm (FA) decision. In order to optimize the decision in terms of the STD evaluation metric, the confidence has to be discriminative. Multi-layer perceptrons (MLPs) and support vector machines (SVMs) exhibit good performance in producing discriminative confidence; however they are severely limited by the continuous objective functions, and are therefore less capable of dealing with complex decision tasks. This leads to a substantial performance reduction when measuring detection of out-of-vocabulary (OOV) terms, where the high diversity in term properties usually leads to a complicated decision boundary. In this paper we present a new discriminative confidence estimation approach based on evolutionary discriminant analysis (EDA). Unlike MLPs and SVMs, EDA uses the classification error as its objective function, resulting in a model optimized towards the evaluation metric. In addition, EDA combines heterogeneous projection functions and classification strategies in decision making, leading to a highly flexible classifier that is capable of dealing with complex decision tasks. Finally, the evolutionary strategy of EDA reduces the risk of local minima. We tested the EDA-based confidence with a state-of-the-art phoneme-based STD system on an English meeting domain corpus, which employs a phoneme speech recognition system to produce lattices within which the phoneme sequences corresponding to the enquiry terms are searched. The test corpora comprise 11 h of speech data recorded with individual head-mounted microphones from 30 meetings carried out at several institutes including ICSI; NIST; ISL; LDC; the Virginia Polytechnic Institute and State University; and the University of Edinburgh. The experimental results demonstrate that EDA considerably outperforms MLPs and SVMs on both classification and confidence measurement in STD, and the advantage is found to be more significant on OOV terms than on in-vocabulary (INV) terms. In terms of classification performance, EDA achieved an equal error rate (EER) of 11% on OOV terms, compared to 34% and 31% with MLPs and SVMs respectively; for INV terms, an EER of 15% was obtained with EDA compared to 17% obtained with MLPs and SVMs. In terms of STD performance for OOV terms, EDA presented a significant relative improvement of 1.4% and 2.5% in terms of average term-weighted value (ATWV) over MLPs and SVMs respectively.", "paper_title": "Evolutionary discriminative confidence estimation for spoken term detection", "paper_id": "WOS:000313965800002"}