{"auto_keywords": [{"score": 0.048193365666829385, "phrase": "lle"}, {"score": 0.020172593798921404, "phrase": "neighborhood_sizes"}, {"score": 0.019064112432670838, "phrase": "input_data_spaces"}, {"score": 0.009853661701244073, "phrase": "nonlinear_dimensionality_reduction"}, {"score": 0.00936012167704538, "phrase": "paper_show"}, {"score": 0.008207357003054201, "phrase": "dimensionality_reduction"}, {"score": 0.006679463171074705, "phrase": "regularization_method"}, {"score": 0.004520438007604407, "phrase": "well-known_method"}, {"score": 0.004392565073466714, "phrase": "mathematical_proof"}, {"score": 0.004342430078306461, "phrase": "experimental_results"}, {"score": 0.0037617986040878342, "phrase": "nonlinear_method"}, {"score": 0.0036553070575015344, "phrase": "linear_method"}, {"score": 0.0025596276616952516, "phrase": "moderate_regularization_parameters"}, {"score": 0.002472822097373027, "phrase": "relative_distance"}, {"score": 0.0024305268807926056, "phrase": "input_data"}, {"score": 0.0021539955106204354, "phrase": "multiple_solutions"}, {"score": 0.0021049977753042253, "phrase": "best_way"}], "paper_keywords": ["locally linear embedding", " nonlinear dimensionality reduction", " manifold learning", " principle component analysis"], "paper_abstract": "Locally linear embedding (LLE) is a well-known method for nonlinear dimensionality reduction. The mathematical proof and experimental results presented in this paper show that the neighborhood sizes in LLE must be smaller than the dimensions of input data spaces, otherwise LLE would degenerate from a nonlinear method for dimensionality reduction into a linear method for dimensionality reduction. Furthermore, when the neighborhood sizes are larger than the dimensions of input data spaces, the solutions to LLE are not unique. In these cases, the addition of some regularization method is often proposed. The experimental results presented in this paper show that the regularization method is not robust. Too large or too small regularization parameters cannot unwrap S-curve. Although a moderate regularization parameters can unwrap S-curve, the relative distance in the input data will be distorted in unwrapping. Therefore, in order to make LLE play fully its advantage in nonlinear dimensionality reduction and avoid multiple solutions happening, the best way is to make sure that the neighborhood sizes are smaller than the dimensions of input data spaces.", "paper_title": "Constraints on the Neighborhood Size in LLE", "paper_id": "WOS:000293664700012"}