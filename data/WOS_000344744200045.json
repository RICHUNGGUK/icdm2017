{"auto_keywords": [{"score": 0.0468646800853908, "phrase": "popular_music"}, {"score": 0.012632298670518294, "phrase": "emotion_detection"}, {"score": 0.00481495049065317, "phrase": "popular_music_representation_strategy"}, {"score": 0.00469500313566324, "phrase": "song's_emotion"}, {"score": 0.004380265418103948, "phrase": "chorus_and_verse_segments"}, {"score": 0.004298134888203576, "phrase": "proposed_chorus_detection_algorithm"}, {"score": 0.003909923690310641, "phrase": "structured_segments"}, {"score": 0.003788444178071508, "phrase": "hierarchical_adaboost_classifier"}, {"score": 0.003467940281748612, "phrase": "general_emotion"}, {"score": 0.0032970801489442952, "phrase": "thayer's_model"}, {"score": 0.002676587673012276, "phrase": "average_precision_rate"}, {"score": 0.002576988153314685, "phrase": "additional_tests"}, {"score": 0.002481085648977411, "phrase": "cover_versions"}, {"score": 0.002449915958738505, "phrase": "different_lyrics"}, {"score": 0.0023587312574818208, "phrase": "resultant_precision_rate"}, {"score": 0.002285335999629823, "phrase": "proposes_approaches"}, {"score": 0.0021726139494880653, "phrase": "professional_online_music_company"}, {"score": 0.0021453112313233554, "phrase": "kkbox_inc."}, {"score": 0.0021049977753042253, "phrase": "promising_performance"}], "paper_keywords": ["Popular music", " Chorus", " Verse", " MFCCs", " Rhythm", " Emotion", " Adaboost"], "paper_abstract": "This paper proposes a popular music representation strategy based on the song's emotion. First, a piece of popular music is decomposed into chorus and verse segments through the proposed chorus detection algorithm. Three descriptive features: intensity, frequency band and rhythm regularity are extracted from the structured segments for emotion detection. A hierarchical Adaboost classifier is employed to recognize the emotion of a piece of popular music. The general emotion of the music is classified according to Thayer's model into four emotions: happy, angry, depressed and relaxed. Experiments conducted on a 350-popular-music database show the average recall and precision of our proposed chorus detection are approximately 95% and 84 %, respectively; and the average precision rate of emotion detection is 92 %. Additional tests are performed on songs with cover versions in different lyrics and languages, and the resultant precision rate is 90 %. The proposes approaches have been tested and proven by the professional online music company, KKBOX Inc. and show promising performance for effectively and efficiently identifying the emotions of a variety of popular music.", "paper_title": "Popular music representation: chorus detection & emotion recognition", "paper_id": "WOS:000344744200045"}