{"auto_keywords": [{"score": 0.0414232075728796, "phrase": "optimal_action"}, {"score": 0.015561929573070624, "phrase": "regular_functions"}, {"score": 0.015191490416907665, "phrase": "la"}, {"score": 0.013619709041005712, "phrase": "pursuit_algorithms"}, {"score": 0.011773053034781803, "phrase": "ryan"}, {"score": 0.011725410748655485, "phrase": "omkar"}, {"score": 0.011420620455960415, "phrase": "previous_proofs"}, {"score": 0.010509751876547947, "phrase": "reward_probability_estimates"}, {"score": 0.00481495049065317, "phrase": "continuous_pursuit_algorithms"}, {"score": 0.004669845451682529, "phrase": "learning_automata"}, {"score": 0.00460362743452656, "phrase": "formal_proofs"}, {"score": 0.004556901872357751, "phrase": "mathematical_techniques"}, {"score": 0.0045198615640633455, "phrase": "different_families"}, {"score": 0.00410645614623058, "phrase": "pioneering_schemes"}, {"score": 0.003926105480202798, "phrase": "arbitrarily_large_probability"}, {"score": 0.0038941724772770794, "phrase": "learning_parameter"}, {"score": 0.0038467574225322086, "phrase": "existing_proofs"}, {"score": 0.003438058620195309, "phrase": "common_flaw"}, {"score": 0.0033548062793973144, "phrase": "so-called_\"monotonicity\"_property"}, {"score": 0.0030290092764035607, "phrase": "single_point"}, {"score": 0.002837255855523494, "phrase": "j_appl_probab"}, {"score": 0.002690406375639144, "phrase": "pioneering_ea"}, {"score": 0.0026521818472499906, "phrase": "new_proof"}, {"score": 0.0026252106881752067, "phrase": "absorbing_cpa"}, {"score": 0.0025615908073796027, "phrase": "cpa_paradigm"}, {"score": 0.0025148871904409095, "phrase": "action_probability"}, {"score": 0.002469032978674379, "phrase": "previous_flawed_proofs"}, {"score": 0.0024389277933858054, "phrase": "monotonicity_property"}, {"score": 0.002424012799998538, "phrase": "action_probabilities"}, {"score": 0.0023652572260178637, "phrase": "traditional_approach"}, {"score": 0.0021661448244238994, "phrase": "different_eas"}], "paper_keywords": ["Pursuit algorithms", " CPA", " Absorbing CPA", " epsilon-optimality"], "paper_abstract": "The most difficult part in the design and analysis of Learning Automata (LA) consists of the formal proofs of their convergence accuracies. The mathematical techniques used for the different families (Fixed Structure, Variable Structure, Discretized etc.) are quite distinct. Among the families of LA, Estimator Algorithms (EAs) are certainly the fastest, and within this family, the set of Pursuit algorithms have been considered to be the pioneering schemes. Informally, if the environment is stationary, their epsilon-optimality is defined as their ability to converge to the optimal action with an arbitrarily large probability, if the learning parameter is sufficiently small/large. The existing proofs of all the reported EAs follow the same fundamental principles, and to clarify this, in the interest of simplicity, we shall concentrate on the family of Pursuit algorithms. Recently, it has been reported Ryan and Omkar (J Appl Probab 49(3):795-805, 2012) that the previous proofs for epsilon-optimality of all the reported EAs have a common flaw. The flaw lies in the condition which apparently supports the so-called \"monotonicity\" property of the probability of selecting the optimal action, which states that after some time instant t (0), the reward probability estimates will be ordered correctly forever. The authors of the various proofs have rather offered a proof for the fact that the reward probability estimates are ordered correctly at a single point of time after t (0), which, in turn, does not guarantee the ordering forever, rendering the previous proofs incorrect. While in Ryan and Omkar (J Appl Probab 49(3):795-805, 2012), a rectified proof was presented to prove the epsilon-optimality of the Continuous Pursuit Algorithm (CPA), which was the pioneering EA, in this paper, a new proof is provided for the Absorbing CPA (ACPA), i.e., an algorithm which follows the CPA paradigm but which artificially has absorbing states whenever any action probability is arbitrarily close to unity. Unlike the previous flawed proofs, instead of examining the monotonicity property of the action probabilities, it rather examines their submartingale property, and then, unlike the traditional approach, invokes the theory of Regular functions to prove that the probability of converging to the optimal action can be made arbitrarily close to unity. We believe that the proof is both unique and pioneering, and adds insights into the convergence of different EAs. It can also form the basis for formally demonstrating the epsilon-optimality of other Estimator algorithms which are artificially rendered absorbing.", "paper_title": "A formal proof of the epsilon-optimality of absorbing continuous pursuit algorithms using the theory of regular functions", "paper_id": "WOS:000342426700020"}