{"auto_keywords": [{"score": 0.03345207366592562, "phrase": "relative_intensities"}, {"score": 0.00481495049065317, "phrase": "online_tracking"}, {"score": 0.004760017604908536, "phrase": "outdoor_lighting_variations_for_augmented_reality"}, {"score": 0.0047057084749407485, "phrase": "moving_cameras"}, {"score": 0.0046253989970108985, "phrase": "augmented_reality"}, {"score": 0.00452043800760441, "phrase": "key_tasks"}, {"score": 0.004417848254181138, "phrase": "convincing_visual_appearance_consistency"}, {"score": 0.0042928648367867835, "phrase": "video_scenes"}, {"score": 0.004171402455813099, "phrase": "coherent_illumination"}, {"score": 0.0041001740903338834, "phrase": "whole_sequence"}, {"score": 0.004030157055463817, "phrase": "outdoor_illumination"}, {"score": 0.0038271712887391015, "phrase": "lighting_condition"}, {"score": 0.003511246498068952, "phrase": "full_image-based_approach"}, {"score": 0.0034118234596993836, "phrase": "outdoor_illumination_variations"}, {"score": 0.0030414140732789186, "phrase": "sparse_set"}, {"score": 0.003006654007926993, "phrase": "planar_feature-points"}, {"score": 0.0028550709503536494, "phrase": "inevitable_feature_misalignments"}, {"score": 0.0026191799769765085, "phrase": "spatial_and_temporal_coherence"}, {"score": 0.0023889533502525527, "phrase": "optimization_process"}, {"score": 0.002268441347979241, "phrase": "real-life_videos"}, {"score": 0.0021049977753042253, "phrase": "video_sequences"}], "paper_keywords": ["Augmented reality", " illumination coherence", " moving cameras"], "paper_abstract": "In augmented reality, one of key tasks to achieve a convincing visual appearance consistency between virtual objects and video scenes is to have a coherent illumination along the whole sequence. As outdoor illumination is largely dependent on the weather, the lighting condition may change from frame to frame. In this paper, we propose a full image-based approach for online tracking of outdoor illumination variations from videos captured with moving cameras. Our key idea is to estimate the relative intensities of sunlight and skylight via a sparse set of planar feature-points extracted from each frame. To address the inevitable feature misalignments, a set of constraints are introduced to select the most reliable ones. Exploiting the spatial and temporal coherence of illumination, the relative intensities of sunlight and skylight are finally estimated by using an optimization process. We validate our technique on a set of real-life videos and show that the results with our estimations are visually coherent along the video sequences.", "paper_title": "Online Tracking of Outdoor Lighting Variations for Augmented Reality with Moving Cameras", "paper_id": "WOS:000301526500010"}