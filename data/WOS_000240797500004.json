{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "classifier_performance"}, {"score": 0.04783182929351233, "phrase": "cost_curves"}, {"score": 0.03524369468825586, "phrase": "roc_curves"}, {"score": 0.0037864980290391354, "phrase": "full_range"}, {"score": 0.003714368305523811, "phrase": "possible_class_distributions"}, {"score": 0.003643607569483598, "phrase": "misclassification_costs"}, {"score": 0.0028923335491735564, "phrase": "performance_assessment"}, {"score": 0.0025521085778978042, "phrase": "confidence_intervals"}, {"score": 0.00247944491239733, "phrase": "classifier's_performance"}, {"score": 0.00236289633510808, "phrase": "statistical_significance"}, {"score": 0.002145942273032774, "phrase": "software_tool"}], "paper_keywords": ["performance evaluation", " classifiers", " ROC curves", " machine learning"], "paper_abstract": "This paper introduces cost curves, a graphical technique for visualizing the performance (error rate or expected cost) of 2-class classifiers over the full range of possible class distributions and misclassification costs. Cost curves are shown to be superior to ROC curves for visualizing classifier performance for most purposes. This is because they visually support several crucial types of performance assessment that cannot be done easily with ROC curves, such as showing confidence intervals on a classifier's performance, and visualizing the statistical significance of the difference in performance of two classifiers. A software tool supporting all the cost curve analysis described in this paper is available from the authors.", "paper_title": "Cost curves: An improved method for visualizing classifier performance", "paper_id": "WOS:000240797500004"}