{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "tensor_dictionary_learning_for_positive_definite_matrices"}, {"score": 0.004765173195920904, "phrase": "sparse_models"}, {"score": 0.004571133708117502, "phrase": "image_processing_and_computer_vision"}, {"score": 0.004272456401437226, "phrase": "sparse_representation"}, {"score": 0.004184526032558792, "phrase": "low-rank_models"}, {"score": 0.004014035333627087, "phrase": "sparse_modeling"}, {"score": 0.0038907236419588255, "phrase": "region_covariances"}, {"score": 0.0037516215763875225, "phrase": "sparse_coding_approaches"}, {"score": 0.003693533648584145, "phrase": "positive_definite_descriptors"}, {"score": 0.0036174746598098863, "phrase": "earlier_work"}, {"score": 0.0033285306462537884, "phrase": "training_signals"}, {"score": 0.0031762308449055305, "phrase": "concise_dictionary"}, {"score": 0.0031270239691197515, "phrase": "entire_training"}, {"score": 0.002968424524565369, "phrase": "novel_approach"}, {"score": 0.0029376803941247084, "phrase": "dictionary_learning"}, {"score": 0.0029072537537959374, "phrase": "positive_definite_matrices"}, {"score": 0.002759769970554556, "phrase": "sparse_coding"}, {"score": 0.0027311809666295565, "phrase": "dictionary_update"}, {"score": 0.002674885993329912, "phrase": "different_atom_update_methods"}, {"score": 0.0026061419474030633, "phrase": "discriminative_version"}, {"score": 0.0025657442830956017, "phrase": "dictionary_learning_approach"}, {"score": 0.002435542816459651, "phrase": "different_classes"}, {"score": 0.002360607691114015, "phrase": "experimental_results"}, {"score": 0.0022291501521610737, "phrase": "reconstruction_and_classification_viewpoints"}, {"score": 0.002171836484200008, "phrase": "software_library"}], "paper_keywords": ["Sparse coding", " dictionary learning", " positive definite matrices", " region covariance descriptors", " optimization"], "paper_abstract": "Sparse models have proven to be extremely successful in image processing and computer vision. However, a majority of the effort has been focused on sparse representation of vectors and low-rank models for general matrices. The success of sparse modeling, along with popularity of region covariances, has inspired the development of sparse coding approaches for these positive definite descriptors. While in earlier work, the dictionary was formed from all, or a random subset of, the training signals, it is clearly advantageous to learn a concise dictionary from the entire training set. In this paper, we propose a novel approach for dictionary learning over positive definite matrices. The dictionary is learned by alternating minimization between sparse coding and dictionary update stages, and different atom update methods are described. A discriminative version of the dictionary learning approach is also proposed, which simultaneously learns dictionaries for different classes in classification or clustering. Experimental results demonstrate the advantage of learning dictionaries from data both from reconstruction and classification viewpoints. Finally, a software library is presented comprising C++ binaries for all the positive definite sparse coding and dictionary learning approaches presented here.", "paper_title": "Tensor Dictionary Learning for Positive Definite Matrices", "paper_id": "WOS:000360814100009"}