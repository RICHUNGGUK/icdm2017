{"auto_keywords": [{"score": 0.03622410301658812, "phrase": "spectral_content"}, {"score": 0.00481495049065317, "phrase": "phonetic_syllables"}, {"score": 0.004666460260366703, "phrase": "acoustic_properties"}, {"score": 0.00459393336391459, "phrase": "emotion_recognition"}, {"score": 0.004434824354230475, "phrase": "feature_extraction"}, {"score": 0.0043148760739240575, "phrase": "real_time_processing_systems"}, {"score": 0.004005339423663657, "phrase": "classical_research_methods"}, {"score": 0.003821342577980031, "phrase": "specific_areas"}, {"score": 0.003776674472150248, "phrase": "speech_signal"}, {"score": 0.003732526540522333, "phrase": "intonation_phenomena"}, {"score": 0.003703380599999214, "phrase": "technological_approaches"}, {"score": 0.003561017335579207, "phrase": "whole_speech_signal"}, {"score": 0.0034782306784111494, "phrase": "qualitative_variability"}, {"score": 0.0033444934455768623, "phrase": "theoretical_basis"}, {"score": 0.0033053807885373905, "phrase": "prosodic_research"}, {"score": 0.003203294948113915, "phrase": "feature_extraction_method"}, {"score": 0.003116551456858777, "phrase": "phonetic_interpretation"}, {"score": 0.002926973459215349, "phrase": "syllabic_nuclei"}, {"score": 0.002748895580860912, "phrase": "feature_weighting"}, {"score": 0.0027167292419065514, "phrase": "syllabic_prominence"}, {"score": 0.002462867872567125, "phrase": "classical_axes"}, {"score": 0.002444134427534857, "phrase": "valence"}, {"score": 0.0024059650358100367, "phrase": "dominance"}, {"score": 0.002250272652754455, "phrase": "potential_impact"}, {"score": 0.002180702259644951, "phrase": "affective_computing_systems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Affective computing", " Feature extraction", " Phonetic syllables", " Valence-Activation-Dominance space"], "paper_abstract": "As research on the extraction of acoustic properties of speech for emotion recognition progresses, the need of investigating methods of feature extraction taking into account the necessities of real time processing systems becomes more important. Past works have shown the importance of syllables for the transmission of emotions, while classical research methods adopted in prosody show that it is important to concentrate on specific areas of the speech signal to study intonation phenomena. Technological approaches, however, are often designed to use the whole speech signal without taking into account the qualitative variability of the spectral content. Given this contrast with the theoretical basis around which prosodic research is pursued, we present here a feature extraction method built on the basis of a phonetic interpretation of the concept of syllable. In particular, we concentrate on the spectral content of syllabic nuclei, thus reducing the amount of information to be processed. Moreover, we introduce feature weighting based on syllabic prominence, thus not considering all the units of analysis as being equally important. The method is evaluated on a continuous, three-dimensional model of emotions built on the classical axes of Valence, Activation and Dominance and is shown to be competitive with state-of-the-art performance. The potential impact of this approach on the design of affective computing systems is also analysed. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Continuous emotion recognition with phonetic syllables", "paper_id": "WOS:000328180100012"}