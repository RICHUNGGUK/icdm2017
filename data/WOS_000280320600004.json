{"auto_keywords": [{"score": 0.03307663719414094, "phrase": "phonemic_degradation"}, {"score": 0.00481495049065317, "phrase": "image_processing"}, {"score": 0.0047650691627251825, "phrase": "loss_research"}, {"score": 0.00466684417181804, "phrase": "perceptual_criteria"}, {"score": 0.004491970050862321, "phrase": "computational_models"}, {"score": 0.004445419749485783, "phrase": "auditory_periphery"}, {"score": 0.004190563478825626, "phrase": "clinical_research"}, {"score": 0.004161553532799662, "phrase": "human_subjects"}, {"score": 0.0038822311096089307, "phrase": "wide_range"}, {"score": 0.003855347387268162, "phrase": "physiological_data"}, {"score": 0.003815369123984481, "phrase": "normal_and_impaired_ears"}, {"score": 0.0037889466472096284, "phrase": "stimuli_presentation_levels"}, {"score": 0.003749654338704576, "phrase": "dynamic_range"}, {"score": 0.003685067218455088, "phrase": "model_output"}, {"score": 0.003584025547693836, "phrase": "spectro-temporal_output"}, {"score": 0.003485744667868367, "phrase": "sensorineural_hearing_loss"}, {"score": 0.0034615969985956866, "phrase": "snhl"}, {"score": 0.00342568771304873, "phrase": "phonemic_structure"}, {"score": 0.003217896008931311, "phrase": "average_discharge_rate"}, {"score": 0.0031955979242589494, "phrase": "temporal_envelope"}, {"score": 0.0031624392548836654, "phrase": "new_systematic_way"}, {"score": 0.0030437652050982643, "phrase": "auditory_nerve_model"}, {"score": 0.0029602552900111407, "phrase": "mean_structured_similarity_index"}, {"score": 0.0028991255455294565, "phrase": "objective_measure"}, {"score": 0.002849146732780381, "phrase": "perceptual_image_quality"}, {"score": 0.002685558057339722, "phrase": "impaired_auditory_nerve_outputs"}, {"score": 0.002657677633954843, "phrase": "full_evaluation"}, {"score": 0.002540160379502092, "phrase": "large_amount"}, {"score": 0.0025225467103906314, "phrase": "natural_human_speech"}, {"score": 0.0024963543716522087, "phrase": "metric's_boundedness"}, {"score": 0.0024533019565858073, "phrase": "tfs_neurograms"}, {"score": 0.0023859534478427313, "phrase": "standard_point"}, {"score": 0.0023285383529595416, "phrase": "absolute_error"}, {"score": 0.002312388685547026, "phrase": "relative_mean"}, {"score": 0.002280424506654019, "phrase": "mssim"}, {"score": 0.0022567398334877847, "phrase": "indicative_score"}, {"score": 0.002149418970824546, "phrase": "standard_speech_intelligibility_index_metric"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Auditory periphery model", " Hearing aids", " Sensorineural hearing loss", " Structural similarity", " MSSIM", " Speech intelligibility"], "paper_abstract": "Hearing loss research has traditionally been based on perceptual criteria, speech intelligibility and threshold levels. The development of computational models of the auditory periphery has allowed experimentation via simulation to provide quantitative, repeatable results at a more granular level than would be practical with clinical research on human subjects. The responses of the model used in this study have been previously shown to be consistent with a wide range of physiological data from both normal and impaired ears for stimuli presentation levels spanning the dynamic range of hearing. The model output can be assessed by examination of the spectro-temporal output visualised as neurograms. The effect of sensorineural hearing loss (SNHL) on phonemic structure was evaluated in this study using two types of neurograms: temporal fine structure (TFS) and average discharge rate or temporal envelope. A new systematic way of assessing phonemic degradation is proposed using the outputs of an auditory nerve model for a range of SNHLs. The mean structured similarity index (MSSIM) is an objective measure originally developed to assess perceptual image quality. The measure is adapted here for use in measuring the phonemic degradation in neurograms derived from impaired auditory nerve outputs. A full evaluation of the choice of parameters for the metric is presented using a large amount of natural human speech. The metric's boundedness and the results for TFS neurograms indicate it is a superior metric to standard point to point metrics of relative mean absolute error and relative mean squared error. MSSIM as an indicative score of intelligibility is also promising, with results similar to those of the standard speech intelligibility index metric. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Speech intelligibility from image processing", "paper_id": "WOS:000280320600004"}