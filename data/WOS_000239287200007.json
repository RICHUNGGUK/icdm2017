{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "empirical_entropy-normal_numbers"}, {"score": 0.004253618550301311, "phrase": "markov_processes"}, {"score": 0.003680587852807675, "phrase": "kolmogorov_complexity"}, {"score": 0.0029928611380840757, "phrase": "surpasses_m._reasonable_complexity_metric"}, {"score": 0.002643386043540555, "phrase": "length_m"}], "paper_keywords": ["analysis of algorithms", " data compression", " Kolmogorov complexity", " Shannon's entropy", " empirical entropy", " normal numbers", " de Bruijn sequences", " threshold phenomena", " self-information", " Markov processes", " relative entropy", " birthday paradox"], "paper_abstract": "We briefly survey some concepts related to empirical entropy-normal numbers, de Bruijn sequences and Markov processes and investigate how well it approximates Kolmogorov complexity. Our results suggest lth-order empirical entropy stops being a surpasses m. reasonable complexity metric for almost all strings of length m over alphabets of size n about when n(l) surpasses m. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Large alphabets and incompressibility", "paper_id": "WOS:000239287200007"}