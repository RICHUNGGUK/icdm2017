{"auto_keywords": [{"score": 0.028200034697259978, "phrase": "near-duplicate_keyframe_retrieval"}, {"score": 0.00481495049065317, "phrase": "-duplicate_keyframe_retrieval"}, {"score": 0.004775918707955445, "phrase": "semi-supervised_learning"}, {"score": 0.004660702714929615, "phrase": "ear-duplicate_keyframe"}, {"score": 0.004585433265422727, "phrase": "retrieval_techniques"}, {"score": 0.004108066884382925, "phrase": "effective_approach"}, {"score": 0.00407474190126995, "phrase": "ndk_retrieval"}, {"score": 0.004041686156098498, "phrase": "large-scale_data"}, {"score": 0.003960210592458847, "phrase": "effective_multi-level_ranking"}, {"score": 0.0037866774001097596, "phrase": "coarse-to-fine_manner"}, {"score": 0.003680212979775528, "phrase": "mlr_ranking_scheme"}, {"score": 0.0035913348026306306, "phrase": "effective_ranking_function"}, {"score": 0.003562186600028245, "phrase": "extremely_small_training_examples"}, {"score": 0.0035189057079817285, "phrase": "near-duplicate_detection_task"}, {"score": 0.003378385493203297, "phrase": "semi-supervised_learning_method"}, {"score": 0.00335095982979018, "phrase": "semi-supervised_support_vector_machines"}, {"score": 0.0032302647179383915, "phrase": "retrieval_performance"}, {"score": 0.0031910037920846817, "phrase": "unlabeled_data"}, {"score": 0.0031522185379771056, "phrase": "key_stage"}, {"score": 0.0031139032290048788, "phrase": "mlr_scheme"}, {"score": 0.0029773436815290215, "phrase": "keyframe_candidates"}, {"score": 0.0029291801502381513, "phrase": "previous_coarse_ranking_stage"}, {"score": 0.002870066750788841, "phrase": "previous_approaches"}, {"score": 0.0028236336891860592, "phrase": "simple_heuristics"}, {"score": 0.0028006988338192375, "phrase": "rigid_matching_models"}, {"score": 0.0027330029055210926, "phrase": "nonrigid_image_matching"}, {"score": 0.0027108312432163957, "phrase": "nim"}, {"score": 0.002634506575564286, "phrase": "real-world_video_corpora"}, {"score": 0.002570817338292482, "phrase": "effective_fine_matching"}, {"score": 0.0025189177411152645, "phrase": "conventional_methods"}, {"score": 0.0024882810071079797, "phrase": "proposed_nim_approach"}, {"score": 0.0024580159789774516, "phrase": "explicit_mapping"}, {"score": 0.002359759876402679, "phrase": "correct_correspondences"}, {"score": 0.0023405839743112482, "phrase": "noisy_data"}, {"score": 0.0022287497627555895, "phrase": "extensive_experiments"}, {"score": 0.0021309254505358253, "phrase": "promising_results"}], "paper_keywords": ["Algorithms", " Performance", " Experimentations", " Near-duplicate keyframe", " image copy detection", " nonrigid image matching", " semi-supervised learning"], "paper_abstract": "ear-duplicate keyframe (NDK) retrieval techniques are critical to many real-world multimedia applications. Over the last few years, we have witnessed a surge of attention on studying near-duplicate image/keyframe retrieval in the multimedia community. To facilitate an effective approach to NDK retrieval on large-scale data, we suggest an effective Multi-Level Ranking (MLR) scheme that effectively retrieves NDKs in a coarse-to-fine manner. One key stage of the MLR ranking scheme is how to learn an effective ranking function with extremely small training examples in a near-duplicate detection task. To attack this challenge, we employ a semi-supervised learning method, semi-supervised support vector machines, which is able to significantly improve the retrieval performance by exploiting unlabeled data. Another key stage of the MLR scheme is to perform a fine matching among a subset of keyframe candidates retrieved from the previous coarse ranking stage. In contrast to previous approaches based on either simple heuristics or rigid matching models, we propose a novel Nonrigid Image Matching (NIM) approach to tackle near-duplicate keyframe retrieval from real-world video corpora in order to conduct an effective fine matching. Compared with the conventional methods, the proposed NIM approach can recover explicit mapping between two near-duplicate images with a few deformation parameters and find out the correct correspondences from noisy data simultaneously. To evaluate the effectiveness of our proposed approach, we performed extensive experiments on two benchmark testbeds extracted from the TRECVID2003 and TRECVID2004 corpora. The promising results indicate that our proposed method is more effective than other state-of-the-art approaches for near-duplicate keyframe retrieval.", "paper_title": "Near-Duplicate Keyframe Retrieval by Semi-Supervised Learning and Nonrigid Image Matching", "paper_id": "WOS:000286653800004"}