{"auto_keywords": [{"score": 0.04954756810706401, "phrase": "ordinal_regression"}, {"score": 0.00481495049065317, "phrase": "orthogonal_projection_vectors"}, {"score": 0.004553510708976456, "phrase": "ordinal_scale"}, {"score": 0.00445293569103488, "phrase": "wide_applications"}, {"score": 0.004330321475256457, "phrase": "human_evaluation"}, {"score": 0.004258372598568333, "phrase": "major_role"}, {"score": 0.004027031316965272, "phrase": "ordinal_regression_problems"}, {"score": 0.003641713874009232, "phrase": "projected_samples"}, {"score": 0.003501991125315889, "phrase": "common_shortcoming"}, {"score": 0.0033301694494391643, "phrase": "sample_space"}, {"score": 0.003166751241099304, "phrase": "useful_information"}, {"score": 0.002977835845437357, "phrase": "novel_ordinal_regression_strategy"}, {"score": 0.0028635111041882956, "phrase": "orthogonal_feature_vectors"}, {"score": 0.0027690086059100495, "phrase": "projector_vectors"}, {"score": 0.002677616534005393, "phrase": "ordinal_regression_rule"}, {"score": 0.002618366076489732, "phrase": "previous_ordinal_regression_methods"}, {"score": 0.002574788013427524, "phrase": "proposed_strategy"}, {"score": 0.002531933388815139, "phrase": "multiple_features"}, {"score": 0.0024897902536499005, "phrase": "original_data_space"}, {"score": 0.0022386642196006567, "phrase": "experimental_results"}, {"score": 0.002176887956041267, "phrase": "real_datasets"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Ordinal regression", " Linear discriminant analysis", " Kernel discriminant analysis", " Multiple feature combination"], "paper_abstract": "Ordinal regression is to predict categories of ordinal scale and it has wide applications in many domains where the human evaluation plays a major role. So far several algorithms have been proposed to tackle ordinal regression problems from a machine learning perspective. However, most of these algorithms only seek one direction where the projected samples are well ranked. So a common shortcoming of these algorithms is that only one dimension in the sample space is used, which would definitely lose some useful information in its orthogonal subspaces. In this paper, we propose a novel ordinal regression strategy which consists of two stages: firstly orthogonal feature vectors are extracted and then these projector vectors are combined to learn an ordinal regression rule. Compared with previous ordinal regression methods, the proposed strategy can extract multiple features from the original data space. So the performance of ordinal regression could be improved because more information of the data is used. The experimental results on both benchmark and real datasets proves the performance of the proposed method.", "paper_title": "Constructing and Combining Orthogonal Projection Vectors for Ordinal Regression", "paper_id": "WOS:000347684700009"}