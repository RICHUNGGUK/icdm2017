{"auto_keywords": [{"score": 0.04967298152704187, "phrase": "cloud_data_centers"}, {"score": 0.011453710083284878, "phrase": "different_types"}, {"score": 0.009710363783463842, "phrase": "resource_allocation"}, {"score": 0.00481495049065317, "phrase": "heterogeneous_workloads"}, {"score": 0.0046141941030386525, "phrase": "different_scenarios"}, {"score": 0.004459605573798577, "phrase": "heterogeneous_applications"}, {"score": 0.004421770937919324, "phrase": "diverse_workloads"}, {"score": 0.0043842558719324526, "phrase": "diverse_quality"}, {"score": 0.004148014765950199, "phrase": "physical_servers"}, {"score": 0.003958049372486465, "phrase": "energy_consumption"}, {"score": 0.0037607172875103946, "phrase": "vm"}, {"score": 0.0036191240628152205, "phrase": "co-hosted_workloads"}, {"score": 0.003394891095032025, "phrase": "diverse_qos_requirements"}, {"score": 0.0033232673019931206, "phrase": "dynamic_behavior"}, {"score": 0.0032531496610470377, "phrase": "efficient_provisioning"}, {"score": 0.002924074850256874, "phrase": "data_center"}, {"score": 0.0028623555849897632, "phrase": "application_workloads"}, {"score": 0.002639440558428147, "phrase": "interference-and_power-aware_management_mechanism"}, {"score": 0.002539978170928796, "phrase": "scheduling_algorithm"}, {"score": 0.002475755804232436, "phrase": "virtualized_environments"}, {"score": 0.0024028742248152425, "phrase": "synthetic_workloads"}, {"score": 0.002362192695471035, "phrase": "last_version"}, {"score": 0.002332133125576037, "phrase": "google_cloud_tracelogs"}, {"score": 0.0022251433045184454, "phrase": "contracted_slas"}, {"score": 0.0022062235065459274, "phrase": "real-world_environments"}, {"score": 0.002178144355363467, "phrase": "energy_costs"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Performance interference", " Energy efficiency", " CPU-intensive load", " I/O intensive load", " SLA", " QoS"], "paper_abstract": "Cloud data centers have been progressively adopted in different scenarios, as reflected in the execution of heterogeneous applications with diverse workloads and diverse quality of service (QoS) requirements. Virtual machine (VM) technology eases resource management in physical servers and helps cloud providers achieve goals such as optimization of energy consumption. However, the performance of an application running inside a VM is not guaranteed due to the interference among co-hosted workloads sharing the same physical resources. Moreover, the different types of co-hosted applications with diverse QoS requirements as well as the dynamic behavior of the cloud makes efficient provisioning of resources even more difficult and a challenging problem in cloud data centers. In this paper, we address the problem of resource allocation within a data center that runs different types of application workloads, particularly CPU-and network-intensive applications. To address these challenges, we propose an interference-and power-aware management mechanism that combines a performance deviation estimator and a scheduling algorithm to guide the resource allocation in virtualized environments. We conduct simulations by injecting synthetic workloads whose characteristics follow the last version of the Google Cloud tracelogs. The results indicate that our performance-enforcing strategy is able to fulfill contracted SLAs of real-world environments while reducing energy costs by as much as 21%. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "PIASA: A power and interference aware resource management strategy for heterogeneous workloads in cloud data centers", "paper_id": "WOS:000359315800010"}