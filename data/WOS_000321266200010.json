{"auto_keywords": [{"score": 0.004742730438544081, "phrase": "improving_accuracy"}, {"score": 0.004695183699894267, "phrase": "agent-based_expert_systems"}, {"score": 0.0043753813457279404, "phrase": "self-affirmation_theory"}, {"score": 0.004309725894724034, "phrase": "human_expert_users"}, {"score": 0.004016072233242585, "phrase": "system's_conflicting_recommendations"}, {"score": 0.003780286517897356, "phrase": "unrelated_area"}, {"score": 0.0036491673002304326, "phrase": "conflicting_information"}, {"score": 0.003576286811853861, "phrase": "affirmation_manipulation"}, {"score": 0.0035048567587934254, "phrase": "credibility_assessment_task"}, {"score": 0.003332440548684892, "phrase": "counterattitudinal_expert_system_recommendations"}, {"score": 0.0030895394261534776, "phrase": "border_security_agency"}, {"score": 0.002952356518921907, "phrase": "deception_detection_expert_system"}, {"score": 0.0028933521924166287, "phrase": "deception_judgment"}, {"score": 0.002486734224234698, "phrase": "human_experts"}, {"score": 0.002437012847684331, "phrase": "advanced_expert_systems"}, {"score": 0.0023170054862555896, "phrase": "artificial_intelligence"}, {"score": 0.0021697677572213086, "phrase": "self-evaluative_concerns"}, {"score": 0.0021049977753042253, "phrase": "technology_acceptance"}], "paper_keywords": ["credibility assessment systems", " deception detection", " expert systems", " user anxiety"], "paper_abstract": "Despite the improving accuracy of agent-based expert systems, human expert users aided by these systems have not improved their accuracy. Self-affirmation theory suggests that human expert users could be experiencing threat, causing them to act defensively and ignore the system's conflicting recommendations. Previous research has demonstrated that affirming an individual in an unrelated area reduces defensiveness and increases objectivity to conflicting information. Using an affirmation manipulation prior to a credibility assessment task, this study investigated if experts are threatened by counterattitudinal expert system recommendations. For our study, 178 credibility assessment experts from the American Polygraph Association (n = 134) and the European Union's border security agency Frontex (n = 44) interacted with a deception detection expert system to make a deception judgment that was immediately contradicted. Reducing the threat prior to making their judgments did not improve accuracy, but did improve objectivity toward the system. This study demonstrates that human experts are threatened by advanced expert systems that contradict their expertise. As more and more systems increase integration of artificial intelligence and inadvertently assail the expertise and abilities of users, threat and self-evaluative concerns will become an impediment to technology acceptance.", "paper_title": "Are Users Threatened by Credibility Assessment Systems?", "paper_id": "WOS:000321266200010"}