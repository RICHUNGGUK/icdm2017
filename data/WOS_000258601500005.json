{"auto_keywords": [{"score": 0.0047113960612140335, "phrase": "imbalanced_data_sets"}, {"score": 0.004660453113061494, "phrase": "convoluted_problem"}, {"score": 0.00456020621016909, "phrase": "cost_standpoints"}, {"score": 0.004397875849247165, "phrase": "great_interest"}, {"score": 0.004075469816959996, "phrase": "large-scale_simulations"}, {"score": 0.004002242925856335, "phrase": "correspondingly_high_cost"}, {"score": 0.00393032656248792, "phrase": "rare_events"}, {"score": 0.0036953036453370087, "phrase": "high_minority_class_accuracy"}, {"score": 0.0036288825833675127, "phrase": "sampling_methods"}, {"score": 0.0034491650585057754, "phrase": "proper_amount"}, {"score": 0.0032783186166708985, "phrase": "wrapper_paradigm"}, {"score": 0.003172969962401266, "phrase": "data_set"}, {"score": 0.003138609109371368, "phrase": "optimizing_evaluation_functions"}, {"score": 0.003048782877550259, "phrase": "roc_curve"}, {"score": 0.002704554429386671, "phrase": "different_evaluation_and_wrapper_optimization_functions"}, {"score": 0.0025892330566358503, "phrase": "cost-_sensitive_environment"}, {"score": 0.002542642270762272, "phrase": "unknown_or_changing_cost_matrices"}, {"score": 0.0024342079318127423, "phrase": "cost-sensitive_learning_methods"}, {"score": 0.0022884433286785165, "phrase": "cost-sensitive_classifiers"}, {"score": 0.002263639474937039, "phrase": "cost-sensitive_environment"}, {"score": 0.002206801982145622, "phrase": "lowest_cost"}, {"score": 0.002190825828942124, "phrase": "test_example"}], "paper_keywords": ["classification", " unbalanced data", " cost-sensitive learning"], "paper_abstract": "Learning from imbalanced data sets presents a convoluted problem both from the modeling and cost standpoints. In particular, when a class is of great interest but occurs relatively rarely such as in cases of fraud, instances of disease, and regions of interest in large-scale simulations, there is a correspondingly high cost for the misclassification of rare events. Under such circumstances, the data set is often re-sampled to generate models with high minority class accuracy. However, the sampling methods face a common, but important, criticism: how to automatically discover the proper amount and type of sampling? To address this problem, we propose a wrapper paradigm that discovers the amount of re-sampling for a data set based on optimizing evaluation functions like the f-measure, Area Under the ROC Curve (AUROC), cost, cost-curves, and the cost dependent f-measure. Our analysis of the wrapper is twofold. First, we report the interaction between different evaluation and wrapper optimization functions. Second, we present a set of results in a cost- sensitive environment, including scenarios of unknown or changing cost matrices. We also compared the performance of the wrapper approach versus cost-sensitive learning methods-MetaCost and the Cost-Sensitive Classifiers-and found the wrapper to outperform the cost-sensitive classifiers in a cost-sensitive environment. Lastly, we obtained the lowest cost per test example compared to any result we are aware of for the KDD-99 Cup intrusion detection data set.", "paper_title": "Automatically countering imbalance and its empirical relationship to cost", "paper_id": "WOS:000258601500005"}