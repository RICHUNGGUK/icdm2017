{"auto_keywords": [{"score": 0.04217589518665354, "phrase": "field_classification_scheme"}, {"score": 0.012529866132761542, "phrase": "recursive_citation"}, {"score": 0.00481495049065317, "phrase": "information_science"}, {"score": 0.004490842671590769, "phrase": "citation-based_research_performance_indicators"}, {"score": 0.003643185395780667, "phrase": "pagerank-inspired_indicators"}, {"score": 0.0033306180744375616, "phrase": "single_indicator"}, {"score": 0.003075296862372287, "phrase": "normalized_citation_score_indicator"}, {"score": 0.0026480044868438875, "phrase": "proposed_indicator"}, {"score": 0.0022573076362326135, "phrase": "strong_tendency"}, {"score": 0.0021049977753042253, "phrase": "classification_scheme"}], "paper_keywords": ["Bibliometric indicator", " Citation impact", " Field normalization", " Recursive indicator"], "paper_abstract": "Two commonly used ideas in the development of citation-based research performance indicators are the idea of normalizing citation counts based on a field classification scheme and the idea of recursive citation weighing (like in PageRank-inspired indicators). We combine these two ideas in a single indicator, referred to as the recursive mean normalized citation score indicator, and we study the validity of this indicator. Our empirical analysis shows that the proposed indicator is highly sensitive to the field classification scheme that is used. The indicator also has a strong tendency to reinforce biases caused by the classification scheme. Based on these observations, we advise against the use of indicators in which the idea of normalization based on a field classification scheme and the idea of recursive citation weighing are combined.", "paper_title": "A recursive field-normalized bibliometric performance indicator: an application to the field of library and information science", "paper_id": "WOS:000294839200017"}