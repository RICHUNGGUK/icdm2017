{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "symbolic_ai_approaches"}, {"score": 0.041390252700290016, "phrase": "dichotomic_entropy"}, {"score": 0.04076936422859309, "phrase": "compound_distributional_index"}, {"score": 0.03915697229912192, "phrase": "continuous_attributes"}, {"score": 0.03722739012087964, "phrase": "decision_value_distribution"}, {"score": 0.028875195100310683, "phrase": "multiknowledge_approach"}, {"score": 0.028147595116575684, "phrase": "information_systems"}, {"score": 0.0046176782475198085, "phrase": "continuous_valued_attributes"}, {"score": 0.004405348628112645, "phrase": "continuous_attribute_values"}, {"score": 0.004359500411441827, "phrase": "symbolic_data"}, {"score": 0.004202741104973709, "phrase": "novel_distribution-index-based_discretizer"}, {"score": 0.0038249462699142733, "phrase": "simple_criterion"}, {"score": 0.0035920758080335655, "phrase": "homogeneity_degree"}, {"score": 0.0033910448175165004, "phrase": "best_splitting_point"}, {"score": 0.0032689949867583633, "phrase": "attribute_value_distributions"}, {"score": 0.0029593432468318745, "phrase": "potentially_improved_solution"}, {"score": 0.0029131986574478046, "phrase": "discretization_problem"}, {"score": 0.0027936239349923464, "phrase": "multiple_reducts"}, {"score": 0.0027645030021576926, "phrase": "rough_set_theory"}, {"score": 0.002678944072162297, "phrase": "high_decision_accuracy"}, {"score": 0.0026096659285441384, "phrase": "large_number"}, {"score": 0.0023499703712897293, "phrase": "decision_accuracy"}, {"score": 0.0022772115643656153, "phrase": "experimental_results"}, {"score": 0.002253461585851626, "phrase": "benchmark_data_sets"}, {"score": 0.002206700502606511, "phrase": "new_discretizer"}, {"score": 0.002105115320062621, "phrase": "bayes"}], "paper_keywords": ["data mining", " machine learning", " information theory", " decision support"], "paper_abstract": "When symbolic AI approaches are applied to handle continuous valued attributes, there is a requirement to transform the continuous attribute values to symbolic data. In this paper, a novel distribution-index-based discretizer is proposed for such a transformation. Based on definitions of dichotomic entropy and a compound distributional index, a simple criterion is applied to discretize continuous attributes adaptively. The dichotomic entropy indicates the homogeneity degree of the decision value distribution, and is applied to determine the best splitting point. The compound distributional index combines both the homogeneity degrees of attribute value distributions and the decision value distribution, and is applied to determine which interval should be split further; thus, a potentially improved solution of the discretization problem can be found efficiently. Based on multiple reducts in rough set theory, a multiknowledge approach can attain high decision accuracy for information systems with a large number of attributes and missing values. In this paper, our discretizer is combined with the multiknowledge approach to further improve decision accuracy for information systems with continuous attributes. Experimental results on benchmark data sets show that the new discretizer can improve not only the multiknowledge approach, but also the naive Bayes classifier and the C5.0 tree.", "paper_title": "A distribution-index-based discretizer for decision-making with symbolic AI approaches", "paper_id": "WOS:000242041400002"}