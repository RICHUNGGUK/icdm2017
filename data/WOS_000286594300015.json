{"auto_keywords": [{"score": 0.04505400945695757, "phrase": "differential_privacy"}, {"score": 0.00481495049065317, "phrase": "types_grow_stronger_a_calculus"}, {"score": 0.004611224230543916, "phrase": "sensitive_information"}, {"score": 0.004480196733208298, "phrase": "aggregate_data"}, {"score": 0.0042495320879288615, "phrase": "strong_statistical_guarantee"}, {"score": 0.0038230844545071303, "phrase": "auxiliary_knowledge"}, {"score": 0.0037322713756404295, "phrase": "prior_work"}, {"score": 0.003309452522760298, "phrase": "functional_language"}, {"score": 0.003138874040786261, "phrase": "complex_privacy-safe_query_programs"}, {"score": 0.0030938932434437178, "phrase": "flexible_and_compositional_way"}, {"score": 0.003049555059533735, "phrase": "key_novelty"}, {"score": 0.0029627701619228527, "phrase": "function_sensitivity"}, {"score": 0.0027697290872182477, "phrase": "similar_inputs"}, {"score": 0.0027431953780099826, "phrase": "well-typed_programs"}, {"score": 0.0025521085778978042, "phrase": "nearby_inputs"}, {"score": 0.002443890721386284, "phrase": "random_computations"}, {"score": 0.00236289633510808, "phrase": "established_definition"}, {"score": 0.0022626835039082746, "phrase": "special_case"}, {"score": 0.0022302306304023602, "phrase": "soundness_principle"}, {"score": 0.0021563019696857768, "phrase": "privacy-aware_variants"}, {"score": 0.0021356322417874106, "phrase": "standard_functional_programming_idioms"}, {"score": 0.0021049977753042253, "phrase": "compositionality_principles"}], "paper_keywords": ["Languages", " Differential Privacy", " Type Systems"], "paper_abstract": "We want assurances that sensitive information will not be disclosed when aggregate data derived from a database is published. Differential privacy offers a strong statistical guarantee that the effect of the presence of any individual in a database will be negligible, even when an adversary has auxiliary knowledge. Much of the prior work in this area consists of proving algorithms to be differentially private one at a time; we propose to streamline this process with a functional language whose type system automatically guarantees differential privacy, allowing the programmer to write complex privacy-safe query programs in a flexible and compositional way. The key novelty is the way our type system captures function sensitivity, a measure of how much a function can magnify the distance between similar inputs: well-typed programs not only can't go wrong, they can't go too far on nearby inputs. Moreover, by introducing a monad for random computations, we can show that the established definition of differential privacy falls out naturally as a special case of this soundness principle. We develop examples including known differentially private algorithms, privacy-aware variants of standard functional programming idioms, and compositionality principles for differential privacy.", "paper_title": "Distance Makes the Types Grow Stronger A Calculus for Differential Privacy", "paper_id": "WOS:000286594300015"}