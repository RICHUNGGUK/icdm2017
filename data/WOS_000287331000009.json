{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "bayesian_variable_selection"}, {"score": 0.04731051870228707, "phrase": "matching_pursuit_algorithm"}, {"score": 0.04497268099057208, "phrase": "bayesian_formulation"}, {"score": 0.03396430246149429, "phrase": "proposed_algorithm"}, {"score": 0.03226363023909562, "phrase": "componentwise_gibbs_sampler"}, {"score": 0.00462773520532301, "phrase": "stochastic_version"}, {"score": 0.004418456827500267, "phrase": "linear_regression"}, {"score": 0.004218602458288531, "phrase": "prior_distribution"}, {"score": 0.0041357305373417455, "phrase": "regression_coefficient"}, {"score": 0.0037699306119313154, "phrase": "zero_mean"}, {"score": 0.0036958398682001015, "phrase": "large_variance"}, {"score": 0.003623199939953831, "phrase": "proposed_stochastic_matching_pursuit_algorithm"}, {"score": 0.003459191419478298, "phrase": "posterior_distribution"}, {"score": 0.0032807941194429235, "phrase": "variable_selection"}, {"score": 0.002761954897932813, "phrase": "systematic_scan"}, {"score": 0.002689746491842271, "phrase": "stochastic_matching_pursuit_algorithm"}, {"score": 0.0025340874787959195, "phrase": "current_residual_vector"}, {"score": 0.0024842242921857705, "phrase": "higher_probabilities"}, {"score": 0.0022196020509093694, "phrase": "well_defined_prior_distributions"}, {"score": 0.0021330830123432614, "phrase": "small_n"}, {"score": 0.0021049977753042253, "phrase": "large_p"}], "paper_keywords": ["Gibbs sampler", " Metropolis algorithm", " Stochastic search variable selection"], "paper_abstract": "This article proposes a stochastic version of the matching pursuit algorithm for Bayesian variable selection in linear regression. In the Bayesian formulation, the prior distribution of each regression coefficient is assumed to be a mixture of a point mass at 0 and a normal distribution with zero mean and a large variance. The proposed stochastic matching pursuit algorithm is designed for sampling from the posterior distribution of the coefficients for the purpose of variable selection. The proposed algorithm can be considered a modification of the componentwise Gibbs sampler. In the componentwise Gibbs sampler, the variables are visited by a random or a systematic scan. In the stochastic matching pursuit algorithm, the variables that better align with the current residual vector are given higher probabilities of being visited. The proposed algorithm combines the efficiency of the matching pursuit algorithm and the Bayesian formulation with well defined prior distributions on coefficients. Several simulated examples of small n and large p are used to illustrate the algorithm. These examples show that the algorithm is efficient for screening and selecting variables.", "paper_title": "Stochastic matching pursuit for Bayesian variable selection", "paper_id": "WOS:000287331000009"}