{"auto_keywords": [{"score": 0.047862640203653294, "phrase": "planning_problems"}, {"score": 0.00481495049065317, "phrase": "markov_decision_process"}, {"score": 0.004764681809596152, "phrase": "mdp"}, {"score": 0.004665296491645837, "phrase": "general_model"}, {"score": 0.0043797373807446015, "phrase": "multiobjective_mdp"}, {"score": 0.004265953661191515, "phrase": "multiagent_problems"}, {"score": 0.003623352647973122, "phrase": "pareto-optimal_policies"}, {"score": 0.0034193226278107346, "phrase": "direct_determination"}, {"score": 0.0033480035183418642, "phrase": "well-balanced_tradeoffs"}, {"score": 0.0031929098985796814, "phrase": "reference_point_method"}, {"score": 0.0029972034683917164, "phrase": "wowa"}, {"score": 0.0029501745152877706, "phrase": "individual_disachievements"}, {"score": 0.002858313353461727, "phrase": "resulting_notion"}, {"score": 0.002828331235643921, "phrase": "optimal_policy"}, {"score": 0.0027547408718334603, "phrase": "bellman_principle"}, {"score": 0.0026830601040919166, "phrase": "initial_state"}, {"score": 0.0025452314655691165, "phrase": "solution_method"}, {"score": 0.002492098272172066, "phrase": "linear_programming"}, {"score": 0.0022783523466965187, "phrase": "proposed_method"}, {"score": 0.0021385822825864425, "phrase": "autonomous_agent"}, {"score": 0.0021049977753042253, "phrase": "inventory_management"}], "paper_keywords": ["Multiobjective optimization", " Markov decision processes", " compromise programming", " reference point method", " ordered weighted average", " linear programming"], "paper_abstract": "A Markov decision process (MDP) is a general model for solving planning problems under uncertainty. It has been extended to multiobjective MDP to address multicriteria or multiagent problems in which the value of a decision must be evaluated according to several viewpoints, sometimes conflicting. Although most of the studies concentrate on the determination of the set of Pareto-optimal policies, we focus here on a more specialized problem that concerns the direct determination of policies achieving well-balanced tradeoffs. To this end, we introduce a reference point method based on the optimization of a weighted ordered weighted average (WOWA) of individual disachievements. We show that the resulting notion of optimal policy does not satisfy the Bellman principle and depends on the initial state. To overcome these difficulties, we propose a solution method based on a linear programming (LP) reformulation of the problem. Finally, we illustrate the feasibility of the proposed method on two types of planning problems under uncertainty arising in navigation of an autonomous agent and in inventory management.", "paper_title": "A COMPROMISE PROGRAMMING APPROACH TO MULTIOBJECTIVE MARKOV DECISION PROCESSES", "paper_id": "WOS:000325419500008"}