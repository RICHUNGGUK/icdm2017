{"auto_keywords": [{"score": 0.031763843900136826, "phrase": "smt"}, {"score": 0.009641451417117903, "phrase": "non-time-series_data"}, {"score": 0.00481495049065317, "phrase": "single_variable_split"}, {"score": 0.004741395005218184, "phrase": "traditional_tree"}, {"score": 0.004481132747216135, "phrase": "small_number"}, {"score": 0.004435363840720883, "phrase": "labeled_instances"}, {"score": 0.0038810583785936505, "phrase": "important_information"}, {"score": 0.00368673793612343, "phrase": "simple_decision_tree"}, {"score": 0.003611751858608048, "phrase": "intrinsic_feature_selection"}, {"score": 0.0035565113234273926, "phrase": "regularized_logistic_regression"}, {"score": 0.0033957904376127187, "phrase": "natural_choice"}, {"score": 0.003343841875107018, "phrase": "multivariate_tree_model"}, {"score": 0.003176333519010176, "phrase": "natural_solution"}, {"score": 0.0031116963435584982, "phrase": "sparse_multivariate_tree"}, {"score": 0.002851301751761804, "phrase": "time-series_classification_problems"}, {"score": 0.0027646829399573434, "phrase": "interpretable_temporal_patterns"}, {"score": 0.002533253511622532, "phrase": "binary_classification_problems"}, {"score": 0.0024062532032402533, "phrase": "multiclass_problems"}, {"score": 0.0023816257768353344, "phrase": "multinomial_lr_models"}, {"score": 0.0023211517663846346, "phrase": "computational_efficiency"}, {"score": 0.0022390533383717715, "phrase": "large_number"}, {"score": 0.002193447487477984, "phrase": "time_series"}, {"score": 0.0021049977753042253, "phrase": "wiley_periodicals"}], "paper_keywords": ["time series classification", " decision tree", " Lasso", " fused Lasso", " feature extraction"], "paper_abstract": "A multivariate decision tree attempts to improve upon the single variable split in a traditional tree. With the increase in datasets with many features and a small number of labeled instances in a variety of domains (bioinformatics, text mining, etc.), a traditional tree-based approach with a greedy variable selection at a node may omit important information. Therefore, the recursive partitioning idea of a simple decision tree combined with the intrinsic feature selection of L-1 regularized logistic regression (LR) at each node is a natural choice for a multivariate tree model that is simple, but broadly applicable. This natural solution leads to the sparse multivariate tree (SMT) considered here. SMT can naturally handle non-time-series data and is extended to handle time-series classification problems with the power of extracting interpretable temporal patterns (e.g., means, slopes, and deviations). Binary L-1 regularized LR models are used here for binary classification problems. However, SMT may be extended to solve multiclass problems with multinomial LR models. The accuracy and computational efficiency of SMT is compared to a large number of competitors on time series and non-time-series data. (C) 2013 Wiley Periodicals, Inc.", "paper_title": "SMT: Sparse Multivariate Tree", "paper_id": "WOS:000364190400004"}