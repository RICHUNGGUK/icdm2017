{"auto_keywords": [{"score": 0.02938290939469859, "phrase": "user-specified_level"}, {"score": 0.015719716506582538, "phrase": "false_discovery_rate"}, {"score": 0.015418231335134047, "phrase": "pc_algorithm"}, {"score": 0.010786741944567886, "phrase": "fdr"}, {"score": 0.009338872823935617, "phrase": "proposed_method"}, {"score": 0.004666460260366703, "phrase": "real_world_applications"}, {"score": 0.004630055463858585, "phrase": "graphical_statistical_models"}, {"score": 0.004331811712726697, "phrase": "network_structures"}, {"score": 0.0041981583430961734, "phrase": "great_interest"}, {"score": 0.004100620365805411, "phrase": "brain_connectivity"}, {"score": 0.003821342577980031, "phrase": "reasonable_error-rate_criterion"}, {"score": 0.003717925116469845, "phrase": "current_learning_algorithms"}, {"score": 0.003688892770976908, "phrase": "graphical_models"}, {"score": 0.0035332114155090886, "phrase": "fdr."}, {"score": 0.0035056109035307716, "phrase": "traditional_practice"}, {"score": 0.0034510635632071978, "phrase": "type_i_error_rate"}, {"score": 0.0034107088717109857, "phrase": "type_ii_error_rate"}, {"score": 0.0033708244679086265, "phrase": "conventional_level"}, {"score": 0.0031907572162427978, "phrase": "sparse_networks"}, {"score": 0.0030680392468327147, "phrase": "fdr-control_procedure"}, {"score": 0.002915514089373717, "phrase": "learned_graph"}, {"score": 0.0027167292419065514, "phrase": "large_sample_sizes"}, {"score": 0.0026535183547537655, "phrase": "moderate_sample_size"}, {"score": 0.0025917743904900576, "phrase": "empirical_experiments"}, {"score": 0.0024150092189446424, "phrase": "heuristic_modification"}, {"score": 0.0021892798077661956, "phrase": "statistical_tests"}, {"score": 0.0021721582450016, "phrase": "conditional_independence"}, {"score": 0.0021215910859085146, "phrase": "discrete_models"}, {"score": 0.0021049977753042253, "phrase": "gaussian_models"}], "paper_keywords": ["Bayesian networks", " false discovery rate", " PC algorithm", " directed acyclic graph", " skeleton"], "paper_abstract": "In real world applications, graphical statistical models are not only a tool for operations such as classification or prediction, but usually the network structures of the models themselves are also of great interest (e.g., in modeling brain connectivity). The false discovery rate (FDR), the expected ratio of falsely claimed connections to all those claimed, is often a reasonable error-rate criterion in these applications. However, current learning algorithms for graphical models have not been adequately adapted to the concerns of the FDR. The traditional practice of controlling the type I error rate and the type II error rate under a conventional level does not necessarily keep the FDR low, especially in the case of sparse networks. In this paper, we propose embedding an FDR-control procedure into the PC algorithm to curb the FDR of the skeleton of the learned graph. We prove that the proposed method can control the FDR under a user-specified level at the limit of large sample sizes. In the cases of moderate sample size (about several hundred), empirical experiments show that the method is still able to control the FDR under the user-specified level, and a heuristic modification of the method is able to control the FDR more accurately around the user-specified level. The proposed method is applicable to any models for which statistical tests of conditional independence are available, such as discrete models and Gaussian models.", "paper_title": "Controlling the False Discovery Rate of the Association/Causality Structure Learned with the PC Algorithm", "paper_id": "WOS:000270824200013"}