{"auto_keywords": [{"score": 0.04926219622874721, "phrase": "matrix_factorization"}, {"score": 0.00481495049065317, "phrase": "collaborative_video_reindexing"}, {"score": 0.004652016085325825, "phrase": "concept-based_video_indexing"}, {"score": 0.004159446063902181, "phrase": "video_shots"}, {"score": 0.003916098498242888, "phrase": "collaborative_filtering"}, {"score": 0.003751011827704279, "phrase": "unsupervised_methods"}, {"score": 0.003623949225126944, "phrase": "initial_scores"}, {"score": 0.003531474887552889, "phrase": "concept_classifiers"}, {"score": 0.0032398798149196432, "phrase": "concept_correlation"}, {"score": 0.0031845067058084583, "phrase": "shot-to-shot_similarity"}, {"score": 0.0029467742734417255, "phrase": "noisy_matrix"}, {"score": 0.002822434555587263, "phrase": "inaccurate_scores"}, {"score": 0.002566997205079849, "phrase": "multiple_local_models"}, {"score": 0.0025014259919355453, "phrase": "contextual-temporal_structures"}, {"score": 0.0023958341044090503, "phrase": "trecvid"}, {"score": 0.0023145690608400425, "phrase": "relative_performance_gains"}, {"score": 0.0021416404045850224, "phrase": "user_annotations"}, {"score": 0.0021049977753042253, "phrase": "external_knowledge_resources"}], "paper_keywords": ["Algorithms", " Experimentation", " Multimedia content analysis", " semantic video indexing", " concept detection", " unsupervised learning", " TRECVID"], "paper_abstract": "Concept-based video indexing generates a matrix of scores predicting the possibilities of concepts occurring in video shots. Based on the idea of collaborative filtering, this article presents unsupervised methods to refine the initial scores generated by concept classifiers by taking into account the concept-to-concept correlation and shot-to-shot similarity embedded within the score matrix. Given a noisy matrix, we refine the inaccurate scores via matrix factorization. This method is further improved by learning multiple local models and incorporating contextual-temporal structures. Experiments on the TRECVID 2006-2008 datasets demonstrate relative performance gains ranging from 13% to 52% without using any user annotations or external knowledge resources.", "paper_title": "Collaborative Video Reindexing via Matrix Factorization", "paper_id": "WOS:000304248900007"}