{"auto_keywords": [{"score": 0.04244756435515675, "phrase": "source_domain"}, {"score": 0.04116861455251995, "phrase": "target_domain"}, {"score": 0.02602318921131217, "phrase": "proposed_kernel_matching_method"}, {"score": 0.00481495049065317, "phrase": "feature_space_independent_semi-supervised_domain_adaptation"}, {"score": 0.004771435352180973, "phrase": "kernel_matching"}, {"score": 0.0047283116134926645, "phrase": "domain_adaptation_methods"}, {"score": 0.0046221918332842995, "phrase": "good_prediction_model"}, {"score": 0.004559661374976129, "phrase": "label-scarce_target_domain"}, {"score": 0.004417012437860011, "phrase": "related_source_domain"}, {"score": 0.004317848984770719, "phrase": "large_amount"}, {"score": 0.004278807087784626, "phrase": "labeled_data"}, {"score": 0.0036998728605395384, "phrase": "feature_representation"}, {"score": 0.0034092396400930446, "phrase": "substantial_feature_distribution_divergence"}, {"score": 0.00334780964309978, "phrase": "heterogeneous_feature_representations"}, {"score": 0.0033175095965171674, "phrase": "different_domains"}, {"score": 0.003141364320497748, "phrase": "kernel_matching_method"}, {"score": 0.0031129269142224194, "phrase": "domain_adaptation"}, {"score": 0.0030017207229983385, "phrase": "prediction_function"}, {"score": 0.0029610472910087176, "phrase": "labeled_source_data"}, {"score": 0.0029076695661972114, "phrase": "target_data_points"}, {"score": 0.0028813415821988156, "phrase": "similar_source_data_points"}, {"score": 0.0028293966058473476, "phrase": "target_kernel_matrix"}, {"score": 0.002753224894944965, "phrase": "source_kernel_matrix"}, {"score": 0.0027035833504191233, "phrase": "hilbert_schmidt_independence_criterion"}, {"score": 0.0026427848602443267, "phrase": "simultaneous_learning"}, {"score": 0.0025716240685409513, "phrase": "non-convex_integer_optimization_problem"}, {"score": 0.002525248554951453, "phrase": "local_minimization_procedure"}, {"score": 0.0024020005505684928, "phrase": "amazon"}, {"score": 0.0023586493263143553, "phrase": "cross_language_text_classification_tasks"}, {"score": 0.0023372808856170386, "phrase": "reuters_multilingual_newswire_stories"}, {"score": 0.0022231606165229235, "phrase": "comparison_methods"}, {"score": 0.002193013499219711, "phrase": "cross_domain_classification_problems"}, {"score": 0.0021731423856364003, "phrase": "homogeneous_feature_spaces"}, {"score": 0.0021049977753042253, "phrase": "heterogeneous_feature_spaces"}], "paper_keywords": ["Domain adaptation", " kernel matching", " heterogeneous feature spaces"], "paper_abstract": "Domain adaptation methods aim to learn a good prediction model in a label-scarce target domain by leveraging labeled patterns from a related source domain where there is a large amount of labeled data. However, in many practical domain adaptation learning scenarios, the feature distribution in the source domain is different from that in the target domain. In the extreme, the two distributions could differ completely when the feature representation of the source domain is totally different from that of the target domain. To address the problems of substantial feature distribution divergence across domains and heterogeneous feature representations of different domains, we propose a novel feature space independent semi-supervised kernel matching method for domain adaptation in this work. Our approach learns a prediction function on the labeled source data while mapping the target data points to similar source data points by matching the target kernel matrix to a submatrix of the source kernel matrix based on a Hilbert Schmidt Independence Criterion. We formulate this simultaneous learning and mapping process as a non-convex integer optimization problem and present a local minimization procedure for its relaxed continuous form. We evaluate the proposed kernel matching method using both cross domain sentiment classification tasks of Amazon product reviews and cross language text classification tasks of Reuters multilingual newswire stories. Our empirical results demonstrate that the proposed kernel matching method consistently and significantly outperforms comparison methods on both cross domain classification problems with homogeneous feature spaces and cross domain classification problems with heterogeneous feature spaces.", "paper_title": "Feature Space Independent Semi-Supervised Domain Adaptation via Kernel Matching", "paper_id": "WOS:000346970600006"}