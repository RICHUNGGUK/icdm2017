{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "large_database_tables"}, {"score": 0.004647911247507267, "phrase": "randomized_ordering"}, {"score": 0.004582722012454012, "phrase": "input_data"}, {"score": 0.004392565073466714, "phrase": "online_aggregation"}, {"score": 0.004330941610682453, "phrase": "data_mining"}, {"score": 0.0038953958723049287, "phrase": "large_database"}, {"score": 0.003813669883040509, "phrase": "randomized_order"}, {"score": 0.0037073529462522403, "phrase": "difficult_problem"}, {"score": 0.003334309053314909, "phrase": "existing_methods"}, {"score": 0.0031286936417685178, "phrase": "front_end"}, {"score": 0.0028944757265206332, "phrase": "back_end"}, {"score": 0.002658863179011018, "phrase": "simple_file_structure"}, {"score": 0.0024251568696803177, "phrase": "efficient_online_sampling"}, {"score": 0.0022276618873985445, "phrase": "key_innovation"}, {"score": 0.0021049977753042253, "phrase": "small_degree"}], "paper_keywords": ["sampling methods", " database systems"], "paper_abstract": "Many applications require a randomized ordering of input data. Examples include algorithms for online aggregation, data mining, and various randomized algorithms. Most existing work seems to assume that accessing the records from a large database in a randomized order is not a difficult problem. However, it turns out to be extremely difficult in practice. Using existing methods, randomization is either extremely expensive at the front end ( as data are loaded), or at the back end ( as data are queried). This paper presents a simple file structure which supports both efficient, online random shuffling of a large database, as well as efficient online sampling or randomization of the database when it is queried. The key innovation of our method is the introduction of a small degree of carefully controlled, rigorously monitored nonrandomness into the file.", "paper_title": "Online random shuffling of large database tables", "paper_id": "WOS:000242041400006"}