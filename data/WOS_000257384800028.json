{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "novel_feature-aware_rendering_system"}, {"score": 0.004133055661437163, "phrase": "visual_communication_tasks"}, {"score": 0.003951453722517865, "phrase": "bilateral_grid"}, {"score": 0.003777800904236079, "phrase": "low_contrast"}, {"score": 0.0035473867669654174, "phrase": "separable_approximation"}, {"score": 0.0034529760173586583, "phrase": "bilateral_filter"}, {"score": 0.0033011569787033297, "phrase": "feature_flow-guided_anisotropic_edge_detection_filter"}, {"score": 0.0026362590493392785, "phrase": "isotropic_difference"}, {"score": 0.0025660347613972573, "phrase": "-gaussian_filter"}, {"score": 0.00249767641333441, "phrase": "presented_algorithms"}, {"score": 0.0023451553255837317, "phrase": "real-time_performance"}], "paper_keywords": ["non-photorealistic rendering", " visual communication", " real-time video processing", " image processing"], "paper_abstract": "This paper presents a novel feature-aware rendering system that automatically abstracts videos and images with the goal of improving the effectiveness of imagery for visual communication tasks. We integrate the bilateral grid to simplify regions of low contrast, which is faster than the separable approximation to the bilateral filter, and use a feature flow-guided anisotropic edge detection filter to enhance regions of high contrast. The edges detected in this paper are smoother, more coherent and stylistic than those of the isotropic difference-of-Gaussian filter. The presented algorithms are highly parallel, allowing a real-time performance on modern GPUs. The implementation of our approach is straightforward. Several experimental examples are given at the end of the paper to demonstrate the effectiveness of our approach.", "paper_title": "Real-time feature-aware video abstraction", "paper_id": "WOS:000257384800028"}