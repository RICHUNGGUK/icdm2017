{"auto_keywords": [{"score": 0.026975799694162368, "phrase": "proposed_model"}, {"score": 0.00481495049065317, "phrase": "binary_data"}, {"score": 0.004425215632459868, "phrase": "naive_bayes_models"}, {"score": 0.004308791766002289, "phrase": "bayesian_network_models"}, {"score": 0.003754140294151593, "phrase": "independence_assumption"}, {"score": 0.0036715973701254823, "phrase": "previous_work"}, {"score": 0.003374094774912924, "phrase": "continuous_domains"}, {"score": 0.003314591878914152, "phrase": "naive_bayes_model"}, {"score": 0.0032706520949775065, "phrase": "latent_variables"}, {"score": 0.0032272929113113203, "phrase": "class-conditional_dependencies"}, {"score": 0.0031006232333900055, "phrase": "good_classification_accuracy"}, {"score": 0.0030595248673398498, "phrase": "lcm"}, {"score": 0.0029789104204803137, "phrase": "relatively_small_parameter_space"}, {"score": 0.0027989800906333784, "phrase": "first_step"}, {"score": 0.0027373807320805084, "phrase": "hybrid_domains"}, {"score": 0.002629889135655667, "phrase": "binary_attributes"}, {"score": 0.002470987929071079, "phrase": "variational_approximation-based_inference_procedure"}, {"score": 0.002250415129116109, "phrase": "different_domains"}, {"score": 0.0021620042653528846, "phrase": "black_and_white_images"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Classification", " Binary images", " Bayesian networks", " Variational inference"], "paper_abstract": "One of the simplest, and yet most consistently well-performing set of classifiers is the naive Bayes models (a special class of Bayesian network models). However, these models rely on the (naive) assumption that all the attributes used to describe an instance are conditionally independent given the class of that instance. To relax this independence assumption, we have in previous work proposed a family of models, called latent classification models (LCMs). LCMs are defined for continuous domains and generalize the naive Bayes model by using latent variables to model class-conditional dependencies between the attributes. In addition to providing good classification accuracy, the LCM has several appealing properties, including a relatively small parameter space making it less susceptible to over-fitting. In this paper we take a first step towards generalizing LCMs to hybrid domains, by proposing an LCM for domains with binary attributes. We present algorithms for learning the proposed model, and we describe a variational approximation-based inference procedure. Finally, we empirically compare the accuracy of the proposed model to the accuracy of other classifiers for a number of different domains, including the problem of recognizing symbols in black and white images. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Latent classification models for binary data", "paper_id": "WOS:000268453800034"}