{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "large-scale_dynamic_scientific_applications"}, {"score": 0.004688321299229397, "phrase": "general-purpose_communication_package"}, {"score": 0.00446471538346719, "phrase": "inter-processor_communications"}, {"score": 0.004386063799793622, "phrase": "supercomputer_architecture"}, {"score": 0.004195418010131832, "phrase": "parallel_applications"}, {"score": 0.004066898031169739, "phrase": "large_number"}, {"score": 0.0038385317554884713, "phrase": "processor_neighborhoods"}, {"score": 0.0036715973701254823, "phrase": "static_mesh_partitions"}, {"score": 0.003374094774912924, "phrase": "mesh_adaptation"}, {"score": 0.0031703706626348507, "phrase": "dynamic_movement"}, {"score": 0.0031422859551159506, "phrase": "partition_objects"}, {"score": 0.0031006232333900055, "phrase": "current_package"}, {"score": 0.003032405563826263, "phrase": "dynamic_applications"}, {"score": 0.0028492532869274743, "phrase": "neighborhood_communication_pattern"}, {"score": 0.002811464848641341, "phrase": "many-to-many_calls"}, {"score": 0.0027131212233443137, "phrase": "collective_calls"}, {"score": 0.00258347644721642, "phrase": "non-blocking_mpi_functions"}, {"score": 0.0025042115651986332, "phrase": "message_flow_control"}, {"score": 0.00241658945942583, "phrase": "communication_calls"}, {"score": 0.0023845255359681143, "phrase": "test_application"}, {"score": 0.002352886041381761, "phrase": "parallel_unstructured_mesh_adaptation"}, {"score": 0.0022304616068189575, "phrase": "neighborhood-based_communication_control"}, {"score": 0.0021620042653528846, "phrase": "generally_imbalanced_mesh_adaptation_runs"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Asynchronous communication", " MPI", " Dynamic data migration", " Parallel algorithms", " Overlapping communication and computation"], "paper_abstract": "This paper introduces a general-purpose communication package built on top of MPI which is aimed at improving inter-processor communications independently of the supercomputer architecture being considered. The package is developed to support parallel applications that rely on computation characterized by large number of messages of various sizes, often small, that are focused within processor neighborhoods. In some cases, such as solvers having static mesh partitions, the number and size of messages are known a priori. However, in other cases such as mesh adaptation, the messages evolve and vary in number and size and include the dynamic movement of partition objects. The current package provides a utility for dynamic applications based on two key attributes that are: (i) explicit consideration of the neighborhood communication pattern to avoid many-to-many calls and also to reduce the number of collective calls to a minimum, and (ii) use of non-blocking MPI functions along with message packing to manage message flow control and reduce the number and time of communication calls. The test application demonstrated is parallel unstructured mesh adaptation. Results on IBM Blue Gene/P and Cray XE6 computers show that the use of neighborhood-based communication control leads to scalable results when executing generally imbalanced mesh adaptation runs. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Neighborhood communication paradigm to increase scalability in large-scale dynamic scientific applications", "paper_id": "WOS:000300742800004"}