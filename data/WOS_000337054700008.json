{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "redundant-data_clustering"}, {"score": 0.004772367030970874, "phrase": "interactive_walkthrough_applications"}, {"score": 0.004709193603747991, "phrase": "modern_walkthrough_applications"}, {"score": 0.004646852519870358, "phrase": "massive_datasets"}, {"score": 0.004425215632459868, "phrase": "gigantic_disk-based_storage_devices"}, {"score": 0.004270665568018583, "phrase": "blu-ray_discs"}, {"score": 0.004013025478863664, "phrase": "interactive_environments"}, {"score": 0.0039248128268720645, "phrase": "data_transfer_speed"}, {"score": 0.003404244237372396, "phrase": "secondary_storage"}, {"score": 0.003374094774912924, "phrase": "main_memory"}, {"score": 0.0033442114331500407, "phrase": "existing_algorithms"}, {"score": 0.0032852337992126564, "phrase": "suitable_data_layout_algorithms"}, {"score": 0.0030868583963299698, "phrase": "commonly_used_techniques"}, {"score": 0.0030459283281463953, "phrase": "total_time"}, {"score": 0.002861961643289598, "phrase": "total_data"}, {"score": 0.0027252240573281163, "phrase": "orthogonal_approach"}, {"score": 0.0027010719929751, "phrase": "aggregate_data"}, {"score": 0.002629889135655667, "phrase": "multiple_places"}, {"score": 0.0025950024597986366, "phrase": "storage_device"}, {"score": 0.0025605773834404253, "phrase": "consistent_data"}, {"score": 0.0024600113832396187, "phrase": "linear_integer_programming_problem"}, {"score": 0.002352886041381761, "phrase": "fetch_time_budget_constraint"}, {"score": 0.0021910825909008946, "phrase": "data_clustering"}, {"score": 0.0021049977753042253, "phrase": "optimal_solution"}], "paper_keywords": ["Out-of-core rendering", " Data layout", " Secondary storage devices", " Redundant data", " Linear programming", " Walkthrough rendering", " Seek time", " Transfer time"], "paper_abstract": "In modern walkthrough applications, storing massive datasets has become easy and inexpensive due to the availability of gigantic disk-based storage devices including hard drives, DVDs, and Blu-ray discs. However, fetching data from these devices for processing and rendering in interactive environments remains a bottleneck as data transfer speed has not kept pace with the sizes of both the secondary storage and main memory.Out-of-core algorithms are commonly used as a solution to transfer data efficiently from the secondary storage to main memory. Existing algorithms strongly rely on suitable data layout algorithms to reduce the data fetch time. However, in spite of all commonly used techniques, the total time required to seek and transfer data can still easily exceed the budget for total data fetch time. In this work, we propose an orthogonal approach to aggregate data and store them redundantly in multiple places in the storage device to ensure consistent data fetching performance. We pose this as a linear integer programming problem to minimize the amount of redundancy subject to the fetch time budget constraint. We provide an implementation on datasets with hundreds of millions of triangles to demonstrate how this data clustering can be created in practice and how the optimal solution is found.", "paper_title": "Optimizing redundant-data clustering for interactive walkthrough applications", "paper_id": "WOS:000337054700008"}