{"auto_keywords": [{"score": 0.023697948507795153, "phrase": "rl"}, {"score": 0.00481495049065317, "phrase": "adaptive_experience_engine_for_serious_games"}, {"score": 0.004786002454145624, "phrase": "designing_games"}, {"score": 0.004714387899814988, "phrase": "skill_acquisition"}, {"score": 0.0046578649614541995, "phrase": "promising_frontier"}, {"score": 0.004629856947559767, "phrase": "education_techniques"}, {"score": 0.004505881071218599, "phrase": "user_concentration"}, {"score": 0.004478782833067256, "phrase": "long_periods"}, {"score": 0.004398457709182882, "phrase": "realistic_and_compelling_challenges"}, {"score": 0.004254901969197879, "phrase": "scientific_and_engineering_methods"}, {"score": 0.004078923069461593, "phrase": "effective_learning_experiences"}, {"score": 0.003863275399791591, "phrase": "new_design_methodology"}, {"score": 0.0038284549148537373, "phrase": "sand_box"}, {"score": 0.003692271726952282, "phrase": "delivery_strategy"}, {"score": 0.0034759420565135253, "phrase": "growing_demand"}, {"score": 0.0034550163444256386, "phrase": "interactive_learning"}, {"score": 0.0033725614574134396, "phrase": "sbsg"}, {"score": 0.0032037993117317175, "phrase": "runtime_scheduling_policy"}, {"score": 0.003174903873774882, "phrase": "learning_objectives"}, {"score": 0.0031462682245392785, "phrase": "full_entertainment_context"}, {"score": 0.0030711589859463814, "phrase": "experience_engine"}, {"score": 0.0030160025335218047, "phrase": "computational_intelligence"}, {"score": 0.002952900365829518, "phrase": "domain-expert_author"}, {"score": 0.0029206771363036103, "phrase": "ee."}, {"score": 0.002899861600151726, "phrase": "semantic_annotation"}, {"score": 0.0027630232270330402, "phrase": "game_designers"}, {"score": 0.0027298319171606498, "phrase": "expected_learning_curve"}, {"score": 0.0026326249204932733, "phrase": "task_sequencing"}, {"score": 0.0025697460140513932, "phrase": "real_user_profile"}, {"score": 0.0024263474406990846, "phrase": "learning_curve"}, {"score": 0.002389956401870098, "phrase": "game_flow"}, {"score": 0.0023399219122055177, "phrase": "target_knowledge_levels"}, {"score": 0.0022702515669908285, "phrase": "ee_module"}, {"score": 0.0022497569011987587, "phrase": "genetic_computation"}, {"score": 0.0022361964497681934, "phrase": "reinforcement_learning"}, {"score": 0.0021893739085996856, "phrase": "state-of-the-art_game_engine"}, {"score": 0.0021049977753042253, "phrase": "real-time_missions"}], "paper_keywords": ["Genetic algorithms", " reinforcement learning (RL)", " serious games", " technology enhanced education", " user modeling"], "paper_abstract": "Designing games that support knowledge and skill acquisition has become a promising frontier of education techniques, since games are able to capture the user concentration for long periods and can present users with realistic and compelling challenges. In this scenario, there is a need for scientific and engineering methods to build games not only as more realistic simulations of the physical world but as means to provide effective learning experiences. Abstracting state of the art serious games' (SGs) features, we propose a new design methodology for the sand box serious games (SBSGs) class, decoupling content from the delivery strategy during the gameplay. This methodology aims at making design more efficient and standardized in order to meet the growing demand for interactive learning. The methodology consists in modeling an SBSG as a hierarchy of tasks (e.g., missions) and specifies the requirements for a runtime scheduling policy that maximizes learning objectives in a full entertainment context. The policy is learned by an experience engine (EE) based on computational intelligence. In this approach, the domain-expert author focuses on the creation and semantic annotation of tasks. Tasks are put in a repository and can then be exploited by game designers who define the expected learning curve and other requirements about education and entertainment for the game. The task sequencing that aims at matching such specifications with the real user profile is then presented to the EE. The EE can operate also in absence of the specification of the learning curve, continuously adapting the game flow without aiming at the achievement of target knowledge levels predefined by the author. We have implemented an EE module based on genetic computation and reinforcement learning (RL) atop of a state-of-the-art game engine. Test results show that the EE is able to define in real-time missions that meet the requirements expressed by the author.", "paper_title": "Adaptive Experience Engine for Serious Games", "paper_id": "WOS:000208082100002"}