{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "digital_universe"}, {"score": 0.004598933498016774, "phrase": "new_ways"}, {"score": 0.004359078118356132, "phrase": "audio_content"}, {"score": 0.004007083686875716, "phrase": "actor_level_emotion_magnitude_prediction"}, {"score": 0.0035997452281985465, "phrase": "emotion_magnitudes"}, {"score": 0.003334309053314909, "phrase": "previous_emotion_magnitudes"}, {"score": 0.0032836104153151973, "phrase": "current_text"}, {"score": 0.003088384809415812, "phrase": "actor's_emotional_state"}, {"score": 0.0029270797740550973, "phrase": "non-linear_regression_techniques"}, {"score": 0.00283870598459543, "phrase": "optimal_model"}, {"score": 0.0025892330566358503, "phrase": "non-linear_regression_models"}, {"score": 0.002530359917257626, "phrase": "support_vector_regression"}, {"score": 0.002416589459425828, "phrase": "radial_basis_function"}, {"score": 0.0021049977753042253, "phrase": "emotion_magnitude_prediction"}], "paper_keywords": ["Artificial intelligence", " Natural language processing", " Machine learning", " Multimedia semantic analysis", " Affect detection", " Speech processing"], "paper_abstract": "The digital universe is expanding at very high rates. New ways of retrieving and enriching text and audio content are required. In this work, a methodology for actor level emotion magnitude prediction in text and speech is proposed. A model is trained to predict emotion magnitudes per actor at any point in a story using previous emotion magnitudes plus current text and speech features which act on the actor's emotional state. The methodology compares linear and non-linear regression techniques to determine the optimal model that fits the data. Results of the analysis show that non-linear regression models based on Support Vector Regression (SVR) using a Radial Basis Function (RBF) kernel provide the most accurate prediction model. An analysis of the contribution of the features for emotion magnitude prediction is performed.", "paper_title": "Actor level emotion magnitude prediction in text and speech", "paper_id": "WOS:000313965900002"}