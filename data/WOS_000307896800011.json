{"auto_keywords": [{"score": 0.04558099031824589, "phrase": "collaborative_filtering"}, {"score": 0.0048149508482222, "phrase": "deblocking"}, {"score": 0.00462919213721188, "phrase": "powerful_video_filtering_algorithm"}, {"score": 0.0045748683993128425, "phrase": "temporal_and_spatial_redundancy"}, {"score": 0.004539005582217309, "phrase": "natural_video_sequences"}, {"score": 0.004398331355940011, "phrase": "nonlocal_grouping"}, {"score": 0.004295681900150244, "phrase": "higher_dimensional_transform-domain_representation"}, {"score": 0.0038624981944755813, "phrase": "motion_vectors"}, {"score": 0.003817137134650275, "phrase": "similar_volumes"}, {"score": 0.0036697319652557363, "phrase": "additional_fourth_dimension"}, {"score": 0.0035141291835319682, "phrase": "different_types"}, {"score": 0.00348655247465418, "phrase": "data_correlation"}, {"score": 0.003432044343307207, "phrase": "different_dimensions"}, {"score": 0.0032350961776525075, "phrase": "motion_trajectories"}, {"score": 0.0030494153169181334, "phrase": "fourth_dimension"}, {"score": 0.002807178116892454, "phrase": "inverse_transformation"}, {"score": 0.002474447780553576, "phrase": "proposed_filtering_procedure"}, {"score": 0.002323142666222693, "phrase": "color_data"}, {"score": 0.0023048904639724438, "phrase": "experimental_results"}, {"score": 0.0022157533515146503, "phrase": "subjective_and_objective_visual_quality"}, {"score": 0.0021049977753042253, "phrase": "video_denoising"}], "paper_keywords": ["Adaptive transforms", " motion estimation", " nonlocal methods", " video deblocking", " video denoising", " video enhancement", " video filtering"], "paper_abstract": "We propose a powerful video filtering algorithm that exploits temporal and spatial redundancy characterizing natural video sequences. The algorithm implements the paradigm of nonlocal grouping and collaborative filtering, where a higher dimensional transform-domain representation of the observations is leveraged to enforce sparsity, and thus regularize the data: 3-D spatiotemporal volumes are constructed by tracking blocks along trajectories defined by the motion vectors. Mutually similar volumes are then grouped together by stacking them along an additional fourth dimension, thus producing a 4-D structure, termed group, where different types of data correlation exist along the different dimensions: local correlation along the two dimensions of the blocks, temporal correlation along the motion trajectories, and nonlocal spatial correlation (i.e., self-similarity) along the fourth dimension of the group. Collaborative filtering is then realized by transforming each group through a decorrelating 4-D separable transform and then by shrinkage and inverse transformation. In this way, the collaborative filtering provides estimates for each volume stacked in the group, which are then returned and adaptively aggregated to their original positions in the video. The proposed filtering procedure addresses several video processing applications, such as denoising, deblocking, and enhancement of both grayscale and color data. Experimental results prove the effectiveness of our method in terms of both subjective and objective visual quality, and show that it outperforms the state of the art in video denoising.", "paper_title": "Video Denoising, Deblocking, and Enhancement Through Separable 4-D Nonlocal Spatiotemporal Transforms", "paper_id": "WOS:000307896800011"}