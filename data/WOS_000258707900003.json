{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "bayesian_networks"}, {"score": 0.004583878086896926, "phrase": "novel_method"}, {"score": 0.004494570360108983, "phrase": "approximate_inference"}, {"score": 0.003728000957725218, "phrase": "latent_tree_model"}, {"score": 0.0035141291835319682, "phrase": "data_offline"}, {"score": 0.0031845128645595715, "phrase": "ltm"}, {"score": 0.0030614565460256897, "phrase": "original_bn."}, {"score": 0.0027741761880779535, "phrase": "linear_time"}, {"score": 0.002538687900036229, "phrase": "complex_relationship"}, {"score": 0.0024891269874339553, "phrase": "leaf_nodes"}, {"score": 0.0023928819778638055, "phrase": "approximation_accuracy"}, {"score": 0.0022777800735119405, "phrase": "empirical_evidence"}, {"score": 0.002146926767291475, "phrase": "good_approximation_accuracy"}, {"score": 0.0021049977753042253, "phrase": "low_online_computational_cost"}], "paper_keywords": [""], "paper_abstract": "We propose a novel method for approximate inference in Bayesian networks (BNs). The idea is to sample data from a BN, learn a latent tree model (LTM) from the data offline, and when online, make inference with the LTM instead of the original BN. Because LTMs are tree-structured, inference takes linear time. In the meantime, they can represent complex relationship among leaf nodes and hence the approximation accuracy is often good. Empirical evidence shows that our method can achieve good approximation accuracy at low online computational cost.", "paper_title": "Latent tree models and approximate inference in Bayesian networks", "paper_id": "WOS:000258707900003"}