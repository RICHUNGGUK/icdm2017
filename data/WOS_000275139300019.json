{"auto_keywords": [{"score": 0.03151036962346512, "phrase": "renyi_entropy_rate"}, {"score": 0.011050755582851759, "phrase": "renyi_entropy"}, {"score": 0.008295395459294572, "phrase": "shannon_entropy_rate"}, {"score": 0.00481495049065317, "phrase": "gaussian_processes"}, {"score": 0.00429057323623293, "phrase": "conditional_renyi_entropy"}, {"score": 0.004208881856146758, "phrase": "continuous_random_variables"}, {"score": 0.004011366422179016, "phrase": "so-called_chain_rule"}, {"score": 0.0029203055813347874, "phrase": "stationary_gaussian_processes"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Renyi entropy", " Renyi entropy rate", " Gaussian process", " Stationary process", " Shannon entropy rate"], "paper_abstract": "In this paper, we introduce the definition of the conditional Renyi entropy for continuous random variables and show that the so-called chain rule holds. Then, we use this rule to obtain another relation for getting the rate of Renyi entropy. Using this relation and properties of the Renyi entropy we obtain the Renyi entropy rate for stationary Gaussian processes. Finally, we show that the bound for the Renyi entropy rate is simply the Shannon entropy rate and that the Renyi entropy rate reduces to the Shannon entropy rate as alpha -> 1. (C) 2009 Published by Elsevier Inc.", "paper_title": "Renyi entropy rate for Gaussian processes", "paper_id": "WOS:000275139300019"}