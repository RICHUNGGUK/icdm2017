{"auto_keywords": [{"score": 0.04667104055240119, "phrase": "forney"}, {"score": 0.00481495049065317, "phrase": "error_exponents"}, {"score": 0.0046859752697029355, "phrase": "distance_enumerators"}, {"score": 0.0045959609346817535, "phrase": "random_coding_error_exponents"}, {"score": 0.004336115760817672, "phrase": "jensen's_inequality"}, {"score": 0.004106810349956121, "phrase": "exponentially_tight_analysis"}, {"score": 0.003981243132108877, "phrase": "relevant_moments"}, {"score": 0.003488874535154583, "phrase": "random_coding_distribution"}, {"score": 0.0030572112793962004, "phrase": "binary_symmetric_channel"}, {"score": 0.0029867619862229853, "phrase": "optimum_value"}, {"score": 0.002895341091441627, "phrase": "closed_form"}, {"score": 0.002763415176377921, "phrase": "numerical_search"}, {"score": 0.0026788122684116224, "phrase": "numerical_example"}, {"score": 0.0026477564788515984, "phrase": "new_bound"}, {"score": 0.0025172781808293827, "phrase": "additional_evidence"}, {"score": 0.0024880904032564583, "phrase": "forney's_conjecture"}, {"score": 0.002421291757425244, "phrase": "average_code"}, {"score": 0.002356282242320051, "phrase": "proposed_analysis_technique"}, {"score": 0.00224013518726087, "phrase": "significantly_tighter_exponential_error_bounds"}, {"score": 0.0021214346747442363, "phrase": "exponential_error_bounds"}], "paper_keywords": ["distance enumerator", " erasure", " error exponent", " list", " random coding"], "paper_abstract": "The analysis of random coding error exponents pertaining to erasure/list decoding, due to Forney, is revisited. Instead of using Jensen's inequality as well as some other inequalities in the derivation, we demonstrate that an exponentially tight analysis can be carried out by assessing the relevant moments of certain distance enumerators. The resulting bound has the following advantages: i) it is at least as tight as Forney's bound, ii) under certain symmetry conditions associated with the channel and the random coding distribution, it is simpler than Forney's bound in the sense that it involves an optimization over one parameter only (rather than two), and iii) in certain special cases, like the binary symmetric channel (BSC), the optimum value of this parameter can be found in closed form, and so, there is no need to conduct a numerical search. We have not found yet a numerical example where this new bound is strictly better than Forney's bound and this may provide an additional evidence to support Forney's conjecture that his bound is tight for the average code. However, when applying the proposed analysis technique to a certain universal decoder with erasures, we demonstrate that it may yield significantly tighter exponential error bounds. We believe that this technique can be useful in simplifying and improving exponential error bounds in other problem settings as well.", "paper_title": "Error exponents of erasure/list decoding revisited via moments of distance enumerators", "paper_id": "WOS:000259407000003"}