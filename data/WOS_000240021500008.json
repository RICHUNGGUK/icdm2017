{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "random_forests"}, {"score": 0.048901199639170195, "phrase": "complex_aggregates"}, {"score": 0.04409655240764186, "phrase": "relational_classifiers"}, {"score": 0.03172720880188204, "phrase": "aggregate_functions"}, {"score": 0.029619512158162505, "phrase": "first_order_logic"}, {"score": 0.004638354165775803, "phrase": "relational_learning"}, {"score": 0.004250969091124481, "phrase": "related_individuals"}, {"score": 0.003721735062704032, "phrase": "specific_individuals"}, {"score": 0.003482276061796395, "phrase": "undesirable_bias"}, {"score": 0.003354393040689453, "phrase": "learning_approach"}, {"score": 0.0032581736321024373, "phrase": "first_order_random_forests"}, {"score": 0.0031647054743284947, "phrase": "decision_trees"}, {"score": 0.0030739103951333696, "phrase": "first_order_logic_queries"}, {"score": 0.0028760125558659907, "phrase": "first_order_logic_query"}, {"score": 0.0027133032795773697, "phrase": "forest's_uniform_feature_sampling_procedure"}, {"score": 0.0024554476124885806, "phrase": "resulting_first_order_random_forest_induction_algorithm"}, {"score": 0.0023750478314945303, "phrase": "ace-ilprolog_system"}, {"score": 0.002231310272815607, "phrase": "first_order"}, {"score": 0.002176275802465835, "phrase": "efficient_and_effective_approach"}, {"score": 0.0021049977753042253, "phrase": "complex_selections"}], "paper_keywords": ["relational learning", " random forests", " aggregation", " decision tree learning"], "paper_abstract": "In relational learning, predictions for an individual are based not only on its own properties but also on the properties of a set of related individuals. Relational classifiers differ with respect to how they handle these sets: some use properties of the set as a whole (using aggregation), some refer to properties of specific individuals of the set, however, most classifiers do not combine both. This imposes an undesirable bias on these learners. This article describes a learning approach that avoids this bias, using first order random forests. Essentially, an ensemble of decision trees is constructed in which tests are first order logic queries. These queries may contain aggregate functions, the argument of which may again be a first order logic query. The introduction of aggregate functions in first order logic, as well as upgrading the forest's uniform feature sampling procedure to the space of first order logic, generates a number of complications. We address these and propose a solution for them. The resulting first order random forest induction algorithm has been implemented and integrated in the ACE-ilProlog system, and experimentally evaluated on a variety of datasets. The results indicate that first order random forests with complex aggregates are an efficient and effective approach towards learning relational classifiers that involve aggregates over complex selections.", "paper_title": "First order random forests: Learning relational classifiers with complex aggregates", "paper_id": "WOS:000240021500008"}