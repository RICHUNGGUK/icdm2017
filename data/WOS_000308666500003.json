{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "ann"}, {"score": 0.049594743402738874, "phrase": "gmm"}, {"score": 0.033794068367687426, "phrase": "segmental_level"}, {"score": 0.004696608876994947, "phrase": "voice_conversion_framework"}, {"score": 0.004490842671590769, "phrase": "comparative_analysis"}, {"score": 0.004446349752828045, "phrase": "artificial_neural_networks"}, {"score": 0.004337028108577593, "phrase": "gaussian_mixture_models"}, {"score": 0.004188459638572375, "phrase": "voice_conversion_system"}, {"score": 0.0041469500929423595, "phrase": "line_spectral_frequencies"}, {"score": 0.0040449598280454645, "phrase": "feature_vectors"}, {"score": 0.003906357144047631, "phrase": "nonlinear_mapping_functions"}, {"score": 0.003829290275367182, "phrase": "vocal_tract_characteristics"}, {"score": 0.0037724857647796813, "phrase": "source_speaker"}, {"score": 0.0036980501827538455, "phrase": "desired_target_speaker"}, {"score": 0.0035358770665604657, "phrase": "vocal_tract_transfer_function"}, {"score": 0.0034834098902271626, "phrase": "particular_speaker"}, {"score": 0.003397683082821229, "phrase": "intonation_patterns"}, {"score": 0.0032324864013225166, "phrase": "codebook_based_model"}, {"score": 0.003152915289414825, "phrase": "energy_profile"}, {"score": 0.003029643234751066, "phrase": "fixed_scaling_factor"}, {"score": 0.0028253682745674608, "phrase": "residual_modification"}, {"score": 0.0027834145465170292, "phrase": "residual_copying"}, {"score": 0.0027557911038816256, "phrase": "residual_selection_methods"}, {"score": 0.0026745503978347143, "phrase": "target_residual_signal"}, {"score": 0.002569933140999018, "phrase": "based_voice_conversion"}, {"score": 0.0025444729366256966, "phrase": "vc"}, {"score": 0.0024693979425773993, "phrase": "subjective_and_objective_measures"}, {"score": 0.0023846534541336326, "phrase": "proposed_ann-based_model"}, {"score": 0.0022460727898764216, "phrase": "state-of-the-art_gmm-based_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Artificial neural networks", " Gaussian mixture models", " Prosody", " Pitch contour", " Intonation patterns", " Duration patterns", " Energy profiles", " Residual modification"], "paper_abstract": "In this paper, we present a comparative analysis of artificial neural networks (ANNs) and Gaussian mixture models (GMMs) for design of voice conversion system using line spectral frequencies (LSFs) as feature vectors. Both the ANN and GMM based models are explored to capture nonlinear mapping functions for modifying the vocal tract characteristics of a source speaker according to a desired target speaker. The LSFs are used to represent the vocal tract transfer function of a particular speaker. Mapping of the intonation patterns (pitch contour) is carried out using a codebook based model at segmental level. The energy profile of the signal is modified using a fixed scaling factor defined between the source and target speakers at the segmental level. Two different methods for residual modification such as residual copying and residual selection methods are used to generate the target residual signal. The performance of ANN and GMM based voice conversion (VC) system are conducted using subjective and objective measures. The results indicate that the proposed ANN-based model using LSFs feature set may be used as an alternative to state-of-the-art GMM-based models used to design a voice conversion system. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Comparing ANN and GMM in a voice conversion framework", "paper_id": "WOS:000308666500003"}