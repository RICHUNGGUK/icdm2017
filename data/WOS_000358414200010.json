{"auto_keywords": [{"score": 0.04882655221850924, "phrase": "krylov"}, {"score": 0.044673250506432303, "phrase": "graphics_processing_units"}, {"score": 0.00481495049065317, "phrase": "gpu-based_krylov_solvers"}, {"score": 0.004446823283475876, "phrase": "large_sparse_linear_systems"}, {"score": 0.004330450801016359, "phrase": "hardware_accelerators"}, {"score": 0.004161553532799662, "phrase": "point_performance"}, {"score": 0.004106725110985659, "phrase": "matrix_and_vector_computations"}, {"score": 0.004070573090297285, "phrase": "easy-to-use_libraries"}, {"score": 0.003709595902020469, "phrase": "linear_algebra_operations"}, {"score": 0.00342568771304873, "phrase": "full_potential"}, {"score": 0.0032199307816384577, "phrase": "krylov_subspace_iterative_methods"}, {"score": 0.0031079352545607267, "phrase": "biconjugate_gradient"}, {"score": 0.003053402354907241, "phrase": "significant_improvement"}, {"score": 0.00289546142998427, "phrase": "application-specific_kernels"}, {"score": 0.002832081745025006, "phrase": "generic_blas_kernels"}, {"score": 0.0027578496677536373, "phrase": "nvidia's_cublas_library"}, {"score": 0.002685558057339722, "phrase": "graphics_processing_unit"}, {"score": 0.0026736945502820303, "phrase": "specific_sparse_matrix-vector_product_kernel"}, {"score": 0.0025692477422626678, "phrase": "graphics_processing_unit's_computing_power"}, {"score": 0.0024579623598183355, "phrase": "performance_improvement"}, {"score": 0.0024148064819862337, "phrase": "experimental_data"}, {"score": 0.0023724065150232897, "phrase": "expected_runtime_savings"}, {"score": 0.002320449502337321, "phrase": "derived_implementation"}, {"score": 0.0022999859758286423, "phrase": "significantly_higher_performance"}, {"score": 0.0022496114364599328, "phrase": "similar_optimizations"}, {"score": 0.0022297712188622293, "phrase": "algorithm_structure"}, {"score": 0.0021809311689473493, "phrase": "sparse_matrix-vector"}, {"score": 0.002123730137917387, "phrase": "subsequent_development"}, {"score": 0.0021049977753042253, "phrase": "high-performance_graphics_processing_units"}], "paper_keywords": ["Krylov subspace methods", " iterative solvers", " sparse linear systems", " graphics processing units", " BiCGSTAB"], "paper_abstract": "Krylov subspace iterative solvers are often the method of choice when solving large sparse linear systems. At the same time, hardware accelerators such as graphics processing units continue to offer significant floating point performance gains for matrix and vector computations through easy-to-use libraries of computational kernels. However, as these libraries are usually composed of a well optimized but limited set of linear algebra operations, applications that use them often fail to reduce certain data communications, and hence fail to leverage the full potential of the accelerator. In this paper, we target the acceleration of Krylov subspace iterative methods for graphics processing units, and in particular the Biconjugate Gradient Stabilized solver that significant improvement can be achieved by reformulating the method to reduce data-communications through application-specific kernels instead of using the generic BLAS kernels, e.g. as provided by NVIDIA's cuBLAS library, and by designing a graphics processing unit specific sparse matrix-vector product kernel that is able to more efficiently use the graphics processing unit's computing power. Furthermore, we derive a model estimating the performance improvement, and use experimental data to validate the expected runtime savings. Considering that the derived implementation achieves significantly higher performance, we assert that similar optimizations addressing algorithm structure, as well as sparse matrix-vector, are crucial for the subsequent development of high-performance graphics processing units accelerated Krylov subspace iterative methods.", "paper_title": "Acceleration of GPU-based Krylov solvers via data transfer reduction", "paper_id": "WOS:000358414200010"}