{"auto_keywords": [{"score": 0.048223267193393836, "phrase": "real-world_video_sequences"}, {"score": 0.04230431876032307, "phrase": "manual_labeling"}, {"score": 0.03399273535727023, "phrase": "video_sequence"}, {"score": 0.031811450897395364, "phrase": "proposed_framework"}, {"score": 0.00481495049065317, "phrase": "robust_semi-automatic_head"}, {"score": 0.004746263721902201, "phrase": "real-world_face_video_sequences"}, {"score": 0.004513450434595191, "phrase": "computer_vision_community"}, {"score": 0.004449045430179066, "phrase": "prior_knowledge"}, {"score": 0.004354149483556514, "phrase": "face_detection"}, {"score": 0.0042459818200777846, "phrase": "pose_estimation_algorithms"}, {"score": 0.0038119123317396954, "phrase": "high_uncertainty"}, {"score": 0.003757480190200645, "phrase": "angle_estimate"}, {"score": 0.0037038224217016817, "phrase": "unconstrained_environments"}, {"score": 0.0036640806940633373, "phrase": "arbitrary_facial_expression"}, {"score": 0.0034967186553667715, "phrase": "semi-automatic_framework"}, {"score": 0.0034343965063429447, "phrase": "temporal_head"}, {"score": 0.003361069456060196, "phrase": "proposed_multi-stage_labeling_framework"}, {"score": 0.00326572165784246, "phrase": "distinct_head"}, {"score": 0.003071965703296204, "phrase": "ground_truth"}, {"score": 0.0029740732099993706, "phrase": "continuous_head_pose_label"}, {"score": 0.002952745241052452, "phrase": "corresponding_confidence_value"}, {"score": 0.0029210388852074208, "phrase": "pose_angles"}, {"score": 0.0028689475587958917, "phrase": "interpolation_scheme"}, {"score": 0.002747676657869163, "phrase": "manual_labels"}, {"score": 0.002669683153809812, "phrase": "confidence_value"}, {"score": 0.0026410082462069596, "phrase": "automatic_head"}, {"score": 0.0026220625042810706, "phrase": "estimation_framework"}, {"score": 0.00247529638625566, "phrase": "labeling_accuracy"}, {"score": 0.0021049977753042253, "phrase": "video_frames"}], "paper_keywords": ["Semi-automatic labeling", " Real-world video sequence", " Head pose", " Automatic face tracking", " Bag-of-words", " Manifold"], "paper_abstract": "Automatic head pose estimation from real-world video sequences is of great interest to the computer vision community since pose provides prior knowledge for tasks, such as face detection and classification. However, developing pose estimation algorithms requires large, labeled real-world video databases on which computer vision systems can be trained and tested. Manual labeling of each frame is tedious, time consuming, and often difficult due to the high uncertainty in head pose angle estimate, particularly in unconstrained environments that include arbitrary facial expression, occlusion, illumination etc. To overcome these difficulties, a semi-automatic framework is proposed for labeling temporal head pose in real-world video sequences. The proposed multi-stage labeling framework first detects a subset of frames with distinct head poses over a video sequence, which is then manually labeled by the expert to obtain the ground truth for those frames. The proposed framework provides a continuous head pose label and corresponding confidence value over the pose angles. Next, the interpolation scheme over a video sequence estimates i) labels for the frames without manual labels and ii) corresponding confidence values for interpolated labels. This confidence value permits an automatic head pose estimation framework to determine the subset of frames to be used for further processing, depending on the labeling accuracy required. The experiments performed on an in-house, labeled, large, real-world face video database (which will be made publicly available) show that the proposed framework achieves 96.98 % labeling accuracy when manual labeling is only performed on 30 % of the video frames.", "paper_title": "Robust semi-automatic head pose labeling for real-world face video sequences", "paper_id": "WOS:000336807300023"}