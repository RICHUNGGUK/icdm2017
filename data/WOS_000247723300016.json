{"auto_keywords": [{"score": 0.023808348905144983, "phrase": "act"}, {"score": 0.00481495049065317, "phrase": "multi-agent_systems"}, {"score": 0.004734448316824488, "phrase": "abridged_history"}, {"score": 0.0045262653692203815, "phrase": "future_agent_design"}, {"score": 0.004450568197899267, "phrase": "agent_technologies"}, {"score": 0.004400804926266097, "phrase": "increasingly_sophisticated_techniques"}, {"score": 0.0043029342321223825, "phrase": "formal_programming_languages"}, {"score": 0.004278807087784626, "phrase": "object-oriented_programming"}, {"score": 0.004195418010131832, "phrase": "corresponding_shift"}, {"score": 0.004171891198117434, "phrase": "scripted_agents"}, {"score": 0.0041136473765874815, "phrase": "agent-oriented_designs"}, {"score": 0.003823584649521733, "phrase": "ubiquitous_paper_clip"}, {"score": 0.0037595947142663997, "phrase": "entire_applications"}, {"score": 0.003738502710504415, "phrase": "even_games"}, {"score": 0.0034423598165638884, "phrase": "dai"}, {"score": 0.0033974527047473044, "phrase": "agent_technology"}, {"score": 0.0031666307941887093, "phrase": "critical_components"}, {"score": 0.003148854910240482, "phrase": "modern_distributed_artificial_intelligence"}, {"score": 0.0030961218779438702, "phrase": "current_applications"}, {"score": 0.003027178161479457, "phrase": "next_generation"}, {"score": 0.003016270530839053, "phrase": "jack"}, {"score": 0.002995788533376303, "phrase": "bdi"}, {"score": 0.0029764767329116875, "phrase": "liuman-centric_interaction"}, {"score": 0.0028775998963807324, "phrase": "new_paradigm"}, {"score": 0.002727700630869639, "phrase": "jack_framework"}, {"score": 0.0026820015810254004, "phrase": "individual_reasoning_processes"}, {"score": 0.002556625752785268, "phrase": "superior_agents"}, {"score": 0.00227604665144097, "phrase": "orient"}, {"score": 0.0021773853011112882, "phrase": "learning_component"}, {"score": 0.0021590588269751816, "phrase": "team_environment"}, {"score": 0.002146926767291475, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Artificial Intelligence (AI)", " agent", " Multi-Agent Systems (MAS)", " Distributed Artificial Intelligence (DIA)", " Belief, Desire, and Intension (BDI)", " Human-Computer Interface (HCI)", " Observe, Orient, Decide and Act (OODA)", " Procedural Reasoning System (PRS)", " Decision Support System (DSS)", " Intelligent Decision Support System (IDSS)"], "paper_abstract": "This paper outlines an abridged history of agents as a guide for the reader to understand the trends and directions of future agent design. This description includes how agent technologies have developed using increasingly sophisticated techniques. It also indicates the transition of formal programming languages into object-oriented programming and how this transition facilitated a corresponding shift from scripted agents (bots) to agent-oriented designs. The trend shows that applications with agents are increasingly being used to assist humans, either at work or play. Examples include the ubiquitous paper clip, through to wizards, entire applications and even games. The trend also demonstrates that agents vary in the complexity of the problem being solved and their environment. Following the discussion of trends, we briefly look at the origins of agent technology and its principles, which reflects heavily on 'Intelligence with Interaction'. We further pinpoint how the interaction with humans is one of the critical components of modern Distributed Artificial Intelligence (DAI) and how current applications fail to address this fact. The next generation of agents should focus on liuman-centric interaction to achieve intelligence. Utilising these advancements, we introduce a new paradigm that uses Intelligent Agents based on a Belief, Desire, and Intention (BDI) architecture to achieve situation awareness in a hostile environment. BDI agents are implemented using the JACK framework, and spawn agents with individual reasoning processes specifically relating to the goals being instigated in its environment. They depend on the environment or superior agents to generate goals for them to act upon. I ii order to improve the performance of the agents we need to remove this dependency. To this end, it is suggested that JACK can be extended to realise the Observe, Orient, Decide and Act (OODA) loop using feedback from a learning component within a team environment. Crown Copyright (C) 2006 Published by Elsevier Ltd. All rights reserved.", "paper_title": "Innovations in multi-agent systems", "paper_id": "WOS:000247723300016"}