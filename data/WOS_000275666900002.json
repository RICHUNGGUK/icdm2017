{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "analysis"}, {"score": 0.004735254735115024, "phrase": "video_acquisition"}, {"score": 0.004522796947899013, "phrase": "independent_tasks"}, {"score": 0.004429388453288922, "phrase": "negative_impact"}, {"score": 0.0043560464825349275, "phrase": "consumed_resources"}, {"score": 0.004248294537944227, "phrase": "raw_information"}, {"score": 0.004195418010131832, "phrase": "conventional_acquisition_devices"}, {"score": 0.004108742905942481, "phrase": "coding_phase"}, {"score": 0.004040688646993605, "phrase": "analysis_step"}, {"score": 0.003940706575253453, "phrase": "salient_video_characteristics"}, {"score": 0.00390792986752692, "phrase": "recent_compressive_sensing_literature"}, {"score": 0.003670608022642996, "phrase": "unified_architecture"}, {"score": 0.0036097844103129043, "phrase": "light_encoder"}, {"score": 0.0034620831765465425, "phrase": "underlying_signal"}, {"score": 0.0034332736827447654, "phrase": "efficient_recovery"}, {"score": 0.0033622909109253616, "phrase": "clear_understanding"}, {"score": 0.003292770855568091, "phrase": "video_analysis"}, {"score": 0.003092690568543981, "phrase": "joint_compressive_video_coding"}, {"score": 0.0029909851863915283, "phrase": "specific_application_example"}, {"score": 0.00290473242917264, "phrase": "object_tracking"}, {"score": 0.0028805474861014722, "phrase": "video_sequences"}, {"score": 0.0026941587813581274, "phrase": "analysis_module"}, {"score": 0.0025623050508233078, "phrase": "foreground_objects"}, {"score": 0.0024573577356299765, "phrase": "conventional_disjoint_approach"}, {"score": 0.0023864566654035924, "phrase": "video_signal"}, {"score": 0.002337066031028783, "phrase": "pixel_domain"}, {"score": 0.00227914162528171, "phrase": "considerable_gains"}, {"score": 0.0022041312401435346, "phrase": "video_analysis_applications"}, {"score": 0.002158505888557746, "phrase": "joint_analysis-aware_design"}, {"score": 0.0021049977753042253, "phrase": "signal_recovery"}], "paper_keywords": ["Compressive sensing", " video coding and analysis"], "paper_abstract": "Traditionally, video acquisition, coding and analysis have been designed and optimized as independent tasks. This has a negative impact in terms of consumed resources, as most of the raw information captured by conventional acquisition devices is discarded in the coding phase, while the analysis step only requires a few descriptors of salient video characteristics. Recent compressive sensing literature has partially broken this paradigm by proposing to integrate sensing and coding in a unified architecture composed by a light encoder and a more complex decoder, which exploits sparsity of the underlying signal for efficient recovery. However, a clear understanding of how to embed video analysis in this scheme is still missing. In this paper, we propose a joint compressive video coding and analysis scheme and, as a specific application example, we consider the problem of object tracking in video sequences. We show that, weaving together compressive sensing and the information computed by the analysis module, the bit-rate required to perform reconstruction and tracking of the foreground objects can be considerably reduced, with respect to a conventional disjoint approach that postpones the analysis after the video signal is recovered in the pixel domain. These findings suggest that considerable gains in performance can be potentially obtained in video analysis applications, provided that a joint analysis-aware design of acquisition, coding and signal recovery is carried out.", "paper_title": "Joint Compressive Video Coding and Analysis", "paper_id": "WOS:000275666900002"}