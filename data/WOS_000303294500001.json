{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "pervasive_sensing"}, {"score": 0.004740476936977635, "phrase": "surgical_activities"}, {"score": 0.004523865550323285, "phrase": "generic_framework"}, {"score": 0.004453874101119545, "phrase": "activity_recognition"}, {"score": 0.0043509032299218955, "phrase": "temporal_signals"}, {"score": 0.004250302819248558, "phrase": "multiple_input_modalities"}, {"score": 0.004087756756529841, "phrase": "eye-hand_data_fusion"}, {"score": 0.003870541730075597, "phrase": "data_fusion_framework"}, {"score": 0.0037224647319912293, "phrase": "multi-objective_bayesian_framework_for_feature_selection"}, {"score": 0.0036363418376496484, "phrase": "pruned-tree_search_algorithm"}, {"score": 0.0035245918797629804, "phrase": "optimal_feature"}, {"score": 0.003389704997952315, "phrase": "computationally_efficient_manner"}, {"score": 0.0032855095476183372, "phrase": "endoscopic_surgical_episode_recognition"}, {"score": 0.003015143226706584, "phrase": "pervasive_monitoring"}, {"score": 0.002968424524565369, "phrase": "surgical_operation"}, {"score": 0.002854761308379149, "phrase": "additional_information"}, {"score": 0.0027886573969044042, "phrase": "hand_motion"}, {"score": 0.002681859084438076, "phrase": "recognition_accuracy"}, {"score": 0.002599365215003002, "phrase": "proposed_multi-objective_bffs_algorithm"}, {"score": 0.002422890839801611, "phrase": "feature_relevancy"}, {"score": 0.0022760856906838814, "phrase": "minimal_number"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Activity recognition", " Eye-hand coordination", " Feature selection", " Multi-objective feature selection", " Multi-objective BFFS", " Surgical workflow classification"], "paper_abstract": "This paper describes a generic framework for activity recognition based on temporal signals acquired from multiple input modalities and demonstrates its use for eye-hand data fusion. As a part of the data fusion framework, we present a multi-objective Bayesian Framework for Feature Selection with a pruned-tree search algorithm for finding the optimal feature set(s) in a computationally efficient manner. Experiments on endoscopic surgical episode recognition are used to investigate the potential of using eye-tracking for pervasive monitoring of surgical operation and to demonstrate how additional information induced by hand motion can further enhance the recognition accuracy. With the proposed multi-objective BFFS algorithm, suitable feature sets both in terms of feature relevancy and redundancy can be identified with a minimal number of instruments being tracked. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "An eye-hand data fusion framework for pervasive sensing of surgical activities", "paper_id": "WOS:000303294500001"}