{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "time-series_modeling"}, {"score": 0.004575053987970206, "phrase": "probabilistic_approach"}, {"score": 0.004459605573798577, "phrase": "second-order_training"}, {"score": 0.0043842558719324526, "phrase": "recurrent_neural_networks"}, {"score": 0.004201381218977942, "phrase": "improved_time-series_modeling"}, {"score": 0.00402610372759447, "phrase": "bayesian_levenberg-marquardt_algorithm"}, {"score": 0.0034828730516958807, "phrase": "main_strengths"}, {"score": 0.003309124298009635, "phrase": "principled_handling"}, {"score": 0.0032255172568437965, "phrase": "regularization_hyperparameters"}, {"score": 0.003117307618682836, "phrase": "better_generalization"}, {"score": 0.003038532168038562, "phrase": "stable_numerical_performance"}, {"score": 0.0028139168128067343, "phrase": "noise_hyperparameter_and_local_weight_prior_hyperparameters"}, {"score": 0.0024969812322112174, "phrase": "model_parameters"}, {"score": 0.0024547103576350233, "phrase": "experimental_investigations"}, {"score": 0.002413153346716919, "phrase": "artificial_and_real-world_data_sets"}, {"score": 0.0022731540640627307, "phrase": "proposed_approach"}, {"score": 0.0022346638243276717, "phrase": "standard_real-time_recurrent_learning"}, {"score": 0.002178215385686643, "phrase": "kalman"}, {"score": 0.0021049977753042253, "phrase": "recurrent_networks"}], "paper_keywords": ["Bayesian regularization", " recurrent neural network (RNN)", " sequential Levenberg-Marquardt"], "paper_abstract": "This paper develops a probabilistic approach to recursive second-order training of recurrent neural networks (RNNs) for improved time-series modeling. A general recursive Bayesian Levenberg-Marquardt algorithm is derived to sequentially update the weights and the covariance (Hessian) matrix. The main strengths of the approach are a principled handling of the regularization hyperparameters that leads to better generalization, and stable numerical performance. The framework involves the adaptation of a noise hyperparameter and local weight prior hyperparameters, which represent the noise in the data and the uncertainties in the model parameters. Experimental investigations using artificial and real-world data sets show that RNNs equipped with the proposed approach outperform standard real-time recurrent learning and extended Kalman training algorithms for recurrent networks, as well as other contemporary nonlinear neural models, on time-series modeling.", "paper_title": "Recursive Bayesian Recurrent Neural Networks for Time-Series Modeling", "paper_id": "WOS:000274382400007"}