{"auto_keywords": [{"score": 0.028895644956226617, "phrase": "novelty_functions"}, {"score": 0.00481495049065317, "phrase": "audio_properties_of_perceived_boundaries"}, {"score": 0.004777236322125634, "phrase": "music"}, {"score": 0.004739416327250269, "phrase": "data_mining_tasks"}, {"score": 0.004683540676363745, "phrase": "music_indexing"}, {"score": 0.004646654984830476, "phrase": "information_retrieval"}, {"score": 0.00459186790405058, "phrase": "similarity_search"}, {"score": 0.00425951071471662, "phrase": "recorded_music"}, {"score": 0.004192653260742387, "phrase": "large_change"}, {"score": 0.0038584250641318057, "phrase": "listeners_segment_melodies"}, {"score": 0.0032034752726003025, "phrase": "algorithmic_approaches"}, {"score": 0.0031782087629067686, "phrase": "different_corpora"}, {"score": 0.0030913302090179967, "phrase": "statistical_analysis"}, {"score": 0.003054825135908205, "phrase": "large_corpus"}, {"score": 0.002971309306027602, "phrase": "expert_listeners"}, {"score": 0.002901538668877986, "phrase": "acoustic_properties"}, {"score": 0.0027999339042953076, "phrase": "previous_perceptual_experiments"}, {"score": 0.0027778413437997613, "phrase": "nearly_all_boundaries"}, {"score": 0.0026175952455594277, "phrase": "musical_feature"}, {"score": 0.0025866699249916508, "phrase": "particular_time_scale"}, {"score": 0.0023801608396295374, "phrase": "boundary-novelty_relationship"}, {"score": 0.0021901023885734, "phrase": "boundary_profile"}, {"score": 0.0021049977753042253, "phrase": "estimated_salience"}], "paper_keywords": ["Boundaries", " corpus analysis", " music analysis", " music information retrieval"], "paper_abstract": "Data mining tasks such as music indexing, information retrieval, and similarity search, require an understanding of how listeners process music internally. Many algorithms for automatically analyzing the structure of recorded music assume that a large change in one or another musical feature suggests a section boundary. However, this assumption has not been tested: while our understanding of how listeners segment melodies has advanced greatly in the past decades, little is known about how this process works with more complex, full-textured pieces of music, or how stable this process is across genres. Knowing how these factors affect how boundaries are perceived will help researchers to judge the viability of algorithmic approaches with different corpora of music. We present a statistical analysis of a large corpus of recordings whose formal structure was annotated by expert listeners. We find that the acoustic properties of boundaries in these recordings corroborate findings of previous perceptual experiments. Nearly all boundaries correspond to peaks in novelty functions, which measure the rate of change of a musical feature at a particular time scale. Moreover, most of these boundaries match peaks in novelty for several features at several time scales. We observe that the boundary-novelty relationship can vary with listener, time scale, genre, and musical feature. Finally, we show that a boundary profile derived from a collection of novelty functions correlates with the estimated salience of boundaries indicated by listeners.", "paper_title": "Audio Properties of Perceived Boundaries in Music", "paper_id": "WOS:000340295600005"}