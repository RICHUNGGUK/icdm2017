{"auto_keywords": [{"score": 0.03279538488952693, "phrase": "wisteria"}, {"score": 0.00481495049065317, "phrase": "scalable_data_cleaning_infrastructure"}, {"score": 0.004498490110526062, "phrase": "data_cleaning"}, {"score": 0.004428452434981208, "phrase": "data_cleaning_process"}, {"score": 0.0041589926969138585, "phrase": "basic_exploratory_data_analysis"}, {"score": 0.004051595625804513, "phrase": "dirty_data"}, {"score": 0.0036489343475053187, "phrase": "full_dataset"}, {"score": 0.003480993634130542, "phrase": "logical_level"}, {"score": 0.003234934827553253, "phrase": "large_search_space"}, {"score": 0.0032012284065895537, "phrase": "physical_operators"}, {"score": 0.002974886152979993, "phrase": "iterative_development"}, {"score": 0.0029131986574478046, "phrase": "data_cleaning_workflows"}, {"score": 0.002750056254309311, "phrase": "logical_operations"}, {"score": 0.002721388234661538, "phrase": "physical_implementations"}, {"score": 0.002651015392318126, "phrase": "analyst_feedback"}, {"score": 0.002542174767860791, "phrase": "analyst's_choice"}, {"score": 0.0025156683465194967, "phrase": "physical_implementation"}, {"score": 0.0024634797027967203, "phrase": "research_challenges"}, {"score": 0.002387214876538434, "phrase": "flight_operator_replacement"}, {"score": 0.002289180040240783, "phrase": "system_architecture"}, {"score": 0.0021049977753042253, "phrase": "iterative_data_analysis"}], "paper_keywords": [""], "paper_abstract": "Analysts report spending upwards of 80% of their time on problems in data cleaning. The data cleaning process is inherently iterative, with evolving cleaning workflows that start with basic exploratory data analysis on small samples of dirty data, then refine analysis with more sophisticated/expensive cleaning operators (e.g., crowdsourcing), and finally apply the insights to a full dataset. While an analyst often knows at a logical level what operations need to be done, they often have to manage a large search space of physical operators and parameters. We present Wisteria, a system designed to support the iterative development and optimization of data cleaning workflows, especially ones that utilize the crowd. Wisteria separates logical operations from physical implementations, and driven by analyst feedback, suggests optimizations and/or replacements to the analyst's choice of physical implementation. We highlight research challenges in sampling, in-flight operator replacement, and crowdsourcing. We overview the system architecture and these techniques, then provide a demonstration designed to showcase how Wisteria can improve iterative data analysis and cleaning. The code is available at: http://www.sampleclean.org.", "paper_title": "Wisteria: Nurturing Scalable Data Cleaning Infrastructure", "paper_id": "WOS:000386424800087"}