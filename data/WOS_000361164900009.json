{"auto_keywords": [{"score": 0.04852995440159012, "phrase": "mcda"}, {"score": 0.01574740186596477, "phrase": "matrix"}, {"score": 0.004697655699119423, "phrase": "completion_discriminant_analysis"}, {"score": 0.004204054047427536, "phrase": "mapping_class_labels"}, {"score": 0.004101579688745222, "phrase": "regular_simplex"}, {"score": 0.00405127920820053, "phrase": "c_classes"}, {"score": 0.0038720442355114045, "phrase": "unit_sphere"}, {"score": 0.0035515148917169173, "phrase": "unlabeled_cases"}, {"score": 0.0034083145672246067, "phrase": "large_matrix"}, {"score": 0.0032174507570710835, "phrase": "vertex_coordinates"}, {"score": 0.0029876282026237207, "phrase": "niatrix_completion"}, {"score": 0.00292674497467906, "phrase": "matrix_completion"}, {"score": 0.0028086649378423357, "phrase": "nuclear_norm_penalty"}, {"score": 0.0027741761880779535, "phrase": "simplest_solution"}, {"score": 0.002740109776120878, "phrase": "mm_algorithm"}, {"score": 0.0027176309244222, "phrase": "singular_value_decomposition"}, {"score": 0.0025865679621853667, "phrase": "cross_validation"}, {"score": 0.002565345470805401, "phrase": "randomly_withheld_case_labels"}, {"score": 0.002471973283582411, "phrase": "unlabeled_case"}, {"score": 0.0024215727801940434, "phrase": "class_vertex"}, {"score": 0.0022670785913397637, "phrase": "statistical_literature"}, {"score": 0.002202617924488607, "phrase": "traditional_problems"}, {"score": 0.002157697367447098, "phrase": "large-scale_problems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Classification", " Missing observations", " MM algorithm", " Semi-supervised learning", " Singular value decomposition"], "paper_abstract": "Matrix completion discriminant analysis (MCDA) is designed for semi-supervised learning where the rate of missingness is high and predictors vastly outnumber cases. MCDA operates by mapping class labels to the vertices of a regular simplex. With c classes, these vertices are arranged on the surface of the unit sphere in c - 1 dimensional Euclidean space. Because all pairs of vertices are equidistant, the classes are treated symmetrically. To assign unlabeled cases to classes, the data is entered into a large matrix (cases along rows and predictors along columns) that is augmented by vertex coordinates stored in the last c - 1 columns. Once the matrix is constructed, its missing entries can be filled in by niatrix completion. To carry out matrix completion, one minimizes a sum of squares plus a nuclear norm penalty. The simplest solution invokes an MM algorithm and singular value decomposition. Choice of the penalty tuning constant can be achieved by cross validation on randomly withheld case labels. Once the matrix is completed, an unlabeled case is assigned to the class vertex closest to the point deposited in its last c - 1 columns. A variety of examples drawn from the statistical literature demonstrate that MCDA is competitive on traditional problems and outperforms alternatives on large-scale problems. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Matrix completion discriminant analysis", "paper_id": "WOS:000361164900009"}