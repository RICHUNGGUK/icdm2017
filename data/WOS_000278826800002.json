{"auto_keywords": [{"score": 0.04327832021381773, "phrase": "intrinsic_dimensionality"}, {"score": 0.00481495049065317, "phrase": "data_compression_and"}, {"score": 0.0047310525657970615, "phrase": "local_principal_curves"}, {"score": 0.004594443767709888, "phrase": "principal_curves"}, {"score": 0.00440976345264104, "phrase": "multivariate_regression_modelling"}, {"score": 0.004332894955218135, "phrase": "predictor_spaces"}, {"score": 0.004282391936827106, "phrase": "complex_dependency_patterns"}, {"score": 0.004207734323806386, "phrase": "involved_variables"}, {"score": 0.0038534477978822133, "phrase": "high_redundancy"}, {"score": 0.0034673190692473903, "phrase": "high-dimensional_predictor_space"}, {"score": 0.0034068225125064586, "phrase": "low-dimensional_manifold"}, {"score": 0.00304737045343781, "phrase": "compressed_predictors"}, {"score": 0.002994178996584381, "phrase": "regression_problem"}, {"score": 0.0028234703730349916, "phrase": "predictor_space"}, {"score": 0.00270978310478061, "phrase": "local_principal_curve_algorithm"}, {"score": 0.0025854347094662247, "phrase": "novel_algorithm"}, {"score": 0.00249592321829865, "phrase": "local_principal_surfaces"}, {"score": 0.0022192891418394514, "phrase": "arbitrary_dimension"}, {"score": 0.002129877319760485, "phrase": "novel_techniques"}, {"score": 0.0021049977753042253, "phrase": "astrophysical_and_oceanographic_data_examples"}], "paper_keywords": ["Dimension reduction", " smoothing", " Iocalized PCA", " mean shift"], "paper_abstract": "We consider principal curves and surfaces in the context of multivariate regression modelling. For predictor spaces featuring complex dependency patterns between the involved variables, the intrinsic dimensionality of the data tends to be very small due to the high redundancy induced by the dependencies. In situations of this type, it is useful to approximate the high-dimensional predictor space through a low-dimensional manifold (i.e., a curve or a surface), and use the projections onto the manifold as compressed predictors in the regression problem. In the case that the intrinsic dimensionality of the predictor space equals one, we use the local principal curve algorithm for the the compression step. We provide a novel algorithm which extends this idea to local principal surfaces, thus covering cases of an intrinsic dimensionality equal to two, which is in principle extendible to manifolds of arbitrary dimension. We motivate and apply the novel techniques using astrophysical and oceanographic data examples.", "paper_title": "DATA COMPRESSION AND REGRESSION THROUGH LOCAL PRINCIPAL CURVES AND SURFACES", "paper_id": "WOS:000278826800002"}