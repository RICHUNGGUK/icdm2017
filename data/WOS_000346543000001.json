{"auto_keywords": [{"score": 0.041554759596607996, "phrase": "proposed_algorithm"}, {"score": 0.03507428260415787, "phrase": "exact_mst_algorithm"}, {"score": 0.00481495049065317, "phrase": "tree_algorithm"}, {"score": 0.004575354958479747, "phrase": "data_mining"}, {"score": 0.004546252387071551, "phrase": "pattern_recognition"}, {"score": 0.004517334089033334, "phrase": "machine_learning"}, {"score": 0.004389451298343287, "phrase": "traditional_mst_algorithms"}, {"score": 0.004347629793717084, "phrase": "large_dataset"}, {"score": 0.004306205029641728, "phrase": "time_complexity"}, {"score": 0.004118026552723285, "phrase": "fast_mst"}, {"score": 0.004027031316965272, "phrase": "complete_graph"}, {"score": 0.004001402461081236, "phrase": "n_points"}, {"score": 0.003925486550801027, "phrase": "divide-and-conquer_scheme"}, {"score": 0.003838729434721053, "phrase": "theoretical_time_complexity"}, {"score": 0.0037180939187449937, "phrase": "conventional_mst_algorithms"}, {"score": 0.003578307035551443, "phrase": "first_stage"}, {"score": 0.003454856391312304, "phrase": "k-means"}, {"score": 0.003367611042980526, "phrase": "root_n_clusters"}, {"score": 0.003240958183116486, "phrase": "produced_root_n_msts"}, {"score": 0.003169281681417552, "phrase": "proposed_criterion"}, {"score": 0.0031290354217563938, "phrase": "approximate_mst."}, {"score": 0.0030991854367616737, "phrase": "second_stage"}, {"score": 0.0028068790615886755, "phrase": "neighboring_boundaries"}, {"score": 0.0027800937731919276, "phrase": "neighboring_pair"}, {"score": 0.002324381111188894, "phrase": "experimental_results"}, {"score": 0.0022948394240866555, "phrase": "proposed_approximate_mst_algorithm"}, {"score": 0.0022084431489676993, "phrase": "exact_mst"}, {"score": 0.002180371753380285, "phrase": "practical_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Minimum spanning tree", " Clustering", " Manifold learning", " K-means"], "paper_abstract": "Minimum spanning trees (MSTs) have long been used in data mining, pattern recognition and machine learning. However, it is difficult to apply traditional MST algorithms to a large dataset since the time complexity of the algorithms is quadratic. In this paper, we present a fast MST (FMST) algorithm on the complete graph of N points. The proposed algorithm employs a divide-and-conquer scheme to produce an approximate MST with theoretical time complexity of O(N-1.5), which is faster than the conventional MST algorithms with O(N-2). It consists of two stages. In the first stage, called the divide-and-conquer stage, K-means is employed to partition a dataset into root N clusters. Then an exact MST algorithm is applied to each cluster and the produced root N MSTs are connected in terms of a proposed criterion to form an approximate MST. In the second stage, called the refinement stage, the clusters produced in the first stage form root N - 1 neighboring pairs, and the dataset is repartitioned into root N - 1 clusters with the purpose of partitioning the neighboring boundaries of a neighboring pair into a cluster. With the root N - 1 clusters, another approximate MST is constructed. Finally, the two approximate MSTs are combined into a graph and a more accurate MST is generated from it. The proposed algorithm can be regarded as a framework, since any exact MST algorithm can be incorporated into the framework to reduce its running time. Experimental results show that the proposed approximate MST algorithm is computationally efficient, and the approximation is close to the exact MST so that in practical applications the performance does not suffer. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "A fast minimum spanning tree algorithm based on K-means", "paper_id": "WOS:000346543000001"}