{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dynamic_integration"}, {"score": 0.004442032546224076, "phrase": "novel_method"}, {"score": 0.004266501496765747, "phrase": "ensemble_meta-techniques"}, {"score": 0.004016072233242585, "phrase": "regression_problems"}, {"score": 0.0038186039088445524, "phrase": "introductory_experimental_analysis"}, {"score": 0.0033832583769880576, "phrase": "single_model_linear_regression"}, {"score": 0.0030895394261534776, "phrase": "dynamic_weighting"}, {"score": 0.0027370835853738626, "phrase": "base_models"}, {"score": 0.0026023381988430666, "phrase": "linear_regression"}, {"score": 0.0023762535034673017, "phrase": "strongest_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["ensemble learning", " stacking", " regression"], "paper_abstract": "In this paper we present a novel method that fuses the ensemble meta-techniques of stacking and dynamic integration for regression problems. We detail an introductory experimental analysis of the technique referred to as wMetaComb and compare its performance to single model linear regression, stacking and the dynamic integration technique of dynamic weighting with selection, where in the case of the ensembles the base models were also created using linear regression. The evaluation showed that wMetaComb returned the strongest performance. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "A weighted combination of stacking and dynamic integration", "paper_id": "WOS:000243766700021"}