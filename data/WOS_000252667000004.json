{"auto_keywords": [{"score": 0.04019924384798351, "phrase": "engine_sound"}, {"score": 0.010613920761525746, "phrase": "sound"}, {"score": 0.0047292449487169345, "phrase": "virtual_environments"}, {"score": 0.004686963264680882, "phrase": "linear_vection"}, {"score": 0.00450130420152996, "phrase": "self-motion_illusion"}, {"score": 0.004401342842183475, "phrase": "virtual_reality_applications"}, {"score": 0.004208002469225673, "phrase": "auditory_motion_cues"}, {"score": 0.004114527599108734, "phrase": "contextual_information"}, {"score": 0.004023120753104693, "phrase": "virtual_environment"}, {"score": 0.0034685354330506605, "phrase": "auditory_scene"}, {"score": 0.0034220655476652683, "phrase": "subjective_ratings"}, {"score": 0.0033914308417007316, "phrase": "vection_intensity"}, {"score": 0.0033160345607565565, "phrase": "vection_onset_times"}, {"score": 0.003198860258228543, "phrase": "individual_imagery_vividness_scores"}, {"score": 0.003113696267229798, "phrase": "vection_measures"}, {"score": 0.0030307927228223883, "phrase": "higher_kinesthetic_imagery"}, {"score": 0.002910545717767559, "phrase": "lower_kinesthetic_imagery_scores"}, {"score": 0.002845809662579165, "phrase": "vection_sensation"}, {"score": 0.00277001889871322, "phrase": "high_correlation"}, {"score": 0.0027452053065200152, "phrase": "participants'_kinesthetic_imagery_vividness_scores"}, {"score": 0.0026720866990543744, "phrase": "first_person_perspective"}, {"score": 0.002398529964696261, "phrase": "specific_type"}, {"score": 0.0023770362063833903, "phrase": "acoustic_body-centered_feedback"}, {"score": 0.0022419349154472806, "phrase": "better_understanding"}, {"score": 0.0021920373388760314, "phrase": "self-representation_sounds"}, {"score": 0.0021049977753042253, "phrase": "virtual_and_augmented_environments"}], "paper_keywords": [""], "paper_abstract": "Sound is an important, but often neglected, component for creating a self-motion illusion (vection) in Virtual Reality applications, for example, motion simulators. Apart from auditory motion cues, sound can provide contextual information representing self-motion in a virtual environment. In two experiments we investigated the benefits of hearing an engine sound when presenting auditory (Experiment 1) or auditory-vibrotactile (Experiment 2) virtual environments inducing linear vection. The addition of the engine sound to the auditory scene significantly enhanced subjective ratings of vection intensity in Experiment 1 and vection onset times but not subjective ratings in Experiment 2. Further analysis using individual imagery vividness scores showed that this disparity between vection measures was created by participants with higher kinesthetic imagery. On the other hand, for participants with lower kinesthetic imagery scores, the engine sound enhanced vection sensation in both experiments. A high correlation with participants' kinesthetic imagery vividness scores suggests the influence of a first person perspective in the perception of the engine sound. We hypothesize that self-motion sounds (e.g., the sound of footsteps, engine sound) represent a specific type of acoustic body-centered feedback in virtual environments. Therefore, the results may contribute to a better understanding of the role of self-representation sounds (sonic self-avatars), in virtual and augmented environments.", "paper_title": "Sound representing self-motion in virtual environments enhances linear vection", "paper_id": "WOS:000252667000004"}