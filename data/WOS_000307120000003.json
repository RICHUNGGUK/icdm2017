{"auto_keywords": [{"score": 0.048846087603041044, "phrase": "burn"}, {"score": 0.00481495049065317, "phrase": "workload_burstiness"}, {"score": 0.0047732596509542135, "phrase": "customized_service_benchmarks"}, {"score": 0.00457013354092966, "phrase": "customized_benchmarks"}, {"score": 0.0045108906244892165, "phrase": "multitier_applications"}, {"score": 0.0044718206943536514, "phrase": "time-varying_resource_usage_conditions"}, {"score": 0.004318881178805575, "phrase": "test_workloads"}, {"score": 0.004099183062034004, "phrase": "multitier_application"}, {"score": 0.004046020290832207, "phrase": "controlled_burstiness"}, {"score": 0.004010960493946656, "phrase": "resource_consumption"}, {"score": 0.0038401488612789963, "phrase": "controlled_way"}, {"score": 0.003757480190200645, "phrase": "software_services"}, {"score": 0.003724911315685105, "phrase": "sudden_changes"}, {"score": 0.00367658459781873, "phrase": "workload_characteristics"}, {"score": 0.003613119346373748, "phrase": "usage_levels"}, {"score": 0.0034441627435203804, "phrase": "model-based_technique"}, {"score": 0.003384695931421288, "phrase": "markov_models"}, {"score": 0.003340768341189764, "phrase": "resource_consumption_patterns"}, {"score": 0.0032974089700312423, "phrase": "test_workload"}, {"score": 0.0031568884810273226, "phrase": "optimization_program"}, {"score": 0.0030754582519753474, "phrase": "target_request_mix"}, {"score": 0.003048782877550259, "phrase": "user-specified_levels"}, {"score": 0.0029830992938695033, "phrase": "different_resources"}, {"score": 0.0029188509899068845, "phrase": "burstiness"}, {"score": 0.002855934865505357, "phrase": "novel_metric"}, {"score": 0.0027581067089091434, "phrase": "natural_way"}, {"score": 0.0026175952455594277, "phrase": "long_periods"}, {"score": 0.0025611773887867255, "phrase": "multiple_requests"}, {"score": 0.0025279105573394727, "phrase": "case_study"}, {"score": 0.0024842242921857705, "phrase": "three-tier_application_testbed"}, {"score": 0.002357632753637638, "phrase": "session_service_demands"}, {"score": 0.0023270035715132866, "phrase": "fine-grained_scale"}, {"score": 0.0021702292394814144, "phrase": "throughput_degradations"}, {"score": 0.002132711053003407, "phrase": "nonbursty_workloads"}], "paper_keywords": ["Benchmarking", " performance", " burstiness", " bottleneck migration", " overdemand"], "paper_abstract": "We introduce BURN, a methodology to create customized benchmarks for testing multitier applications under time-varying resource usage conditions. Starting from a set of preexisting test workloads, BURN finds a policy that interleaves their execution to stress the multitier application and generate controlled burstiness in resource consumption. This is useful to study, in a controlled way, the robustness of software services to sudden changes in the workload characteristics and in the usage levels of the resources. The problem is tackled by a model-based technique which first generates Markov models to describe resource consumption patterns of each test workload. Then, a policy is generated using an optimization program which sets as constraints a target request mix and user-specified levels of burstiness at the different resources in the system. Burstiness is quantified using a novel metric called overdemand, which describes in a natural way the tendency of a workload to keep a resource congested for long periods of time and across multiple requests. A case study based on a three-tier application testbed shows that our method is able to control and predict burstiness for session service demands at a fine-grained scale. Furthermore, experiments demonstrate that for any given request mix our approach can expose latency and throughput degradations not found with nonbursty workloads having the same request mix.", "paper_title": "BURN: Enabling Workload Burstiness in Customized Service Benchmarks", "paper_id": "WOS:000307120000003"}