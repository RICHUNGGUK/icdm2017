{"auto_keywords": [{"score": 0.04972867160744286, "phrase": "heterogeneous_clusters"}, {"score": 0.029420333683948755, "phrase": "tarazu"}, {"score": 0.015492998098236694, "phrase": "data_center-scale_clusters"}, {"score": 0.014671460350533665, "phrase": "mapreduce"}, {"score": 0.012500383673104618, "phrase": "hadoop"}, {"score": 0.011878400228813065, "phrase": "poor_performance"}, {"score": 0.009233346024045191, "phrase": "reduce_computation"}, {"score": 0.00481495049065317, "phrase": "optimizing_mapreduce"}, {"score": 0.004675565200598801, "phrase": "heterogeneous_hardware"}, {"score": 0.0045736684402340275, "phrase": "differentiated_price-performance"}, {"score": 0.004441236717408874, "phrase": "well-known_programming_model"}, {"score": 0.0041418132064539185, "phrase": "homogeneous_clusters"}, {"score": 0.00373682045166829, "phrase": "homogeneous_sub-clusters"}, {"score": 0.0035887342563437935, "phrase": "previously_proposed_optimizations"}, {"score": 0.0035233696341819437, "phrase": "straggler_tasks"}, {"score": 0.0034212450542713607, "phrase": "mapreduce's_poor_performance"}, {"score": 0.003030247482854539, "phrase": "excessive_and_bursty_network_communication"}, {"score": 0.002846549461929597, "phrase": "load_imbalance"}, {"score": 0.002693708217226793, "phrase": "mapreduce_performance"}, {"score": 0.00244792069601419, "phrase": "map_computation"}, {"score": 0.0024300378400439666, "phrase": "cas"}, {"score": 0.0023944552329463035, "phrase": "bursty_network_traffic"}, {"score": 0.0023421547766273015, "phrase": "load_balancing"}, {"score": 0.0021205548157547495, "phrase": "straightforward_tuning"}, {"score": 0.0021049977753042253, "phrase": "hardware_heterogeneity"}], "paper_keywords": ["Design", " Measurement", " Performance", " Heterogeneous clusters", " MapReduce", " Shuffle", " Load imbalance", " Cluster Scheduling"], "paper_abstract": "Data center-scale clusters are evolving towards heterogeneous hardware for power, cost, differentiated price-performance, and other reasons. MapReduce is a well-known programming model to process large amount of data on data center-scale clusters. Most MapReduce implementations have been designed and optimized for homogeneous clusters. Unfortunately, these implementations perform poorly on heterogeneous clusters (e.g., on a 90-node cluster that contains 10 Xeon-based servers and 80 Atom-based servers, Hadoop performs worse than on 10-node Xeon-only or 80node Atom-only homogeneous sub-clusters for many of our benchmarks). This poor performance remains despite previously proposed optimizations related to management of straggler tasks. In this paper, we address MapReduce's poor performance on heterogeneous clusters. Our first contribution is that the poor performance is due to two key factors: (1) the non-intuitive effect that MapReduce's built-in load balancing results in excessive and bursty network communication during the Map phase, and (2) the intuitive effect that the heterogeneity amplifies load imbalance in the Reduce computation. Our second contribution is Tarazu, a suite of optimizations to improve MapReduce performance on heterogeneous clusters. Tarazu consists of (1) Communication-Aware Load Balancing of Map computation (CALB) across the nodes, (2) Communication-Aware Scheduling of Map computation (CAS) to avoid bursty network traffic and (3) Predictive Load Balancing of Reduce computation (PLB) across the nodes. Using the above 90-node cluster, we show that Tarazu significantly improves performance over a baseline of Hadoop with straightforward tuning for hardware heterogeneity.", "paper_title": "Tarazu: Optimizing MapReduce On Heterogeneous Clusters", "paper_id": "WOS:000209339300006"}