{"auto_keywords": [{"score": 0.048778468893892986, "phrase": "kernel_quadratic_programming_feature_selection"}, {"score": 0.00481495049065317, "phrase": "kernel_fisher_discriminant_analysis"}, {"score": 0.004372442291178139, "phrase": "quadratic_programming_feature_selection"}, {"score": 0.003970439654470374, "phrase": "kernel_space"}, {"score": 0.003555902292752528, "phrase": "quadratic_objective_function"}, {"score": 0.0034591919339528794, "phrase": "qpfs."}, {"score": 0.0026616868981501006, "phrase": "new_interpretation"}, {"score": 0.0025537472239953807, "phrase": "discriminant_analysis"}, {"score": 0.0023507916951658455, "phrase": "computational_advantages"}, {"score": 0.002286781334850213, "phrase": "highly_unbalanced_datasets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Kernel Fisher discriminant", " Quadratic Programming Feature Selection", " Feature selection", " Kernel methods"], "paper_abstract": "We reformulate the Quadratic Programming Feature Selection (QPFS) method in a Kernel space to obtain a vector which maximizes the quadratic objective function of QPFS. We demonstrate that the vector obtained by Kernel Quadratic Programming Feature Selection is equivalent to the Kernel Fisher vector and, therefore, a new interpretation of the Kernel Fisher discriminant analysis is given which provides some computational advantages for highly unbalanced datasets. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "On the equivalence of Kernel Fisher discriminant analysis and Kernel Quadratic Programming Feature Selection", "paper_id": "WOS:000293050700009"}