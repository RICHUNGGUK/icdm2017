{"auto_keywords": [{"score": 0.037702637270507856, "phrase": "cr_networks"}, {"score": 0.031947736897611906, "phrase": "available_cooperators"}, {"score": 0.00481495049065317, "phrase": "cognitive_radio_networks"}, {"score": 0.004748740786945996, "phrase": "primary_objective"}, {"score": 0.004661868629458321, "phrase": "cognitive_radio"}, {"score": 0.004620221438586091, "phrase": "cr"}, {"score": 0.004472146692254812, "phrase": "spectrum_access_efficiency"}, {"score": 0.004390312150344245, "phrase": "network_performance"}, {"score": 0.004309968592440261, "phrase": "byzantine_adversaries"}, {"score": 0.004270347498153512, "phrase": "unintentional_erroneous_conduct"}, {"score": 0.004153647187175639, "phrase": "destructive_behavior"}, {"score": 0.0041154571996523505, "phrase": "cr_users"}, {"score": 0.003839962121679795, "phrase": "dynamic_solution"}, {"score": 0.0038046452381676967, "phrase": "cooperation_reliability"}, {"score": 0.0036665842836420223, "phrase": "cr_network"}, {"score": 0.0028172726995962147, "phrase": "cr_user"}, {"score": 0.002702415623060517, "phrase": "cooperators_behavior"}, {"score": 0.0026651772919894534, "phrase": "reinforcement_learning"}, {"score": 0.00264070055763654, "phrase": "rl"}, {"score": 0.0025802660239538353, "phrase": "rl_algorithm"}, {"score": 0.002266765479420981, "phrase": "simulation_results"}, {"score": 0.0022355167967736326, "phrase": "learning_capabilities"}, {"score": 0.002204697943520258, "phrase": "proposed_solution"}, {"score": 0.0021843879253500894, "phrase": "especially_its_reliable_behavior"}, {"score": 0.002164264600379492, "phrase": "highly_unreliable_conditions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Cognitive radio networks", " Cooperation", " Reinforcement learning", " Reliability", " Security"], "paper_abstract": "The primary objective of cooperation in cognitive radio (CR) networks is to increase the spectrum access efficiency and improve the network performance. However, Byzantine adversaries or unintentional erroneous conduct in cooperation can lead to destructive behavior of CR users that can decrease their own and others' performances. This work presents a dynamic solution for cooperation reliability in conditions with constraints typical for a CR network. Specifically, in CR networks, the information on the success of cooperation can be limited only to cases with interference; when malicious, cooperators can be completely non-correlated and can alter behavior; and the set of available cooperators can dynamically change in time. In order to face these challenges, each CR user autonomously decides with whom to cooperate by learning cooperators behavior with a reinforcement learning (RL) algorithm. This RL algorithm determines the suitability of the available cooperators, and selects the most appropriate ones to cooperate with the objective to increase the efficiency of spectrum access in CR networks. The simulation results demonstrate the learning capabilities of the proposed solution and especially its reliable behavior under highly unreliable conditions. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Dynamic cooperator selection in cognitive radio networks", "paper_id": "WOS:000303075200006"}