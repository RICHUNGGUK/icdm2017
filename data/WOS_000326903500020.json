{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "human_action_recognition"}, {"score": 0.00476697427418509, "phrase": "motion_capture"}, {"score": 0.004625881588444304, "phrase": "challenging_problem"}, {"score": 0.004466519142879166, "phrase": "video_surveillance"}, {"score": 0.004122490120202936, "phrase": "novel_framework"}, {"score": 0.004060986196931943, "phrase": "streamed_actions"}, {"score": 0.0038239757564863057, "phrase": "completed_activities"}, {"score": 0.0036921366375716005, "phrase": "early_recognition"}, {"score": 0.0036553070575015344, "phrase": "ongoing_activities"}, {"score": 0.0036007478932719417, "phrase": "proposed_method"}, {"score": 0.003407549468745519, "phrase": "action_poses"}, {"score": 0.003339886795391701, "phrase": "mocap_data"}, {"score": 0.0032246835734680377, "phrase": "hausdorff_distance"}, {"score": 0.0030823667846259836, "phrase": "bhattacharyya_distance"}, {"score": 0.0030060256866508606, "phrase": "dynamic_time"}, {"score": 0.002719055901632759, "phrase": "stretching_flexibility"}, {"score": 0.002665027876903161, "phrase": "possible_action_length_changes"}, {"score": 0.0024717881264735477, "phrase": "large_datasets"}, {"score": 0.0022133711375320266, "phrase": "excellent_recognition_rates"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Human action recognition", " Histogram", " Ongoing recognition", " Human-computer interaction"], "paper_abstract": "Ongoing human action recognition is a challenging problem that has many applications, such as video surveillance, patient monitoring, human-computer interaction, etc. This paper presents a novel framework for recognizing streamed actions using Motion Capture (MoCap) data. Unlike the after-the-fact classification of completed activities, this work aims at achieving early recognition of ongoing activities. The proposed method is time efficient as it is based on histograms of action poses, extracted from MoCap data, that are computed according to Hausdorff distance. The histograms are then compared with the Bhattacharyya distance and warped by a dynamic time warping process to achieve their optimal alignment. This process, implemented by our dynamic programming-based solution, has the advantage of allowing some stretching flexibility to accommodate for possible action length changes. We have shown the success and effectiveness of our solution by testing it on large datasets and comparing it with several state-of-the-art methods. In particular, we were able to achieve excellent recognition rates that have outperformed many well known methods. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Ongoing human action recognition with motion capture", "paper_id": "WOS:000326903500020"}