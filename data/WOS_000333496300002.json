{"auto_keywords": [{"score": 0.049038638823551965, "phrase": "glottal_source_analysis"}, {"score": 0.00481495049065317, "phrase": "context-sensitive_glottal_source_processing"}, {"score": 0.004547564208690591, "phrase": "phonetic_properties"}, {"score": 0.00416478405812793, "phrase": "vocal_tract_spectrum"}, {"score": 0.004128317208406523, "phrase": "aperiodic_noise"}, {"score": 0.0040385352882334235, "phrase": "negative_effect"}, {"score": 0.004003169429008801, "phrase": "glottal_inverse_filtering"}, {"score": 0.003633927813203731, "phrase": "binary_feature_extractors"}, {"score": 0.003586278948128509, "phrase": "phonetic_classes"}, {"score": 0.003477505397536663, "phrase": "voice_quality_classification"}, {"score": 0.0034018288705284427, "phrase": "feature_data"}, {"score": 0.0031565959573536194, "phrase": "classification_accuracy"}, {"score": 0.003101503914610488, "phrase": "phonetic_feature_extraction"}, {"score": 0.00307431840409833, "phrase": "classification_algorithms"}, {"score": 0.00303398491761013, "phrase": "artificial_neural_networks"}, {"score": 0.002967931416941965, "phrase": "gaussian_mixture"}, {"score": 0.002890557197908352, "phrase": "support_vector_machines"}, {"score": 0.002753891109273246, "phrase": "discriminative_classifiers"}, {"score": 0.0026352496813713292, "phrase": "better_results"}, {"score": 0.0025892330566358503, "phrase": "generative_learning_algorithm"}, {"score": 0.002298902547676131, "phrase": "syllabic_regions"}, {"score": 0.002248816575548875, "phrase": "best_classification"}, {"score": 0.0022290883852844057, "phrase": "voice_quality"}, {"score": 0.0021901485584955487, "phrase": "glottal_source_parameter_data"}, {"score": 0.0021613897794439227, "phrase": "detected_syllabic_regions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Voice quality", " Phonation type", " Glottal source", " Expressive speech", " Speech synthesis"], "paper_abstract": "The effectiveness of glottal source analysis is known to be dependent on the phonetic properties of its concomitant supraglottal features. Phonetic classes like nasals and fricatives are particularly problematic. Their acoustic characteristics, including zeros in the vocal tract spectrum and aperiodic noise, can have a negative effect on glottal inverse filtering, a necessary pre-requisite to glottal source analysis. In this paper, we first describe and evaluate a set of binary feature extractors, for phonetic classes with relevance for glottal source analysis. As voice quality classification is typically achieved using feature data derived by glottal source analysis, we then investigate the effect of removing data from certain detected phonetic regions on the classification accuracy. For the phonetic feature extraction, classification algorithms based on Artificial Neural Networks (ANNs), Gaussian Mixture Models (GMMs) and Support Vector Machines (SVMs) are compared. Experiments demonstrate that the discriminative classifiers (i.e. ANNs and SVMs) in general give better results compared with the generative learning algorithm (i.e. GMMs). This accuracy generally decreases according to the sparseness of the feature (e.g., accuracy is lower for nasals compared to syllabic regions). We find best classification of voice quality when just using glottal source parameter data derived within detected syllabic regions. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Phonetic feature extraction for context-sensitive glottal source processing", "paper_id": "WOS:000333496300002"}