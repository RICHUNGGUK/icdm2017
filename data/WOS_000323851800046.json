{"auto_keywords": [{"score": 0.0242524688704516, "phrase": "irls"}, {"score": 0.004671342094877447, "phrase": "compressed_sensing"}, {"score": 0.004492950096237056, "phrase": "signal_processing"}, {"score": 0.004454237726525018, "phrase": "machine_learning"}, {"score": 0.004396790930873782, "phrase": "pattern_recognition"}, {"score": 0.004302680891412643, "phrase": "sparse_representation"}, {"score": 0.004247180402119585, "phrase": "vector_w.r.t"}, {"score": 0.003962998498942108, "phrase": "computational_difficulty"}, {"score": 0.00374610869916551, "phrase": "sparsest_solution"}, {"score": 0.0037138072936226, "phrase": "strong_incoherence_conditions"}, {"score": 0.0032471982781283374, "phrase": "noise_ratio"}, {"score": 0.00319141242685261, "phrase": "successful_recovery"}, {"score": 0.002990592465417758, "phrase": "better_alternative"}, {"score": 0.002814545518256278, "phrase": "typical_algorithms"}, {"score": 0.0025474814283429213, "phrase": "general_iteratively_reweighted_least_squares"}, {"score": 0.002335889180060105, "phrase": "comprehensive_comparison"}, {"score": 0.0022174469839432013, "phrase": "best_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Compressed sensing", " Sparse representation", " l(1) minimization", " l(p) minimization"], "paper_abstract": "Recently, compressed sensing has been widely applied to various areas such as signal processing, machine learning, and pattern recognition. To find the sparse representation of a vector w.r.t a dictionary, an l(1) minimization problem, which is convex, is usually solved in order to overcome the computational difficulty. However, to guarantee that the l(1) minimizer is close to the sparsest solution, strong incoherence conditions should be imposed. In comparison, nonconvex minimization problems such as those with the l(p) (0 < p < 1) penalties require much weaker incoherence conditions and smaller signal to noise ratio to guarantee a successful recovery. Hence the l(p) (0 < p < 1) regularization serves as a better alternative to the popular l(1) one. In this paper, we review some typical algorithms, Iteratively Reweighted l(1) minimization (IRL1), Iteratively Reweighted Least Squares (IRLS) (and its general form General Iteratively Reweighted Least Squares (GIRLS)), and Iteratively Thresholding Method (ITM), for l(p) minimization and do comprehensive comparison among them, in which IRLS is identified as having the best performance and being the fastest as well. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A comparison of typical l(p) minimization algorithms", "paper_id": "WOS:000323851800046"}