{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-modality_medical_images"}, {"score": 0.004658426838467567, "phrase": "multi-modality_medical_volumes"}, {"score": 0.004244040105917499, "phrase": "complementary_functional_and_anatomical_features"}, {"score": 0.004193316635088688, "phrase": "spatial_relationships"}, {"score": 0.004130760425485278, "phrase": "improved_cancer_diagnosis"}, {"score": 0.00400842252537852, "phrase": "multi-modality_volume_retrieval"}, {"score": 0.003913155833767365, "phrase": "complementary_geometric_and_topologic_attributes"}, {"score": 0.003740568332108757, "phrase": "tumour_staging"}, {"score": 0.0035648266669315943, "phrase": "graph-based_methods"}, {"score": 0.00349055018979517, "phrase": "spatial_similarity"}, {"score": 0.003387108469185429, "phrase": "complete_graph"}, {"score": 0.003326515807982512, "phrase": "tumour-anatomy_relationships"}, {"score": 0.003276848046269042, "phrase": "new_graph_structure"}, {"score": 0.0032474028991861543, "phrase": "complete_graphs"}, {"score": 0.003122824878906245, "phrase": "spatial_proximity"}, {"score": 0.0030030115662983956, "phrase": "tumour_localisation"}, {"score": 0.0028964869166407054, "phrase": "different_feature_sets"}, {"score": 0.0028791027911595976, "phrase": "graph_elements"}, {"score": 0.002861822702206142, "phrase": "different_imaging_modalities"}, {"score": 0.002776961266279729, "phrase": "related_organs"}, {"score": 0.0027354763093906547, "phrase": "patient-specific_anatomical_variations"}, {"score": 0.002694609420649617, "phrase": "related_anatomical_structures"}, {"score": 0.00267038214449389, "phrase": "discrimination_potential"}, {"score": 0.0025989960809479104, "phrase": "similar_images"}, {"score": 0.002575626245702045, "phrase": "tumour_location"}, {"score": 0.002506766880001808, "phrase": "clinical_pet-ct_volumes"}, {"score": 0.0024324082074887858, "phrase": "multi-modality_images"}, {"score": 0.0022289812518790824, "phrase": "visual_words"}, {"score": 0.0022089311733832985, "phrase": "scale-_invariant_feature_transform"}, {"score": 0.002195688725791208, "phrase": "sift"}, {"score": 0.002175913488493802, "phrase": "relational_matrices"}, {"score": 0.0021563397322290445, "phrase": "spatial_arrangements"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Content-based image retrieval", " Graph similarity", " Multi-modality", " PET-CT"], "paper_abstract": "In this paper, we address the retrieval of multi-modality medical volumes, which consist of two different imaging modalities, acquired sequentially, from the same scanner. One such example, positron emission tomography and computed tomography (PET-CT), provides physicians with complementary functional and anatomical features as well as spatial relationships and has led to improved cancer diagnosis, localisation, and staging. The challenge of multi-modality volume retrieval for cancer patients lies in representing the complementary geometric and topologic attributes between tumours and organs. These attributes and relationships, which are used for tumour staging and classification, can be formulated as a graph. It has been demonstrated that graph-based methods have high accuracy for retrieval by spatial similarity. However, naively representing all relationships on a complete graph obscures the structure of the tumour-anatomy relationships. We propose a new graph structure derived from complete graphs that structurally constrains the edges connected to tumour vertices based upon the spatial proximity of tumours and organs. This enables retrieval on the basis of tumour localisation. We also present a similarity matching algorithm that accounts for different feature sets for graph elements from different imaging modalities. Our method emphasises the relationships between a tumour and related organs, while still modelling patient-specific anatomical variations. Constraining tumours to related anatomical structures improves the discrimination potential of graphs, making it easier to retrieve similar images based on tumour location. We evaluated our retrieval methodology on a dataset of clinical PET-CT volumes. Our results showed that our method enabled the retrieval of multi-modality images using spatial features. Our graph-based retrieval algorithm achieved a higher precision than several other retrieval techniques: gray-level histograms as well as state-of-the-art methods such as visual words using the scale- invariant feature transform (SIFT) and relational matrices representing the spatial arrangements of objects. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A graph-based approach for the retrieval of multi-modality medical images", "paper_id": "WOS:000332194600007"}