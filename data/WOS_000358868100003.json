{"auto_keywords": [{"score": 0.02926876360393359, "phrase": "linear_interpolation"}, {"score": 0.00481495049065317, "phrase": "convex_optimization"}, {"score": 0.004615202066192795, "phrase": "nonsmooth_convex_function"}, {"score": 0.004400329132129292, "phrase": "nonsmooth_convex_constraint"}, {"score": 0.004217708394188058, "phrase": "derivative-free_optimization"}, {"score": 0.004042635935882651, "phrase": "objective_and_constraint_functions"}, {"score": 0.0038748022659578865, "phrase": "function_values"}, {"score": 0.0036359780843400625, "phrase": "dfo_adaptation"}, {"score": 0.003578600071301459, "phrase": "-comirror_algorithm"}, {"score": 0.0034482025128821548, "phrase": "comirror_algorithm"}, {"score": 0.0033579708256295847, "phrase": "convex_problems"}, {"score": 0.0033225603248736163, "phrase": "oper"}, {"score": 0.0032553318692364118, "phrase": "lett"}, {"score": 0.002988101395789399, "phrase": "algorithmic_convergence"}, {"score": 0.0026447893350441502, "phrase": "sampling_radii"}, {"score": 0.0025214217930287003, "phrase": "new_algorithm"}, {"score": 0.0024423826953133844, "phrase": "original_gradient-based_algorithm"}, {"score": 0.002378408229095287, "phrase": "novel_global_rate-of-convergence_result"}, {"score": 0.0023038418282549274, "phrase": "nonsmooth_convex_constraints"}, {"score": 0.0022434880661725493, "phrase": "numerical_testing"}, {"score": 0.002196342933346204, "phrase": "practical_feasibility"}], "paper_keywords": ["convex optimization", " derivative-free optimization", " lower-C-2", " approximate subgradient", " Non-Euclidean projected subgradient", " Bregman distance"], "paper_abstract": "We consider the minimization of a nonsmooth convex function over a compact convex set subject to a nonsmooth convex constraint. We work in the setting of derivative-free optimization (DFO), assuming that the objective and constraint functions are available through a black-box that provides function values for lower-C-2 representation of the functions. Our approach is based on a DFO adaptation of the -comirror algorithm [ Beck et al. The CoMirror algorithm for solving nonsmooth constrained convex problems, Oper. Res. Lett. 38( 6) ( 2010), pp. 493-498]. Algorithmic convergence hinges on the ability to accurately approximate subgradients of lower-C-2 functions, which we prove is possible through linear interpolation. We show that, if the sampling radii for linear interpolation are properly selected, then the new algorithm has the same convergence rate as the original gradient-based algorithm. This provides a novel global rate-of-convergence result for nonsmooth convex DFO with nonsmooth convex constraints. We conclude with numerical testing that demonstrates the practical feasibility of the algorithm and some directions for further research.", "paper_title": "A derivative-free comirror algorithm for convex optimization", "paper_id": "WOS:000358868100003"}