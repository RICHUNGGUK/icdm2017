{"auto_keywords": [{"score": 0.004766388573192505, "phrase": "concept_similarity"}, {"score": 0.004198965651975536, "phrase": "common_communication_language"}, {"score": 0.004032002950217453, "phrase": "standard_protocol"}, {"score": 0.0038913443732432468, "phrase": "natural_language"}, {"score": 0.003551694229680741, "phrase": "imperfect_understanding"}, {"score": 0.0031284221314354065, "phrase": "ontology_o-a"}, {"score": 0.002414544068560716, "phrase": "word_comparison"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["ontology matching", " natural language", " concept similarity", " degree of understanding", " imperfect knowledge"], "paper_abstract": "Two agents previously unknown to each other cannot communicate by exchanging concepts (nodes of their own ontology): they need to use a common communication language. If they do not use a standard protocol. most likely they use a natural language. The ambiguities of it, and the different concepts the agents possess, give rise to imperfect understanding among them: How closely concepts in ontology O-A map(1) to which of O-B? Can we measure these mismatches? Given a concept from ontology O-A, a method is provided to find the most similar concept in O-B, and to measure the similarity between both concepts. The paper also gives an algorithm to gauge du(A, B), the degree of understanding that agent A has about the ontology of B. The procedures use word comparison, since no agent (except the Very Wise Creature, VWC) can measure du directly. Examples are given. (c) 2005 Published by Elsevier Ltd.", "paper_title": "Measuring the understanding between two agents through concept similarity", "paper_id": "WOS:000236048400003"}