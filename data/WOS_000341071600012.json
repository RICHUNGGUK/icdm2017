{"auto_keywords": [{"score": 0.038824379524943164, "phrase": "parallelizable_part"}, {"score": 0.03606832220914119, "phrase": "amdahl's_law"}, {"score": 0.015545326851917417, "phrase": "multithreaded_multicore_processors"}, {"score": 0.014908163153953139, "phrase": "parallel_computing"}, {"score": 0.013444430270413242, "phrase": "critical_sections"}, {"score": 0.011689391921945444, "phrase": "resource_contention"}, {"score": 0.009184861050222929, "phrase": "critical_section"}, {"score": 0.009133436943528054, "phrase": "multicore_processors"}, {"score": 0.004814951563359404, "phrase": "amdahl"}, {"score": 0.004654749973584499, "phrase": "performance_scaling_analysis"}, {"score": 0.0044998554636609955, "phrase": "thread-level_closed-queuing_network_model"}, {"score": 0.004374704085463403, "phrase": "hardware_scaling_models"}, {"score": 0.0042891660310426976, "phrase": "simultaneous_multithreading"}, {"score": 0.004265078268098042, "phrase": "smt"}, {"score": 0.004042416569959828, "phrase": "closed-form_solution"}, {"score": 0.003963349828993976, "phrase": "speedup_performance_measure"}, {"score": 0.0037990701686283672, "phrase": "multiple_dimensions"}, {"score": 0.0033742996685636687, "phrase": "strong_function"}, {"score": 0.0033552975070941416, "phrase": "workload_characteristics"}, {"score": 0.003271099035362546, "phrase": "strong_cpu-bound_workloads"}, {"score": 0.0032070701272953563, "phrase": "core_multithreading"}, {"score": 0.00302238310602767, "phrase": "core_threads"}, {"score": 0.00300535676490851, "phrase": "strong_cache_affinity"}, {"score": 0.00288067078705169, "phrase": "tight_speedup"}, {"score": 0.002816294613779422, "phrase": "memory_resource_contention"}, {"score": 0.002768955745188582, "phrase": "single-threaded_cores"}, {"score": 0.0026316476955518175, "phrase": "shared_memory"}, {"score": 0.0025947264971912616, "phrase": "sequential_term"}, {"score": 0.002417728087149033, "phrase": "sequential_part"}, {"score": 0.0023108237893935766, "phrase": "speedup_performance"}, {"score": 0.0022527762945938586, "phrase": "memory_parallelism"}, {"score": 0.002171488970077653, "phrase": "smallest_possible_number"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Amdahl's law", " Multithreaded multicore processor", " Closed queuing network", " Speedup"], "paper_abstract": "In this paper, we conduct performance scaling analysis of multithreaded multicore processors (MMPs) for parallel computing. We propose a thread-level closed-queuing network model covering a fairly large design space, accounting for hardware scaling models, coarse-grain, fine-grain, and simultaneous multithreading (SMT) cores, shared resources, including cache, memory, and critical sections. We then derive a closed-form solution for this model in terms of speedup performance measure. This solution makes it possible to analyze performance scaling properties of MMPs along multiple dimensions. In particular, we show that for the parallelizable part of the workload, the speedup, in the absence of resource contention, is no longer just a linear function of parallel processing unit counts, as predicted by Amdahl's law, but also a strong function of workload characteristics, ranging from strong memory-bound to strong CPU-bound workloads. We also find that with core multithreading, super linear speedup, higher than that predicted by Amdahl's law, may be achieved for the parallelizable part of the workload, if core threads exhibit strong cache affinity and the workload is strongly memory-bound. Then, we derive a tight speedup upper bound in the presence of both memory resource contention and critical section for multicore processors with single-threaded cores. This speedup upper bound indicates that with resource contention among threads, whether it is due to shared memory or critical section, a sequential term is guaranteed to emerge from the parallelizable part of the workload, fundamentally limiting the scalability of multicore processors for parallel computing, in addition to the sequential part of the workload, as dictated by Amdahl's law. As a result, to improve speedup performance for MMPs, one should strive to enhance memory parallelism and confine critical sections as locally as possible, e.g., to the smallest possible number of threads in the same core. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Amdahl's law for multithreaded multicore processors", "paper_id": "WOS:000341071600012"}