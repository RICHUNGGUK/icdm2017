{"auto_keywords": [{"score": 0.04839639002577896, "phrase": "active_learning"}, {"score": 0.010612387000973441, "phrase": "extreme_learning_machine"}, {"score": 0.006284771330379153, "phrase": "elm"}, {"score": 0.005256543188584107, "phrase": "al-elm"}, {"score": 0.004679134285953932, "phrase": "supervised_learning"}, {"score": 0.004530894050040479, "phrase": "training_instances"}, {"score": 0.00449859196755507, "phrase": "obvious_loss"}, {"score": 0.004450568197899267, "phrase": "classification_performance"}, {"score": 0.0036292245355184576, "phrase": "light_computational_costs"}, {"score": 0.0035393874762182486, "phrase": "strong_generalization_ability"}, {"score": 0.003464150192089816, "phrase": "support_vector_machine"}, {"score": 0.0032829570709414736, "phrase": "binary-class_and_multiclass_problems"}, {"score": 0.0032246835734680377, "phrase": "active_learning_algorithm"}, {"score": 0.003190215563286321, "phrase": "elm_classifier"}, {"score": 0.002969628818856786, "phrase": "unlabeled_instance"}, {"score": 0.002927371124061966, "phrase": "mapping_relation"}, {"score": 0.002896071795090179, "phrase": "actual_outputs"}, {"score": 0.0028142286985235977, "phrase": "approximated_membership_probability"}, {"score": 0.002686124293881678, "phrase": "equivalent_bayes_classifier"}, {"score": 0.0025273383208209922, "phrase": "classification_model"}, {"score": 0.0025003054002226965, "phrase": "learning_procedure"}, {"score": 0.002447101794397243, "phrase": "pre-designed_criterion"}, {"score": 0.002174041708084857, "phrase": "running_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Active learning", " Extreme learning machine", " Uncertainty measure", " Uncertainty sampling", " Pool-based active learning"], "paper_abstract": "It is well known that in supervised learning, active learning could effectively decrease the complexity of training instances without obvious loss of the classification performance. Generally, active learning is applied in the scenario that lots of instances are easy to be acquired, but labeling them is expensive and/or time-consuming. In this study, we try to implement active learning by using extreme learning machine (ELM) classifier based on three reasons as follows: (1) ELM has light computational costs, (2) ELM has strong generalization ability which is even comparable with support vector machine (SVM) and (3) ELM could be directly applied on both binary-class and multiclass problems. Specifically, an active learning algorithm based on ELM classifier named AL-ELM is proposed in this paper. During active learning, AL-ELM estimates the uncertainty of each unlabeled instance by creating a mapping relation between the actual outputs of the instance in ELM and the approximated membership probability of the same instance. In other words, ELM is converted as the equivalent Bayes classifier. On each iteration, those most uncertain instances are extracted and labeled to promote the quality of classification model. The learning procedure stops until it satisfies a pre-designed criterion. Experimental results on 20 benchmark data sets show that AL-ELM is better than or at least comparable to several state-of-the-art uncertainty-based active learning algorithms. Also, in contrast with several other algorithms, AL-ELM could effectively decrease the running time of learning procedure. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "AL-ELM: One uncertainty-based active learning algorithm using extreme learning machine", "paper_id": "WOS:000357751200015"}