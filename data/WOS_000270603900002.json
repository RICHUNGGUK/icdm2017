{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "instance_classifications"}, {"score": 0.0045726187330434025, "phrase": "feature_values"}, {"score": 0.004231699728933577, "phrase": "novel_method"}, {"score": 0.0039841418890102925, "phrase": "arbitrary_classifier"}, {"score": 0.003531474887552889, "phrase": "instance_level"}, {"score": 0.0034118234596993836, "phrase": "model's_prediction"}, {"score": 0.003157174936641705, "phrase": "attributes'_values"}, {"score": 0.002822434555587263, "phrase": "generated_explanations"}, {"score": 0.0027503564589458837, "phrase": "decision-making_properties"}, {"score": 0.002680114113899346, "phrase": "explained_model"}, {"score": 0.002437525632451029, "phrase": "prediction_quality"}, {"score": 0.002375253757224999, "phrase": "model_increases"}, {"score": 0.0021601997088758957, "phrase": "successful_application"}, {"score": 0.0021049977753042253, "phrase": "real-world_breast_cancer_recurrence_prediction_problem"}], "paper_keywords": ["Data mining", " Machine learning", " Knowledge discovery", " Visualization", " Classification", " Explanation"], "paper_abstract": "In this paper, we present a novel method for explaining the decisions of an arbitrary classifier, independent of the type of classifier. The method works at the instance level, decomposing the model's prediction for an instance into the contributions of the attributes' values. We use several artificial data sets and several different types of models to show that the generated explanations reflect the decision-making properties of the explained model and approach the concepts behind the data set as the prediction quality of the model increases. The usefulness of the method is justified by a successful application on a real-world breast cancer recurrence prediction problem. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Explaining instance classifications with interactions of subsets of feature values", "paper_id": "WOS:000270603900002"}