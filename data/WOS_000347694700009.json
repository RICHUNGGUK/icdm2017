{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "cluster_analysis"}, {"score": 0.004539005582217305, "phrase": "clustering_algorithms"}, {"score": 0.0041074234667687875, "phrase": "minority_clustering_tasks"}, {"score": 0.004015182362035361, "phrase": "small_fraction"}, {"score": 0.003978866233891427, "phrase": "signal_data"}, {"score": 0.0037336520904376687, "phrase": "minority_clustering"}, {"score": 0.003503497128638099, "phrase": "background_clusters"}, {"score": 0.0034560481756572632, "phrase": "supervised_learning"}, {"score": 0.00334780964309978, "phrase": "combination_methods"}, {"score": 0.0032429499567088113, "phrase": "distribution-free_learners"}, {"score": 0.003141364320497748, "phrase": "weak_individual_algorithms"}, {"score": 0.003015401937358271, "phrase": "novel_ensemble_minority_clustering_algorithm"}, {"score": 0.002988101395789399, "phrase": "ewocs"}, {"score": 0.002934237411711622, "phrase": "weak_clustering_combination"}, {"score": 0.002816556934231128, "phrase": "loose_set"}, {"score": 0.0026913130726432645, "phrase": "weak_clustering_algorithms"}, {"score": 0.0026427848602443267, "phrase": "unsupervised_procedure"}, {"score": 0.0025951294037626174, "phrase": "scaling_parameters"}, {"score": 0.0025716240685409513, "phrase": "gaussian_kernels"}, {"score": 0.002391067964886602, "phrase": "proposed_components"}, {"score": 0.0021049977753042253, "phrase": "-other_minority_clustering_approaches"}], "paper_keywords": ["Clustering", " Minority clustering", " Ensemble clustering", " Weak learning"], "paper_abstract": "Cluster analysis lies at the core of most unsupervised learning tasks. However, the majority of clustering algorithms depend on the all-in assumption, in which all objects belong to some cluster, and perform poorly on minority clustering tasks, in which a small fraction of signal data stands against a majority of noise. The approaches proposed so far for minority clustering are supervised: they require the number and distribution of the foreground and background clusters. In supervised learning and all-in clustering, combination methods have been successfully applied to obtain distribution-free learners, even from the output of weak individual algorithms. In this work, we propose a novel ensemble minority clustering algorithm, Ewocs, suitable for weak clustering combination. Its properties have been theoretically proved under a loose set of constraints. We also propose a number of weak clustering algorithms, and an unsupervised procedure to determine the scaling parameters for Gaussian kernels used within the task. We have implemented a number of approaches built from the proposed components, and evaluated them on a collection of datasets. The results show how approaches based on Ewocs are competitive with respect to-and even outperform-other minority clustering approaches in the state of the art.", "paper_title": "Unsupervised ensemble minority clustering", "paper_id": "WOS:000347694700009"}