{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "face_recognition"}, {"score": 0.04491687458404755, "phrase": "dimensionality_dilemma"}, {"score": 0.04325124255431723, "phrase": "novel_approach"}, {"score": 0.030440448768260665, "phrase": "higher_order"}, {"score": 0.004710854091689325, "phrase": "growing_interest"}, {"score": 0.004669845451682529, "phrase": "subspace_learning_techniques"}, {"score": 0.004529093447865156, "phrase": "excessive_dimension"}, {"score": 0.004470071518923524, "phrase": "data_space"}, {"score": 0.00406001734835979, "phrase": "supervised_dimensionality_reduction_problem"}, {"score": 0.00398959232769596, "phrase": "image_object"}, {"score": 0.003937573222812911, "phrase": "general_tensor"}, {"score": 0.003903269701018361, "phrase": "second_or_even_higher_order"}, {"score": 0.0037855348847339655, "phrase": "discriminant_tensor_criterion"}, {"score": 0.0037361664435836845, "phrase": "multiple_interrelated_lower_dimensional_discriminative_subspaces"}, {"score": 0.0032764307492734145, "phrase": "different_tensor_directions"}, {"score": 0.003191485583025302, "phrase": "multilinear_discriminant_analysis"}, {"score": 0.0031636612155559267, "phrase": "nida"}, {"score": 0.0030281251520610604, "phrase": "multiple_interrelated_subspaces"}, {"score": 0.002962543869356265, "phrase": "different_classes"}, {"score": 0.002898378776839434, "phrase": "classification_problems"}, {"score": 0.002823207272381655, "phrase": "nida_algorithm"}, {"score": 0.00270221723573854, "phrase": "small_sample_size_problem"}, {"score": 0.0026321198895843173, "phrase": "computational_cost"}, {"score": 0.0025977542995083624, "phrase": "learning_stage"}, {"score": 0.0025414699652861667, "phrase": "large_extent"}, {"score": 0.002497319603143104, "phrase": "reduced_data_dimensions"}, {"score": 0.002475532161577715, "phrase": "k-mode_optimization"}, {"score": 0.0024325244760735566, "phrase": "extensive_experiments"}, {"score": 0.002328238264850759, "phrase": "third-order_tensors"}, {"score": 0.0022777800735119405, "phrase": "proposed_nida_algorithm"}, {"score": 0.0021705796895687864, "phrase": "traditional_vector-based_subspace_learning_algorithms"}, {"score": 0.0021049977753042253, "phrase": "small_sample_sizes"}], "paper_keywords": ["2-D LDA", " 2-D PCA", " linear discriminant analysis (LDA)", " multilinear algebra", " principal component analysis (PCA)", " subspace learning"], "paper_abstract": "There is a growing interest in subspace learning techniques for face recognition; however, the excessive dimension of the data space often brings the algorithms into the curse of dimensionality dilemma. In this paper, we present a novel approach to solve the supervised dimensionality reduction problem by encoding an image object as a general tensor of second or even higher order. First, we propose a discriminant tensor criterion, whereby multiple interrelated lower dimensional discriminative subspaces are derived for feature extraction. Then, a novel approach, called k-mode optimization, is presented to iteratively learn these subspaces by unfolding the tensor along different tensor directions. We call this algorithm multilinear discriminant analysis (NIDA), which has the following characteristics: 1) multiple interrelated subspaces can collaborate to discriminate different classes, 2) for classification problems involving higher order tensors, the NIDA algorithm can avoid the curse of dimensionality dilemma and alleviate the small sample size problem, and 3) the computational cost in the learning stage is reduced to a large extent owing to the reduced data dimensions in k-mode optimization. We provide extensive experiments on ORL, CMU PIE, and FERET databases by encoding face images as second- or third-order tensors to demonstrate that the proposed NIDA algorithm based on higher order tensors has the potential to outperform the traditional vector-based subspace learning algorithms, especially in the cases with small sample sizes.", "paper_title": "Multilinear discriminant analysis for face recognition", "paper_id": "WOS:000243236200020"}