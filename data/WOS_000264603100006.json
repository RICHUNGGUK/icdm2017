{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "cell_processor"}, {"score": 0.014994780988604602, "phrase": "multi-core_processors"}, {"score": 0.004757849078050144, "phrase": "high-throughput_processing"}, {"score": 0.004687419167634463, "phrase": "data_stream_management_systems"}, {"score": 0.004549657384420166, "phrase": "high_aggregate_processing_capacity"}, {"score": 0.004468942661513215, "phrase": "costly_dsms_operators"}, {"score": 0.004429121482144758, "phrase": "recently_developed_cell_processor"}, {"score": 0.004389653570743615, "phrase": "good_example"}, {"score": 0.0043505358211043425, "phrase": "heterogeneous_multi-core_architecture"}, {"score": 0.0042989181990989965, "phrase": "powerful_platform"}, {"score": 0.004260605564118872, "phrase": "data_stream_operators"}, {"score": 0.0041353355816051126, "phrase": "full_potential"}, {"score": 0.004098474819777767, "phrase": "multi-core_processor"}, {"score": 0.003966096429996537, "phrase": "heterogeneous_nature"}, {"score": 0.003930738245421039, "phrase": "processing_elements"}, {"score": 0.0038725043244407387, "phrase": "local_memory"}, {"score": 0.003837977308651303, "phrase": "co-processor_side"}, {"score": 0.0036263171149449997, "phrase": "scalable_execution"}, {"score": 0.003604725094696445, "phrase": "windowed_stream"}, {"score": 0.0034262895977021854, "phrase": "execution_flow"}, {"score": 0.0033755037617077483, "phrase": "right_set"}, {"score": 0.003276171848389645, "phrase": "sequential_segments"}, {"score": 0.0031797536775378327, "phrase": "basic_windows"}, {"score": 0.0031513836446128264, "phrase": "low-overhead_pointer-shifting_techniques"}, {"score": 0.0030769577726521323, "phrase": "window_partitioning"}, {"score": 0.003058626737273869, "phrase": "column-oriented_join_window_organization"}, {"score": 0.0030042843107651847, "phrase": "scattered_data_transfers"}, {"score": 0.0029863849319835354, "phrase": "delay-optimized_double_buffering"}, {"score": 0.0029421002892899015, "phrase": "effective_pipelining"}, {"score": 0.002924570313075411, "phrase": "rate-aware_batching"}, {"score": 0.0028469653622421828, "phrase": "tuple_delay"}, {"score": 0.0028215560905969304, "phrase": "finally_single-instruction_multiple-data"}, {"score": 0.0028047500569722095, "phrase": "simd"}, {"score": 0.002722160504975204, "phrase": "data_parallelism"}, {"score": 0.0026578445199569893, "phrase": "design_guidelines"}, {"score": 0.0026420037427645725, "phrase": "implementation_techniques"}, {"score": 0.0025795767081439277, "phrase": "high_scalability"}, {"score": 0.002488684109969271, "phrase": "efficient_use"}, {"score": 0.0024664646023470813, "phrase": "extensive_hardware_parallelism"}, {"score": 0.0022888335017747768, "phrase": "conventional_high-end_processors"}, {"score": 0.002261621709656129, "phrase": "combined_input_stream_rate"}], "paper_keywords": [""], "paper_abstract": "Low-latency and high-throughput processing are key requirements of data stream management systems (DSMSs). Hence, multi-core processors that provide high aggregate processing capacity are ideal matches for executing costly DSMS operators. The recently developed Cell processor is a good example of a heterogeneous multi-core architecture and provides a powerful platform for executing data stream operators with high-performance. On the down side, exploiting the full potential of a multi-core processor like Cell is often challenging, mainly due to the heterogeneous nature of the processing elements, the software managed local memory at the co-processor side, and the unconventional programming model in general. In this paper, we study the problem of scalable execution of windowed stream join operators on multi-core processors, and specifically on the Cell processor. By examining various aspects of join execution flow, we determine the right set of techniques to apply in order to minimize the sequential segments and maximize parallelism. Concretely, we show that basic windows coupled with low-overhead pointer-shifting techniques can be used to achieve efficient join window partitioning, column-oriented join window organization can be used to minimize scattered data transfers, delay-optimized double buffering can be used for effective pipelining, rate-aware batching can be used to balance join throughput and tuple delay, and finally single-instruction multiple-data (SIMD) optimized operator code can be used to exploit data parallelism. Our experimental results show that, following the design guidelines and implementation techniques outlined in this paper, windowed stream joins can achieve high scalability (linear in the number of co-processors) by making efficient use of the extensive hardware parallelism provided by the Cell processor (reaching data processing rates of a parts per thousand 13 GB/s) and significantly surpass the performance obtained form conventional high-end processors (supporting a combined input stream rate of 2,000 tuples/s using 15 min windows and without dropping any tuples, resulting in a parts per thousand 8.3 times higher output rate compared to an SSE implementation on dual 3.2 GHz Intel Xeon).", "paper_title": "CellJoin: a parallel stream join operator for the cell processor", "paper_id": "WOS:000264603100006"}