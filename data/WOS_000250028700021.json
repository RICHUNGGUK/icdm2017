{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "quantitative-qualitative_measure"}, {"score": 0.04657105320398181, "phrase": "multimodality_image_registration"}, {"score": 0.026466296425426257, "phrase": "q-mi-based_registration_method"}, {"score": 0.004685106586595599, "phrase": "novel_image_similarity_measure"}, {"score": 0.004435782384431224, "phrase": "conventional_information_measures"}, {"score": 0.004382196270563035, "phrase": "shannon's_entropy"}, {"score": 0.004355645393953418, "phrase": "mutual_information"}, {"score": 0.004329447014648659, "phrase": "mi"}, {"score": 0.004276949941406725, "phrase": "quantitative_aspects"}, {"score": 0.003988180913997414, "phrase": "underlying_goal"}, {"score": 0.0032629585038738856, "phrase": "different_voxels"}, {"score": 0.0032333158387737424, "phrase": "different_utilities"}, {"score": 0.0031748333717241456, "phrase": "brain_images"}, {"score": 0.00291555613737437, "phrase": "higher_utility"}, {"score": 0.0028890603352364273, "phrase": "wm_voxel"}, {"score": 0.0028628046285909276, "phrase": "large_uniform_wm_region"}, {"score": 0.0027101925966844117, "phrase": "regional_saliency_value"}, {"score": 0.002677396270783542, "phrase": "scale-space_map"}, {"score": 0.0026050445177883005, "phrase": "higher_utility_values"}, {"score": 0.0025813632575129933, "phrase": "saliency_values"}, {"score": 0.0024288830311280573, "phrase": "conventional_mi-based_registration_methods"}, {"score": 0.0023275257102180554, "phrase": "relatively_larger_capture_range"}, {"score": 0.002278440725193305, "phrase": "proposed_q-mi"}, {"score": 0.0022236070278432575, "phrase": "rigid_registrations"}, {"score": 0.0022101055924375725, "phrase": "clinical_brain_images"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["multimodality image registration", " mutual information", " quantitative-qualitative measure of mutual information", " salient measure", " utilities of events"], "paper_abstract": "This paper presents a novel image similarity measure, referred to as quantitative-qualitative measure of mutual information (Q-MI), for multimodality image registration. Conventional information measures, e.g., Shannon's entropy and mutual information (MI), reflect quantitative aspects of information because they only consider probabilities of events. In fact, each event has its own utility to the fulfillment of the underlying goal, which can be independent of its probability of occurrence. Thus, it is important to consider both quantitative (i.e., probability) and qualitative (i.e., utility) measures of information in order to fully capture the characteristics of events. Accordingly, in multimodality image registration, Q-MI should be used to integrate the information obtained from both the image intensity distributions and the utilities of voxels in the images. Different voxels can have different utilities, for example, in brain images, two voxels can have the same intensity value, but their utilities can be different, e.g., a white matter (WM) voxel near the cortex can have higher utility than a WM voxel inside a large uniform WM region. In Q-ML the utility of each voxel in an image can be determined according to the regional saliency value calculated from the scale-space map of this image. Since the voxels with higher utility values (or saliency values) contribute more in measuring Q-MI of the two images, the Q-MI-based registration method is much more robust, compared to conventional MI-based registration methods. Also, the Q-MI-based registration method can provide a smoother registration function with a relatively larger capture range. In this paper, the proposed Q-MI has been validated and applied to the rigid registrations of clinical brain images, such as MR, CT and PET images. (C) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "Multimodality image registration by maximization of quantitative-qualitative measure of mutual information", "paper_id": "WOS:000250028700021"}