{"auto_keywords": [{"score": 0.0496540934239714, "phrase": "sensor_network_approach"}, {"score": 0.04507642295589586, "phrase": "task-driven_approach"}, {"score": 0.03156763959900261, "phrase": "tracker_performance"}, {"score": 0.00481495049065317, "phrase": "multiple_cameras"}, {"score": 0.004632469280786256, "phrase": "single_object"}, {"score": 0.004404188306112211, "phrase": "communication_bandwidth"}, {"score": 0.004287903986946197, "phrase": "camera_subset_selection"}, {"score": 0.004162281538812753, "phrase": "simple_local_processing"}, {"score": 0.004113064886401964, "phrase": "horizontal_position"}, {"score": 0.003933609372601274, "phrase": "cluster_head"}, {"score": 0.003795677450778112, "phrase": "static_occluders"}, {"score": 0.0036625643243684827, "phrase": "moving_occluders"}, {"score": 0.003608482801645977, "phrase": "noisy_perspective_camera_measurement_model"}, {"score": 0.003513133457324989, "phrase": "occlusion_indicator_functions"}, {"score": 0.003481911583035097, "phrase": "auxiliary_particle_filter"}, {"score": 0.0034407121288076783, "phrase": "occluder_information"}, {"score": 0.0033497809969621267, "phrase": "camera_subset_selection_algorithm"}, {"score": 0.003320006029757563, "phrase": "minimum_mean_square_error"}, {"score": 0.003290494847464381, "phrase": "best_linear_estimate"}, {"score": 0.0032612451286025555, "phrase": "object_position"}, {"score": 0.0031003255054939524, "phrase": "preselected_subsets"}, {"score": 0.002929824640902227, "phrase": "moving_occluder_priors"}, {"score": 0.0028102048802494434, "phrase": "occluder_prior_accuracy"}, {"score": 0.002768674345336861, "phrase": "prescribed_tracker_performance"}, {"score": 0.0025853800975668946, "phrase": "occluder_priors"}, {"score": 0.0024797884462618427, "phrase": "high_accuracy"}, {"score": 0.002385595105638277, "phrase": "camera_nodes"}, {"score": 0.0023433334920926713, "phrase": "tracking_performance"}, {"score": 0.0022881443200668886, "phrase": "greedy_selection_algorithm"}, {"score": 0.0022543116010603293, "phrase": "brute-force_method"}, {"score": 0.002168664249034287, "phrase": "small_fraction"}], "paper_keywords": ["Algorithms", " Theory", " Auxiliary particle filter", " camera sensor network", " collaborative signal processing", " noisy perspective camera model", " occlusion", " selection", " sensor fusion", " sensor tasking", " tracking"], "paper_abstract": "This article describes a sensor network approach to tracking a single object in the presence of static and moving occluders using a network of cameras. To conserve communication bandwidth and energy, we combine a task-driven approach with camera subset selection. In the task-driven approach, each camera first performs simple local processing to detect the horizontal position of the object in the image. This information is then sent to a cluster head to track the object. We assume the locations of the static occluders to be known, but only prior statistics on the positions of the moving occluders are available. A noisy perspective camera measurement model is introduced, where occlusions are captured through occlusion indicator functions. An auxiliary particle filter that incorporates the occluder information is used to track the object. The camera subset selection algorithm uses the minimum mean square error of the best linear estimate of the object position as a metric, and tracking is performed using only the selected subset of cameras. Using simulations and preselected subsets of cameras, we investigate (i) the dependency of the tracker performance on the accuracy of the moving occluder priors, (ii) the trade-off between the number of cameras and the occluder prior accuracy required to achieve a prescribed tracker performance, and (iii) the importance of having occluder priors to the tracker performance as the number of occluders increases. We find that computing moving occluder priors may not be worthwhile, unless it can be obtained cheaply and to high accuracy. We also investigate the effect of dynamically selecting the subset of camera nodes used in tracking on the tracking performance. We show through simulations that a greedy selection algorithm performs close to the brute-force method and outperforms other heuristics, and the performance achieved by greedily selecting a small fraction of the cameras is close to that of using all the cameras.", "paper_title": "Object Tracking in the Presence of Occlusions Using Multiple Cameras: A Sensor Network Approach", "paper_id": "WOS:000316964400007"}