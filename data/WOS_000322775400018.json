{"auto_keywords": [{"score": 0.013874638344905176, "phrase": "power_losses"}, {"score": 0.01043848672600228, "phrase": "energy_consumption"}, {"score": 0.010122976886488956, "phrase": "data_center"}, {"score": 0.00481495049065317, "phrase": "hpc_data_centers"}, {"score": 0.004713162564945179, "phrase": "high_performance_computing_data_centers"}, {"score": 0.004668613659668831, "phrase": "long_standing_issue"}, {"score": 0.004635477242873163, "phrase": "rising_costs"}, {"score": 0.004483909657713567, "phrase": "overall_energy_consumption"}, {"score": 0.0043682904296796264, "phrase": "reduced_energy_consumption"}, {"score": 0.004316722156877335, "phrase": "idle_nodes"}, {"score": 0.003991247722150554, "phrase": "considerable_energy_savings"}, {"score": 0.003916098498242888, "phrase": "rack_components"}, {"score": 0.0038332390893263844, "phrase": "scheduling_technique"}, {"score": 0.0035105510305489243, "phrase": "well-known_maui_scheduler"}, {"score": 0.0032844779865261425, "phrase": "overall_cluster_performance"}, {"score": 0.003199687131875466, "phrase": "wide_variety"}, {"score": 0.0031693980719538287, "phrase": "real_cluster_deployments"}, {"score": 0.003146868994031064, "phrase": "simulation_mode"}, {"score": 0.0031319396107404767, "phrase": "maui"}, {"score": 0.003072918736387408, "phrase": "currently_available_maui_scheduler_configurations"}, {"score": 0.0029511579080222137, "phrase": "existing_energy"}, {"score": 0.002909342017421165, "phrase": "enhanced_energy_savings"}, {"score": 0.002868116925014397, "phrase": "side_effects"}, {"score": 0.0028274743316389437, "phrase": "network_switches"}, {"score": 0.0027413748388534025, "phrase": "existing_techniques"}, {"score": 0.002645276944582444, "phrase": "sharma"}, {"score": 0.0026327164894606753, "phrase": "ranganathan"}, {"score": 0.0026015832411231425, "phrase": "computer_science"}, {"score": 0.002492513778739949, "phrase": "best_fit_scheme"}, {"score": 0.0024747842618794255, "phrase": "rack_considerations"}, {"score": 0.0024397017438101726, "phrase": "enhanced_technique"}, {"score": 0.0024051153560799335, "phrase": "node_allocation"}, {"score": 0.002388006025267707, "phrase": "rack_information"}, {"score": 0.0022340607507189735, "phrase": "job_splitting"}, {"score": 0.0022234513723622252, "phrase": "multiple_racks"}, {"score": 0.002150580119047236, "phrase": "learning_model"}, {"score": 0.0021049977753042253, "phrase": "scheduling_parameters"}], "paper_keywords": ["Rack aware scheduling", " Power conservation", " Scheduling"], "paper_abstract": "Energy consumption in high performance computing data centers has become a long standing issue. With rising costs of operating the data center, various techniques need to be employed to reduce the overall energy consumption. Currently, among others there are techniques that guarantee reduced energy consumption by powering on/off the idle nodes. However, most of them do not consider the energy consumed by other components in a rack. Our study addresses this aspect of the data center. We show that we can gain considerable energy savings by reducing the energy consumed by these rack components. In this regard, we propose a scheduling technique that will help schedule jobs with the above mentioned goal. We claim that by our scheduling technique we can reduce the energy consumption considerably without affecting other performance metrics of a job. We implement this technique as an enhancement to the well-known Maui scheduler and present our results. We propose three different algorithms as part of this technique. The algorithms evaluate the various trade-offs that could be possibly made with respect to overall cluster performance. We compare our technique with various currently available Maui scheduler configurations. We simulate a wide variety of workloads from real cluster deployments using the simulation mode of Maui. Our results consistently show about 7 to 14 % savings over the currently available Maui scheduler configurations. We shall also see that our technique can be applied in tandem with most of the existing energy aware scheduling techniques to achieve enhanced energy savings. We also consider the side effects of power losses due to the network switches as a result of deploying our technique. We compare our technique with the existing techniques in terms of the power losses due to these switches based on the results in Sharma and Ranganathan, Lecture Notes in Computer Science, vol. 5550, 2009 and account for the power losses. We there on provide a best fit scheme with the rack considerations. We then propose an enhanced technique that merges the two extremes of node allocation based on rack information. We see that we can provide a way to configure the scheduler based on the kind of workload that it schedules and reduce the effect of job splitting across multiple racks. We further discuss how the enhancement can be utilized to build a learning model which can be used to adaptively adjust the scheduling parameters based on the workload experienced.", "paper_title": "Rack aware scheduling in HPC data centers: an energy conservation strategy", "paper_id": "WOS:000322775400018"}