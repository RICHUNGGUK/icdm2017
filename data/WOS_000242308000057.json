{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "rectangle_learning"}, {"score": 0.004445961412092278, "phrase": "training_instances"}, {"score": 0.0035766032751309677, "phrase": "hybrid_learner"}, {"score": 0.003424225677958491, "phrase": "accuracy_advantage"}, {"score": 0.003350480663660326, "phrase": "classification_time"}, {"score": 0.0031845067058084613, "phrase": "decision_trees"}, {"score": 0.0029830992938695033, "phrase": "accuracy_improvement"}, {"score": 0.0022801453935251503, "phrase": "local_decisions"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": [""], "paper_abstract": "In Nearest Rectangle (NR) learning, training instances are generalized into hyperrectangles and a query is classified according to the class of its nearest rectangle. The method has not received much attention since its introduction mainly because, as a hybrid learner, it does not gain accuracy advantage while sacrificing classification time comparing to some other interpretable eager learners such as decision trees. In this paper, we seek for accuracy improvement of NR learning through controlling the generation of rectangles, so that each of them has the right of inference. Rectangles having the right of inference are compact, conservative, and good for making local decisions. Experiments on benchmark datasets validate the effectiveness of the proposed approach.", "paper_title": "Right of inference: Nearest rectangle learning revisited", "paper_id": "WOS:000242308000057"}