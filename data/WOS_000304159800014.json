{"auto_keywords": [{"score": 0.04797725309056393, "phrase": "image_understanding"}, {"score": 0.031223727851499707, "phrase": "multitag_image_annotation"}, {"score": 0.00481495049065317, "phrase": "input-output_structural_grouping_sparsity"}, {"score": 0.004779085953614184, "phrase": "automatic_image_annotation"}, {"score": 0.004743626074448764, "phrase": "aia"}, {"score": 0.0046382670208947605, "phrase": "image_retrieval"}, {"score": 0.0043363441738461335, "phrase": "visual_feature_selection"}, {"score": 0.004256005669252138, "phrase": "hierarchical_correlated_structures"}, {"score": 0.004224286804379592, "phrase": "multiple_tags"}, {"score": 0.004130535674260505, "phrase": "image_annotation"}, {"score": 0.00399378014373321, "phrase": "output_structural_grouping_sparsity"}, {"score": 0.003949204622915113, "phrase": "regularized_regression_model"}, {"score": 0.0038471128411102914, "phrase": "high-dimensional_heterogeneous_features"}, {"score": 0.0037058116979705857, "phrase": "different_kinds"}, {"score": 0.003609989117581185, "phrase": "different_intrinsic_discriminative_power"}, {"score": 0.003503497128638099, "phrase": "proposed_structured_feature_selection"}, {"score": 0.0034773669221269594, "phrase": "structural_grouping_sparsity"}, {"score": 0.003238616481108356, "phrase": "group_selection"}, {"score": 0.003214455466823939, "phrase": "hierarchical_correlations"}, {"score": 0.003190474123738408, "phrase": "output_labels"}, {"score": 0.0031195948946937378, "phrase": "tree_structure"}, {"score": 0.003050285492466281, "phrase": "proposed_tree-structured_grouping_sparsity"}, {"score": 0.00286213454317036, "phrase": "proposed_regression_model"}, {"score": 0.0028090313440881937, "phrase": "solving_process"}, {"score": 0.0027466028572379455, "phrase": "bilayer_regression_model"}, {"score": 0.002665511985052972, "phrase": "heterogeneous_features"}, {"score": 0.00264561514767961, "phrase": "structural_grouping"}, {"score": 0.0025578967205807843, "phrase": "first-layer_regression"}, {"score": 0.002418099158357658, "phrase": "second-layer_regression"}, {"score": 0.002373214852820709, "phrase": "feature_selection_model"}, {"score": 0.002337906603857861, "phrase": "first_layer"}, {"score": 0.0022688546528208133, "phrase": "multilabel_boosting_process"}, {"score": 0.002251911996999611, "phrase": "extensive_experiments"}, {"score": 0.002235095576913575, "phrase": "public_benchmark_image_data_sets"}, {"score": 0.002218404456227325, "phrase": "real-world_image_data_sets"}, {"score": 0.0021609589091422608, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "quite_interpretable_model"}], "paper_keywords": ["Automatic image annotation (AIA)", " regularized regression", " structural grouping sparsity", " structured feature selection", " tree-structured grouping sparsity"], "paper_abstract": "Automatic image annotation (AIA) is very important to image retrieval and image understanding. Two key issues in AIA are explored in detail in this paper, i.e., structured visual feature selection and the implementation of hierarchical correlated structures among multiple tags to boost the performance of image annotation. This paper simultaneously introduces an input and output structural grouping sparsity into a regularized regression model for image annotation. For input high-dimensional heterogeneous features such as color, texture, and shape, different kinds (groups) of features have different intrinsic discriminative power for the recognition of certain concepts. The proposed structured feature selection by structural grouping sparsity can be used not only to select group-of-features but also to conduct within-group selection. Hierarchical correlations among output labels are well represented by a tree structure, and therefore, the proposed tree-structured grouping sparsity can be used to boost the performance of multitag image annotation. In order to efficiently solve the proposed regression model, we relax the solving process as a framework of the bilayer regression model for multilabel boosting by the selection of heterogeneous features with structural grouping sparsity (Bi-MtBGS). The first-layer regression is to select the discriminative features for each label. The aim of the second-layer regression is to refine the feature selection model learned from the first layer, which can be taken as a multilabel boosting process. Extensive experiments on public benchmark image data sets and real-world image data sets demonstrate that the proposed approach has better performance of multitag image annotation and leads to a quite interpretable model for image understanding.", "paper_title": "Image Annotation by Input-Output Structural Grouping Sparsity", "paper_id": "WOS:000304159800014"}