{"auto_keywords": [{"score": 0.04418176494619199, "phrase": "sober"}, {"score": 0.00481495049065317, "phrase": "manual_debugging"}, {"score": 0.0046382670208947605, "phrase": "high_cost"}, {"score": 0.00453537012358554, "phrase": "fault_localization_techniques"}, {"score": 0.004418192459607072, "phrase": "fault_locations"}, {"score": 0.004271953920234395, "phrase": "new_statistical_method"}, {"score": 0.004146015717402716, "phrase": "software_faults"}, {"score": 0.0040997480534580065, "phrase": "prior_knowledge"}, {"score": 0.004053994613859937, "phrase": "program_semantics"}, {"score": 0.004008749730113699, "phrase": "existing_statistical_approaches"}, {"score": 0.003919763262805793, "phrase": "program_failures"}, {"score": 0.003890540531028228, "phrase": "sober_models"}, {"score": 0.003861534816807933, "phrase": "predicate_evaluation"}, {"score": 0.0038184296585478724, "phrase": "correct_and_incorrect_executions"}, {"score": 0.0036507498735369576, "phrase": "incorrect_executions"}, {"score": 0.003569681826459428, "phrase": "correct_ones"}, {"score": 0.0034514309280805106, "phrase": "hypothesis_testing"}, {"score": 0.003387431241133385, "phrase": "fault_relevance"}, {"score": 0.0033121909731471787, "phrase": "principled_way"}, {"score": 0.003190474123738408, "phrase": "previous_studies"}, {"score": 0.002949189427671915, "phrase": "siemens_suite"}, {"score": 0.002830153695660011, "phrase": "cause_transition_approach"}, {"score": 0.0027985291920293127, "phrase": "holger_et_al"}, {"score": 0.002695637404144115, "phrase": "liblit_et_al"}, {"score": 0.0024916819803100635, "phrase": "\"imperfect_world"}, {"score": 0.00244543519230361, "phrase": "test_suite"}, {"score": 0.0023031224517224757, "phrase": "competitive_quality"}, {"score": 0.0022773736136311056, "phrase": "harsh_circumstances"}, {"score": 0.0021049977753042253, "phrase": "reasonably_large_programs"}], "paper_keywords": ["debugging aids", " statistical methods", " statistical debugging"], "paper_abstract": "Manual debugging is tedious, as well as costly. The high cost has motivated the development of fault localization techniques, which help developers search for fault locations. In this paper, we propose a new statistical method, called SOBER, which automatically localizes software faults without any prior knowledge of the program semantics. Unlike existing statistical approaches that select predicates correlated with program failures, SOBER models the predicate evaluation in both correct and incorrect executions and regards a predicate as fault-relevant if its evaluation pattern in incorrect executions significantly diverges from that in correct ones. Featuring a rationale similar to that of hypothesis testing, SOBER quantifies the fault relevance of each predicate in a principled way. We systematically evaluate SOBER under the same setting as previous studies. The result clearly demonstrates the effectiveness: SOBER could help developers locate 68 out of the 130 faults in the Siemens suite by examining no more than 10 percent of the code, whereas the Cause Transition approach proposed by Holger et al. [6] and the statistical approach by Liblit et al. [12] locate 34 and 52 faults, respectively. Moreover, the effectiveness of SOBER is also evaluated in an \"imperfect world,\" where the test suite is either inadequate or only partially labeled. The experiments indicate that SOBER could achieve competitive quality under these harsh circumstances. Two case studies with grep 2.2 and bc 1.06 are reported, which shed light on the applicability of SOBER on reasonably large programs.", "paper_title": "Statistical debugging: A hypothesis testing-based approach", "paper_id": "WOS:000241385700005"}