{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "parallel_cell-based_finite_element_operator_application"}, {"score": 0.0046632033374901715, "phrase": "memory-efficient_and_parallel_framework"}, {"score": 0.004401955895933783, "phrase": "generic_open-source_library_deal"}, {"score": 0.004208881856146758, "phrase": "sparse_matrix"}, {"score": 0.004076157223660074, "phrase": "matrix-vector_products"}, {"score": 0.0038973170902076707, "phrase": "cell-wise_quadrature"}, {"score": 0.0037743802306714545, "phrase": "shape_functions"}, {"score": 0.0036553070575015344, "phrase": "sum-factorization_approach"}, {"score": 0.0034282732966589478, "phrase": "modern_supercomputer_architecture"}, {"score": 0.003362944428837724, "phrase": "optimal_way"}, {"score": 0.0032777653153451265, "phrase": "remote_nodes"}, {"score": 0.0032359856233193504, "phrase": "thread_parallelization"}, {"score": 0.003194736764837261, "phrase": "dynamic_task_scheduling"}, {"score": 0.0030741085942960814, "phrase": "explicit_vectorization"}, {"score": 0.003015508235745547, "phrase": "processors'_vector_units"}, {"score": 0.002977061391551631, "phrase": "special_data_structures"}, {"score": 0.002901627749562029, "phrase": "high_performance"}, {"score": 0.0028100102841877835, "phrase": "memory_requirements"}, {"score": 0.002568542343945288, "phrase": "partial_differential_equations"}, {"score": 0.0025034338848015187, "phrase": "performance_tests"}, {"score": 0.002347775213789611, "phrase": "sparse_matrix-vector_products"}, {"score": 0.0022302306304023602, "phrase": "hexahedral_elements"}, {"score": 0.0021876814398268775, "phrase": "ten_times_higher_gflops_rates"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Finite/spectral element method", " Matrix-free method", " Sum-factorization", " Hybrid parallelization"], "paper_abstract": "We present a memory-efficient and parallel framework for finite element operator application implemented in the generic open-source library deal.II. Instead of assembling a sparse matrix and using it for matrix-vector products, the operation is applied by cell-wise quadrature. The evaluation of shape functions is implemented with a sum-factorization approach. Our implementation is parallelized on three levels to exploit modern supercomputer architecture in an optimal way: MPI over remote nodes, thread parallelization with dynamic task scheduling within the nodes, and explicit vectorization for utilizing processors' vector units. Special data structures are designed for high performance and to keep the memory requirements to a minimum. The framework handles adaptively refined meshes and systems of partial differential equations. We provide performance tests for both linear and nonlinear PDEs which show that our cell-based implementation is faster than sparse matrix-vector products for polynomial order two and higher on hexahedral elements and yields ten times higher Gflops rates. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "A generic interface for parallel cell-based finite element operator application", "paper_id": "WOS:000307093500010"}