{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "iteratively_a_classifier"}, {"score": 0.004682708592184678, "phrase": "bayesian_model_averaging_principle"}, {"score": 0.0044702911400353535, "phrase": "learning_algorithm"}, {"score": 0.004388035083357706, "phrase": "nominal_vector_data"}, {"score": 0.00418892838079239, "phrase": "complex_classifier"}, {"score": 0.00399881984083004, "phrase": "simple_function"}, {"score": 0.003852939975815287, "phrase": "current_classifier"}, {"score": 0.003644001325962353, "phrase": "overtraining_problem"}, {"score": 0.003320561182494713, "phrase": "optimal_bayesian_learning"}, {"score": 0.0028087949095629955, "phrase": "naive_bayes"}, {"score": 0.0027570267191549774, "phrase": "logistic_classification"}, {"score": 0.002656327554326748, "phrase": "experimental_results"}, {"score": 0.0025355968118803956, "phrase": "standard_data_sets"}, {"score": 0.002397923568994474, "phrase": "standard_learning"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Bayesian model averaging", " point estimate approximation", " Naive Bayes classifier", " statistical classification"], "paper_abstract": "We present a learning algorithm for nominal vector data. It builds a complex classifier by adding iteratively a simple function that modifies the current classifier. In order to limit overtraining problem we focus on a class of such functions for which optimal Bayesian learning is tractable. We investigate a few classes of functions that yield to models that are similar to Naive Bayes and logistic classification. We report experimental results for a collection of standard data sets that show that our learning algorithm outperforms standard learning of such these standard models. (C) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "Learning iteratively a classifier with the Bayesian model averaging principle", "paper_id": "WOS:000251357100014"}