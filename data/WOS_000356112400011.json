{"auto_keywords": [{"score": 0.04052904383503032, "phrase": "low-rank_coherency"}, {"score": 0.00481495049065317, "phrase": "low-rank_coherency_analysis"}, {"score": 0.00474075475474847, "phrase": "object_tracking"}, {"score": 0.004653220443592979, "phrase": "security_surveillance"}, {"score": 0.004553128404612054, "phrase": "traffic_control"}, {"score": 0.0045249263666466005, "phrase": "augmented_reality"}, {"score": 0.0044968982227349625, "phrase": "human-computer_interaction"}, {"score": 0.004413846562278824, "phrase": "rapid_growth"}, {"score": 0.004071249707923223, "phrase": "novel_video_object_tracking_approach"}, {"score": 0.004008467832216946, "phrase": "local_and_global_information"}, {"score": 0.00398362591640497, "phrase": "consecutive_video_observations"}, {"score": 0.003825849505589868, "phrase": "accompanying_feature_space"}, {"score": 0.003802135020791801, "phrase": "targeting_objects"}, {"score": 0.0035507457285983268, "phrase": "transient_illumination"}, {"score": 0.003528730431045574, "phrase": "rapid_movement"}, {"score": 0.0034959622587016222, "phrase": "scale_change"}, {"score": 0.003431332820984854, "phrase": "local_space-distinctive_candidate_features"}, {"score": 0.0034100553723847037, "phrase": "global_time-continuous_target_coherency"}, {"score": 0.003378385493203297, "phrase": "smart_low-rank_analysis_model"}, {"score": 0.0032749212355657215, "phrase": "simple_yet_efficient_patch-level_feature_descriptor"}, {"score": 0.0031549249117721946, "phrase": "frame_color_distribution"}, {"score": 0.003125617049841619, "phrase": "video_frames"}, {"score": 0.003077372515276563, "phrase": "powerful_local_representation"}, {"score": 0.0030017207229983385, "phrase": "frame_cache"}, {"score": 0.002973831814707697, "phrase": "yet-to-be-processed_new_frame"}, {"score": 0.0028470613150369823, "phrase": "low-rank_decomposition"}, {"score": 0.0028206052780047424, "phrase": "global_coherency_voting"}, {"score": 0.002759823989317719, "phrase": "intrinsic_co-occurring_parts"}, {"score": 0.002708766459414734, "phrase": "robust_tracking"}, {"score": 0.0026257554931689076, "phrase": "matching_criterion"}, {"score": 0.002585206414738808, "phrase": "drastically_varying_appearance"}, {"score": 0.002521623057264411, "phrase": "prior-frames'_tracking_results"}, {"score": 0.002498183546874872, "phrase": "low-rank_approximation"}, {"score": 0.002474961375646351, "phrase": "current_frame"}, {"score": 0.0023990982005125763, "phrase": "real-time_performance"}, {"score": 0.0023694065215394593, "phrase": "extensive_experiments"}, {"score": 0.002325554982412043, "phrase": "comprehensive_and_quantitative_evaluations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Localized compressive sensing representation", " Fast lowrank approximation", " Lowrank coherency tracking", " Visual tracking"], "paper_abstract": "Object tracking in video is vital for security surveillance, pattern and motion recognition, traffic control, augmented reality, human-computer interaction, etc. Despite the rapid growth of various techniques in recent years, certain technical challenges still exist in terms of efficiency, accuracy, and robustness. To ameliorate, this paper suggests a novel video object tracking approach by first collecting both local and global information from consecutive video observations (i.e., frames) and then exploring the low-rank coherency in the accompanying feature space of targeting objects, which enables real-time and robust object tracking in video while combating certain technical difficulties due to occlusion, deformation, transient illumination, rapid movement, and scale change. Our central idea is to integrate local space-distinctive candidate features and global time-continuous target coherency into a smart low-rank analysis model. For local candidate representation, we propose a simple yet efficient patch-level feature descriptor based on compressive sensing, which is directly derived from the frame color distribution available from video frames. Building upon this powerful local representation, we further organize all the candidates in the frame cache and the yet-to-be-processed new frame to form a space-time feature set, we then employ the low-rank decomposition to enable global coherency voting. Since the low-rank coherency implies the intrinsic co-occurring parts of different target observations, robust tracking can be achieved by employing this principle as the matching criterion even for objects with drastically varying appearance. Furthermore, we progressively incorporate the prior-frames' tracking results into the low-rank approximation in the current frame, which can greatly reduce the most time-consuming computation and guarantee real-time performance. We conduct extensive experiments on several well-known yet challenging benchmarks, and make comprehensive and quantitative evaluations with state-of-the-art methods. All the results demonstrate the superiority of our method in terms of accuracy, efficiency, robustness, and versatility. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Real-time and robust object tracking in video via low-rank coherency analysis in feature space", "paper_id": "WOS:000356112400011"}