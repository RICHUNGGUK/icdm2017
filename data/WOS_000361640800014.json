{"auto_keywords": [{"score": 0.048539652036902976, "phrase": "hac"}, {"score": 0.00481495049065317, "phrase": "multi-threaded_hierarchical_clustering"}, {"score": 0.004770211811866158, "phrase": "parallel_nearest-neighbor"}, {"score": 0.004703878334423852, "phrase": "hierarchical_agglomerative_clustering"}, {"score": 0.004573953147933065, "phrase": "clustering_method"}, {"score": 0.004264558080356621, "phrase": "hierarchical_structure"}, {"score": 0.004205226397573506, "phrase": "input_data"}, {"score": 0.004050996777117918, "phrase": "large_data"}, {"score": 0.003848088904418221, "phrase": "global_inter-cluster_distance_information"}, {"score": 0.0036213041338584756, "phrase": "new_parallelization_scheme"}, {"score": 0.003587616378156851, "phrase": "multi-threaded_shared-memory_machines"}, {"score": 0.0034398445347109396, "phrase": "proposed_multi-threaded_algorithm"}, {"score": 0.0032827577713351336, "phrase": "nn_chains"}, {"score": 0.0031919592786945126, "phrase": "distance_information"}, {"score": 0.0030319482153908037, "phrase": "ideal_configuration"}, {"score": 0.00297576670831646, "phrase": "theoretical_performance_bounds"}, {"score": 0.002853124436286834, "phrase": "multiple_public_datasets"}, {"score": 0.002684819249720834, "phrase": "proposed_method"}, {"score": 0.002456486927713543, "phrase": "performance-limiting_factors"}, {"score": 0.0023996890513009743, "phrase": "chain_growing"}, {"score": 0.002333258365963461, "phrase": "synchronization_locks"}, {"score": 0.0022686625017583387, "phrase": "memory-bandwidth_saturation"}, {"score": 0.002195552442011313, "phrase": "proposed_scheme"}, {"score": 0.0021347607855562102, "phrase": "hac_algorithm"}, {"score": 0.0021049977753042253, "phrase": "significant_gains"}], "paper_keywords": ["Hierarchical clustering", " unsupervised learning", " parallelization", " multi-threading", " multi-core CPU"], "paper_abstract": "Hierarchical agglomerative clustering (HAC) is a clustering method widely used in various disciplines from astronomy to zoology. HAC is useful for discovering hierarchical structure embedded in input data. The cost of executing HAC on large data is typically high, due to the need for maintaining global inter-cluster distance information throughout the execution. To address this issue, we propose a new parallelization scheme for multi-threaded shared-memory machines based on the concept of nearest-neighbor (NN) chains. The proposed multi-threaded algorithm allocates available threads into two groups, one for managing NN chains and the other for updating distance information. In-depth analysis of our approach gives insight into the ideal configuration of threads and theoretical performance bounds. We evaluate our proposed method by testing it with multiple public datasets and comparing its performance with that of several alternatives. In our test, the proposed method completes hierarchical clustering 3.09-51.79 times faster than the alternatives. Our test results also reveal the effects of performance-limiting factors such as starvation in chain growing, overhead incurred from using synchronization locks, and hardware aspects including memory-bandwidth saturation. According to our evaluation, the proposed scheme is effective in improving the HAC algorithm, achieving significant gains over the alternatives in terms of runtime and scalability.", "paper_title": "Multi-Threaded Hierarchical Clustering by Parallel Nearest-Neighbor Chaining", "paper_id": "WOS:000361640800014"}