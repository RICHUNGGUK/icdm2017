{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "appearance_similarity"}, {"score": 0.023028833773630644, "phrase": "keypoint_correspondences"}, {"score": 0.006515797719846582, "phrase": "ecc"}, {"score": 0.005424085689949545, "phrase": "proposed_approach"}, {"score": 0.004731492618963217, "phrase": "accurate_homography_estimation"}, {"score": 0.004669845451682529, "phrase": "classical_problem"}, {"score": 0.00462919213721188, "phrase": "high_industrial_value"}, {"score": 0.004167982855788402, "phrase": "novel_algorithm"}, {"score": 0.003920384090110374, "phrase": "feature-based_homography_estimation"}, {"score": 0.003802135020791801, "phrase": "probability_models"}, {"score": 0.003671338229632309, "phrase": "maximum_likelihood_framework"}, {"score": 0.0035761913760242697, "phrase": "homography_estimation"}, {"score": 0.0032908057622663732, "phrase": "inlier_location_error"}, {"score": 0.003219553875143356, "phrase": "laplacian_distribution"}, {"score": 0.0031498398446368025, "phrase": "previous_gaussian_distribution"}, {"score": 0.003108735847242537, "phrase": "heavy-tailed_distributions"}, {"score": 0.0029755458462182565, "phrase": "enhanced_correlation_coefficient"}, {"score": 0.0028731024405707277, "phrase": "image_similarity"}, {"score": 0.00270221723573854, "phrase": "truncated_exponential_distribution"}, {"score": 0.00266693888510356, "phrase": "proposed_model"}, {"score": 0.0025977542995083624, "phrase": "improved_framework"}, {"score": 0.0025750928944698673, "phrase": "random_sample_consensus"}, {"score": 0.0024325244760735566, "phrase": "objective_quality_measurement"}, {"score": 0.0024113009621042677, "phrase": "subjective_visual_quality"}, {"score": 0.0023798115577749225, "phrase": "computation_time"}, {"score": 0.0023487324083283205, "phrase": "experimental_results"}, {"score": 0.0022579036318895753, "phrase": "different_image_transformation_degrees"}, {"score": 0.002228412982799273, "phrase": "different_ratios"}, {"score": 0.002208966376185464, "phrase": "inlier_keypoint_correspondences"}, {"score": 0.0021610874773389096, "phrase": "state-of-the-art_works"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Homography estimation", " Keypoint consensus", " Appearance similarity", " RANSAC"], "paper_abstract": "Accurate homography estimation is a classical problem with high industrial value and has been investigated extensively. Most previous homography estimation methods used either appearance similarity or keypoint correspondences to find their best estimation. In this paper, a novel algorithm is proposed which integrates the advantages of the pixel-based and the feature-based homography estimation approaches. We elegantly combined the probability models of appearance similarity and keypoint correspondences in a Maximum Likelihood framework, which is named as Homography Estimation based on Appearance Similarity and Keypoint correspondences (HEASK). In the model of keypoint correspondences, the distribution of inlier location error is represented by a Laplacian distribution, which outperforms the previous Gaussian distribution in characterizing heavy-tailed distributions. And in the model of appearance similarity, the enhanced correlation coefficient (ECC) is adopted for describing image similarity, and the distribution of ECC is studied and parametrically formulated using a truncated exponential distribution. The proposed model is solved based on an improved framework of random sample consensus (RANSAC). Several simulations summarize the performance of the proposed approach in objective quality measurement, subjective visual quality, and computation time. The experimental results demonstrate that the proposed approach can achieve more accurate homography estimation under different image transformation degrees and with different ratios of inlier keypoint correspondences as compared to the state-of-the-art works. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "HEASK: Robust homography estimation based on appearance similarity and keypoint correspondences", "paper_id": "WOS:000326903500030"}