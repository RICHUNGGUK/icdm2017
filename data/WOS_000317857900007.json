{"auto_keywords": [{"score": 0.028468920438729128, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "gaussian_processes"}, {"score": 0.004772818068176176, "phrase": "pose-invariant_facial_expression_recognition"}, {"score": 0.004628223381645729, "phrase": "head-pose_invariant_facial_expression_recognition"}, {"score": 0.004468304427278713, "phrase": "characteristic_facial_points"}, {"score": 0.00439041997682389, "phrase": "head-pose_invariance"}, {"score": 0.00395069818358908, "phrase": "facial_points"}, {"score": 0.00346223706087128, "phrase": "coupled_functions"}, {"score": 0.0034319005131102495, "phrase": "different_poses"}, {"score": 0.0033572130837348623, "phrase": "gating_function"}, {"score": 0.0032697235411641695, "phrase": "head-pose_estimation"}, {"score": 0.003226834737003501, "phrase": "query_points"}, {"score": 0.0031845067058084583, "phrase": "proposed_model"}, {"score": 0.0031565959573536194, "phrase": "state-of-the-art_regression-based_approaches"}, {"score": 0.0028151944356239952, "phrase": "unknown_poses"}, {"score": 0.002790511479398411, "phrase": "imbalanced_training_data"}, {"score": 0.002646880721119838, "phrase": "first_one"}, {"score": 0.0025665261770229757, "phrase": "expressive_faces"}, {"score": 0.0024776677004255104, "phrase": "degrees_pan_rotation"}, {"score": 0.0023918783117166326, "phrase": "continuous_changes"}, {"score": 0.002248816575548875, "phrase": "small_set"}, {"score": 0.0022290883852844057, "phrase": "discrete_poses"}, {"score": 0.0021613897794439227, "phrase": "synthetic_and_real_images"}, {"score": 0.0021049977753042253, "phrase": "facial_expressions"}], "paper_keywords": ["Multiview/pose-invariant facial expression/emotion recognition", " head-pose estimation", " Gaussian process regression"], "paper_abstract": "We propose a method for head-pose invariant facial expression recognition that is based on a set of characteristic facial points. To achieve head-pose invariance, we propose the Coupled Scaled Gaussian Process Regression (CSGPR) model for head-pose normalization. In this model, we first learn independently the mappings between the facial points in each pair of (discrete) nonfrontal poses and the frontal pose, and then perform their coupling in order to capture dependences between them. During inference, the outputs of the coupled functions from different poses are combined using a gating function, devised based on the head-pose estimation for the query points. The proposed model outperforms state-of-the-art regression-based approaches to head-pose normalization, 2D and 3D Point Distribution Models (PDMs), and Active Appearance Models (AAMs), especially in cases of unknown poses and imbalanced training data. To the best of our knowledge, the proposed method is the first one that is able to deal with expressive faces in the range from -45 degrees to +45 degrees pan rotation and -30 degrees to +30 degrees tilt rotation, and with continuous changes in head pose, despite the fact that training was conducted on a small set of discrete poses. We evaluate the proposed method on synthetic and real images depicting acted and spontaneously displayed facial expressions.", "paper_title": "Coupled Gaussian Processes for Pose-Invariant Facial Expression Recognition", "paper_id": "WOS:000317857900007"}