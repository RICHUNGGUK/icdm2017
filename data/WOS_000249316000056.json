{"auto_keywords": [{"score": 0.041535261263051605, "phrase": "proposed_methods"}, {"score": 0.00481495049065317, "phrase": "random_partitions"}, {"score": 0.004760017604908536, "phrase": "high-dimensional_data"}, {"score": 0.004678785623021003, "phrase": "robust_classification_procedure"}, {"score": 0.0042928648367867835, "phrase": "different_set"}, {"score": 0.004147523799581407, "phrase": "random_partition"}, {"score": 0.0040767015025213625, "phrase": "entire_set"}, {"score": 0.0038492126993451337, "phrase": "multiple_classifiers"}, {"score": 0.0037617986040878342, "phrase": "substantially_improved_prediction"}, {"score": 0.0036763623220059933, "phrase": "optimal_single_classifier"}, {"score": 0.003511246498068952, "phrase": "high-dimensional_data_sets"}, {"score": 0.00307657476125683, "phrase": "computational_advantage"}, {"score": 0.003006654007926993, "phrase": "growing_problem"}, {"score": 0.0027741761880779535, "phrase": "classification_tree"}, {"score": 0.0027424619603260837, "phrase": "logistic_regression_tree"}, {"score": 0.002574387911697005, "phrase": "different_areas"}, {"score": 0.002444544487772349, "phrase": "widely_used_classification_methods"}, {"score": 0.002402731767209114, "phrase": "unbalanced_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["class prediction", " classification tree", " cross validation", " logistic regression", " majority voting", " risk profiling"], "paper_abstract": "A robust classification procedure is developed based on ensembles of classifiers, with each classifier constructed from a different set of predictors determined by a random partition of the entire set of predictors. The proposed methods combine the results of multiple classifiers to achieve a substantially improved prediction compared to the optimal single classifier. This approach is designed specifically for high-dimensional data sets for which a classifier is sought. By combining classifiers built from each subspace of the predictors, the proposed methods achieve a computational advantage in tackling the growing problem of dimensionality. For each subspace of the predictors, we build a classification tree or logistic regression tree. Our study shows, using four real data sets from different areas, that our methods perform consistently well compared to widely used classification methods. For unbalanced data, our approach maintains the balance between sensitivity and specificity more adequately than many other classification methods considered in this study. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Classification by ensembles from random partitions of high-dimensional data", "paper_id": "WOS:000249316000056"}