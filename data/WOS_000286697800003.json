{"auto_keywords": [{"score": 0.04915747964534472, "phrase": "jackson_operator"}, {"score": 0.00481495049065317, "phrase": "least_square_algorithm"}, {"score": 0.004454691230204595, "phrase": "regression_problem"}, {"score": 0.004161553532799662, "phrase": "least_square_schemes"}, {"score": 0.004081385289516914, "phrase": "polynomial_space"}, {"score": 0.0030778231027679464, "phrase": "good_rate"}, {"score": 0.002903161412792026, "phrase": "main_tool"}, {"score": 0.002685558057339722, "phrase": "approximation_theory"}, {"score": 0.0024126686412257407, "phrase": "obtained_estimation"}, {"score": 0.002297949552105756, "phrase": "simulated_data"}, {"score": 0.0022536005664642294, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Learning theory", " Covering number", " Rate of convergence", " Jackson operator"], "paper_abstract": "In this paper, regression problem in learning theory is investigated by least square schemes in polynomial space. Results concerning the estimation of rate of convergence are derived. In particular, it is shown that for one variable smooth regression function, the estimation is able to achieve good rate of convergence. As a main tool in the study, the Jackson operator in approximation theory is used to estimate the rate. Finally, the obtained estimation is illustrated by applying simulated data. Crown Copyright (c) 2010 Published by Elsevier B.V. All rights reserved.", "paper_title": "Estimation of learning rate of least square algorithm via Jackson operator", "paper_id": "WOS:000286697800003"}