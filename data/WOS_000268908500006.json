{"auto_keywords": [{"score": 0.034897987249739235, "phrase": "image_similarity"}, {"score": 0.015719716506582538, "phrase": "bronchoscope_tracking"}, {"score": 0.01555996713314101, "phrase": "image_registration"}, {"score": 0.011523768816723845, "phrase": "real_and_virtual_bronchoscopic_images"}, {"score": 0.009352228395342811, "phrase": "proposed_method"}, {"score": 0.004684157900507474, "phrase": "selective_method"}, {"score": 0.004604214511792668, "phrase": "image_similarities"}, {"score": 0.004556901872357751, "phrase": "characteristic_structure_extraction"}, {"score": 0.004479120557712926, "phrase": "flexible_endoscope_navigation"}, {"score": 0.0043875257506180865, "phrase": "bronchoscope_navigation_system"}, {"score": 0.004357410458790669, "phrase": "camera_motion_tracking"}, {"score": 0.004312622975366676, "phrase": "fundamental_function"}, {"score": 0.004268293864953256, "phrase": "image-guided_treatment"}, {"score": 0.004138010495069077, "phrase": "ultra-tiny_electromagnetic_sensor"}, {"score": 0.003956784357357341, "phrase": "camera_position"}, {"score": 0.0038492126993451337, "phrase": "space_limitations"}, {"score": 0.003592859432554987, "phrase": "ultra-thin_bronchoscopes"}, {"score": 0.003543667617024855, "phrase": "continuous_image_registration"}, {"score": 0.0031626225189867354, "phrase": "mutual_information"}, {"score": 0.003130077012135034, "phrase": "gray-level_difference"}, {"score": 0.0030344301563232944, "phrase": "intensity_values"}, {"score": 0.0030031998605136788, "phrase": "entire_region"}, {"score": 0.002822434555587263, "phrase": "entire_image"}, {"score": 0.0027741761880779535, "phrase": "small_subblocks"}, {"score": 0.002707993764473537, "phrase": "characteristic_shapes"}, {"score": 0.0026161698049580804, "phrase": "selected_subblocks"}, {"score": 0.0025537472239953807, "phrase": "feature_values"}, {"score": 0.0024586427394152196, "phrase": "chest_x-ray_ct_images"}, {"score": 0.0023999697562763433, "phrase": "experimental_results"}, {"score": 0.0022710523337245337, "phrase": "external_position_sensors"}, {"score": 0.002255431275670053, "phrase": "tracking_performance"}, {"score": 0.0021940118003312397, "phrase": "standard_method"}, {"score": 0.0021714122348552747, "phrase": "gray-level_differences"}, {"score": 0.0021490449563443025, "phrase": "entire_images"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Bronchoscopy", " Virtual bronchoscopy", " Image registration", " Image similarity", " Motion recovery", " Video image analysis", " Tracking", " Camera tracking"], "paper_abstract": "We propose a selective method of measurement for computing image similarities based on characteristic structure extraction and demonstrate its application to flexible endoscope navigation, in particular to a bronchoscope navigation system. Camera motion tracking is a fundamental function required for image-guided treatment or therapy systems. In recent years, an ultra-tiny electromagnetic sensor commercially became available, and many image-guided treatment or therapy systems use this sensor for tracking the camera position and orientation. However, due to space limitations, it is difficult to equip the tip of a bronchoscope with such a position sensor, especially in the case of ultra-thin bronchoscopes. Therefore, continuous image registration between real and virtual bronchoscopic images becomes an efficient tool for tracking the bronchoscope. Usually, image registration is done by calculating the image similarity between real and virtual bronchoscopic images. Since global schemes to measure image similarity, such as mutual information, squared gray-level difference, or cross correlation, average differences in intensity values over an entire region, they fail at tracking of scenes where less characteristic structures can be observed. The proposed method divides an entire image into a set of small subblocks and only selects those in which characteristic shapes are observed. Then image similarity is calculated within the selected subblocks. Selection is done by calculating feature values within each subblock. We applied our proposed method to eight pairs of chest X-ray CT images and bronchoscopic video images. The experimental results revealed that bronchoscope tracking using the proposed method could track up to 1600 consecutive bronchoscopic images (about 50 s) without external position sensors. Tracking performance was greatly improved in comparison with a standard method utilizing squared gray-level differences of the entire images. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Selective image similarity measure for bronchoscope tracking based on image registration", "paper_id": "WOS:000268908500006"}