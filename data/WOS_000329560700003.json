{"auto_keywords": [{"score": 0.048636009815037955, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "high-dimensional_small_sample"}, {"score": 0.004622450915803531, "phrase": "high-dimensional_small_samples"}, {"score": 0.0044150318724093226, "phrase": "general_analytical_framework"}, {"score": 0.004260134699483774, "phrase": "selection_strategy"}, {"score": 0.0037307208089736835, "phrase": "partial_least_squares"}, {"score": 0.0036553070575015344, "phrase": "based_feature_selection_methods"}, {"score": 0.0036181717017041387, "phrase": "hdss"}, {"score": 0.0035269696779744266, "phrase": "proposed_methodologies"}, {"score": 0.0034733518170738517, "phrase": "pls_model"}, {"score": 0.003403122817578447, "phrase": "parameter_selection"}, {"score": 0.0033173234105492895, "phrase": "pls-based_recursive_feature_elimination"}, {"score": 0.0031360786664165093, "phrase": "support_vector_machine"}, {"score": 0.0030726480920918097, "phrase": "based_feature_selection"}, {"score": 0.0030414140732789186, "phrase": "svm-based_recursive_feature_elimination"}, {"score": 0.002934566917795928, "phrase": "rf-based_recursive_feature_elimination"}, {"score": 0.002860546817196148, "phrase": "relieff_algorithm"}, {"score": 0.002831462722290752, "phrase": "relieff-based_recursive_feature_elimination"}, {"score": 0.0027459678326877744, "phrase": "twelve_high-dimensional_datasets"}, {"score": 0.002272794656458419, "phrase": "proposed_approach"}, {"score": 0.0021705796895687864, "phrase": "two-category_and_multi-category_problems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["High-dimensional small samples (HDSS)", " Partial least squares (PLS)", " Recursive feature elimination (RFE)", " Feature subset consistency", " Feature subset compactness"], "paper_abstract": "This paper focused on feature selection for high-dimensional small samples (HDSS). We first presented a general analytical framework for feature selection on a HDSS including selection strategy (single-feature ranking and multi-feature ranking) and evaluation criteria (feature subset consistency and compactness). Then we proposed partial least squares (PLS) based feature selection methods for HDSS and two theorems. The proposed methodologies include a PLS model for classification, parameter selection, PLSRanking, and PLS-based recursive feature elimination. Furthermore, we compared our proposed methods with several existing feature selection methods such as Support Vector Machine (SVM) based feature selection, SVM-based recursive feature elimination (SVMRFE), Random Forest (RF) based feature selection, RF-based recursive feature elimination (RFRFE), ReliefF algorithm and ReliefF-based recursive feature elimination (ReliefFRFE). Using twelve high-dimensional datasets from different areas of research, we evaluated the results in terms of accuracy (sensitivity and specificity), running time, and the feature subset consistency and compactness. The analysis demonstrated that the proposed approach from our research performed very well when handling both two-category and multi-category problems. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "PLS-based recursive feature elimination for high-dimensional small sample", "paper_id": "WOS:000329560700003"}