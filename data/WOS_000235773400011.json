{"auto_keywords": [{"score": 0.043716255883393715, "phrase": "tnn"}, {"score": 0.00481495049065317, "phrase": "perceptive_cycles"}, {"score": 0.004503959683578956, "phrase": "logical_document_structure_extraction"}, {"score": 0.0043560464825349275, "phrase": "nn_architecture"}, {"score": 0.004248294537944227, "phrase": "transparent_neural_network"}, {"score": 0.004040688646993605, "phrase": "document_structure"}, {"score": 0.0037480753312398754, "phrase": "interpretation_decomposition"}, {"score": 0.003418958653159371, "phrase": "successive_interpretation_steps"}, {"score": 0.0031448288291084, "phrase": "logical_element"}, {"score": 0.0029909851863915283, "phrase": "repetitive_perceptive_cycles"}, {"score": 0.002728166176898541, "phrase": "low_recognition_rate"}, {"score": 0.0022133711375320244, "phrase": "modified_filter_method"}, {"score": 0.002158505888557744, "phrase": "first_experiments"}, {"score": 0.0021049977753042253, "phrase": "scientific_documents"}], "paper_keywords": [""], "paper_abstract": "This paper describes a Neural Network (NN) approach for logical document structure extraction. In this NN architecture, called Transparent Neural Network (TNN), the document structure is stretched along the layers, allowing an interpretation decomposition from physical (NN input) to logical (NN output) level. The intermediate layers represent successive interpretation steps. Each neuron is apparent and associated to a logical element. The recognition proceeds by repetitive perceptive cycles propagating the information through the layers. In case of low recognition rate, an enhancement is achieved by error back-propagation leading to correct or pick up a more adapted input feature subset. Several feature subsets are created using a modified filter method. The first experiments performed on scientific documents are encouraging.", "paper_title": "Document logical structure analysis based on perceptive cycles", "paper_id": "WOS:000235773400011"}