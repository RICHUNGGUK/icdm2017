{"auto_keywords": [{"score": 0.04568107674629595, "phrase": "afid"}, {"score": 0.02819827616624647, "phrase": "software_faults"}, {"score": 0.007126342608170697, "phrase": "crashing_faults"}, {"score": 0.0047006879240764935, "phrase": "new_approach"}, {"score": 0.004589124394375718, "phrase": "real_software_faults"}, {"score": 0.004208881856146758, "phrase": "afid_records"}, {"score": 0.004108942392772092, "phrase": "test_case"}, {"score": 0.004050116768809519, "phrase": "faulty_version"}, {"score": 0.003992129945230457, "phrase": "source_code"}, {"score": 0.0037683358267785435, "phrase": "source_code_change"}, {"score": 0.0035914198812657897, "phrase": "test_cases"}, {"score": 0.0035399770257915466, "phrase": "significant_contribution"}, {"score": 0.0034558655164987134, "phrase": "new_research"}, {"score": 0.0033900126423990823, "phrase": "dynamic_behaviors"}, {"score": 0.003262035294895737, "phrase": "operating_system_level_monitoring_mechanism"}, {"score": 0.002948547333717581, "phrase": "wide_range"}, {"score": 0.0029203055813347874, "phrase": "programming_languages"}, {"score": 0.0027697290872182477, "phrase": "controlled_case_study"}, {"score": 0.002716915166374506, "phrase": "real_development_environment"}, {"score": 0.0026395715432958665, "phrase": "internal_development"}, {"score": 0.0024914105981393127, "phrase": "basic_approach"}, {"score": 0.0024556852466581527, "phrase": "longer_term_internal_study"}, {"score": 0.0023857603808363527, "phrase": "original_version"}, {"score": 0.002340250894008014, "phrase": "real_development"}, {"score": 0.002166711569953301, "phrase": "real_software_development"}], "paper_keywords": ["Fault collection"], "paper_abstract": "We present a new approach for creating repositories of real software faults. We have developed a tool, the Automatic Fault IDentification Tool (AFID), that implements this approach. AFID records both a fault revealing test case and a faulty version of the source code for any crashing faults that the developer discovers and a fault correcting source code change for any crashing faults that the developer corrects. The test cases are a significant contribution, because they enable new research that explores the dynamic behaviors of the software faults. AFID uses an operating system level monitoring mechanism to monitor both the compilation and execution of the application. This technique makes it straightforward for AFID to support a wide range of programming languages and compilers. We present our experience using AFID in a controlled case study and in a real development environment to collect software faults in the internal development of our group's compiler. The case studies collected several real software faults and validated the basic approach. The longer term internal study revealed weaknesses in using the original version of AFID for real development. This experience led to a number of refinements to the tool for use in real software development. We have collected over 20 real software faults in large programs and continue to collect software faults.", "paper_title": "AFID: an automated approach to collecting software faults", "paper_id": "WOS:000278573200005"}