{"auto_keywords": [{"score": 0.028098467864962343, "phrase": "proposed_model"}, {"score": 0.011377463075960773, "phrase": "innovative_frames"}, {"score": 0.00481495049065317, "phrase": "efficient_video_representation_models"}, {"score": 0.004295459433506106, "phrase": "sparsest_solution"}, {"score": 0.0042489946866108895, "phrase": "model_video_frames"}, {"score": 0.004135010810625326, "phrase": "spatio-temporal_information"}, {"score": 0.003728966994353039, "phrase": "visual_information"}, {"score": 0.0033810134162565843, "phrase": "dynamic_behaviour"}, {"score": 0.003272375502853897, "phrase": "proposed_approach"}, {"score": 0.0031845067058084583, "phrase": "recent_results"}, {"score": 0.002999386721353559, "phrase": "common_frame"}, {"score": 0.0029029754274913803, "phrase": "video_segment"}, {"score": 0.0028096544129939277, "phrase": "proposed_modeling_framework"}, {"score": 0.002779217021776702, "phrase": "common_and_innovative_visuals"}, {"score": 0.0025611773887867255, "phrase": "scene_change_boundaries"}, {"score": 0.0024653491388223546, "phrase": "multiple_scenes"}, {"score": 0.0022228943786652914, "phrase": "motion_estimation"}, {"score": 0.00217496508306238, "phrase": "image_segmentation"}, {"score": 0.002128067018576581, "phrase": "object_tracking"}, {"score": 0.0021049977753042253, "phrase": "video_editing"}], "paper_keywords": ["Video models", " sparse coding", " compressed sensing", " common and innovative parts"], "paper_abstract": "Efficient video representation models are critical for many video analysis and processing tasks. In this paper, we present a framework based on the concept of finding the sparsest solution to model video frames. To model the spatio-temporal information, frames from one scene are decomposed into two components: 1) a common frame, which describes the visual information common to all the frames in the scene/segment and 2) a set of innovative frames, which depicts the dynamic behaviour of the scene. The proposed approach exploits and builds on recent results in the field of compressed sensing to jointly estimate the common frame and the innovative frames for each video segment. We refer to the proposed modeling framework by common and innovative visuals (CIV). We show how the proposed model can be utilized to find scene change boundaries and extend CIV to videos from multiple scenes. Furthermore, the proposed model is robust to noise and can be used for various video processing applications without relying on motion estimation and detection or image segmentation. Results for object tracking, video editing (object removal, inpainting), and scene change detection are presented to demonstrate the efficiency and performance of the proposed model.", "paper_title": "Common and Innovative Visuals: A Sparsity Modeling Framework for Video", "paper_id": "WOS:000348366200005"}