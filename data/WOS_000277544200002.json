{"auto_keywords": [{"score": 0.04534393383857731, "phrase": "emotional_speech"}, {"score": 0.03942705680162171, "phrase": "hmm-based_method"}, {"score": 0.013501768491393397, "phrase": "emotional_strength"}, {"score": 0.009086783843392718, "phrase": "unit_selection_methods"}, {"score": 0.00481495049065317, "phrase": "statistical_parametric"}, {"score": 0.00477513738640734, "phrase": "unit_selection_speech_synthesis_systems"}, {"score": 0.004505538613259573, "phrase": "hmm"}, {"score": 0.004250969091124481, "phrase": "carefully_designed_perceptual_tests"}, {"score": 0.004198323646273642, "phrase": "speech_quality"}, {"score": 0.004163587877500036, "phrase": "emotion_identification_rates"}, {"score": 0.004044251230868813, "phrase": "six_emotions"}, {"score": 0.003977594755967813, "phrase": "-_happiness"}, {"score": 0.003660374693346876, "phrase": "source_components"}, {"score": 0.003439117493141663, "phrase": "hmm_method"}, {"score": 0.0034106416719768035, "phrase": "significantly_better_neutral_speech"}, {"score": 0.0033128141572497704, "phrase": "similar_quality"}, {"score": 0.003231191164622055, "phrase": "context-dependent_prosodic_patterns"}, {"score": 0.0031254704616199614, "phrase": "unit_selection_method"}, {"score": 0.0030995835539697893, "phrase": "better_emotional_strength_scores"}, {"score": 0.002828556054338357, "phrase": "spectral_and_prosodic_components"}, {"score": 0.002624482632439123, "phrase": "prosodic_components"}, {"score": 0.002602734354498382, "phrase": "hmm-based_synthetic_speech"}, {"score": 0.002496659907186784, "phrase": "previous_results"}, {"score": 0.0024759682272230735, "phrase": "listener_judgements"}, {"score": 0.0024554476124885806, "phrase": "speaker_similarity"}, {"score": 0.0024350966556966757, "phrase": "neutral_speech"}, {"score": 0.002306855521822739, "phrase": "hmm-based_methods"}, {"score": 0.002268769196700254, "phrase": "spectral_modeling"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Emotional speech synthesis", " HMM-based synthesis", " Unit selection"], "paper_abstract": "We have applied two state-of-the-art speech synthesis techniques (unit selection and HMM-based synthesis) to the synthesis of emotional speech. A series of carefully designed perceptual tests to evaluate speech quality, emotion identification rates and emotional strength were used for the six emotions which we recorded - happiness, sadness, anger, surprise, fear, disgust. For the HMM-based method, we evaluated spectral and source components separately and identified which components contribute to which emotion. Our analysis shows that, although the HMM method produces significantly better neutral speech, the two methods produce emotional speech of similar quality, except for emotions having context-dependent prosodic patterns. Whilst synthetic speech produced using the unit selection method has better emotional strength scores than the HMM-based method, the HMM-based method has the ability to manipulate the emotional strength. For emotions that are characterized by both spectral and prosodic components, synthetic speech using unit selection methods was more accurately identified by listeners. For emotions mainly characterized by prosodic components, HMM-based synthetic speech was more accurately identified. This finding differs from previous results regarding listener judgements of speaker similarity for neutral speech. We conclude that unit selection methods require improvements to prosodic modeling and that HMM-based methods require improvements to spectral modeling for emotional speech. Certain emotions cannot be reproduced well by either method. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Analysis of statistical parametric and unit selection speech synthesis systems applied to emotional speech", "paper_id": "WOS:000277544200002"}