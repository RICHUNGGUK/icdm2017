{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "sparse_ridge"}, {"score": 0.004769702911065878, "phrase": "kernel_regressor"}, {"score": 0.004571269461883144, "phrase": "sparse_ridgelet_kernel_regressor"}, {"score": 0.00438105507792004, "phrase": "ridgelet_theory"}, {"score": 0.0043194180167921165, "phrase": "sparse_theory"}, {"score": 0.004278807087784626, "phrase": "kernel_trick"}, {"score": 0.004178935413340453, "phrase": "dimensionality_non-separable_ridgelet_kernels"}, {"score": 0.004139639802595566, "phrase": "srkr"}, {"score": 0.004023947242621452, "phrase": "high-dimensional_data"}, {"score": 0.0039114753002009485, "phrase": "preferable_future"}, {"score": 0.0038746849003761024, "phrase": "sequential_learning"}, {"score": 0.0036610702290043387, "phrase": "batch_learning"}, {"score": 0.003541923233726252, "phrase": "new_kernel_method"}, {"score": 0.0034920505103165403, "phrase": "online_setting"}, {"score": 0.0034428776029411974, "phrase": "sequential_extreme_learning_scheme"}, {"score": 0.0033943947596098583, "phrase": "online_learning_algorithm"}, {"score": 0.003299460925313939, "phrase": "online_sequential_extreme_learning_algorithm"}, {"score": 0.003015950477134494, "phrase": "training_data_one-by-one_or_chunk"}, {"score": 0.002769805263310232, "phrase": "training_procedure"}, {"score": 0.0026169435194789772, "phrase": "online_learning"}, {"score": 0.0025922974876210194, "phrase": "evolution_scheme"}, {"score": 0.002507845411496512, "phrase": "'good'_sparse_regressor"}, {"score": 0.002426137929553722, "phrase": "nonlinear_time-series_prediction_problems"}, {"score": 0.0022280223816618736, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multiscale geometric analysis", " Sparse Ridgelet Kernel Regressor", " Online Sequential Extreme Learning", " Algorithm"], "paper_abstract": "In this paper, a Sparse Ridgelet Kernel Regressor (SRKR) is constructed by combing the ridgelet theory, the sparse theory with kernel trick. By using the dimensionality non-separable ridgelet kernels, SRKR is capable of processing the high-dimensional data more efficiently. Considering the preferable future of sequential learning over batch learning in problems where data arrive constantly and where batch learning is expensive, we exploit the new kernel method in an online setting using the sequential extreme learning scheme. The online learning algorithm of the examples, named Online Sequential Extreme Learning Algorithm (OS-ELA) is employed to rapidly produce a sequence of estimations. OS-ELA learns the training data one-by-one or chunk by chunk (with fixed or varying size), and discards them as long as the training procedure for those data is completed to keep the memory bounded in online learning. Evolution scheme is also incorporated to obtain a 'good' sparse regressor. Experiments are taken on some nonlinear time-series prediction problems, in which the examples are available one by one. Some comparisons are made and the experimental results show its efficiency and superiority to its counterparts. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Sparse Ridge let Kernel Regressor and its online sequential extreme learning", "paper_id": "WOS:000335486000022"}