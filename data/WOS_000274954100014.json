{"auto_keywords": [{"score": 0.034692465572853035, "phrase": "marginal_distribution"}, {"score": 0.00481495049065317, "phrase": "k-nearest_neighbor_search"}, {"score": 0.004650896226390719, "phrase": "novel_approach"}, {"score": 0.004597457370802855, "phrase": "k-nearest_neighbor"}, {"score": 0.004389745162172933, "phrase": "euclidean_metric"}, {"score": 0.004048483412089098, "phrase": "brute-force_algorithm"}, {"score": 0.003777088546146369, "phrase": "probably_correct_approach"}, {"score": 0.0036694287631595995, "phrase": "correct_set"}, {"score": 0.0036272258853286433, "phrase": "k-nearest_neighbors"}, {"score": 0.0035442655396704724, "phrase": "high_probability"}, {"score": 0.0033839745649214548, "phrase": "searching_time"}, {"score": 0.0032309093154028663, "phrase": "k_th_nearest_neighbors"}, {"score": 0.003049247243348174, "phrase": "stored_data"}, {"score": 0.002861160152640875, "phrase": "basic_nature"}, {"score": 0.00270023138867066, "phrase": "implemented_algorithm"}, {"score": 0.002623184850933423, "phrase": "probabilistic_variant"}, {"score": 0.0025780134737796085, "phrase": "partial_distance"}, {"score": 0.0024756080101497086, "phrase": "data_size"}, {"score": 0.0021794454466797382, "phrase": "fixed_dimension"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Pattern recognition", " The k-nearest neighbor method", " Probably correct algorithm", " PAC framework"], "paper_abstract": "A novel approach for k-nearest neighbor (k-NN) searching with Euclidean metric is described. It is well known that many sophisticated algorithms cannot beat the brute-force algorithm when the dimensionality is high. In this study, a probably correct approach, in which the correct set of k-nearest neighbors is obtained in high probability, is proposed for greatly reducing the searching time. We exploit the marginal distribution of the k th nearest neighbors in low dimensions, which is estimated from the stored data (an empirical percentile approach). We analyze the basic nature of the marginal distribution and show the advantage of the implemented algorithm, which is a probabilistic variant of the partial distance searching. Its query time is sublinear in data size n, that is, O(mn delta) with S=o(1) in n and delta <= 1, for any fixed dimension m. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Probably correct k-nearest neighbor search in high dimensions", "paper_id": "WOS:000274954100014"}