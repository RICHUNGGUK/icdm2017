{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "robotic_emotional_expression_generation"}, {"score": 0.0047395356621991935, "phrase": "mood_transition"}, {"score": 0.004472935829694716, "phrase": "mood_transition_design"}, {"score": 0.004356741449157895, "phrase": "autonomous_emotional_interaction"}, {"score": 0.004133292222875435, "phrase": "robot_emotion"}, {"score": 0.00392125815948488, "phrase": "emotional_expressions"}, {"score": 0.0037793152987497286, "phrase": "robot_personality"}, {"score": 0.0036043137580229873, "phrase": "five_factor_model"}, {"score": 0.003492155652400838, "phrase": "big_five_personality_traits"}, {"score": 0.003437387719239532, "phrase": "influence_factors"}, {"score": 0.0034013521529056715, "phrase": "robot_mood_transition"}, {"score": 0.003226744277130179, "phrase": "basic_robotic_emotional_behaviors"}, {"score": 0.0031098631445657158, "phrase": "robotic_emotional_states"}, {"score": 0.0030772505522663612, "phrase": "continuous_facial_expressions"}, {"score": 0.003028969851366049, "phrase": "artificial_face"}, {"score": 0.002828331235643921, "phrase": "humanlike_appearance"}, {"score": 0.0027258422018680453, "phrase": "human-robot_interaction"}, {"score": 0.0026830601040919166, "phrase": "artificial_face_simulator"}, {"score": 0.0025452314655691165, "phrase": "proposed_methods"}, {"score": 0.002518525107994039, "phrase": "questionnaire_surveys"}, {"score": 0.002376559242152662, "phrase": "proposed_method"}, {"score": 0.002339246282204109, "phrase": "robotic_responses"}, {"score": 0.0023025177990160487, "phrase": "user's_emotional_expressions"}, {"score": 0.0022783523466965187, "phrase": "preliminary_experimental_results"}, {"score": 0.002242577809454225, "phrase": "robotic_head"}, {"score": 0.0021957487795963666, "phrase": "proposed_mood_state_transition_scheme"}, {"score": 0.0021385822825864425, "phrase": "user's_emotional_changes"}, {"score": 0.0021049977753042253, "phrase": "continuous_manner"}], "paper_keywords": ["Emotional model", " facial expression generation", " facial expression recognition", " robotic behavior fusion", " robotic emotional interactions", " robotic mood state transition"], "paper_abstract": "This paper presents a method of mood transition design of a robot for autonomous emotional interaction with humans. A 2-D emotional model is proposed to combine robot emotion, mood, and personality in order to generate emotional expressions. In this design, the robot personality is programmed by adjusting the factors of the five factor model proposed by psychologists. From Big Five personality traits, the influence factors of robot mood transition are determined. Furthermore, a method to fuse basic robotic emotional behaviors is proposed in order to manifest robotic emotional states via continuous facial expressions. An artificial face on a screen is a way to provide a robot with a humanlike appearance, which might be useful for human-robot interaction. An artificial face simulator has been implemented to show the effectiveness of the proposed methods. Questionnaire surveys have been carried out to evaluate the effectiveness of the proposed method by observing robotic responses to a user's emotional expressions. Preliminary experimental results on a robotic head show that the proposed mood state transition scheme appropriately responds to a user's emotional changes in a continuous manner.", "paper_title": "Robotic Emotional Expression Generation Based on Mood Transition and Personality Model", "paper_id": "WOS:000322029400012"}