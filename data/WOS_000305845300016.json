{"auto_keywords": [{"score": 0.049272843653565726, "phrase": "active_learning"}, {"score": 0.04770962178512547, "phrase": "informative_examples"}, {"score": 0.027125384680946746, "phrase": "svm"}, {"score": 0.00481495049065317, "phrase": "support_vector_machines"}, {"score": 0.004766487181100495, "phrase": "classification_tasks"}, {"score": 0.004531357177195719, "phrase": "big_unlabeled_dataset"}, {"score": 0.004410713064804144, "phrase": "classification_pattern"}, {"score": 0.00430777589162606, "phrase": "new_examples"}, {"score": 0.0042500322609733574, "phrase": "selection_result"}, {"score": 0.004013098289856805, "phrase": "manual_effort"}, {"score": 0.003959288961559545, "phrase": "data_complexity"}, {"score": 0.003919404114585274, "phrase": "data_redundancy"}, {"score": 0.0038668462001710314, "phrase": "learning_efficiency"}, {"score": 0.0037765536386719775, "phrase": "new_active_learning_strategy"}, {"score": 0.003751143724152193, "phrase": "pool-based_settings"}, {"score": 0.003255189076644247, "phrase": "traditional_concept_learning_model"}, {"score": 0.003063180586734181, "phrase": "current_version_space"}, {"score": 0.0030118779844670353, "phrase": "unlabeled_examples"}, {"score": 0.0029815085406590426, "phrase": "new_sample_selection_criterion"}, {"score": 0.0029118285733827406, "phrase": "whole_learning_process"}, {"score": 0.002853396755102163, "phrase": "additional_knowledge"}, {"score": 0.0027492917990724467, "phrase": "vector_machine"}, {"score": 0.0026222551419772867, "phrase": "specific_algorithm"}, {"score": 0.0024591621759745648, "phrase": "gs_structure"}, {"score": 0.0024343522820859578, "phrase": "sample_selection_process"}, {"score": 0.002361410799860054, "phrase": "initial_version_space"}, {"score": 0.002321834168782981, "phrase": "proposed_i-alsvm"}, {"score": 0.0022446552199168472, "phrase": "experimental_result"}, {"score": 0.0021921581733031514, "phrase": "generalization_capability"}, {"score": 0.002162711766975021, "phrase": "good_feasibility"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Active learning", " Concept learning", " Inconsistency", " Sample selection", " Support vector machine"], "paper_abstract": "In classification tasks, active learning is often used to select out a set of informative examples from a big unlabeled dataset. The objective is to learn a classification pattern that can accurately predict labels of new examples by using the selection result which is expected to contain as few examples as possible. The selection of informative examples also reduces the manual effort for labeling, data complexity, and data redundancy, thus improves learning efficiency. In this paper, a new active learning strategy with pool-based settings, called inconsistency-based active learning, is proposed. This strategy is built up under the guidance of two classical works: (1) the learning philosophy of query-by-committee (QBC) algorithm; and (2) the structure of the traditional concept learning model: from-general-to-specific (GS) ordering. By constructing two extreme hypotheses of the current version space, the strategy evaluates unlabeled examples by a new sample selection criterion as inconsistency value, and the whole learning process could be implemented without any additional knowledge. Besides, since active learning is favorably applied to support vector machine (SVM) and its related applications, the strategy is further restricted to a specific algorithm called inconsistency-based active learning for SVM (I-ALSVM). By building up a GS structure, the sample selection process in our strategy is formed by searching through the initial version space. We compare the proposed I-ALSVM with several other pool-based methods for SVM on selected datasets. The experimental result shows that, in terms of generalization capability, our model exhibits good feasibility and competitiveness. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Inconsistency-based active learning for support vector machines", "paper_id": "WOS:000305845300016"}