{"auto_keywords": [{"score": 0.03455018268948868, "phrase": "pca"}, {"score": 0.02265499889209597, "phrase": "lda"}, {"score": 0.014243191462592774, "phrase": "robust"}, {"score": 0.008970643138237916, "phrase": "dp"}, {"score": 0.005974418154321071, "phrase": "hri"}, {"score": 0.004529093447865156, "phrase": "natural_human_gestures."}, {"score": 0.004312622975366676, "phrase": "robust_and_friendly_human-robot_interface"}, {"score": 0.00405646687267772, "phrase": "natural_human_gestures"}, {"score": 0.003910106508089187, "phrase": "triple-face_detection_method"}, {"score": 0.0038389110156920926, "phrase": "fuzzy_logic_controller"}, {"score": 0.0037459885494311217, "phrase": "tracking_system"}, {"score": 0.0035233696341819437, "phrase": "dynamic_and_cluttered_working_environment"}, {"score": 0.003375429082739004, "phrase": "combined_classifier"}, {"score": 0.0033139366449568565, "phrase": "principal_component_analysis"}, {"score": 0.003213920601037463, "phrase": "back-propagation_artificial_neural_network"}, {"score": 0.003116913644889395, "phrase": "single_and_successive_commands"}, {"score": 0.0030601162942933665, "phrase": "facial_positions"}, {"score": 0.003022825806274343, "phrase": "hand_gestures"}, {"score": 0.002949598537993663, "phrase": "real-time_command_recognition"}, {"score": 0.002690406375639144, "phrase": "hri_system"}, {"score": 0.002641360377825228, "phrase": "member_recognition"}, {"score": 0.0026091594819333654, "phrase": "expression_recognition"}, {"score": 0.002469032978674379, "phrase": "linear_discriminant_analysis"}, {"score": 0.0023944552329463035, "phrase": "bpann."}, {"score": 0.0023652572260178637, "phrase": "experimental_results"}, {"score": 0.0023079225317714815, "phrase": "proposed_hri_system"}, {"score": 0.0022519745140925475, "phrase": "real-time_face_detection"}, {"score": 0.0021309898622781124, "phrase": "corresponding_gesture_commands"}, {"score": 0.0021049977753042253, "phrase": "eight_frames"}], "paper_keywords": ["HRI system", " triple face detection", " face tracking", " hand gesture recognition", " member recognition", " expression recognition"], "paper_abstract": "In this paper, we design a robust and friendly human-robot interface (HRI) system for our intelligent mobile robot based only on natural human gestures. It consists of a triple-face detection method and a fuzzy logic controller (FLC)-Kalman filter tracking system to check the users and predict their current position in a dynamic and cluttered working environment. In addition, through the combined classifier of the principal component analysis (PCA) and back-propagation artificial neural network (BPANN), single and successive commands defined by facial positions and hand gestures are identified for real-time command recognition after dynamic programming (DP). Therefore, the users can instruct this HRI system to make member recognition or expression recognition corresponding to their gesture commands, respectively based on the linear discriminant analysis (LDA) and BPANN. The experimental results prove that the proposed HRI system perform accurately in real-time face detection and tracking, and robustly react to the corresponding gesture commands at eight frames per second (fps).", "paper_title": "A ROBUST AND FRIENDLY HUMAN-ROBOT INTERFACE SYSTEM BASED ON NATURAL HUMAN GESTURES", "paper_id": "WOS:000282216200001"}