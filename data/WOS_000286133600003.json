{"auto_keywords": [{"score": 0.03762867376091313, "phrase": "measurement_density"}, {"score": 0.00481495049065317, "phrase": "least_squares_estimation_without_priors"}, {"score": 0.004704844560325455, "phrase": "optimal_estimator"}, {"score": 0.00461246494886034, "phrase": "training_samples"}, {"score": 0.004462494148878735, "phrase": "prior_probability_model"}, {"score": 0.004418456827500267, "phrase": "true_values"}, {"score": 0.004190796368475121, "phrase": "measurement_process"}, {"score": 0.004163172790791119, "phrase": "known_statistics"}, {"score": 0.00400119808662365, "phrase": "unsupervised_measurements"}, {"score": 0.003922580121023413, "phrase": "corresponding_true_value"}, {"score": 0.003858241873901003, "phrase": "unknown_distribution"}, {"score": 0.003794954883650141, "phrase": "general_expression"}, {"score": 0.003757480190200645, "phrase": "nonparametric_empirical_bayes_least_squares"}, {"score": 0.003732702104052828, "phrase": "nebls"}, {"score": 0.0036472537997966938, "phrase": "optimal_least_squares"}, {"score": 0.0035285548582081627, "phrase": "explicit_reference"}, {"score": 0.0033576858946833587, "phrase": "specific_forms"}, {"score": 0.0033025823350563087, "phrase": "different_measurement_processes"}, {"score": 0.003205657519784272, "phrase": "nebls_estimators"}, {"score": 0.0031115683920520773, "phrase": "estimation_error"}, {"score": 0.0030003014343035965, "phrase": "stein's_unbiased_risk_estimator"}, {"score": 0.00290259605431505, "phrase": "additive_gaussian_noise_case"}, {"score": 0.0028739078688746374, "phrase": "error_expression"}, {"score": 0.0028173769301594745, "phrase": "noisy_measurement_samples"}, {"score": 0.0027619548979328154, "phrase": "supervised_training_data"}, {"score": 0.0027256122357680393, "phrase": "generalized_sure-optimized_parametric_least_squares"}, {"score": 0.0026543514413663893, "phrase": "special_case"}, {"score": 0.0026281103468378856, "phrase": "linear_parameterization"}, {"score": 0.0025678829712650437, "phrase": "nonlinear_kernel_functions"}, {"score": 0.0025340874787959195, "phrase": "objective_function"}, {"score": 0.0024678216843278806, "phrase": "incremental_form"}, {"score": 0.0023559890904375526, "phrase": "nebls_form"}, {"score": 0.002294369814584028, "phrase": "score-matching_procedure"}, {"score": 0.002279217896185919, "phrase": "parametric_density_estimation"}, {"score": 0.002118993962770973, "phrase": "regression_counterparts"}, {"score": 0.0021049977753042253, "phrase": "moderate_to_large_amounts"}], "paper_keywords": [""], "paper_abstract": "Selection of an optimal estimator typically relies on either supervised training samples (pairs of measurements and their associated true values) or a prior probability model for the true values. Here, we consider the problem of obtaining a least squares estimator given a measurement process with known statistics (i.e., a likelihood function) and a set of unsupervised measurements, each arising from a corresponding true value drawn randomly from an unknown distribution. We develop a general expression for a nonparametric empirical Bayes least squares (NEBLS) estimator, which expresses the optimal least squares estimator in terms of the measurement density, with no explicit reference to the unknown (prior) density. We study the conditions under which such estimators exist and derive specific forms for a variety of different measurement processes. We further show that each of these NEBLS estimators may be used to express the mean squared estimation error as an expectation over the measurement density alone, thus generalizing Stein's unbiased risk estimator (SURE), which provides such an expression for the additive gaussian noise case. This error expression may then be optimized over noisy measurement samples, in the absence of supervised training data, yielding a generalized SURE-optimized parametric least squares (SURE2PLS) estimator. In the special case of a linear parameterization (i.e., a sum of nonlinear kernel functions), the objective function is quadratic, and we derive an incremental form for learning this estimator from data. We also show that combining the NEBLS form with its corresponding generalized SURE expression produces a generalization of the score-matching procedure for parametric density estimation. Finally, we have implemented several examples of such estimators, and we show that their performance is comparable to their optimal Bayesian or supervised regression counterparts for moderate to large amounts of data.", "paper_title": "Least Squares Estimation Without Priors or Supervision", "paper_id": "WOS:000286133600003"}