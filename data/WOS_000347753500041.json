{"auto_keywords": [{"score": 0.045781263860754984, "phrase": "class_label"}, {"score": 0.013585517269476361, "phrase": "multi-labeler_learning"}, {"score": 0.010933341285891993, "phrase": "multi-instance_learning"}, {"score": 0.00481495049065317, "phrase": "dual_annotation_ambiguity"}, {"score": 0.004750873844061641, "phrase": "min-max_framework"}, {"score": 0.0046046429665581555, "phrase": "annotation_ambiguity"}, {"score": 0.004502943680955863, "phrase": "multiple_annotators"}, {"score": 0.0038855864345030563, "phrase": "input_vectors"}, {"score": 0.0037827603118271757, "phrase": "individual_instance"}, {"score": 0.003149094460617212, "phrase": "labeling_ambiguity"}, {"score": 0.0030113280682863234, "phrase": "dual_ambiguity_problem"}, {"score": 0.002931569771634119, "phrase": "novel_optimization_framework"}, {"score": 0.0028795712616923462, "phrase": "hinge_loss"}, {"score": 0.0028284924551705516, "phrase": "weighted_consensus"}, {"score": 0.0028032928749970026, "phrase": "different_labelers'_labels"}, {"score": 0.002716844480081738, "phrase": "loss_functions"}, {"score": 0.0026686444508167875, "phrase": "multiple_instances"}, {"score": 0.0026330549554033876, "phrase": "proposed_formulation"}, {"score": 0.002506562885555113, "phrase": "labeling_bias"}, {"score": 0.002473129577319634, "phrase": "alternating_optimization_algorithm"}, {"score": 0.002354302193867031, "phrase": "proposed_algorithms"}, {"score": 0.0023333173799963795, "phrase": "existing_methods"}, {"score": 0.0023125191783901367, "phrase": "benchmark_data_sets"}, {"score": 0.0022816681646340518, "phrase": "document_classification"}, {"score": 0.0022013916728990564, "phrase": "heart_wall_motion_analysis"}, {"score": 0.002162316557411786, "phrase": "multiple_radiologists"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Classification", " Data annotation ambiguity", " Learning from multiple data annotators", " Multiple instance learning"], "paper_abstract": "Many pattern recognition problems confront two sources of annotation ambiguity where (1) multiple annotators have provided their versions of a class label which may not be consistent with one another, which forms multi-labeler learning; (2) and meanwhile a class label is associated with a bag of input vectors or instances rather than each individual instance and a bag is positive for a class label as long as one of its instances shows an evidence of that class, which is often referred to as multi-instance learning. Existing methods for multi-labeler learning and multi-instance learning only address one source of the labeling ambiguity. They are not trivially feasible to tackle the dual ambiguity problem. We hence propose a novel optimization framework by modifying the hinge loss to employ the weighted consensus of different labelers' labels and further generalizing the notion of loss functions to bags of multiple instances. The proposed formulation can be approximately solved by two mathematically tractable models that accommodate two types of labeling bias. An alternating optimization algorithm has been derived to efficiently solve the two models. The proposed algorithms outperform existing methods on benchmark data sets collected for document classification, real-life crowd-sourced data sets, and a medical problem of heart wall motion analysis with diagnoses from multiple radiologists. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Learning classifiers from dual annotation ambiguity via a min-max framework", "paper_id": "WOS:000347753500041"}