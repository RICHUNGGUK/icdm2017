{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "asymmetric_pruning"}, {"score": 0.004769182299692333, "phrase": "learning_cascade_detectors"}, {"score": 0.004723847090183984, "phrase": "cascade_classifiers"}, {"score": 0.004568525347438891, "phrase": "real-time_object_detection"}, {"score": 0.004376273644295806, "phrase": "training_cascade_detectors"}, {"score": 0.004252602474733162, "phrase": "node_classifier"}, {"score": 0.0041522059428827345, "phrase": "symmetric_classifier"}, {"score": 0.004073590964805314, "phrase": "low_misclassification_error_rate"}, {"score": 0.003977403701783668, "phrase": "optimal_node_learning_goal"}, {"score": 0.0037199473428123175, "phrase": "moderate_false_positive_rate"}, {"score": 0.0035632774896594524, "phrase": "new_approach"}, {"score": 0.00349577373145384, "phrase": "effective_node_classifier"}, {"score": 0.0034459835582278746, "phrase": "cascade_detector"}, {"score": 0.00326939082861424, "phrase": "redundant_weak_classifiers"}, {"score": 0.003131637033429892, "phrase": "final_detector"}, {"score": 0.003072285184441679, "phrase": "asymmetric_learning_objective"}, {"score": 0.0030285084113651035, "phrase": "cascade_architecture"}, {"score": 0.00290087451159631, "phrase": "classifier_training"}, {"score": 0.002739001004969201, "phrase": "final_classifier"}, {"score": 0.002699960312990493, "phrase": "weak_classifiers"}, {"score": 0.0026235360404084137, "phrase": "asymmetric_learning_criterion"}, {"score": 0.002488985155689794, "phrase": "learning_time"}, {"score": 0.0024417832296664698, "phrase": "pre-determined_learning_objective"}, {"score": 0.002350041573006264, "phrase": "car_data_sets"}, {"score": 0.0022834993174767016, "phrase": "proposed_algorithm"}, {"score": 0.0022401855403251653, "phrase": "fddb_face_data_sets"}, {"score": 0.002176747110119268, "phrase": "state-of-the-art_performance"}], "paper_keywords": ["Asymmetric classification", " asymmetric pruning", " boosting", " cascade classifier", " feature selection", " object detection"], "paper_abstract": "Cascade classifiers are one of the most important contributions to real-time object detection. Nonetheless, there are many challenging problems arising in training cascade detectors. One common issue is that the node classifier is trained with a symmetric classifier. Having a low misclassification error rate does not guarantee an optimal node learning goal in cascade classifiers, i.e., an extremely high detection rate with a moderate false positive rate. In this work, we present a new approach to train an effective node classifier in a cascade detector. The algorithm is based on two key observations: 1) Redundant weak classifiers can be safely discarded; 2) The final detector should satisfy the asymmetric learning objective of the cascade architecture. To achieve this, we separate the classifier training into two steps: finding a pool of discriminative weak classifiers/features and training the final classifier by pruning weak classifiers which contribute little to the asymmetric learning criterion (asymmetric classifier construction). Our model reduction approach helps accelerate the learning time while achieving the pre-determined learning objective. Experimental results on both face and car data sets verify the effectiveness of the proposed algorithm. On the FDDB face data sets, our approach achieves the state-of-the-art performance, which demonstrates the advantage of our approach.", "paper_title": "Asymmetric Pruning for Learning Cascade Detectors", "paper_id": "WOS:000340295600008"}