{"auto_keywords": [{"score": 0.025141068979759856, "phrase": "artemis"}, {"score": 0.00481495049065317, "phrase": "enhancing_training_collections_for_image_annotation"}, {"score": 0.004533142516832776, "phrase": "tagged_web_images"}, {"score": 0.004398457709182882, "phrase": "labeled_training_examples"}, {"score": 0.004345706062641742, "phrase": "visual_concept_learning"}, {"score": 0.004165987300206134, "phrase": "automatic_training_data_selection"}, {"score": 0.00406663414150229, "phrase": "highly_inaccurate_tags"}, {"score": 0.004017846065981189, "phrase": "atypical_images"}, {"score": 0.003922011960904278, "phrase": "manually_curated_training_data_sets"}, {"score": 0.0038284549148537373, "phrase": "preferred_choice"}, {"score": 0.0036700484729006136, "phrase": "artemis-a_scheme"}, {"score": 0.00360417515510547, "phrase": "automatic_selection"}, {"score": 0.0035609154384221567, "phrase": "training_images"}, {"score": 0.003496994062890991, "phrase": "instance-weighted_mixture_modeling_framework"}, {"score": 0.003213489259323924, "phrase": "parameter_estimation"}, {"score": 0.0029351141718104725, "phrase": "hypothetical_local_mapping"}, {"score": 0.002813566267090177, "phrase": "diverse_mathematical_forms"}, {"score": 0.0025388705701873075, "phrase": "training_examples"}, {"score": 0.002478225374613311, "phrase": "top-ranked_images"}, {"score": 0.0024336917123957387, "phrase": "likelihood-based_image_ranking"}, {"score": 0.0023328599525181707, "phrase": "higher_resilience"}, {"score": 0.0022497569011987587, "phrase": "large_training_data_collection"}, {"score": 0.0021827653135510225, "phrase": "artemis-trained_image_annotation_system"}, {"score": 0.0021049977753042253, "phrase": "manually_curated_data_sets"}], "paper_keywords": ["Training data selection", " statistical learning", " clustering methods", " instance-weighted mixture models", " hypothetical local mapping", " ARTEMIS"], "paper_abstract": "Tagged Web images provide an abundance of labeled training examples for visual concept learning. However, the performance of automatic training data selection is susceptible to highly inaccurate tags and atypical images. Consequently, manually curated training data sets are still a preferred choice for many image annotation systems. This paper introduces ARTEMIS-a scheme to enhance automatic selection of training images using an instance-weighted mixture modeling framework. An optimization algorithm is derived to learn instance-weights in addition to mixture parameter estimation, essentially adapting to the noise associated with each example. The mechanism of hypothetical local mapping is evoked so that data in diverse mathematical forms or modalities can be cohesively treated as the system maintains tractability in optimization. Finally, training examples are selected from top-ranked images of a likelihood-based image ranking. Experiments indicate that ARTEMIS exhibits higher resilience to noise than several baselines for large training data collection. The performance of ARTEMIS-trained image annotation system is comparable with usage of manually curated data sets.", "paper_title": "Enhancing Training Collections for Image Annotation: An Instance-Weighted Mixture Modeling Approach", "paper_id": "WOS:000324382700011"}