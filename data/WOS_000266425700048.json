{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "computational_issues"}, {"score": 0.004701015188740582, "phrase": "semi-supervised_local_fisher_discriminant_analysis"}, {"score": 0.004589763483242731, "phrase": "dimensionality_reduction"}, {"score": 0.004322967486451877, "phrase": "important_preprocessing_steps"}, {"score": 0.004220624516321415, "phrase": "practical_pattern_recognition"}, {"score": 0.003975200317233532, "phrase": "local_fisher"}, {"score": 0.0036553070575015344, "phrase": "semi-supervised_and_local_extension"}, {"score": 0.002981216610222911, "phrase": "data_dimensionality"}, {"score": 0.0027741761880779535, "phrase": "naive_use"}, {"score": 0.00255068452076921, "phrase": "high_computational_costs"}, {"score": 0.0024901940672239784, "phrase": "large_memory_requirement"}, {"score": 0.002262209824105154, "phrase": "computational_tricks"}, {"score": 0.0021049977753042253, "phrase": "large-scale_problems"}], "paper_keywords": ["dimensionality reduction", " semi-supervised learning", " semi-supervised local Fisher discriminant analysis", " sparsity", " generalized eigenvalue problem"], "paper_abstract": "Dimensionality reduction is one of the important preprocessing steps in practical pattern recognition. SEmi-supervised Local Fisher discriminant analysis (SELF)-which is a semi-Supervised and local extension of Fisher discriminant analysis-was shown to work excellently in experiments. However, when data dimensionality is very high. a naive use of SELF is prohibitive due to high computational costs and large memory requirement. In this paper, we introduce computational tricks for making SELF applicable to large-scale problems.", "paper_title": "On Computational Issues of Semi-Supervised Local Fisher Discriminant Analysis", "paper_id": "WOS:000266425700048"}