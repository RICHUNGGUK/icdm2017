{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "scene_capture"}, {"score": 0.004774324145784758, "phrase": "image_display"}, {"score": 0.0046544807197808095, "phrase": "bright_images"}, {"score": 0.004576253356889219, "phrase": "large_apertures"}, {"score": 0.004312622975366676, "phrase": "robust_scene"}, {"score": 0.00416882434439484, "phrase": "projection_defocus_analysis"}, {"score": 0.004081385289516914, "phrase": "projector's_defocus"}, {"score": 0.0040298010803060495, "phrase": "linear_system"}, {"score": 0.0038789122930433305, "phrase": "novel_temporal_defocus_analysis_method"}, {"score": 0.00378145978325955, "phrase": "camera_pixel"}, {"score": 0.003459191419478298, "phrase": "depth_discontinuities"}, {"score": 0.0033579708256295847, "phrase": "coaxial_projector-camera_system"}, {"score": 0.0032184697893776052, "phrase": "camera_pixels"}, {"score": 0.0031643005824589917, "phrase": "missing_parts"}, {"score": 0.0030847461428168614, "phrase": "recovered_scene_geometry"}, {"score": 0.0030199761431186434, "phrase": "refocus_synthesis"}, {"score": 0.0029817668105720924, "phrase": "depth-based_image_composition"}, {"score": 0.0028216858159564808, "phrase": "defocus_compensation_method"}, {"score": 0.0027741761880779535, "phrase": "projection_image"}, {"score": 0.0023408288327263316, "phrase": "projector_defocus"}, {"score": 0.0023013968622710847, "phrase": "strong_pixelation_artifacts"}, {"score": 0.0022722584151582616, "phrase": "digital_projectors"}, {"score": 0.002196342933346204, "phrase": "projected_image"}, {"score": 0.0021049977753042253, "phrase": "real_scenes"}], "paper_keywords": ["projector defocus", " temporal defocus analysis", " depth recovery", " multi-focal projection", " projector depixelation", " refocus synthesis", " image composition"], "paper_abstract": "In order to produce bright images, projectors have large apertures and hence narrow depths of field. In this paper, we present methods for robust scene capture and enhanced image display based on projection defocus analysis. We model a projector's defocus using a linear system. This model is used to develop a novel temporal defocus analysis method to recover depth at each camera pixel by estimating the parameters of its projection defocus kernel in frequency domain. Compared to most depth recovery methods, our approach is more accurate near depth discontinuities. Furthermore, by using a coaxial projector-camera system, we ensure that depth is computed at all camera pixels, without any missing parts. We show that the recovered scene geometry can be used for refocus synthesis and for depth-based image composition. Using the same projector defocus model and estimation technique, we also propose a defocus compensation method that filters a projection image in a spatially-varying, depth-dependent manner to minimize its defocus blur after it is projected onto the scene. This method effectively increases the depth of field of a projector without modifying its optics. Finally, we present an algorithm that exploits projector defocus to reduce the strong pixelation artifacts produced by digital projectors, while preserving the quality of the projected image. We have experimentally verified each of our methods using real scenes.", "paper_title": "Projection defocus analysis for scene capture and image display", "paper_id": "WOS:000239817400052"}