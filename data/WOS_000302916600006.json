{"auto_keywords": [{"score": 0.02512571059927161, "phrase": "mnist"}, {"score": 0.00481495049065317, "phrase": "handwritten_digit_classification"}, {"score": 0.004706453355638515, "phrase": "latent_log-linear_models"}, {"score": 0.004574247691703376, "phrase": "log-linear_models"}, {"score": 0.0039216854691927865, "phrase": "resulting_models"}, {"score": 0.0036622637391432143, "phrase": "model_complexity"}, {"score": 0.003559284776569813, "phrase": "log-linear_mixture_models"}, {"score": 0.0034395119150793787, "phrase": "log-linear_modeling_framework"}, {"score": 0.0032860401904845522, "phrase": "deformation-aware_model"}, {"score": 0.0032302647179383915, "phrase": "image_deformations"}, {"score": 0.0031393948330209224, "phrase": "discriminative_training"}, {"score": 0.00308610073274614, "phrase": "deformation_parameters"}, {"score": 0.0028328599839713866, "phrase": "stationary_point"}, {"score": 0.002706383680762465, "phrase": "even_variants"}, {"score": 0.002442025065383455, "phrase": "usps_data"}, {"score": 0.0022802596433757565, "phrase": "generalization_capabilities"}, {"score": 0.0021784009230363627, "phrase": "significantly_fewer_parameters"}, {"score": 0.0021049977753042253, "phrase": "competitive_results"}], "paper_keywords": ["Log-linear models", " latent variables", " conditional random fields", " OCR", " image classification"], "paper_abstract": "We present latent log-linear models, an extension of log-linear models incorporating latent variables, and we propose two applications thereof: log-linear mixture models and image deformation-aware log-linear models. The resulting models are fully discriminative, can be trained efficiently, and the model complexity can be controlled. Log-linear mixture models offer additional flexibility within the log-linear modeling framework. Unlike previous approaches, the image deformation-aware model directly considers image deformations and allows for a discriminative training of the deformation parameters. Both are trained using alternating optimization. For certain variants, convergence to a stationary point is guaranteed and, in practice, even variants without this guarantee converge and find models that perform well. We tune the methods on the USPS data set and evaluate on the MNIST data set, demonstrating the generalization capabilities of our proposed models. Our models, although using significantly fewer parameters, are able to obtain competitive results with models proposed in the literature.", "paper_title": "Latent Log-Linear Models for Handwritten Digit Classification", "paper_id": "WOS:000302916600006"}