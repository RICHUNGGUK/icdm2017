{"auto_keywords": [{"score": 0.03878676535760206, "phrase": "cray_xmt."}, {"score": 0.010391910731240147, "phrase": "intel_nehalem"}, {"score": 0.00481495049065317, "phrase": "multithreaded_architectures"}, {"score": 0.004788057423546704, "phrase": "graph_matching"}, {"score": 0.004747997855358171, "phrase": "prototypical_combinatorial_problem"}, {"score": 0.004695103516280934, "phrase": "high-performance_scientific_computing"}, {"score": 0.0046298096189358595, "phrase": "computing_matchings"}, {"score": 0.004552648949390462, "phrase": "approximation_algorithms"}, {"score": 0.004389831166704716, "phrase": "large-scale_problems"}, {"score": 0.004316652646915877, "phrase": "nearly_optimal_solutions"}, {"score": 0.004173919673709335, "phrase": "multithreaded_algorithms"}, {"score": 0.003731237342932566, "phrase": "special_features"}, {"score": 0.0036587247965487366, "phrase": "carefully_chosen_dataset"}, {"score": 0.003597689785303029, "phrase": "wide_range"}, {"score": 0.0035376693476114733, "phrase": "scalable_performance"}, {"score": 0.0035178850936755848, "phrase": "different_platforms"}, {"score": 0.003224957676162907, "phrase": "amd_magny-cours"}, {"score": 0.0031357528589442915, "phrase": "nvidia_tesla"}, {"score": 0.0031007635286163875, "phrase": "nvidia_fermi_relative"}, {"score": 0.0029813378321133697, "phrase": "strong_as_well_as_weak_scaling"}, {"score": 0.0028745530564286003, "phrase": "excessive_fine-tuning"}, {"score": 0.0028186421364058264, "phrase": "basic_structure"}, {"score": 0.00272530629391977, "phrase": "dataflow_algorithm"}, {"score": 0.002642458851766937, "phrase": "authors'_knowledge"}, {"score": 0.0026056359564738413, "phrase": "first_such_large-scale_study"}, {"score": 0.002583788342438538, "phrase": "half-approximate_weighted_matching_problem"}, {"score": 0.0025264171945423254, "phrase": "critical_enabling_role"}, {"score": 0.002512274063686441, "phrase": "combinatorial_algorithms"}, {"score": 0.002477260798809435, "phrase": "scientific_computing"}, {"score": 0.0024427343146442284, "phrase": "informatics_applications"}, {"score": 0.0024086878766794695, "phrase": "growing_demand"}, {"score": 0.002388487669097511, "phrase": "irregular_computations"}, {"score": 0.0023751148426586154, "phrase": "current_and_future_computing_platforms"}, {"score": 0.0023028883978637536, "phrase": "emerging_multithreaded_platforms"}, {"score": 0.002264420105254984, "phrase": "irregular_memory_access_patterns"}, {"score": 0.0022328534191265854, "phrase": "fine-grained_parallelism"}, {"score": 0.0022203500288703443, "phrase": "light-weight_synchronization_mechanisms"}, {"score": 0.0021893963445354507, "phrase": "architectural_features"}, {"score": 0.002152819774055793, "phrase": "cray_xmt"}, {"score": 0.0021049977753042253, "phrase": "irregular_memory-intensive_applications"}], "paper_keywords": ["approximation", " dataflow", " GPU", " graph algorithms", " manycore", " matching", " multicore", " weighted matching"], "paper_abstract": "Graph matching is a prototypical combinatorial problem with many applications in high-performance scientific computing. Optimal algorithms for computing matchings are challenging to parallelize. Approximation algorithms are amenable to parallelization and are therefore important to compute matchings for large-scale problems. Approximation algorithms also generate nearly optimal solutions that are sufficient for many applications. In this paper we present multithreaded algorithms for computing half-approximate weighted matching on state-of-the-art multicore (Intel Nehalem and AMD Magny-Cours), manycore (Nvidia Tesla and Nvidia Fermi), and massively multithreaded (Cray XMT) platforms. We provide two implementations: the first uses shared work queues and is suited for all platforms; and the second implementation, based on dataflow principles, exploits special features available on the Cray XMT. Using a carefully chosen dataset that exhibits characteristics from a wide range of applications, we show scalable performance across different platforms. In particular, for one instance of the input, an R-MAT graph (RMAT-G), we show speedups of about 32 on 48 cores of an AMD Magny-Cours, 7 on 8 cores of Intel Nehalem, 3 on Nvidia Tesla and 10 on Nvidia Fermi relative to one core of Intel Nehalem, and 60 on 128 processors of Cray XMT. We demonstrate strong as well as weak scaling for graphs with up to a billion edges using up to 12,800 threads. We avoid excessive fine-tuning for each platform and retain the basic structure of the algorithm uniformly across platforms. An exception is the dataflow algorithm designed specifically for the Cray XMT. To the best of the authors' knowledge, this is the first such large-scale study of the half-approximate weighted matching problem on multithreaded platforms. Driven by the critical enabling role of combinatorial algorithms such as matching in scientific computing and the emergence of informatics applications, there is a growing demand to support irregular computations on current and future computing platforms. In this context, we evaluate the capability of emerging multithreaded platforms to tolerate latency induced by irregular memory access patterns, and to support fine-grained parallelism via light-weight synchronization mechanisms. By contrasting the architectural features of these platforms against the Cray XMT, which is specifically designed to support irregular memory-intensive applications, we delineate the impact of these choices on performance.", "paper_title": "Approximate weighted matching on emerging manycore and multithreaded architectures", "paper_id": "WOS:000310796300009"}