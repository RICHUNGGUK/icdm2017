{"auto_keywords": [{"score": 0.04844170546569224, "phrase": "high-dimensional_datasets"}, {"score": 0.00481495049065317, "phrase": "feature_selection"}, {"score": 0.00457013354092966, "phrase": "support_vector_machine"}, {"score": 0.004491594252746931, "phrase": "svm"}, {"score": 0.004337710093279712, "phrase": "state-of-the-art_classification_method"}, {"score": 0.003907586297783078, "phrase": "important_extension"}, {"score": 0.003773870856027139, "phrase": "elastic_net_penalty"}, {"score": 0.0037087324991876727, "phrase": "drsvm"}, {"score": 0.0034894451015047875, "phrase": "variable_selection"}, {"score": 0.0032830808525570903, "phrase": "correlated_variables"}, {"score": 0.0025059724686541263, "phrase": "computation_complexity"}, {"score": 0.0023990982005125763, "phrase": "corresponding_algorithms"}, {"score": 0.002357632753637638, "phrase": "global_convergence_property"}, {"score": 0.0023168823213024856, "phrase": "empirical_results"}, {"score": 0.002257070536352418, "phrase": "simulated_and_real-world_gene_datasets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Feature selection", " SVM", " DrSVM", " Sparse learning"], "paper_abstract": "Support vector machine (SVM) is the state-of-the-art classification method, and the doubly regularized SVM (DrSVM) is an important extension based on the elastic net penalty. DrSVM has been successfully applied in handling variable selection while retaining (or discarding) correlated variables. However, it is challenging to solve this model. In this paper we develop an iterative l(2)-SVM approach to implement DrSVM over high-dimensional datasets. Our approach can significantly reduce the computation complexity. Moreover, the corresponding algorithms have global convergence property. Empirical results over the simulated and real-world gene datasets are encouraging. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "An iterative SVM approach to feature selection and classification in high-dimensional datasets", "paper_id": "WOS:000318837400011"}