{"auto_keywords": [{"score": 0.041780182369542326, "phrase": "smart_phone"}, {"score": 0.03686514017937803, "phrase": "surf"}, {"score": 0.00481495049065317, "phrase": "eye_phone"}, {"score": 0.004356535752468849, "phrase": "unfamiliar_environment"}, {"score": 0.0043083624695326745, "phrase": "public_buildings"}, {"score": 0.004213601332868765, "phrase": "novel_smart_phone"}, {"score": 0.00418247778205288, "phrase": "vision-based_indoor_localization"}, {"score": 0.00407533728096378, "phrase": "seeing_eye_phone"}, {"score": 0.003592581806180854, "phrase": "phone_images"}, {"score": 0.0033730181385496186, "phrase": "stored_map_images"}, {"score": 0.0032141856243404618, "phrase": "direct_linear_transform"}, {"score": 0.0030970990565391183, "phrase": "rough_initial_pose_estimate"}, {"score": 0.0030628094110419697, "phrase": "levenberg-marquardt_algorithm"}, {"score": 0.0030176779201170306, "phrase": "pose_estimate"}, {"score": 0.002929394386754424, "phrase": "estimated_pose"}, {"score": 0.0028969560940141233, "phrase": "camera's_intrinsic_parameters"}, {"score": 0.002689666606553487, "phrase": "positional_information"}, {"score": 0.0024879169065840493, "phrase": "indoor_guiding_system"}, {"score": 0.002469508424323385, "phrase": "efficient_algorithms"}, {"score": 0.0024061422012437344, "phrase": "multi-view_geometry"}, {"score": 0.002250549946875429, "phrase": "experimental_results"}, {"score": 0.0021927897271015657, "phrase": "simple_machine_vision_system_design"}, {"score": 0.0021604504765314497, "phrase": "complex_task"}, {"score": 0.0021049977753042253, "phrase": "commercial_product"}], "paper_keywords": ["Smart phone", " POSE estimation", " Visually impaired", " Indoor guidance system"], "paper_abstract": "In order to help the visually impaired as they navigate unfamiliar environment such as public buildings, this paper presents a novel smart phone, vision-based indoor localization, and guidance system, called Seeing Eye Phone. This system requires a smart phone from the user and a server. The smart phone captures and transmits images of the user facing forward to the server. The server processes the phone images to detect and describe 2D features by SURF and then matches them to the 2D features of the stored map images that include their corresponding 3D information of the building. After features are matched, Direct Linear Transform runs on a subset of correspondences to find a rough initial pose estimate and the Levenberg-Marquardt algorithm further refines the pose estimate to find a more optimal solution. With the estimated pose and the camera's intrinsic parameters, the location and orientation of the user are calculated using 3D location correspondence data stored for features of each image. Positional information is then transmitted back to the smart phone and communicated to the user via text-to-speech. This indoor guiding system uses efficient algorithms such as SURF, homographs, multi-view geometry, and 3D to 2D reprojection to solve a very unique problem that will benefit the visually impaired. The experimental results demonstrate the feasibility of using a simple machine vision system design to accomplish a complex task and the potential of building a commercial product based on this design.", "paper_title": "Seeing Eye Phone: a smart phone-based indoor localization and guidance system for the visually impaired", "paper_id": "WOS:000333364300019"}