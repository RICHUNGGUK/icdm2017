{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "echocardiographic_sequences"}, {"score": 0.04963913874714364, "phrase": "sparse_representation"}, {"score": 0.049203403415225284, "phrase": "dictionary_learning"}, {"score": 0.004597754207658615, "phrase": "dynamical_appearance_model"}, {"score": 0.004134508282135594, "phrase": "offline_spatiotemporal_priors"}, {"score": 0.004002972723329302, "phrase": "inherent_spatiotemporal_coherence"}, {"score": 0.003966162568548304, "phrase": "individual_data"}, {"score": 0.003911578552479064, "phrase": "cardiac_contour_estimation"}, {"score": 0.0038577428353448596, "phrase": "contour_tracker"}, {"score": 0.0037696519417841287, "phrase": "manual_tracing"}, {"score": 0.0037177622939493084, "phrase": "first_frame"}, {"score": 0.0036496814103475174, "phrase": "multiscale_sparse_representation"}, {"score": 0.003616108223034427, "phrase": "local_image_appearance"}, {"score": 0.0035663245542174224, "phrase": "online_multiscale_appearance_dictionaries"}, {"score": 0.003517223847512266, "phrase": "boosting_framework"}, {"score": 0.003468796799802612, "phrase": "image_sequence"}, {"score": 0.0034368818187904744, "phrase": "segmented_frame"}, {"score": 0.0033739270918502285, "phrase": "frame_sequentially"}, {"score": 0.0032968474833776906, "phrase": "multiscale_appearance_dictionaries"}, {"score": 0.003118942369691329, "phrase": "complementary_multilevel_information"}, {"score": 0.0030617935728586006, "phrase": "multiscale_local_appearance"}, {"score": 0.0030196181347744372, "phrase": "dynamical_shape_prediction"}, {"score": 0.0028698706191651155, "phrase": "healthy_and_post-infarct_canines"}, {"score": 0.002765636101369536, "phrase": "expert_manual_tracings"}, {"score": 0.0027275289970185015, "phrase": "ejection_fraction_estimates"}, {"score": 0.0026899455459275575, "phrase": "good_agreement"}, {"score": 0.0026651772919894534, "phrase": "manual_results"}, {"score": 0.0025329623864528317, "phrase": "conventional_pure_intensity_model"}, {"score": 0.00249805321224923, "phrase": "registration-based_contour_tracker"}, {"score": 0.002225196379204285, "phrase": "clinical_application"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Echocardiography", " Segmentation", " Contour tracking", " Sparse representation", " Dictionary learning"], "paper_abstract": "This paper presents a dynamical appearance model based on sparse representation and dictionary learning for tracking both endocardial and epicardial contours of the left ventricle in echocardiographic sequences. Instead of learning offline spatiotemporal priors from databases, we exploit the inherent spatiotemporal coherence of individual data to constraint cardiac contour estimation. The contour tracker is initialized with a manual tracing of the first frame. It employs multiscale sparse representation of local image appearance and learns online multiscale appearance dictionaries in a boosting framework as the image sequence is segmented frame-by-frame sequentially. The weights of multiscale appearance dictionaries are optimized automatically. Our region-based level set segmentation integrates a spectrum of complementary multilevel information including intensity, multiscale local appearance, and dynamical shape prediction. The approach is validated on twenty-six 4D canine echocardiographic images acquired from both healthy and post-infarct canines. The segmentation results agree well with expert manual tracings. The ejection fraction estimates also show good agreement with manual results. Advantages of our approach are demonstrated by comparisons with a conventional pure intensity model, a registration-based contour tracker, and a state-of-the-art database-dependent offline dynamical shape model. We also demonstrate the feasibility of clinical application by applying the method to four 4D human data sets. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Contour tracking in echocardiographic sequences via sparse representation and dictionary learning", "paper_id": "WOS:000332194600002"}