{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "interleaved_categorization"}, {"score": 0.004659951478263083, "phrase": "novel_method"}, {"score": 0.004509919457793852, "phrase": "visual_category"}, {"score": 0.00447316895126645, "phrase": "cluttered_real-world_scenes"}, {"score": 0.004382591802405206, "phrase": "object_categorization"}, {"score": 0.004346874334971379, "phrase": "figure-ground_segmentation"}, {"score": 0.004206879557938045, "phrase": "common_goal"}, {"score": 0.0040713749949601915, "phrase": "tight_coupling"}, {"score": 0.0038446194432899183, "phrase": "combined_performance"}, {"score": 0.003797690272118125, "phrase": "core_part"}, {"score": 0.0037207397635410327, "phrase": "highly_flexible_learned_representation"}, {"score": 0.003556873173040169, "phrase": "different_training_examples"}, {"score": 0.003513443975425428, "phrase": "probabilistic_extension"}, {"score": 0.0034422330919613294, "phrase": "resulting_approach"}, {"score": 0.003400198866111204, "phrase": "categorical_objects"}, {"score": 0.003372460634140967, "phrase": "novel_images"}, {"score": 0.003304097742490627, "phrase": "probabilistic_segmentation"}, {"score": 0.0032637448078885016, "phrase": "recognition_result"}, {"score": 0.002994701080666466, "phrase": "object_pixels"}, {"score": 0.0029460197288680864, "phrase": "misleading_influences"}, {"score": 0.0026920404458807444, "phrase": "mdl_based_hypothesis_verification_stage"}, {"score": 0.002637433799290365, "phrase": "overlapping_hypotheses"}, {"score": 0.0025628355581338563, "phrase": "partial_occlusion"}, {"score": 0.0025315126622525424, "phrase": "extensive_evaluation"}, {"score": 0.0024700078414481297, "phrase": "proposed_system"}, {"score": 0.0024001337476063094, "phrase": "different_object_categories"}, {"score": 0.0023610946923597405, "phrase": "rigid_and_articulated_objects"}, {"score": 0.002266246304762945, "phrase": "competitive_object_detection_performance"}, {"score": 0.0022385401780982204, "phrase": "training_sets"}, {"score": 0.0021049977753042253, "phrase": "comparable_systems"}], "paper_keywords": ["object categorization", " object detection", " segmentation", " clustering", " hough transform", " hypothesis selection", " MDL"], "paper_abstract": "This paper presents a novel method for detecting and localizing objects of a visual category in cluttered real-world scenes. Our approach considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal. As shown in our work, the tight coupling between those two processes allows them to benefit from each other and improve the combined performance. The core part of our approach is a highly flexible learned representation for object shape that can combine the information observed on different training examples in a probabilistic extension of the Generalized Hough Transform. The resulting approach can detect categorical objects in novel images and automatically infer a probabilistic segmentation from the recognition result. This segmentation is then in turn used to again improve recognition by allowing the system to focus its efforts on object pixels and to discard misleading influences from the background. Moreover, the information from where in the image a hypothesis draws its support is employed in an MDL based hypothesis verification stage to resolve ambiguities between overlapping hypotheses and factor out the effects of partial occlusion. An extensive evaluation on several large data sets shows that the proposed system is applicable to a range of different object categories, including both rigid and articulated objects. In addition, its flexible representation allows it to achieve competitive object detection performance already from training sets that are between one and two orders of magnitude smaller than those used in comparable systems.", "paper_title": "Robust object detection with interleaved categorization and segmentation", "paper_id": "WOS:000253526100015"}