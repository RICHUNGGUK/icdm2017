{"auto_keywords": [{"score": 0.04196067534343774, "phrase": "finite_dirichlet_mixture_models"}, {"score": 0.00481495049065317, "phrase": "expectation_propagation_learning"}, {"score": 0.004738325072560588, "phrase": "finite_dirichlet"}, {"score": 0.0044795698035664695, "phrase": "appropriate_statistical_models"}, {"score": 0.00437302709192313, "phrase": "fundamental_data_analysis_task"}, {"score": 0.004134137523409649, "phrase": "continuing_interest"}, {"score": 0.0038152404172111815, "phrase": "effective_and_flexible_model_learning_technique"}, {"score": 0.0032753168662834516, "phrase": "expectation_propagation"}, {"score": 0.003171740347925348, "phrase": "inference_framework"}, {"score": 0.003071429173571846, "phrase": "proposed_ep_learning_method"}, {"score": 0.0029982770062678926, "phrase": "finite_mixture_models"}, {"score": 0.002880196765572443, "phrase": "model_complexity"}, {"score": 0.0027446057983474994, "phrase": "mixture_components"}, {"score": 0.002553063001454623, "phrase": "single_optimization_framework"}, {"score": 0.002512342528545883, "phrase": "extensive_simulations"}, {"score": 0.002472269923319476, "phrase": "synthetic_data"}, {"score": 0.002374855916752648, "phrase": "real-world_applications"}, {"score": 0.0023369711258107244, "phrase": "automatic_image_annotation"}, {"score": 0.002299689297293321, "phrase": "human_action_videos"}, {"score": 0.0021391300942881, "phrase": "better_results"}, {"score": 0.0021049977753042253, "phrase": "comparable_techniques"}], "paper_keywords": ["Mixture models", " Dirichlet distribution", " Expectation propagation", " Image annotation", " Human action videos categorization"], "paper_abstract": "Learning appropriate statistical models is a fundamental data analysis task which has been the topic of continuing interest. Recently, finite Dirichlet mixture models have proved to be an effective and flexible model learning technique in several machine learning and data mining applications. In this article, the problem of learning and selecting finite Dirichlet mixture models is addressed using an expectation propagation (EP) inference framework. Within the proposed EP learning method, for finite mixture models, all the involved parameters and the model complexity (i.e. the number of mixture components), can be evaluated simultaneously in a single optimization framework. Extensive simulations using synthetic data along with two challenging real-world applications involving automatic image annotation and human action videos categorization demonstrate that our approach is able to achieve better results than comparable techniques.", "paper_title": "Non-Gaussian Data Clustering via Expectation Propagation Learning of Finite Dirichlet Mixture Models and Applications", "paper_id": "WOS:000332793100001"}