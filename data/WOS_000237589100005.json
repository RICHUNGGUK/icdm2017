{"auto_keywords": [{"score": 0.05007813205043779, "phrase": "distance_functions"}, {"score": 0.02919282695639583, "phrase": "ncc"}, {"score": 0.02490757541282183, "phrase": "seven_data_sets"}, {"score": 0.004769182299692333, "phrase": "supervised_similarity_assessment"}, {"score": 0.004397230847865867, "phrase": "novel_approach"}, {"score": 0.00401560412621627, "phrase": "data_set"}, {"score": 0.003828187766572941, "phrase": "local_class_density_information"}, {"score": 0.0036669760226536977, "phrase": "weight_adjustment"}, {"score": 0.003580355398511932, "phrase": "distance_function"}, {"score": 0.0035125292519354724, "phrase": "class_density"}, {"score": 0.003429544382524185, "phrase": "attribute_space"}, {"score": 0.003300813776412652, "phrase": "distance_function_modification"}, {"score": 0.003222814590544802, "phrase": "\"good\"_distance_function"}, {"score": 0.002928765962664163, "phrase": "seven_uci_data_sets"}, {"score": 0.002687070469080394, "phrase": "learnt_distance_function_and_cluster_centroids"}, {"score": 0.002537097217899195, "phrase": "experimental_results"}, {"score": 0.0024534993283766332, "phrase": "statistically_significant_improvements"}, {"score": 0.0024301229420875155, "phrase": "prediction_accuracy"}], "paper_keywords": ["distance function learning", " supervised clustering", " nearest neighbor"], "paper_abstract": "Assessing the similarity between objects is a prerequisite for many data mining techniques. This paper introduces a novel approach to learn distance functions that maximizes the clustering of objects belonging to the same class. Objects belonging to a data set are clustered with respect to a given distance function and the local class density information of each cluster is then used by a weight adjustment heuristic to modify the distance function so that the class density is increased in the attribute space. This process of interleaving clustering with distance function modification is repeated until a \"good\" distance function has been found. We implemented our approach using the k-means clustering algorithm. We evaluated our approach using seven UCI data sets for a traditional 1-nearest-neighbor (1-NN) classifier and a compressed 1-NN classifier, called NCC, that uses the learnt distance function and cluster centroids instead of all the points of a training set. The experimental results show that attribute weighting leads to statistically significant improvements in prediction accuracy over a traditional 1-NN classifier for two of the seven data sets tested, whereas using NCC significantly improves the accuracy of the 1-NN classifier for four of the seven data sets. (C) 2006 Elsevier Ltd. All fights reserved.", "paper_title": "Using clustering to learn distance functions for supervised similarity assessment", "paper_id": "WOS:000237589100005"}