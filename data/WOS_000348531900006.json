{"auto_keywords": [{"score": 0.04600874337248756, "phrase": "krasnogor"}, {"score": 0.00481495049065317, "phrase": "enhanced_universal_similarity_metric"}, {"score": 0.004777451835750203, "phrase": "ultimate_aim"}, {"score": 0.004752614341164843, "phrase": "memetic_computing"}, {"score": 0.004715598857504476, "phrase": "fully_autonomous_solution"}, {"score": 0.004691081414630302, "phrase": "complex_optimisation_problems"}, {"score": 0.004594273895196032, "phrase": "memetic_algorithms_literature"}, {"score": 0.00449945511326728, "phrase": "ever_increasing_generalisation"}, {"score": 0.00444118525702523, "phrase": "seminal_papers"}, {"score": 0.004383846455798434, "phrase": "smith"}, {"score": 0.0042375659560642265, "phrase": "workshops_proceedings"}, {"score": 0.00419359499046542, "phrase": "international_genetic_and_evolutionary_computation_conference"}, {"score": 0.0040856507026714355, "phrase": "gustafson"}, {"score": 0.00404324427123215, "phrase": "nature-inspired_computation"}, {"score": 0.003939149473120381, "phrase": "related_and_more_recent_work"}, {"score": 0.003908461005196596, "phrase": "ong"}, {"score": 0.0038881155648923145, "phrase": "keane"}, {"score": 0.0034483755691680474, "phrase": "modern_search_technology"}, {"score": 0.0033859514549584497, "phrase": "recent_trend"}, {"score": 0.0033683237474307582, "phrase": "ever_greater_generalisation"}, {"score": 0.0031227655905108668, "phrase": "fixed_problem_type"}, {"score": 0.0030264524348640218, "phrase": "optimisation_frameworks"}, {"score": 0.002979494701400548, "phrase": "springer"}, {"score": 0.0028950571578012195, "phrase": "first_step"}, {"score": 0.0028724674034965115, "phrase": "generalisation_ladder"}, {"score": 0.0026769078650806283, "phrase": "problem_instance"}, {"score": 0.0026147181807295115, "phrase": "human_intervention"}, {"score": 0.0025673464455688816, "phrase": "likely_family_class"}, {"score": 0.0024622581232640705, "phrase": "automatic_problem_classifier_system"}, {"score": 0.002343025203704225, "phrase": "innovative_approach"}, {"score": 0.0023247328402019743, "phrase": "universal_similarity_metric"}, {"score": 0.002282602844012085, "phrase": "normalised_compression_distance"}, {"score": 0.002241234633963619, "phrase": "different_problem_instances"}, {"score": 0.0021834315230252047, "phrase": "compression_dictionaries"}, {"score": 0.0021049977753042253, "phrase": "studied_dataset"}], "paper_keywords": ["Problem classification", " Second keyword", " Similarity matrix"], "paper_abstract": "The ultimate aim of Memetic Computing is the fully autonomous solution to complex optimisation problems. For a while now, the Memetic algorithms literature has been moving in the direction of ever increasing generalisation of optimisers initiated by seminal papers such as Krasnogor and Smith (IEEE Trans 9(5): 474-488, 2005; Workshops Proceedings of the 2000 International Genetic and Evolutionary Computation Conference (GECCO2000), 2000), Krasnogor and Gustafson (Advances in nature-inspired computation: the PPSN VII Workshops 16(52), 2002) and followed by related and more recent work such as Ong and Keane (IEEE Trans Evol Comput 8(2): 99-110, 2004), Ong et al. (IEEE Comp Int Mag 5(2): 24-31, 2010), Burke et al. (Hyper-heuristics: an emerging direction in modern search technology, 2003). In this recent trend to ever greater generalisation and applicability, the research has focused on selecting (or even evolving), the right search operator(s) to use when tackling a given instance of a fixed problem type (e. g. Euclidean 2D TSP) within a range of optimisation frameworks (Krasnogor, Handbook of natural computation, Springer, Berlin/Heidelberg, 2009). This paper is the first step up the generalisation ladder, where one assumes that the optimiser is given (perhaps by other solvers who do not necessarily know how to deal with a given problem instance) a problem instance to tackle and it must autonomously and without human intervention pre-select which is the likely family class of problems the instance belongs to. In order to do that we propose an Automatic Problem Classifier System able to identify automatically which kind of instance or problem the system is dealing with. We test an innovative approach to the Universal Similarity Metric, as a variant of the normalised compression distance (NCD), to classify different problem instances. This version is based on the management of compression dictionaries. The results obtained are encouraging as we achieve a 96% average classification success with the studied dataset.", "paper_title": "Blind optimisation problem instance classification via enhanced universal similarity metric", "paper_id": "WOS:000348531900006"}