{"auto_keywords": [{"score": 0.04791278459794138, "phrase": "sentence_retrieval"}, {"score": 0.03786990417643338, "phrase": "class_model"}, {"score": 0.033316644670367705, "phrase": "trigger_model"}, {"score": 0.00481495049065317, "phrase": "vocabulary_gap"}, {"score": 0.0047517225918491226, "phrase": "answer_sentences"}, {"score": 0.004477270137801732, "phrase": "class-based_language_model"}, {"score": 0.004447766706144458, "phrase": "trained_trigger_language_model"}, {"score": 0.004303127794432684, "phrase": "smaller_segments"}, {"score": 0.0042325743185503825, "phrase": "document_retrieval"}, {"score": 0.004163172790791119, "phrase": "data_sparsity"}, {"score": 0.0041357305373417455, "phrase": "exact_matching"}, {"score": 0.004067910470129423, "phrase": "different_techniques"}, {"score": 0.004014452814186653, "phrase": "translation_model"}, {"score": 0.003922580121023413, "phrase": "word_mismatch_problem"}, {"score": 0.003820144626025562, "phrase": "trigger_language_models"}, {"score": 0.003757480190200645, "phrase": "different_approaches"}, {"score": 0.0036352070472201086, "phrase": "exiting_models"}, {"score": 0.003516898780234098, "phrase": "term_relationships"}, {"score": 0.0031845067058084583, "phrase": "relevant_sentences"}, {"score": 0.003030247482854539, "phrase": "large_corpus"}, {"score": 0.0028739078688746374, "phrase": "trigger_word"}, {"score": 0.0027803070408286158, "phrase": "corresponding_target_word"}, {"score": 0.0027437235598539904, "phrase": "proposed_models"}, {"score": 0.002707620139970122, "phrase": "different_notions"}, {"score": 0.002663156413861478, "phrase": "word_relations"}, {"score": 0.00257640185288362, "phrase": "corpus_size"}, {"score": 0.00250073564820402, "phrase": "trec_qa"}, {"score": 0.002459660938061167, "phrase": "proposed_model"}, {"score": 0.002427286272201272, "phrase": "sentence_retrieval_performance"}, {"score": 0.002395336706478158, "phrase": "state-of-the-art_translation_model"}, {"score": 0.0023326907270271153, "phrase": "mutual_information"}, {"score": 0.0023172863267744703, "phrase": "karimzadehgan"}, {"score": 0.0023019861600169487, "phrase": "zhai"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Sentence retrieval", " Language modeling", " Word Clustering", " Triggering", " Question answering"], "paper_abstract": "We propose two novel language models to improve the performance of sentence retrieval in Question Answering (QA): class-based language model and trained trigger language model. As the search in sentence retrieval is conducted over smaller segments of text than in document retrieval, the problems of data sparsity and exact matching become more critical. Different techniques such as the translation model are also proposed to overcome the word mismatch problem. Our class-based and trained trigger language models, however, use different approaches to this aim and are shown to outperform the exiting models. The class model uses word clustering algorithm to capture term relationships. In this model, we assume a relation between the terms that belong to the same clusters; as a result, they can be substituted when searching for relevant sentences. The trigger model captures pairs of trigger and target words while training on a large corpus. The model considers a relation between a question and a sentence, if a trigger word appears in the question and the sentence contains the corresponding target word. For both proposed models, we introduce different notions of co-occurrence to find word relations. In addition, we study the impact of corpus size and domain on the models. Our experiments on TREC QA collection verify that the proposed model significantly improves the sentence retrieval performance compared to the state-of-the-art translation model. While the translation model based on mutual information (Karimzadehgan and Zhai, 2010) has 0.3927 Mean Average Precision (MAP), the class model achieves 0.4174 MAP and the trigger model enhances the performance to 0.4381. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Bridging the vocabulary gap between questions and answer sentences", "paper_id": "WOS:000359504900003"}