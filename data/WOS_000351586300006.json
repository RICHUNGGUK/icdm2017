{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "gestalt_rule_feature_points"}, {"score": 0.004722791767189843, "phrase": "large_online_repositories"}, {"score": 0.004632388761885302, "phrase": "video_data"}, {"score": 0.004392565073466714, "phrase": "visual_variations"}, {"score": 0.0041450181887917135, "phrase": "visual_scene"}, {"score": 0.003987755561492638, "phrase": "different_colors"}, {"score": 0.003949377440799037, "phrase": "image_editing_tools"}, {"score": 0.0038737214010638745, "phrase": "multiple_representations"}, {"score": 0.0037267132967205136, "phrase": "hand-drawn_sketch"}, {"score": 0.0036730297909962142, "phrase": "large_visual_variations"}, {"score": 0.0035507457285983268, "phrase": "existing_computer_vision_algorithms"}, {"score": 0.0034826993555190765, "phrase": "visual_analogies"}, {"score": 0.0033182152378613767, "phrase": "related_applications"}, {"score": 0.003146212656743413, "phrase": "new_approach"}, {"score": 0.003100865267124765, "phrase": "reliable_visual_features"}, {"score": 0.0030121159909273897, "phrase": "particular_focus"}, {"score": 0.0029117710453690827, "phrase": "local_features"}, {"score": 0.00269475174341129, "phrase": "different_visual_styles"}, {"score": 0.002530359917257626, "phrase": "novel_method"}, {"score": 0.00249386680748172, "phrase": "visual_correspondences"}, {"score": 0.0024224481033945943, "phrase": "gestalt_theory"}, {"score": 0.0023417010799384524, "phrase": "human_visions"}, {"score": 0.0023079225317714815, "phrase": "visual_perception"}, {"score": 0.0021987994275190314, "phrase": "state-of-the-art_local_features"}, {"score": 0.0021049977753042253, "phrase": "cross_domain_image_matching"}], "paper_keywords": ["Cross domain image matching", " Gestalt rules", " graph-based ranking", " local feature detector"], "paper_abstract": "As the large online repositories of image and video data has emerged and continued to grow in number, the visual variations in such repositories has also increased dramatically. For example, the visual scene of a photograph can be changed into different colors by image editing tools or depicted by multiple representations, such as a painting and a hand-drawn sketch. The large visual variations tend to cause ambiguities for the existing computer vision algorithms to recognize the visual analogies of these images and often limit the potential of related applications. In this paper, therefore, we propose a new approach for detecting reliable visual features from images, with a particular focus on improving the repeatability of the local features in those images containing the same semantic contents (e. g., a landmark) but in different visual styles (e. g., a photo and a painting). We proposed a novel method for establishing visual correspondences between images based on the Gestalt theory, a psychological study of how human visions organize the visual perception. Experiments demonstrated the outperformance of our approach over the state-of-the-art local features in various computer vision tasks, such as cross domain image matching and retrieval.", "paper_title": "Gestalt Rule Feature Points", "paper_id": "WOS:000351586300006"}