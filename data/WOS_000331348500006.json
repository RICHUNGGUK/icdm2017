{"auto_keywords": [{"score": 0.032133834017660755, "phrase": "proposed_model"}, {"score": 0.00481495049065317, "phrase": "lookup_model"}, {"score": 0.004780183091824403, "phrase": "fast_updates"}, {"score": 0.004660453113061494, "phrase": "core_function"}, {"score": 0.004462105963334103, "phrase": "serious_challenges"}, {"score": 0.004381962669035583, "phrase": "memory_efficiency"}, {"score": 0.004350308086118336, "phrase": "update_performance"}, {"score": 0.004241299366498948, "phrase": "optimization_techniques"}, {"score": 0.004195418010131832, "phrase": "traditional_lookup_model"}, {"score": 0.0041051328120736575, "phrase": "brand-new_parallel_lookup_model"}, {"score": 0.004060718465754644, "phrase": "split_routing_lookup_model"}, {"score": 0.003987755561492638, "phrase": "partial_similarities"}, {"score": 0.0037493114715625784, "phrase": "information_integration"}, {"score": 0.003668591097652231, "phrase": "on-chip_structure"}, {"score": 0.003525074461418428, "phrase": "route_updates"}, {"score": 0.003399466007862412, "phrase": "lookup_process"}, {"score": 0.0033262524445013303, "phrase": "parallel_processing"}, {"score": 0.003104619199351347, "phrase": "encouraging_results"}, {"score": 0.0030048355421601705, "phrase": "comprehensive_view"}, {"score": 0.0029722900280316216, "phrase": "on-chip_memory_savings"}, {"score": 0.002814759530655965, "phrase": "update_overhead"}, {"score": 0.0027641218567092665, "phrase": "worst_case"}, {"score": 0.002675252546913683, "phrase": "pipeline_depth"}, {"score": 0.0024968877430444304, "phrase": "virtual_router_platform"}, {"score": 0.0023730978395564116, "phrase": "on-chip_memory"}, {"score": 0.002182881082103045, "phrase": "virtual_routers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Split Trie", " Memory efficient", " Fast update", " Parallel lookup"], "paper_abstract": "Routing lookup, as a core function of routers for forwarding and filtering packets, has confronted with serious challenges nowadays, ranging from memory efficiency, update performance and throughput. Rather than seeking optimization techniques for the traditional lookup model, this paper presents a brand-new parallel lookup model, named Split Routing Lookup Model. In consideration of partial similarities among prefixes, we split all prefixes to produce redundancies, which are then removed during information integration. After that, the on-chip structure is compressed sharply. Besides, by such \"splitting\", route updates are diverged to be more targeted, and the lookup process is also decomposed to support parallel processing. With 14 real-world routing data, the proposed model is evaluated through 4 classic trie-based approaches, in comparison with their traditional implementations. The encouraging results show the superiorities of the proposed model in a comprehensive view. The on-chip memory savings are up to 99.2% and 94.8% for IPv4/6 respectively. While the reduction of update overhead, even in the worst case, is 50% and 30% respectively. Moreover, the pipeline depth is also reduced by 25-50%. Besides, another 2 techniques are selected to evaluate the proposed model on the virtual router platform. According to the results, based on the proposed model, 160 KB on-chip memory is enough to store 14 virtual routers, each consuming only 11 KB on average. In this way, the scalability of the proposed model to virtual routers is also clearly demonstrated. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A memory-efficient parallel routing lookup model with fast updates", "paper_id": "WOS:000331348500006"}