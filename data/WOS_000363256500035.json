{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "dictionary_learning_uniquely_recover_sparse_data"}, {"score": 0.004586531354697466, "phrase": "sparse_dictionary_learning"}, {"score": 0.004333642054036135, "phrase": "underlying_structure"}, {"score": 0.004195418010131832, "phrase": "natural_data"}, {"score": 0.0036257863613963245, "phrase": "sparse_codes"}, {"score": 0.003398015125667192, "phrase": "natural_symmetries"}, {"score": 0.003236596168242036, "phrase": "useful_lemma"}, {"score": 0.0031845067058084583, "phrase": "combinatorial_matrix_theory"}, {"score": 0.0029602552900111433, "phrase": "sample_sizes"}, {"score": 0.002796782643988021, "phrase": "training_data"}, {"score": 0.0024761702541879213, "phrase": "sparsity-constrained_learning_algorithm"}, {"score": 0.0023016843709107297, "phrase": "original_sparse_codes"}, {"score": 0.0021745003291048356, "phrase": "potential_applications"}, {"score": 0.0021049977753042253, "phrase": "data_analysis"}], "paper_keywords": ["Dictionary learning", " sparse coding", " sparse matrix factorization", " uniqueness", " compressed sensing", " combinatorial matrix theory"], "paper_abstract": "Sparse coding or sparse dictionary learning has been widely used to recover underlying structure in many kinds of natural data. Here, we provide conditions guaranteeing when this recovery is universal; that is, when sparse codes and dictionaries are unique (up to natural symmetries). Our main tool is a useful lemma in combinatorial matrix theory that allows us to derive bounds on the sample sizes guaranteeing such uniqueness under various assumptions for how training data are generated. Whenever the conditions to one of our theorems are met, any sparsity-constrained learning algorithm that succeeds in reconstructing the data recovers the original sparse codes and dictionary. We also discuss potential applications to neuroscience and data analysis.", "paper_title": "When Can Dictionary Learning Uniquely Recover Sparse Data From Subsamples?", "paper_id": "WOS:000363256500035"}