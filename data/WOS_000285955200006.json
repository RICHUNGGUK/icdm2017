{"auto_keywords": [{"score": 0.044869792207088706, "phrase": "usability_evaluation"}, {"score": 0.03886698645129167, "phrase": "evaluation_patterns"}, {"score": 0.00481495049065317, "phrase": "novice_evaluators"}, {"score": 0.004598933498016774, "phrase": "complex_activity"}, {"score": 0.004375789703278455, "phrase": "educational_quality_heuristic_evaluation"}, {"score": 0.0043258453436258405, "phrase": "widespread_method"}, {"score": 0.004163427731140163, "phrase": "subjective_variability"}, {"score": 0.0035586268203884673, "phrase": "pb_inspection"}, {"score": 0.0034911335714333507, "phrase": "e_learning_systems"}, {"score": 0.003296212583539166, "phrase": "heuristic_evaluation"}, {"score": 0.0032710562699144814, "phrase": "user_testing"}, {"score": 0.0031360786664165093, "phrase": "e_learning_application"}, {"score": 0.0029951555610569225, "phrase": "six_major_dimensions"}, {"score": 0.002949598537993663, "phrase": "classical_test_theory"}, {"score": 0.0029270797740550973, "phrase": "pragmatic_aspects"}, {"score": 0.002784828661426853, "phrase": "expert_evaluators"}, {"score": 0.0027215202678634517, "phrase": "systematic_framework"}, {"score": 0.0026698611202305694, "phrase": "individual_skills"}, {"score": 0.002629238854352447, "phrase": "rater_reliability"}, {"score": 0.0026091594819333654, "phrase": "output_standardization"}, {"score": 0.002540078552743003, "phrase": "larger_set"}, {"score": 0.002520678372430923, "phrase": "different_problems"}, {"score": 0.0024918548761791435, "phrase": "evaluation_cost_results"}, {"score": 0.0023798115577749225, "phrase": "methodological_apparatus"}, {"score": 0.0023346234464901978, "phrase": "judgement_bias"}, {"score": 0.002316788811533867, "phrase": "individual_preferences"}, {"score": 0.0022296340517805125, "phrase": "interactive_quality"}, {"score": 0.0022041312401435346, "phrase": "subjective_judgement"}, {"score": 0.002145750895912557, "phrase": "ux_research_agenda"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd"}], "paper_keywords": ["Usability evaluation techniques", " e Learning evaluation", " Evaluation patterns"], "paper_abstract": "Evaluating e learning systems is a complex activity which requires considerations of several criteria addressing quality in use as well as educational quality Heuristic evaluation is a widespread method for usability evaluation, yet its output is often prone to subjective variability, primarily due to the generality of many heuristics This paper presents the pattern based (PB) inspection, which aims at reducing this drawback by exploiting a set of evaluation patterns to systematically drive inspectors in their evaluation activities The application of PB inspection to the evaluation of e learning systems is reported in this paper together with a study that compares this method to heuristic evaluation and user testing The study involved 73 novice evaluators and 25 end users, who evaluated an e learning application using one of the three techniques The comparison metric was defined along six major dimensions covering concepts of classical test theory and pragmatic aspects of usability evaluation The study showed that evaluation patterns capitalizing on the reuse of expert evaluators know how, provide a systematic framework which reduces reliance on individual skills, increases inter rater reliability and output standardization, permits the discovery of a larger set of different problems and decreases evaluation cost Results also indicated that evaluation in general is strongly dependent on the methodological apparatus as well as on judgement bias and individual preferences of evaluators, providing support to the conceptualisation of interactive quality as a subjective judgement, recently brought forward by the UX research agenda (C) 2010 Elsevier Ltd All rights reserved", "paper_title": "Do patterns help novice evaluators? A comparative study", "paper_id": "WOS:000285955200006"}