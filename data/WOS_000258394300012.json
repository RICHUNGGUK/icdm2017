{"auto_keywords": [{"score": 0.030215809679591407, "phrase": "quantization_parameter"}, {"score": 0.00481495049065317, "phrase": "high_performance"}, {"score": 0.004765788394931875, "phrase": "video_coding"}, {"score": 0.004621279527317074, "phrase": "temporal_redundancies"}, {"score": 0.004412654209742722, "phrase": "variable_block_size_motion_estimation"}, {"score": 0.004235095881928715, "phrase": "coding_gain"}, {"score": 0.004127753467337283, "phrase": "computational_complexity"}, {"score": 0.004085579055228591, "phrase": "motion_estimation"}, {"score": 0.003861175855298779, "phrase": "reference_frame_number"}, {"score": 0.003802135020791801, "phrase": "intermode_number"}, {"score": 0.00374399358035391, "phrase": "mathematical_analysis"}, {"score": 0.003611751858608048, "phrase": "prediction_errors"}, {"score": 0.0035201528214608914, "phrase": "image_edge_gradient_amplitude"}, {"score": 0.00332670230152448, "phrase": "image_content"}, {"score": 0.0033096502887394233, "phrase": "based_early_termination_algorithm"}, {"score": 0.0032256881625734777, "phrase": "original_method"}, {"score": 0.003176333519010176, "phrase": "jvt_reference_software"}, {"score": 0.0031116963435584982, "phrase": "high_and_moderate_bit_rates"}, {"score": 0.0030327408069772293, "phrase": "rate-distortion_theory"}, {"score": 0.002793260314529583, "phrase": "homogenous_block"}, {"score": 0.0027363971333961967, "phrase": "futile_reference_frames"}, {"score": 0.002443671484766342, "phrase": "content_based_fast_algorithms"}, {"score": 0.002393907896783117, "phrase": "unsymmetrical-cross_multihexagon-grid_search"}, {"score": 0.002250601866422547, "phrase": "original_umhexagons"}], "paper_keywords": ["H.264/AVC", " motion estimation", " early termination", " multiple reference frame", " variable block size"], "paper_abstract": "The key to high performance in video coding lies on efficiently reducing the temporal redundancies. For this purpose, H.264/AVC coding standard has adopted variable block size motion estimation on multiple reference frames to improve the coding gain. However, the computational complexity of motion estimation is also increased in proportion to the product of the reference frame number and the intermode number. The mathematical analysis in this paper reveals that the prediction errors mainly depend on the image edge gradient amplitude and quantization parameter. Consequently, this paper proposes the image content based early termination algorithm, which outperforms the original method adopted by JVT reference software, especially at high and moderate bit rates. In light of rate-distortion theory, this paper also relates the homogeneity of image to the quantization parameter. For the homogenous block, its search computation for futile reference frames and intermodes can be efficiently discarded. Therefore, the computation saving performance increases with the value of quantization parameter. These content based fast algorithms were integrated with Unsymmetrical-cross Multihexagon-grid Search (UMHexagonS) algorithm to demonstrate their performance. Compared to the original UMHexagonS fast matching algorithm, 26.14-54.97% search time can be saved with an average of 0.0369 dB coding quality degradation.", "paper_title": "Content-aware fast motion estimation for H.264/AVC", "paper_id": "WOS:000258394300012"}