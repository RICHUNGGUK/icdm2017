{"auto_keywords": [{"score": 0.03835854353748624, "phrase": "fw_method"}, {"score": 0.033794611981689246, "phrase": "quadratic_forms"}, {"score": 0.03236064162810805, "phrase": "mdm"}, {"score": 0.00481496336289543, "phrase": "frank-wolfe"}, {"score": 0.00470862827326028, "phrase": "large-scale_svm_training"}, {"score": 0.00458997570994803, "phrase": "renewed_interest"}, {"score": 0.004445836970274954, "phrase": "sparse_greedy_approximation_procedure"}, {"score": 0.004170940184489072, "phrase": "large-scale_instances"}, {"score": 0.004144399274022276, "phrase": "non-linear_support_vector_machines"}, {"score": 0.004039906986937495, "phrase": "svm_training"}, {"score": 0.003975936061382971, "phrase": "efficient_algorithms"}, {"score": 0.003925486550801027, "phrase": "important_theoretical_results"}, {"score": 0.0038880683136866268, "phrase": "convergence_analysis"}, {"score": 0.0038633204164544802, "phrase": "training_algorithms"}, {"score": 0.003838729434721053, "phrase": "new_characterizations"}, {"score": 0.00381429438125808, "phrase": "model_sparsity"}, {"score": 0.0036826452656927877, "phrase": "novel_variant"}, {"score": 0.003601235776892337, "phrase": "new_way"}, {"score": 0.0034218279328844746, "phrase": "basic_fw_procedure"}, {"score": 0.0033248546272754936, "phrase": "general_concave_maximization_problem"}, {"score": 0.003139048969111903, "phrase": "classic_methods"}, {"score": 0.0031190537176106386, "phrase": "computational_geometry"}, {"score": 0.0030795363259301435, "phrase": "gilbert"}, {"score": 0.0030113280682863234, "phrase": "theoretical_side"}, {"score": 0.0028887887866517496, "phrase": "convergence_rate"}, {"score": 0.002718581874516321, "phrase": "linear_rate"}, {"score": 0.0025665698207861533, "phrase": "practical_side"}, {"score": 0.0024620842899061614, "phrase": "statistical_tests"}, {"score": 0.0023694065215394593, "phrase": "classic_away_steps"}, {"score": 0.0021664698544866753, "phrase": "predictive_accuracy"}, {"score": 0.0021457826677689037, "phrase": "obtained_svm_model"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Learning from massive datasets", " Large-scale support vector machines", " Frank-Wolfe methods", " Concave optimization", " Quadratic programming"], "paper_abstract": "Recently, there has been a renewed interest in the machine learning community for variants of a sparse greedy approximation procedure for concave optimization known as the Frank-Wolfe (FW) method. In particular, this procedure has been successfully applied to train large-scale instances of non-linear Support Vector Machines (SVMs). Specializing FW to SVM training has allowed to obtain efficient algorithms, but also important theoretical results, including convergence analysis of training algorithms and new characterizations of model sparsity. In this paper, we present and analyze a novel variant of the FW method based on a new way to perform away steps, a classic strategy used to accelerate the convergence of the basic FW procedure. Our formulation and analysis is focused on a general concave maximization problem on the simplex. However, the specialization of our algorithm to quadratic forms is strongly related to some classic methods in computational geometry, namely the Gilbert and MDM algorithms. On the theoretical side, we demonstrate that the method matches the guarantees in terms of convergence rate and number of iterations obtained by using classic away steps. In particular, the method enjoys a linear rate of convergence, a result that has been recently proved for MDM on quadratic forms. On the practical side, we provide experiments on several classification datasets, and evaluate the results using statistical tests. Experiments show that our method is faster than the FW method with classic away steps, and works well even in the cases in which classic away steps slow down the algorithm. Furthermore, these improvements are obtained without sacrificing the predictive accuracy of the obtained SVM model. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "A novel Frank-Wolfe algorithm. Analysis and applications to large-scale SVM training", "paper_id": "WOS:000342540700006"}