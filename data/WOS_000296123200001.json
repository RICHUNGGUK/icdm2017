{"auto_keywords": [{"score": 0.04516451046664893, "phrase": "object_recognition"}, {"score": 0.03209407174434937, "phrase": "object_location"}, {"score": 0.00481495049065317, "phrase": "coherent_object_detection"}, {"score": 0.00477924690801092, "phrase": "scene_layout_understanding"}, {"score": 0.004691136491297242, "phrase": "complex_scenes"}, {"score": 0.004621813738791474, "phrase": "scene_layout"}, {"score": 0.004570491683870396, "phrase": "critical_functionality"}, {"score": 0.004354572391793908, "phrase": "geometric_contextual_reasoning"}, {"score": 0.003737934295442975, "phrase": "hidden_parameters"}, {"score": 0.0035744997458371335, "phrase": "joint_scene_reconstruction"}, {"score": 0.0033801845720347118, "phrase": "joint_probability"}, {"score": 0.0033054391731615618, "phrase": "detected_objects"}, {"score": 0.0032895815266044013, "phrase": "k"}, {"score": 0.0031726587374218277, "phrase": "key_ingredient"}, {"score": 0.0031257046538823354, "phrase": "optimization_problem"}, {"score": 0.0030565692640988585, "phrase": "novel_relationship"}, {"score": 0.002933756577145939, "phrase": "scene_layout_parameters"}, {"score": 0.0027433143290371293, "phrase": "focal_length"}, {"score": 0.00269263690712392, "phrase": "novel_probabilistic_formulation"}, {"score": 0.0026232532659260033, "phrase": "unique_ability"}, {"score": 0.0025556529150386168, "phrase": "false_alarm"}, {"score": 0.0025366596616434767, "phrase": "false_negative_object_detection_rate"}, {"score": 0.002389696110283506, "phrase": "camera_parameters"}, {"score": 0.002285075675790214, "phrase": "quantitative_and_qualitative_experimental_evaluation"}, {"score": 0.0022428442879034614, "phrase": "desk-top_dataset"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Object detection", " Scene layout", " Focal length estimation", " Supporting surface estimation"], "paper_abstract": "Detecting objects in complex scenes while recovering the scene layout is a critical functionality in many vision-based applications. In this work, we advocate the importance of geometric contextual reasoning for object recognition. We start from the intuition that objects' location and pose in the 3D space are not arbitrarily distributed but rather constrained by the fact that objects must lie on one or multiple supporting surfaces. We model such supporting surfaces by means of hidden parameters (i.e. not explicitly observed) and formulate the problem of joint scene reconstruction and object recognition as the one of finding the set of parameters that maximizes the joint probability of having a number of detected objects on K supporting planes given the observations. As a key ingredient for solving this optimization problem, we have demonstrated a novel relationship between object location and pose in the image, and the scene layout parameters (i.e. normal of one or more supporting planes in 3D and camera pose, location and focal length). Using a novel probabilistic formulation and the above relationship our method has the unique ability to jointly: i) reduce false alarm and false negative object detection rate; ii) recover object location and supporting planes within the 3D camera reference system; iii) infer camera parameters (view point and the focal length) from just one single uncalibrated image. Quantitative and qualitative experimental evaluation on two datasets (desk-top dataset [1] and LabelMe [2]) demonstrates our theoretical claims. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Toward coherent object detection and scene layout understanding", "paper_id": "WOS:000296123200001"}