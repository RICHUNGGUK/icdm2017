{"auto_keywords": [{"score": 0.042051296116313676, "phrase": "video_summarization"}, {"score": 0.00481495049065317, "phrase": "automatic_home_video_summarization"}, {"score": 0.004756805752518494, "phrase": "viewing_behavior_analysis"}, {"score": 0.004263972370406983, "phrase": "user's_reactions"}, {"score": 0.004186926251483987, "phrase": "user's_interest"}, {"score": 0.003845313870879042, "phrase": "users'_spontaneous_reactions"}, {"score": 0.0036627245728600073, "phrase": "user's_viewing_interest"}, {"score": 0.003618443379266972, "phrase": "quantitative_interest_measures"}, {"score": 0.0033230588808076267, "phrase": "attention_states"}, {"score": 0.0032431667821391044, "phrase": "user's_eye_movement"}, {"score": 0.0031459887611258765, "phrase": "head_motion"}, {"score": 0.00303319936111073, "phrase": "emotion_states"}, {"score": 0.0029965060407413898, "phrase": "facial_expression"}, {"score": 0.0029244418026475832, "phrase": "positive_or_neural_emotion"}, {"score": 0.002735052488172277, "phrase": "fuzzy_fusion_scheme"}, {"score": 0.0025892330566358503, "phrase": "quantitative_interest_scores"}, {"score": 0.0025423706961391034, "phrase": "interesting_parts"}, {"score": 0.002406799309495983, "phrase": "video_summaries"}, {"score": 0.0023776656246300063, "phrase": "experimental_results"}, {"score": 0.002320449502337321, "phrase": "proposed_concept"}, {"score": 0.0021569129153653777, "phrase": "promising_direction"}, {"score": 0.0021049977753042253, "phrase": "human_factor"}], "paper_keywords": ["Attention detection", " editing by viewing", " emotion recognition", " Interest Meter (IM)", " video summarization"], "paper_abstract": "In this paper, we propose the Interest Meter (IM), a system making the computer conscious of user's reactions to measure user's interest and thus use it to conduct video summarization. The IM takes account of users' spontaneous reactions when they view videos. To estimate user's viewing interest, quantitative interest measures are devised based on the perspectives of attention and emotion. For estimating attention states, variations of user's eye movement, blink, and head motion are considered. For estimating emotion states, facial expression is recognized as positive or neural emotion. By combining characteristics of attention and emotion by a fuzzy fusion scheme, we transform users' viewing behaviors into quantitative interest scores, determine interesting parts of videos, and finally concatenate them as video summaries. Experimental results show that the proposed concept \"editing by viewing\" works well and may provide a promising direction to consider the human factor in video summarization.", "paper_title": "Editing by Viewing: Automatic Home Video Summarization by Viewing Behavior Analysis", "paper_id": "WOS:000290733700013"}