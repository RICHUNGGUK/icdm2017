{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "stochastic_approximation_problem"}, {"score": 0.004299621153829837, "phrase": "nonlinear_function"}, {"score": 0.0035869274480340727, "phrase": "classical_rm_algorithm"}, {"score": 0.0033511469200347907, "phrase": "new_three-term_combinatorial_direction_stochastic_approximation_algorithm"}, {"score": 0.0030606302942851027, "phrase": "weighted_combination"}, {"score": 0.002958281631770322, "phrase": "current_noisy_gradient"}, {"score": 0.002795228413298423, "phrase": "iterative_direction"}, {"score": 0.0024673738215365104, "phrase": "new_algorithms"}, {"score": 0.0023579143175099324, "phrase": "numerical_experiments"}, {"score": 0.002253299769886694, "phrase": "new_algorithm"}, {"score": 0.0021778895748464045, "phrase": "rm_algorithm"}, {"score": 0.0021049977753042253, "phrase": "existing_combined_direction_algorithm"}], "paper_keywords": ["stochastic approximation", " conjugate gradient", " Robbins-Monro algorithm", " combinatorial direction"], "paper_abstract": "The stochastic approximation problem is to find some roots or minimizers of a nonlinear function whose expression is unknown and whose evaluations are contaminated with noise. In order to accelerate the classical RM algorithm, this paper proposes a new three-term combinatorial direction stochastic approximation algorithm and its general framework which employ a weighted combination of the current noisy gradient and several previous noisy gradients as the iterative direction. Both the almost sure convergence and the asymptotic rate of convergence of the new algorithms are established. Numerical experiments show that the new algorithm outperforms the RM algorithm and another existing combined direction algorithm.", "paper_title": "New combinatorial direction stochastic approximation algorithms", "paper_id": "WOS:000320925500006"}