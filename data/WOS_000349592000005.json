{"auto_keywords": [{"score": 0.04580640178167045, "phrase": "intermediate_images"}, {"score": 0.01118627404853445, "phrase": "subject_point"}, {"score": 0.00481495049065317, "phrase": "sparse_learning"}, {"score": 0.004634799977448855, "phrase": "new_approach"}, {"score": 0.004556901872357751, "phrase": "subject_image"}, {"score": 0.003978866233891427, "phrase": "similar_local_appearances"}, {"score": 0.0038953958723049287, "phrase": "common_correspondence"}, {"score": 0.0037021153060910164, "phrase": "sparse_representation"}, {"score": 0.0035183910023550246, "phrase": "selected_intermediate_candidate"}, {"score": 0.00337224813954299, "phrase": "template_space"}, {"score": 0.003204841443605308, "phrase": "confidence_level"}, {"score": 0.0031375577552605533, "phrase": "learned_sparse_coefficient"}, {"score": 0.002994449398035894, "phrase": "selected_key_points"}, {"score": 0.002944039482467119, "phrase": "multiple_predictions"}, {"score": 0.0029067881142952664, "phrase": "key_point"}, {"score": 0.002762423953243486, "phrase": "key_points"}, {"score": 0.0027159094186967247, "phrase": "varying_confidences"}, {"score": 0.0026475981474045414, "phrase": "dense_transformation_field"}, {"score": 0.002505412457777352, "phrase": "prediction_reconstruction_protocol"}, {"score": 0.0024632148715152393, "phrase": "multi-resolution_hierarchy"}, {"score": 0.002360796860462937, "phrase": "existing_registration_method"}, {"score": 0.0023408288327263316, "phrase": "effective_manners"}, {"score": 0.0022722584151582616, "phrase": "brain_mr_images"}, {"score": 0.002215081186105616, "phrase": "proposed_framework"}, {"score": 0.002168531704054597, "phrase": "registration_performances"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Deformable image registration", " Brain MR image registration", " Transformation prediction", " Correspondence detection", " Sparsity learning"], "paper_abstract": "We propose a new approach to register the subject image with the template by leveraging a set of intermediate images that are pre-aligned to the template. We argue that, if points in the subject and the intermediate images share similar local appearances, they may have common correspondence in the template. In this way, we learn the sparse representation of a certain subject point to reveal several similar candidate points in the intermediate images. Each selected intermediate candidate can bridge the correspondence from the subject point to the template space, thus predicting the transformation associated with the subject point at the confidence level that relates to the learned sparse coefficient. Following this strategy, we first predict transformations at selected key points, and retain multiple predictions on each key point, instead of allowing only a single correspondence. Then, by utilizing all key points and their predictions with varying confidences, we adaptively reconstruct the dense transformation field that warps the subject to the template. We further embed the prediction reconstruction protocol above into a multi-resolution hierarchy. In the final, we refine our estimated transformation field via existing registration method in effective manners. We apply our method to registering brain MR images, and conclude that the proposed framework is competent to improve registration performances substantially. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Predict brain MR image registration via sparse learning of appearance and transformation", "paper_id": "WOS:000349592000005"}