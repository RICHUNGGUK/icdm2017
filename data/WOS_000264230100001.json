{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "visual_tracking"}, {"score": 0.004744018246633455, "phrase": "object_tracking"}, {"score": 0.004697308822154191, "phrase": "visual_features"}, {"score": 0.004515004397496303, "phrase": "high_dimensional_motion_parameters"}, {"score": 0.00442651096522781, "phrase": "complex_motion_estimation"}, {"score": 0.00427578268550103, "phrase": "large_search_space"}, {"score": 0.004109770306454165, "phrase": "reasonable_strategy"}, {"score": 0.004029187256595917, "phrase": "small_components"}, {"score": 0.003911253966141701, "phrase": "lower_dimensional_motion_parameter_spaces"}, {"score": 0.0037039021744127783, "phrase": "overall_high_dimensional_motion"}, {"score": 0.003455765987713262, "phrase": "individual_tracking_results"}, {"score": 0.0033214855341753544, "phrase": "lower_dimensional_space"}, {"score": 0.0030988889679192965, "phrase": "local_motion_information"}, {"score": 0.003053159610975692, "phrase": "global_parameters"}, {"score": 0.0030081030319492343, "phrase": "robust_way"}, {"score": 0.0029637093924781825, "phrase": "individual_component_motions"}, {"score": 0.0028484940955893134, "phrase": "robust_fusion_algorithm"}, {"score": 0.0027925723953701083, "phrase": "complex_motion_parameters"}, {"score": 0.0027650234530228897, "phrase": "variable-bandwidth_mean-shift"}, {"score": 0.002710735995572145, "phrase": "correlation-based_uncertainty_modeling"}, {"score": 0.002657511557782469, "phrase": "individual_components"}, {"score": 0.0023476849595393872, "phrase": "target_appearance_model"}, {"score": 0.0022563636435096457, "phrase": "component_motion_consistency"}, {"score": 0.0021049977753042253, "phrase": "real_video_sequences"}], "paper_keywords": ["Visual tracking", " Density-based fusion", " Mean-shift", " Component-based tracking"], "paper_abstract": "In object tracking, Visual features may not be discriminative enough to estimate high dimensional motion parameters accurately, and complex motion estimation is computationally expensive due to a large search space. To tackle these problems, a reasonable strategy is to track small components within the target independently in lower dimensional motion parameter spaces (e.g., translation only) and then estimate the overall high dimensional motion (e.g., translation, scale and rotation) by statistically integrating the individual tracking results. Although tracking each component in a lower dimensional space is more reliable and faster, it is not trivial to combine the local motion information and estimate global parameters in a robust way because the individual component motions are frequently inconsistent. We propose a robust fusion algorithm to estimate the complex motion parameters using variable-bandwidth mean-shift. By employing correlation-based uncertainty modeling and fusion of individual components, the motion parameter that is robust to outliers can be detected with variable-bandwidth density-based fusion (VBDF) algorithm. In addition, we describe a method to update target appearance model for each component adaptively based on the component motion consistency. We present various tracking results and compare the performance of our algorithm with others using real video sequences. (C) 2008 Elsevier Inc. All rights reserved.", "paper_title": "Probabilistic fusion-based parameter estimation for visual tracking", "paper_id": "WOS:000264230100001"}