{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "human_action_detection"}, {"score": 0.003931402465972151, "phrase": "actions'_spatial-temporal_locations"}, {"score": 0.003389704997952315, "phrase": "new_graph"}, {"score": 0.0032599633778910516, "phrase": "search_space"}, {"score": 0.0029916929549256297, "phrase": "novel_sub-volume_search_method"}, {"score": 0.0029453365339797933, "phrase": "minimum_cycle"}, {"score": 0.002854761308379149, "phrase": "proposed_method"}, {"score": 0.0027886573969044042, "phrase": "low_computation_complexity"}, {"score": 0.002702887319160534, "phrase": "high_action_detection_accuracy"}, {"score": 0.0024803459795996116, "phrase": "cluttered_backgrounds"}, {"score": 0.002422890839801611, "phrase": "proposed_approach"}, {"score": 0.0021381565332182773, "phrase": "precision-recall_values"}, {"score": 0.0021049977753042253, "phrase": "running_speeds"}], "paper_keywords": ["action detection", " graph representation", " Minimum Cycle detection", " sub-volume search"], "paper_abstract": "This paper discusses the task of human action detection. It requires not only classifying what type the action of interest is, but also finding actions' spatial-temporal locations in a video. The novelty of this paper lies on two significant aspects. One is to introduce a new graph based representation for the search space in a video. The other is to propose a novel sub-volume search method by Minimum Cycle detection. The proposed method has a low computation complexity while maintaining a high action detection accuracy. It is evaluated on two challenging datasets which are captured in cluttered backgrounds. The proposed approach outperforms other state-of-the-art methods in most situations in terms of both Precision-Recall values and running speeds.", "paper_title": "A Fast Sub-Volume Search Method for Human Action Detection", "paper_id": "WOS:000299588600035"}