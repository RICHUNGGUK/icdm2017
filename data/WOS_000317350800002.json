{"auto_keywords": [{"score": 0.03229908250417436, "phrase": "unsupervised_feature_selection"}, {"score": 0.029022889730364838, "phrase": "reconstruction_error"}, {"score": 0.0146971300091401, "phrase": "challenging_task"}, {"score": 0.013182035049715103, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "greedy_feature_selection"}, {"score": 0.004764859786310636, "phrase": "unsupervised_learning"}, {"score": 0.004451676867747938, "phrase": "data_mining_and_machine_learning_applications"}, {"score": 0.004246947739596565, "phrase": "irrelevant_and_redundant_features"}, {"score": 0.004072851768196397, "phrase": "different_learning_algorithms"}, {"score": 0.003926359151817743, "phrase": "dimension_reduction_techniques"}, {"score": 0.0037456980766939836, "phrase": "better_understanding"}, {"score": 0.003480993634130542, "phrase": "relevant_features"}, {"score": 0.003373334961160647, "phrase": "supervised_learning"}, {"score": 0.003251920460276645, "phrase": "class_labels"}, {"score": 0.003085989256759819, "phrase": "novel_method"}, {"score": 0.0029284999172756103, "phrase": "greedy_manner"}, {"score": 0.002823050755743821, "phrase": "effective_criterion"}, {"score": 0.002693018258362651, "phrase": "data_matrix"}, {"score": 0.002637160140011997, "phrase": "selected_subset"}, {"score": 0.0025156683465194967, "phrase": "novel_algorithm"}, {"score": 0.0023254633298356894, "phrase": "greedy_algorithm"}, {"score": 0.0022653055209664284, "phrase": "efficient_recursive_formula"}, {"score": 0.002172266188075892, "phrase": "real_data_sets"}, {"score": 0.0021049977753042253, "phrase": "proposed_algorithm"}], "paper_keywords": ["Feature selection", " Greedy algorithms", " Unsupervised learning"], "paper_abstract": "Reducing the dimensionality of the data has been a challenging task in data mining and machine learning applications. In these applications, the existence of irrelevant and redundant features negatively affects the efficiency and effectiveness of different learning algorithms. Feature selection is one of the dimension reduction techniques, which has been used to allow a better understanding of data and improve the performance of other learning tasks. Although the selection of relevant features has been extensively studied in supervised learning, feature selection in the absence of class labels is still a challenging task. This paper proposes a novel method for unsupervised feature selection, which efficiently selects features in a greedy manner. The paper first defines an effective criterion for unsupervised feature selection that measures the reconstruction error of the data matrix based on the selected subset of features. The paper then presents a novel algorithm for greedily minimizing the reconstruction error based on the features selected so far. The greedy algorithm is based on an efficient recursive formula for calculating the reconstruction error. Experiments on real data sets demonstrate the effectiveness of the proposed algorithm in comparison with the state-of-the-art methods for unsupervised feature selection.", "paper_title": "Efficient greedy feature selection for unsupervised learning", "paper_id": "WOS:000317350800002"}