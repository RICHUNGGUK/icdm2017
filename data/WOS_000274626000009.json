{"auto_keywords": [{"score": 0.04025918977200475, "phrase": "random_forests"}, {"score": 0.007115303547579972, "phrase": "ensemble_bridge_algorithm"}, {"score": 0.0047035227618053965, "phrase": "drug_discovery_problems"}, {"score": 0.004672160300006692, "phrase": "ensemble_algorithms"}, {"score": 0.004311660976562745, "phrase": "boosting_algorithms"}, {"score": 0.004225950334493496, "phrase": "ail_iterative_greedy_optimization_strategy"}, {"score": 0.004046020290832207, "phrase": "stage_weights"}, {"score": 0.003978866233891427, "phrase": "difficult-to-classify_regions"}, {"score": 0.0037966832758423883, "phrase": "randomly_selected_features"}, {"score": 0.0037713445867641393, "phrase": "complex_learners"}, {"score": 0.0037087324991876727, "phrase": "low_bias"}, {"score": 0.0035507457285983268, "phrase": "entire_training_data"}, {"score": 0.003445316481824611, "phrase": "next_learner"}, {"score": 0.003343007152920687, "phrase": "natural_robustness"}, {"score": 0.0033206861608068025, "phrase": "noisy_labels"}, {"score": 0.0030847461428168614, "phrase": "regularization_parameter_nu"}, {"score": 0.0028944757265206332, "phrase": "greedy_nature"}, {"score": 0.002780381587615479, "phrase": "robust_performance"}, {"score": 0.0027250276317603507, "phrase": "noisy_response"}, {"score": 0.0027068216332674895, "phrase": "superior_performance"}, {"score": 0.00265292826903791, "phrase": "clean_response"}, {"score": 0.0026175952455594277, "phrase": "drug_discovery_data"}, {"score": 0.002539802613867161, "phrase": "varying_levels"}, {"score": 0.00242335068996852, "phrase": "single_method"}, {"score": 0.0023990982005125763, "phrase": "ensemble_performance"}, {"score": 0.002375087848055933, "phrase": "method's_robustness"}, {"score": 0.0023199918653986342, "phrase": "data_sets"}, {"score": 0.00227378279992074, "phrase": "better_performance"}, {"score": 0.002184101477091303, "phrase": "diagnostic_tools"}, {"score": 0.0021622381640810442, "phrase": "new_algorithm"}, {"score": 0.0021191645265024855, "phrase": "variable_importance"}, {"score": 0.0021049977753042253, "phrase": "ail_observational_clustering_tool"}], "paper_keywords": [""], "paper_abstract": "Ensemble algorithms have been historically categorized into two separate paradigms, boosting and random forests, which differ significantly in the way each ensemble is constructed. Boosting algorithms represent one extreme, where ail iterative greedy optimization strategy, weak learners (e.g., small classification trees), and stage weights are employed to target difficult-to-classify regions in the training space. Oil the other extreme, random forests rely on randomly selected features and complex learners (learners that exhibit low bias, e.g., large regression trees) to classify well over the entire training data. Because the approach is not targeting the next learner For inclusion, it tends to provide a natural robustness to noisy labels. In this work, we introduce the ensemble bridge algorithm, which is capable of transitioning between boosting and random forests using a regularization parameter nu is an element of [0, 1]. Because the ensemble bridge algorithm is a compromise between the greedy nature of boosting and the randomness present in random forests, it yields robust performance in the presence of a noisy response and superior performance in the presence of a clean response. Often, drug discovery data (e.g., computational chemistry data) have varying levels of noise. Hence, this method enables a practitioner to employ a single method to evaluate ensemble performance. The method's robustness is verified across a variety of data sets where the algorithm repeatedly yields better performance than either boosting or random forests alone. Finally, we provide diagnostic tools for the new algorithm, including a measure of variable importance and ail observational Clustering tool.", "paper_title": "The Ensemble Bridge Algorithm: A New Modeling Tool for Drug Discovery Problems", "paper_id": "WOS:000274626000009"}