{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multimodal_spontaneous_facial_expression_database"}, {"score": 0.043891862951523725, "phrase": "database_collection"}, {"score": 0.03311990226198299, "phrase": "affective_states"}, {"score": 0.028073043512638375, "phrase": "expression_image"}, {"score": 0.004753670676591174, "phrase": "large_and_natural_facial_expression_database"}, {"score": 0.0046781613377273774, "phrase": "facial_expression_analysis"}, {"score": 0.004401955895933783, "phrase": "adequately_large_number"}, {"score": 0.0043738432231020885, "phrase": "spontaneous_facial_expression_images"}, {"score": 0.0042495320879288615, "phrase": "exact_measurements"}, {"score": 0.004115530872032165, "phrase": "comprehensive_first-hand_data_analyses"}, {"score": 0.003985738225654119, "phrase": "future_research"}, {"score": 0.00396027311392058, "phrase": "database_construction"}, {"score": 0.003934970057482768, "phrase": "expression_recognition"}, {"score": 0.0038973170902076707, "phrase": "emotion_inference"}, {"score": 0.0037743802306714545, "phrase": "natural_visible_and_infrared_facial_expressions"}, {"score": 0.0036553070575015344, "phrase": "emotion-eliciting_videos"}, {"score": 0.0035060903664150115, "phrase": "subjects'_self-reported_data"}, {"score": 0.003450329424861292, "phrase": "interrater_reliability_analysis"}, {"score": 0.0034282732966589478, "phrase": "raters'_subjective_evaluations"}, {"score": 0.0034063576796640603, "phrase": "apex_expression_images"}, {"score": 0.003341701945638249, "phrase": "kappa"}, {"score": 0.003320103862138634, "phrase": "kendall"}, {"score": 0.0032256239062596944, "phrase": "matching_rate_matrix"}, {"score": 0.0031641444460976673, "phrase": "displayed_spontaneous_expressions"}, {"score": 0.0030839851024657395, "phrase": "thermal_differences"}, {"score": 0.003054450075234415, "phrase": "posed_and_spontaneous_facial_expressions"}, {"score": 0.0030058503645435455, "phrase": "paired-samples_t-test"}, {"score": 0.0028463059289874637, "phrase": "emotional_responses"}, {"score": 0.0027741761880779535, "phrase": "facial_image_sequences"}, {"score": 0.002730023736069673, "phrase": "apex_images"}, {"score": 0.002610090005760493, "phrase": "multiple_categories"}, {"score": 0.0025521085778978042, "phrase": "better_approach"}, {"score": 0.002416589459425828, "phrase": "facial_expressions"}, {"score": 0.002310393431454434, "phrase": "displayed_manifestations"}, {"score": 0.0022956075241520064, "phrase": "felt_emotions"}, {"score": 0.002251813863195168, "phrase": "significant_differences"}, {"score": 0.0022302306304023602, "phrase": "temperature_difference_data"}, {"score": 0.0021049977753042253, "phrase": "cheek_regions"}], "paper_keywords": ["Spontaneous facial expression", " database construction", " analysis"], "paper_abstract": "Creating a large and natural facial expression database is a prerequisite for facial expression analysis and classification. It is, however, not only time consuming but also difficult to capture an adequately large number of spontaneous facial expression images and their meanings because no standard, uniform, and exact measurements are available for database collection and annotation. Thus, comprehensive first-hand data analyses of a spontaneous expression database may provide insight for future research on database construction, expression recognition, and emotion inference. This paper presents our analyses of a multimodal spontaneous facial expression database of natural visible and infrared facial expressions (NVIE). First, the effectiveness of emotion-eliciting videos in the database collection is analyzed with the mean and variance of the subjects' self-reported data. Second, an interrater reliability analysis of raters' subjective evaluations for apex expression images and sequences is conducted using Kappa and Kendall's coefficients. Third, we propose a matching rate matrix to explore the agreements between displayed spontaneous expressions and felt affective states. Lastly, the thermal differences between the posed and spontaneous facial expressions are analyzed using a paired-samples t-test. The results of these analyses demonstrate the effectiveness of our emotion-inducing experimental design, the gender difference in emotional responses, and the coexistence of multiple emotions/expressions. Facial image sequences are more informative than apex images for both expression and emotion recognition. Labeling an expression image or sequence with multiple categories together with their intensities could be a better approach than labeling the expression image or sequence with one dominant category. The results also demonstrate both the importance of facial expressions as a means of communication to convey affective states and the diversity of the displayed manifestations of felt emotions. There are indeed some significant differences between the temperature difference data of most posed and spontaneous facial expressions, many of which are found in the forehead and cheek regions.", "paper_title": "Analyses of a Multimodal Spontaneous Facial Expression Database", "paper_id": "WOS:000323642900004"}