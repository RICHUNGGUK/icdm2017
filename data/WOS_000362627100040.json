{"auto_keywords": [{"score": 0.04567231189431087, "phrase": "group_probability_dataset"}, {"score": 0.04049871558392554, "phrase": "ic"}, {"score": 0.02987155483253437, "phrase": "training_data"}, {"score": 0.025676397475815696, "phrase": "testing_data"}, {"score": 0.00481495049065317, "phrase": "group_probabilities"}, {"score": 0.004761968711051715, "phrase": "regression_model"}, {"score": 0.004726970265271088, "phrase": "group_probability_classifier_learning"}, {"score": 0.004623503587186056, "phrase": "learning_technique"}, {"score": 0.004555781299332848, "phrase": "privacy-preserving_data_mining"}, {"score": 0.004310501708408856, "phrase": "class_labels"}, {"score": 0.004048378919038729, "phrase": "whole_dataset"}, {"score": 0.003974349782102708, "phrase": "existing_work"}, {"score": 0.00388729255686046, "phrase": "inverse_calibration"}, {"score": 0.003774164192882704, "phrase": "estimated_labels"}, {"score": 0.003623949225126944, "phrase": "classical_classification_algorithms"}, {"score": 0.003584025547693836, "phrase": "support_vector_machine"}, {"score": 0.003479692058963528, "phrase": "desired_classifier"}, {"score": 0.003441352119167824, "phrase": "critical_challenge"}, {"score": 0.0034034331737042363, "phrase": "exiting_ic-based_methods"}, {"score": 0.003304339421246321, "phrase": "ideal_ic_function"}, {"score": 0.0032800186243040663, "phrase": "label_estimation"}, {"score": 0.0031845067058084583, "phrase": "adopted_ic_function"}, {"score": 0.003069006373093756, "phrase": "novel_probability_transductive_classifier"}, {"score": 0.0029796206196589115, "phrase": "learning_procedure"}, {"score": 0.002914288956035066, "phrase": "probability_values"}, {"score": 0.0027878797103973313, "phrase": "model_training"}, {"score": 0.0026768142335374156, "phrase": "continuous_real_values"}, {"score": 0.0026472970609754095, "phrase": "existing_classical_regression_model"}, {"score": 0.002570162055835289, "phrase": "group_probability_classification_problem"}, {"score": 0.0025324393547676623, "phrase": "future_testing_data"}, {"score": 0.0025045102029373854, "phrase": "model_output"}, {"score": 0.0024768883044869023, "phrase": "obtained_group_probability_classification_model"}, {"score": 0.0023781827711414107, "phrase": "positive_class"}, {"score": 0.002317423416027688, "phrase": "final_class_label"}, {"score": 0.0022415745160585146, "phrase": "classification_task"}, {"score": 0.0022168460543913787, "phrase": "experimental_results"}, {"score": 0.0022005118194652704, "phrase": "synthetic_datasets"}, {"score": 0.0021842976754894846, "phrase": "real_uci_datasets"}, {"score": 0.0021522261505574035, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "existing_methods"}], "paper_keywords": ["Privacy preserving", " regression model", " probability transductive", " group probability", " classification"], "paper_abstract": "Group probability classifier learning is an emerging and promising learning technique, especially in privacy-preserving data mining. It is used to train a classifier from a group probability dataset, where the class labels of each sample are unknown while the probabilities of each class in the given data groups of the whole dataset are available. The existing work is mainly based on the inverse calibration (IC) strategy to obtain the estimated labels for data in the group probability dataset and then make use of classical classification algorithms such as support vector machine (SVM) model to train the desired classifier. A critical challenge of the exiting IC-based methods lies in the difficulty of designing an ideal IC function for label estimation and the methods are sensitive to the adopted IC function. In order to overcome this shortcoming, a novel probability transductive classifier that does not involve IC in the learning procedure is proposed, where the probability values are directly used as the output of the training data for the model training. Particularly, on the training data with the output being continuous real values, the existing classical regression model can be easily adopted to model the group probability classification problem. For a future testing data, the model output of the obtained group probability classification model can present the probability that the testing data belong to the positive class. With a given threshold, the final class label of the testing data can be obtained for the classification task. The experimental results on synthetic datasets and real UCI datasets show that the proposed method is more effective than the existing methods.", "paper_title": "A novel privacy-preserving probability transductive classifiers from group probabilities based on regression model", "paper_id": "WOS:000362627100040"}