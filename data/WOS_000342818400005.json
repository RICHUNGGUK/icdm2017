{"auto_keywords": [{"score": 0.03858815077336417, "phrase": "ofc"}, {"score": 0.00481495049065317, "phrase": "emotional_brain"}, {"score": 0.004757227624616643, "phrase": "online_visual_object_recognition"}, {"score": 0.004505881071218599, "phrase": "novel_visual_object_recognizer"}, {"score": 0.004398457709182882, "phrase": "human_brain's_emotional_learning"}, {"score": 0.004293584349522444, "phrase": "proposed_computational_model"}, {"score": 0.004216566615939546, "phrase": "visual_information"}, {"score": 0.004091248980678087, "phrase": "ventral_visual_pathway"}, {"score": 0.0038749521906474593, "phrase": "emotional_visual_stimuli"}, {"score": 0.003714629047818465, "phrase": "orbitofrontal_cortex"}, {"score": 0.0036082391635407036, "phrase": "ofc."}, {"score": 0.0035824802350703376, "phrase": "amygdala_response"}, {"score": 0.0034759420565135253, "phrase": "inappropriate_answers"}, {"score": 0.0034135407979996673, "phrase": "proposed_visual_recognizer"}, {"score": 0.003332072426367186, "phrase": "threshold_logic_units"}, {"score": 0.003252542052430779, "phrase": "neural_models"}, {"score": 0.00306189690236109, "phrase": "experimental_results"}, {"score": 0.0030069062905274976, "phrase": "presented_model"}, {"score": 0.002952900365829518, "phrase": "visual_patterns"}, {"score": 0.0028823939507764238, "phrase": "higher_performance"}, {"score": 0.002830617996609902, "phrase": "brain_emotional_learning-based_pattern_recognizer"}, {"score": 0.0027966169696270627, "phrase": "brlpr"}, {"score": 0.0025697460140513932, "phrase": "adaptive_neurofuzzy_inference_system"}, {"score": 0.0023328599525181707, "phrase": "main_features"}, {"score": 0.0022909325048608054, "phrase": "proposed_model"}, {"score": 0.0022497569011987587, "phrase": "lower_time"}, {"score": 0.002222717552124615, "phrase": "spatial_complexity"}, {"score": 0.0021049977753042253, "phrase": "real-time_visual_object_recognition"}], "paper_keywords": [""], "paper_abstract": "In this study, we propose a novel visual object recognizer inspired by the human brain's emotional learning. In the proposed computational model, the visual information is transferred through the ventral visual pathway to the amygdala, which is responsible for emotional visual stimuli. In the model, the orbitofrontal cortex (OFC) evaluates the amygdala response and tries to prevent inappropriate answers. The proposed visual recognizer is based on threshold logic units defined on the neural models of the amygdala and the OFC. According to the experimental results, the presented model learns the visual patterns quickly and shows higher performance than the brain emotional learning-based pattern recognizer (BRLPR) and multilayer perceptron (MLP) with Levenberg-Marquardt backpropagation (BPG) learning algorithm, in which the adaptive neurofuzzy inference system (ANFIS) cannot be trained because of the curse of dimensionality. The main features of the proposed model are the lower time and spatial complexity. Hence, it can be utilized in real-time visual object recognition.", "paper_title": "A Neural Basis Computational Model of Emotional Brain for Online Visual Object Recognition", "paper_id": "WOS:000342818400005"}