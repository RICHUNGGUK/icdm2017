{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "process_variation_impact"}, {"score": 0.004775335634705251, "phrase": "instruction_fetches"}, {"score": 0.004658426838467567, "phrase": "finer_process_geometries"}, {"score": 0.004488384083300084, "phrase": "critical_physical_parameters"}, {"score": 0.00443308765153716, "phrase": "channel_length"}, {"score": 0.004396600680348434, "phrase": "gate_oxide_thickness"}, {"score": 0.004342430078306461, "phrase": "dopant_ion_concentration"}, {"score": 0.004201202199968683, "phrase": "dramatic_variations"}, {"score": 0.0041666157975446564, "phrase": "access_latencies"}, {"score": 0.004132312946154097, "phrase": "static_random_access_memory"}, {"score": 0.0039813976794342, "phrase": "different_lines"}, {"score": 0.0038838500580958744, "phrase": "different_access_latencies"}, {"score": 0.003835972725191194, "phrase": "simple_solution"}, {"score": 0.00371115485111022, "phrase": "worst-case_latency_paradigm"}, {"score": 0.0036502716977381004, "phrase": "egalitarian_cache_management"}, {"score": 0.0035461111918923117, "phrase": "significant_performance_overhead"}, {"score": 0.0033883824438527316, "phrase": "lookaside_buffer"}, {"score": 0.0031452231581533814, "phrase": "future_high-performance_processors"}, {"score": 0.0030177339185643226, "phrase": "hardware_and_software_enhancements"}, {"score": 0.0028360962841331634, "phrase": "process_variation"}, {"score": 0.002778006389296707, "phrase": "pipeline_stage"}, {"score": 0.002755104031926742, "phrase": "modern_processors"}, {"score": 0.0025785359740308337, "phrase": "-physical_page_translation"}, {"score": 0.002494531100339247, "phrase": "special_register"}, {"score": 0.0023346234464901978, "phrase": "varying_access_latencies"}, {"score": 0.002315367926547472, "phrase": "different_instruction_cache_lines"}, {"score": 0.0022679195103377124, "phrase": "cache_access_latency"}, {"score": 0.0021049977753042253, "phrase": "next_instruction"}], "paper_keywords": ["Algorithms", " Performance", " Process variation", " instruction cache", " address translation", " encoding"], "paper_abstract": "As technology moves towards finer process geometries, it is becoming extremely difficult to control critical physical parameters such as channel length, gate oxide thickness, and dopant ion concentration. Variations in these parameters lead to dramatic variations in access latencies in Static Random Access Memory (SRAM) devices. This means that different lines of the same cache may have different access latencies. A simple solution to this problem is to adopt the worst-case latency paradigm. While this egalitarian cache management is simple, it may introduce significant performance overhead during instruction fetches when both address translation (instruction Translation Lookaside Buffer (TLB) access) and instruction cache access take place, making this solution infeasible for future high-performance processors. In this study, we first propose some hardware and software enhancements and then, based on those, investigate several techniques to mitigate the effect of process variation on the instruction fetch pipeline stage in modern processors. For address translation, we study an approach that performs the virtual-to-physical page translation once, then stores it in a special register, reusing it as long as the execution remains on the same instruction page. To handle varying access latencies across different instruction cache lines, we annotate the cache access latency of instructions within themselves to give the circuitry a hint about how long to wait for the next instruction to become available.", "paper_title": "Hardware/Software Approaches for Reducing the Process Variation Impact on Instruction Fetches", "paper_id": "WOS:000327119100010"}