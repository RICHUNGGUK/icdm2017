{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multiple_datasets"}, {"score": 0.00475924837336259, "phrase": "entity_resolution"}, {"score": 0.004211731831120046, "phrase": "different_types"}, {"score": 0.002867348342846275, "phrase": "similar_records"}, {"score": 0.002736694413701639, "phrase": "full_data"}, {"score": 0.00249293148301837, "phrase": "individual_er_algorithms"}, {"score": 0.0023932142697579506, "phrase": "full_dataset"}, {"score": 0.0022184630090454132, "phrase": "\"state-based\"_training_technique"}, {"score": 0.0021049977753042253, "phrase": "particular_execution_context"}], "paper_keywords": ["Entity resolution", " Joint entity resolution", " Physical execution", " Influence graph", " Execution plan", " Expander function", " State-based training", " Data cleaning"], "paper_abstract": "Entity resolution (ER) is the problem of identifying which records in a database represent the same entity. Often, records of different types are involved (e.g., authors, publications, institutions, venues), and resolving records of one type can impact the resolution of other types of records. In this paper we propose a flexible, modular resolution framework where existing ER algorithms developed for a given record type can be plugged in and used in concert with other ER algorithms. Our approach also makes it possible to run ER on subsets of similar records at a time, important when the full data are too large to resolve together. We study the scheduling and coordination of the individual ER algorithms, in order to resolve the full dataset, and show the scalability of our approach. We also introduce a \"state-based\" training technique where each ER algorithm is trained for the particular execution context (relative to other types of records) where it will be used.", "paper_title": "Joint entity resolution on multiple datasets", "paper_id": "WOS:000327130400003"}