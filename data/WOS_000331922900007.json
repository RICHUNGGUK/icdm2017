{"auto_keywords": [{"score": 0.040845749728847636, "phrase": "morgan"}, {"score": 0.00481495049065317, "phrase": "weakest_pre-expectation_semantics"}, {"score": 0.0047026237903774895, "phrase": "probabilistic_guarded_command_language"}, {"score": 0.004485735417293941, "phrase": "simple_operational_semantics"}, {"score": 0.004346704947011699, "phrase": "dijkstra's_guarded_command_language"}, {"score": 0.00412338045153682, "phrase": "mciver"}, {"score": 0.0040176151419992956, "phrase": "pgcl's_wp-semantics"}, {"score": 0.003832198214757852, "phrase": "parametric_markov_decision"}, {"score": 0.003459191419478298, "phrase": "operational_model"}, {"score": 0.00314708280192844, "phrase": "pgcl-program_w.r.t"}, {"score": 0.0029781530607129653, "phrase": "expected_cumulative_reward"}, {"score": 0.0028857130140890787, "phrase": "terminal_state"}, {"score": 0.00281826552772148, "phrase": "parametric_mdp"}, {"score": 0.002645992747675361, "phrase": "similar_way"}, {"score": 0.0025038930574283174, "phrase": "weakest_liberal_pre-expectations"}, {"score": 0.002464709648714996, "phrase": "liberal_expected_cumulative_rewards"}, {"score": 0.0023694065215394593, "phrase": "probabilistic_programs"}, {"score": 0.0022958180852458215, "phrase": "operational_semantics"}, {"score": 0.0022070310530794097, "phrase": "simple_running_example"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Expectation transformer semantics", " Operational semantics", " Markov decision process", " Expected rewards"], "paper_abstract": "This paper proposes a simple operational semantics of pGCL, Dijkstra's guarded command language extended with probabilistic choice, and relates this to pGCL's wp-semantics by McIver and Morgan. Parametric Markov decision processes whose state rewards depend on the post-expectation at hand are used as the operational model. We show that the weakest pre-expectation of a pGCL-program w.r.t. a post-expectation corresponds to the expected cumulative reward to reach a terminal state in the parametric MDP associated to the program. In a similar way, we show a correspondence between weakest liberal pre-expectations and liberal expected cumulative rewards. The verification of probabilistic programs using wp-semantics and operational semantics is illustrated using a simple running example. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Operational versus weakest pre-expectation semantics for the probabilistic guarded command language", "paper_id": "WOS:000331922900007"}