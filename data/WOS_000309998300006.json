{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "location-based_information"}, {"score": 0.004775335634705251, "phrase": "rich_audio_representations"}, {"score": 0.004506968388996092, "phrase": "navigation_tasks"}, {"score": 0.004360412703519539, "phrase": "-situ_audio_services"}, {"score": 0.004306688605423827, "phrase": "isas"}, {"score": 0.004132312946154097, "phrase": "blind_and_visually_impaired_communities"}, {"score": 0.004064548693812535, "phrase": "spatialized_audio_rendering"}, {"score": 0.003997891221012094, "phrase": "relevant_content"}, {"score": 0.0038678251731669865, "phrase": "immediate_surroundings"}, {"score": 0.003773049633656302, "phrase": "cultural_sites"}, {"score": 0.0037419747525425586, "phrase": "public_transportation_locations"}, {"score": 0.003560807940070886, "phrase": "online_data_resources"}, {"score": 0.003444912629614206, "phrase": "speech_technology"}, {"score": 0.0032376465741070274, "phrase": "location-aware_mobile_device"}, {"score": 0.0030680994147125364, "phrase": "specific_constraints"}, {"score": 0.003030247482854539, "phrase": "target_population"}, {"score": 0.0029437270961011077, "phrase": "general_mobile_users"}, {"score": 0.0027211030647461324, "phrase": "spatialized_audio_content"}, {"score": 0.002676418520290942, "phrase": "interactive_auditory_maps"}, {"score": 0.002363806685815014, "phrase": "rendering_strategies"}, {"score": 0.002258546887303777, "phrase": "spatial_audio"}, {"score": 0.0022214412809055013, "phrase": "effective_technique"}], "paper_keywords": ["Sound spatialization", " Auditory maps", " Mobile applications", " Blind and visually impaired community", " Location-based information"], "paper_abstract": "We consider the challenge of delivering location-based information through rich audio representations of the environment, and the associated opportunities that such an approach offers to support navigation tasks. This challenge is addressed by In-Situ Audio Services, or ISAS, a system intended primarily for use by the blind and visually impaired communities. It employs spatialized audio rendering to convey the relevant content, which may include information about the immediate surroundings, such as restaurants, cultural sites, public transportation locations, and other points of interest. Information is aggregated mostly from online data resources, converted using text-to-speech technology, and \"displayed\", either as speech or more abstract audio icons, through a location-aware mobile device or smart-phone. This is suitable not only for the specific constraints of the target population, but is equally useful for general mobile users whose visual attention is otherwise occupied with navigation. We designed and conducted an experiment to evaluate two techniques for delivering spatialized audio content to users via interactive auditory maps: the shockwave mode and the radar mode. While neither mode proved to be significantly better than the other, subjects proved competent at navigating the maps using these rendering strategies, and reacted positively to the system, demonstrating that spatial audio can be an effective technique for conveying location-based information. The results of this experiment and its implications to our project are described here.", "paper_title": "Eyes-free environmental awareness for navigation", "paper_id": "WOS:000309998300006"}