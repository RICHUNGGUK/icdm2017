{"auto_keywords": [{"score": 0.050072553508821435, "phrase": "machine_learning"}, {"score": 0.03992177733192289, "phrase": "gmm_and_knn_classifiers"}, {"score": 0.02945562830088263, "phrase": "svm"}, {"score": 0.004709567162738894, "phrase": "computer-aided_screening_system"}, {"score": 0.004606479650820579, "phrase": "fundus_images"}, {"score": 0.0045726187330434025, "phrase": "varying_illumination"}, {"score": 0.004423284899590467, "phrase": "severity_grade"}, {"score": 0.004390764654147291, "phrase": "diabetic_retinopathy"}, {"score": 0.004216112320418982, "phrase": "gaussian_mixture_model"}, {"score": 0.004123781267600542, "phrase": "-nearest_neighbor"}, {"score": 0.0039306272589185185, "phrase": "adaboost"}, {"score": 0.003858697684681798, "phrase": "retinopathy_lesions"}, {"score": 0.0037188360359702182, "phrase": "best_classifiers"}, {"score": 0.0036914757355166966, "phrase": "bright_and_red_lesion_classification"}, {"score": 0.003623949225126944, "phrase": "main_contribution"}, {"score": 0.003441352119167824, "phrase": "lesion_classification"}, {"score": 0.0032558762499901727, "phrase": "novel_two-step_hierarchical_classification_approach"}, {"score": 0.0031727643282003976, "phrase": "false_positives"}, {"score": 0.0031146967095233586, "phrase": "first_step"}, {"score": 0.003069006373093756, "phrase": "second_step"}, {"score": 0.003035177667751495, "phrase": "bright_lesions"}, {"score": 0.0029906503184034634, "phrase": "hard_exudates"}, {"score": 0.0029686314779877525, "phrase": "cotton_wool_spots"}, {"score": 0.002925077525258983, "phrase": "red_lesions"}, {"score": 0.0028293966058473476, "phrase": "lesion_classification_problem"}, {"score": 0.0027982016314450717, "phrase": "unbalanced_datasets"}, {"score": 0.0027571412070078703, "phrase": "combination_classifiers"}, {"score": 0.0026966744704447275, "phrase": "dempster-shafer_theory"}, {"score": 0.0025796799784169196, "phrase": "data_imbalance"}, {"score": 0.002551231163230566, "phrase": "dr_severity_grading_system"}, {"score": 0.0024860616730750158, "phrase": "publicly_available_messidor_dataset"}, {"score": 0.0024586427394152196, "phrase": "dream_system"}, {"score": 0.0023870184576855764, "phrase": "auc"}, {"score": 0.0022005118194652704, "phrase": "feature_reduction"}, {"score": 0.0021682027434117095, "phrase": "average_computation_time"}, {"score": 0.0021522261505574035, "phrase": "dr_severity"}], "paper_keywords": ["Bright lesions", " classification", " diabetic retinopathy (DR)", " fundus image processing", " red lesions", " segmentation", " severity grade"], "paper_abstract": "This paper presents a computer-aided screening system (DREAM) that analyzes fundus images with varying illumination and fields of view, and generates a severity grade for diabetic retinopathy (DR) using machine learning. Classifiers such as the Gaussian Mixture model (GMM), k-nearest neighbor (kNN), support vector machine (SVM), and AdaBoost are analyzed for classifying retinopathy lesions from nonlesions. GMM and kNN classifiers are found to be the best classifiers for bright and red lesion classification, respectively. A main contribution of this paper is the reduction in the number of features used for lesion classification by feature ranking using Adaboost where 30 top features are selected out of 78. A novel two-step hierarchical classification approach is proposed where the nonlesions or false positives are rejected in the first step. In the second step, the bright lesions are classified as hard exudates and cotton wool spots, and the red lesions are classified as hemorrhages and micro-aneurysms. This lesion classification problem deals with unbalanced datasets and SVM or combination classifiers derived from SVM using the Dempster-Shafer theory are found to incur more classification error than the GMM and kNN classifiers due to the data imbalance. The DR severity grading system is tested on 1200 images from the publicly available MESSIDOR dataset. The DREAM system achieves 100% sensitivity, 53.16% specificity, and 0.904 AUC, compared to the best reported 96% sensitivity, 51% specificity, and 0.875 AUC, for classifying images as with or without DR. The feature reduction further reduces the average computation time for DR severity per image from 59.54 to 3.46 s.", "paper_title": "DREAM: Diabetic Retinopathy Analysis Using Machine Learning", "paper_id": "WOS:000341986600022"}