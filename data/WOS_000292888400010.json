{"auto_keywords": [{"score": 0.03843856552198327, "phrase": "probability_distribution"}, {"score": 0.027974447194407184, "phrase": "data_manifold"}, {"score": 0.00481495049065317, "phrase": "laplacian_regularized_gaussian_mixture_model_for_data_clustering"}, {"score": 0.004760017604908536, "phrase": "gaussian_mixture_models"}, {"score": 0.004317576641196539, "phrase": "gaussian_distribution"}, {"score": 0.004243862930012258, "phrase": "clustering_process"}, {"score": 0.004030157055463817, "phrase": "gaussian_mixture"}, {"score": 0.003916098498242888, "phrase": "expectation-maximization_algorithm"}, {"score": 0.0034118234596993836, "phrase": "ambient_space"}, {"score": 0.0031481164109237636, "phrase": "intrinsic_geometry"}, {"score": 0.0028880836335117297, "phrase": "regularized_probabilistic_model"}, {"score": 0.00283870598459543, "phrase": "manifold_structure"}, {"score": 0.002806256131739047, "phrase": "data_clustering"}, {"score": 0.002759003871926, "phrase": "laplacian"}, {"score": 0.002726740692380339, "phrase": "gaussian_mixture_model"}, {"score": 0.0025596276616952516, "phrase": "nearest_neighbor_graph"}, {"score": 0.0025014259919355453, "phrase": "graph_structure"}, {"score": 0.0024305268807926056, "phrase": "maximum_likelihood_objective_function"}, {"score": 0.0023346234464901978, "phrase": "obtained_conditional_probability_distribution"}, {"score": 0.0022041312401435346, "phrase": "experimental_results"}, {"score": 0.0021789194955896124, "phrase": "real_data_sets"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Gaussian mixture model", " clustering", " graph laplacian", " manifold structure"], "paper_abstract": "Gaussian Mixture Models (GMMs) are among the most statistically mature methods for clustering. Each cluster is represented by a Gaussian distribution. The clustering process thereby turns to estimate the parameters of the Gaussian mixture, usually by the Expectation-Maximization algorithm. In this paper, we consider the case where the probability distribution that generates the data is supported on a submanifold of the ambient space. It is natural to assume that if two points are close in the intrinsic geometry of the probability distribution, then their conditional probability distributions are similar. Specifically, we introduce a regularized probabilistic model based on manifold structure for data clustering, called Laplacian regularized Gaussian Mixture Model (LapGMM). The data manifold is modeled by a nearest neighbor graph, and the graph structure is incorporated in the maximum likelihood objective function. As a result, the obtained conditional probability distribution varies smoothly along the geodesics of the data manifold. Experimental results on real data sets demonstrate the effectiveness of the proposed approach.", "paper_title": "Laplacian Regularized Gaussian Mixture Model for Data Clustering", "paper_id": "WOS:000292888400010"}