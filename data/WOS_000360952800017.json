{"auto_keywords": [{"score": 0.035604227519209775, "phrase": "sge"}, {"score": 0.008713746535735483, "phrase": "subclass_graph_embedding"}, {"score": 0.007963887102559748, "phrase": "sda"}, {"score": 0.007754249471411714, "phrase": "cda"}, {"score": 0.007086661447867037, "phrase": "ge"}, {"score": 0.0065846140614018, "phrase": "subclass_discriminant_information"}, {"score": 0.004687815426832587, "phrase": "subspace_learning_techniques"}, {"score": 0.0045946617913925755, "phrase": "dimensionality_reduction"}, {"score": 0.004513361120638696, "phrase": "smfa"}, {"score": 0.0044286400018187354, "phrase": "subclass_discriminant_analysis"}, {"score": 0.004355795360847047, "phrase": "clustering"}, {"score": 0.004311660976562745, "phrase": "discriminant_analysis"}, {"score": 0.004211831095629, "phrase": "subclass_information"}, {"score": 0.00412809672402551, "phrase": "data_classes"}, {"score": 0.00400559360117678, "phrase": "important_work"}, {"score": 0.003939107874750185, "phrase": "graph_embedding"}, {"score": 0.0038350096441245153, "phrase": "general_framework"}, {"score": 0.0034684722988160637, "phrase": "main_contribution"}, {"score": 0.003200551622256746, "phrase": "lpp"}, {"score": 0.003168543855125077, "phrase": "principal_component_analysis"}, {"score": 0.0031474704265380586, "phrase": "pca"}, {"score": 0.003115908199991072, "phrase": "linear_discriminant_analysis"}, {"score": 0.0030951788076085253, "phrase": "lda"}, {"score": 0.003053894781246847, "phrase": "theoretical_link"}, {"score": 0.002799080959445996, "phrase": "typical_ge_framework"}, {"score": 0.002780381587615479, "phrase": "subclass_dr_methods"}, {"score": 0.0027068216332674895, "phrase": "easy_utilization"}, {"score": 0.0025654738267173274, "phrase": "novel_dr_algorithm"}, {"score": 0.0025059724686541263, "phrase": "subclass_marginal_fisher_analysis"}, {"score": 0.0021477840826122853, "phrase": "new_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Dimensionality reduction", " Subspace learning", " Graph Embedding", " Subclass structure"], "paper_abstract": "Subspace learning techniques have been extensively used for dimensionality reduction (DR) in many pattern classification problem domains. Recently, methods like Subclass Discriminant Analysis (SDA) and Clustering-based Discriminant Analysis (CDA), which use subclass information for the discrimination between the data classes, have attracted much attention. In parallel, important work has been accomplished on Graph Embedding (GE), which is a general framework unifying several subspace learning techniques. In this paper, GE has been extended in order to integrate subclass discriminant information resulting to the novel Subclass Graph Embedding (SGE) framework, which is the main contribution of our work. It is proven that SGE encapsulates a diversity of both supervised and unsupervised unimodal methods like Locality Preserving Projections (LPP), Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA). The theoretical link of SDA and CDA methods with SGE is also established. Along these lines, it is shown that SGE comprises a generalization of the typical GE framework including subclass DR methods. Moreover, it allows for an easy utilization of kernels for confronting non-linearly separable data. Employing SGE, in this paper a novel DR algorithm, which uses subclass discriminant information, called Subclass Marginal Fisher Analysis (SMFA) has been proposed. Through a series of experiments on various real-world datasets, it is shown that SMFA outperforms in most of the cases the state-of-the-art demonstrating the efficacy and power of SGE as a platform to develop new methods. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Subclass Graph Embedding and a Marginal Fisher Analysis paradigm", "paper_id": "WOS:000360952800017"}