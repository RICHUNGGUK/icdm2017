{"auto_keywords": [{"score": 0.0313210843742285, "phrase": "icomp"}, {"score": 0.015719713042815744, "phrase": "multivariate_adaptive_regression_splines"}, {"score": 0.013593183595993923, "phrase": "mars"}, {"score": 0.00907163077292733, "phrase": "parameter_estimates"}, {"score": 0.004741845603430361, "phrase": "information_complexity"}, {"score": 0.004698514007994158, "phrase": "fitness_function"}, {"score": 0.004627168743964783, "phrase": "information-theoretic_measure"}, {"score": 0.004515252649226697, "phrase": "model_selection"}, {"score": 0.004119049028319832, "phrase": "popular_nonparametric_regression_technique"}, {"score": 0.00405646687267772, "phrase": "nonlinear_relationship"}, {"score": 0.0040193730627071135, "phrase": "response_variable"}, {"score": 0.0038981499110532307, "phrase": "piecewise_linear"}, {"score": 0.0038743458641420157, "phrase": "cubic_splines"}, {"score": 0.003850686614685676, "phrase": "basis_functions"}, {"score": 0.0038154673253945003, "phrase": "critical_aspect"}, {"score": 0.003734531922225675, "phrase": "nonparametric_regression_model"}, {"score": 0.003700371064796848, "phrase": "mars_strategy"}, {"score": 0.0035777568441311292, "phrase": "best_submodel"}, {"score": 0.003545024951402821, "phrase": "appropriate_number"}, {"score": 0.003438058620195309, "phrase": "usual_regression_modeling"}, {"score": 0.0033961782274326948, "phrase": "large_number"}, {"score": 0.003375429082739004, "phrase": "predictor_variables"}, {"score": 0.0032635467579751423, "phrase": "precise_information"}, {"score": 0.0032336801561165113, "phrase": "exact_functional_relationships"}, {"score": 0.0030601162942933665, "phrase": "simplest_model"}, {"score": 0.002913650880082273, "phrase": "powerful_model_selection_criterion"}, {"score": 0.0028430608076324727, "phrase": "model_complexity"}, {"score": 0.0026986685585382347, "phrase": "free_parameters"}, {"score": 0.0025537472239953807, "phrase": "akaike's_information_criterion"}, {"score": 0.002538131851615231, "phrase": "schwarz's_bayesian_information_criterion"}, {"score": 0.0025226117209113737, "phrase": "generalized_cross-validation"}, {"score": 0.002469032978674379, "phrase": "best_subset_models"}, {"score": 0.00241658945942583, "phrase": "real_benchmark_example"}, {"score": 0.0023507916951658455, "phrase": "proposed_model_selection_approach"}, {"score": 0.002329258721870127, "phrase": "best_functional_form"}, {"score": 0.0023079225317714815, "phrase": "predictive_model"}, {"score": 0.0022519745140925475, "phrase": "general_model_selection_criterion"}, {"score": 0.002197379785587054, "phrase": "correlational_structure"}, {"score": 0.002163930783583212, "phrase": "selected_model"}, {"score": 0.0021441057555396013, "phrase": "new_approach"}], "paper_keywords": ["Model selection", " Multivariate adaptive regression Splines (MARS)", " Nonparametric regression", " Information complexity"], "paper_abstract": "This paper introduces information-theoretic measure of complexity (ICOMP) criterion for model selection in multivariate adaptive regression splines (MARS) to tradeoff efficiently between how well the model fits the data and the model complexity. As is well known, MARS is a popular nonparametric regression technique used to study the nonlinear relationship between a response variable and the set of predictors with the help of piecewise linear or cubic splines as basis functions. A critical aspect in determining the form of the nonparametric regression model during the MARS strategy is the evaluation of portfolio of submodels to select the best submodel with the appropriate number of knots over subset of predictors. In the usual regression modeling, when a large number of predictor variables are present in the model, and there is no precise information about the exact functional relationships among the variables, many model selection criteria still overfit the model. In this paper, to find the simplest model that balances the overfitting and underfitting for the model, ICOMP is proposed as a powerful model selection criterion for MARS modeling. Here, the model complexity is treated with respect to the interdependency of parameter estimates, as well as the number of free parameters in the model. We develop and study the performance of ICOMP along with several most popular model selection criteria such as Akaike's information criterion, Schwarz's Bayesian information criterion and generalized cross-validation in MARS modeling to select the best subset models. We provide two Monte Carlo simulation examples and a real benchmark example to demonstrate the utility and versatility of the proposed model selection approach to determine best functional form of the predictive model. Our numerical examples show that ICOMP provides a general model selection criterion with an insight to the interdependencies and/or correlational structure between parameter estimates in the selected model. This new approach can also be applicable to many complex statistical modeling problems.", "paper_title": "Model selection in multivariate adaptive regression splines (MARS) using information complexity as the fitness function", "paper_id": "WOS:000361624700003"}