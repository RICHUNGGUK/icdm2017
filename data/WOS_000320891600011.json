{"auto_keywords": [{"score": 0.049193598318116316, "phrase": "wireless_sensor_networks"}, {"score": 0.004815315858763141, "phrase": "distributed"}, {"score": 0.004681971826924847, "phrase": "reinforcement_learning"}, {"score": 0.004510336430422002, "phrase": "resource-constrained_nodes"}, {"score": 0.004385733482617193, "phrase": "highly_dynamic_and_often_unattended_environments"}, {"score": 0.004050996777117918, "phrase": "scalable_and_dynamic_wsn_applications"}, {"score": 0.003884212965525665, "phrase": "resource_management_framework"}, {"score": 0.003812299519486331, "phrase": "two-tier_reinforcement_learning_scheme"}, {"score": 0.0037592362369401546, "phrase": "autonomous_self-learning_and_adaptive_applications"}, {"score": 0.003672427620845944, "phrase": "efficient_resource_management"}, {"score": 0.003504756881063581, "phrase": "bottom-up_approach"}, {"score": 0.0034559594248079807, "phrase": "sensor_node"}, {"score": 0.0033603864623013733, "phrase": "task_selection"}, {"score": 0.003313592421224647, "phrase": "first_learning_tier"}, {"score": 0.003206916619690171, "phrase": "individual_sensor_nodes"}, {"score": 0.0030178044717552605, "phrase": "timely_adaptation"}, {"score": 0.00297576670831646, "phrase": "second_learning_tier"}, {"score": 0.0027100527874262446, "phrase": "global_application-specific_optimization_goal"}, {"score": 0.00263505298504827, "phrase": "network_lifetime"}, {"score": 0.002479579797152119, "phrase": "target_tracking_application"}, {"score": 0.0021649437083408425, "phrase": "traditional_approaches"}, {"score": 0.0021447748132703078, "phrase": "resource_management"}, {"score": 0.0021049977753042253, "phrase": "application_requirements"}], "paper_keywords": ["Wireless sensor networks", " Resource management", " Task scheduling", " Reinforcement learning", " Target tracking"], "paper_abstract": "In wireless sensor networks (WSNs), resource-constrained nodes are expected to operate in highly dynamic and often unattended environments. Hence, support for intelligent, autonomous, adaptive and distributed resource management is an essential ingredient of a middleware solution for developing scalable and dynamic WSN applications. In this article, we present a resource management framework based on a two-tier reinforcement learning scheme to enable autonomous self-learning and adaptive applications with inherent support for efficient resource management. Our design goal is to build a system with a bottom-up approach where each sensor node is responsible for its resource allocation and task selection. The first learning tier (micro-learning) allows individual sensor nodes to self-schedule their tasks by using only local information, thus enabling a timely adaptation. The second learning tier (macro-learning) governs the micro-learners by tuning their operating parameters so as to guide the system towards a global application-specific optimization goal (e.g., maximizing the network lifetime). The effectiveness of our framework is exemplified by means of a target tracking application built on top of it. Finally, the performance of our scheme is compared against other existing approaches by simulation. We show that our two-tier reinforcement learning scheme is significantly more efficient than traditional approaches to resource management while fulfilling the application requirements.", "paper_title": "Distributed resource management in wireless sensor networks using reinforcement learning", "paper_id": "WOS:000320891600011"}