{"auto_keywords": [{"score": 0.029468551220963573, "phrase": "natural_images"}, {"score": 0.00481495049065317, "phrase": "hierarchical_generative_model"}, {"score": 0.004766683200410046, "phrase": "natural_scene_statistics"}, {"score": 0.004718897469501381, "phrase": "gaussian_scale_mixture_models"}, {"score": 0.00464811139983244, "phrase": "top-down_description"}, {"score": 0.004509694461067052, "phrase": "key_bottom-up_statistical_characteristics"}, {"score": 0.003935892934907777, "phrase": "novel_extension"}, {"score": 0.003876806615011266, "phrase": "gaussian_scale_mixture_model"}, {"score": 0.0037235274565193665, "phrase": "observed_inputs"}, {"score": 0.00363080961099728, "phrase": "hierarchical_representation"}, {"score": 0.0033832583769880576, "phrase": "gaussian_variables"}, {"score": 0.003332440548684892, "phrase": "local_filter_structure"}, {"score": 0.003233075944817365, "phrase": "mixer_variable"}, {"score": 0.0030431198971423937, "phrase": "possible_mixers"}, {"score": 0.0028933521924166287, "phrase": "generative_model"}, {"score": 0.0028498718992429825, "phrase": "synthesized_data"}, {"score": 0.0028070431733705735, "phrase": "different_classes"}, {"score": 0.002709589081384597, "phrase": "generic_ensemble"}, {"score": 0.0025892330566358503, "phrase": "variable_assignments"}, {"score": 0.0025119730908615104, "phrase": "complex_cells"}, {"score": 0.002486734224234698, "phrase": "visual_cortex"}, {"score": 0.0024125253170522816, "phrase": "gaussian_components"}, {"score": 0.002282166507956957, "phrase": "divisive_normalization_models"}, {"score": 0.0021697677572213086, "phrase": "wide_range"}, {"score": 0.0021263705039915198, "phrase": "image_statistics"}, {"score": 0.0021049977753042253, "phrase": "cortical_processing"}], "paper_keywords": [""], "paper_abstract": "Gaussian scale mixture models offer a top-down description of signal generation that captures key bottom-up statistical characteristics of filter responses to images. However, the pattern of dependence among the filters for this class of models is prespecified. We propose a novel extension to the gaussian scale mixture model that learns the pattern of dependence from observed inputs and thereby induces a hierarchical representation of these inputs. Specifically, we propose that inputs are generated by gaussian variables (modeling local filter structure), multiplied by a mixer variable that is assigned probabilistically to each input from a set of possible mixers. We demonstrate inference of both components of the generative model, for synthesized data and for different classes of natural images, such as a generic ensemble and faces. For natural images, the mixer variable assignments show invariances resembling those of complex cells in visual cortex; the statistics of the gaussian components of the model are in accord with the outputs of divisive normalization models. We also show how our model helps interrelate a wide range of models of image statistics and cortical processing.", "paper_title": "Soft mixer assignment in a hierarchical generative model of natural scene statistics", "paper_id": "WOS:000240735600005"}