{"auto_keywords": [{"score": 0.030041686957073252, "phrase": "fastspmm"}, {"score": 0.00481495049065317, "phrase": "sparse_matrix_matrix_product"}, {"score": 0.004470539706227421, "phrase": "wide_range"}, {"score": 0.00442651096522781, "phrase": "scientific_and_technical_applications"}, {"score": 0.004361276005140776, "phrase": "computational_requirements"}, {"score": 0.004130165601475531, "phrase": "large_matrices"}, {"score": 0.0038727120021750973, "phrase": "spmm_product"}, {"score": 0.003815607281455725, "phrase": "computing_environment"}, {"score": 0.0037593414153801394, "phrase": "graphics_processing_units"}, {"score": 0.003577691211998842, "phrase": "matricial_operation"}, {"score": 0.0033050703534275717, "phrase": "existing_approaches"}, {"score": 0.003176626803985225, "phrase": "ellpack-r_storage_format"}, {"score": 0.003038066486989815, "phrase": "spmm_operation"}, {"score": 0.0029344771385297137, "phrase": "compute_unified_device_architecture"}, {"score": 0.0029199689963238726, "phrase": "streaming_computation"}, {"score": 0.0026973310437053573, "phrase": "cusparse_library"}, {"score": 0.002644390364524668, "phrase": "nvidia"}, {"score": 0.0024793019587009035, "phrase": "experimental_evaluations"}, {"score": 0.002394719113232821, "phrase": "test_matrices"}, {"score": 0.0022563639794965095, "phrase": "cusparse"}, {"score": 0.0021049977753042253, "phrase": "sparse_matrix_vector_products"}], "paper_keywords": ["SpMM", " streaming computation", " GPU computing", " matricial operations"], "paper_abstract": "Sparse matrix matrix (SpMM) multiplication is involved in a wide range of scientific and technical applications. The computational requirements for this kind of operation are enormous, especially for large matrices. This paper analyzes and evaluates a method to efficiently compute the SpMM product in a computing environment that includes graphics processing units (GPUs). Some libraries to compute this matricial operation can be found in the literature. However, our strategy (FastSpMM) outperforms the existing approaches because it combines the use of the ELLPACK-R storage format with the exploitation of the high ratio computation/memory access of the SpMM operation and the overlapping of CPU-GPU communications/computations by Compute Unified Device Architecture streaming computation. In this work, FastSpMM is described and its performance evaluated with regard to the CUSPARSE library (supplied by NVIDIA), which also includes routines to compute SpMM on GPUs. Experimental evaluations based on a representative set of test matrices show that, in terms of performance, FastSpMM outperforms the CUSPARSE routine as well as the implementation of the SpMM as a set of sparse matrix vector products.", "paper_title": "FastSpMM: An Efficient Library for Sparse Matrix Matrix Product on GPUs", "paper_id": "WOS:000338648900002"}