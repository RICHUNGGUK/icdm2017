{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "spoken_dialog"}, {"score": 0.04788181103940386, "phrase": "user's_interest"}, {"score": 0.035366979368155665, "phrase": "lexical_information"}, {"score": 0.004769958800452922, "phrase": "decision-level_fusion"}, {"score": 0.004725385523804256, "phrase": "acoustic_and_lexical_evidence"}, {"score": 0.004487541157100498, "phrase": "important_role"}, {"score": 0.004362870617347183, "phrase": "tutoring_systems"}, {"score": 0.00432208488976429, "phrase": "customer_service_systems"}, {"score": 0.004143196873246147, "phrase": "decision-level_fusion_approach"}, {"score": 0.004104456271230213, "phrase": "acoustic_and_lexical_information"}, {"score": 0.003953068310598579, "phrase": "utterance_level"}, {"score": 0.003581620064675766, "phrase": "final_output"}, {"score": 0.003401148484767927, "phrase": "acoustic_model"}, {"score": 0.0032602525602322832, "phrase": "bag-of-words_model"}, {"score": 0.003139903872290182, "phrase": "level-of-interest_value"}, {"score": 0.0025171669791790438, "phrase": "lexical_features"}, {"score": 0.002447101794397243, "phrase": "acoustic_and_lexical_models"}, {"score": 0.0023902026696615473, "phrase": "decision_level"}, {"score": 0.002323663295811215, "phrase": "acoustic_evidence"}, {"score": 0.002280333649167796, "phrase": "level-of-interest_detection_performance"}, {"score": 0.0021857667493036786, "phrase": "asr_output"}, {"score": 0.0021652891317252994, "phrase": "high_word_error_rate"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Level of interest", " Decision-level fusion", " Human machine interaction"], "paper_abstract": "Automatic detection of a user's interest in spoken dialog plays an important role in many applications, such as tutoring systems and customer service systems. In this study, we propose a decision-level fusion approach using acoustic and lexical information to accurately sense a user's interest at the utterance level. Our system consists of three parts: acoustic/prosodic model, lexical model, and a model that combines their decisions for the final output. We use two different regression algorithms to complement each other for the acoustic model. For lexical information, in addition to the bag-of-words model, we propose new features including a level-of-interest value for each word, length information using the number of words, estimated speaking rate, silence in the utterance, and similarity with other utterances. We also investigate the effectiveness of using more automatic speech recognition (ASR) hypotheses (n-best lists) to extract lexical features. The outputs from the acoustic and lexical models are combined at the decision level. Our experiments show that combining acoustic evidence with lexical information improves level-of-interest detection performance, even when lexical features are extracted from ASR output with high word error rate. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Level of interest sensing in spoken dialog using decision-level fusion of acoustic and lexical evidence", "paper_id": "WOS:000329415400005"}