{"auto_keywords": [{"score": 0.004703878334423852, "phrase": "sparse_or_compressible_signals"}, {"score": 0.004406260054779782, "phrase": "n-dimensional_basis"}, {"score": 0.004304574865291508, "phrase": "periodic_samples"}, {"score": 0.004224911726496726, "phrase": "inner_products"}, {"score": 0.003957477564354679, "phrase": "sparsity-seeking_optimization"}, {"score": 0.0038661089070527424, "phrase": "standard_cs"}, {"score": 0.003812299519486331, "phrase": "robust_signal_recovery"}, {"score": 0.0033761303704612734, "phrase": "simple_sparsity"}, {"score": 0.00329813918116714, "phrase": "structural_dependencies"}, {"score": 0.0031770714776989282, "phrase": "signal_coefficients"}, {"score": 0.0030891871245908665, "phrase": "model-based_cs_theory"}, {"score": 0.0030319482153908037, "phrase": "conventional_theory"}, {"score": 0.002989714021608139, "phrase": "concrete_guidelines"}, {"score": 0.0029206231857112305, "phrase": "model-based_recovery_algorithms"}, {"score": 0.0027483472371835865, "phrase": "new_class"}, {"score": 0.002722758109991685, "phrase": "structured_compressible_signals"}, {"score": 0.0026722904884984348, "phrase": "new_sufficient_condition"}, {"score": 0.0026474076254702525, "phrase": "robust_structured_compressible_signal_recovery"}, {"score": 0.0025862068041567934, "phrase": "restricted_amplification_property"}, {"score": 0.0025264171945423254, "phrase": "natural_counterpart"}, {"score": 0.0024912073108138613, "phrase": "restricted_isometry_property"}, {"score": 0.00246800641971897, "phrase": "conventional_cs._two_examples"}, {"score": 0.0021750990136123367, "phrase": "extensive_numerical_simulations"}], "paper_keywords": ["Block sparsity", " compressive sensing", " signal model", " sparsity", " union of subspaces", " wavelet tree"], "paper_abstract": "Compressive sensing (CS) is an alternative to Shannon/Nyquist sampling for the acquisition of sparse or compressible signals that can be well approximated by just K << N elements from an N-dimensional basis. Instead of taking periodic samples, CS measures inner products with M < N random vectors and then recovers the signal via a sparsity-seeking optimization or greedy algorithm. Standard CS dictates that robust signal recovery is possible from M = O(K log(N/K)) measurements. It is possible to substantially decrease M without sacrificing robustness by leveraging more realistic signal models that go beyond simple sparsity and compressibility by including structural dependencies between the values and locations of the signal coefficients. This paper introduces a model-based CS theory that parallels the conventional theory and provides concrete guidelines on how to create model-based recovery algorithms with provable performance guarantees. A highlight is the introduction of a new class of structured compressible signals along with a new sufficient condition for robust structured compressible signal recovery that we dub the restricted amplification property, which is the natural counterpart to the restricted isometry property of conventional CS. Two examples integrate two relevant signal models-wavelet trees and block sparsity-into two state-of-the-art CS recovery algorithms and prove that they offer robust recovery from just M = O(K) measurements. Extensive numerical simulations demonstrate the validity and applicability of our new theory and algorithms.", "paper_title": "Model-Based Compressive Sensing", "paper_id": "WOS:000275999500039"}