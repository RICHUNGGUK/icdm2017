{"auto_keywords": [{"score": 0.004652016085325825, "phrase": "input-restricted_memoryless_channels"}, {"score": 0.004494570360108983, "phrase": "high_snr."}, {"score": 0.004195418010131832, "phrase": "memoryless_channel"}, {"score": 0.0039841418890102925, "phrase": "input_markov_process"}, {"score": 0.0037188360359702182, "phrase": "mixing_finite-type_constraint"}, {"score": 0.003130077012135034, "phrase": "entropy_rate"}, {"score": 0.0029214769181390653, "phrase": "hidden_markov_chain"}, {"score": 0.0026342827320931937, "phrase": "high_signal-to-noise_ratio"}, {"score": 0.0021049977753042253, "phrase": "\"almost\"_all_input_markov_chains"}], "paper_keywords": ["Concavity", " entropy rate", " hidden Markov chain", " mutual information rate"], "paper_abstract": "We consider a memoryless channel with an input Markov process supported on a mixing finite-type constraint. We continue the development of asymptotics for the entropy rate of the output hidden Markov chain and deduce that, at high signal-to-noise ratio, the mutual information rate of such a channel is concave with respect to \"almost\" all input Markov chains of a given order.", "paper_title": "Concavity of the Mutual Information Rate for Input-Restricted Memoryless Channels at High SNR", "paper_id": "WOS:000300845900015"}