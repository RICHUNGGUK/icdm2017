{"auto_keywords": [{"score": 0.037882458018129755, "phrase": "sigma"}, {"score": 0.012353947955327623, "phrase": "input_word"}, {"score": 0.010419574450162969, "phrase": "detection-probability_function_p"}, {"score": 0.00481495049065317, "phrase": "selfish_on-going_behaviors"}, {"score": 0.004780682284581074, "phrase": "rational_and_selfish_environment"}, {"score": 0.00442992128941259, "phrase": "real_behavior"}, {"score": 0.004124395355033225, "phrase": "weighted_automata"}, {"score": 0.004085276767320258, "phrase": "selfish_environments"}, {"score": 0.004008144689408573, "phrase": "successful_formalism"}, {"score": 0.003970124306962642, "phrase": "on-going_interaction"}, {"score": 0.003876637620664603, "phrase": "weighted_finite_automata"}, {"score": 0.0036786145247574547, "phrase": "quantitative_outcome"}, {"score": 0.003280856703386986, "phrase": "possible_false-report"}, {"score": 0.0029190098927559514, "phrase": "minimal_expected_cost"}, {"score": 0.002829878763611803, "phrase": "rational_environment"}, {"score": 0.002763167575414408, "phrase": "basic_problems"}, {"score": 0.002493727601586245, "phrase": "minimum_resources"}, {"score": 0.002218500301413453, "phrase": "general_wfas"}, {"score": 0.0021507128934288335, "phrase": "polynomial-time_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Reactive systems", " Selfish agents", " Weighted automata"], "paper_abstract": "A rational and selfish environment may have an incentive to cheat the system it interacts with. Cheating the system amounts to reporting a stream of inputs that is different from the one corresponding to the real behavior of the environment. The system may cope with cheating by charging penalties to cheats it detects. In this paper, we formalize this setting by means of weighted automata and their resilience to selfish environments. Automata have proven to be a successful formalism for modeling the on-going interaction between a system and its environment. In particular, weighted finite automata (WFAs), which assign a cost to each input word, are useful in modeling an interaction that has a quantitative outcome. Consider a WFA A over the alphabet Sigma. At each moment in time, the environment may cheat A by reporting a letter different from the one it actually generates. A penalty function eta : Sigma x Sigma up arrow R->= 0 maps each possible false-report to a penalty, charged whenever the false-report is detected. A detection-probability function p : Sigma x Sigma -> [0, 1] gives the probability of detecting each false-report. We say that A is (eta, p)-resilient to cheating if <eta, p > ensures that the minimal expected cost of an input word is achieved with no cheating. Thus, a rational environment has no incentive to cheat A. We study the basic problems arising in the analysis of this setting. In particular, we consider the problem of deciding whether a given WFA A is (eta, p)-resilient with respect to a given penalty function eta and a detection-probability function p; and the problem of achieving resilience with minimum resources, namely, given A and eta. finding the minimal (with respect to Sigma(sigma, sigma), eta(sigma, sigma') . p(sigma, sigma')) detection-probability function p, such that A is (eta, p)-resilient. While for general WFAs both problems are shown to be PSPACE-hard, we present polynomial-time algorithms for deterministic WFAs. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "Coping with selfish on-going behaviors", "paper_id": "WOS:000299597500001"}