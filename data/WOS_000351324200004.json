{"auto_keywords": [{"score": 0.04952782290107846, "phrase": "users'_privacy"}, {"score": 0.00468656988857138, "phrase": "web_search_engines"}, {"score": 0.004632597963417253, "phrase": "search_engines"}, {"score": 0.004355026964936104, "phrase": "personalized_search_results"}, {"score": 0.004222515162635615, "phrase": "user's_preferences"}, {"score": 0.0039694170761766226, "phrase": "sensitive_information"}, {"score": 0.003548579306515579, "phrase": "current_proposals"}, {"score": 0.0032216622984027558, "phrase": "new_approach"}, {"score": 0.0030994630902300133, "phrase": "similar_profiles"}, {"score": 0.0029589086332593674, "phrase": "current_schemes"}, {"score": 0.002879872305061576, "phrase": "proposed_system"}, {"score": 0.0027386335451725762, "phrase": "real_data"}, {"score": 0.002707033618304716, "phrase": "aol_dataset"}, {"score": 0.00268616928039386, "phrase": "simulation_results"}, {"score": 0.0025054621733192283, "phrase": "selfish_users"}, {"score": 0.002429090371567499, "phrase": "large_number"}, {"score": 0.002171202123281881, "phrase": "privacy_point"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Web Search Engines", " Profile", " Personalization", " Privacy", " P2P"], "paper_abstract": "Web Search Engines store and analyze queries made by their users in order to build their profiles and offer them personalized search results (i.e., results are ranked according to each user's preferences). Even though this service is positive for the users, their profiles may contain sensitive information that can threaten their privacy. Literature in this field stresses the existence of a trade-off between the level of privacy achieved and the quality of service received. Current proposals try to maximize this trade-off, yet we argue that there is still room for improvement. In this paper, we present a new approach which improves the trade-off by grouping users who share similar profiles. Moreover, our new proposal is based on a hybrid P2P architecture that outperforms current schemes in terms of scalability. The proposed system has been tested in terms of performance and privacy achieved, using real data from the AOL dataset. Simulation results show that: (i) the system protects users' privacy when they behave honestly, and penalizes selfish users; (ii) it supports a large number of users; (iii) the runtime required to group users is affordable; and (iv) groups are dynamic and their topology is unpredictable, which we argue that is positive from the privacy point of view. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Design of a P2P network that protects users' privacy in front of Web Search Engines", "paper_id": "WOS:000351324200004"}