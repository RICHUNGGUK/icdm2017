{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "linear_systems"}, {"score": 0.0403859758180314, "phrase": "first_algorithm"}, {"score": 0.00477513738640734, "phrase": "sparse_triangular_matrices"}, {"score": 0.00446820572467064, "phrase": "shared_memory_architecture"}, {"score": 0.004431246962597134, "phrase": "multilevel_incomplete_lu_factorization_based_preconditioners"}, {"score": 0.004180919839686364, "phrase": "triangular_solves"}, {"score": 0.003799878496075633, "phrase": "triangular_matrix"}, {"score": 0.003482276061796395, "phrase": "appropriate_block_structure"}, {"score": 0.003368367923339972, "phrase": "good_block_partition"}, {"score": 0.003191134522157061, "phrase": "second_algorithm"}, {"score": 0.003151572886432253, "phrase": "hybrid_approach"}, {"score": 0.0030995835539697893, "phrase": "triangular_system"}, {"score": 0.0030739103951333696, "phrase": "block_columns"}, {"score": 0.00288800021194675, "phrase": "block_structure"}, {"score": 0.002816814445002924, "phrase": "nearly_optimal_manner"}, {"score": 0.0027818804382539444, "phrase": "numerical_results"}, {"score": 0.0026135859312619875, "phrase": "strong_diagonal_structure"}, {"score": 0.002591927716261631, "phrase": "narrow_bandwidth"}, {"score": 0.002249961956629804, "phrase": "non-zero_elements"}, {"score": 0.0021049977753042253, "phrase": "distributed_memory_architectures"}], "paper_keywords": ["Preconditioning", " Iterative methods", " Sparse linear systems", " Parallelization"], "paper_abstract": "In this article, we present two new algorithms for solving given triangular systems in parallel on a shared memory architecture. Multilevel incomplete LU factorization based preconditioners, which have been very successful for solving linear systems iteratively, require these triangular solves. Hence, the algorithms presented here can be seen as parallelizing the application of these preconditioners. The first algorithm solves the triangular matrix by block anti-diagonals. The drawback of this approach is that it can be difficult to choose an appropriate block structure. On the other hand, if a good block partition can be found, this algorithm can be quite effective. The second algorithm takes a hybrid approach by solving the triangular system by block columns and anti-diagonals. It is usually as effective as the first algorithm, but the block structure can be chosen in a nearly optimal manner. Although numerical results indicate that the speed-up can be fairly good, systems with matrices having a strong diagonal structure or narrow bandwidth cannot be solved effectively in parallel. Hence, for these matrices, the results are disappointing. On the other hand, the results are better for matrices having a more uniform distribution of non-zero elements. Although not discussed in this article, these algorithms can possibly be adapted for distributed memory architectures.", "paper_title": "Parallel algorithms for solving linear systems with sparse triangular matrices", "paper_id": "WOS:000271501300002"}