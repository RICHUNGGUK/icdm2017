{"auto_keywords": [{"score": 0.04323039047337744, "phrase": "mfa"}, {"score": 0.015441338489137403, "phrase": "factor_analyzers"}, {"score": 0.012073155580699277, "phrase": "vb"}, {"score": 0.009603428717613882, "phrase": "lfa"}, {"score": 0.008660201566610848, "phrase": "lfa."}, {"score": 0.008022619383879666, "phrase": "byy"}, {"score": 0.00481495049065317, "phrase": "local_factor_analysis"}, {"score": 0.00468627326602559, "phrase": "automatic_model_selection"}, {"score": 0.004623224002010226, "phrase": "factor_analysis"}, {"score": 0.004459190343665408, "phrase": "gaussian_mixture_model"}, {"score": 0.004320421465896323, "phrase": "local_dimensionality_reduction"}, {"score": 0.0037219886365287085, "phrase": "variational_bayes"}, {"score": 0.003638823482920949, "phrase": "bayesian_ying-yang"}, {"score": 0.003400274964240732, "phrase": "component_number"}, {"score": 0.0033544692489307676, "phrase": "local_hidden_dimensionalities"}, {"score": 0.0032207283736492083, "phrase": "fa"}, {"score": 0.002955533639862811, "phrase": "alternative_vb_algorithm"}, {"score": 0.002712131567923321, "phrase": "corresponding_byy_algorithms"}, {"score": 0.0026157259734105, "phrase": "wide_range"}, {"score": 0.002592163447843447, "phrase": "synthetic_experiments"}, {"score": 0.002488724764295623, "phrase": "model_selection"}, {"score": 0.0023044434462692483, "phrase": "empirical_findings"}, {"score": 0.002252880693912436, "phrase": "real_applications"}, {"score": 0.002212460584002629, "phrase": "handwritten_digit_images"}, {"score": 0.002162951519368368, "phrase": "unsupervised_image_segmentation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Automatic model selection", " Mixture of factor analyzers", " Local factor analysis", " Variational Bayes", " Bayesian Ying-Yang", " Dirichlet-Normal-Gamma"], "paper_abstract": "Considering Factor Analysis (FA) for each component of Gaussian Mixture Model (GMM), clustering and local dimensionality reduction can be addressed simultaneously by Mixture of Factor Analyzers (MFA) and Local Factor Analysis (LFA), which correspond to two FA parameterizations, respectively. This paper investigates the performance of Variational Bayes (VB) and Bayesian Ying-Yang (BYY) harmony learning on MFA/LFA for the problem of automatically determining the component number and the local hidden dimensionalities (i.e., the number of factors of FA in each component). Similar to the existing VB learning algorithm on MFA, we develop an alternative VB algorithm on LFA with a similar conjugate Dirichlet-Normal-Gamma (DNG) prior on all parameters of LFA. Also, the corresponding BYY algorithms are developed for MFA and LFA. A wide range of synthetic experiments shows that LFA is superior to MFA in model selection under either VB or BYY, while BYY outperforms VB reliably on both MFA and LFA. These empirical findings are consistently observed from real applications on not only face and handwritten digit images clustering, but also unsupervised image segmentation. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Learning local factor analysis versus mixture of factor analyzers with automatic model selection", "paper_id": "WOS:000337661800002"}