{"auto_keywords": [{"score": 0.03248288336480739, "phrase": "privacy_budget"}, {"score": 0.010963987794391493, "phrase": "personalised_differential_privacy"}, {"score": 0.00481495049065317, "phrase": "differential_privacy"}, {"score": 0.004716924994370903, "phrase": "useful_information"}, {"score": 0.0046846932351254636, "phrase": "sensitive_data"}, {"score": 0.004255807517348647, "phrase": "differentially_private_mechanisms"}, {"score": 0.004169117683086526, "phrase": "challenging_task"}, {"score": 0.004042369239448456, "phrase": "new_differential_private_mechanisms"}, {"score": 0.003826441783705964, "phrase": "differentially_private_building_blocks"}, {"score": 0.0037228262889889402, "phrase": "resulting_programs"}, {"score": 0.003536023290715607, "phrase": "new_accounting_principle"}, {"score": 0.00349979888845939, "phrase": "differentially_private_programs"}, {"score": 0.0034167069467881143, "phrase": "simple_generalisation"}, {"score": 0.0033933295645859015, "phrase": "classic_differential_privacy"}, {"score": 0.003278819376393891, "phrase": "pdp"}, {"score": 0.002998776886514782, "phrase": "primitive_query"}, {"score": 0.0028678338651577056, "phrase": "involved_records"}, {"score": 0.002705405787092544, "phrase": "alice"}, {"score": 0.002649978056195926, "phrase": "privacy_decrease"}, {"score": 0.002631832840403278, "phrase": "alice's_budget"}, {"score": 0.002569294946452846, "phrase": "previous_systems"}, {"score": 0.0024069209350505933, "phrase": "global_sensitivity"}, {"score": 0.002317636745271539, "phrase": "live_database"}, {"score": 0.0023017619208704067, "phrase": "new_individuals"}, {"score": 0.002231657123365799, "phrase": "formal_model"}, {"score": 0.002208765537836048, "phrase": "proper_approach"}, {"score": 0.002126816206925344, "phrase": "prototype_implementation"}, {"score": 0.0021049977753042253, "phrase": "mcsherry's_pinq_system"}], "paper_keywords": ["Design", " Languages", " Theory", " differential privacy", " provenance"], "paper_abstract": "Differential privacy provides a way to get useful information about sensitive data without revealing much about any one individual. It enjoys many nice compositionality properties not shared by other approaches to privacy, including, in particular, robustness against side-knowledge. Designing differentially private mechanisms from scratch can be a challenging task. One way to make it easier to construct new differential private mechanisms is to design a system which allows more complex mechanisms (programs) to be built from differentially private building blocks in principled way, so that the resulting programs are guaranteed to be differentially private by construction. This paper is about a new accounting principle for building differentially private programs. It is based on a simple generalisation of classic differential privacy which we call Personalised Differential Privacy (PDP). In PDP each individual has its own personal privacy level. We describe ProPer, a interactive system for implementing PDP which maintains a privacy budget for each individual. When a primitive query is made on data derived from individuals, the provenance of the involved records determines how the privacy budget of an individual is affected: the number of records derived from Alice determines the multiplier for the privacy decrease in Alice's budget. This offers some advantages over previous systems, in particular its fine-grained character allows better utilisation of the privacy budget than mechanisms based purely on the concept of global sensitivity, and it applies naturally to the case of a live database where new individuals are added over time. We provide a formal model of the ProPer approach, prove that it provides personalised differential privacy, and describe a prototype implementation based on McSherry's PINQ system.", "paper_title": "Differential Privacy: Now it's Getting Personal", "paper_id": "WOS:000354800500007"}