{"auto_keywords": [{"score": 0.04705125463422358, "phrase": "es"}, {"score": 0.04493961720435844, "phrase": "global_convergence"}, {"score": 0.034209389283801815, "phrase": "function_values"}, {"score": 0.03265658319333053, "phrase": "step_size"}, {"score": 0.00481495049065317, "phrase": "convergent_evolution_strategies"}, {"score": 0.004590052784169268, "phrase": "large_class"}, {"score": 0.004550300345169981, "phrase": "evolution_strategies"}, {"score": 0.00443308765153716, "phrase": "unconstrained_optimization"}, {"score": 0.00420760449108585, "phrase": "stationary_points"}, {"score": 0.004135010810625326, "phrase": "starting_point"}, {"score": 0.003958937342925219, "phrase": "parent_points"}, {"score": 0.0038737214010638745, "phrase": "weighted_sum"}, {"score": 0.0037903327482565097, "phrase": "offspring_points"}, {"score": 0.0037249113156851013, "phrase": "random_generation"}, {"score": 0.0036288825833675127, "phrase": "covariance_matrix_adaptation"}, {"score": 0.003581870222322018, "phrase": "cma"}, {"score": 0.0032830808525570903, "phrase": "sufficient_decrease_condition"}, {"score": 0.002957222630196853, "phrase": "es's_themselves"}, {"score": 0.002880927789104712, "phrase": "latter_one"}, {"score": 0.002722288966917744, "phrase": "sufficient_decrease"}, {"score": 0.002652039172817654, "phrase": "reasonable_assumptions"}, {"score": 0.0025500402081330394, "phrase": "unit_sphere"}, {"score": 0.0024950747439601863, "phrase": "limited_budget"}, {"score": 0.002473420909291381, "phrase": "function_evaluations"}, {"score": 0.0023990982005125763, "phrase": "modified_cma-es"}, {"score": 0.002151388538895855, "phrase": "underlying_method"}], "paper_keywords": ["Evolution strategy", " Global convergence", " Sufficient decrease", " Covariance matrix adaptation (CMA)"], "paper_abstract": "In this paper we show how to modify a large class of evolution strategies (ES's) for unconstrained optimization to rigorously achieve a form of global convergence, meaning convergence to stationary points independently of the starting point. The type of ES under consideration recombines the parent points by means of a weighted sum, around which the offspring points are computed by random generation. One relevant instance of such an ES is covariance matrix adaptation ES (CMA-ES). The modifications consist essentially of the reduction of the size of the steps whenever a sufficient decrease condition on the function values is not verified. When such a condition is satisfied, the step size can be reset to the step size maintained by the ES's themselves, as long as this latter one is sufficiently large. We suggest a number of ways of imposing sufficient decrease for which global convergence holds under reasonable assumptions (in particular density of certain limit directions in the unit sphere). Given a limited budget of function evaluations, our numerical experiments have shown that the modified CMA-ES is capable of further progress in function values. Moreover, we have observed that such an improvement in efficiency comes without weakening significantly the performance of the underlying method in the presence of several local minimizers.", "paper_title": "Globally convergent evolution strategies", "paper_id": "WOS:000358292600015"}