{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "contextual_tag_inference"}, {"score": 0.004183137595671171, "phrase": "content-based_music_taggers"}, {"score": 0.00304737045343781, "phrase": "conditional_restricted_boltzmann_machine_models"}, {"score": 0.0028652153774536967, "phrase": "related_tags"}, {"score": 0.002600661525224505, "phrase": "training_data"}, {"score": 0.0024236964502593254, "phrase": "support_vector_machines"}], "paper_keywords": ["Experimentation", " Performance", " Autotagging", " clips", " context", " music", " smoothing", " tags"], "paper_abstract": "This article examines the use of two kinds of context to improve the results of content-based music taggers: the relationships between tags and between the clips of songs that are tagged. We show that users agree more on tags applied to clips temporally \"closer\" to one another; that conditional restricted Boltzmann machine models of tags can more accurately predict related tags when they take context into account; and that when training data is \"smoothed\" using context, support vector machines can better rank these clips according to the original, unsmoothed tags and do this more accurately than three standard multi-label classifiers.", "paper_title": "Contextual Tag Inference", "paper_id": "WOS:000297725800013"}