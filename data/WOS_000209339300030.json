{"auto_keywords": [{"score": 0.03566651822244946, "phrase": "simd_lanes"}, {"score": 0.00481495049065317, "phrase": "data-parallel_architectures"}, {"score": 0.0045119929871912405, "phrase": "mobile_systems"}, {"score": 0.004367707617503722, "phrase": "central_challenge"}, {"score": 0.00428733103049275, "phrase": "parallel_resources"}, {"score": 0.004228016636379321, "phrase": "simd_hardware"}, {"score": 0.00418892838079239, "phrase": "real_application_performance"}, {"score": 0.00413096972023037, "phrase": "scientific_applications"}, {"score": 0.004092774981286263, "phrase": "automatic_vectorization_techniques"}, {"score": 0.003961842092184655, "phrase": "large_levels"}, {"score": 0.0039252049353279556, "phrase": "data-level_parallelism"}, {"score": 0.003678023470672862, "phrase": "media_applications"}, {"score": 0.0036271080216837286, "phrase": "low_trip_count_loops"}, {"score": 0.003593555152077465, "phrase": "complex_control_flow"}, {"score": 0.0033051623473192814, "phrase": "insufficient_dlp."}, {"score": 0.0031550351923674337, "phrase": "new_vectorization_pass"}, {"score": 0.003125852779015699, "phrase": "simd"}, {"score": 0.003068242064611088, "phrase": "hidden_dlp"}, {"score": 0.0029288446848334576, "phrase": "instruction-level_parallelism"}, {"score": 0.0026811531172346676, "phrase": "simd_execution"}, {"score": 0.0026440008776012665, "phrase": "simd_degragmenter"}, {"score": 0.0025474193855847074, "phrase": "compatible_instructions"}, {"score": 0.0023210846870653757, "phrase": "subgraph_level"}, {"score": 0.0022155569675462333, "phrase": "experimental_results"}, {"score": 0.0021848422732893926, "phrase": "simd_defragmentation"}, {"score": 0.002134592410214824, "phrase": "traditional_loop_vectorization"}], "paper_keywords": ["Algorithms", " Experimentation", " Performance", " Compiler", " SIMD Architecture", " Optimization"], "paper_abstract": "Single-instruction multiple-data (SIMD) accelerators provide an energy-efficient platform to scale the performance of mobile systems while still retaining post-programmability. The central challenge is translating the parallel resources of the SIMD hardware into real application performance. In scientific applications, automatic vectorization techniques have proven quite effective at extracting large levels of data-level parallelism (DLP). However, vectorization is often much less effective for media applications due to low trip count loops, complex control flow, and non-uniform execution behavior. As a result, SIMD lanes remain idle due to insufficient DLP. To attack this problem, this paper proposes a new vectorization pass called SIMD Defragmenter to uncover hidden DLP that lurks below the surface in the form of instruction-level parallelism (ILP). The difficulty is managing the data packing/unpacking overhead that can easily exceed the benefits gained through SIMD execution. The SIMD degragmenter overcomes this problem by identifying groups of compatible instructions (subgraphs) that can be executed in parallel across the SIMD lanes. By SIMDizing in bulk at the subgraph level, packing/unpacking overhead is minimized. On a 16-lane SIMD processor, experimental results show that SIMD defragmentation achieves a mean 1.6x speedup over traditional loop vectorization and a 31% gain over prior research approaches for converting ILP to DLP.", "paper_title": "SIMD Defragmenter: Efficient ILP Realization on Data-parallel Architectures", "paper_id": "WOS:000209339300030"}