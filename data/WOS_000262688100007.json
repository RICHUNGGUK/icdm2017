{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "ga"}, {"score": 0.04848125038474166, "phrase": "gmm"}, {"score": 0.047704540042202745, "phrase": "automatic_text_summarization"}, {"score": 0.00473445042632846, "phrase": "ffnn"}, {"score": 0.004333283735537634, "phrase": "content_selection"}, {"score": 0.0042250123967577284, "phrase": "statistical_tools"}, {"score": 0.0041194351307673556, "phrase": "trainable_summarizer"}, {"score": 0.003965975628742746, "phrase": "sentence_position"}, {"score": 0.003932654396285872, "phrase": "positive_keyword"}, {"score": 0.003899612025233852, "phrase": "negative_keyword"}, {"score": 0.0038668462001710314, "phrase": "sentence_centrality"}, {"score": 0.0038343546245999285, "phrase": "sentence_resemblance"}, {"score": 0.0037070855410818986, "phrase": "name_entity"}, {"score": 0.0036296886647898094, "phrase": "numerical_data"}, {"score": 0.0034504423179340738, "phrase": "aggregated_similarity"}, {"score": 0.0032387402145603412, "phrase": "cacti_sentence_feature"}, {"score": 0.0031979796189858206, "phrase": "summarization_task"}, {"score": 0.00305285084207725, "phrase": "genetic_algorithm"}, {"score": 0.0028775998963807324, "phrase": "suitable_combination"}, {"score": 0.002853396755102163, "phrase": "feature_weights"}, {"score": 0.002770273247998903, "phrase": "feature_parameters"}, {"score": 0.0026445028886931837, "phrase": "probabilistic_neural_network"}, {"score": 0.0026222637282574453, "phrase": "pnn"}, {"score": 0.002591161121098735, "phrase": "gaussian"}, {"score": 0.002471661547432869, "phrase": "text_summarizer"}, {"score": 0.0023794391656001466, "phrase": "trained_models"}, {"score": 0.0023296961971785357, "phrase": "summarization_performance"}, {"score": 0.0022713722522505592, "phrase": "proposed_approach_performance"}, {"score": 0.0022051664509486206, "phrase": "data_corpus"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Automatic summarization", " Genetic algorithm", " Mathematical regression", " Feed forward neural network", " Probabilistic neural network", " Gaussian mixture model"], "paper_abstract": "This work proposes an approach to address the problem of improving content selection in automatic text summarization by using some statistical tools. This approach is a trainable summarizer, which takes into account several features, including sentence position, positive keyword, negative keyword, sentence centrality, sentence resemblance to the title, sentence inclusion of name entity, sentence inclusion of numerical data, sentence relative length, Bushy path of the sentence and aggregated similarity for each sentence to generate summaries. First, we investigate the effect of cacti sentence feature on the summarization task. Then we use all features in combination to train genetic algorithm (GA) and mathematical regression (MR) models to obtain a suitable combination of feature weights. Moreover, we use all feature parameters to train feed forward neural network (FFNN), probabilistic neural network (PNN) and Gaussian mixture model (GMM) in order to construct a text summarizer for each model. Furthermore, we use trained models by one language to test summarization performance in the other language. The proposed approach performance is measured at several compression rates on a data corpus composed of 100 Arabic political articles and 100 English religious articles. The results of the proposed approach are promising, especially the GMM approach. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "GA, MR, FFNN, PNN and GMM based models for automatic text summarization", "paper_id": "WOS:000262688100007"}