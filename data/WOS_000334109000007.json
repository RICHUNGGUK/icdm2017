{"auto_keywords": [{"score": 0.04074141016787776, "phrase": "jdl"}, {"score": 0.007100927465892277, "phrase": "visually_correlated_categories"}, {"score": 0.00481495049065317, "phrase": "learning_visually"}, {"score": 0.004721711709176679, "phrase": "large-scale_visual_recognition_applications"}, {"score": 0.004562847483469705, "phrase": "content_representation"}, {"score": 0.004496402246090618, "phrase": "critical_role"}, {"score": 0.004452641437293878, "phrase": "visual_recognition"}, {"score": 0.004260906498835763, "phrase": "joint_dictionary_learning"}, {"score": 0.004097389262726735, "phrase": "inter-category_visual_correlations"}, {"score": 0.0037888687452790953, "phrase": "multiple_category-specific_dictionaries"}, {"score": 0.003697287104870263, "phrase": "shared_visual_atoms"}, {"score": 0.0036434002236454305, "phrase": "category-specific_ones"}, {"score": 0.0034693659976716197, "phrase": "joint_optimization"}, {"score": 0.0034187896011435245, "phrase": "discrimination_promotion_term"}, {"score": 0.0033524956061690868, "phrase": "fisher_discrimination_criterion"}, {"score": 0.003303617297414837, "phrase": "visual_tree_method"}, {"score": 0.0032079813320482304, "phrase": "large_number"}, {"score": 0.003099888654615187, "phrase": "disjoint_groups"}, {"score": 0.002966230968271199, "phrase": "reasonable_number"}, {"score": 0.0028662606272282926, "phrase": "image_category_clustering"}, {"score": 0.0027969169552386, "phrase": "better_dictionaries"}, {"score": 0.0026243534128245886, "phrase": "strong_visual_correlations"}, {"score": 0.002474505516708906, "phrase": "large-scale_applications"}, {"score": 0.002391067964886602, "phrase": "full_use"}, {"score": 0.00229914226836813, "phrase": "visual_content_representation"}, {"score": 0.0022434880661725493, "phrase": "image_categorization"}, {"score": 0.0021784745589727246, "phrase": "proposed_algorithms"}], "paper_keywords": ["Joint dictionary learning", " common visual atoms", " category-specific visual atoms", " visual tree", " large-scale visual recognition"], "paper_abstract": "Learning discriminative dictionaries for image content representation plays a critical role in visual recognition. In this paper, we present a joint dictionary learning (JDL) algorithm which exploits the inter-category visual correlations to learn more discriminative dictionaries. Given a group of visually correlated categories, JDL simultaneously learns one common dictionary and multiple category-specific dictionaries to explicitly separate the shared visual atoms from the category-specific ones. The problem of JDL is formulated as a joint optimization with a discrimination promotion term according to the Fisher discrimination criterion. A visual tree method is developed to cluster a large number of categories into a set of disjoint groups, so that each of them contains a reasonable number of visually correlated categories. The process of image category clustering helps JDL to learn better dictionaries for classification by ensuring that the categories in the same group are of strong visual correlations. Also, it makes JDL to be computationally affordable in large-scale applications. Three classification schemes are adopted to make full use of the dictionaries learned by JDL for visual content representation in the task of image categorization. The effectiveness of the proposed algorithms has been evaluated using two image databases containing 17 and 1,000 categories, respectively.", "paper_title": "Jointly Learning Visually Correlated Dictionaries for Large-Scale Visual Recognition Applications", "paper_id": "WOS:000334109000007"}