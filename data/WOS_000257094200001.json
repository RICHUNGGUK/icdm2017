{"auto_keywords": [{"score": 0.041843926397594905, "phrase": "genetic_algorithm"}, {"score": 0.00481495049065317, "phrase": "automatic_voice_query_transcription"}, {"score": 0.004640472497133447, "phrase": "efficient_music_retrieval_systems"}, {"score": 0.004297948502679085, "phrase": "reliable_query_source"}, {"score": 0.004273601449537163, "phrase": "elaborate_signal_processing_and_acoustic_similarity_measurement_schemes"}, {"score": 0.004095323392273661, "phrase": "increased_interest"}, {"score": 0.004072119477195683, "phrase": "query_reformulation"}, {"score": 0.004049046499912914, "phrase": "relevance_feedback"}, {"score": 0.00402610372759447, "phrase": "evolutionary_techniques"}, {"score": 0.00396931167065037, "phrase": "multimedia_information_retrieval"}, {"score": 0.003803678911024785, "phrase": "music_retrieval"}, {"score": 0.003707623127692214, "phrase": "novel_music_retrieval_system"}, {"score": 0.003552871243410983, "phrase": "sung_or_hummed_query"}, {"score": 0.003423969509052361, "phrase": "improved_accuracy"}, {"score": 0.003404556450666522, "phrase": "music_representation"}, {"score": 0.003108455203728626, "phrase": "acoustic_signal"}, {"score": 0.002995687244869055, "phrase": "ae"}, {"score": 0.002970177327299509, "phrase": "small_but_coherent_windows"}, {"score": 0.002953329533402266, "phrase": "local_and_global_threshold_values"}, {"score": 0.0028707999970792836, "phrase": "af"}, {"score": 0.002782079283183827, "phrase": "absolute_values"}, {"score": 0.0027662954811372175, "phrase": "signal_differences"}, {"score": 0.002742787059497186, "phrase": "clustering_energy_contour"}, {"score": 0.002696366237523415, "phrase": "user_query"}, {"score": 0.0026658551560513662, "phrase": "user_relevance_feedback"}, {"score": 0.002620732961022912, "phrase": "retrieval_performance"}, {"score": 0.0025112322629187787, "phrase": "musemble"}, {"score": 0.0024969812322112174, "phrase": "versatile_query"}, {"score": 0.0024062957362867453, "phrase": "extensive_experiments"}, {"score": 0.002385839330752606, "phrase": "prototype_system"}, {"score": 0.002332133125576037, "phrase": "genetic_algorithm-based_relevance_feedback_schemes"}, {"score": 0.0022796331061797916, "phrase": "retrieval_accuracy"}, {"score": 0.002184353189568121, "phrase": "dynamic_adf"}, {"score": 0.002159623311924437, "phrase": "transcription_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["genetic algorithm", " multimedia database", " music retrieval", " pitch tracking", " relevance feedback", " signal processing"], "paper_abstract": "So far, many researches have been done to develop efficient music retrieval systems, and query-by-humming has been considered as one of the most intuitive and effective query methods for music retrieval. For the voice humming to be a reliable query source, elaborate signal processing and acoustic similarity measurement schemes are necessary. On the other hand, recently, there has been an increased interest in query reformulation using relevance feedback with evolutionary techniques such as genetic algorithm for multimedia information retrieval. However, these techniques have not been exploited widely in the field of music retrieval. In this paper, we develop a novel music retrieval system called MUSEMBLE (MUSic enEMBLE) based on two distinct features: (i) A sung or hummed query is automatically transcribed into a sequence of pitch and duration pairs with improved accuracy for music representation. More specifically, we developed two new and unique techniques called WAE (windowed average energy) and dynamic ADF (amplitude-based difference function) onsets for more accurate note segmentation and onset/offset detection in acoustic signal, respectively. The former improved energy-based approaches such as AE by defining small but coherent windows with local and global threshold values. On the other hand, the latter improved the AF (amplitude function) that calculates the summation of the absolute values of signal differences for the clustering energy contour. (ii) A user query is reformulated using user relevance feedback with a genetic algorithm to improve retrieval performance. Even though we have especially focused on humming queries in this paper, MUSEMBLE provides versatile query and browsing interfaces for various kinds of users. We have carried out extensive experiments on the prototype system to evaluate the performance of our voice query transcription and genetic algorithm-based relevance feedback schemes. We demonstrate that our proposed method improves the retrieval accuracy up to 20-40%, compared with other popular RF methods. We also show that both WAE and Dynamic ADF methods improve the transcription accuracy up to 95%. (c) 2007 Elsevier Inc. All rights reserved.", "paper_title": "MUSEMBLE: A novel music retrieval system with automatic voice query transcription and reformulation", "paper_id": "WOS:000257094200001"}