{"auto_keywords": [{"score": 0.040876478468159366, "phrase": "resource_reciprocation"}, {"score": 0.012156057191113909, "phrase": "optimal_strategies"}, {"score": 0.010943170684048806, "phrase": "foresighted_decisions"}, {"score": 0.00481495049065317, "phrase": "foresighted_resource_reciprocation"}, {"score": 0.00457457085958402, "phrase": "multimedia_content"}, {"score": 0.00448179813172021, "phrase": "shared_resources"}, {"score": 0.004243460284890507, "phrase": "autonomous_and_self-interested_peers"}, {"score": 0.0038170129089059013, "phrase": "stochastic_game"}, {"score": 0.003516417950483685, "phrase": "myopic_decisions"}, {"score": 0.003152052338320169, "phrase": "mdp"}, {"score": 0.0030879936732269293, "phrase": "novel_algorithm"}, {"score": 0.0030460403366412126, "phrase": "state_transition"}, {"score": 0.003014948673771347, "phrase": "representative_resource_reciprocation_models"}, {"score": 0.00293357578778008, "phrase": "peers'_different_attitudes"}, {"score": 0.002825251837733693, "phrase": "true_and_estimated_state_transition_probability_impacts"}, {"score": 0.0027116246112603875, "phrase": "resulting_utilities"}, {"score": 0.0025584115892805384, "phrase": "reciprocation_history"}, {"score": 0.002532284627202572, "phrase": "limited_number"}, {"score": 0.002515014676664348, "phrase": "state_descriptions"}, {"score": 0.002422108787774162, "phrase": "resulting_resource_reciprocation"}, {"score": 0.0024055884143050037, "phrase": "simulation_results"}, {"score": 0.0023728841359713106, "phrase": "proposed_approach"}, {"score": 0.0023486473525617794, "phrase": "reciprocation_models"}, {"score": 0.002300912218086077, "phrase": "dynamically_changing_environment"}, {"score": 0.002141334979696276, "phrase": "best_performance"}, {"score": 0.0021049977753042253, "phrase": "cumulative_expected_utilities"}], "paper_keywords": ["Bounded rationality", " foresighted decision", " Markov decision process", " peer-to-peer (P2P) network", " resource reciprocation game"], "paper_abstract": "We consider peer-to-peer (P2P) networks, where multiple peers are interested in sharing multimedia content. In such P2P networks, the shared resources are the peers' contributed content and their upload bandwidth. While sharing resources, autonomous and self-interested peers need to make decisions on the amount of their resource reciprocation (i.e., representing their actions) such that their individual utilities are maximized. We model the resource reciprocation among the peers as a stochastic game and show how the peers can determine optimal strategies for resource reciprocation using a Markov Decision Process (MDP) framework. Unlike existing resource reciprocation strategies, which focus on myopic decisions of peers, the optimal strategies determined based on MDP enable the peers to make foresighted decisions about resource reciprocation, such that they can explicitly consider both their immediate as well as future expected utilities. To successfully formulate the MDP framework, we propose a novel algorithm that identifies the state transition probabilities using representative resource reciprocation models of peers. These models express the peers' different attitudes toward resource reciprocation. We analytically investigate how the error between the true and estimated state transition probability impacts each peer's decisions for selecting its actions as well as the resulting utilities. Moreover, we also analytically study how bounded rationality (e.g., limited memory for reciprocation history and the limited number of state descriptions) can impact the interactions among the peers and the resulting resource reciprocation. Simulation results show that the proposed approach based on reciprocation models can effectively cope with a dynamically changing environment such as peers' joining or leaving P2P networks. Moreover, we show that the propose foresighted decisions lead to the best performance in terms of the cumulative expected utilities.", "paper_title": "A Framework for Foresighted Resource Reciprocation in P2P Networks", "paper_id": "WOS:000262714700009"}