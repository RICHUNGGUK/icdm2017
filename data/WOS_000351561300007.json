{"auto_keywords": [{"score": 0.04334863831976788, "phrase": "main_memory"}, {"score": 0.03678902168567898, "phrase": "secondary_storage"}, {"score": 0.0349322668245239, "phrase": "relationship_matrix"}, {"score": 0.00481495049065317, "phrase": "big-data_gwas."}, {"score": 0.0046993598473345395, "phrase": "complex_traits"}, {"score": 0.004653900688892822, "phrase": "genetic_polymorphisms"}, {"score": 0.004608879242346434, "phrase": "genome-wide_association_studies"}, {"score": 0.004101281992566145, "phrase": "contemporary_computers"}, {"score": 0.00323134923196813, "phrase": "large_populations"}, {"score": 0.00312310128226407, "phrase": "combined_main_memory"}, {"score": 0.0030778231027679464, "phrase": "distributed_architecture"}, {"score": 0.0029602552900111407, "phrase": "distributed_resources"}, {"score": 0.002919073317408295, "phrase": "cloud"}, {"score": 0.002778682854371595, "phrase": "genotype_and_phenotype_data"}, {"score": 0.002685558057339722, "phrase": "double-buffering_technique"}, {"score": 0.0025331002386232014, "phrase": "distributed_memory_system"}, {"score": 0.002400944221804575, "phrase": "separate_algorithms"}, {"score": 0.002135995282374723, "phrase": "enormous_datasets"}], "paper_keywords": ["Genome-wide association study", " Mixed-models", " Generalized least squares", " Big data", " Distributed memory", " Omics"], "paper_abstract": "In order to associate complex traits with genetic polymorphisms, genome-wide association studies process huge datasets involving tens of thousands of individuals genotyped for millions of polymorphisms. When handling these datasets, which exceed the main memory of contemporary computers, one faces two distinct challenges: (1) millions of polymorphisms and thousands of phenotypes come at the cost of hundreds of gigabytes of data, which can only be kept in secondary storage; (2) the relatedness of the test population is represented by a relationship matrix, which, for large populations, can only fit in the combined main memory of a distributed architecture. In this paper, by using distributed resources such as Cloud or clusters, we address both challenges: the genotype and phenotype data is streamed from secondary storage using the double-buffering technique, while the relationship matrix is kept across the main memory of a distributed memory system. With the help of these solutions, we develop separate algorithms for studies involving only one or a multitude of traits. We show that these algorithms sustain high-performance and allow the analysis of enormous datasets. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "High performance solutions for big-data GWAS", "paper_id": "WOS:000351561300007"}