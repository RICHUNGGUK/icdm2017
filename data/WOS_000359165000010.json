{"auto_keywords": [{"score": 0.035395086221830935, "phrase": "candidate_feature"}, {"score": 0.004817860389586586, "phrase": "multi"}, {"score": 0.004539005582217309, "phrase": "different_labels"}, {"score": 0.004421471944783611, "phrase": "traditional_supervised_feature_selection"}, {"score": 0.004363846362238565, "phrase": "multi-label_feature_selection"}, {"score": 0.0042508289538799905, "phrase": "important_role"}, {"score": 0.004195418010131832, "phrase": "data_mining"}, {"score": 0.004140726362519362, "phrase": "information_retrieval"}, {"score": 0.00406001734835979, "phrase": "machine_learning"}, {"score": 0.003752550907120244, "phrase": "multi-label_feature"}, {"score": 0.003631390978147703, "phrase": "feature_redundancy"}, {"score": 0.0031429517477457925, "phrase": "information_overlap"}, {"score": 0.003021502415143067, "phrase": "selected_features"}, {"score": 0.0028480459059007468, "phrase": "evaluation_measure"}, {"score": 0.0027924625350414655, "phrase": "mutual_information"}, {"score": 0.00270221723573854, "phrase": "min-redundancy_algorithm"}, {"score": 0.0025807396931129926, "phrase": "superior_feature_subset"}, {"score": 0.002547043222086858, "phrase": "multi-label_learning"}, {"score": 0.0024325244760735566, "phrase": "proposed_method"}, {"score": 0.0023538840032613535, "phrase": "good_feature_subset"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Feature selection", " Multi-label learning", " Mutual information", " Max-dependency and min-redundancy"], "paper_abstract": "Multi-label learning deals with data belonging to different labels simultaneously. Like traditional supervised feature selection, multi-label feature selection also plays an important role in data mining, information retrieval, and machine learning. In this paper, we first consider the two factors of multi-label feature, feature dependency and feature redundancy. In particular, dependency implies the degree to which a candidate feature contributes to each label, and redundancy represents the information overlap between the candidate feature and the selected features under all labels. We then propose an evaluation measure that combines mutual information with a max-dependency and min-redundancy algorithm, which allows us to select superior feature subset for multi-label learning. Extensive experiments show that the proposed method can effectively select a good feature subset, and outperform some state-of-the-art approaches. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Multi-label feature selection based on max-dependency and min-redundancy", "paper_id": "WOS:000359165000010"}