{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "patch-based_appearance_model"}, {"score": 0.00445293569103488, "phrase": "tracker_drift"}, {"score": 0.004403480614319231, "phrase": "occlusion_problem"}, {"score": 0.00428222231579898, "phrase": "robust_visual_tracking_algorithm"}, {"score": 0.004211069233133584, "phrase": "patch-based_adaptive_appearance_model"}, {"score": 0.00400459716272594, "phrase": "human_visual_mechanisms"}, {"score": 0.0034630606658026595, "phrase": "confidence_map"}, {"score": 0.003311604528903634, "phrase": "confidence_maps"}, {"score": 0.003220315882881027, "phrase": "robust_estimator"}, {"score": 0.0030282147475402736, "phrase": "local_spatial_co-occurrence"}, {"score": 0.0028795712616923462, "phrase": "local_context_background_model"}, {"score": 0.0028316582436089064, "phrase": "interested_object"}, {"score": 0.0027690086059100495, "phrase": "single_camera"}, {"score": 0.002574788013427524, "phrase": "local_background_estimation"}, {"score": 0.0024620842899061614, "phrase": "possible_occlusions"}, {"score": 0.0023281003994670714, "phrase": "qualitative_and_quantitative_experimental_results"}, {"score": 0.0022137465420508785, "phrase": "proposed_method"}, {"score": 0.002189105604712615, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual tracking", " Background estimation", " Context-awareness"], "paper_abstract": "In this paper, to simultaneously address the tracker drift and occlusion problem, we propose a robust visual tracking algorithm via a patch-based adaptive appearance model driven by local background estimation. Inspired by human visual mechanisms (i.e., context-awareness and attentional selection), an object is represented with a patch-based appearance model, in which each patch outputs a confidence map during the tracking. Then, these confidence maps are combined via a robust estimator to finally get more robust and accurate tracking results. Moreover, we present a local spatial co-occurrence based background modeling approach to automatically estimate the local context background model of an interested object captured from a single camera, which may be stationary or moving. Finally, we utilize local background estimation to provide supervision to an analysis of possible occlusions and the adaption of patch-based appearance model of an object. Qualitative and quantitative experimental results on challenging videos demonstrate the robustness of the proposed method. Crown Copyright (C) 2013 Published by Elsevier B.V. All rights reserved.", "paper_title": "Robust tracking via patch-based appearance model and local background estimation", "paper_id": "WOS:000326909600035"}