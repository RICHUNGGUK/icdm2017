{"auto_keywords": [{"score": 0.04255058048967938, "phrase": "quantum_parallelism"}, {"score": 0.039279164506438924, "phrase": "eigen_state"}, {"score": 0.03230929858177126, "phrase": "probability_amplitude"}, {"score": 0.004828914602826593, "phrase": "quantum"}, {"score": 0.0046650615456476155, "phrase": "machine_learning"}, {"score": 0.004573748810476845, "phrase": "unknown_probabilistic_environments"}, {"score": 0.0045198174374297285, "phrase": "new_representations"}, {"score": 0.004484215355348556, "phrase": "computation_mechanisms"}, {"score": 0.004225950334493496, "phrase": "reinforcement_learning"}, {"score": 0.004192754820265881, "phrase": "rl"}, {"score": 0.0040943214728975845, "phrase": "state_superposition_principle"}, {"score": 0.003966776222128288, "phrase": "value-updating_algorithm"}, {"score": 0.003812896124654341, "phrase": "traditional_rl"}, {"score": 0.003650488931770814, "phrase": "qrl."}, {"score": 0.0034811680446852054, "phrase": "quantum_superposition_state"}, {"score": 0.0032675209435107273, "phrase": "simulated_quantum_state"}, {"score": 0.0032161835102640372, "phrase": "collapse_postulate"}, {"score": 0.003190817088774159, "phrase": "quantum_measurement"}, {"score": 0.003115908199991072, "phrase": "eigen_action"}, {"score": 0.002913052619634697, "phrase": "related_characteristics"}, {"score": 0.002627985415362773, "phrase": "good_tradeoff"}, {"score": 0.0023990989148919978, "phrase": "qrl"}, {"score": 0.0022517100995552443, "phrase": "qrl_algorithm"}, {"score": 0.0022250978492127163, "phrase": "complex_problems"}, {"score": 0.002164216680934624, "phrase": "effective_exploration"}, {"score": 0.00212175050242788, "phrase": "quantum_computation"}, {"score": 0.0021049977753042253, "phrase": "artificial_intelligence"}], "paper_keywords": ["collapse", " Grover iteration", " probability amplitude", " quantum reinforcement learning (QRL)", " state superposition"], "paper_abstract": "The key approaches for machine learning, particularly learning in unknown probabilistic environments, are new representations and computation mechanisms. In this paper, a novel quantum reinforcement learning (QRL) method is proposed by combining quantum theory and reinforcement learning (RL). inspired by the state superposition principle and quantum parallelism, a framework of a value-updating algorithm is introduced. The state (action) in traditional RL is identified as the eigen state (eigen action) in QRL. The state (action) set can be represented with a quantum superposition state, and the eigen state (eigen action) can be obtained by randomly observing the simulated quantum state according to the collapse postulate of quantum measurement. The probability of the eigen action is determined by the probability amplitude, which is updated in parallel according to rewards. Some related characteristics of QRL such as convergence, optimality, and balancing between exploration and exploitation are also analyzed, which shows that this approach makes a good tradeoff between exploration and exploitation using the probability amplitude and can speedup learning through the quantum parallelism. To evaluate the performance and practicability of QRL, several simulated experiments are given, and the results demonstrate the effectiveness and superiority of the QRL algorithm for some complex problems. This paper is also an effective exploration on the application of quantum computation to artificial intelligence.", "paper_title": "Quantum reinforcement learning", "paper_id": "WOS:000259191900003"}