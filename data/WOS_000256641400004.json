{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "max-sum_classifiers"}, {"score": 0.019646531955428276, "phrase": "max-sum_classifier"}, {"score": 0.007413564187281155, "phrase": "observable_variables"}, {"score": 0.007241056212559411, "phrase": "quality_functions"}, {"score": 0.004278807087784626, "phrase": "map_assignments"}, {"score": 0.004228577663320847, "phrase": "random_markov_field"}, {"score": 0.004178935413340453, "phrase": "particular_example"}, {"score": 0.003986103192038901, "phrase": "challenging_problem"}, {"score": 0.0038476319156841784, "phrase": "np"}, {"score": 0.0036987521452843987, "phrase": "maximum_likelihood_approach"}, {"score": 0.003541923233726252, "phrase": "acyclic_structure"}, {"score": 0.0035141291835319682, "phrase": "neighbouring_pairs"}, {"score": 0.003445591238183763, "phrase": "discriminative_methods"}, {"score": 0.003260690513595527, "phrase": "binary_linear_classifiers"}, {"score": 0.0030374213037172803, "phrase": "acyclic_neighbouring_structure"}, {"score": 0.002943147037670826, "phrase": "discriminative_learning"}, {"score": 0.0028857130140890787, "phrase": "arbitrary_neighbouring_structure"}, {"score": 0.00281826552772148, "phrase": "additional_constraints"}, {"score": 0.0027200305495826797, "phrase": "discriminative_approach"}, {"score": 0.0026459927476753585, "phrase": "arbitrary_neighbourhood_structure"}, {"score": 0.0024842242921857705, "phrase": "polynomial_time"}, {"score": 0.0023787690061742566, "phrase": "supermodular_quality_functions"}, {"score": 0.002242127152093798, "phrase": "linear_programming_relaxation"}, {"score": 0.0021724831184390192, "phrase": "learning_problem"}, {"score": 0.0021049977753042253, "phrase": "general_max-sum"}], "paper_keywords": ["max-xum classifier", " hidden Markov networks", " support vector machines"], "paper_abstract": "The max-sum classifier predicts n-tuple of labels from n-tuple of observable variables by maximizing a sum of quality functions defined over neighbouring pairs of labels and observable variables. Predicting labels as MAP assignments of a Random Markov Field is a particular example of the max-sum classifier. Learning parameters of the max-sum classifier is a challenging problem because even computing the response of such classifier is NP-complete in general. Estimating parameters using the Maximum Likelihood approach is feasible only for a subclass of max-sum classifiers with an acyclic structure of neighbouring pairs. Recently, the discriminative methods represented by the perceptron and the Support Vector Machines, originally designed for binary linear classifiers, have been extended for learning some subclasses of the max-sum classifier. Besides the max-sum classifiers with the acyclic neighbouring structure, it has been shown that the discriminative learning is possible even with arbitrary neighbouring structure provided the quality functions fulfill some additional constraints. In this article, we extend the discriminative approach to other three classes of max-sum classifiers with an arbitrary neighbourhood structure. We derive learning algorithms for two subclasses of max-sum classifiers whose response can be computed in polynomial time: (i) the max-sum classifiers with supermodular quality functions and (ii) the max-sum classifiers whose response can be computed exactly by a linear programming relaxation. Moreover, we show that the learning problem can be approximately solved even for a general max-sum classifier.", "paper_title": "Discriminative learning of max-sum classifiers", "paper_id": "WOS:000256641400004"}