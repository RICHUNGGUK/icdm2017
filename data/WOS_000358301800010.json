{"auto_keywords": [{"score": 0.033734452966208577, "phrase": "heart_rate"}, {"score": 0.028755275121255128, "phrase": "cart"}, {"score": 0.025205140717179844, "phrase": "highest_accuracies"}, {"score": 0.00481495049065317, "phrase": "decision_support"}, {"score": 0.0047588556219929756, "phrase": "emotion_elicitation"}, {"score": 0.004567596860086148, "phrase": "standardized_stimuli_sets"}, {"score": 0.004461761855323898, "phrase": "international_affective_picture_systems"}, {"score": 0.00440976345264104, "phrase": "international_affective_digital_sound"}, {"score": 0.00408617426304956, "phrase": "financial_decision"}, {"score": 0.003676811616723809, "phrase": "private_investors"}, {"score": 0.0036126731589251906, "phrase": "controlled_trading_experiment"}, {"score": 0.0033277936960179892, "phrase": "trading_outcomes"}, {"score": 0.0032697235411641695, "phrase": "physiological_measurements"}, {"score": 0.0032315723330399375, "phrase": "skin_conductance_response"}, {"score": 0.0026624684547385718, "phrase": "random_forest_algorithms"}, {"score": 0.002615977783510631, "phrase": "different_window_lengths"}, {"score": 0.0025254115243261875, "phrase": "window_lengths"}, {"score": 0.002326068563512387, "phrase": "labeling_methods"}, {"score": 0.00224551648748308, "phrase": "binary_rejoice"}, {"score": 0.0021049977753042253, "phrase": "tetrastate_blended_emotion_models"}], "paper_keywords": ["Emotion recognition", " multimodal sensors", " user behavior"], "paper_abstract": "Emotion elicitation and classification have been performed on standardized stimuli sets, such as international affective picture systems and international affective digital sound. However, the literature which elicits and classifies emotions in a financial decision making context is scarce. In this paper, we present an evaluation to detect emotions of private investors through a controlled trading experiment. Subjects reported their level of \"rejoice\" and \"regret\" based on trading outcomes, and physiological measurements of skin conductance response and heart rate were obtained. To detect emotions, three labeling methods, namely binary, tri-, and tetrastate \"blended\" models were compared by means of C4.5, CART, and random forest algorithms, across different window lengths for heart rate. Taking moving window lengths of 2.5 s prior to and 0.3 s postevent (parasympathetic phase) led to the highest accuracies. Comparing labeling methods, accuracies were 67% for binary rejoice, 44% for a tristate, and 45% for a tetrastate blended emotion models. The CART yielded the highest accuracies.", "paper_title": "Blended Emotion Detection for Decision Support", "paper_id": "WOS:000358301800010"}