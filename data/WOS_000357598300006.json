{"auto_keywords": [{"score": 0.0465247817138105, "phrase": "mocap_data"}, {"score": 0.00481495049065317, "phrase": "human_motion_capture"}, {"score": 0.004668957916795845, "phrase": "widely_used_technique"}, {"score": 0.004597622380240611, "phrase": "human_movements"}, {"score": 0.004527371799277529, "phrase": "growing_usage"}, {"score": 0.004390060342250211, "phrase": "increasing_attention"}, {"score": 0.004322967486451877, "phrase": "compact_data_size"}, {"score": 0.004278807087784626, "phrase": "efficient_storage"}, {"score": 0.004064653055162238, "phrase": "unique_characteristics"}, {"score": 0.0037632749713937637, "phrase": "video_compression_techniques"}, {"score": 0.00368673793612343, "phrase": "discrete_cosine_transform"}, {"score": 0.0034308688638878286, "phrase": "novel_mocap-tailored_transform_coding_algorithm"}, {"score": 0.0032423089921154503, "phrase": "input_mocap_sequences"}, {"score": 0.002986329509791943, "phrase": "data-dependent_orthogonal_bases"}, {"score": 0.0028076592725295646, "phrase": "transform_coefficients"}, {"score": 0.0027789349951704177, "phrase": "significantly_less_dependency"}, {"score": 0.0026532596852754525, "phrase": "entropy_coding"}, {"score": 0.0026126405272417783, "phrase": "quantized_coefficients"}, {"score": 0.0025202582748972122, "phrase": "low_computational_cost"}, {"score": 0.0024186620196958867, "phrase": "mocap_databases"}, {"score": 0.0023331227492950422, "phrase": "complicated_parameter"}, {"score": 0.0022973933270056743, "phrase": "experimental_results"}, {"score": 0.002250601866422547, "phrase": "proposed_scheme"}, {"score": 0.0021049977753042253, "phrase": "compression_performance"}], "paper_keywords": ["Motion capture", " transform coding", " data compression", " optimization"], "paper_abstract": "Human motion capture (mocap) is a widely used technique for digitalizing human movements. With growing usage, compressing mocap data has received increasing attention, since compact data size enables efficient storage and transmission. Our analysis shows that mocap data have some unique characteristics that distinguish themselves from images and videos. Therefore, directly borrowing image or video compression techniques, such as discrete cosine transform, does not work well. In this paper, we propose a novel mocap-tailored transform coding algorithm that takes advantage of these features. Our algorithm segments the input mocap sequences into clips, which are represented in 2D matrices. Then it computes a set of data-dependent orthogonal bases to transform the matrices to frequency domain, in which the transform coefficients have significantly less dependency. Finally, the compression is obtained by entropy coding of the quantized coefficients and the bases. Our method has low computational cost and can be easily extended to compress mocap databases. It also requires neither training nor complicated parameter setting. Experimental results demonstrate that the proposed scheme significantly outperforms state-of-the-art algorithms in terms of compression performance and speed.", "paper_title": "Human Motion Capture Data Tailored Transform Coding", "paper_id": "WOS:000357598300006"}