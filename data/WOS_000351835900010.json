{"auto_keywords": [{"score": 0.04522176534199055, "phrase": "navigation_behaviors"}, {"score": 0.014912758063254096, "phrase": "rc"}, {"score": 0.010407792486748479, "phrase": "multiple_behaviors"}, {"score": 0.00481495049065317, "phrase": "learning_navigation_behaviors"}, {"score": 0.004763895422211728, "phrase": "small_mobile_robots_with_reservoir_computing_architectures"}, {"score": 0.004613940521007727, "phrase": "general_reservoir_computing"}, {"score": 0.0042820680211904235, "phrase": "mobile_robots"}, {"score": 0.004236639288852276, "phrase": "simple_and_complex_unknown_partially_observable_environments"}, {"score": 0.004038076978795421, "phrase": "recurrent_neural_networks"}, {"score": 0.003952828685048176, "phrase": "recurrent_part"}, {"score": 0.003629392214109574, "phrase": "proposed_rc_framework"}, {"score": 0.0035150223642728437, "phrase": "navigation_attractor"}, {"score": 0.00335016692413066, "phrase": "high-dimensional_space"}, {"score": 0.0030923570058383355, "phrase": "dynamic_robot_behavior"}, {"score": 0.003010893527930816, "phrase": "sensory-motor_sequence"}, {"score": 0.002884979280317279, "phrase": "high-dimensional_nonlinear_space"}, {"score": 0.0026486862281576086, "phrase": "first_approach"}, {"score": 0.002431699464104896, "phrase": "second_approach"}, {"score": 0.002405853977978678, "phrase": "goal-directed_navigation_behaviors"}, {"score": 0.002317533977770783, "phrase": "third_approach"}, {"score": 0.0022928991183989115, "phrase": "complex_goal-directed_behaviors"}, {"score": 0.0022444104439449737, "phrase": "supervised_way"}, {"score": 0.002196944917134202, "phrase": "hierarchical_architecture"}, {"score": 0.0021620042653528846, "phrase": "contextual_switches"}, {"score": 0.0021049977753042253, "phrase": "basic_navigation_behaviors"}], "paper_keywords": ["Echo state network (ESN)", " goal-directed navigation", " recurrent neural networks (RNNs)", " reinforcement learning (RL)", " reservoir computing (RC)", " robot navigation", " sensory-motor coupling"], "paper_abstract": "This paper proposes a general reservoir computing (RC) learning framework that can be used to learn navigation behaviors for mobile robots in simple and complex unknown partially observable environments. RC provides an efficient way to train recurrent neural networks by letting the recurrent part of the network (called reservoir) be fixed while only a linear readout output layer is trained. The proposed RC framework builds upon the notion of navigation attractor or behavior that can be embedded in the high-dimensional space of the reservoir after learning. The learning of multiple behaviors is possible because the dynamic robot behavior, consisting of a sensory-motor sequence, can be linearly discriminated in the high-dimensional nonlinear space of the dynamic reservoir. Three learning approaches for navigation behaviors are shown in this paper. The first approach learns multiple behaviors based on the examples of navigation behaviors generated by a supervisor, while the second approach learns goal-directed navigation behaviors based only on rewards. The third approach learns complex goal-directed behaviors, in a supervised way, using a hierarchical architecture whose internal predictions of contextual switches guide the sequence of basic navigation behaviors toward the goal.", "paper_title": "On Learning Navigation Behaviors for Small Mobile Robots With Reservoir Computing Architectures", "paper_id": "WOS:000351835900010"}