{"auto_keywords": [{"score": 0.025675923378322106, "phrase": "frgc"}, {"score": 0.00481495049065317, "phrase": "single_training_image"}, {"score": 0.004653900688892822, "phrase": "current_face_recognition_techniques"}, {"score": 0.004542158659382197, "phrase": "large_size"}, {"score": 0.00443308765153716, "phrase": "training_sets"}, {"score": 0.004326624385772596, "phrase": "degraded_performance"}, {"score": 0.0040027552011993005, "phrase": "\"one_sample_problem"}, {"score": 0.003925633992809873, "phrase": "challenging_issue"}, {"score": 0.0038876302202924644, "phrase": "face_recognition"}, {"score": 0.003721098220825489, "phrase": "novel_feature_extraction_method"}, {"score": 0.0035443861412929006, "phrase": "underlying_idea"}, {"score": 0.0031536550157613974, "phrase": "recognition_error"}, {"score": 0.003092842645798083, "phrase": "close_class_prototypes"}, {"score": 0.0029747028229638625, "phrase": "pairwise_distances"}, {"score": 0.0029458777184930896, "phrase": "different_class_prototypes"}, {"score": 0.0028195727965553367, "phrase": "whitened_pca_space"}, {"score": 0.002778682854371595, "phrase": "low_dimensional_projections"}, {"score": 0.002725081358527507, "phrase": "local_confusion"}, {"score": 0.002685558057339722, "phrase": "similar_faces"}, {"score": 0.002659527314613792, "phrase": "resulting_low_dimensional_transformed_features"}, {"score": 0.00259554612218815, "phrase": "complex_image_variations"}, {"score": 0.00247215300812495, "phrase": "standardized_procedure"}, {"score": 0.002436289099444074, "phrase": "large-scale_feret"}, {"score": 0.0022101055924375725, "phrase": "proposed_up_method"}, {"score": 0.0021569129153653777, "phrase": "state-of-the-art_one_sample_based_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd"}], "paper_keywords": ["Face recognition", " One sample problem", " Principal component analysis", " Whitening transformation", " Uniform pursuit"], "paper_abstract": "Current face recognition techniques rely heavily on the large size and representativeness of the training sets, and most methods suffer degraded performance or fail to work if there is only one training sample per person available This so-called \"one sample problem\" is a challenging issue in face recognition. In this paper, we propose a novel feature extraction method named uniform pursuit to address the one sample problem. The underlying idea is that most recognition errors are due to the confusions between faces that look very similar, and thus one can reduce the risk of recognition error by mapping the close class prototypes to be distant, i e., uniforming the pairwise distances between different class prototypes Specifically, the UP method pursues, in the whitened PCA space, the low dimensional projections that reduce the local confusion between the similar faces The resulting low dimensional transformed features are robust against the complex image variations such as those caused by lighting and aging A standardized procedure on the large-scale FERET and FRGC databases is applied to evaluate the one sample problem Experimental results show that the robustness, accuracy and efficiency of the proposed UP method compare favorably to the state-of-the-art one sample based methods (C) 2009 Elsevier Ltd All rights reserved", "paper_title": "Robust, accurate and efficient face recognition from a single training image: A uniform pursuit approach", "paper_id": "WOS:000275615800003"}