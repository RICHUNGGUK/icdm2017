{"auto_keywords": [{"score": 0.04952525101149597, "phrase": "digital"}, {"score": 0.00481495049065317, "phrase": "high-speed_video_streams"}, {"score": 0.0045959609346817535, "phrase": "discrete_sampling"}, {"score": 0.004542780650208743, "phrase": "real-world_imagery"}, {"score": 0.004464156619275582, "phrase": "spatial_sampling_effects"}, {"score": 0.004067152645111547, "phrase": "temporal_sampling"}, {"score": 0.003792657064634775, "phrase": "conventional_frame-rate_video"}, {"score": 0.003662410853488772, "phrase": "human_perception"}, {"score": 0.003415137969569376, "phrase": "controlled_temporal_sampling_behavior"}, {"score": 0.0033170847930578473, "phrase": "high_fps_input_stream"}, {"score": 0.003259604990188875, "phrase": "conventional_speed_output_video"}, {"score": 0.003093054709625219, "phrase": "different_temporal_sampling_kernels"}, {"score": 0.0029867619862229853, "phrase": "overlapping_kernels"}, {"score": 0.0029349892964423197, "phrase": "aliasing_artifacts"}, {"score": 0.002867348342846275, "phrase": "npr_effects"}, {"score": 0.00280126189041041, "phrase": "enhanced_motion_blur"}, {"score": 0.0026736111900632934, "phrase": "fourier_transforms"}, {"score": 0.0026272523687965615, "phrase": "temporal_domain"}, {"score": 0.002536926192232391, "phrase": "novel_tools"}, {"score": 0.0024640253074497114, "phrase": "time_dependent_effects"}, {"score": 0.002351705899181029, "phrase": "contemporary_and_idealized_display_devices"}, {"score": 0.0022708315711029423, "phrase": "different_sampling_kernels"}, {"score": 0.002231441081806766, "phrase": "enhanced_movies"}, {"score": 0.0021799789348982516, "phrase": "fast_motion"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Computational videography", " Real-time", " Sampling", " Temporal filtering"], "paper_abstract": "Digital movie cameras only perform a discrete sampling of real-world imagery. While spatial sampling effects are well studied in the literature, there has not been as much work in regards to temporal sampling. As cameras get faster and faster, the need for conventional frame-rate video that matches the abilities of human perception remains. In this article, we introduce a system with controlled temporal sampling behavior. It transforms a high fps input stream into a conventional speed output video in real-time. We investigate the effect of different temporal sampling kernels and demonstrate that extended, overlapping kernels can mitigate aliasing artifacts. Furthermore, NPR effects, such as enhanced motion blur, can be achieved. By applying Fourier transforms in the temporal domain, we can also obtain novel tools for analyzing and visualizing time dependent effects. We study the properties of both contemporary and idealized display devices and demonstrate the effect of different sampling kernels in creating enhanced movies and stills of fast motion. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Real-time temporal shaping of high-speed video streams", "paper_id": "WOS:000282529400012"}