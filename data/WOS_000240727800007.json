{"auto_keywords": [{"score": 0.049485717468789034, "phrase": "word_confusion_networks"}, {"score": 0.04909475946343088, "phrase": "spoken_language_understanding"}, {"score": 0.03757432921561726, "phrase": "asr"}, {"score": 0.030102374282455203, "phrase": "named_entity_detection"}, {"score": 0.004543046350523362, "phrase": "robust_understanding"}, {"score": 0.004505471345843642, "phrase": "noisy_spontaneous_speech_input"}, {"score": 0.004394592555435104, "phrase": "automated_speech_recognition"}, {"score": 0.004061088450663783, "phrase": "large_vocabulary"}, {"score": 0.00402748353567517, "phrase": "language_understanding"}, {"score": 0.00396110232316167, "phrase": "asr_errors"}, {"score": 0.003928321515373316, "phrase": "state_of_the_art_spoken_language_understanding"}, {"score": 0.003600022318864217, "phrase": "tighter_integration"}, {"score": 0.0035406620265705587, "phrase": "slu"}, {"score": 0.0033964919992320024, "phrase": "asr_word_graphs"}, {"score": 0.0033128141572497704, "phrase": "compact_representation"}, {"score": 0.003191134522157061, "phrase": "word_confidence_scores"}, {"score": 0.00313849462329633, "phrase": "recognition_accuracy"}, {"score": 0.0029857124153761187, "phrase": "asr_one-best_hypotheses"}, {"score": 0.0027473784878300133, "phrase": "spoken_dialog_system"}, {"score": 0.002486292595645607, "phrase": "word_lattices"}, {"score": 0.002259346051668556, "phrase": "real-life_applications"}, {"score": 0.002167235986623239, "phrase": "relative_reduction"}, {"score": 0.0021492686054379755, "phrase": "error_rate"}], "paper_keywords": [""], "paper_abstract": "We are interested in the problem of robust understanding from noisy spontaneous speech input. With the advances in automated speech recognition (ASR), there has been increasing interest in spoken language understanding (SLU). A challenge in large vocabulary spoken language understanding is robustness to ASR errors. State of the art spoken language understanding relies on the best ASR hypotheses (ASR 1-best). In this,paper, we propose methods for a tighter integration of ASR and SLU using word confusion networks (WCNs). WCNs obtained from ASR word graphs (lattices) provide a compact representation of multiple aligned. ASR hypotheses along with word confidence scores, without compromising recognition accuracy. We present our work on exploiting WCNs instead of simply using ASR one-best hypotheses. In this work, we focus on the tasks of named entity detection and extraction and call classification in a spoken dialog system, although the idea is more general and applicable to other spoken language processing tasks. For named entity detection, we have improved the F-measure by using both word lattices and WCNs, 6-10% absolute. The processing of WCNs was 25 times faster than lattices, which is very important for real-life applications. For call classification, we have shown between 5% and 10% relative reduction in error rate using WCNs compared to ASR 1-best output. (c) 2005 Elsevier Ltd. All rights reserved.", "paper_title": "Beyond ASR 1-best: Using word confusion networks in spoken language understanding", "paper_id": "WOS:000240727800007"}