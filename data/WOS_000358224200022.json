{"auto_keywords": [{"score": 0.0485324803193334, "phrase": "linear_regression"}, {"score": 0.030161824991677605, "phrase": "sc_algorithms"}, {"score": 0.004608730887154718, "phrase": "support_vector_regression"}, {"score": 0.004459857205489101, "phrase": "popular_function_estimation_technique"}, {"score": 0.004387225575447685, "phrase": "vapnik's_concept"}, {"score": 0.004339459955098738, "phrase": "support_vector_machine"}, {"score": 0.0040192915527630995, "phrase": "useful_features"}, {"score": 0.003868142906199082, "phrase": "sparse_coding"}, {"score": 0.0035630518377071916, "phrase": "efficient_algorithms"}, {"score": 0.0031932442564773468, "phrase": "close_connection"}, {"score": 0.0030229485340586473, "phrase": "typical_algorithms"}, {"score": 0.0027996401456881806, "phrase": "newton_linear_programming_algorithm"}, {"score": 0.002388043660169452, "phrase": "high_efficiency"}, {"score": 0.00221153232497724, "phrase": "orthogonal_matching_pursuit"}, {"score": 0.0021049977753042253, "phrase": "well-known_rbf_network"}], "paper_keywords": ["Newton linear programming (NLP)", " radial basis function (RBF) neural network", " regression", " sparse coding (SC)", " support vector machine (SVM)"], "paper_abstract": "Support vector regression (SVR) is a popular function estimation technique based on Vapnik's concept of support vector machine. Among many variants, the l(1)-norm SVR is known to be good at selecting useful features when the features are redundant. Sparse coding (SC) is a technique widely used in many areas and a number of efficient algorithms are available. Both l(1)-norm SVR and SC can be used for linear regression. In this brief, the close connection between the l(1)-norm SVR and SC is revealed and some typical algorithms are compared for linear regression. The results show that the SC algorithms outperform the Newton linear programming algorithm, an efficient l(1)-norm SVR algorithm, in efficiency. The algorithms are then used to design the radial basis function (RBF) neural networks. Experiments on some benchmark data sets demonstrate the high efficiency of the SC algorithms. In particular, one of the SC algorithms, the orthogonal matching pursuit is two orders of magnitude faster than a well-known RBF network designing algorithm, the orthogonal least squares algorithm.", "paper_title": "Comparison of l(1)-Norm SVR and Sparse Coding Algorithms for Linear Regression", "paper_id": "WOS:000358224200022"}