{"auto_keywords": [{"score": 0.029777538630542333, "phrase": "correct_words"}, {"score": 0.00481495049065317, "phrase": "high_precision_optical_character_recognition"}, {"score": 0.004367707617503722, "phrase": "high_precision"}, {"score": 0.004267468074128779, "phrase": "relatively_low_recall"}, {"score": 0.0034785371344994197, "phrase": "correctly_translated_document_words"}, {"score": 0.0033986345279488476, "phrase": "\"clean_set"}, {"score": 0.0033051623473192814, "phrase": "document-specific_training_data"}, {"score": 0.0032594177686868556, "phrase": "ocr"}, {"score": 0.00321425262806329, "phrase": "confidence_measures"}, {"score": 0.0029838294169759663, "phrase": "significant_number"}, {"score": 0.0028882701690741467, "phrase": "novel_technique"}, {"score": 0.0027188259793109264, "phrase": "posterior_probabilities"}, {"score": 0.0025592969422491476, "phrase": "approximate_worst_case_analysis"}, {"score": 0.0025121156016001864, "phrase": "empirical_results"}, {"score": 0.0024772998651215964, "phrase": "data_set"}, {"score": 0.0024543571925896073, "phrase": "difficult_historical_newspaper_scans"}, {"score": 0.0022995854132747233, "phrase": "document-specific_character_models"}, {"score": 0.0021545524633190985, "phrase": "properly_segmented_characters"}], "paper_keywords": ["optical character recognition", " probability bounding", " document-specific modeling", " computer vision"], "paper_abstract": "We consider a model for which it is important, early in processing, to estimate some variables with high precision, but perhaps at relatively low recall. If some variables can be identified with near certainty, they can be conditioned upon, allowing further inference to be done efficiently. Specifically, we consider optical character recognition (OCR) systems that can be bootstrapped by identifying a subset of correctly translated document words with very high precision. This \"clean set\" is subsequently used as document-specific training data. While OCR systems produce confidence measures for the identity of each letter or word, thresholding these values still produces a significant number of errors. We introduce a novel technique for identifying a set of correct words with very high precision. Rather than estimating posterior probabilities, we bound the probability that any given word is incorrect using an approximate worst case analysis. We give empirical results on a data set of difficult historical newspaper scans, demonstrating that our method for identifying correct words makes only two errors in 56 documents. Using document-specific character models generated from this data, we are able to reduce the error over properly segmented characters by 34.1% from an initial OCR system's translation.(1)", "paper_title": "Bounding the Probability of Error for High Precision Optical Character Recognition", "paper_id": "WOS:000303046000005"}