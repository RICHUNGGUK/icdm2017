{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "nonnegative_low-rank"}, {"score": 0.014833257252423187, "phrase": "good_graph"}, {"score": 0.004768104290288521, "phrase": "sparse_graph"}, {"score": 0.004721711709176679, "phrase": "data-adaptive_features"}, {"score": 0.004452641437293878, "phrase": "intrinsic_data_structures"}, {"score": 0.004387793971765289, "phrase": "semisupervised_learning_setting"}, {"score": 0.003661275004971829, "phrase": "sparse_reconstruction_coefficients_matrix"}, {"score": 0.0035902958977673313, "phrase": "data_sample"}, {"score": 0.0035379628447303703, "phrase": "linear_combination"}, {"score": 0.0034524248924699985, "phrase": "so-obtained_nnlrs-graph"}, {"score": 0.0033361232750221863, "phrase": "subspaces_structure"}, {"score": 0.0032079813320482304, "phrase": "locally_linear_structure"}, {"score": 0.0028944757265206332, "phrase": "good_features"}, {"score": 0.002511147886053878, "phrase": "nnlrs"}, {"score": 0.0024866599295898517, "phrase": "embedded_features"}, {"score": 0.0024264778000639485, "phrase": "nnlrs-ef"}, {"score": 0.002391067964886602, "phrase": "extensive_nnlrs_experiments"}, {"score": 0.002321787726770895, "phrase": "proposed_method"}, {"score": 0.002287902310873394, "phrase": "state-of-the-art_graph_construction_method"}, {"score": 0.0021784745589727246, "phrase": "discriminative_analysis"}], "paper_keywords": ["Graph Construction", " low-rank and sparse representation", " semi-supervised learning", " data embedding"], "paper_abstract": "This paper aims at constructing a good graph to discover the intrinsic data structures under a semisupervised learning setting. First, we propose to build a nonnegative low-rank and sparse (referred to as NNLRS) graph for the given data representation. In particular, the weights of edges in the graph are obtained by seeking a nonnegative low-rank and sparse reconstruction coefficients matrix that represents each data sample as a linear combination of others. The so-obtained NNLRS-graph captures both the global mixture of subspaces structure (by the low-rankness) and the locally linear structure (by the sparseness) of the data, hence it is both generative and discriminative. Second, as good features are extremely important for constructing a good graph, we propose to learn the data embedding matrix and construct the graph simultaneously within one framework, which is termed as NNLRS with embedded features (referred to as NNLRS-EF). Extensive NNLRS experiments on three publicly available data sets demonstrate that the proposed method outperforms the state-of-the-art graph construction method by a large margin for both semisupervised classification and discriminative analysis, which verifies the effectiveness of our proposed method.", "paper_title": "Constructing a Nonnegative Low-Rank and Sparse Graph With Data-Adaptive Features", "paper_id": "WOS:000358615500004"}