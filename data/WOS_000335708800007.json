{"auto_keywords": [{"score": 0.047358918256261213, "phrase": "annealed_cooperative-competitive_learning"}, {"score": 0.00481495049065317, "phrase": "mahalanobis-nrbf_neural_modules"}, {"score": 0.004735254735115024, "phrase": "nonlinear_and_chaotic_differential_function_approximation"}, {"score": 0.0043560464825349275, "phrase": "mahalanobis_normalized_radial_basis_functions"}, {"score": 0.004283913685201902, "phrase": "nrbf"}, {"score": 0.004108742905942481, "phrase": "nonlinear_function_approximation"}, {"score": 0.004040688646993605, "phrase": "chaotic_differential_function_approximation"}, {"score": 0.003940706575253453, "phrase": "multilayer_neural_network"}, {"score": 0.0037168948492715386, "phrase": "multiple_mahalanobis-nrbf_modules"}, {"score": 0.0035648266669315943, "phrase": "normalized_outputs"}, {"score": 0.003505749731180509, "phrase": "radial_basis_functions"}, {"score": 0.003418958653159371, "phrase": "mahalanobis_radial_distances"}, {"score": 0.0032517484445814334, "phrase": "essential_cooperative_scheme"}, {"score": 0.0031186510842824626, "phrase": "multi-module_network"}, {"score": 0.0029909851863915283, "phrase": "individual_modules"}, {"score": 0.002941389980674657, "phrase": "adaptable_network_interconnections"}, {"score": 0.0028926147550022607, "phrase": "asynchronously_updated_module"}, {"score": 0.0026164433143193015, "phrase": "physical-like_mean-field_annealing_process"}, {"score": 0.0023864566654035924, "phrase": "multi-module_mahalanobis-nrbf_network"}, {"score": 0.0022696277881969896, "phrase": "long_term"}, {"score": 0.0022507188208913394, "phrase": "look-ahead_prediction"}, {"score": 0.0022133711375320244, "phrase": "chaotic_time_series"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multilayer neural networks", " Free energy function", " Mixed integer programming", " Mean field annealing", " Long term prediction", " Chaotic time series"], "paper_abstract": "This work explores annealed cooperative-competitive learning of multiple modules of Mahalanobis normalized radial basis functions (NRBF) with applications to nonlinear function approximation and chaotic differential function approximation. A multilayer neural network is extended to be composed of multiple Mahalanobis-NRBF modules. Each module activates normalized outputs of radial basis functions, determining Mahalanobis radial distances based on its own adaptable weight matrix. An essential cooperative scheme well decomposes learning a multi-module network to sub-tasks of learning individual modules. Adaptable network interconnections are asynchronously updated module-by-module based on annealed cooperative-competitive learning for function approximation under a physical-like mean-field annealing process. Numerical simulations show outstanding performance of annealed cooperative-competitive learning of a multi-module Mahalanobis-NRBF network for nonlinear function approximation and long term look-ahead prediction of chaotic time series. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Annealed cooperative-competitive learning of Mahalanobis-NRBF neural modules for nonlinear and chaotic differential function approximation", "paper_id": "WOS:000335708800007"}