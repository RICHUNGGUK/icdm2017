{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "probabilistic_logical_models"}, {"score": 0.004690305164360866, "phrase": "relational_data"}, {"score": 0.00433531459712787, "phrase": "complex_relational_structure"}, {"score": 0.0036553070575015344, "phrase": "traditional_machine_learning_algorithms"}, {"score": 0.0031636612155559267, "phrase": "so-called_probabilistic_logical_models"}, {"score": 0.0028857130140890787, "phrase": "first-order_logic"}, {"score": 0.00270221723573854, "phrase": "corresponding_learning_algorithms"}], "paper_keywords": ["Probabilistic logic learning", " Bayesian networks", " decision trees"], "paper_abstract": "Data that has a complex relational structure and in which observations are noisy or partially missing poses several challenges to traditional machine learning algorithms. One solution to this problem is the use of so-called probabilistic logical models (models that combine elements of first-order logic with probabilities) and corresponding learning algorithms. In this thesis we focus on directed probabilistic logical models. We show how to represent such models and develop several algorithms to learn such models from data.", "paper_title": "Learning directed probabilistic logical models from relational data", "paper_id": "WOS:000262452100006"}