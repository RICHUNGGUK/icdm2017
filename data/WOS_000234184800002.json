{"auto_keywords": [{"score": 0.04274518365190484, "phrase": "proposed_system"}, {"score": 0.03596176205294266, "phrase": "voice_code"}, {"score": 0.00481495049065317, "phrase": "models-based_text-prompted_speaker_independent_verification_algorithm"}, {"score": 0.004556901872357751, "phrase": "text-prompted_speaker_independent_verification_algorithm"}, {"score": 0.004138010495069077, "phrase": "user_entrance_authentication"}, {"score": 0.004025531820226182, "phrase": "text-prompted_speaker"}, {"score": 0.003809628721278519, "phrase": "speaker_dependent_model"}, {"score": 0.0037747835341722636, "phrase": "extra_trained_model"}, {"score": 0.0037231102027070724, "phrase": "alternative_hypothesis"}, {"score": 0.003689053436223376, "phrase": "log-likelihood_ratio_test"}, {"score": 0.003349670229755675, "phrase": "security_reasoning"}, {"score": 0.0033037970113095577, "phrase": "targeting_domain"}, {"score": 0.0030414140732789186, "phrase": "log-likelihood_normalization"}, {"score": 0.002985988377995789, "phrase": "acoustic_model"}, {"score": 0.002931569771634119, "phrase": "voice_code_model"}, {"score": 0.002878140062594849, "phrase": "automatic_production_rules"}, {"score": 0.002799810685137358, "phrase": "initial_time"}, {"score": 0.002748775748298028, "phrase": "statistical_distance"}, {"score": 0.002613163083407071, "phrase": "two-pass_strategy"}, {"score": 0.00257735013358606, "phrase": "schmm-based_recognition"}, {"score": 0.002472822097373027, "phrase": "harmonics-based_spectral_subtraction_algorithm"}, {"score": 0.00241658945942583, "phrase": "noisy_robustness"}, {"score": 0.0023834640793589414, "phrase": "outdoor_environment"}, {"score": 0.0023507916951658455, "phrase": "performance_evaluation"}, {"score": 0.002286781334850213, "phrase": "common_korean_database"}, {"score": 0.002163930783583212, "phrase": "silent_environment"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["utterance verification", " LRT", " voice code verification"], "paper_abstract": "In this paper, we propose competing models based on text-prompted speaker independent verification algorithm for an intelligent surveillance guard robot, wherein a robot prompts a code (i.e. word or phrase) for user entrance authentication. The proposed system requires the text-prompted speaker independent verification. In addition, it does not require a speaker dependent model and extra trained model as an alternative hypothesis for log-likelihood ratio test because of memory limitation. This is due to the given application scenario that an administrator changes the voice code every day for security reasoning and the targeting domain is unlimited. To resolve these issues, we propose to exploit the sub-word based anti-models for log-likelihood normalization through reusing an acoustic model and competing with voice code model. Anti-models using automatic production rules are set up in an initial time by using the statistical distance of phonemes against a voice code. The proposed system uses a two-pass strategy using a SCHMM-based recognition and verification step. In addition, a harmonics-based spectral subtraction algorithm is applied for a noisy robustness on an outdoor environment. The performance evaluation is done by using a common Korean database, PBW452DB, which consists of 63,280 utterances of 452 isolated words recorded in silent environment. (c) 2005 Elsevier B.V. All rights reserved.", "paper_title": "Competing models-based text-prompted speaker independent verification algorithm", "paper_id": "WOS:000234184800002"}