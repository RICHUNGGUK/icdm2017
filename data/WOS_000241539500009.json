{"auto_keywords": [{"score": 0.042389058155836386, "phrase": "translation_model"}, {"score": 0.012803639601309353, "phrase": "parsimonious_translation_model"}, {"score": 0.009838900562761032, "phrase": "query_model"}, {"score": 0.008640669843316549, "phrase": "term_co-occurrence_statistics"}, {"score": 0.00481495049065317, "phrase": "information_retrieval"}, {"score": 0.0047113960612140335, "phrase": "kl_divergence_framework"}, {"score": 0.004635187610736025, "phrase": "extended_language_modeling_approach"}, {"score": 0.00456020621016909, "phrase": "critical_problem"}, {"score": 0.004342430078306461, "phrase": "probabilistic_model"}, {"score": 0.0042489946866108895, "phrase": "user's_information"}, {"score": 0.004157561334726201, "phrase": "query_expansion"}, {"score": 0.004112582094962078, "phrase": "initial_retrieval"}, {"score": 0.003531474887552889, "phrase": "offline_time"}, {"score": 0.0034366728236876047, "phrase": "large_collection"}, {"score": 0.0033262524445013303, "phrase": "co-occurrences_statistics"}, {"score": 0.003236941658990869, "phrase": "space_complexity"}, {"score": 0.0031500213134140953, "phrase": "reliable_retrieval_performance"}, {"score": 0.0029830992938695007, "phrase": "noisy_non-topical_terms"}, {"score": 0.002779217021776702, "phrase": "effective_method"}, {"score": 0.0027341763737751467, "phrase": "co-occurrence_statistics"}, {"score": 0.0026898636962522505, "phrase": "noisy_terms"}, {"score": 0.0025472634689904772, "phrase": "compact_version"}, {"score": 0.002386062690026682, "phrase": "non-zero_probabilities"}, {"score": 0.002347378595930709, "phrase": "non-topical_terms"}, {"score": 0.0022595316565074304, "phrase": "seven_different_test_collections"}], "paper_keywords": ["information retrieval", " language model", " parsimonious translation model", " query expansion"], "paper_abstract": "In the KL divergence framework, the extended language modeling approach has a critical problem of estimating a query model, which is the probabilistic model that encodes the user's information need. For query expansion in initial retrieval, the translation model had been proposed to involve term co-occurrence statistics. However, the translation model was difficult to apply, because the term co-occurrence statistics must be constructed in the offline time. Especially in a large collection, constructing such a large matrix of term co-occurrences statistics prohibitively increases time and space complexity. In addition, reliable retrieval performance cannot be guaranteed because the translation model may comprise noisy non-topical terms in documents. To resolve these problems, this paper investigates an effective method to construct co-occurrence statistics and eliminate noisy terms by employing a parsimonious translation model. The parsimonious translation model is a compact version of a translation model that can reduce the number of terms containing non-zero probabilities by eliminating non-topical terms in documents. Through experimentation on seven different test collections, we show that the query model estimated from the parsimonious translation model significantly outperforms not only the baseline language modeling, but also the non-parsimonious models. (c) 2006 Elsevier Ltd. All rights reserved.", "paper_title": "Parsimonious translation models for information retrieval", "paper_id": "WOS:000241539500009"}