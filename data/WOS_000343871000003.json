{"auto_keywords": [{"score": 0.04720712072096041, "phrase": "computer_animation"}, {"score": 0.00468656988857138, "phrase": "forthcoming_action"}, {"score": 0.004614745158543967, "phrase": "efficient_and_smooth_transitions"}, {"score": 0.00445712058827745, "phrase": "motion_graphs"}, {"score": 0.004094018760244776, "phrase": "new_method"}, {"score": 0.004046843083499649, "phrase": "preparation_behaviors"}, {"score": 0.004015693806064219, "phrase": "reinforcement_learning"}, {"score": 0.003954109842050071, "phrase": "offline_process"}, {"score": 0.0038634933357842302, "phrase": "optimal_way"}, {"score": 0.0036884198249734863, "phrase": "scalar_value"}, {"score": 0.0034538466642399976, "phrase": "initial_action"}, {"score": 0.0034140224493254935, "phrase": "interacting_action"}, {"score": 0.0032592499906265882, "phrase": "customized_motion_blending_scheme"}, {"score": 0.0030994630902300133, "phrase": "optimization_framework"}, {"score": 0.0029361086955646625, "phrase": "trained_controller"}, {"score": 0.0028138046006772567, "phrase": "appropriate_level"}, {"score": 0.0027386335451725762, "phrase": "humanlike_behavior"}, {"score": 0.0025942468561537682, "phrase": "complex_environment"}, {"score": 0.0023188652648490874, "phrase": "real-time_applications"}, {"score": 0.002292097733181405, "phrase": "computer_games"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["preparation behavior", " motion synthesis", " reinforcement learning", " motion blending", " posture optimization"], "paper_abstract": "Humans adjust their movements in advance to prepare for the forthcoming action, resulting in efficient and smooth transitions. However, traditional computer animation approaches such as motion graphs simply concatenate a series of actions without taking into account the following one. In this paper, we propose a new method to produce preparation behaviors using reinforcement learning. As an offline process, the system learns the optimal way to approach a target and to prepare for interaction. A scalar value called the level of preparation is introduced, which represents the degree of transition from the initial action to the interacting action. To synthesize the movements of preparation, we propose a customized motion blending scheme based on the level of preparation, which is followed by an optimization framework that adjusts the posture to keep the balance. During runtime, the trained controller drives the character to move to a target with the appropriate level of preparation, resulting in a humanlike behavior. We create scenes in which the character has to move in a complex environment and to interact with objects, such as crawling under and jumping over obstacles while walking. The method is useful not only for computer animation but also for real-time applications such as computer games, in which the characters need to accomplish a series of tasks in a given environment. Copyright (c) 2013 John Wiley & Sons, Ltd.", "paper_title": "Natural preparation behavior synthesis", "paper_id": "WOS:000343871000003"}