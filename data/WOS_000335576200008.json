{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "probabilistic_hierarchical_task_networks"}, {"score": 0.039108224572764555, "phrase": "user_preferences"}, {"score": 0.034406625716344015, "phrase": "preferred_plans"}, {"score": 0.03198563340320762, "phrase": "feasibility_constraints"}, {"score": 0.004780633011300165, "phrase": "probabilistic_context-free_grammars_to_capture_user_preferences"}, {"score": 0.004514714250357749, "phrase": "user's_preferences"}, {"score": 0.0043560464825349275, "phrase": "common_choice"}, {"score": 0.003954837422946628, "phrase": "prior_work"}, {"score": 0.003856971411867688, "phrase": "domain_physics"}, {"score": 0.003829455440282146, "phrase": "search_control"}, {"score": 0.0036292245355184576, "phrase": "htn_learning"}, {"score": 0.003603327452846714, "phrase": "additional_information"}, {"score": 0.0034890505116128606, "phrase": "learning_process"}, {"score": 0.0031448288291084, "phrase": "accurate_representation"}, {"score": 0.0031223774204093713, "phrase": "user_preference"}, {"score": 0.0029169007179202164, "phrase": "prevalent_perspective"}, {"score": 0.0028446460307503343, "phrase": "primitive_actions"}, {"score": 0.0027054473441439422, "phrase": "probabilistic_grammar_induction"}, {"score": 0.002676514445417281, "phrase": "probabilistic_context-free_grammars"}, {"score": 0.00249135867469492, "phrase": "possible_and_preferred_plans"}, {"score": 0.0024383449794706477, "phrase": "core_em_technique"}, {"score": 0.00235247790591897, "phrase": "proposed_approaches"}, {"score": 0.0022615046141708987, "phrase": "inside-outside_algorithm"}, {"score": 0.0021662599012740127, "phrase": "rescaled_input"}, {"score": 0.0021049977753042253, "phrase": "original_input"}], "paper_keywords": ["Algorithms", " Hierarchical task networks", " learning user preferences", " planning", " AI Technology"], "paper_abstract": "We introduce an algorithm to automatically learn probabilistic hierarchical task networks (pHTNs) that capture a user's preferences on plans by observing only the user's behavior. HTNs are a common choice of representation for a variety of purposes in planning, including work on learning in planning. Our contributions are twofold. First, in contrast with prior work, which employs HTNs to represent domain physics or search control knowledge, we use HTNs to model user preferences. Second, while most prior work on HTN learning requires additional information (e.g., annotated traces or tasks) to assist the learning process, our system only takes plan traces as input. Initially, we will assume that users carry out preferred plans more frequently, and thus the observed distribution of plans is an accurate representation of user preference. We then generalize to the situation where feasibility constraints frequently prevent the execution of preferred plans. Taking the prevalent perspective of viewing HTNs as grammars over primitive actions, we adapt an expectation-maximization (EM) technique from the discipline of probabilistic grammar induction to acquire probabilistic context-free grammars (pCFG) that capture the distribution on plans. To account for the difference between the distributions of possible and preferred plans, we subsequently modify this core EM technique by rescaling its input. We empirically demonstrate that the proposed approaches are able to learn HTNs representing user preferences better than the inside-outside algorithm. Furthermore, when feasibility constraints are obfuscated, the algorithm with rescaled input performs better than the algorithm with the original input.", "paper_title": "Learning Probabilistic Hierarchical Task Networks as Probabilistic Context-Free Grammars to Capture User Preferences", "paper_id": "WOS:000335576200008"}