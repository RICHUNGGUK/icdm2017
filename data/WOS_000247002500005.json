{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "data_sets"}, {"score": 0.04896221231267542, "phrase": "summary_statistics"}, {"score": 0.004312622975366672, "phrase": "data_mining"}, {"score": 0.0036553070575015344, "phrase": "initial_definition"}, {"score": 0.00348655247465418, "phrase": "geometrical_notions"}, {"score": 0.003097865379563127, "phrase": "cubic_time"}, {"score": 0.002752390133272192, "phrase": "unique_mahalanobis_distance"}, {"score": 0.0024842242921857705, "phrase": "binary_data_sets"}, {"score": 0.0021384748235753425, "phrase": "linear_time"}], "paper_keywords": ["data mining theory", " complex data", " binary data", " itemsets"], "paper_abstract": "The concepts of similarity and distance are crucial in data mining. We consider the problem of defining the distance between two data sets by comparing summary statistics computed from the data sets. The initial definition of our distance is based on geometrical notions of certain sets of distributions. We show that this distance can be computed in cubic time and that it has several intuitive properties. We also show that this distance is the unique Mahalanobis distance satisfying certain assumptions. We also demonstrate that if we are dealing with binary data sets, then the distance can be represented naturally by certain parity functions, and that it can be evaluated in linear time. Our empirical tests with real world data show that the distance works well.", "paper_title": "Distances between data sets based on summary statistics", "paper_id": "WOS:000247002500005"}