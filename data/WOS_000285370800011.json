{"auto_keywords": [{"score": 0.049220049459043146, "phrase": "nhl"}, {"score": 0.013929097285781768, "phrase": "proposed_system"}, {"score": 0.010612382125825607, "phrase": "nonlinear_hebbian_learning"}, {"score": 0.007917523843653322, "phrase": "lhl"}, {"score": 0.006404515794560454, "phrase": "snr"}, {"score": 0.004750002000045893, "phrase": "new_biologically_inspired_approach_nonlinear_hebbian_learning"}, {"score": 0.004685925469417181, "phrase": "acoustic_signal_recognition"}, {"score": 0.004664758386159831, "phrase": "noisy_environments"}, {"score": 0.004643686471944062, "phrase": "proposed_learning_processes"}, {"score": 0.004622709302902907, "phrase": "spectral_and_temporal_features"}, {"score": 0.0046018264570209765, "phrase": "input_acoustic_data"}, {"score": 0.004581037514126714, "phrase": "spectral_analysis"}, {"score": 0.004529473241633146, "phrase": "auditory_gammatone"}, {"score": 0.004498812433096501, "phrase": "temporal_dynamics"}, {"score": 0.004448169552315403, "phrase": "gammatone-filtered_feature_vectors"}, {"score": 0.004280200258155376, "phrase": "str"}, {"score": 0.004251210982670317, "phrase": "exact_acoustic_signatures"}, {"score": 0.004184347221796807, "phrase": "mixing_property"}, {"score": 0.0040171817997972335, "phrase": "independent_features"}, {"score": 0.003945037259654532, "phrase": "extracted_independent_features"}, {"score": 0.0038218760331371043, "phrase": "synaptic_weight_vectors"}, {"score": 0.0038045970814886304, "phrase": "input_and_output_neurons"}, {"score": 0.0037617394143447044, "phrase": "weight_vectors"}, {"score": 0.003719362723728175, "phrase": "feature_subspace"}, {"score": 0.003603221407278025, "phrase": "linear_hebbian_learning"}, {"score": 0.003546513036085932, "phrase": "second-order_moment"}, {"score": 0.00348279167515198, "phrase": "higher-order_statistics"}, {"score": 0.0034279721355412285, "phrase": "representative_features"}, {"score": 0.0033435594184605686, "phrase": "nonlinear_activation_function"}, {"score": 0.003268619794473257, "phrase": "implicit_distribution"}, {"score": 0.0031736957037696396, "phrase": "mutual_information_simulation_results"}, {"score": 0.0031450448937139015, "phrase": "whole_proposed_system"}, {"score": 0.003067577724136682, "phrase": "severely_noisy_circumstances"}, {"score": 0.0030329970862470732, "phrase": "vehicles_noise-contaminated_vehicle"}, {"score": 0.002944895504859249, "phrase": "human_vowel_bird_chirp"}, {"score": 0.002931569771634119, "phrase": "additive_white_gaussian_noise"}, {"score": 0.0028399580599632788, "phrase": "error_rate"}, {"score": 0.002827105825163379, "phrase": "normally_used_acoustic_feature_extraction_method"}, {"score": 0.002659172481861264, "phrase": "applicable_project"}, {"score": 0.002647136220577337, "phrase": "vehicle_type_identification"}, {"score": 0.0026232264620319476, "phrase": "better_performance"}, {"score": 0.0025995321009841975, "phrase": "gasoline_heavy_wheeled_car"}, {"score": 0.0025760768972820673, "phrase": "awgn"}, {"score": 0.0025011895514488783, "phrase": "real-time_field"}, {"score": 0.002368638639160796, "phrase": "missing_rate"}, {"score": 0.00232075924198957, "phrase": "surrounding_noises"}, {"score": 0.0022278779300543548, "phrase": "false_alarm_rate"}, {"score": 0.0021729527129781463, "phrase": "efficient_approach"}, {"score": 0.0021582090265155783, "phrase": "representative_independent_features"}, {"score": 0.00214843540071852, "phrase": "high-dimensional_data"}, {"score": 0.0021193787241069683, "phrase": "severe_noises"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd"}], "paper_keywords": ["Independent feature extraction", " Higher order statistics", " Noise robustness", " Nonlinear Hebbian learning", " Statistical optimization"], "paper_abstract": "We propose using a new biologically inspired approach nonlinear Hebbian learning (NHL) to implement acoustic signal recognition in noisy environments The proposed learning processes both spectral and temporal features of input acoustic data The spectral analysis is realized by using auditory gammatone filterbanks The temporal dynamics is addressed by analyzing gammatone-filtered feature vectors over multiple temporal frames which is called a spectro-temporal representation (STR) Given STR features the exact acoustic signatures of signals of interest and the mixing property between signals of interest and noises are generally unknown The nonlinear Hebbian learning is then employed to extract representative independent features from STRs and to reduce their dimensionality The extracted independent features of signals of interest are called signatures In the meantime of learning the synaptic weight vectors between input and output neurons are adaptively updated These weight vectors project data into a feature subspace in which signals of interest are selected while noises are attenuated Compared with linear Hebbian learning (LHL) which explores the second-order moment of data the applied NHL involves the higher-order statistics of data Therefore NHL can capture representative features that are more statistically independent than LHL can Besides the nonlinear activation function of NHL can be chosen to refer to the implicit distribution of many acoustic sounds and thus making the learning optimized in an aspect of mutual information Simulation results show that the whole proposed system can more accurately recognize signals of interest than other conventional methods in severely noisy circumstances One applicable project is detecting moving vehicles Noise-contaminated vehicle sound is recognized while other non-vehicle sounds are rejected When vehicle is contaminated by human vowel bird chirp or additive white Gaussian noise (AWGN) at SNR = 0 dB the proposed system dramatically decreases the error rate over normally used acoustic feature extraction method mel-frequency cepstral computation (MFCC) by 26% 36 3% and 60 3% respectively and over LHL by 20% 2 3% and 15 3% respectively Another applicable project is vehicle type identification The proposed system achieves better performance than LHL e g 40% improvement when gasoline heavy wheeled car is contaminated by AWGN at SNR = 5 dB More importantly the proposed system is implemented in real-time field testing for months The purpose is to detect vehicle with any make or model moving on the street with speed 10-35 mph The missing rate is 1-2% when vehicle is contaminated by any surrounding noises (human conversation animal sound airplane wind etc) at SNR = 0-20 dB The false alarm rate is around 1% To summarize this study not only provides an efficient approach to extract representative independent features from high-dimensional data but also offers robustness against severe noises Published by Elsevier Ltd", "paper_title": "Noise-robust acoustic signature recognition using nonlinear Hebbian learning", "paper_id": "WOS:000285370800011"}