{"auto_keywords": [{"score": 0.03747360849945525, "phrase": "timely"}, {"score": 0.00481495049065317, "phrase": "congestion_control"}, {"score": 0.004704501096407779, "phrase": "datacenter"}, {"score": 0.004596561972944185, "phrase": "low_latency_messaging"}, {"score": 0.004532988904965752, "phrase": "high_throughput"}, {"score": 0.0044289730051264116, "phrase": "simple_packet_delay"}, {"score": 0.004347473906950474, "phrase": "round-trip_times"}, {"score": 0.004228016636379321, "phrase": "effective_congestion_signal"}, {"score": 0.00413096972023037, "phrase": "switch_feedback"}, {"score": 0.003961842092184655, "phrase": "nic_hardware"}, {"score": 0.003907019784466283, "phrase": "rtt"}, {"score": 0.00383508177668219, "phrase": "microsecond_accuracy"}, {"score": 0.0036609730219354796, "phrase": "switch_queueing"}, {"score": 0.0035110198699787013, "phrase": "transmission_rates"}, {"score": 0.0034785371344994197, "phrase": "rtt_gradients"}, {"score": 0.0033515736929172644, "phrase": "high_bandwidth"}, {"score": 0.0032593915869553714, "phrase": "host_software"}, {"score": 0.0031845067058084613, "phrase": "os-bypass_capabilities"}, {"score": 0.003011706511096639, "phrase": "clos_network"}, {"score": 0.002942495422585405, "phrase": "excellent_performance"}, {"score": 0.0028615323526689582, "phrase": "os-bypass_messaging"}, {"score": 0.002795770597497659, "phrase": "pfc"}, {"score": 0.0026811531172346676, "phrase": "line-rate_throughput"}, {"score": 0.0025592969422491476, "phrase": "optimized_kernel"}, {"score": 0.002523828967909659, "phrase": "tail_latency"}, {"score": 0.0023867931451842087, "phrase": "first_delay-based_congestion_control_protocol"}, {"score": 0.002164602220179823, "phrase": "nic_offload"}, {"score": 0.002134592410214824, "phrase": "earlier_delay-based_schemes"}, {"score": 0.002105000753485991, "phrase": "vegas"}], "paper_keywords": ["datacenter transport", " delay-based congestion control", " OS-bypass", " RDMA"], "paper_abstract": "Datacenter transports aim to deliver low latency messaging together with high throughput. We show that simple packet delay, measured as round-trip times at hosts, is an effective congestion signal without the need for switch feedback. First, we show that advances in NIC hardware have made RTT measurement possible with microsecond accuracy, and that these RTTs are sufficient to estimate switch queueing. Then we describe how TIMELY can adjust transmission rates using RTT gradients to keep packet latency low while delivering high bandwidth. We implement our design in host software running over NICs with OS-bypass capabilities. We show using experiments with up to hundreds of machines on a Clos network topology that it provides excellent performance: turning on TIMELY for OS-bypass messaging over a fabric with PFC lowers 99 percentile tail latency by 9 X while maintaining near line-rate throughput. Our system also outperforms DCTCP running in an optimized kernel, reducing tail latency by 13X. To the best of our knowledge, TIMELY is the first delay-based congestion control protocol for use in the datacenter, and it achieves its results despite having an order of magnitude fewer RTT signals (due to NIC offload) than earlier delay-based schemes such as Vegas.", "paper_title": "TIMELY: RTT-based Congestion Control for the Datacenter", "paper_id": "WOS:000370556200072"}