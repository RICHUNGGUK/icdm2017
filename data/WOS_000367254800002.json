{"auto_keywords": [{"score": 0.04410293038185961, "phrase": "sequential_bottleneck"}, {"score": 0.04129099571761686, "phrase": "deletemin_operation"}, {"score": 0.030124351850484017, "phrase": "high_probability"}, {"score": 0.00481495049065317, "phrase": "concurrent_priority_queues"}, {"score": 0.004672808182229058, "phrase": "task_scheduling"}, {"score": 0.004632968695963776, "phrase": "discrete_event_simulation"}, {"score": 0.0045543011700929096, "phrase": "even_the_best_performing_implementations"}, {"score": 0.004344755264641137, "phrase": "single_digits"}, {"score": 0.003788196352457501, "phrase": "spraylist"}, {"score": 0.0037398106866046972, "phrase": "scalable_priority_queue"}, {"score": 0.0037078961288626185, "phrase": "relaxed_ordering_semantics"}, {"score": 0.003629291866667764, "phrase": "non-blocking_skiplist"}, {"score": 0.003477029725200912, "phrase": "deletemin_operations"}, {"score": 0.003274499008699115, "phrase": "skiplist_list"}, {"score": 0.003232653376857698, "phrase": "coordinated_fashion"}, {"score": 0.003123652729688503, "phrase": "carefully_designed_random_walk"}, {"score": 0.0030705342386533083, "phrase": "deletemin"}, {"score": 0.0029925402963843282, "phrase": "first_o"}, {"score": 0.0026767629720554397, "phrase": "running_time"}, {"score": 0.0024252458095689847, "phrase": "relaxed_semantics"}, {"score": 0.0023942269247089277, "phrase": "data_structure"}, {"score": 0.002353483216544667, "phrase": "high_thread_counts"}, {"score": 0.0023035249767734286, "phrase": "classic_unordered_skiplist"}, {"score": 0.002216251512062482, "phrase": "reasonably_parallel_workloads"}, {"score": 0.00218789980093445, "phrase": "scalability_benefits"}, {"score": 0.0021322775033565805, "phrase": "additional_work"}, {"score": 0.0021049977753042253, "phrase": "out-of-order_execution"}], "paper_keywords": ["Concurrent data structures", " parallel algorithms"], "paper_abstract": "High-performance concurrent priority queues are essential for applications such as task scheduling and discrete event simulation. Unfortunately, even the best performing implementations do not scale past a number of threads in the single digits. This is because of the sequential bottleneck in accessing the elements at the head of the queue in order to perform a DeleteMin operation. In this paper, we present the SprayList, a scalable priority queue with relaxed ordering semantics. Starting from a non-blocking SkipList, the main innovation behind our design is that the DeleteMin operations avoid a sequential bottleneck by \"spraying\" themselves onto the head of the SkipList list in a coordinated fashion. The spraying is implemented using a carefully designed random walk, so that DeleteMin returns an element among the first O (p log(3) p) in the list, with high probability, where p is the number of threads. We prove that the running time of a DeleteMin operation is O (log(3) p), with high probability, independent of the size of the list. Our experiments show that the relaxed semantics allow the data structure to scale for high thread counts, comparable to a classic unordered SkipList. Furthermore, we observe that, for reasonably parallel workloads, the scalability benefits of relaxation considerably outweigh the additional work due to out-of-order execution.", "paper_title": "The SprayList: A Scalable Relaxed Priority Queue", "paper_id": "WOS:000367254800002"}