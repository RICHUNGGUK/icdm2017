{"auto_keywords": [{"score": 0.04765855071912561, "phrase": "camera_sensors"}, {"score": 0.015719716506582538, "phrase": "view-coverage_ratio"}, {"score": 0.01562520542667837, "phrase": "camera_sensor_networks"}, {"score": 0.011480378927108363, "phrase": "coverage_quality"}, {"score": 0.008606666137454092, "phrase": "target_region"}, {"score": 0.004367333454187657, "phrase": "traditional_scalar_sensor_networks"}, {"score": 0.004301238254323321, "phrase": "distinct_positions"}, {"score": 0.004262060185430346, "phrase": "distinct_images"}, {"score": 0.0040220535813966255, "phrase": "frontier_view"}, {"score": 0.0039011907503957075, "phrase": "new_coverage_model_full-view_coverage_wang"}, {"score": 0.00387747544445992, "phrase": "cao"}, {"score": 0.003559884222226099, "phrase": "full-view_coverage_model"}, {"score": 0.0033388363997245286, "phrase": "novel_view-coverage_model"}, {"score": 0.0032682370318207503, "phrase": "finer_granularity"}, {"score": 0.003218721776850253, "phrase": "face_recognition"}, {"score": 0.003121923422694974, "phrase": "distributed_multi-round_view-coverage_enhancing"}, {"score": 0.002910159235873015, "phrase": "overlapping_view-coverage"}, {"score": 0.002848598297362903, "phrase": "stable_state"}, {"score": 0.002771352849127134, "phrase": "vce_algorithm"}, {"score": 0.0027293449981640105, "phrase": "corresponding_refinement_procedures"}, {"score": 0.002704445718144686, "phrase": "first_one"}, {"score": 0.0024903043450159594, "phrase": "second_one"}, {"score": 0.0024600517975561127, "phrase": "rotating_angle"}, {"score": 0.002393317277328894, "phrase": "global_optimal_solution"}, {"score": 0.0023787343905076024, "phrase": "simulation_results"}, {"score": 0.0023355154605700095, "phrase": "significant_improvement"}, {"score": 0.0022930799650968544, "phrase": "random_deployment"}, {"score": 0.002258305302735867, "phrase": "refinement_procedures"}, {"score": 0.002237693583489426, "phrase": "remarkable_improvement"}, {"score": 0.00221726957085921, "phrase": "basic_vce_algorithm"}, {"score": 0.00214396012113301, "phrase": "real_deployed_camera_sensors"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Camera sensor network", " View-coverage ratio", " Overlapping view-coverage degree", " Boundary effect", " Dynamic rotating angle"], "paper_abstract": "In recent years, camera sensor networks are widely studied due to the strength of the camera sensors in retrieving more types of information in terms of videos or images. Different from traditional scalar sensor networks, camera sensors from distinct positions can get distinct images with the same object. The object is more likely to be recognized if its image is captured around the frontier view of the camera. To this end, a new coverage model full-view coverage Wang and Cao (2011) is proposed for the camera sensors, to judge whether an object is recognized no matter which direction it faces to. However, the full-view coverage model fails to evaluate the coverage quality when the object is not full-view covered. In this paper, we introduce a novel view-coverage model which measures the coverage quality with a finer granularity for the purpose of face recognition. Based on this model, we propose a distributed multi-round view-coverage enhancing (VCE) algorithm by the self-orientation of the camera sensors. In this algorithm, sensors are continuously rotated to reduce the overlapping view-coverage with their neighbors until reaching the stable state. Furthermore, we address two important issues in the VCE algorithm, and propose the corresponding refinement procedures. The first one is about the sensors near the boundary of the target region whose view-coverage may include the outside of the target region, which is meaningless for our problem. The second one is about the rotating angle which should be set appropriately to achieve a global optimal solution. Simulation results show that our algorithm brings a significant improvement on the view-coverage ratio compared with random deployment. Also, the refinement procedures make a remarkable improvement over the basic VCE algorithm. Moreover, we evaluate the performance of our algorithm with real deployed camera sensors. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Self-orienting the cameras for maximizing the view-coverage ratio in camera sensor networks", "paper_id": "WOS:000349760500006"}