{"auto_keywords": [{"score": 0.04255384302903808, "phrase": "artificial_agents"}, {"score": 0.03827394525154412, "phrase": "human_user"}, {"score": 0.03353032684383617, "phrase": "artificial_agent"}, {"score": 0.00481495049065317, "phrase": "human_and_artificial_agents"}, {"score": 0.004719664411221952, "phrase": "complex_form"}, {"score": 0.003981928669805484, "phrase": "co-operative_way"}, {"score": 0.003955465362027017, "phrase": "human-agent_interaction"}, {"score": 0.003749969582830009, "phrase": "natural_language"}, {"score": 0.0035669891404642015, "phrase": "suitable_set"}, {"score": 0.003438483411236772, "phrase": "general_framework"}, {"score": 0.003359119985242403, "phrase": "natural_language_interfaces"}, {"score": 0.0032489004068215407, "phrase": "task-related_communication"}, {"score": 0.00312138530097218, "phrase": "cooperative_work"}, {"score": 0.0030902938839530883, "phrase": "human_partners"}, {"score": 0.002988868585379496, "phrase": "main_aim"}, {"score": 0.0029101233953870466, "phrase": "consistent_and_coherent_formal_framework"}, {"score": 0.0027495914857929584, "phrase": "action_execution"}, {"score": 0.0025892330566358503, "phrase": "verbal_expressions"}, {"score": 0.002572001496778222, "phrase": "i.e._commands"}, {"score": 0.002470987929071079, "phrase": "suggested_framework"}, {"score": 0.002438203996977464, "phrase": "formal_methods"}, {"score": 0.002421975107313603, "phrase": "knowledge_representation"}, {"score": 0.002397833600728684, "phrase": "particular_description_logics"}, {"score": 0.002366017944545902, "phrase": "semantic_and_ontological_descriptive_elements"}, {"score": 0.0023268399760599336, "phrase": "computer_science"}, {"score": 0.002213147136067999, "phrase": "simulated_agents"}, {"score": 0.0021910825909008946, "phrase": "interior_design_system"}, {"score": 0.00216923754570397, "phrase": "household_robot"}, {"score": 0.0021404485085209143, "phrase": "speech_controlled_toy_car"}, {"score": 0.0021049977753042253, "phrase": "physical_agent"}], "paper_keywords": [""], "paper_abstract": "The use of a complex form of language for the purpose of communication with others, to exchange ideas and thoughts, to express statements, wishes, goals, and plans, and to issue questions, commands and instructions, is one of the most important and distinguishing aspects humankind. If artificial agents want to participate in a co-operative way in human-agent interaction, they must be able - to a certain degree - to understand and interpret natural language, and translate commands and questions of a human user and map them onto a suitable set of their own primitive actions. In this paper, we outline a general framework and architecture for the development of natural language interfaces for artificial agents. We focus in this paper on task-related communication, in a scenario where the artificial agent performs actions in a cooperative work setting with human partners, who serve as instructors or supervisors. The main aim of this research is to provide a consistent and coherent formal framework for the representation of actions, which can be used for planning, reasoning, and action execution by the artificial agent, and at the same time can serve as a basis for analyzing and generating verbal expressions, i.e. commands, instructions and queries, issued by the human user. The suggested framework is derived from formal methods in knowledge representation, in particular description logics, and involves semantic and ontological descriptive elements taken from linguistics, computer science, and philosophy. Several prototypical agent systems have been developed based on this framework, including simulated agents like an interior design system and a household robot, and a speech controlled toy car as example of a physical agent.", "paper_title": "Natural language communication between human and artificial agents", "paper_id": "WOS:000239626100011"}