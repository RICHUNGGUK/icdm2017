{"auto_keywords": [{"score": 0.040387229066893286, "phrase": "cocr"}, {"score": 0.010612384215170072, "phrase": "ranking_performance"}, {"score": 0.0077151779664798754, "phrase": "point-wise_regression"}, {"score": 0.004753670676591174, "phrase": "cost-sensitive_ordinal_classification"}, {"score": 0.0045162169185355, "phrase": "novel_ranking_approach"}, {"score": 0.004076157223660074, "phrase": "discrete_nature"}, {"score": 0.004024242000713225, "phrase": "ordinal_ranks"}, {"score": 0.0039729853486821995, "phrase": "real-world_data_sets"}, {"score": 0.0037743802306714545, "phrase": "theoretically_sound_method"}, {"score": 0.0036788184374592706, "phrase": "ordinal_classification"}, {"score": 0.0035399770257915466, "phrase": "binary_classification_sub-tasks"}, {"score": 0.003298856341173034, "phrase": "mis-ranking_costs"}, {"score": 0.003015508235745547, "phrase": "corresponding_cost"}, {"score": 0.002958021635132416, "phrase": "popular_ranking_criterion"}, {"score": 0.0029203055813347874, "phrase": "expected_reciprocal_rank"}, {"score": 0.0025034338848015166, "phrase": "top-rank_prediction"}, {"score": 0.0024556852466581527, "phrase": "err_criterion"}, {"score": 0.002317829569619977, "phrase": "yahoo"}, {"score": 0.002259054486157494, "phrase": "rank_challenge\""}, {"score": 0.0022302306304023602, "phrase": "\"microsoft_learning_to_rank"}, {"score": 0.0021597662797996843, "phrase": "significant_superiority"}, {"score": 0.0021049977753042253, "phrase": "commonly_used_regression_approaches"}], "paper_keywords": ["List-wise ranking", " Cost-sensitive", " Regression", " Reduction"], "paper_abstract": "This paper proposes a novel ranking approach, cost-sensitive ordinal classification via regression (COCR), which respects the discrete nature of ordinal ranks in real-world data sets. In particular, COCR applies a theoretically sound method for reducing an ordinal classification to binary and solves the binary classification sub-tasks with point-wise regression. Furthermore, COCR allows us to specify mis-ranking costs to further improve the ranking performance; this ability is exploited by deriving a corresponding cost for a popular ranking criterion, expected reciprocal rank (ERR). The resulting ERR-tuned COCR boosts the benefits of the efficiency of using point-wise regression and the accuracy of top-rank prediction from the ERR criterion. Evaluations on four large-scale benchmark data sets, i.e., \"Yahoo! Learning to Rank Challenge\" and \"Microsoft Learning to Rank,\" verify the significant superiority of COCR over commonly used regression approaches.", "paper_title": "Improving ranking performance with cost-sensitive ordinal classification via regression", "paper_id": "WOS:000330971400001"}