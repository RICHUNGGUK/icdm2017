{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "action_recognition"}, {"score": 0.04846792924157254, "phrase": "human_actions"}, {"score": 0.03261638306028882, "phrase": "particle_trajectories"}, {"score": 0.004768104290288521, "phrase": "key-point_trajectory"}, {"score": 0.004607686390487483, "phrase": "realistic_videos"}, {"score": 0.004518442937844318, "phrase": "promising_results"}, {"score": 0.004366387782457736, "phrase": "entire_actor"}, {"score": 0.004057495982111461, "phrase": "partial_occlusions"}, {"score": 0.0038827100184187805, "phrase": "novel_approach"}, {"score": 0.0038261310307416475, "phrase": "weighted_feature_trajectories"}, {"score": 0.0036612799047323363, "phrase": "bof"}, {"score": 0.0036079110889031874, "phrase": "weighted_spatio-temporal_descriptors"}, {"score": 0.0034693659976716197, "phrase": "spatio-temporal_regions"}, {"score": 0.003303617297414837, "phrase": "scale-invariant_feature_transform"}, {"score": 0.0031767199435197243, "phrase": "sift_descriptors"}, {"score": 0.0030397596289795143, "phrase": "sift_trajectories"}, {"score": 0.0030101325901285537, "phrase": "dense_optical_flow"}, {"score": 0.0029662627465531816, "phrase": "roi"}, {"score": 0.002880333728285514, "phrase": "sound_coverage"}, {"score": 0.00274267875691788, "phrase": "sift"}, {"score": 0.0026762874092443197, "phrase": "weighting_scheme"}, {"score": 0.002598764579760562, "phrase": "accumulated_global_distribution"}, {"score": 0.002573424607574822, "phrase": "feature_points"}, {"score": 0.002486659929589854, "phrase": "concatenated_two_distinct_sift_and_particle_bofs"}, {"score": 0.0023677483882740317, "phrase": "experimental_results"}, {"score": 0.002265586601922693, "phrase": "real-world_action_datasets"}, {"score": 0.0022325288883065755, "phrase": "kth"}, {"score": 0.0022107428653358715, "phrase": "ucf_sports"}, {"score": 0.0021678232353129472, "phrase": "human_interaction"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Action recognition", " Feature trajectories", " Bag-of-features", " Weighted spatio-temporal descriptor"], "paper_abstract": "Key-point trajectory based approaches to recognizing human actions in realistic videos have recently shown promising results. However, their coverage of the entire actor is not sufficient for describing human actions, and the trajectories often disappear due to partial occlusions. In this paper, we propose a novel approach based on weighted feature trajectories and concatenated bag-of-features (BOF) using weighted spatio-temporal descriptors to overcome these limitations. To capture spatio-temporal regions of interest (ROI), we first build scale-invariant feature transform (SIFT) trajectories based on matching SIFT descriptors. Then, we extract particle trajectories around the SIFT trajectories using dense optical flow to retain ROI subsidiarily and to give a sound coverage of the actors. For balancing the leverages between SIFT and particle trajectories, a weighting scheme is presented according to the accumulated global distribution of feature points. Furthermore, we propose the concatenated two distinct SIFT and particle BOFs with weighted spatio-temporal descriptors for action recognition. Experimental results demonstrate the effectiveness of this approach in challenging real-world action datasets such as KTH, UCF sports, and TV human interaction. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Weighted feature trajectories and concatenated bag-of-features for action recognition", "paper_id": "WOS:000332805700022"}