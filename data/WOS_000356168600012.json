{"auto_keywords": [{"score": 0.04857317035991677, "phrase": "lighting_level"}, {"score": 0.04794124607475939, "phrase": "vqips"}, {"score": 0.00481495049065317, "phrase": "video_sequences"}, {"score": 0.004771196027464407, "phrase": "chosen_generalized_use_classes"}, {"score": 0.004496280772084575, "phrase": "public_safety"}, {"score": 0.004237138632255772, "phrase": "user_guide"}, {"score": 0.00419861271409079, "phrase": "public_safety_video_applications"}, {"score": 0.004085115444878828, "phrase": "five_parameters"}, {"score": 0.0040479661688863884, "phrase": "particular_importance"}, {"score": 0.003920573616298175, "phrase": "recognition_task"}, {"score": 0.003832031470970347, "phrase": "usage_time-frame"}, {"score": 0.0031627430133087616, "phrase": "input_sequences"}, {"score": 0.003063123420705719, "phrase": "target_size"}, {"score": 0.0028995712226514746, "phrase": "experts'_ambiguity"}, {"score": 0.0028340217672278975, "phrase": "manual_target_size_determination_process"}, {"score": 0.002769950045729965, "phrase": "automatic_methods"}, {"score": 0.0027322025124213566, "phrase": "target_size_classification"}, {"score": 0.0026582395558737855, "phrase": "guc_parameters"}, {"score": 0.0025981315738078793, "phrase": "end-users'_opinion"}, {"score": 0.002527788827701828, "phrase": "entire_sequence"}, {"score": 0.0023173287402646577, "phrase": "test_application"}, {"score": 0.0022136780933978612, "phrase": "video_files"}, {"score": 0.002193509835371438, "phrase": "display_classification_results"}, {"score": 0.002163600705898299, "phrase": "user_interface"}], "paper_keywords": ["Subjective evaluation techniques", " Objective evaluation techniques", " Quality of experience", " Implementation"], "paper_abstract": "The VQiPS (Video Quality in Public Safety) Working Group, supported by the U.S. Department of Homeland Security, has been developing a user guide for public safety video applications. According to VQiPS, five parameters have particular importance influencing the ability to achieve a recognition task. They are: usage time-frame, discrimination level, target size, lighting level, and level of motion. These parameters form what are referred to as Generalized Use Classes (GUCs). The aim of our research was to develop algorithms that would automatically assist classification of input sequences into one of the GUCs. Target size and lighting level parameters were approached. The experiment described reveals the experts' ambiguity and hesitation during the manual target size determination process. However, the automatic methods developed for target size classification make it possible to determine GUC parameters with 70 % compliance to the end-users' opinion. Lighting levels of the entire sequence can be classified with an efficiency reaching 93 %. To make the algorithms available for use, a test application has been developed. It is able to process video files and display classification results, the user interface being very simple and requiring only minimal user interaction.", "paper_title": "Classification of video sequences into chosen generalized use classes of target size and lighting level", "paper_id": "WOS:000356168600012"}