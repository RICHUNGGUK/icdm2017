{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "feedforward_neural_networks"}, {"score": 0.03605781665678907, "phrase": "hidden_layer"}, {"score": 0.004658426838467567, "phrase": "novel_learning_algorithm"}, {"score": 0.004556901872357751, "phrase": "bpwa"}, {"score": 0.003948613642680196, "phrase": "forward_phase"}, {"score": 0.0038624981944755813, "phrase": "backward_phase"}, {"score": 0.0036553070575015344, "phrase": "minimum_norm_square_solution"}, {"score": 0.0033465923623290034, "phrase": "output_layer"}, {"score": 0.0032376465741070274, "phrase": "forward_pass"}, {"score": 0.003097865379563127, "phrase": "backward_pass"}, {"score": 0.0028993944292191433, "phrase": "input_layer"}, {"score": 0.0024569466759289055, "phrase": "extreme_learning_machine"}, {"score": 0.00240328454980006, "phrase": "bp_algorithm"}, {"score": 0.0023507916951658455, "phrase": "lmbp_algorithm_oil_function_approximation"}, {"score": 0.002200077887697072, "phrase": "experiments'_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_algorithm"}], "paper_keywords": [""], "paper_abstract": "A novel learning algorithm called BPWA for feedforward neural networks is presented, which ad Lists the weights during both forward phase and backward phase. It calculates the minimum norm square solution as the weights between the hidden layer and Output layer in the forward pass, while the backward pass adjusts the weights connecting the input layer to hidden layer according to error gradient descent algorithm. The algorithm is compared with Extreme learning Machine, BP algorithm and LMBP algorithm oil function approximation and classification tasks. The experiments' results demonstrate that the proposed algorithm performs well.", "paper_title": "A novel learning algorithm for feedforward neural networks", "paper_id": "WOS:000238112000076"}