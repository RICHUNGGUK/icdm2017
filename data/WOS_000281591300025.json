{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "binary_particle_swarm_optimization"}, {"score": 0.04889532068804289, "phrase": "feature_selection"}, {"score": 0.03405024562525932, "phrase": "chaotic_maps"}, {"score": 0.004625881588444304, "phrase": "useful_pre-processing_technique"}, {"score": 0.004377921202912336, "phrase": "feature_selection_problem"}, {"score": 0.004291073117901643, "phrase": "evolutionary_algorithms"}, {"score": 0.004184921610672245, "phrase": "huge_number"}, {"score": 0.004000396172153709, "phrase": "classification_data"}, {"score": 0.003785836059995376, "phrase": "primary_objective"}, {"score": 0.0037106898330901534, "phrase": "irrelevant_features"}, {"score": 0.0036553070575015344, "phrase": "feature_space"}, {"score": 0.0035648266669315943, "phrase": "relevant_features"}, {"score": 0.00349405245698573, "phrase": "bpso"}, {"score": 0.003356675879109443, "phrase": "feature_selection_problems"}, {"score": 0.0031925019616678217, "phrase": "so-called_logistic_maps"}, {"score": 0.002931569771634119, "phrase": "inertia_weight"}, {"score": 0.0028877818105020434, "phrase": "bpso."}, {"score": 0.0028446460307503343, "phrase": "chaotic_binary_particle_swarm_optimization"}, {"score": 0.002534597716082948, "phrase": "loocv"}, {"score": 0.0024348510123716424, "phrase": "classification_accuracies"}, {"score": 0.002398464540102246, "phrase": "proposed_feature_selection_method"}, {"score": 0.0022810491620483737, "phrase": "feature_subsets"}, {"score": 0.002246955931290095, "phrase": "classification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Feature selection", " Binary particle swarm optimization", " Chaotic maps", " K-nearest neighbor", " Leave-one-out cross-validation"], "paper_abstract": "Feature selection is a useful pre-processing technique for solving classification problems. The challenge of solving the feature selection problem lies in applying evolutionary algorithms capable of handling the huge number of features typically involved. Generally, given classification data may contain useless, redundant or misleading features. To increase classification accuracy, the primary objective is to remove irrelevant features in the feature space and to correctly identify relevant features. Binary particle swarm optimization (BPSO) has been applied successfully to solving feature selection problems. In this paper, two kinds of chaotic maps-so-called logistic maps and tent maps-are embedded in BPSO. The purpose of chaotic maps is to determine the inertia weight of the BPSO. We propose chaotic binary particle swarm optimization (CBPSO) to implement the feature selection, in which the K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) serves as a classifier for evaluating classification accuracies. The proposed feature selection method shows promising results with respect to the number of feature subsets. The classification accuracy is superior to other methods from the literature. (c) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Chaotic maps based on binary particle swarm optimization for feature selection", "paper_id": "WOS:000281591300025"}