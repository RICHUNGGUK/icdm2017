{"auto_keywords": [{"score": 0.03843856552198327, "phrase": "tf-idf"}, {"score": 0.03066943263750806, "phrase": "weighted_voting_classifier"}, {"score": 0.00481495049065317, "phrase": "term_frequency-inverse_document"}, {"score": 0.004171065188039856, "phrase": "vector_space_model"}, {"score": 0.004075053556360943, "phrase": "text_mining"}, {"score": 0.004043541331944951, "phrase": "information_retrieval"}, {"score": 0.0035297609635321203, "phrase": "term_idf_weighting"}, {"score": 0.0034618794528555063, "phrase": "different_roles"}, {"score": 0.0033429545815200825, "phrase": "positive_and_negative_training"}, {"score": 0.003304224820203298, "phrase": "text_classification"}, {"score": 0.003228101865545105, "phrase": "aforementioned_text"}, {"score": 0.0031537270875516108, "phrase": "novel_tf-idf-improved_feature_weighting_approach"}, {"score": 0.0029867619862229853, "phrase": "negative_training_examples"}, {"score": 0.002839625463110821, "phrase": "support_vector_machine_algorithm"}, {"score": 0.0028067105937184954, "phrase": "one-class_support_vector_machine"}, {"score": 0.0024977819584875573, "phrase": "unlabeled_examples"}, {"score": 0.0024592402228499105, "phrase": "experimental_results"}, {"score": 0.0023746766301040974, "phrase": "positive-negative_document_frequency-based_classifier"}, {"score": 0.0022141537427057363, "phrase": "one-class_support"}, {"score": 0.002205560249972527, "phrase": "vector_machine-based_classifier"}, {"score": 0.002163089417146551, "phrase": "learning-based_classifier"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["TF-IDF", " TFIPNDF", " Classification", " 1-DNFC", " WVC"], "paper_abstract": "Term frequency-inverse document frequency (TF-IDF), one of the most popular feature (also called term or word) weighting methods used to describe documents in the vector space model and the applications related to text mining and information retrieval, can effectively reflect the importance of the term in the collection of documents, in which all documents play the same roles. But, TF-IDF does not take into account the difference of term IDF weighting if the documents play different roles in the collection of documents, such as positive and negative training set in text classification. In view of the aforementioned text, this paper presents a novel TF-IDF-improved feature weighting approach, which reflects the importance of the term in the positive and the negative training examples, respectively. We also build a weighted voting classifier by iteratively applying the support vector machine algorithm and implement one-class support vector machine and Positive Example Based Learning methods used for comparison. During classifying, an improved 1-DNF algorithm, called 1-DNFC, is also adopted, aiming at identifying more reliable negative documents from the unlabeled examples set. The experimental results show that the performance of term frequency inverse positive-negative document frequency-based classifier outperforms that of TF-IDF-based one, and the performance of weighted voting classifier also exceeds that of one-class support vector machine-based classifier and Positive Example Based Learning-based classifier. Copyright (c) 2013 John Wiley & Sons, Ltd.", "paper_title": "PU text classification enhanced by term frequency-inverse document frequency-improved weighting", "paper_id": "WOS:000331020300006"}