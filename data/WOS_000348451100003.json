{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "hierarchical_parallel_genetic_algorithms"}, {"score": 0.0046069985410261746, "phrase": "comprehensive_methodology"}, {"score": 0.0044922081848067135, "phrase": "design_problem"}, {"score": 0.0044079880067019765, "phrase": "fuzzy_artmap_neural_network"}, {"score": 0.004112411350177274, "phrase": "training_data"}, {"score": 0.00406083086983316, "phrase": "supervised_learning"}, {"score": 0.004009894739765119, "phrase": "optimum_parameter_tuning"}, {"score": 0.0038853212888610234, "phrase": "baseline_vigilance"}, {"score": 0.0038124354878360032, "phrase": "genetic_algorithm_search_heuristic"}, {"score": 0.0036707250689857348, "phrase": "multi-objective_optimization_problem"}, {"score": 0.0035342634200440435, "phrase": "artmap's_pattern_classification_ability"}, {"score": 0.0033814348757887232, "phrase": "genetic_algorithm"}, {"score": 0.003276321257403678, "phrase": "classifier_ensemble"}, {"score": 0.0032148229832850215, "phrase": "optimal_ensemble"}, {"score": 0.0031148723927633955, "phrase": "inter-classifier_diversity"}, {"score": 0.0029427043216782604, "phrase": "mitigating_convergence"}, {"score": 0.002887450071878095, "phrase": "genetic_algorithms"}, {"score": 0.002815383690003621, "phrase": "hierarchical_parallel_architecture"}, {"score": 0.0027625134766418266, "phrase": "best-performing_classifiers"}, {"score": 0.002609770322855842, "phrase": "probabilistic_voting"}, {"score": 0.002576988153314685, "phrase": "decision_combination"}, {"score": 0.0024654516678953658, "phrase": "disparate_methods"}, {"score": 0.0023887436047824386, "phrase": "single_framework"}, {"score": 0.0023144166368024586, "phrase": "proposed_novel_method"}, {"score": 0.002256619934086924, "phrase": "optimum_classifier_ensemble_configuration"}, {"score": 0.002228263890334039, "phrase": "minimum_user_intervention"}, {"score": 0.0021317885325570604, "phrase": "popular_data_sets"}, {"score": 0.0021049977753042253, "phrase": "uci_machine_learning_repository"}], "paper_keywords": ["Ensembles", " Fuzzy ARTMAP", " Plurality voting", " Parallel genetic algorithm", " Feature selection"], "paper_abstract": "In this study, a comprehensive methodology for overcoming the design problem of the Fuzzy ARTMAP neural network is proposed. The issues addressed are the sequence of training data for supervised learning and optimum parameter tuning for parameters such as baseline vigilance. A genetic algorithm search heuristic was chosen to solve this multi-objective optimization problem. To further augment the ARTMAP's pattern classification ability, multiple ARTMAPs were optimized via genetic algorithm and assembled into a classifier ensemble. An optimal ensemble was realized by the inter-classifier diversity of its constituents. This was achieved by mitigating convergence in the genetic algorithms by employing a hierarchical parallel architecture. The best-performing classifiers were then combined in an ensemble, using probabilistic voting for decision combination. This study also integrated the disparate methods to operate within a single framework, which is the proposed novel method for creating an optimum classifier ensemble configuration with minimum user intervention. The methodology was benchmarked using popular data sets from UCI machine learning repository.", "paper_title": "Probabilistic ensemble Fuzzy ARTMAP optimization using hierarchical parallel genetic algorithms", "paper_id": "WOS:000348451100003"}