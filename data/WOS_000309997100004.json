{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "virtual_human"}, {"score": 0.02958368726755707, "phrase": "listener_responses"}, {"score": 0.004273601449537163, "phrase": "attentive_speaker"}, {"score": 0.00317095235382607, "phrase": "new_developments"}, {"score": 0.0028623555849897632, "phrase": "multimodal_behavior"}, {"score": 0.0025183881730011597, "phrase": "appropriate_reactions"}, {"score": 0.0022731540640627307, "phrase": "task-based_setup"}, {"score": 0.002215663255682209, "phrase": "responsive_virtual_human"}], "paper_keywords": ["Virtual humans", " Attentive speaking", " Listener responses", " Continuous interaction"], "paper_abstract": "This paper presents our progress in developing a Virtual Human capable of being an attentive speaker. Such a Virtual Human should be able to attend to its interaction partner while it is speaking-and modify its communicative behavior on-the-fly based on what it observes in the behavior of its partner. We report new developments concerning a number of aspects, such as scheduling and interrupting multimodal behavior, automatic classification of listener responses, generation of response eliciting behavior, and strategies for generating appropriate reactions to listener responses. On the basis of this progress, a task-based setup for a responsive Virtual Human was implemented to carry out two user studies, the results of which are presented and discussed in this paper.", "paper_title": "Continuous interaction with a virtual human", "paper_id": "WOS:000309997100004"}