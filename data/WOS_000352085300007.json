{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-camera_tracking"}, {"score": 0.0047292449487169345, "phrase": "unmanned_aerial_vehicles"}, {"score": 0.004686963264680882, "phrase": "unstructured_environments"}, {"score": 0.004582897918101983, "phrase": "small_unmanned_aerial_vehicles"}, {"score": 0.004521566043596533, "phrase": "large_improvements"}, {"score": 0.003951453722517865, "phrase": "power_consumption"}, {"score": 0.003611751858608048, "phrase": "useful_information"}, {"score": 0.003499864176875713, "phrase": "pose_estimation_problem"}, {"score": 0.003361069456060196, "phrase": "cameras'_field"}, {"score": 0.0031559919178954644, "phrase": "multi-camera_egomotion_estimation"}, {"score": 0.0029901699209266435, "phrase": "multiple_cameras"}, {"score": 0.00277001889871322, "phrase": "multi-camera_visual_pose_estimator"}, {"score": 0.0027452053065200152, "phrase": "ultra_wide_angle_fisheye_cameras"}, {"score": 0.002624423288947767, "phrase": "traditional_visual_pose_estimators"}, {"score": 0.0024864612830452254, "phrase": "flight_scenarios"}, {"score": 0.002453116398642071, "phrase": "unprepared_urban_rooftop"}, {"score": 0.002313701040445819, "phrase": "first_time"}, {"score": 0.002292965705677312, "phrase": "visual_pose_estimator"}, {"score": 0.0021529183360603434, "phrase": "small_aerial_vehicle"}, {"score": 0.0021049977753042253, "phrase": "subsequent_takeoff_maneuvers"}], "paper_keywords": ["Multi-camera", " Tracking", " Mapping", " Visual SLAM", " Omnidirectional", " Fisheye", " UAV", " Takeoff", " Landing"], "paper_abstract": "Pose estimation for small unmanned aerial vehicles has made large improvements in recent years, leading to vehicles that use a suite of sensors to navigate and explore various environments. In particular, cameras have become popular due to their low weight and power consumption, as well as the large amount of data they capture. However, processing this data to extract useful information has proved challenging, as the pose estimation problem is inherently nonlinear and, depending on the cameras' field of view, potentially ill-posed. Results from the field of multi-camera egomotion estimation show that these issues can be reduced or eliminated by using multiple cameras positioned appropriately. In this work, we make use of these insights to develop a multi-camera visual pose estimator using ultra wide angle fisheye cameras, leading to a system that has many advantages over traditional visual pose estimators. The system is tested in a variety of configurations and flight scenarios on an unprepared urban rooftop, including landings and takeoffs. To our knowledge, this is the first time a visual pose estimator has been shown to be able to continuously track the pose of a small aerial vehicle throughout the landing and subsequent takeoff maneuvers.", "paper_title": "Multi-Camera Tracking and Mapping for Unmanned Aerial Vehicles in Unstructured Environments", "paper_id": "WOS:000352085300007"}