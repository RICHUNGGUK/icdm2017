{"auto_keywords": [{"score": 0.033803903176279494, "phrase": "mfcc"}, {"score": 0.004833906824323787, "phrase": "eer"}, {"score": 0.00481495049065317, "phrase": "short_utterance_speaker_recognition"}, {"score": 0.004742730438544081, "phrase": "human_speaker_recognition_expert"}, {"score": 0.00464811139983244, "phrase": "speech_spectrogram"}, {"score": 0.004601508848655033, "phrase": "multiple_different_scales"}, {"score": 0.004555371402128666, "phrase": "speaker_recognition"}, {"score": 0.004442032546224076, "phrase": "short_utterance_condition"}, {"score": 0.004202472962684885, "phrase": "novel_multi-resolution_time_frequency_feature"}, {"score": 0.003780286517897356, "phrase": "time_frequency_spectrogram_matrix"}, {"score": 0.00363080961099728, "phrase": "final_multi-scaled_transformed_elements"}, {"score": 0.003366233863411861, "phrase": "multi-resolution_temporal-frequency_information"}, {"score": 0.0031684791285366315, "phrase": "mrtf"}, {"score": 0.0031208772639433145, "phrase": "feature_level"}, {"score": 0.003058515297281172, "phrase": "-vector_level"}, {"score": 0.003012560489169148, "phrase": "score_level"}, {"score": 0.0028933521924166287, "phrase": "best_results"}, {"score": 0.002524688179363081, "phrase": "short_utterance"}, {"score": 0.002486734224234698, "phrase": "long_utterance"}, {"score": 0.002214048743052355, "phrase": "male_dataset"}, {"score": 0.0021049977753042253, "phrase": "best_reported_result"}], "paper_keywords": ["Multi-resolution time frequency feature", " I-vector", " Complementary combination", " Speaker recognition", " Short utterance"], "paper_abstract": "A human speaker recognition expert often observes the speech spectrogram in multiple different scales for speaker recognition, especially under the short utterance condition. Inspired by this action, this paper proposes a novel multi-resolution time frequency feature (MRTF) extraction method, which is obtained by performing a 2-Dimensional discrete cosine transform (DCT) in multi-scale on the time frequency spectrogram matrix and then selecting and combining to the final multi-scaled transformed elements. Compared to the traditional Mel-Frequency Cepstral Coefficient (MFCC) feature extraction, the proposed method can make better use of multi-resolution temporal-frequency information. Beyond this, we also proposed three complementary combination strategies of MFCC and MRTF: in feature level, in i-vector level and in score level. Comparing their performance. We found the best results are obtained by combination in i-vector level. In the three NIST 2008 Speaker Recognition Evaluation datasets, the proposed method is the most effective for improving the performance under short utterance than under long utterance. And after the combination, we can achieve an EER of 11.32 % and MinDCF of 0.054 in the 10sec-10sec trials on the male dataset, which is an absolute 3 % improvement of EER than the best reported result in this field.", "paper_title": "Multi-resolution time frequency feature and complementary combination for short utterance speaker recognition", "paper_id": "WOS:000349356400013"}