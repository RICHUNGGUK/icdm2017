{"auto_keywords": [{"score": 0.03940660329523235, "phrase": "asr"}, {"score": 0.013565380591158907, "phrase": "nsc"}, {"score": 0.011591159548537174, "phrase": "mfcc"}, {"score": 0.00481495049065317, "phrase": "noise_robust_asr"}, {"score": 0.004729856080441582, "phrase": "multisource_environments"}, {"score": 0.0046739596755881185, "phrase": "convolutive_nmf"}, {"score": 0.004618720776729413, "phrase": "long_short-term_memory"}, {"score": 0.004275173711009189, "phrase": "bidirectional_long_short-term_memory"}, {"score": 0.004174677062711731, "phrase": "temporal_context_modeling"}, {"score": 0.004052358316137446, "phrase": "automatic_speech_recognition"}, {"score": 0.003933609372601274, "phrase": "noisy_and_reverberated_environments"}, {"score": 0.0038411109150557504, "phrase": "recent_advances"}, {"score": 0.003795677450778112, "phrase": "long_short-term_memory_architectures"}, {"score": 0.0036408354779365643, "phrase": "novel_front-end"}, {"score": 0.0035977623578676496, "phrase": "context-sensitive_tandem_feature_extraction"}, {"score": 0.003369778677878286, "phrase": "blstm-based_back-end"}, {"score": 0.003290494847464381, "phrase": "hidden_markov_models"}, {"score": 0.0031561961485589633, "phrase": "context-sensitive_blstm-based_feature_generation"}, {"score": 0.002991524908432975, "phrase": "convolutive_non-negative_matrix_factorization"}, {"score": 0.0028865314258560214, "phrase": "multi-stream_hmm_framework"}, {"score": 0.0027852126030055305, "phrase": "nmf-enhanced_speech"}, {"score": 0.002719644855867468, "phrase": "word_predictions"}, {"score": 0.0026714812866037584, "phrase": "blstm_networks"}, {"score": 0.002639845784408318, "phrase": "non-negative_sparse_classification"}, {"score": 0.0025169965861573185, "phrase": "average_accuracy"}, {"score": 0.0024431289979171505, "phrase": "pascal_chime_challenge_task"}, {"score": 0.002414191082427217, "phrase": "signal-to-noise_ratios"}, {"score": 0.0022476051902301187, "phrase": "best_result"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Automatic speech recognition", " Long Short-Term Memory", " Non-negative matrix factorization", " Tandem feature extraction"], "paper_abstract": "This article proposes and evaluates various methods to integrate the concept of bidirectional Long Short-Term Memory (BLSTM) temporal context modeling into a system for automatic speech recognition (ASR) in noisy and reverberated environments. Building on recent advances in Long Short-Term Memory architectures for ASR, we design a novel front-end for context-sensitive Tandem feature extraction and show how the Connectionist Temporal Classification approach can be used as a BLSTM-based back-end, alternatively to Hidden Markov Models (HMM). We combine context-sensitive BLSTM-based feature generation and speech decoding techniques with source separation by convolutive non-negative matrix factorization. Applying our speaker adapted multi-stream HMM framework that processes MFCC features from NMF-enhanced speech as well as word predictions obtained via BLSTM networks and non-negative sparse classification (NSC), we obtain an average accuracy of 91.86% on the PASCAL CHiME Challenge task at signal-to-noise ratios ranging from -6 to 9 dB. To our knowledge, this is the best result ever reported for the CHiME Challenge task. (c) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Noise robust ASR in reverberated multisource environments applying convolutive NMF and Long Short-Term Memory", "paper_id": "WOS:000314741500010"}