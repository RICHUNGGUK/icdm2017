{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "short_texts"}, {"score": 0.010304246687739802, "phrase": "stc"}, {"score": 0.005438235764129297, "phrase": "classification_effectiveness"}, {"score": 0.004779406424192843, "phrase": "structured_sparse_representation"}, {"score": 0.004744123493964429, "phrase": "dictionary_filtering"}, {"score": 0.0047090997998449095, "phrase": "short_text_classification"}, {"score": 0.004605565335682916, "phrase": "increasing_interest"}, {"score": 0.004537804310268603, "phrase": "rapid_growth"}, {"score": 0.00450429688285697, "phrase": "web_and_social_media_data"}, {"score": 0.004454497011118188, "phrase": "short_text_form"}, {"score": 0.0043404186974790706, "phrase": "traditional_text_classification"}, {"score": 0.00430895464006555, "phrase": "tc"}, {"score": 0.004229249483672161, "phrase": "feature_sparsity"}, {"score": 0.00418247778205288, "phrase": "processed_short_texts"}, {"score": 0.004060256280654948, "phrase": "art_tc_approaches"}, {"score": 0.0038263829059336564, "phrase": "sparse_problem"}, {"score": 0.0037700424606538856, "phrase": "text_content"}, {"score": 0.0037421829222825964, "phrase": "outer_corpora"}, {"score": 0.0037145284903339327, "phrase": "additional_information"}, {"score": 0.0036734281414482735, "phrase": "better_performance"}, {"score": 0.003474624627033273, "phrase": "outer_or_additional_information"}, {"score": 0.0032743731084995515, "phrase": "high_cost"}, {"score": 0.0031317713853981064, "phrase": "structured_sparse_representation_classifier"}, {"score": 0.0030288982511487835, "phrase": "effective_approach"}, {"score": 0.0029402874300114537, "phrase": "data_correlation"}, {"score": 0.0028331500847209984, "phrase": "training_texts"}, {"score": 0.002760478838718213, "phrase": "stc_efficiency"}, {"score": 0.002630414143385786, "phrase": "first_work"}, {"score": 0.0026012779346272848, "phrase": "structured_sparsity"}, {"score": 0.002582032847722892, "phrase": "stc._experiments"}, {"score": 0.002534539169474629, "phrase": "proposed_approach"}, {"score": 0.0024786956187352327, "phrase": "art_tc_methods"}, {"score": 0.0024330980793680337, "phrase": "traditional_sr_classifier"}, {"score": 0.002388337333984138, "phrase": "classification_efficiency"}, {"score": 0.002267329954548889, "phrase": "additional_content"}, {"score": 0.002176560171729638, "phrase": "existing_sic_methods"}, {"score": 0.002152440300818582, "phrase": "external_text_sources"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Short text classification", " Sparse representation", " Group sparsity", " Dictionary filtering"], "paper_abstract": "Short text classification (STC) has attracted increasing interest recently with the rapid growth of Web and social media data existing in short text form. It is a more challenging task than traditional text classification (TC) because of the feature sparsity of the processed short texts, which makes the state of the art TC approaches perform poorly on short texts if being applied straightforwardly. Existing STC approaches deal with the sparse problem mainly by enriching text content with outer corpora or additional information. Though better performance can be obtained, the performance heavily relies on the amount and quality of outer or additional information. What is worse, such outer or additional information is not always available, not to mention the high cost for acquiring such information. In this paper, we introduce a structured sparse representation classifier to effectively classify short texts, and develop an effective approach called convex hull vertices selection to reduce data correlation and redundancy of the dictionary (the set of training texts), which thus substantially boosts STC efficiency and performance. To the best of our knowledge, this is the first work that exploits structured sparsity for STC. Experiments over five datasets show that the proposed approach outperforms the state of the art TC methods in classification effectiveness and the traditional SR classifier in both classification effectiveness and classification efficiency. Furthermore, we carry out an experiment to classify short texts expanded by additional content, which indirectly shows that our approach performs better than the existing SIC methods that exploit external text sources. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Effectively classifying short texts by structured sparse representation with dictionary filtering", "paper_id": "WOS:000362307100009"}