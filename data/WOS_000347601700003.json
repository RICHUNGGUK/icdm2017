{"auto_keywords": [{"score": 0.036085589662484915, "phrase": "p_-_f"}, {"score": 0.03424697573466403, "phrase": "fractional_polynomial"}, {"score": 0.029015767395547738, "phrase": "high_probability"}, {"score": 0.026258210921664, "phrase": "message_complexity"}, {"score": 0.00481495049065317, "phrase": "undependable_workers"}, {"score": 0.00478768880281476, "phrase": "decentralized_network_supercomputing"}, {"score": 0.004760580729109124, "phrase": "internet_supercomputing"}, {"score": 0.00458806383414443, "phrase": "vast_number"}, {"score": 0.004562080863250721, "phrase": "interconnected_computers"}, {"score": 0.004485007534408526, "phrase": "new_algorithm"}, {"score": 0.004347057700479576, "phrase": "large_collection"}, {"score": 0.004322433660826523, "phrase": "independent_tasks"}, {"score": 0.0042614794708537235, "phrase": "undependable_processors"}, {"score": 0.004142126987434192, "phrase": "bogus_results"}, {"score": 0.00402610372759447, "phrase": "subset_f"}, {"score": 0.003991932110277654, "phrase": "initial_set"}, {"score": 0.003750012556296276, "phrase": "crashed_processors"}, {"score": 0.0036866077729419784, "phrase": "average_probability"}, {"score": 0.0036242711304204076, "phrase": "bogus_result"}, {"score": 0.003004160926679449, "phrase": "n_processors"}, {"score": 0.0028542251004668156, "phrase": "live_processor"}, {"score": 0.00256905228394684, "phrase": "log_log"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Distributed algorithms", " Fault-tolerance", " Internet supercomputing"], "paper_abstract": "Internet supercomputing is an approach to solving partitionable, computation-intensive problems by harnessing the power of a vast number of interconnected computers. This paper presents a new algorithm for the problem of using network supercomputing to perform a large collection of independent tasks, while dealing with undependable processors. The adversary may cause the processors to return bogus results for tasks with certain probabilities, and may cause a subset F of the initial set of processors P to crash. The adversary is constrained in two ways. First, for the set of non-crashed processors P - F, the average probability of a processor returning a bogus result is inferior to 1/2 Second, the adversary may crash a subset of processors F, provided the size of P - F is bounded from below. We consider two models: the first bounds the size of P - F by a fractional polynomial, the second bounds this size by a poly-logarithm. Both models yield adversaries that are much stronger than previously studied. Our randomized synchronous algorithm is formulated for n processors and t tasks, with n <= t, where depending on the number of crashes each live processor is able to terminate dynamically with the knowledge that the problem is solved with high probability. For the adversary constrained by a fractional polynomial, the round complexity of the algorithm is O (t/n(epsilon) log n log log n), its work is O (t log n log log n) and message complexity is O (n log n log log n). For the poly-log constrained adversary, the round complexity is O (t), work is O (tn(epsilon)), and message complexity is O (n(1+epsilon)). All bounds are shown to hold with high probability. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Dealing with undependable workers in decentralized network supercomputing", "paper_id": "WOS:000347601700003"}