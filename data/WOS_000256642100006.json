{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "control_knowledge"}, {"score": 0.046847070735126436, "phrase": "forward_state-space_search"}, {"score": 0.0047797212183363835, "phrase": "forward_search_planning"}, {"score": 0.004312622975366676, "phrase": "computing_domain"}, {"score": 0.004007083686875716, "phrase": "poor_guidance"}, {"score": 0.003948613642680196, "phrase": "planning_failure"}, {"score": 0.0037094500688222695, "phrase": "domain-specific_knowledge"}, {"score": 0.0036553070575015344, "phrase": "forward_search"}, {"score": 0.0035233696341819437, "phrase": "large_body"}, {"score": 0.003471933181807712, "phrase": "inductive_learning"}, {"score": 0.003421245054271364, "phrase": "ai_planning"}, {"score": 0.003297728079517964, "phrase": "forward-state-space_search"}, {"score": 0.0031207372860045427, "phrase": "knowledge_representation"}, {"score": 0.0030751605843937673, "phrase": "important_concepts"}, {"score": 0.0030414140732789186, "phrase": "wide_range"}, {"score": 0.0029641011108505785, "phrase": "main_contributions"}, {"score": 0.002878140062594849, "phrase": "novel_feature_space"}, {"score": 0.0028153046221865386, "phrase": "key_idea"}, {"score": 0.0027036380093304747, "phrase": "relaxed_plan_extraction"}, {"score": 0.0026446021865907197, "phrase": "major_source"}, {"score": 0.0026059610060579145, "phrase": "non-learning_planners"}, {"score": 0.002558450494671067, "phrase": "new_way"}, {"score": 0.002530359917257626, "phrase": "relaxed_planning_techniques"}, {"score": 0.00244792069601419, "phrase": "feature_space"}, {"score": 0.0023944552329463035, "phrase": "control_knowledge-reactive_policies"}, {"score": 0.0022994427535192514, "phrase": "linear_heuristics"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_non-learning_planners"}], "paper_keywords": ["planning", " machine learning", " knowledge representation", " search"], "paper_abstract": "A number of today's state-of-the-art planners are based on forward state-space search. The impressive performance can be attributed to progress in computing domain independent heuristics that perform well across many domains. However, it is easy to find domains where such heuristics provide poor guidance, leading to planning failure. Motivated by such failures, the focus of this paper is to investigate mechanisms for learning domain-specific knowledge to better control forward search in a given domain. While there has been a large body of work on inductive learning of control knowledge for AI planning, there is a void of work aimed at forward-state-space search. One reason for this may be that it is challenging to specify a knowledge representation for compactly representing important concepts across a wide range of domains. One of the main contributions of this work is to introduce a novel feature space for representing such control knowledge. The key idea is to define features in terms of information computed via relaxed plan extraction, which has been a major source of success for non-learning planners. This gives a new way of leveraging relaxed planning techniques in the context of learning. Using this feature space, we describe three forms of control knowledge-reactive policies (decision list rules and measures of progress) and linear heuristics-and show how to learn them and incorporate them into forward state-space search. Our empirical results show that our approaches are able to surpass state-of-the-art non-learning planners across a wide range of planning competition domains.", "paper_title": "Learning control knowledge for forward search planning", "paper_id": "WOS:000256642100006"}