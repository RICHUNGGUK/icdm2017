{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "correct_classification"}, {"score": 0.03972278524435738, "phrase": "posterior_probability"}, {"score": 0.032300927701088396, "phrase": "test_object"}, {"score": 0.004726382602809228, "phrase": "probabilistic_bagged_k-nearest_neighbours"}, {"score": 0.0044702911400353535, "phrase": "new_method"}, {"score": 0.003678023470672862, "phrase": "new_object"}, {"score": 0.0029152570900178956, "phrase": "training_objects"}, {"score": 0.0025121156016001886, "phrase": "calibration_space"}, {"score": 0.0024429654627197393, "phrase": "classical_measure"}, {"score": 0.0021049977753042253, "phrase": "new_rule"}], "paper_keywords": ["Classification", " Nearest neighbours", " Bootstrap", " Probability of classification", " Reliability"], "paper_abstract": "This paper presents a new method for computing the probability of correct classification for the k-Nearest Neighbours (kNN) method. The method uses bootstrap to provide the posterior probability which a new object is classified with. This is a measure of the reliability of the classification: it increases as the test object is closer to the training objects of a given class and is more sensitive to the position of the test object in the calibration space than the classical measure of posterior probability in kNN. This reliability of the classification is also used to derive a new rule for classification. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Calculation of the probability of correct classification in probabilistic bagged k-Nearest Neighbours", "paper_id": "WOS:000263443400006"}