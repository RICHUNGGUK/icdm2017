{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "speech-based_recognition"}, {"score": 0.004589124394375718, "phrase": "dimensional_space"}, {"score": 0.004480196733208298, "phrase": "self-reported_and_observed_emotion"}, {"score": 0.004270003565426343, "phrase": "speech-based_automatic_emotion_recognition"}, {"score": 0.004108942392772092, "phrase": "self-reported_emotion_ratings"}, {"score": 0.003714368305523811, "phrase": "automatic_emotion_recognizers"}, {"score": 0.0035914198812657897, "phrase": "dimensional_approach"}, {"score": 0.0033900126423990823, "phrase": "continuous_arousal"}, {"score": 0.0033575566897536906, "phrase": "valence_scales"}, {"score": 0.0032777653153451265, "phrase": "tno-gaming_corpus"}, {"score": 0.0032308006242867224, "phrase": "spontaneous_vocal_and_facial_expressions"}, {"score": 0.003169222811082848, "phrase": "multiplayer_videogame"}, {"score": 0.003108814986752103, "phrase": "emotion_annotations"}, {"score": 0.0028784478769295204, "phrase": "self-reported_and_observed_emotion_ratings"}, {"score": 0.0027431953780099826, "phrase": "emotion_recognizers"}, {"score": 0.002690886043654469, "phrase": "support_vector_regression"}, {"score": 0.0026395715432958665, "phrase": "acoustic_and_textual_features"}, {"score": 0.002340250894008014, "phrase": "self-reported_emotion"}, {"score": 0.002251813863195168, "phrase": "observed_emotion"}, {"score": 0.002208853811052348, "phrase": "averaging_ratings"}, {"score": 0.0021876814398268775, "phrase": "multiple_observers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Affective computing", " Automatic emotion recognition", " Emotional speech", " Emotion database", " Audiovisual database", " Emotion perception", " Emotion annotation", " Emotion elicitation", " Videogames", " Support Vector Regression"], "paper_abstract": "The differences between self-reported and observed emotion have only marginally been investigated in the context of speech-based automatic emotion recognition. We address this issue by comparing self-reported emotion ratings to observed emotion ratings and look at how differences between these two types of ratings affect the development and performance of automatic emotion recognizers developed with these ratings. A dimensional approach to emotion modeling is adopted: the ratings are based on continuous arousal and valence scales. We describe the TNO-Gaming Corpus that contains spontaneous vocal and facial expressions elicited via a multiplayer videogame and that includes emotion annotations obtained via self-report and observation by outside observers. Comparisons show that there are discrepancies between self-reported and observed emotion ratings which are also reflected in the performance of the emotion recognizers developed. Using Support Vector Regression in combination with acoustic and textual features, recognizers of arousal and valence are developed that can predict points in a 2-dimensional arousal-valence space. The results of these recognizers show that the self-reported emotion is much harder to recognize than the observed emotion, and that averaging ratings from multiple observers improves performance. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Speech-based recognition of self-reported and observed emotion in a dimensional space", "paper_id": "WOS:000307419400005"}