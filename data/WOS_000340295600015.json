{"auto_keywords": [{"score": 0.004112175423546628, "phrase": "proposed_watermarking_algorithm"}, {"score": 0.0040508247605225214, "phrase": "extremely_efficient_watermark"}, {"score": 0.00396050388346298, "phrase": "simple_bit_substitutions"}, {"score": 0.003673675864705682, "phrase": "motion_vector_differences"}, {"score": 0.0036188435232325337, "phrase": "non-reference_frames"}, {"score": 0.003407549468745519, "phrase": "applications_scenarios"}, {"score": 0.0031606404966938568, "phrase": "bitstream_units"}, {"score": 0.002953711377604328, "phrase": "watermark_detection"}, {"score": 0.0028661330049356186, "phrase": "image_domain"}, {"score": 0.0027395968397212053, "phrase": "video_format_changes"}, {"score": 0.0024105326885334962, "phrase": "quality_evaluation"}, {"score": 0.0023214774334744713, "phrase": "subjective_evaluations"}, {"score": 0.0021049977753042253, "phrase": "superior_performance"}], "paper_keywords": ["Video watermarking", " H.264", " compressed video", " information hiding", " data embedding", " video quality", " subjective quality"], "paper_abstract": "In this work we propose a novel non-blind H.264/CAVLC structure-preserving substitution watermarking algorithm. The proposed watermarking algorithm enables extremely efficient watermark embedding by simple bit substitutions (substitution watermarking). The bit-substitutions change the motion vector differences of non-reference frames. Furthermore our watermarking algorithm can be applied in applications scenarios which require that watermarking preserves the length of the bitstream units (structure-preserving watermarking). The watermark detection works in the image domain and thus is robust to video format changes. The quality and robustness of the approach are in depth evaluated and analyzed, the quality evaluation is backed up by subjective evaluations. Comparison to the state-of-the-art indicates a superior performance of our watermarking algorithm.", "paper_title": "Non-Blind Structure-Preserving Substitution Watermarking of H.264/CAVLC Inter-Frames", "paper_id": "WOS:000340295600015"}