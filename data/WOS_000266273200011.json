{"auto_keywords": [{"score": 0.03983926434466607, "phrase": "floating-point_numbers"}, {"score": 0.004342430078306461, "phrase": "fixed_finite_precision"}, {"score": 0.0036167509502276294, "phrase": "computed_result"}, {"score": 0.0033937776228549557, "phrase": "twice_the_working_precision"}, {"score": 0.00252812242767189, "phrase": "triangular_matrix"}, {"score": 0.0023346234464901978, "phrase": "root_product_form"}, {"score": 0.0021559025985688255, "phrase": "integer_power"}, {"score": 0.0021049977753042253, "phrase": "floating-point_number"}], "paper_keywords": ["Accurate product", " exponentiation", " finite precision", " floating-point arithmetic", " faithful rounding", " error-free transformations"], "paper_abstract": "Several different techniques and softwares intend to improve the accuracy of results computed in a fixed finite precision. Here, we focus on a method to improve the accuracy of the product of floating-point numbers. We show that the computed result is as accurate as if computed in twice the working precision. The algorithm is simple since it only requires addition, subtraction, and multiplication of floating-point numbers in the same working precision as the given data. Such an algorithm can be useful for example to compute the determinant of a triangular matrix and to evaluate a polynomial when represented by the root product form. It can also be used to compute the integer power of a floating-point number.", "paper_title": "Accurate Floating-Point Product and Exponentiation", "paper_id": "WOS:000266273200011"}