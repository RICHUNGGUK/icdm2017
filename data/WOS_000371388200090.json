{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "training_videos"}, {"score": 0.00843402294949598, "phrase": "user_preferences"}, {"score": 0.007591816902452573, "phrase": "web_videos"}, {"score": 0.004780030485538593, "phrase": "fully_automated_application-specific_classification"}, {"score": 0.004575740812937594, "phrase": "content_or_social_network_connections"}, {"score": 0.004493207015584002, "phrase": "personalized_advertisements"}, {"score": 0.004285489630701221, "phrase": "customized_personalization_applications"}, {"score": 0.004223521213460728, "phrase": "growing_popularity"}, {"score": 0.004042919099733537, "phrase": "application-specific_categories"}, {"score": 0.003998983496539902, "phrase": "different_applications"}, {"score": 0.003941141575848601, "phrase": "different_aspects"}, {"score": 0.0038559375376635047, "phrase": "key_requirement"}, {"score": 0.0038279459368975965, "phrase": "supervised_classification_models"}, {"score": 0.003664196785572724, "phrase": "arbitrary_application-specific_categories"}, {"score": 0.00350742771604554, "phrase": "completely_automated_framework"}, {"score": 0.0034692911858848893, "phrase": "training_web_videos"}, {"score": 0.0034440966820590024, "phrase": "arbitrary_categories"}, {"score": 0.0033451289921748407, "phrase": "manual_labeling"}, {"score": 0.0024987660207458555, "phrase": "human_input"}, {"score": 0.0024715695446993107, "phrase": "tune_parameters"}, {"score": 0.002314481096847367, "phrase": "automated_framework"}, {"score": 0.002272641094287882, "phrase": "application-specific_categorization"}, {"score": 0.002215329893200788, "phrase": "proposed_approaches"}, {"score": 0.002183230464873613, "phrase": "substantial_improvement"}, {"score": 0.0021437580456873584, "phrase": "classification_models"}], "paper_keywords": ["Obtain training data", " metadata based video classification"], "paper_abstract": "Personalization approaches seek to estimate user preferences in order to recommend content or social network connections, or to serve personalized advertisements to users. Such approaches are being increasingly adopted by organizations to build customized personalization applications. Leveraging the growing popularity of Web videos for such approaches necessitates the ability to classify Web videos into application-specific categories, since different applications are interested in different aspects of the user preferences. A key requirement of supervised classification models to address this is the availability of training videos labeled to the arbitrary application-specific categories. In order to address this requirement, we propose a completely automated framework to obtain training Web videos for arbitrary categories, which does not rely on any manual labeling of videos. This is achieved utilizing keywords to retrieve training videos, thereby simplifying the problem of obtaining training videos to the problem of selecting keywords to retrieve them. We show that there are two opposing objectives (proximity and diversity) that need to be considered while developing such keyword selection techniques. We propose two efficient approaches (linear combination of proximity and diversity and annealing-based alternating optimization) and study the tradeoffs between them, with respect to performance and the human input required to tune parameters of the approach. Through experiments over several sets of categories, we demonstrate the feasibility of the automated framework to select training videos for application-specific categorization. We also show that the proposed approaches lead to a substantial improvement in the performance of classification models, as compared with other automated methods.", "paper_title": "Methods to Obtain Training Videos for Fully Automated Application-Specific Classification", "paper_id": "WOS:000371388200090"}