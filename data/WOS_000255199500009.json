{"auto_keywords": [{"score": 0.012144421495881463, "phrase": "overlay_tree"}, {"score": 0.009686836650961737, "phrase": "measurement_redundancy"}, {"score": 0.008964713233307126, "phrase": "computational_overhead"}, {"score": 0.00481495049065317, "phrase": "efficient_overlay_network"}, {"score": 0.004645057834614705, "phrase": "end-to-end_measurement_tools"}, {"score": 0.004548723130053278, "phrase": "underlay_topology"}, {"score": 0.0044277810648955624, "phrase": "max-delta"}, {"score": 0.004335932873514455, "phrase": "highly_accurate_topology"}, {"score": 0.00429715240295033, "phrase": "low_number"}, {"score": 0.004220624516321415, "phrase": "max-_delta"}, {"score": 0.0041703614123283165, "phrase": "central_server"}, {"score": 0.004133055661437163, "phrase": "traceroute_results"}, {"score": 0.003951453722517865, "phrase": "large_groups"}, {"score": 0.00384633057714983, "phrase": "distributed_inference_scheme"}, {"score": 0.0038119123317396954, "phrase": "scalable_inference"}, {"score": 0.003371159698962328, "phrase": "partially_discovered_topology"}, {"score": 0.003311067956326299, "phrase": "key_issue"}, {"score": 0.0032132782979796895, "phrase": "low-diameter_overlay_tree"}, {"score": 0.0030904433394138963, "phrase": "measurement_cost"}, {"score": 0.003071965703296204, "phrase": "topology_inference"}, {"score": 0.0029991500396912923, "phrase": "doubletree_algorithm"}, {"score": 0.002893140560765452, "phrase": "lookup_table"}, {"score": 0.0028500803748621175, "phrase": "traceroute_size"}, {"score": 0.0027992509096654754, "phrase": "topology_abstraction"}, {"score": 0.002765867822046626, "phrase": "computational_frequency"}, {"score": 0.0026841368358805407, "phrase": "naive_max-_delta"}, {"score": 0.002604814679863312, "phrase": "computational_loads"}, {"score": 0.0025892330566358503, "phrase": "target_selection"}, {"score": 0.0025278307267360216, "phrase": "single_server"}, {"score": 0.0024093494406195386, "phrase": "edge_bandwidth"}, {"score": 0.0023171750718791713, "phrase": "internet-like_topologies"}, {"score": 0.0022352169832099153, "phrase": "constructed_tree"}, {"score": 0.0022151834590200953, "phrase": "low_diameter"}, {"score": 0.002188750508959063, "phrase": "quick_data_exchange"}, {"score": 0.002143247921132179, "phrase": "proposed_improvements"}, {"score": 0.0021049977753042253, "phrase": "bandwidth_consumption"}], "paper_keywords": ["topology inference", " topology discovery", " end-to-end measurement", " measurement cost"], "paper_abstract": "To construct an efficient overlay network, the information of underlay is important. We consider using end-to-end measurement tools such as traceroute to infer the underlay topology among a group of hosts. Previously, Max-Delta has been proposed to infer a highly accurate topology with a low number of traceroutes. However, Max- Delta relies on a central server to collect traceroute results and to select paths for hosts to traceroute. It is not scalable to large groups. In this paper, we investigate a distributed inference scheme to support scalable inference. In our scheme, each host joins an overlay tree before conducting traceroute. A host then independently selects paths for tracerouting and exchanges traceroute results with others through the overlay tree. As a result, each host can maintain a partially discovered topology. We have studied the key issue in the scheme, that is, how a low-diameter overlay tree can be constructed. Furthermore, we propose several techniques to reduce the measurement cost for topology inference. They include 1) integrating the Doubletree algorithm into our scheme to reduce measurement redundancy, 2) setting up a lookup table for routers to reduce traceroute size, and 3) conducting topology abstraction and reducing the computational frequency to reduce the computational overhead. As compared to the naive Max- Delta, our scheme is fully distributed and scalable. The computational loads for target selection are distributed to all the hosts instead of a single server. In addition, each host only communicates with a few other hosts. The consumption of edge bandwidth at a host is hence limited. We have done simulations on Internet-like topologies and conducted measurements on PlanetLab. The results show that the constructed tree has a low diameter and can support quick data exchange between hosts. Furthermore, the proposed improvements can efficiently reduce measurement redundancy, bandwidth consumption, and computational overhead.", "paper_title": "Scalable and efficient end-to-end network topology inference", "paper_id": "WOS:000255199500009"}