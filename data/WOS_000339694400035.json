{"auto_keywords": [{"score": 0.04888338488077779, "phrase": "feature_ranking"}, {"score": 0.04810170554931846, "phrase": "feature_rankings"}, {"score": 0.004817940959278259, "phrase": "bias"}, {"score": 0.004734448316824488, "phrase": "single_variable_classifiers"}, {"score": 0.004519908617935935, "phrase": "supervised_dimension_reduction"}, {"score": 0.004154332348800334, "phrase": "computational_power"}, {"score": 0.003899612025233852, "phrase": "dimension_reduction"}, {"score": 0.0038668462001710314, "phrase": "simple_methods"}, {"score": 0.003738502710504415, "phrase": "single_variable_classifier"}, {"score": 0.0035539019235553897, "phrase": "predictive_performance"}, {"score": 0.0033218213825698417, "phrase": "ranking_method"}, {"score": 0.0030657684627749364, "phrase": "extensive_study"}, {"score": 0.0028654728453890426, "phrase": "svc_rankings"}, {"score": 0.0028293966058473476, "phrase": "discriminative_power"}, {"score": 0.002758597251689795, "phrase": "dominant_impact"}, {"score": 0.002723862897844177, "phrase": "final_rankings"}, {"score": 0.00266693888510356, "phrase": "common_intuition"}, {"score": 0.00257831812581194, "phrase": "final_classification"}, {"score": 0.002503187934017557, "phrase": "best_prediction_performance"}, {"score": 0.0023395610923736595, "phrase": "final_classification_performance"}, {"score": 0.0022713722522505592, "phrase": "empirical_prediction_performance_loss"}, {"score": 0.0022145052062614514, "phrase": "svc_feature_ranking"}, {"score": 0.0021590588269751816, "phrase": "optimal_choices"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Feature ranking", " Feature selection", " Bias", " Stability", " Single variable classifier", " Dimension reduction", " Support Vector Machines", " Naive Bayes", " Multilayer Perceptron", " K-Nearest Neighbors", " Logistic Regression", " Ada Boost", " Random Forests"], "paper_abstract": "Feature rankings are often used for supervised dimension reduction especially when discriminating power of each feature is of interest, dimensionality of dataset is extremely high, or computational power is limited to perform more complicated methods. In practice, it is recommended to start dimension reduction via simple methods such as feature rankings before applying more complex approaches. Single variable classifier (SVC) ranking is a feature ranking based on the predictive performance of a classifier built using only a single feature. While benefiting from capabilities of classifiers, this ranking method is not as computationally intensive as wrappers. In this paper, we report the results of an extensive study on the bias and stability of such feature ranking method. We study whether the classifiers influence the SVC rankings or the discriminative power of features themselves has a dominant impact on the final rankings. We show the common intuition of using the same classifier for feature ranking and final classification does not always result in the best prediction performance. We then study if heterogeneous classifiers ensemble approaches provide more unbiased rankings and if they improve final classification performance. Furthermore, we calculate an empirical prediction performance loss for using the same classifier in SVC feature ranking and final classification from the optimal choices. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Bias and stability of single variable classifiers for feature ranking and selection", "paper_id": "WOS:000339694400035"}