{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "disclosure_risk"}, {"score": 0.008867251721192772, "phrase": "controlled_adjustment"}, {"score": 0.004762550320451225, "phrase": "controlled_adjustment_methods"}, {"score": 0.00471071771178029, "phrase": "statistical_tabular_data._minimum_distance"}, {"score": 0.004558564684763264, "phrase": "recent_perturbative_approach"}, {"score": 0.004508942069742167, "phrase": "statistical_disclosure_control"}, {"score": 0.004459857205489101, "phrase": "tabular_data"}, {"score": 0.004153520149706423, "phrase": "closest_safe_table"}, {"score": 0.004063547375196532, "phrase": "particular_distance"}, {"score": 0.003910740988145338, "phrase": "high_data_utility"}, {"score": 0.003661987063211563, "phrase": "theoretical_results"}, {"score": 0.0035049738376240567, "phrase": "previous_results"}, {"score": 0.003373101013123386, "phrase": "extensive_empirical_assessment"}, {"score": 0.002592784882557155, "phrase": "low_disclosure_risk"}, {"score": 0.002508867228980776, "phrase": "good_information"}, {"score": 0.0024276590297034064, "phrase": "optimization_problem"}, {"score": 0.0022980978400845144, "phrase": "good_estimates"}, {"score": 0.002163535133532765, "phrase": "objective_function"}], "paper_keywords": ["Statistical disclosure control", " controlled tabular adjustment", " disclosure risk", " optimization", " linear programming", " quadratic programming"], "paper_abstract": "Minimum distance controlled tabular adjustment is a recent perturbative approach for statistical disclosure control in tabular data. Given a table to be protected, it looks for the closest safe table, using some particular distance. Controlled adjustment is known to provide high data utility. However, the disclosure risk has only been partially analyzed using theoretical results from optimization. This work extends these previous results, providing both a more detailed theoretical analysis, and an extensive empirical assessment of the disclosure risk of the method. A set of 25 instances from the literature and four different attacker scenarios are considered, with several random replications for each scenario, both for L-1 and L-2 distances. This amounts to the solution of more than 2000 optimization problems. The analysis of the results shows that the approach has low disclosure risk when the attacker has no good information on the bounds of the optimization problem. On the other hand, when the attacker has good estimates of the bounds, and the only uncertainty is in the objective function (which is a very strong assumption), the disclosure risk of controlled adjustment is high and it should be avoided.", "paper_title": "ON ASSESSING THE DISCLOSURE RISK OF CONTROLLED ADJUSTMENT METHODS FOR STATISTICAL TABULAR DATA", "paper_id": "WOS:000311967300009"}