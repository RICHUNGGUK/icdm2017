{"auto_keywords": [{"score": 0.03464034545023031, "phrase": "virtual_view_picture"}, {"score": 0.015512225806948927, "phrase": "multi-view_video_coding"}, {"score": 0.00481495049065317, "phrase": "adaptive_learning_based_view_synthesis_prediction"}, {"score": 0.004563028873351776, "phrase": "free_view_tv"}, {"score": 0.004502126088469323, "phrase": "pre-estimated_depth_information"}, {"score": 0.00432423070113186, "phrase": "intermediate_views"}, {"score": 0.0040978781692373005, "phrase": "existing_view_synthesis_prediction_schemes"}, {"score": 0.003909522412849035, "phrase": "interview_pictures"}, {"score": 0.003704797078215222, "phrase": "signal_mismatches"}, {"score": 0.00363080961099728, "phrase": "depth_errors"}, {"score": 0.0035823043879169153, "phrase": "camera_heterogeneity"}, {"score": 0.0033268412940032103, "phrase": "prediction_capability"}, {"score": 0.0030895394261534776, "phrase": "adaptive_learning_based_view_synthesis_prediction_algorithm"}, {"score": 0.0028498718992429825, "phrase": "least_square_prediction"}, {"score": 0.002811770047652563, "phrase": "backward_warping"}, {"score": 0.0026111116934081284, "phrase": "adjacent_views"}, {"score": 0.002524688179363081, "phrase": "temporal_decoded_information"}, {"score": 0.002441118140830714, "phrase": "prediction_coefficients"}, {"score": 0.002344468886431959, "phrase": "proposed_method"}, {"score": 0.002206606452557159, "phrase": "multi-view_video_coding_standard"}, {"score": 0.0021049977753042253, "phrase": "conventional_view_synthesis_prediction_method"}], "paper_keywords": ["Multi-view video coding", " Depth map", " View synthesis prediction"], "paper_abstract": "In the applications of Free View TV, pre-estimated depth information is available to synthesize the intermediate views as well as to assist multi-view video coding. Existing view synthesis prediction schemes generate virtual view picture only from interview pictures. However, there are many types of signal mismatches caused by depth errors, camera heterogeneity or illumination difference across views and these mismatches decrease the prediction capability of virtual view picture. In this paper, we propose an adaptive learning based view synthesis prediction algorithm to enhance the prediction capability of virtual view picture. This algorithm integrates least square prediction with backward warping to synthesize the virtual view picture, which not only utilizes the adjacent views information but also the temporal decoded information to adaptively learn the prediction coefficients. Experiments show that the proposed method reduces the bitrates by up to 18 % relative to the multi-view video coding standard, and about 11 % relative to the conventional view synthesis prediction method.", "paper_title": "Adaptive Learning Based View Synthesis Prediction for Multi-View Video Coding", "paper_id": "WOS:000329620500011"}