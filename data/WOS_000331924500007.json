{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-class_ranking"}, {"score": 0.0047547526023100665, "phrase": "semantic_image_segmentation"}, {"score": 0.004695303774351139, "phrase": "fundamental_importance"}, {"score": 0.004636594774238505, "phrase": "wide_variety"}, {"score": 0.004597861947580946, "phrase": "computer_vision_tasks"}, {"score": 0.0045213598841171935, "phrase": "scene_understanding"}, {"score": 0.004483585361583022, "phrase": "robot_navigation"}, {"score": 0.00444612502361583, "phrase": "image_retrieval"}, {"score": 0.00426344619171077, "phrase": "semantically_consistent_regions"}, {"score": 0.004192484908247302, "phrase": "existing_works"}, {"score": 0.004122699822340296, "phrase": "structured_prediction_problem"}, {"score": 0.004071121244999291, "phrase": "contextual_information"}, {"score": 0.00403709306806495, "phrase": "low-level_cues"}, {"score": 0.003986581218661184, "phrase": "conditional_random_fields"}, {"score": 0.0038227112550093863, "phrase": "heuristic_search"}, {"score": 0.00377487157059352, "phrase": "maximum_likelihood_estimation"}, {"score": 0.003650195070580192, "phrase": "maximum_margin"}, {"score": 0.0034418037573506837, "phrase": "multiple_levels"}, {"score": 0.0033280910751441522, "phrase": "appearance_similarity"}, {"score": 0.0032726467814278345, "phrase": "novel_multi-class_ranking_based_global_constraint"}, {"score": 0.0030343239259424497, "phrase": "existing_global_cues"}, {"score": 0.0029463874016490976, "phrase": "expressive_power"}, {"score": 0.002921732652917206, "phrase": "heterogeneous_regions"}, {"score": 0.00284899583294417, "phrase": "exponential_space"}, {"score": 0.0028251537271620996, "phrase": "possible_label_combinations"}, {"score": 0.002766415324343602, "phrase": "inter-class_co-occurrence_statistics"}, {"score": 0.0026414426081951734, "phrase": "local_and_global_cues"}, {"score": 0.0026083473154448326, "phrase": "s-svms_framework"}, {"score": 0.0025541050375256992, "phrase": "joint_inference"}, {"score": 0.0024800509241747013, "phrase": "better_consistency"}, {"score": 0.002358050109031317, "phrase": "semantic_segmentation_evaluation"}, {"score": 0.002309000874224222, "phrase": "stanford_background"}, {"score": 0.0022232633360792222, "phrase": "high_competitive_performance"}], "paper_keywords": ["Computer vision", " Machine learning", " Semantic segmentation", " Structural SVMs"], "paper_abstract": "Semantic image segmentation is of fundamental importance in a wide variety of computer vision tasks, such as scene understanding, robot navigation and image retrieval, which aims to simultaneously decompose an image into semantically consistent regions. Most of existing works addressed it as structured prediction problem by combining contextual information with low-level cues based on conditional random fields (CRFs), which are often learned by heuristic search based on maximum likelihood estimation. In this paper, we use maximum margin based structural support vector machine (S-SVM) model to combine multiple levels of cues to attenuate the ambiguity of appearance similarity and propose a novel multi-class ranking based global constraint to confine the object classes to be considered when labeling regions within an image. Compared with existing global cues, our method is more balanced between expressive power for heterogeneous regions and the efficiency of searching exponential space of possible label combinations. We then introduce inter-class co-occurrence statistics as pairwise constraints and combine them with the prediction from local and global cues based on S-SVMs framework. This enables the joint inference of labeling within an image for better consistency. We evaluate our algorithm on two challenging datasets which are widely used for semantic segmentation evaluation: MSRC-21 dataset and Stanford Background dataset and experimental results show that we obtain high competitive performance compared with state-of-the-art methods, despite that our model is much simpler and efficient. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Efficient semantic image segmentation with multi-class ranking prior", "paper_id": "WOS:000331924500007"}