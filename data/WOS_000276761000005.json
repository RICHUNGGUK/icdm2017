{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "statistical_learning"}, {"score": 0.03232541789808835, "phrase": "true_distribution"}, {"score": 0.025902560165199172, "phrase": "proposed_equations"}, {"score": 0.004724708238414131, "phrase": "unrealizable_and_regular_case"}, {"score": 0.004578030096508602, "phrase": "hierarchical_structure_or_hidden_variables"}, {"score": 0.0044079880067019765, "phrase": "information_science"}, {"score": 0.0043527164193299574, "phrase": "artificial_intelligence"}, {"score": 0.004009894739765119, "phrase": "regular_but_singular_statistical_models"}, {"score": 0.0036246643358397272, "phrase": "previous_papers"}, {"score": 0.00353426342004404, "phrase": "new_equations"}, {"score": 0.003317970131738248, "phrase": "bayes_generalization_loss"}, {"score": 0.0032556926399045635, "phrase": "bayes_training_loss"}, {"score": 0.003194580334752371, "phrase": "functional_variance"}, {"score": 0.0029241700853970013, "phrase": "learning_machine"}, {"score": 0.002560751416355291, "phrase": "parametric_model"}, {"score": 0.0023887436047824386, "phrase": "regular_case"}, {"score": 0.002299830460180699, "phrase": "takeuchi_information_criterion"}, {"score": 0.0021049977753042253, "phrase": "unknown_true_distribution"}], "paper_keywords": ["bayes learning", " generalization", " information criterion", " singular", " regular"], "paper_abstract": "Many learning machines that have hierarchical structure or hidden variables are now being used in information science, artificial intelligence, and bioinformatics. However, several learning machines used in such fields are not regular but singular statistical models, hence their generalization performance is still left unknown. To overcome these problems, in the previous papers, we proved new equations in statistical learning, by which we can estimate the Bayes generalization loss from the Bayes training loss and the functional variance, on the condition that the true distribution is a singularity contained in a learning machine. In this paper. we prove that the same equations hold even if a true distribution is not contained in a parametric model. Also we prove that, the proposed equations in a regular case are asymptotically equivalent to the Takeuchi information criterion. Therefore, the proposed equations are always applicable without any condition on the unknown true distribution.", "paper_title": "Equations of States in Statistical Learning for an Unrealizable and Regular Case", "paper_id": "WOS:000276761000005"}