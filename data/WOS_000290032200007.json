{"auto_keywords": [{"score": 0.039688023443322194, "phrase": "probabilistic_principal_component_analyzers"}, {"score": 0.027633504965896595, "phrase": "proposed_method"}, {"score": 0.004815141414137688, "phrase": "gaussians"}, {"score": 0.0047555023078686386, "phrase": "linear_transformations"}, {"score": 0.004469042910390712, "phrase": "density_estimation"}, {"score": 0.004413846562278824, "phrase": "high_dimensional_spaces"}, {"score": 0.0038978806337961565, "phrase": "principal_component_analyzers"}, {"score": 0.003662892058072211, "phrase": "factor_analyzers"}, {"score": 0.0034634973175137486, "phrase": "novel_mixture_model"}, {"score": 0.0033159224502739247, "phrase": "linear_transformation"}, {"score": 0.003077372515276563, "phrase": "principal_directions"}, {"score": 0.0030204580407008214, "phrase": "experimental_validation"}, {"score": 0.0029097582786754444, "phrase": "proposed_model"}, {"score": 0.0028382152567141784, "phrase": "five_\"hard\"_data_sets"}, {"score": 0.0022683432490549064, "phrase": "data_sets"}, {"score": 0.0021049977753042253, "phrase": "gaussian_mixture_model"}], "paper_keywords": ["Dimensionality reduction", " Regularized maximum-likelihood", " Mixture models", " Linear transformations", " Object classification"], "paper_abstract": "The curse of dimensionality hinders the effectiveness of density estimation in high dimensional spaces. Many techniques have been proposed in the past to discover embedded, locally linear manifolds of lower dimensionality, including the mixture of principal component analyzers, the mixture of probabilistic principal component analyzers and the mixture of factor analyzers. In this paper, we propose a novel mixture model for reducing dimensionality based on a linear transformation which is not restricted to be orthogonal nor aligned along the principal directions. For experimental validation, we have used the proposed model for classification of five \"hard\" data sets and compared its accuracy with that of other popular classifiers. The performance of the proposed method has outperformed that of the mixture of probabilistic principal component analyzers on four out of the five compared data sets with improvements ranging from 0.5 to 3.2%. Moreover, on all data sets, the accuracy achieved by the proposed method outperformed that of the Gaussian mixture model with improvements ranging from 0.2 to 3.4%.", "paper_title": "MLiT: mixtures of Gaussians under linear transformations", "paper_id": "WOS:000290032200007"}