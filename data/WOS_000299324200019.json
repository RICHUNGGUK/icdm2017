{"auto_keywords": [{"score": 0.04913548507380238, "phrase": "dynamic_systems"}, {"score": 0.04574703079843426, "phrase": "feed-forward_network"}, {"score": 0.00481495049065317, "phrase": "feed-forward_neural_network"}, {"score": 0.004581162468419365, "phrase": "paper_different_structure"}, {"score": 0.004446349752828045, "phrase": "hidden_layer"}, {"score": 0.0035891316580885665, "phrase": "delay_element"}, {"score": 0.003380791705551809, "phrase": "wavelet_activation_function"}, {"score": 0.0032164136388931805, "phrase": "five_possible_configurations"}, {"score": 0.0031845067058084583, "phrase": "recurrent_neurons"}, {"score": 0.0031061129850110994, "phrase": "neuron_models"}, {"score": 0.0030600032877646263, "phrase": "presented_paper"}, {"score": 0.002955050521440921, "phrase": "wavelet_function"}, {"score": 0.002925728709297618, "phrase": "sigmoid_function"}, {"score": 0.002769568481822277, "phrase": "learning_process"}, {"score": 0.0027420820738468577, "phrase": "upper_bound"}, {"score": 0.002701361707441567, "phrase": "learning_rates"}, {"score": 0.0026217213613095322, "phrase": "lyapunov_stability_theorem"}, {"score": 0.0025827837420330816, "phrase": "two-phase_adaptive_learning_rate"}, {"score": 0.0025066304722422463, "phrase": "universal_approximation_property"}, {"score": 0.0024327171018928458, "phrase": "proposed_neurons"}, {"score": 0.002268598551466928, "phrase": "proposed_recurrent_networks"}, {"score": 0.0021907299375981356, "phrase": "different_types"}, {"score": 0.002168975681697056, "phrase": "dynamical_systems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Neural network", " Wavelet network", " Recurrent", " Lyapunov stability", " Universal approximation"], "paper_abstract": "In this paper different structure of the neurons in the hidden layer of a feed-forward network, for forecasting of the dynamic systems, are proposed. Each neuron in the network is a combination of the sigmoidal activation function (SAF) and wavelet activation function (WAF). The output of the hidden neuron is the product of the output from these two activation functions. A delay element is used to feedback the output of the sigmoidal and the wavelet activation function to each other. This arrangement leads to proposed five possible configurations of recurrent neurons. Besides proposing these neuron models, the presented paper tries to compare the performance of wavelet function with sigmoid function. To guarantee the stability and the convergence of the learning process, upper bound for the learning rates has been investigated using the Lyapunov stability theorem. A two-phase adaptive learning rate ensures this upper bound. Universal approximation property of the feed-forward network with the proposed neurons has also been investigated. Finally, the applicability and comparison of the proposed recurrent networks has been weathered on two benchmark problem catering different types of dynamical systems. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Local recurrent sigmoidal-wavelet neurons in feed-forward neural network for forecasting of dynamic systems: Theory", "paper_id": "WOS:000299324200019"}