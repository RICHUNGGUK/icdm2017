{"auto_keywords": [{"score": 0.04790995341030913, "phrase": "virtual_information"}, {"score": 0.00481495049065317, "phrase": "augmented_reality_presentation_space"}, {"score": 0.004704699244406775, "phrase": "wide-ranging_presentation_space"}, {"score": 0.0043718794256931435, "phrase": "physical_objects"}, {"score": 0.0042388570312522, "phrase": "presentation_space"}, {"score": 0.004015693806064219, "phrase": "augmented_reality"}, {"score": 0.0039694170761766226, "phrase": "unique_and_independent_dimensions"}, {"score": 0.003923671536980019, "phrase": "fundamental_spectrum"}, {"score": 0.0037749456215035856, "phrase": "fine-grained_analysis"}, {"score": 0.0037170399498025215, "phrase": "human_understanding"}, {"score": 0.0036600192572132676, "phrase": "multiple_factors"}, {"score": 0.0036038701178581403, "phrase": "multiple_differences"}, {"score": 0.0035761182400032487, "phrase": "different_presentation_systems"}, {"score": 0.0032972747743006603, "phrase": "new_fields"}, {"score": 0.0032341432727280707, "phrase": "not-yet-used_concepts"}, {"score": 0.0031599739264865554, "phrase": "augmented_reality_research"}, {"score": 0.003123527559542239, "phrase": "growing_number"}, {"score": 0.0028687545730861665, "phrase": "independent_dimensions"}, {"score": 0.002846647336160784, "phrase": "representation_principles"}, {"score": 0.0027813397260607487, "phrase": "physical_environment"}, {"score": 0.0025249264547573943, "phrase": "devised_dimensions"}, {"score": 0.0024669814850296146, "phrase": "wide_variety"}, {"score": 0.0024479627964740748, "phrase": "ar_applications"}, {"score": 0.002419708657850547, "phrase": "categorized_data"}, {"score": 0.002373339527491525, "phrase": "most-often_and_less-frequently_used_combinations"}, {"score": 0.0021965609224818853, "phrase": "future_work"}, {"score": 0.002171202123281881, "phrase": "new_options"}, {"score": 0.0021544587602892466, "phrase": "information_presentation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Augmented Reality", " Taxonomy", " Information Presentation"], "paper_abstract": "Augmented Reality has a wide-ranging presentation space. In addition to presenting virtual information in a 3D space, such information can also be placed in relation to physical objects, locations or events. Decomposing this presentation space - or more exactly, the principles of how information is represented in Augmented Reality - into unique and independent dimensions provides a fundamental spectrum of options. First, this decomposition facilitates a fine-grained analysis of effects on human understanding. Second, multiple factors, given by multiple differences between different presentation systems with respect to more than one such principle, can be determined and properly addressed. Third, this decomposition facilitates a determination of new fields of research by identifying not-yet-used concepts. Since the beginning of Augmented Reality research, a growing number of applications have emerged that exploit various ways to represent information. This paper resumes this development and presents a set of independent dimensions covering representation principles of virtual information related to a physical environment: the temporality of virtual information, dimensionality, the frame of reference, mounting/registration and the type of reference. The suitability of the devised dimensions is tested by categorizing a wide variety of AR applications. The categorized data is analyzed for the most-often and less-frequently used combinations of classes. In particular, the classes that have not yet been used exhibit the potential to allow future work that investigates new options for information presentation. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Representing information - Classifying the Augmented Reality presentation space", "paper_id": "WOS:000329541800007"}