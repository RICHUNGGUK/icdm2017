{"auto_keywords": [{"score": 0.04548554730183367, "phrase": "recorded_data"}, {"score": 0.00481495049065317, "phrase": "unknown_discrete-time_nonlinear_systems"}, {"score": 0.004752221133109136, "phrase": "time-based_adaptive_dynamic_programming"}, {"score": 0.004608997772926119, "phrase": "online_optimal_control_scheme"}, {"score": 0.004278807087784626, "phrase": "optimal_controller"}, {"score": 0.004186253035932442, "phrase": "system_dynamics"}, {"score": 0.00398959232769596, "phrase": "neural_network"}, {"score": 0.0038355531523269217, "phrase": "unknown_system"}, {"score": 0.0037198532511087566, "phrase": "estimated_system_model"}, {"score": 0.003671338229632309, "phrase": "novel_time-based_adp_algorithm"}, {"score": 0.003529543381704363, "phrase": "actor-critic_structure"}, {"score": 0.0033489371483830153, "phrase": "optimal_cost"}, {"score": 0.003305243635051068, "phrase": "optimal_control_policy"}, {"score": 0.0029238768315330305, "phrase": "excitation_condition"}, {"score": 0.002835599469639296, "phrase": "adaptive_control"}, {"score": 0.0027620516806198354, "phrase": "new_criterion"}, {"score": 0.0026321198895843173, "phrase": "critic_neural_network"}, {"score": 0.0026091594819333654, "phrase": "lyapunov_techniques"}, {"score": 0.0025414699652861667, "phrase": "system_states"}, {"score": 0.0025192983141887285, "phrase": "cost_function"}, {"score": 0.0023798115577749225, "phrase": "small_bounded_errors"}, {"score": 0.002328238264850759, "phrase": "approximation_errors"}, {"score": 0.0022480304016499605, "phrase": "simulation_results"}, {"score": 0.0021610874773389096, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Adaptive dynamic programming", " Online optimal control", " Reinforcement learning", " Discrete-time systems"], "paper_abstract": "In this paper, an online optimal control scheme for a class of unknown discrete-time (DT) nonlinear systems is developed. The proposed algorithm using current and recorded data to obtain the optimal controller without the knowledge of system dynamics. In order to carry out the algorithm, a neural network (NN) is constructed to identify the unknown system. Then, based on the estimated system model, a novel time-based ADP algorithm without using system dynamics is implemented on an actor-critic structure. Two NNs are used in the structure to generate the optimal cost and the optimal control policy, and both of them are updated once at the sampling instant and thus the algorithm can be regarded as time-based. The persistence of excitation condition, which is generally required in adaptive control, is ensured by a new criterion while using current and recorded data in the update of the critic neural network. Lyapunov techniques are used to show that system states, cost function and control signals are all uniformly ultimately bounded (UUB) with small bounded errors while explicitly considering the approximation errors caused by the three NNs. Finally, simulation results are provided to verify the effectiveness of the proposed approach. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Online optimal control of unknown discrete-time nonlinear systems by using time-based adaptive dynamic programming", "paper_id": "WOS:000356747700021"}