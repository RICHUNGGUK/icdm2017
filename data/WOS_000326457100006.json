{"auto_keywords": [{"score": 0.04935669810434817, "phrase": "visual_attention"}, {"score": 0.048880968765446134, "phrase": "threshold_segmentation"}, {"score": 0.04656689653024886, "phrase": "remote_sensing_images"}, {"score": 0.00481495049065317, "phrase": "interest_detection"}, {"score": 0.004647105813224402, "phrase": "high_spatial_resolution_remote_sensing_images"}, {"score": 0.00457696724030363, "phrase": "continuous_increase"}, {"score": 0.004507882471601552, "phrase": "spatial_resolution"}, {"score": 0.00441738161338662, "phrase": "great_challenge"}, {"score": 0.00437281181878921, "phrase": "image_analysis"}, {"score": 0.004285010985001827, "phrase": "traditional_prior_knowledge-based_region_detection"}, {"score": 0.004135562737140424, "phrase": "high_resolution"}, {"score": 0.004032002950217457, "phrase": "global_searching_solution"}, {"score": 0.0039310261964323545, "phrase": "prohibitive_computational_complexity"}, {"score": 0.003680160390414722, "phrase": "roi"}, {"score": 0.0033759367489122716, "phrase": "visual_attention_mechanism"}, {"score": 0.003291336101694653, "phrase": "image_segmentation"}, {"score": 0.003258090521354736, "phrase": "feature_detection"}, {"score": 0.0032088487124106936, "phrase": "entire_image"}, {"score": 0.0031603487697867538, "phrase": "input_image"}, {"score": 0.002988685006809336, "phrase": "discrete_moment"}, {"score": 0.0028263192354046245, "phrase": "finer_description"}, {"score": 0.0027414948679658816, "phrase": "feature_maps"}, {"score": 0.002592523232809191, "phrase": "\"strong_points"}, {"score": 0.002540377258232509, "phrase": "\"salient_points"}, {"score": 0.00248927752933113, "phrase": "threshold_segmentation_strategy"}, {"score": 0.0024023079401125492, "phrase": "interest_shape_information"}, {"score": 0.002271725588755076, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "traditional_itti's_model"}], "paper_keywords": ["Image processing", " region of interest", " visual attention", " threshold segmentation"], "paper_abstract": "The continuous increase of the spatial resolution of remote sensing images brings great challenge to image analysis and processing. Traditional prior knowledge-based region detection and target recognition algorithms for processing high resolution remote sensing images generally employ a global searching solution, which results in prohibitive computational complexity. In this paper, a more efficient region of interest (ROI) detection algorithm based on visual attention and threshold segmentation (VA-TS) is proposed, wherein a visual attention mechanism is used to eliminate image segmentation and feature detection to the entire image. The input image is subsampled to decrease the amount of data and the discrete moment transform (DMT) feature is extracted to provide a finer description of the edges. The feature maps are combined with weights according to the amount of the \"strong points\" and the \"salient points\". A threshold segmentation strategy is employed to obtain more accurate region of interest shape information with the very low computational complexity. Experimental statistics have shown that the proposed algorithm is computational efficient and provide more visually accurate detection results. The calculation time is only about 0.7% of the traditional Itti's model.", "paper_title": "Region of Interest Detection Based on Visual Attention and Threshold Segmentation in High Spatial Resolution Remote Sensing Images", "paper_id": "WOS:000326457100006"}