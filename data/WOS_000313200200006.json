{"auto_keywords": [{"score": 0.045693275459193064, "phrase": "tensor_space"}, {"score": 0.015051552340376176, "phrase": "data_tensors"}, {"score": 0.013368215794569503, "phrase": "intrinsic_geometry"}, {"score": 0.012498221338004642, "phrase": "product_manifold"}, {"score": 0.012204707836069967, "phrase": "least_squares_regression"}, {"score": 0.008606792404772202, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "product_manifolds"}, {"score": 0.004776669953449352, "phrase": "action_videos"}, {"score": 0.0047386923107107645, "phrase": "multidimensional_data"}, {"score": 0.004553265070135597, "phrase": "tensor_computing"}, {"score": 0.004463278123628969, "phrase": "computer_vision"}, {"score": 0.003959353513286997, "phrase": "action_recognition"}, {"score": 0.0035973486787314883, "phrase": "data_tensor"}, {"score": 0.0034702685641070283, "phrase": "higher_order_singular_value_decomposition"}, {"score": 0.0034426437834159723, "phrase": "hosvd"}, {"score": 0.003361069456060196, "phrase": "factorized_element"}, {"score": 0.003321008590273796, "phrase": "grassmann_manifold"}, {"score": 0.003229374325577207, "phrase": "underlying_geometry"}, {"score": 0.0031277316566463978, "phrase": "composite_function"}, {"score": 0.003065830998810144, "phrase": "natural_extension"}, {"score": 0.0030414140732789186, "phrase": "euclidean_space"}, {"score": 0.002922207118572208, "phrase": "geodesic_distance"}, {"score": 0.002819013004243083, "phrase": "grassmannian"}, {"score": 0.0025609245768750044, "phrase": "cambridge"}, {"score": 0.0024214285524586103, "phrase": "chalearn"}, {"score": 0.0023925401023682717, "phrase": "data_sets"}, {"score": 0.002373472641477602, "phrase": "experimental_results"}, {"score": 0.002262209824105154, "phrase": "standard_benchmark_data_sets"}, {"score": 0.0021821915946356168, "phrase": "one-shot-learning_gesture_challenge"}, {"score": 0.0021049977753042253, "phrase": "simple_statistical_model"}], "paper_keywords": ["gesture recognition", " action recognition", " Grassmann manifolds", " product manifolds", " one-shot-learning", " kinect data"], "paper_abstract": "Action videos are multidimensional data and can be naturally represented as data tensors. While tensor computing is widely used in computer vision, the geometry of tensor space is often ignored. The aim of this paper is to demonstrate the importance of the intrinsic geometry of tensor space which yields a very discriminating structure for action recognition. We characterize data tensors as points on a product manifold and model it statistically using least squares regression. To this aim, we factorize a data tensor relating to each order of the tensor using Higher Order Singular Value Decomposition (HOSVD) and then impose each factorized element on a Grassmann manifold. Furthermore, we account for underlying geometry on manifolds and formulate least squares regression as a composite function. This gives a natural extension from Euclidean space to manifolds. Consequently, classification is performed using geodesic distance on a product manifold where each factor manifold is Grassmannian. Our method exploits appearance and motion without explicitly modeling the shapes and dynamics. We assess the proposed method using three gesture databases, namely the Cambridge hand-gesture, the UMD Keck body-gesture, and the CHALEARN gesture challenge data sets. Experimental results reveal that not only does the proposed method perform well on the standard benchmark data sets, but also it generalizes well on the one-shot-learning gesture challenge. Furthermore, it is based on a simple statistical model and the intrinsic geometry of tensor space.", "paper_title": "Human Gesture Recognition on Product Manifolds", "paper_id": "WOS:000313200200006"}