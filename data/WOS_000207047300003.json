{"auto_keywords": [{"score": 0.02763503661180872, "phrase": "calibration_curves"}, {"score": 0.00481495049065317, "phrase": "cache_architecture"}, {"score": 0.004567230180529598, "phrase": "remote_server"}, {"score": 0.004532892812505505, "phrase": "best-effort_internet"}, {"score": 0.00443141503046841, "phrase": "network_losses"}, {"score": 0.004398094237005956, "phrase": "variable_delays"}, {"score": 0.004348580182733617, "phrase": "primary_technique"}, {"score": 0.0042351951710402425, "phrase": "distributed_content_service"}, {"score": 0.004062937864702115, "phrase": "web_caching"}, {"score": 0.0040171817997972335, "phrase": "traditional_mechanism"}, {"score": 0.003853757393357659, "phrase": "new_staged_delivery_model"}, {"score": 0.003810348067898898, "phrase": "distributed_architecture"}, {"score": 0.0037109446302945903, "phrase": "remote_servers"}, {"score": 0.003480161521018509, "phrase": "last-mile_connection"}, {"score": 0.00340217066797559, "phrase": "novel_revolving_indexed_cache_buffer_management_mechanism"}, {"score": 0.003313380246267812, "phrase": "selective_retransmissions"}, {"score": 0.0032884384364324395, "phrase": "lost_packets"}, {"score": 0.003251376167695528, "phrase": "remote_and_edge_cache"}, {"score": 0.003214730261140886, "phrase": "best-effort_recovery"}, {"score": 0.003142668996712078, "phrase": "new_web_cache_buffer_management_scheme"}, {"score": 0.00307221807606505, "phrase": "cache_buffer_parameters"}, {"score": 0.0030375852871252934, "phrase": "network_conditions"}, {"score": 0.0029807267909921628, "phrase": "performance_of_buffer_management_and_retransmission_policies"}, {"score": 0.002859345731792013, "phrase": "probabilistic_analysis"}, {"score": 0.0028271058251633815, "phrase": "streaming_process"}, {"score": 0.0027846824619356583, "phrase": "system_simulations"}, {"score": 0.0027325449069867222, "phrase": "different_endogenous_control_parameters"}, {"score": 0.002572158343938064, "phrase": "qos_metrics"}, {"score": 0.002552781867125423, "phrase": "different_network_conditions"}, {"score": 0.002486103638234488, "phrase": "edge_cache_management"}, {"score": 0.002305014991156598, "phrase": "endogenous_control_parameters"}, {"score": 0.002287646331988365, "phrase": "specific_qos"}, {"score": 0.00227040825063645, "phrase": "real-time_streaming_operations"}, {"score": 0.0021861425611350857, "phrase": "transmission_characteristics"}, {"score": 0.002169667676959813, "phrase": "real-time_traffic_data"}, {"score": 0.002129020447793464, "phrase": "effective_decision"}, {"score": 0.0021049977753042253, "phrase": "edge_cache_buffer_allocation_and_management_strategies"}], "paper_keywords": ["Design", " Web caching", " on-demand streaming", " quality of service", " edge cache", " buffering", " selective retransmissions"], "paper_abstract": "On-demand streaming from a remote server through best-effort Internet poses several challenges because of network losses and variable delays. The primary technique used to improve the quality of distributed content service is replication. In the context of the Internet, Web caching is the traditional mechanism that is used. In this article we develop a new staged delivery model for a distributed architecture in which video is streamed from remote servers to edge caches where the video is buffered and then streamed to the client through a last-mile connection. The model uses a novel revolving indexed cache buffer management mechanism at the edge cache and employs selective retransmissions of lost packets between the remote and edge cache for a best-effort recovery of the losses. The new Web cache buffer management scheme includes a dynamic adjustment of cache buffer parameters based on network conditions. In addition, performance of buffer management and retransmission policies at the edge cache is modeled and assessed using a probabilistic analysis of the streaming process as well as system simulations. The influence of different endogenous control parameters on the quality of stream received by the client is studied. Calibration curves on the QoS metrics for different network conditions have been obtained using simulations. Edge cache management can be done using these calibration curves. ISPs can make use of calibration curves to set the values of the endogenous control parameters for specific QoS in real-time streaming operations based on network conditions. A methodology to benchmark transmission characteristics using real-time traffic data is developed to enable effective decision making on edge cache buffer allocation and management strategies.", "paper_title": "Cache Architecture for On-Demand Streaming on the Web", "paper_id": "WOS:000207047300003"}