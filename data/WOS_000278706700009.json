{"auto_keywords": [{"score": 0.029466848121789024, "phrase": "global_minimum"}, {"score": 0.00481495049065317, "phrase": "particle_swarm_optimization_performance"}, {"score": 0.0046993598473345395, "phrase": "high-dimensional_function"}, {"score": 0.004631335513513859, "phrase": "particle_swarm_optimization"}, {"score": 0.004586611071476952, "phrase": "pso"}, {"score": 0.004305639197085793, "phrase": "local_optimization_techniques"}, {"score": 0.004161553532799662, "phrase": "necessary_ingredient"}, {"score": 0.004121275290411653, "phrase": "hybrid_algorithms"}, {"score": 0.004081385289516914, "phrase": "global_optimization_problems"}, {"score": 0.0038127186374325582, "phrase": "two-stage_hybrid_algorithm"}, {"score": 0.0036493838225192883, "phrase": "present_algorithm"}, {"score": 0.0035965032173588753, "phrase": "gradient_descent_technique"}, {"score": 0.003493021648360933, "phrase": "local_minimum"}, {"score": 0.0034423989472667756, "phrase": "objective_function"}, {"score": 0.003359647377874098, "phrase": "pso_method"}, {"score": 0.0033271045779740683, "phrase": "latent_parallel_search_capability"}, {"score": 0.0031536550157613974, "phrase": "previously_converged_local_minima"}, {"score": 0.003107935254560724, "phrase": "better_point"}, {"score": 0.003003809128328864, "phrase": "starting_point"}, {"score": 0.0029602552900111407, "phrase": "gradient_methods"}, {"score": 0.0029031614127920232, "phrase": "new_local_search"}, {"score": 0.00259554612218815, "phrase": "maximum_number"}, {"score": 0.002570385604065795, "phrase": "function_evaluations"}, {"score": 0.00247215300812495, "phrase": "repulsion_technique"}, {"score": 0.0024481856932959227, "phrase": "partially_initializing_population_method"}, {"score": 0.002389276641014013, "phrase": "new_algorithm"}, {"score": 0.0022756672722130424, "phrase": "five_large-scale_ones"}, {"score": 0.0021780349459687622, "phrase": "proposed_method"}], "paper_keywords": ["global optimization", " gradient descent method", " particle swarm optimization (PSO)", " repulsion technique"], "paper_abstract": "Particle swarm optimization (PSO) is one recently proposed population-based stochastic optimization technique, and gradient-based descent methods are efficient local optimization techniques that are often used as a necessary ingredient of hybrid algorithms for global optimization problems (GOPs). By examining the properties of the two methods, a two-stage hybrid algorithm for global optimization is proposed. In the present algorithm, the gradient descent technique is used to find a local minimum of the objective function efficiently, and a PSO method with latent parallel search capability is employed to help the algorithm to escape from the previously converged local minima to a better point which is then used as a starting point for the gradient methods to restart a new local search. The above search procedure is applied repeatedly until a global minimum is found (when a global minimum is known in advance) or the maximum number of function evaluations is reached. In addition, a repulsion technique and partially initializing population method are incorporated in the new algorithm to increase its global jumping ability. Simulation results on 15 test problems including five large-scale ones with dimensions up to 1000 demonstrate that the proposed method is more stable and efficient than several other existing methods.", "paper_title": "Improving particle swarm optimization performance with local search for high-dimensional function optimization", "paper_id": "WOS:000278706700009"}