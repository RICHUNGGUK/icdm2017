{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "completely_observed_markov_chains"}, {"score": 0.004750873844061641, "phrase": "generalized_safety_bounds"}, {"score": 0.00470862827326028, "phrase": "optimality_requirement"}, {"score": 0.0046046429665581555, "phrase": "safety_bounds"}, {"score": 0.004383852039913171, "phrase": "state_probability_distribution"}, {"score": 0.0037997077863530897, "phrase": "stationary_control_policy"}, {"score": 0.003249251984154665, "phrase": "linear_programming_formulation"}, {"score": 0.0030932495918679285, "phrase": "system's_transient_behavior"}, {"score": 0.002984504445973107, "phrase": "unique_bunting_distribution"}, {"score": 0.002905454531687249, "phrase": "constraint_set"}, {"score": 0.002841176824012961, "phrase": "finitely-terminating_iterative_algorithm"}, {"score": 0.0027907771648224273, "phrase": "maximal_invariant_safe_set"}, {"score": 0.0026686444508167875, "phrase": "initial_distribution"}, {"score": 0.0026095920086044145, "phrase": "future_distributions"}, {"score": 0.0023754752864092437, "phrase": "simplified_algorithm"}, {"score": 0.0022613292987262177, "phrase": "numerical_examples"}, {"score": 0.002181766829493483, "phrase": "closed-form_representation"}, {"score": 0.0021334650920198715, "phrase": "two-state_system"}], "paper_keywords": ["Controlled Markov chains", " Safety control", " Stochastic discrete event system", " Reliability"], "paper_abstract": "We study the control of completely observed Markov chains subject to generalized safety bounds and optimality requirement. Originally; the safety bounds were specified as unit-interval valued vector pairs (lower and upper bounds for each component of the state probability distribution). In this paper, we generalize the constraint to be any linear convex set, for the distribution to stay in; and present a way to compute a stationary control policy which is safe and at the same time long-run average optimal. This policy guarantees the safety of the system. as it is on its 'limiting status', and is derived through a linear programming formulation with its feasibility problem explored. To assure the safety of the system's transient behavior under the policy assumed to induce a unique bunting distribution in the interior of the constraint set; we present a finitely-terminating iterative algorithm to compute the maximal invariant safe set (MISS) smelt that starting from which any initial distribution incurs a sequence of future distributions that are safe also. A theoretic upper bound for the number of iterations is provided. Furthermore, a simplified algorithm that might require less calculation is also introduced and illustrated in numerical examples. In particular, we obtain the closed-form representation for the MISS of two-state system based on at most one iteration of the algorithm.", "paper_title": "ON CONTROLLED MARKOV CHAINS WITH OPTIMALITY REQUIREMENT AND SAFETY CONSTRAINT", "paper_id": "WOS:000278688700010"}