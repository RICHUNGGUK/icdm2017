{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "smoothing_methods"}, {"score": 0.010480137629968012, "phrase": "minimization_problems"}, {"score": 0.004665483918844599, "phrase": "feasible_set"}, {"score": 0.00452063603944825, "phrase": "objective_function"}, {"score": 0.004191210491013562, "phrase": "lipschitz"}, {"score": 0.003984665807155269, "phrase": "wide_applications"}, {"score": 0.003934681262271618, "phrase": "image_restoration"}, {"score": 0.0038853212888610234, "phrase": "signal_reconstruction"}, {"score": 0.0038365781437074017, "phrase": "variable_selection"}, {"score": 0.003788444178071508, "phrase": "optimal_control"}, {"score": 0.0037409118365761894, "phrase": "stochastic_equilibrium"}, {"score": 0.003693973656103879, "phrase": "spherical_approximations"}, {"score": 0.0028332303659245085, "phrase": "inner_iteration"}, {"score": 0.002659725066330941, "phrase": "smoothing_functions"}, {"score": 0.002609770322855842, "phrase": "gradient_consistency"}, {"score": 0.002512650904797186, "phrase": "smoothing_function"}, {"score": 0.0023587312574818208, "phrase": "smoothing_parameter"}, {"score": 0.0023144166368024603, "phrase": "outer_iteration"}, {"score": 0.0021453112313233554, "phrase": "stationary_point"}, {"score": 0.0021049977753042253, "phrase": "original_minimization_problem"}], "paper_keywords": ["Nonsmooth", " Nonconvex minimization", " Smoothing methods", " Regularized minimization problems", " Eigenvalue optimization", " Stochastic variational inequality problems"], "paper_abstract": "We consider a class of smoothing methods for minimization problems where the feasible set is convex but the objective function is not convex, not differentiable and perhaps not even locally Lipschitz at the solutions. Such optimization problems arise from wide applications including image restoration, signal reconstruction, variable selection, optimal control, stochastic equilibrium and spherical approximations. In this paper, we focus on smoothing methods for solving such optimization problems, which use the structure of the minimization problems and composition of smoothing functions for the plus function (x)(+). Many existing optimization algorithms and codes can be used in the inner iteration of the smoothing methods. We present properties of the smoothing functions and the gradient consistency of subdifferential associated with a smoothing function. Moreover, we describe how to update the smoothing parameter in the outer iteration of the smoothing methods to guarantee convergence of the smoothing methods to a stationary point of the original minimization problem.", "paper_title": "Smoothing methods for nonsmooth, nonconvex minimization", "paper_id": "WOS:000306493800004"}