{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "feed-forward_neural_networks"}, {"score": 0.004088421020408183, "phrase": "vast_literature"}, {"score": 0.003296212583539166, "phrase": "specific_comparisons"}, {"score": 0.0027741761880779535, "phrase": "interesting_results"}, {"score": 0.002437525632451029, "phrase": "neural_network_architecture"}, {"score": 0.002375253757224999, "phrase": "statistical_properties"}, {"score": 0.0023145690608400425, "phrase": "test_statistic"}, {"score": 0.0021049977753042253, "phrase": "skewed_alternatives"}], "paper_keywords": ["discrimination between distributions", " feed-forward neural network", " goodness-of-fit test", " model selection", " normality tests", " 62E15", " 62E17", " 62G09", " 62G30", " 62M45"], "paper_abstract": "A relevant problem in many applicatory contexts is to test whether some given observations follow one of two possible probability distributions. The vast literature produced over the years on this topic does not identify a tool which can be easily adopted to any situation but only finds solutions to specific comparisons. Recently, an easy to implement procedure for discrimination between two distributions based on feed-forward neural networks has been proposed giving interesting results. In this work this procedure is further investigated in terms of power, neural network architecture and expected statistical properties of the test statistic for small, moderate and large sample sizes, in a wide range of symmetric and skewed alternatives.", "paper_title": "Discriminating between distributions using feed-forward neural networks", "paper_id": "WOS:000345689600005"}