{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "eye_tracking"}, {"score": 0.04526762820558843, "phrase": "person's_eyes"}, {"score": 0.004762665113390216, "phrase": "existing_eye_detection"}, {"score": 0.004592427776766215, "phrase": "controlled_environment"}, {"score": 0.004460609967916904, "phrase": "real_world_imaging_conditions"}, {"score": 0.004254393078576148, "phrase": "e.g._glasses"}, {"score": 0.004132237700479874, "phrase": "pixel_clusters"}, {"score": 0.003870009704443373, "phrase": "eye_detection"}, {"score": 0.003717989314966981, "phrase": "head_movement"}, {"score": 0.0036909954181293405, "phrase": "eye_blinking"}, {"score": 0.0034692911858848893, "phrase": "usual_approach"}, {"score": 0.003381905288924267, "phrase": "tracking_routine"}, {"score": 0.003357343256340741, "phrase": "re-initialize_eye_detection"}, {"score": 0.003260860308644701, "phrase": "difficult_process"}, {"score": 0.0032253960472377356, "phrase": "missed_data_problem"}, {"score": 0.0031212935348800467, "phrase": "efficient_method"}, {"score": 0.0030426463790590445, "phrase": "successively_produced_video_image_frames"}, {"score": 0.00296597499768551, "phrase": "person's_head"}, {"score": 0.0028702214190712036, "phrase": "lighting_conditions"}, {"score": 0.0028183634079717136, "phrase": "present_paper"}, {"score": 0.0027674397462322435, "phrase": "efficient_and_reliable_method"}, {"score": 0.002727362288104989, "phrase": "human_eye"}, {"score": 0.002707541142254756, "phrase": "successively_produced_infrared_interlaced_image_frames"}, {"score": 0.002601065207135226, "phrase": "log_likelihood-ratio_function"}, {"score": 0.0025633909553815534, "phrase": "background_models"}, {"score": 0.002535492891830764, "phrase": "particle_filter-based_eye"}, {"score": 0.002480602069295564, "phrase": "key_information"}, {"score": 0.0023229408675543147, "phrase": "good_performance"}, {"score": 0.0022976536579329496, "phrase": "proposed_eye_tracker"}, {"score": 0.002280948283235427, "phrase": "challenging_conditions"}, {"score": 0.002256117165288155, "phrase": "moderate_head_motion"}, {"score": 0.0022397131088479514, "phrase": "significant_local_and_global_lighting_changes"}, {"score": 0.002183230464873613, "phrase": "eye_detector"}, {"score": 0.0021515951441422082, "phrase": "physiological_infrared_eye_responses"}, {"score": 0.002128169201317242, "phrase": "modified_version"}, {"score": 0.0021049977753042253, "phrase": "cascaded_classifier"}], "paper_keywords": ["eye position tracking", " filtering", " observation models", " structured infrared light", " non-visible spectrum", " eye tracking systems and countermeasures", " HCI"], "paper_abstract": "While existing eye detection and tracking algorithms can work reasonably well in a controlled environment, they tend to perform poorly under real world imaging conditions where the lighting produces shadows and the person's eyes can be occluded by e.g. glasses or makeup. As a result, pixel clusters associated with the eyes tend to be grouped together with background-features. This problem occurs both for eye detection and eye tracking. Problems that especially plague eye tracking include head movement, eye blinking and light changes, all of which can cause the eyes to suddenly disappear. The usual approach in such cases is to abandon the tracking routine and re-initialize eye detection. Of course this may be a difficult process due to missed data problem. Accordingly, what is needed is an efficient method of reliably tracking a person's eyes between successively produced video image frames, even in situations where the person's head turns, the eyes momentarily close and/or the lighting conditions are variable. The present paper is directed to an efficient and reliable method of tracking a human eye between successively produced infrared interlaced image frames where the lighting conditions are challenging. It proposes a log likelihood-ratio function of foreground and background models in a particle filter-based eye tracking framework. It fuses key information from even, odd infrared fields (dark and bright-pupil) and their corresponding subtractive image into one single observation model. Experimental validations show good performance of the proposed eye tracker in challenging conditions that include moderate head motion and significant local and global lighting changes. The paper presents also an eye detector that relies on physiological infrared eye responses and a modified version of a cascaded classifier. (C) 2006 Elsevier Inc. All rights reserved.", "paper_title": "An improved likelihood model for eye tracking", "paper_id": "WOS:000246747600007"}