{"auto_keywords": [{"score": 0.04888338488077779, "phrase": "pixel-level_hand_detection"}, {"score": 0.0048150284376570875, "phrase": "structured"}, {"score": 0.004463096299091981, "phrase": "hand_detection"}, {"score": 0.0043150485532080065, "phrase": "human-computer_interactions"}, {"score": 0.004102096151528319, "phrase": "challenging_problem"}, {"score": 0.0034944094552943, "phrase": "new_approach"}, {"score": 0.003378385493203297, "phrase": "inherent_contextual_information"}, {"score": 0.0033218213825698417, "phrase": "structured_hand_labelling"}, {"score": 0.003027178161479457, "phrase": "random_forest_framework"}, {"score": 0.0029020077365708966, "phrase": "hand_mask"}, {"score": 0.002853396755102163, "phrase": "hand_part"}, {"score": 0.002758597251689795, "phrase": "efficient_and_robust_manner"}, {"score": 0.0022522565004588113, "phrase": "hand_parts"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Hand detection", " Egocentric vision", " Random forests", " Hand part labelling"], "paper_abstract": "Hand detection has many important applications in Human-Computer Interactions, yet it is a challenging problem because the appearance of hands can vary greatly in images. In this paper, we present a new approach that exploits the inherent contextual information from structured hand labelling for pixel-level hand detection and hand part labelling. By using a random forest framework, our method can predict hand mask and hand part labels in an efficient and robust manner. Through experiments, we demonstrate that our method can outperform other state-of-the-art pixel-level detection methods in ego-centric videos, and further be able to parse hand parts in details. (c) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Structured forests for pixel-level hand detection and hand part labelling", "paper_id": "WOS:000364981500009"}