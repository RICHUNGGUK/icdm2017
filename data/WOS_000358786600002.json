{"auto_keywords": [{"score": 0.03417062918656798, "phrase": "proposed_technique"}, {"score": 0.00481495049065317, "phrase": "doppler_time-of-flight_imaging"}, {"score": 0.0047051051659828275, "phrase": "depth_cameras"}, {"score": 0.004451546786101008, "phrase": "human-computer_interaction"}, {"score": 0.004370087541308677, "phrase": "augmented_reality"}, {"score": 0.004329916183121203, "phrase": "machine_vision"}, {"score": 0.004270347498153512, "phrase": "medical_imaging"}, {"score": 0.004172874316207784, "phrase": "commercially-available_devices"}, {"score": 0.004040123129261597, "phrase": "flight_principle"}, {"score": 0.00398452530840582, "phrase": "active_illumination"}, {"score": 0.0037696519417841287, "phrase": "per-pixel_depth_map"}, {"score": 0.0035663245542174224, "phrase": "fundamentally_new_imaging_modality"}, {"score": 0.0031918759137610523, "phrase": "doppler_effect"}, {"score": 0.0030617935728586006, "phrase": "temporal_illumination_frequency"}, {"score": 0.002950608985750058, "phrase": "carefully_coded_illumination"}, {"score": 0.0029234476524900794, "phrase": "modulation_frequencies"}, {"score": 0.00288317238346065, "phrase": "tof_camera"}, {"score": 0.0028566300478906916, "phrase": "object_velocities"}, {"score": 0.0028042741141125712, "phrase": "measured_pixel_intensities"}, {"score": 0.0027275289970185015, "phrase": "slight_modification"}, {"score": 0.002498053212249228, "phrase": "optical_flow"}, {"score": 0.0024522530645471065, "phrase": "rgb_frames"}, {"score": 0.002418453525649304, "phrase": "measured_metric_radial_velocity"}, {"score": 0.0022149235007885826, "phrase": "vision_problems"}, {"score": 0.002174303033371869, "phrase": "motion_tracking"}, {"score": 0.0021049977753042253, "phrase": "motion_deblurring"}], "paper_keywords": ["computational photography", " time-of-flight"], "paper_abstract": "Over the last few years, depth cameras have become increasingly popular for a range of applications, including human-computer interaction and gaming, augmented reality, machine vision, and medical imaging. Many of the commercially-available devices use the time-of-flight principle, where active illumination is temporally coded and analyzed in the camera to estimate a per-pixel depth map of the scene. In this paper, we propose a fundamentally new imaging modality for all time-of-flight (ToF) cameras: per-pixel radial velocity measurement. The proposed technique exploits the Doppler effect of objects in motion, which shifts the temporal illumination frequency before it reaches the camera. Using carefully coded illumination and modulation frequencies of the ToF camera, object velocities directly map to measured pixel intensities. We show that a slight modification of our imaging system allows for color, depth, and velocity information to be captured simultaneously. Combining the optical flow computed on the RGB frames with the measured metric radial velocity allows us to further estimate the full 3D metric velocity field of the scene. The proposed technique has applications in many computer graphics and vision problems, for example motion tracking, segmentation, recognition, and motion deblurring.", "paper_title": "Doppler Time-of-Flight Imaging", "paper_id": "WOS:000358786600002"}