{"auto_keywords": [{"score": 0.04709232847739741, "phrase": "triangle_chain_code"}, {"score": 0.004815666799481952, "phrase": "triangle"}, {"score": 0.004720606036240263, "phrase": "image_matching"}, {"score": 0.004605258779434384, "phrase": "local_descriptor"}, {"score": 0.004029187256595917, "phrase": "feature_points"}, {"score": 0.00395017798595193, "phrase": "corner_detectors"}, {"score": 0.003685604033479918, "phrase": "discriminative_information"}, {"score": 0.003507504253087326, "phrase": "knn_neighborhoods"}, {"score": 0.0033879628186273625, "phrase": "proposed_triangle_chain_code"}, {"score": 0.0032724821705972357, "phrase": "matched_pair"}, {"score": 0.0032241994368246065, "phrase": "knn_structures"}, {"score": 0.003176626803985225, "phrase": "candidate_geometric_transformation"}, {"score": 0.0030081030319492343, "phrase": "geometric_transformation"}, {"score": 0.0029199689963238726, "phrase": "largest_number"}, {"score": 0.0028911669203979156, "phrase": "matched_point_pairs"}, {"score": 0.0028203950416405563, "phrase": "corresponding_matched_point_pairs"}, {"score": 0.002710735995572145, "phrase": "affine_transformation"}, {"score": 0.002670719148310961, "phrase": "image_registration"}, {"score": 0.0025924443774713473, "phrase": "least-square_fitting"}, {"score": 0.0025541693207036167, "phrase": "finally_selected_matched_point_pairs"}, {"score": 0.002516457934208144, "phrase": "image_registration_experiments"}, {"score": 0.002467038647952607, "phrase": "remote-sensing_images"}, {"score": 0.0023828731731474306, "phrase": "proposed_method"}, {"score": 0.0023245146355917626, "phrase": "object_recognition"}, {"score": 0.002245225304783468, "phrase": "sift"}, {"score": 0.002223044084917908, "phrase": "ransac"}, {"score": 0.002168586864007222, "phrase": "experimental_part"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Image matching", " Image retrieval", " Object recognition", " Point set matching", " Point pattern matching", " Image registration"], "paper_abstract": "We propose a local descriptor referred to as triangle chain code as well as a matching algorithm for point set matching, image registration, and object recognition and locating. First, feature points are detected using corner detectors. Second, triangle chain code is constructed for every point, which carries the discriminative information regarding its k nearest neighbors (KNN). Third, the KNN neighborhoods of two points are matched using the proposed triangle chain code matching algorithm. Fourth, every matched pair of the KNN structures determines a candidate geometric transformation mapping one point set to the other. Finally, the geometric transformation that is supported by the largest number of matched point pairs is selected and the corresponding matched point pairs are selected in the meantime. The affine transformation to conduct image registration can then be obtained by least-square fitting of the finally selected matched point pairs. The image registration experiments with regard to remote-sensing images show that the performance of the proposed method is satisfactory As for object recognition and locating, evaluation compared with SIFT plus RANSAC is provided in the experimental part. (c) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Triangle chain codes for image matching", "paper_id": "WOS:000324847100029"}