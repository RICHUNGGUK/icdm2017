{"auto_keywords": [{"score": 0.03609162416564472, "phrase": "activity_vectors"}, {"score": 0.015719716506582538, "phrase": "correspondence_matching"}, {"score": 0.015547084727554788, "phrase": "multi-view_video_sequences"}, {"score": 0.015376319150867715, "phrase": "mutual_information"}, {"score": 0.010435409021063343, "phrase": "random_variables"}, {"score": 0.004502943680955863, "phrase": "correspondence_matching_algorithm"}, {"score": 0.004354572391793908, "phrase": "reliable_performance"}, {"score": 0.004258372598568333, "phrase": "multiple_cameras"}, {"score": 0.004211069233133584, "phrase": "significantly_different_parameters"}, {"score": 0.0039380388343479384, "phrase": "activity_vector"}, {"score": 0.003829548069657859, "phrase": "temporal_occurrence_pattern"}, {"score": 0.0037658881407605445, "phrase": "foreground_objects"}, {"score": 0.003703282519292336, "phrase": "pixel_position"}, {"score": 0.0036214184763804034, "phrase": "invariant_feature"}, {"score": 0.0034630606658026595, "phrase": "novel_similarity_measure"}, {"score": 0.003348838095597268, "phrase": "joint_and_individual_behavior"}, {"score": 0.002847540262784593, "phrase": "reliable_homography_transform"}, {"score": 0.0027535633837592597, "phrase": "consistent_pixel_positions"}, {"score": 0.00269263690712392, "phrase": "iterative_bidirectional_matching"}, {"score": 0.002603758927691463, "phrase": "matching_results"}, {"score": 0.002574788013427524, "phrase": "multiple_source_pixel_positions"}, {"score": 0.0025178072071268534, "phrase": "matching_cost_function"}, {"score": 0.0024620842899061614, "phrase": "markov_random_field"}, {"score": 0.0024346858809238766, "phrase": "experimental_results"}, {"score": 0.0023807981747706376, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "visual_sensor_networks"}], "paper_keywords": ["Correspondence matching", " Markov random field", " multi-view videos", " mutual information based similarity measure", " visual sensor networks."], "paper_abstract": "We propose a correspondence matching algorithm for multi-view video sequences, which provides reliable performance even when the multiple cameras have significantly different parameters, such as viewing angles and positions. We use an activity vector, which represents the temporal occurrence pattern of moving foreground objects at a pixel position, as an invariant feature for correspondence matching. We first devise a novel similarity measure between activity vectors by considering the joint and individual behavior of the activity vectors. Specifically, we define random variables associated with the activity vectors and measure their similarity using the mutual information between the random variables. Moreover, to find a reliable homography transform between views, we find consistent pixel positions by employing the iterative bidirectional matching. We also refine the matching results of multiple source pixel positions by minimizing a matching cost function based on the Markov random field. Experimental results show that the proposed algorithm provides more accurate and reliable matching performance than the conventional activity-based and feature-based matching algorithms, and therefore can facilitate various applications of visual sensor networks.", "paper_title": "Correspondence Matching of Multi-View Video Sequences Using Mutual Information Based Similarity Measure", "paper_id": "WOS:000327393900001"}