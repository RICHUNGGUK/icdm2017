{"auto_keywords": [{"score": 0.04858113680192178, "phrase": "data_items"}, {"score": 0.031207500218646943, "phrase": "mcl"}, {"score": 0.012898168254324193, "phrase": "different_views"}, {"score": 0.00481495049065317, "phrase": "multi-view_concept_learning_for_data_representation"}, {"score": 0.004771435352180973, "phrase": "real-world_datasets"}, {"score": 0.004706895428234964, "phrase": "multiple_views"}, {"score": 0.004559661374976129, "phrase": "web_page"}, {"score": 0.004201801856682195, "phrase": "flickr"}, {"score": 0.0041074234667687875, "phrase": "visual_features"}, {"score": 0.0037848978618663684, "phrase": "multi-view_features"}, {"score": 0.0036998728605395384, "phrase": "comprehensive_description"}, {"score": 0.0034876091188625535, "phrase": "simple_idea"}, {"score": 0.0034403745992576808, "phrase": "different_feature_vectors"}, {"score": 0.0034092396400930446, "phrase": "statistical_properties"}, {"score": 0.003257727050827128, "phrase": "dimensionality\"_problem"}, {"score": 0.0031990183472675377, "phrase": "multi-view_concept_learning"}, {"score": 0.0030017207229983385, "phrase": "conceptual_factors"}, {"score": 0.00297454367746853, "phrase": "multi-view_data"}, {"score": 0.0028037753646260937, "phrase": "common_latent_space"}, {"score": 0.0026913130726432645, "phrase": "semantic_relationships"}, {"score": 0.0026427848602443267, "phrase": "graph_embedding_regularization"}, {"score": 0.0026188490199688013, "phrase": "labeled_items"}, {"score": 0.002525248554951453, "phrase": "latent_factor"}, {"score": 0.0024129269611844794, "phrase": "sparseness_constraints"}, {"score": 0.002316105585203396, "phrase": "flexible_conceptual_patterns"}, {"score": 0.002203016940021265, "phrase": "toy_problem"}, {"score": 0.0021049977753042253, "phrase": "baseline_methods"}], "paper_keywords": ["Multi-view learning", " nonnegative matrix factorization", " graph embedding", " structured sparsity"], "paper_abstract": "Real-world datasets often involve multiple views of data items, e.g., a Web page can be described by both its content and anchor texts of hyperlinks leading to it; photos in Flickr could be characterized by visual features, as well as user contributed tags. Different views provide information complementary to each other. Synthesizing multi-view features can lead to a comprehensive description of the data items, which could benefit many data analytic applications. Unfortunately, the simple idea of concatenating different feature vectors ignores statistical properties of each view and usually incurs the \"curse of dimensionality\" problem. We propose Multi-view Concept Learning (MCL), a novel nonnegative latent representation learning algorithm for capturing conceptual factors from multi-view data. MCL exploits both multi-view information and label information. The key idea is to learn a common latent space across different views which (1) captures the semantic relationships between data items through graph embedding regularization on labeled items, and (2) allows each latent factor to be associated with a subset of views via sparseness constraints. In this way, MCL could capture flexible conceptual patterns hidden in multi-view features. Experiments on a toy problem and three real-world datasets show that MCL performs well and outperforms baseline methods.", "paper_title": "Multi-View Concept Learning for Data Representation", "paper_id": "WOS:000362943700012"}