{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "egocentric_viewpoint"}, {"score": 0.004611369021812453, "phrase": "novel_framework"}, {"score": 0.004561826854638056, "phrase": "simultaneous_detection"}, {"score": 0.004512814529823301, "phrase": "click_action"}, {"score": 0.00441635700580562, "phrase": "occluded_fingertip_positions"}, {"score": 0.00436890075128947, "phrase": "egocentric_viewed_single-depth_image_sequences"}, {"score": 0.004161553532799662, "phrase": "novel_probabilistic_inference"}, {"score": 0.004094639048362357, "phrase": "knowledge_priors"}, {"score": 0.003775803846431323, "phrase": "estimation_results"}, {"score": 0.0036159990127332315, "phrase": "fine_resolution_level"}, {"score": 0.00355782527287734, "phrase": "bare_hand-based_interaction"}, {"score": 0.003298441494378465, "phrase": "rotation_and_translation_invariant_finger_clicking_action"}, {"score": 0.002944284514509205, "phrase": "novel_spatio-temporal_random_forest"}, {"score": 0.0027741761880779535, "phrase": "single_framework"}, {"score": 0.0026423134393535243, "phrase": "selection_process"}, {"score": 0.002599763359352916, "phrase": "proposed_clicking_action_detection"}, {"score": 0.0023841092222805253, "phrase": "additional_device"}, {"score": 0.00235843888868088, "phrase": "experimental_results"}, {"score": 0.0023079225317714815, "phrase": "proposed_method"}, {"score": 0.0022830706430588482, "phrase": "promising_performance"}, {"score": 0.002258485755625332, "phrase": "frequent_self-occlusions"}, {"score": 0.0021049977753042253, "phrase": "egocentric-depth_camera-attached_hmd."}], "paper_keywords": ["Hand tracking", " spatio-temporal forest", " selection", " augmented reality", " computer vision", " self-occlusion", " clicking action detection", " fingertip position estimation"], "paper_abstract": "In this paper we present a novel framework for simultaneous detection of click action and estimation of occluded fingertip positions from egocentric viewed single-depth image sequences. For the detection and estimation, a novel probabilistic inference based on knowledge priors of clicking motion and clicked position is presented. Based on the detection and estimation results, we were able to achieve a fine resolution level of a bare hand-based interaction with virtual objects in egocentric viewpoint. Our contributions include: (i) a rotation and translation invariant finger clicking action and position estimation using the combination of 2D image-based fingertip detection with 3D hand posture estimation in egocentric viewpoint. (ii) a novel spatio-temporal random forest, which performs the detection and estimation efficiently in a single framework. We also present (iii) a selection process utilizing the proposed clicking action detection and position estimation in an arm reachable AR/VR space, which does not require any additional device. Experimental results show that the proposed method delivers promising performance under frequent self-occlusions in the process of selecting objects in AR/VR space whilst wearing an egocentric-depth camera-attached HMD.", "paper_title": "3D Finger CAPE: Clicking Action and Position Estimation under Self-Occlusions in Egocentric Viewpoint", "paper_id": "WOS:000351757000010"}