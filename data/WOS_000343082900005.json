{"auto_keywords": [{"score": 0.03549402498548939, "phrase": "blue"}, {"score": 0.010612085509112107, "phrase": "sequencing_errors"}, {"score": 0.004526503177267299, "phrase": "better_quality_sequence_data"}, {"score": 0.004388796812234033, "phrase": "stand-alone_tools"}, {"score": 0.0042552618754756934, "phrase": "good_error-correcting_tool"}, {"score": 0.004211655451604066, "phrase": "transparent_component"}, {"score": 0.004179242907084957, "phrase": "bioinformatics_pipeline"}, {"score": 0.0041364122627073055, "phrase": "sequence_data"}, {"score": 0.004083488168551995, "phrase": "standard_formats"}, {"score": 0.0040416348762873115, "phrase": "higher_quality_version"}, {"score": 0.003989918570528528, "phrase": "far_fewer_errors"}, {"score": 0.003809138029723366, "phrase": "real_sequence_data"}, {"score": 0.0035440100731036913, "phrase": "large_datasets"}, {"score": 0.0035076666315744525, "phrase": "current_sequencing_technologies"}, {"score": 0.003427246079774314, "phrase": "haploid_and_diploid_organisms"}, {"score": 0.003288786791380568, "phrase": "k-mer_consensus"}, {"score": 0.0030914833562520425, "phrase": "fasta"}, {"score": 0.003051887221639784, "phrase": "quality_scores"}, {"score": 0.003036190943494256, "phrase": "corrected_bases"}, {"score": 0.002853997475142499, "phrase": "downstream_tools"}, {"score": 0.0027035450387550277, "phrase": "large_sequencing_datasets"}, {"score": 0.0025347150832077175, "phrase": "longer_contigs"}, {"score": 0.002315875759858594, "phrase": "small_set"}, {"score": 0.0022337135824264135, "phrase": "illumina"}, {"score": 0.0021158902559794295, "phrase": "even_better_assemblies"}, {"score": 0.0021049977753042253, "phrase": "higher_quality_finished_genomes"}], "paper_keywords": [""], "paper_abstract": "Motivation: Bioinformatics tools, such as assemblers and aligners, are expected to produce more accurate results when given better quality sequence data as their starting point. This expectation has led to the development of stand-alone tools whose sole purpose is to detect and remove sequencing errors. A good error-correcting tool would be a transparent component in a bioinformatics pipeline, simply taking sequence data in any of the standard formats and producing a higher quality version of the same data containing far fewer errors. It should not only be able to correct all of the types of errors found in real sequence data (substitutions, insertions, deletions and uncalled bases), but it has to be both fast enough and scalable enough to be usable on the large datasets being produced by current sequencing technologies, and work on data derived from both haploid and diploid organisms. Results: This article presents Blue, an error-correction algorithm based on k-mer consensus and context. Blue can correct substitution, deletion and insertion errors, as well as uncalled bases. It accepts both FASTQ and FASTA formats, and corrects quality scores for corrected bases. Blue also maintains the pairing of reads, both within a file and between pairs of files, making it compatible with downstream tools that depend on read pairing. Blue is memory efficient, scalable and faster than other published tools, and usable on large sequencing datasets. On the tests undertaken, Blue also proved to be generally more accurate than other published algorithms, resulting in more accurately aligned reads and the assembly of longer contigs containing fewer errors. One significant feature of Blue is that its k-mer consensus table does not have to be derived from the set of reads being corrected. This decoupling makes it possible to correct one dataset, such as small set of 454 mate-pair reads, with the consensus derived from another dataset, such as Illumina reads derived from the same DNA sample. Such cross-correction can greatly improve the quality of small (and expensive) sets of long reads, leading to even better assemblies and higher quality finished genomes.", "paper_title": "Blue: correcting sequencing errors using consensus and context", "paper_id": "WOS:000343082900005"}