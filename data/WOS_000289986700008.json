{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "ethically_correct_robots"}, {"score": 0.0040571383470418085, "phrase": "do's_and_don'ts"}, {"score": 0.0034954725617970294, "phrase": "reasoning_principles"}, {"score": 0.0027535633837592597, "phrase": "meta-ethical_capacities"}, {"score": 0.002285075675790214, "phrase": "computational_meta-ethics"}, {"score": 0.0021049977753042253, "phrase": "computational_metaphysics"}], "paper_keywords": ["Automated moral reasoning", " Computational meta-ethics"], "paper_abstract": "It has been argued that ethically correct robots should be able to reason about right and wrong. In order to do so, they must have a set of do's and don'ts at their disposal. However, such a list may be inconsistent, incomplete or otherwise unsatisfactory, depending on the reasoning principles that one employs. For this reason, it might be desirable if robots were to some extent able to reason about their own reasoning-in other words, if they had some meta-ethical capacities. In this paper, we sketch how one might go about designing robots that have such capacities. We show that the field of computational meta-ethics can profit from the same tools as have been used in computational metaphysics.", "paper_title": "Computational Meta-Ethics", "paper_id": "WOS:000289986700008"}