{"auto_keywords": [{"score": 0.02952447778442501, "phrase": "learning_process"}, {"score": 0.00481495049065317, "phrase": "different_levels"}, {"score": 0.004225950334493496, "phrase": "active_vision-based_pursuit"}, {"score": 0.004165105357908494, "phrase": "target_occlusion"}, {"score": 0.004016782710006123, "phrase": "different_lengths"}, {"score": 0.003973320429450603, "phrase": "first_layer"}, {"score": 0.0038179283509963695, "phrase": "known_method"}, {"score": 0.00376293585033711, "phrase": "mean_shift"}, {"score": 0.0037088532571931806, "phrase": "kalman"}, {"score": 0.003563651133299401, "phrase": "hybrid_filter"}, {"score": 0.003537886893587656, "phrase": "active_pursuit"}, {"score": 0.0034742916452682854, "phrase": "hap"}, {"score": 0.0034366728236876016, "phrase": "kalman_filter"}, {"score": 0.003172969962401266, "phrase": "target_identification"}, {"score": 0.003115908199991072, "phrase": "long-term_occlusions"}, {"score": 0.0030709962527878656, "phrase": "second_layer"}, {"score": 0.0030048355421601705, "phrase": "decision_algorithm"}, {"score": 0.002961519813246521, "phrase": "learning_procedure"}, {"score": 0.0029082496141037764, "phrase": "game_theory-related_reinforcement"}, {"score": 0.002887211740180388, "phrase": "cesa-bianchi"}, {"score": 0.0026366753045215558, "phrase": "small_number"}, {"score": 0.0025611773887867255, "phrase": "data_structure"}, {"score": 0.002460876181416983, "phrase": "central_control"}, {"score": 0.0024342079318127423, "phrase": "multi-agent_system"}, {"score": 0.0022967713922705, "phrase": "efficient_agent"}, {"score": 0.0022472527731744974, "phrase": "inefficient_agent"}, {"score": 0.0021049977753042253, "phrase": "multi-agent_control_system"}], "paper_keywords": ["Bio-inspired computer vision", " Hybrid system", " Active pursuit", " Reinforcement learning", " Tracking with occlusion"], "paper_abstract": "We present an algorithm for real-time, robust, vision-based active tracking and pursuit. The algorithm was designed to overcome problems arising from active vision-based pursuit, such as target occlusion. Our method employs two layers to deal with occlusions of different lengths. The first layer is for short- or medium-term occlusions: those where a known method-such as mean shift combined with a Kalman filter-fails. For this layer we designed the hybrid filter for active pursuit (HAP). HAP utilizes a Kalman filter modified to respond to two different modes of action: one in which the target is positively identified and one in which the target identification is uncertain. For long-term occlusions we use the second layer. This layer is a decision algorithm that follows a learning procedure and is based on game theory-related reinforcement (Cesa-Bianchi and Lugosi, Prediction Learning and Games, 2006). The learning process is based on trial and error and is designed to perform adequately with a small number of samples. The algorithm produces a data structure that can be shared among agents or sent to a central control of a multi-agent system. The learning process is designed so that agents perform tasks according to their skills: an efficient agent will pursue targets while an inefficient agent will search for entering targets. These capacities make this system well suited for embedding in a multi-agent control system.", "paper_title": "Active tracking and pursuit under different levels of occlusion: a two-layer approach", "paper_id": "WOS:000330314100013"}