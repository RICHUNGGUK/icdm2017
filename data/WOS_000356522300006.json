{"auto_keywords": [{"score": 0.041078685670043524, "phrase": "landmark_images"}, {"score": 0.03311384186396777, "phrase": "hmme"}, {"score": 0.00481495049065317, "phrase": "landmark_classification_with_hierarchical_multi-modal_exemplar_feature"}, {"score": 0.0047761092701293474, "phrase": "landmark_image_classification"}, {"score": 0.004718431349852634, "phrase": "research_attention"}, {"score": 0.0046238380150870435, "phrase": "real_applications"}, {"score": 0.004549524321051407, "phrase": "travel_guide_recommendation"}, {"score": 0.004386637056030611, "phrase": "large_amount"}, {"score": 0.004061584718427419, "phrase": "key_reasons"}, {"score": 0.004012500850311087, "phrase": "large_intra-class_variance"}, {"score": 0.003947973513495612, "phrase": "diverse_visual_appearance"}, {"score": 0.003806541299696042, "phrase": "scalable_image_search"}, {"score": 0.003685067218455088, "phrase": "new_perspective"}, {"score": 0.0036553070575015344, "phrase": "model_landmark_classification"}, {"score": 0.0036257863613963245, "phrase": "multi-modal_categorization"}, {"score": 0.0035386420095120706, "phrase": "low_storage_overhead"}, {"score": 0.0035100601949451028, "phrase": "high_classification_efficiency"}, {"score": 0.003384262486955773, "phrase": "effective_feature_representation"}, {"score": 0.0033433365160336842, "phrase": "hierarchical_multi-modal_exemplar"}, {"score": 0.003107935254560724, "phrase": "training_images"}, {"score": 0.0030086877092638945, "phrase": "hierarchical_grids"}, {"score": 0.0029722900280316216, "phrase": "candidate_images"}, {"score": 0.0028541057064952876, "phrase": "exemplar_selection"}, {"score": 0.002831037222426215, "phrase": "hierarchical_discriminative_exemplars"}, {"score": 0.0028081546657056948, "phrase": "multiple_modalities"}, {"score": 0.002751751956416832, "phrase": "iterative_boosting"}, {"score": 0.0027295084882654917, "phrase": "latent_region_label_mining"}, {"score": 0.0026316112429083235, "phrase": "region-based_locality-constrained_linear_coding"}, {"score": 0.0025167026017217926, "phrase": "discovered_exemplars"}, {"score": 0.0024963543716522087, "phrase": "hmme."}, {"score": 0.002466139325703204, "phrase": "dimension_reduction"}, {"score": 0.00241658945942583, "phrase": "redundant_information"}, {"score": 0.0023776656246300063, "phrase": "raw_hmme"}, {"score": 0.00235843888868088, "phrase": "lower-dimensional_space"}, {"score": 0.0023298892270500983, "phrase": "final_hmme"}, {"score": 0.002246292543825748, "phrase": "experimental_study"}, {"score": 0.0021922308351126746, "phrase": "real_world_landmark_datasets"}, {"score": 0.0021307975800397816, "phrase": "superior_performance"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Dimension reduction", " diverse visual contents", " exemplar selection", " hierarchical multi-modal exemplar feature (HMME)", " landmark classification", " region-based locality-constrained linear coding (RLLC)"], "paper_abstract": "Landmark image classification attracts increasing research attention due to its great importance in real applications, ranging from travel guide recommendation to 3-D modelling and visualization of geolocation. While large amount of efforts have been invested, it still remains unsolved by academia and industry. One of the key reasons is the large intra-class variance rooted from the diverse visual appearance of landmark images. Distinguished from most existing methods based on scalable image search, we approach the problem from a new perspective and model landmark classification as multi-modal categorization, which enjoys advantages of low storage overhead and high classification efficiency. Toward this goal, a novel and effective feature representation, called hierarchical multi-modal exemplar (HMME) feature, is proposed to characterize landmark images. In order to compute HMME, training images are first partitioned into the regions with hierarchical grids to generate candidate images and regions. Then, at the stage of exemplar selection, hierarchical discriminative exemplars in multiple modalities are discovered automatically via iterative boosting and latent region label mining. Finally, HMME is generated via a region-based locality-constrained linear coding (RLLC), which effectively encodes semantics of the discovered exemplars into HMME. Meanwhile, dimension reduction is applied to reduce redundant information by projecting the raw HMME into lower-dimensional space. The final HMME enjoys advantages of discriminative and linearly separable. Experimental study has been carried out on real world landmark datasets, and the results demonstrate the superior performance of the proposed approach over several state-of-the-art techniques.", "paper_title": "Landmark Classification With Hierarchical Multi-Modal Exemplar Feature", "paper_id": "WOS:000356522300006"}