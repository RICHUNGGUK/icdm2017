{"auto_keywords": [{"score": 0.049825994610035174, "phrase": "distributed_speech_recognition"}, {"score": 0.04957466661795797, "phrase": "ip_networks"}, {"score": 0.04192538265978381, "phrase": "lost_segment"}, {"score": 0.00481495049065317, "phrase": "decoding_strategies"}, {"score": 0.004701556483912018, "phrase": "burst-like_packet_losses"}, {"score": 0.004652016085325825, "phrase": "serious_degradation"}, {"score": 0.004494570360108983, "phrase": "high_speech-signal_correlation"}, {"score": 0.004240116703465252, "phrase": "correctly_received_frames"}, {"score": 0.004195418010131832, "phrase": "nearest_frame_repetition"}, {"score": 0.004085713541752114, "phrase": "etsi_aurora_standard"}, {"score": 0.003978866233891427, "phrase": "interpolation_algorithms"}, {"score": 0.003957833102043277, "phrase": "even_more_complex_mechanisms"}, {"score": 0.0037834649508375544, "phrase": "long_bursts"}, {"score": 0.00362635182075772, "phrase": "repetition_algorithms"}, {"score": 0.003531474887552889, "phrase": "substituted_frame"}, {"score": 0.003503497128638099, "phrase": "high_insertion_rate"}, {"score": 0.0034573575145364207, "phrase": "word_error_rate"}, {"score": 0.0033579708256295847, "phrase": "feasible_strategy"}, {"score": 0.0032787762246235517, "phrase": "soft-decoding_algorithm"}, {"score": 0.0031176485976102688, "phrase": "decoding_stage"}, {"score": 0.003044104460133612, "phrase": "incorrect_vectors"}, {"score": 0.0030199761431186434, "phrase": "recognition_stage"}, {"score": 0.0029565620771207003, "phrase": "comprehensive_study"}, {"score": 0.0029098743621130004, "phrase": "soft-decoding_weighted_viterbi_algorithms"}, {"score": 0.0028868069049393288, "phrase": "burst-like_network_environment"}, {"score": 0.0027741761880779535, "phrase": "nfr_algorithm"}, {"score": 0.002752181482293922, "phrase": "baseline_approach"}, {"score": 0.002687235334499192, "phrase": "first_one"}, {"score": 0.0026659280855649385, "phrase": "fixed_weighting"}, {"score": 0.002575526825728026, "phrase": "basic_nfr_algorithm"}, {"score": 0.0024947959375982614, "phrase": "strong_dependence"}, {"score": 0.002481588370380518, "phrase": "mean_burst_length"}, {"score": 0.0024423826953133844, "phrase": "varying_weighting"}, {"score": 0.0022434880661725493, "phrase": "weighting_coefficient"}, {"score": 0.002213905386163836, "phrase": "third_method"}, {"score": 0.002190519728921395, "phrase": "different_degree"}, {"score": 0.0021673805596370936, "phrase": "individual_components"}, {"score": 0.0021501863832966966, "phrase": "feature_vector"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["distributed speech recognition", " weighted Viterbi decoding", " missing data"], "paper_abstract": "The presence of burst-like packet losses may produce a serious degradation of the performance of Distributed Speech Recognition systems over IP networks. Several strategies that exploit high speech-signal correlation have already been proposed to overcome this problem. One of the most common mechanisms is to fill in the gap using the correctly received frames, as in nearest frame repetition (NFR), the mechanism proposed in the ETSI Aurora standard. Other strategies involve the reconstruction of the lost segment using interpolation algorithms or even more complex mechanisms. However, the effectiveness of these strategies may be seriously compromised if losses appear in long bursts. Interpolation may simply become unfeasible if the lost segment is a lengthy one. In repetition algorithms, on the other hand, the unreliability of the substituted frame produces a high insertion rate that can reduce the word error rate to the point where the mechanism becomes counterproductive. A feasible strategy for palliating this effect is to use a soft-decoding algorithm. In this kind of strategy, the reliability of the frame is taken into account at the decoding stage, aiming to mitigate the effect of the incorrect vectors in the recognition stage. In this paper we present a comprehensive study of the performance of some soft-decoding weighted Viterbi algorithms in a burst-like network environment. Tests will be conducted using the Aurora 3 framework working over three simulated network conditions, with the NFR algorithm as the baseline approach. Three techniques will be thoroughly explored. The first one uses a fixed weighting coefficient along the burst. This improves the results obtained by the basic NFR algorithm, but with the drawback, however, of showing a strong dependence on mean burst length. The application of a varying weighting coefficient is proposed next as a way to solve this problem. Two strategies-one heuristic and one data-driven-are proposed to obtain the variation in the weighting coefficient. Finally, a third method that exploits the different degree of correlation of individual components of the feature vector is presented. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Weighted Viterbi decoding strategies for distributed speech recognition over IP networks", "paper_id": "WOS:000242336300003"}