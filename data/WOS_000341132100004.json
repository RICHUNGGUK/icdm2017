{"auto_keywords": [{"score": 0.04904408662148984, "phrase": "active_learning"}, {"score": 0.014860246541838849, "phrase": "data_points"}, {"score": 0.009099312787110053, "phrase": "data_point"}, {"score": 0.00481495049065317, "phrase": "support_vector_machines"}, {"score": 0.004752221133109136, "phrase": "machine_learning"}, {"score": 0.004316396683332752, "phrase": "large_amounts"}, {"score": 0.004278807087784626, "phrase": "unlabeled_data"}, {"score": 0.00397217701571219, "phrase": "complex_experiments"}, {"score": 0.0037855348847339655, "phrase": "active_learning_algorithm"}, {"score": 0.003498782065781398, "phrase": "learned_model"}, {"score": 0.003247868216333148, "phrase": "labeling_costs"}, {"score": 0.0031637602730676686, "phrase": "svm"}, {"score": 0.002949598537993663, "phrase": "linear_classification"}, {"score": 0.0028857130140890787, "phrase": "kernel-induced_feature_space"}, {"score": 0.002737960968372391, "phrase": "decision_boundary_straightforward"}, {"score": 0.0025414699652861667, "phrase": "current_model"}, {"score": 0.0024325244760735566, "phrase": "training_samples"}, {"score": 0.0023902621773166963, "phrase": "brief_introduction"}, {"score": 0.002359046870732839, "phrase": "active_learning_problem"}, {"score": 0.0023180581939456686, "phrase": "different_query_strategies"}, {"score": 0.002287783663138828, "phrase": "informative_data_points"}, {"score": 0.0021993066642488237, "phrase": "different_variants"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": [""], "paper_abstract": "In machine learning, active learning refers to algorithms that autonomously select the data points from which they will learn. There are many data mining applications in which large amounts of unlabeled data are readily available, but labels (e. g., human annotations or results coming from complex experiments) are costly to obtain. In such scenarios, an active learning algorithm aims at identifying data points that, if labeled and used for training, would most improve the learned model. Labels are then obtained only for the most promising data points. This speeds up learning and reduces labeling costs. Support vector machine (SVM) classifiers are particularly well-suited for active learning due to their convenient mathematical properties. They perform linear classification, typically in a kernel-induced feature space, which makes expressing the distance of a data point from the decision boundary straightforward. Furthermore, heuristics can efficiently help estimate how strongly learning from a data point influences the current model. This information can be used to actively select training samples. After a brief introduction to the active learning problem, we discuss different query strategies for selecting informative data points and review how these strategies give rise to different variants of active learning with SVMs. (C) 2014 John Wiley & Sons, Ltd.", "paper_title": "Active learning with support vector machines", "paper_id": "WOS:000341132100004"}