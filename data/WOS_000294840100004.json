{"auto_keywords": [{"score": 0.04963913874714364, "phrase": "imbalanced_data_sets"}, {"score": 0.00481495049065317, "phrase": "data_complexity"}, {"score": 0.0046834372388970405, "phrase": "smote-based_oversampling"}, {"score": 0.004534517530868195, "phrase": "classification_framework"}, {"score": 0.003911578552479064, "phrase": "minority_classes"}, {"score": 0.003839962121679795, "phrase": "learning_algorithms"}, {"score": 0.003683565150278339, "phrase": "usual_approach"}, {"score": 0.003468796799802612, "phrase": "preprocessing_step"}, {"score": 0.0032968474833776906, "phrase": "data_complexity_measures"}, {"score": 0.0031479142819948007, "phrase": "oversampling_methods"}, {"score": 0.0029780219173522115, "phrase": "wide_range"}, {"score": 0.002909960617042717, "phrase": "real_data"}, {"score": 0.0028566300478906916, "phrase": "oversampling_techniques"}, {"score": 0.0026651772919894534, "phrase": "behavior_patterns"}, {"score": 0.0025922289692173997, "phrase": "data_complexity_space"}, {"score": 0.002341384304635523, "phrase": "good_or_bad_behaviors"}, {"score": 0.002266765479420981, "phrase": "different_preprocessing_approaches"}, {"score": 0.0022149235007885826, "phrase": "complete_characterization"}, {"score": 0.0021843879253500894, "phrase": "data_sets"}, {"score": 0.0021049977753042253, "phrase": "undersampling_results"}], "paper_keywords": ["Classification", " Evolutionary algorithms", " Data complexity", " Imbalanced data sets", " Oversampling", " Undersampling", " C4.5", " PART"], "paper_abstract": "In the classification framework there are problems in which the number of examples per class is not equitably distributed, formerly known as imbalanced data sets. This situation is a handicap when trying to identify the minority classes, as the learning algorithms are not usually adapted to such characteristics. An usual approach to deal with the problem of imbalanced data sets is the use of a preprocessing step. In this paper we analyze the usefulness of the data complexity measures in order to evaluate the behavior of undersampling and oversampling methods. Two classical learning methods, C4.5 and PART, are considered over a wide range of imbalanced data sets built from real data. Specifically, oversampling techniques and an evolutionary undersampling one have been selected for the study. We extract behavior patterns from the results in the data complexity space defined by the measures, coding them as intervals. Then, we derive rules from the intervals that describe both good or bad behaviors of C4.5 and PART for the different preprocessing approaches, thus obtaining a complete characterization of the data sets and the differences between the oversampling and undersampling results.", "paper_title": "Addressing data complexity for imbalanced data sets: analysis of SMOTE-based oversampling and evolutionary undersampling", "paper_id": "WOS:000294840100004"}