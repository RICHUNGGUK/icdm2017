{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "gilbert"}, {"score": 0.0052603140002532274, "phrase": "sch"}, {"score": 0.00470325458481566, "phrase": "general_svm_classifiers"}, {"score": 0.0046593017130868, "phrase": "geometric_methods"}, {"score": 0.004594137808658537, "phrase": "intuitive_and_theoretically_solid_viewpoint"}, {"score": 0.004383406949799696, "phrase": "pattern_recognition"}, {"score": 0.004342430078306461, "phrase": "machine_learning"}, {"score": 0.004104456271230213, "phrase": "excellent_generalization_performance"}, {"score": 0.004047020753789236, "phrase": "wide_variety"}, {"score": 0.0038431888954930083, "phrase": "\"scaled_convex_hull"}, {"score": 0.003649585593445665, "phrase": "nonseparable_svm_classifications"}, {"score": 0.003548111729206587, "phrase": "separable_ones"}, {"score": 0.00348202932445197, "phrase": "suitable_selection"}, {"score": 0.0034332736827447654, "phrase": "reduction_factor"}, {"score": 0.0033851984021896287, "phrase": "initially_overlapping_schs"}, {"score": 0.0032756158688245, "phrase": "training_patterns"}, {"score": 0.0029260602766930065, "phrase": "standard_nonseparable_svm."}, {"score": 0.002885066818322192, "phrase": "practical_application"}, {"score": 0.0028446460307503343, "phrase": "sch_framework"}, {"score": 0.0028047899594686003, "phrase": "popular_gilbert's_algorithm"}, {"score": 0.0025290375256888883, "phrase": "better_performance"}, {"score": 0.0023902026696615473, "phrase": "improved_sequential_minimal_optimization"}, {"score": 0.0023678143146455017, "phrase": "gilbert's_algorithm"}, {"score": 0.002323663295811215, "phrase": "reduced_convex_hull"}, {"score": 0.0022064376000055764, "phrase": "kernel_evaluations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Support vector machines", " Maximal margin", " Reduced convex hulls", " Scaled convex hulls", " Gilbert's algorithm"], "paper_abstract": "Geometric methods provide an intuitive and theoretically solid viewpoint for the solution of many optimization problems in the fields of pattern recognition and machine learning. The support vector machine (SVM) classification is a typical optimization task that has achieved excellent generalization performance in a wide variety of applications. In this paper, the notion of \"scaled convex hull\" (SCH) is presented, through which the nonseparable SVM classifications can be approximately transformed to separable ones: by a suitable selection of the reduction factor, the initially overlapping SCHs (each is generated by the training patterns of each class) can be reduced to become separable, then the maximal margin classifier between them can be trained, which is an approximation of the standard nonseparable SVM. As a practical application of the SCH framework, the popular Gilbert's algorithm has been generalized to approximately solve general (linear and nonlinear, separable and nonseparable) SVM classification problems both accurately and efficiently. The experiments show that the proposed method may achieve better performance than the state-of-the-art methods, an improved sequential minimal optimization and Gilbert's algorithm based on the reduced convex hull (RCH), in terms of the number of kernel evaluations and the execution time. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "A generalized Gilbert's algorithm for approximating general SVM classifiers", "paper_id": "WOS:000272607000028"}