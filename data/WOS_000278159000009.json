{"auto_keywords": [{"score": 0.05007852962010534, "phrase": "ordinal_classification"}, {"score": 0.004646496622257368, "phrase": "important_role"}, {"score": 0.0042354707960660706, "phrase": "learning_tasks"}, {"score": 0.004145882022189891, "phrase": "general_classification_learning"}, {"score": 0.004087207102190335, "phrase": "shannon_information_entropy"}, {"score": 0.004000741805312148, "phrase": "derived_measure"}, {"score": 0.003944112858235306, "phrase": "mutual_information"}, {"score": 0.0038606630003037864, "phrase": "fundamental_role"}, {"score": 0.003646629717560631, "phrase": "feature_evaluation"}, {"score": 0.003544088803300751, "phrase": "decision_tree_construction"}, {"score": 0.002923214590192792, "phrase": "shannon's_entropy"}, {"score": 0.002881793492919646, "phrase": "crisp_ordinal_classification"}, {"score": 0.0028409576481842457, "phrase": "fuzzy_ordinal_classification"}, {"score": 0.0027413748388534025, "phrase": "information_measures"}, {"score": 0.002683304054823427, "phrase": "mutual_information_and_fuzzy_ranking_mutual_information"}, {"score": 0.002445514186654732, "phrase": "proposed_ranking_mutual_information_and_fuzzy_ranking_mutual_information"}, {"score": 0.0021971473452127126, "phrase": "proposed_indexes"}, {"score": 0.0021049977753042253, "phrase": "monotonicity_degree"}], "paper_keywords": ["ordinal classification", " information entropy", " ranking entropy", " ranking mutual information"], "paper_abstract": "Ordinal classification plays an important role in various decision making tasks. However, little attention is paid to this type of learning tasks compared with general classification learning. Shannon information entropy and the derived measure of mutual information play a fundamental role in a number of learning algorithms including feature evaluation, selection and decision tree construction. These measures are not applicable to ordinal classification for they cannot characterize the consistency of monotonicity in ordinal classification. In this paper, we generalize Shannon's entropy to crisp ordinal classification and fuzzy ordinal classification, and show the information measures of ranking mutual information and fuzzy ranking mutual information. We discuss the properties of these measures and show that the proposed ranking mutual information and fuzzy ranking mutual information are the indexes of consistency of monotonicity in ordinal classification. In addition, the proposed indexes are used to evaluate the monotonicity degree between features and decision in the context of ordinal classification.", "paper_title": "Information entropy for ordinal classification", "paper_id": "WOS:000278159000009"}