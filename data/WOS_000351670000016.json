{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "experimental_validation"}, {"score": 0.004598933498016774, "phrase": "service-wise_optimisation"}, {"score": 0.004552255360140208, "phrase": "heterogeneous_wireless_sensor_networks"}, {"score": 0.0044150318724093226, "phrase": "wireless_sensor_networks"}, {"score": 0.004216880725292, "phrase": "specific_application_domain"}, {"score": 0.004068907083697369, "phrase": "custom_medium_access_control_protocol"}, {"score": 0.0038862297330905836, "phrase": "close_proximity"}, {"score": 0.003711723285313348, "phrase": "individual_networks"}, {"score": 0.003545024951402821, "phrase": "unexpected_protocol_interactions"}, {"score": 0.0034911335714333507, "phrase": "performance_impact"}, {"score": 0.003438058620195309, "phrase": "'protocol_interference"}, {"score": 0.003351381374975648, "phrase": "exact_set"}, {"score": 0.003120099687922751, "phrase": "optimisation_approach"}, {"score": 0.0030726480920918097, "phrase": "self-learning_techniques"}, {"score": 0.0029951555610569225, "phrase": "optimal_combination"}, {"score": 0.002889928791032578, "phrase": "individual_network"}, {"score": 0.0027600360731762997, "phrase": "optimal_set"}, {"score": 0.0026359661683151006, "phrase": "co-located_heterogeneous_sensor_networks"}, {"score": 0.002530359917257626, "phrase": "manual_reconfiguration"}, {"score": 0.002479150189700726, "phrase": "minimal_a_priori_knowledge"}, {"score": 0.00240426758768164, "phrase": "continuous_re-evaluation"}, {"score": 0.002367676766637248, "phrase": "decision_process"}, {"score": 0.0023197517832705297, "phrase": "volatile_networking_conditions"}, {"score": 0.002272794656458419, "phrase": "highly_dynamic_environments"}, {"score": 0.0021705796895687864, "phrase": "large_scale_testbed"}, {"score": 0.0021049977753042253, "phrase": "clear_decrease"}], "paper_keywords": ["Network cooperation", " Self-awareness", " Reinforcement learning", " Linear approximation", " Network service negotiation", " epsilon greedy", " Logarithmic state access distribution"], "paper_abstract": "Due to their constrained nature, wireless sensor networks (WSNs) are often optimised for a specific application domain, for example by designing a custom medium access control protocol. However, when several WSNs are located in close proximity to one another, the performance of the individual networks can be negatively affected as a result of unexpected protocol interactions. The performance impact of this 'protocol interference' depends on the exact set of protocols and (network) services used. This paper therefore proposes an optimisation approach that uses self-learning techniques to automatically learn the optimal combination of services and/or protocols in each individual network. We introduce tools capable of discovering this optimal set of services and protocols for any given set of co-located heterogeneous sensor networks. These tools eliminate the need for manual reconfiguration while only requiring minimal a priori knowledge about the network. A continuous re-evaluation of the decision process provides resilience to volatile networking conditions in case of highly dynamic environments. The methodology is experimentally evaluated in a large scale testbed using both single- and multihop scenarios, showing a clear decrease in end-to-end delay and an increase in reliability of almost 25 %.", "paper_title": "Experimental validation of a reinforcement learning based approach for a service-wise optimisation of heterogeneous wireless sensor networks", "paper_id": "WOS:000351670000016"}