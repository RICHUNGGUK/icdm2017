{"auto_keywords": [{"score": 0.0437997945213214, "phrase": "data_caches"}, {"score": 0.029926178931485532, "phrase": "worst-case_performance"}, {"score": 0.00481495049065317, "phrase": "multitasking_real-time_systems"}, {"score": 0.004752221133109136, "phrase": "worst-case_execution_time"}, {"score": 0.004710860389424758, "phrase": "wcet"}, {"score": 0.004588891098290524, "phrase": "also_the_effects"}, {"score": 0.004450568197899267, "phrase": "worst-case_scenario"}, {"score": 0.004024651422626329, "phrase": "small_instruction-driven_data_cache"}, {"score": 0.003752550907120244, "phrase": "memory_instructions"}, {"score": 0.003687439449869248, "phrase": "data_cache_replacement_permission"}, {"score": 0.0035605741849764187, "phrase": "data_reuse_theory"}, {"score": 0.003498782065781398, "phrase": "selected_memory_instruction"}, {"score": 0.0032336801561165113, "phrase": "associated_data_structures"}, {"score": 0.0031223774204093713, "phrase": "lock-ms_wcet_analysis_method"}, {"score": 0.002923876831533028, "phrase": "program_data"}, {"score": 0.0028857130140890787, "phrase": "tested_benchmarks"}, {"score": 0.0027140798043053986, "phrase": "worst_case"}, {"score": 0.0026321198895843173, "phrase": "ideal_case"}, {"score": 0.0024007585788965655, "phrase": "marginal_benefits"}, {"score": 0.0021993066642488237, "phrase": "mibench_application_suite"}, {"score": 0.0021422271362195712, "phrase": "hit_ratios"}], "paper_keywords": ["Design", " Performance", " Worst-case analysis"], "paper_abstract": "In multitasking real-time systems, the worst-case execution time (WCET) of each task and also the effects of interferences between tasks in the worst-case scenario need to be calculated. This is especially complex in the presence of data caches. In this article, we propose a small instruction-driven data cache (256 bytes) that effectively exploits locality. It works by preselecting a subset of memory instructions that will have data cache replacement permission. Selection of such instructions is based on data reuse theory. Since each selected memory instruction replaces its own data cache line, it prevents pollution and performance in tasks becomes independent of the size of the associated data structures. We have modeled several memory configurations using the Lock-MS WCET analysis method. Our results show that, on average, our data cache effectively services 88% of program data of the tested benchmarks. Such results double the worst-case performance of our tested multitasking experiments. In addition, in the worst case, they reach between 75% and 89% of the ideal case of always hitting in instruction and data caches. As well, we show that using partitioning on our proposed hardware only provides marginal benefits in worst-case performance, so using partitioning is discouraged. Finally, we study the viability of our proposal in the MiBench application suite by characterizing its data reuse, achieving hit ratios beyond 90% in most programs.", "paper_title": "ACDC: Small, Predictable and High-Performance Data Cache", "paper_id": "WOS:000352224800019"}