{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "mpi"}, {"score": 0.02303450862994536, "phrase": "openmp"}, {"score": 0.009591410690793055, "phrase": "best_performance"}, {"score": 0.007508667417364385, "phrase": "nas_benchmark"}, {"score": 0.004734038956773703, "phrase": "shared_memory_multiprocessors"}, {"score": 0.004634799977448855, "phrase": "shared_memory_multiprocessor"}, {"score": 0.0044424917428102445, "phrase": "portable_programming_model"}, {"score": 0.004186534737631288, "phrase": "standard_programming_environments"}, {"score": 0.003978866233891427, "phrase": "programming_approach"}, {"score": 0.0038624981944755813, "phrase": "openmip_programming_styles"}, {"score": 0.003533347967582184, "phrase": "large_parallel_sections"}, {"score": 0.0035034979970212845, "phrase": "spmd"}, {"score": 0.0033440274461706988, "phrase": "mg"}, {"score": 0.003045736748141416, "phrase": "ibm"}, {"score": 0.002870006736445581, "phrase": "first_spmd_openmp_version"}, {"score": 0.0027741761880779535, "phrase": "independent_sources"}, {"score": 0.002750723004588879, "phrase": "pbn"}, {"score": 0.002727464442366443, "phrase": "sdsc"}, {"score": 0.002704403349815203, "phrase": "rwcp"}, {"score": 0.0026701760128830573, "phrase": "experimental_results"}, {"score": 0.0026140878612307536, "phrase": "competitive_performance"}, {"score": 0.002548331088496964, "phrase": "large_set"}, {"score": 0.002526780881314497, "phrase": "experimental_conditions"}, {"score": 0.0024114635128122783, "phrase": "strongest_programming_effort"}, {"score": 0.0022530375696567136, "phrase": "execution_times"}, {"score": 0.002215081186105616, "phrase": "hardware_performance"}, {"score": 0.002168531704054597, "phrase": "performance_differences"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["MPI", " OpenMP", " performance evaluation", " shared memory multiprocessors"], "paper_abstract": "When using a shared memory multiprocessor, the programmer faces the issue of selecting the portable programming model which will provide the best performance. Even if they restricts their choice to the standard programming environments (MPI and OpenMP), they have to select a programming approach among MPI and the variety of OpenMIP programming styles. To help the programmer in their decision, we compare MPI with three OpenMP programming styles (loop level, loop level with large parallel sections, SPMD) using a subset of the NAS benchmark (CG, MG, FT, LU), two dataset sizes (A and B), and two shared memory multiprocessors (IBM SP3 NightHawk II, SGI Origin 3800). We have developed the first SPMD OpenMP version of the NAS benchmark and gathered other OpenMP versions from independent sources (PBN, SDSC and RWCP). Experimental results demonstrate that OpenMP provides competitive performance compared with MPI for a large set of experimental conditions. Not surprisingly, the two best OpenMP versions are those requiring the strongest programming effort. MPI still provides the best performance under some conditions. We present breakdowns of the execution times and measurements of hardware performance counters to explain the performance differences. Copyright (c) 2005 John Wiley & Sons, Ltd.", "paper_title": "Performance comparison of MPI and OpenMP on shared memory multiprocessors", "paper_id": "WOS:000234017200002"}