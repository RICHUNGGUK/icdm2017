{"auto_keywords": [{"score": 0.020188292989202886, "phrase": "version_history"}, {"score": 0.008326729095763439, "phrase": "training_data"}, {"score": 0.007663957832550331, "phrase": "change_propagation"}, {"score": 0.006867811446698466, "phrase": "change_impacts"}, {"score": 0.005851045421883617, "phrase": "accurate_predictions"}, {"score": 0.00481495049065317, "phrase": "dependency-based_change"}, {"score": 0.004758053266234474, "phrase": "independent_change_histories"}, {"score": 0.004701825207431857, "phrase": "recent_studies"}, {"score": 0.004646258518859209, "phrase": "present_data"}, {"score": 0.004550585106483935, "phrase": "current_software_version"}, {"score": 0.004430452655732319, "phrase": "previous_software_versions"}, {"score": 0.004339203636449911, "phrase": "change_impact_predictions"}, {"score": 0.004262481067951517, "phrase": "specific_program"}, {"score": 0.004237208239631876, "phrase": "existing_combined_techniques"}, {"score": 0.004052358316137446, "phrase": "prediction_results"}, {"score": 0.003980687255880282, "phrase": "available_change_impact_examples"}, {"score": 0.003898665270269876, "phrase": "hybrid_probabilistic_approach"}, {"score": 0.003852553673822629, "phrase": "change_impact"}, {"score": 0.003818326867123525, "phrase": "software_entity"}, {"score": 0.0037507793596022326, "phrase": "existing_version_histories"}, {"score": 0.00368442237104581, "phrase": "change-impact_predictors"}, {"score": 0.0034922880300145283, "phrase": "different_influencing_factors"}, {"score": 0.0034407121288076783, "phrase": "learning_examples"}, {"score": 0.0033597650090676032, "phrase": "software_entities"}, {"score": 0.003251552926963083, "phrase": "influencing_factors"}, {"score": 0.003232254571848865, "phrase": "structural_and_conceptual_dependencies"}, {"score": 0.002852356597632014, "phrase": "previous_versions"}, {"score": 0.002760441976808015, "phrase": "analyzed_system"}, {"score": 0.002524504774013978, "phrase": "large_variety"}, {"score": 0.00247978844626184, "phrase": "change_histories"}, {"score": 0.002465059277476973, "phrase": "different_projects"}, {"score": 0.0024431289979171505, "phrase": "recall_scores"}, {"score": 0.002428617044669043, "phrase": "predicted_impact_sets"}, {"score": 0.0023503248644593908, "phrase": "new_classes"}, {"score": 0.002336362867844443, "phrase": "recorded_change_histories"}, {"score": 0.0022949714134424272, "phrase": "old_classes"}, {"score": 0.002142970278347126, "phrase": "good_recall_scores"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Change impact analysis", " Impact set prediction", " Change history analysis", " Change impact graph", " Software maintenance"], "paper_abstract": "Context: Recent studies showed that combining present data, which are derived from the current software version, with past data, which are derived from previous software versions, can improve the accuracy of change impact predictions. However, for a specific program, existing combined techniques can rely only on version history of that program, if available, and the prediction results depend on the variety of available change impact examples. Objective: We propose a hybrid probabilistic approach that predicts the change impact for a software entity using, as training data, existing version histories of whatever software systems. Method: Change-impact predictors are learned from past change impact graphs (CIGs), extracted from the version history, along with their associations with different influencing factors of change propagation. The learning examples in CIGs are not specific to the software entities that are covered in those examples, and the change propagation influencing factors are structural and conceptual dependencies between software entities. Once our predictors are trained, they can predict change impacts regardless of the version history of the software under-analysis. We evaluate our approach using four systems in two scenarios. First, we use as training data the CIGs extracted from previous versions of the system under-analysis. Second, for each analyzed system, we use only the training data extracted from the other systems. Results: Our approach produces accurate predictions in terms of both precision and recall. Moreover, when training our classifiers with a large variety of CIGs extracted from the change histories of different projects, the recall scores of predicted impact sets were significantly improved. Conclusion: Our approach produces accurate predictions for new classes without recorded change histories, as well as for old classes. For the systems considered in our evaluation, once our approach is trained with a variety of CIGs it can predict change impacts with good recall scores. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Learning dependency-based change impact predictors using independent change histories", "paper_id": "WOS:000362604600013"}