{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "serial_inference_algorithms"}, {"score": 0.00471811808206897, "phrase": "complex_generalized_linear_model"}, {"score": 0.0045302298105691615, "phrase": "high-profile_drug_safety_disasters"}, {"score": 0.004120289747942224, "phrase": "licensed_medical_products"}, {"score": 0.0040648241451154525, "phrase": "large-scale_observational_databases"}, {"score": 0.0039028497942174777, "phrase": "electronic_health_record_systems"}, {"score": 0.0038242899532391914, "phrase": "particular_attention"}, {"score": 0.003362060602812933, "phrase": "high-performance_statistical_computation"}, {"score": 0.003294350220187021, "phrase": "graphics_processing_units"}, {"score": 0.003249966782844541, "phrase": "relatively_inexpensive_highly_parallel_computing_devices"}, {"score": 0.0030992666061123533, "phrase": "large_databases"}, {"score": 0.002955533639862811, "phrase": "massive_parallelization"}, {"score": 0.002915701586760994, "phrase": "cyclic_coordinate_descent"}, {"score": 0.0028184476518849015, "phrase": "conditioned_generalized_linear_model"}, {"score": 0.0026514708899935333, "phrase": "bayesian_context"}, {"score": 0.0024607296642187846, "phrase": "overall_run-time"}, {"score": 0.0024111277643627154, "phrase": "descent_approaches"}, {"score": 0.0023465400668244386, "phrase": "high-dimensional_statistics"}, {"score": 0.0022074592164608134, "phrase": "new_methodological_possibilities"}, {"score": 0.0021049977753042253, "phrase": "drug_safety"}], "paper_keywords": ["Optimization", " parallel processing", " big data"], "paper_abstract": "Following a series of high-profile drug safety disasters in recent years, many countries are redoubling their efforts to ensure the safety of licensed medical products. Large-scale observational databases such as claims databases or electronic health record systems are attracting particular attention in this regard, but present significant methodological and computational concerns. In this article we show how high-performance statistical computation, including graphics processing units, relatively inexpensive highly parallel computing devices, can enable complex methods in large databases. We focus on optimization and massive parallelization of cyclic coordinate descent approaches to fit a conditioned generalized linear model involving tens of millions of observations and thousands of predictors in a Bayesian context. We find orders-of-magnitude improvement in overall run-time. Coordinate descent approaches are ubiquitous in high-dimensional statistics and the algorithms we propose open up exciting new methodological possibilities with the potential to significantly improve drug safety.", "paper_title": "Massive Parallelization of Serial Inference Algorithms for a Complex Generalized Linear Model", "paper_id": "WOS:000314179000010"}