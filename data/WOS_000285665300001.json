{"auto_keywords": [{"score": 0.03304254866322829, "phrase": "audible_non-speech"}, {"score": 0.00481495049065317, "phrase": "heterogeneous_multimedia_content"}, {"score": 0.004544127927346964, "phrase": "high_quality_classification"}, {"score": 0.004311109608629196, "phrase": "audible_non-speech_events"}, {"score": 0.004199101289890982, "phrase": "audio_recording"}, {"score": 0.004047141845635495, "phrase": "single_parameter"}, {"score": 0.003941964605885606, "phrase": "in-domain_data"}, {"score": 0.00388016972840459, "phrase": "parameter_tuning"}, {"score": 0.0037793152987497286, "phrase": "training_data"}, {"score": 0.0036424917384748024, "phrase": "specific_sounds"}, {"score": 0.003492155652400838, "phrase": "wide_range"}, {"score": 0.0034555479218891638, "phrase": "audio_types"}, {"score": 0.0034193226278107346, "phrase": "varying_conditions"}, {"score": 0.0030772505522663612, "phrase": "single_run"}, {"score": 0.002711506442590442, "phrase": "target_audio"}, {"score": 0.0026689487424251907, "phrase": "bootstrap_classification"}, {"score": 0.0025452314655691165, "phrase": "proposed_system"}, {"score": 0.0022544399432457164, "phrase": "table-top_microphones"}, {"score": 0.0021957487795963666, "phrase": "dutch_television_broadcasts"}, {"score": 0.002105007807034302, "phrase": "elsevier"}], "paper_keywords": ["Speech/non speech classification", " Rich transcription", " SHoUT toolkit"], "paper_abstract": "In this paper we present a speech/non speech classification method that allows high quality classification without the need to know in advance what kinds of audible non-speech events are present in an audio recording and that does not require a single parameter to be tuned on in-domain data Because no parameter tuning is needed and no training data is required to train models for specific sounds the classifier is able to process a wide range of audio types with varying conditions and thereby contributes to the development of a more robust automatic speech recognition framework Our speech/non-speech classification system does not attempt to classify all audible non-speech in a single run Instead, first a bootstrap speech/silence classification is obtained using a standard speech/non-speech classifier Next, models for speech, silence and audible non-speech are trained on the target audio using the bootstrap classification The experiments show that the performance of the proposed system is 83% and 44% (relative) better than that of a common broadcast news speech/non-speech classifier when applied to a collection of meetings recorded with table-top microphones and a collection of Dutch television broadcasts used for TRECVID 2007 (C) 2010 Elsevier B V All rights reserved", "paper_title": "Robust speech/non-speech classification in heterogeneous multimedia content", "paper_id": "WOS:000285665300001"}