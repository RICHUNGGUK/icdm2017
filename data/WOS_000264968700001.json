{"auto_keywords": [{"score": 0.04963419481547922, "phrase": "coarse_grained_reconfigurable_arrays"}, {"score": 0.0326619465863625, "phrase": "new_priority_scheme"}, {"score": 0.030234594632746477, "phrase": "architecture's_resources"}, {"score": 0.00481495049065317, "phrase": "aware_mapping"}, {"score": 0.004725886853744007, "phrase": "coarse_grain_reconfigurable_array_architectures"}, {"score": 0.004205226397573506, "phrase": "huge_complexity"}, {"score": 0.0040890178236849825, "phrase": "new_mapping_methodology"}, {"score": 0.003741712498615481, "phrase": "allocation_phases"}, {"score": 0.0036553070575015344, "phrase": "first_time"}, {"score": 0.003504756881063581, "phrase": "single_step"}, {"score": 0.0034398445347109396, "phrase": "modulo_scheduling"}, {"score": 0.003407839062159497, "phrase": "backtracking_capability"}, {"score": 0.0032827577713351336, "phrase": "main_contribution"}, {"score": 0.0031919592786945126, "phrase": "novel_technique"}, {"score": 0.0031328221096543823, "phrase": "memory_bandwidth_bottleneck"}, {"score": 0.0030461580449080553, "phrase": "new_set"}, {"score": 0.0028133741785871867, "phrase": "overall_approach"}, {"score": 0.002722758109991685, "phrase": "parametric_architecture_template"}, {"score": 0.002684819249720834, "phrase": "large_number"}, {"score": 0.0026598200370569433, "phrase": "architecture_alternatives"}, {"score": 0.002562123444678208, "phrase": "prototype_tool"}, {"score": 0.0025264171945423254, "phrase": "experimental_exploration"}, {"score": 0.0024912073108138613, "phrase": "experimental_results"}, {"score": 0.002445021071485221, "phrase": "achieved_performance_figures"}, {"score": 0.002333258365963461, "phrase": "theoretical_study"}, {"score": 0.0022686625017583387, "phrase": "applications_requirements"}, {"score": 0.0021049977753042253, "phrase": "operation_parallelism"}], "paper_keywords": ["Coarse grained reconfigurable arrays", " Data reuse", " Mapping", " Data bandwidth bottleneck", " Reconfigurable computing"], "paper_abstract": "Coarse grain reconfigurable array architectures have become increasingly popular due to their flexibility, scalability and performance. However, the mapping of programs on these architectures is characterized by huge complexity. This work presents a new mapping methodology for effectively mapping applications on coarse grained reconfigurable arrays. The core of this methodology comprises of the scheduling and register allocation phases performed, for the first time in the case of CGRAs, in a single step. Additionally, modulo scheduling with backtracking capability is incorporated in this scheme. The main contribution of this work includes a novel technique for minimizing the memory bandwidth bottleneck, a new priority scheme and a new set of heuristics which target on the maximization of the Instruction Level Parallelism by efficiently managing the architecture's resources. The overall approach is retargetable with respect to a parametric architecture template modelling a large number of architecture alternatives and it has been automated with a prototype tool which permits experimental exploration. The experimental results showed that the achieved performance figures are very close to the most effective ones derived from the theoretical study on the architecture's resources and the applications requirements. Moreover, the application of the bandwidth optimization technique lead to a 20-130% increase on operation parallelism. Finally, the experiments quantified the benefit from applying the new priority scheme and heuristics. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Resource aware mapping on coarse grained reconfigurable arrays", "paper_id": "WOS:000264968700001"}