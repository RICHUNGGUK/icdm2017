{"auto_keywords": [{"score": 0.045934685709724435, "phrase": "reference_network"}, {"score": 0.01523588584295166, "phrase": "dual_critic_network_design"}, {"score": 0.012970108228860317, "phrase": "critic_network"}, {"score": 0.011805501548199716, "phrase": "reinforcement_signal"}, {"score": 0.00481495049065317, "phrase": "adaptive_learning"}, {"score": 0.00447937340641839, "phrase": "new_adaptive_dynamic_programming_approach"}, {"score": 0.004320421465896323, "phrase": "internal_goal_representation"}, {"score": 0.0038242899532391914, "phrase": "detailed_internal_goal_representation"}, {"score": 0.003738847528809348, "phrase": "value_function"}, {"score": 0.003688497722149817, "phrase": "internal_goal_signal"}, {"score": 0.0031917146566068245, "phrase": "alternative_choice"}, {"score": 0.0030783143919343972, "phrase": "prior_knowledge"}, {"score": 0.002955533639862811, "phrase": "online_action-dependent_heuristic_dynamic_programming"}, {"score": 0.0028505007899807446, "phrase": "detailed_design"}, {"score": 0.0028120802837806234, "phrase": "dual_critic_network_structure"}, {"score": 0.0027867539356701302, "phrase": "detailed_lyapunov_stability_analysis"}, {"score": 0.002687702958515561, "phrase": "proposed_structure"}, {"score": 0.0026514708899935333, "phrase": "theoretical_point"}, {"score": 0.0025341792091114184, "phrase": "virtual_reality_platform"}, {"score": 0.002488724764295623, "phrase": "real-time_simulation"}, {"score": 0.002433048706565187, "phrase": "different_disturbance_situations"}, {"score": 0.002400241288973103, "phrase": "overall_adaptive_learning_performance"}, {"score": 0.0023148964315569866, "phrase": "tracking_filter"}, {"score": 0.0022836785412390544, "phrase": "comparative_studies"}, {"score": 0.00222249726328354, "phrase": "tracking_performance"}, {"score": 0.0021925226977381244, "phrase": "typical_adhdp"}, {"score": 0.0021531831652035482, "phrase": "simulation_results"}, {"score": 0.0021241414408077895, "phrase": "improved_performance"}], "paper_keywords": ["Adaptive critic design (ACD)", " adaptive dynamic programming (ADP)", " internal goal", " lyapunov stability analysis", " online learning", " reinforcement learning", " tracking control", " virtual reality"], "paper_abstract": "In this paper, we present a new adaptive dynamic programming approach by integrating a reference network that provides an internal goal representation to help the systems learning and optimization. Specifically, we build the reference network on top of the critic network to form a dual critic network design that contains the detailed internal goal representation to help approximate the value function. This internal goal signal, working as the reinforcement signal for the critic network in our design, is adaptively generated by the reference network and can also be adjusted automatically. In this way, we provide an alternative choice rather than crafting the reinforcement signal manually from prior knowledge. In this paper, we adopt the online action-dependent heuristic dynamic programming (ADHDP) design and provide the detailed design of the dual critic network structure. Detailed Lyapunov stability analysis for our proposed approach is presented to support the proposed structure from a theoretical point of view. Furthermore, we also develop a virtual reality platform to demonstrate the real-time simulation of our approach under different disturbance situations. The overall adaptive learning performance has been tested on two tracking control benchmarks with a tracking filter. For comparative studies, we also present the tracking performance with the typical ADHDP, and the simulation results justify the improved performance with our approach.", "paper_title": "Adaptive Learning in Tracking Control Based on the Dual Critic Network Design", "paper_id": "WOS:000317786000006"}