{"auto_keywords": [{"score": 0.05007834503226343, "phrase": "numa-aware_cache"}, {"score": 0.0429935486588942, "phrase": "numa"}, {"score": 0.004773692073488661, "phrase": "iscsi_storage_servers"}, {"score": 0.004692227830462433, "phrase": "iscsi_based_storage_area_network"}, {"score": 0.004475266375001531, "phrase": "high_throughput"}, {"score": 0.0044369056710423065, "phrase": "low_latency"}, {"score": 0.004323776691055635, "phrase": "os_page_cache"}, {"score": 0.004268293864953256, "phrase": "data_sharing"}, {"score": 0.004141575435071002, "phrase": "non-uniform_memory_access"}, {"score": 0.0038492126993451337, "phrase": "multi-core_and_many-core_platforms"}, {"score": 0.0037188360359702182, "phrase": "iscsi_target"}, {"score": 0.0036553070575015344, "phrase": "access_request"}, {"score": 0.0035162927451540065, "phrase": "cached_data"}, {"score": 0.0033971539563683174, "phrase": "multi-core_systems"}, {"score": 0.0032538723984338615, "phrase": "ultra_high-speed_data_transfer"}, {"score": 0.0031166151196841308, "phrase": "numa_remote_memory_access"}, {"score": 0.00307657476125683, "phrase": "available_high_network_bandwidth"}, {"score": 0.00295950473406239, "phrase": "entire_end-to-end_data_transfer_path"}, {"score": 0.0028963961037320805, "phrase": "numa-aware_cache_mechanism"}, {"score": 0.002822434555587263, "phrase": "local_numa_nodes"}, {"score": 0.0025122373359090433, "phrase": "lower_access_latency"}, {"score": 0.0024906610581090223, "phrase": "higher_system_throughput"}, {"score": 0.002437525632451029, "phrase": "cache_system"}, {"score": 0.0024061887405214186, "phrase": "linux_scsi_target_framework"}, {"score": 0.0022168467146211077, "phrase": "iscsi"}, {"score": 0.0021232402128269906, "phrase": "intensive_applications"}, {"score": 0.0021049977753042253, "phrase": "real-life_workloads"}], "paper_keywords": ["Non-uniform memory access", " internet small computer system interface (iSCSI)", " storage area networks", " multi-core architecture", " remote direct memory access"], "paper_abstract": "In an iSCSI based storage area network, target hosts serve concurrent I/O requests from initiators to achieve both high throughput and low latency. Existing iSCSI leverages the OS page cache to ensure data sharing and reuse. However, the non-uniform memory access (NUMA) architecture introduces another dimension of complexity, i.e., asymmetric memory access in multi-core and many-core platforms. Within a NUMA platform, an iSCSI target often dispatches an access request with a cache hit to an I/O thread remote to cached data, and thus cannot fully utilize multi-core systems. We encounter this problem in the context of ultra high-speed data transfer between two iSCSI storage systems, during which inferior NUMA remote memory access lags behind available high network bandwidth, and thereby becomes a bottleneck of the entire end-to-end data transfer path. We design a NUMA-aware cache mechanism to align cache memory with local NUMA nodes and threads, and then schedule I/O requests to those threads that are local to the data being accessed. This NUMA-aware solution results in lower access latency and higher system throughput. We implement a cache system within the Linux SCSI target framework, and evaluated it on our NUMA-based iSCSI testbed. Experimental results show the NUMA-aware cache can significantly improve the performance of iSCSI as measured by several benchmark tools and confirm its viability in data intensive applications and real-life workloads.", "paper_title": "Design, Implementation, and Evaluation of a NUMA-Aware Cache for iSCSI Storage Servers", "paper_id": "WOS:000349769300009"}