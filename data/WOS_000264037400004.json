{"auto_keywords": [{"score": 0.049248469394552366, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "informative_vectors"}, {"score": 0.004698392162272106, "phrase": "multivariate_regression"}, {"score": 0.004649302313891199, "phrase": "new_procedure"}, {"score": 0.004616859702338596, "phrase": "high_ability"}, {"score": 0.004536735647938243, "phrase": "multivariate_calibration_models"}, {"score": 0.004489327204473076, "phrase": "small_number"}, {"score": 0.004457995891964028, "phrase": "interpretable_variables"}, {"score": 0.004215057618794356, "phrase": "informative_vector"}, {"score": 0.004141877689172017, "phrase": "systematic_investigation"}, {"score": 0.004112961231504503, "phrase": "pls_regression_models"}, {"score": 0.003929843413153981, "phrase": "cross-validation_parameters"}, {"score": 0.00379452936798156, "phrase": "seven_main_informative_vectors"}, {"score": 0.003162252895465901, "phrase": "main_purpose"}, {"score": 0.0031182092708983184, "phrase": "six_data_sets"}, {"score": 0.003096417317829492, "phrase": "different_sources"}, {"score": 0.0029281231068890197, "phrase": "raman"}, {"score": 0.0025801648787263662, "phrase": "prediction_capability"}, {"score": 0.0025352969524471496, "phrase": "full_data_sets"}, {"score": 0.0024999636244840647, "phrase": "regression_and_nas_informative_vectors"}, {"score": 0.002306123367679187, "phrase": "tested_data_sets"}, {"score": 0.0022739766507258105, "phrase": "best_informative_vectors"}, {"score": 0.0022580713471027996, "phrase": "variable_selection"}, {"score": 0.0022110183535859374, "phrase": "selected_variables"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["variable selection", " informative vectors", " OPS", " partial least squares", " chemometrics"], "paper_abstract": "A new procedure with high ability to enhance prediction of multivariate calibration models with a small number of interpretable variables is presented. The core of this methodology is to sort the variables from an informative vector, followed by a systematic investigation of PLS regression models with the aim of finding the most relevant set of variables by comparing the cross-validation parameters of the models obtained. In this work, seven main informative vectors i.e. regression vector, correlation vector, residual vector, variable influence on projection (VIP), net analyte signal (NAS), covariance procedures vector (CovProc), signal-to-noise ratios vector (StN) and their combinations were automated and tested with the main purpose of feature selection. Six data sets from different sources were employed to validate this methodology. They originated from: near-infrared (NIR) spectroscopy, Raman spectroscopy, gas chromatography (GC), fluorescence spectroscopy, quantitative structure-activity relationships (QSAR) and computer simulation. The results indicate that all vectors and their combinations were able to enhance prediction capability with respect to the full data sets. However, regression and NAS informative vectors from partial least squares (PLS) regression, both built using more latent variables than when building the model presented in most of tested data sets, were the best informative vectors for variable selection. In all the applications, the selected variables were quite effective and useful for interpretation. Copyright (C) 2008 John Wiley & Sons, Ltd.", "paper_title": "Sorting variables by using informative vectors as a strategy for feature selection in multivariate regression", "paper_id": "WOS:000264037400004"}