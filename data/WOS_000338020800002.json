{"auto_keywords": [{"score": 0.027442760024847877, "phrase": "ss"}, {"score": 0.004768378525561471, "phrase": "machine_learning_applications"}, {"score": 0.004676575291629554, "phrase": "important_task"}, {"score": 0.004520132822496416, "phrase": "original_data"}, {"score": 0.004305639197085793, "phrase": "feature_selection_methods"}, {"score": 0.004081385289516914, "phrase": "specific_objective_functions"}, {"score": 0.0038876302202924644, "phrase": "general_graph-preserving_feature_selection_framework"}, {"score": 0.0037392451233558234, "phrase": "specific_definitions"}, {"score": 0.0035965032173588753, "phrase": "existing_filter-type_feature_selection_algorithms"}, {"score": 0.003376037544631762, "phrase": "proposed_framework"}, {"score": 0.0033271045779740683, "phrase": "new_filter-type_feature_selection_method"}, {"score": 0.002917331114260319, "phrase": "data_noise"}, {"score": 0.0028471655497661528, "phrase": "modified_sparse_representation"}, {"score": 0.002711842889248926, "phrase": "graph_adjacency_structure"}, {"score": 0.002685558057339722, "phrase": "corresponding_affinity_weight_matrix"}, {"score": 0.002297949552105756, "phrase": "experimental_results"}, {"score": 0.0022536005664642294, "phrase": "classification_tasks"}, {"score": 0.002199363362666037, "phrase": "benchmark_data_sets"}, {"score": 0.0021569129153653777, "phrase": "proposed_methods"}, {"score": 0.002125612498781805, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "conventional_filter-type_feature_selection_methods"}], "paper_keywords": ["Feature selection", " sparse representation", " l(1) graph", " clustering", " classification"], "paper_abstract": "As thousands of features are available in many pattern recognition and machine learning applications, feature selection remains an important task to find the most compact representation of the original data. In the literature, although a number of feature selection methods have been developed, most of them focus on optimizing specific objective functions. In this paper, we first propose a general graph-preserving feature selection framework where graphs to be preserved vary in specific definitions, and show that a number of existing filter-type feature selection algorithms can be unified within this framework. Then, based on the proposed framework, a new filter-type feature selection method called sparsity score (SS) is proposed. This method aims to preserve the structure of a pre-defined l(1) graph that is proven robust to data noise. Here, the modified sparse representation based on an l(1)-norm minimization problem is used to determine the graph adjacency structure and corresponding affinity weight matrix simultaneously. Furthermore, a variant of SS called supervised SS (SuSS) is also proposed, where the l(1) graph to be preserved is constructed by using only data points from the same class. Experimental results of clustering and classification tasks on a series of benchmark data sets show that the proposed methods can achieve better performance than conventional filter-type feature selection methods.", "paper_title": "SPARSITY SCORE: A NOVEL GRAPH-PRESERVING FEATURE SELECTION METHOD", "paper_id": "WOS:000338020800002"}