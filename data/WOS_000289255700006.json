{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "statistical_abduction"}, {"score": 0.004586531354697466, "phrase": "new_framework"}, {"score": 0.004498213310668266, "phrase": "logic-based_probabilistic_modeling"}, {"score": 0.0031383410838018953, "phrase": "generative_models"}, {"score": 0.002989220655735981, "phrase": "discriminative_models"}, {"score": 0.0028471655497661528, "phrase": "equivalent_cbpms"}, {"score": 0.0024842242921857705, "phrase": "infinite_domains"}, {"score": 0.002389276641014013, "phrase": "existentially_closed_logical_consequences"}, {"score": 0.0021674482571326283, "phrase": "em_algorithm"}, {"score": 0.0021049977753042253, "phrase": "parameter_learning"}], "paper_keywords": ["Probabilistic model", " Constraint", " Abduction"], "paper_abstract": "We introduce a new framework for logic-based probabilistic modeling called constraint-based probabilistic modeling which defines CBPMs (constraint-based probabilistic models) , i.e. conditional joint distributions P(a <...a KB) pound over independent propositional variables constrained by a knowledge base KB consisting of clauses. We first prove that generative models such as PCFGs and discriminative models such as CRFs have equivalent CBPMs as long as they are discrete. We then prove that CBPMs in infinite domains exist which give existentially closed logical consequences of KB probability one. Finally we derive an EM algorithm for the parameter learning of CBPMs and apply it to statistical abduction.", "paper_title": "Constraint-based probabilistic modeling for statistical abduction", "paper_id": "WOS:000289255700006"}