{"auto_keywords": [{"score": 0.04743405832670911, "phrase": "input_variable_selection"}, {"score": 0.04438199165379649, "phrase": "joint_mutual_information"}, {"score": 0.04126630752096143, "phrase": "variable_selection"}, {"score": 0.00481495049065317, "phrase": "multivariate_time"}, {"score": 0.0046069985410261746, "phrase": "multivariate_time_series"}, {"score": 0.004463958296056236, "phrase": "key_problem"}, {"score": 0.0041384457437123635, "phrase": "input_variable_selection_problems"}, {"score": 0.003984665807155269, "phrase": "commonly_used_measure"}, {"score": 0.0036476222647061243, "phrase": "novel_high-dimensional_mutual_information_estimator"}, {"score": 0.0034028574973016933, "phrase": "truncated_k-nearest_neighbor_method"}, {"score": 0.003317970131738248, "phrase": "high_dimensional_gaussian_distributions"}, {"score": 0.003194580334752371, "phrase": "proposed_mutual_information_estimator"}, {"score": 0.00301801991152303, "phrase": "copula_entropy"}, {"score": 0.0028692628457408025, "phrase": "joint_mutual_information_estimation"}, {"score": 0.0027976491158911514, "phrase": "proposed_estimator"}, {"score": 0.0025285834281312705, "phrase": "max_dependency"}, {"score": 0.0024968185204913935, "phrase": "max-min_dependency"}, {"score": 0.002449915958738505, "phrase": "stop_criterion"}, {"score": 0.0023587312574818208, "phrase": "selection_process"}, {"score": 0.0023144166368024603, "phrase": "simulation_results"}, {"score": 0.002256619934086924, "phrase": "input_variable_selection_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Joint mutual information", " Copula entropy", " Input variable selection", " Time series"], "paper_abstract": "For modeling of multivariate time series, input variable selection is a key problem. This paper presents the estimation of joint mutual information and its application in input variable selection problems. Mutual information is a commonly used measure for variable selection. To improve the performance of input variable selection, we propose a novel high-dimensional mutual information estimator based on copula entropy, which is estimated by the truncated k-nearest neighbor method. Simulations on high dimensional Gaussian distributions substantiate the effectiveness of the proposed mutual information estimator. A relationship between the joint mutual information and the copula entropy is derived, which is used for joint mutual information estimation. Then the proposed estimator is applied to input variable selection for multivariate time series modeling based on the criterion of max dependency and max-min dependency. A stop criterion is proposed to terminate the selection process automatically. Simulation results show that the input variable selection method works well on both synthetic and real life dataset. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Joint mutual information-based input variable selection for multivariate time series modeling", "paper_id": "WOS:000346453800021"}