{"auto_keywords": [{"score": 0.0451349936761357, "phrase": "random_space"}, {"score": 0.00481495049065317, "phrase": "model_reduction"}, {"score": 0.0047224703862074665, "phrase": "novel_way"}, {"score": 0.004525190364108967, "phrase": "probability_space"}, {"score": 0.004438250823243621, "phrase": "uncertainty_quantification"}, {"score": 0.004154908228936342, "phrase": "generalized_polynomial_chaos_expansion_techniques"}, {"score": 0.004012271808564447, "phrase": "discontinuous_problems"}, {"score": 0.0038296485293910026, "phrase": "higher_terms"}, {"score": 0.0036838048761094933, "phrase": "smaller_elements"}, {"score": 0.0036411406244705557, "phrase": "lower_degree_polynomial"}, {"score": 0.0033952989364738353, "phrase": "dynamic_process"}, {"score": 0.0031050953733360825, "phrase": "current_work"}, {"score": 0.002952146666681891, "phrase": "random_space_mesh"}, {"score": 0.0028729252198422825, "phrase": "reduced_model"}, {"score": 0.0027958237350835607, "phrase": "good_reduced_model"}, {"score": 0.002720785798036066, "phrase": "random_space_element"}, {"score": 0.0026477564788515984, "phrase": "higher_degree_terms"}, {"score": 0.002617059777997427, "phrase": "chaos_expansion"}, {"score": 0.002536926192232391, "phrase": "efficient_allocation"}, {"score": 0.0025172781808293827, "phrase": "computational_sources"}, {"score": 0.002356282242320051, "phrase": "prototypical_system"}, {"score": 0.00227525089435209, "phrase": "theoretical_results"}, {"score": 0.002231441081806766, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Adaptive mesh refinement", " Multi-element", " gPC", " Model reduction"], "paper_abstract": "We present a novel way of deciding when and where to refine a mesh in probability space in order to facilitate uncertainty quantification in the presence of discontinuities in random space. A discontinuity in random space makes the application of generalized polynomial chaos expansion techniques prohibitively expensive. The reason is that for discontinuous problems, the expansion converges very slowly. An alternative to using higher terms in the expansion is to divide the random space in smaller elements where a lower degree polynomial is adequate to describe the randomness. In general, the partition of the random space is a dynamic process since some areas of the random space, particularly around the discontinuity, need more refinement than others as time evolves. In the current work we propose a way to decide when and where to refine the random space mesh based on the use of a reduced model. The idea is that a good reduced model can monitor accurately, within a random space element, the cascade of activity to higher degree terms in the chaos expansion. In turn, this facilitates the efficient allocation of computational sources to the areas of random space where they are more needed. For the Kraichnan Orszag system, the prototypical system to study discontinuities in random space, we present theoretical results which show why the proposed method is sound and numerical results which corroborate the theory. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Mesh refinement for uncertainty quantification through model reduction", "paper_id": "WOS:000345490200008"}