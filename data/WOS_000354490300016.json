{"auto_keywords": [{"score": 0.042291837632617076, "phrase": "monocular_camera"}, {"score": 0.03672998173300791, "phrase": "joint_localization"}, {"score": 0.00481495049065317, "phrase": "pursuit_quadcopters"}, {"score": 0.004718897469501381, "phrase": "monocular_cues"}, {"score": 0.004671588539217021, "phrase": "pursuit_robots"}, {"score": 0.004442032546224076, "phrase": "moving_target"}, {"score": 0.0043753813457279404, "phrase": "accurate_tracking"}, {"score": 0.004309725894724034, "phrase": "target's_position"}, {"score": 0.0040978781692373005, "phrase": "basic_sensors"}, {"score": 0.003935892934907777, "phrase": "combined_noise"}, {"score": 0.003876806615011266, "phrase": "quadcopter's_sensors"}, {"score": 0.0038379074449947067, "phrase": "large_disturbances"}, {"score": 0.003522579870903474, "phrase": "novel_method"}, {"score": 0.0034348484776384643, "phrase": "quadcopter_pursuer"}, {"score": 0.003332440548684892, "phrase": "arbitrary_target"}, {"score": 0.003152531962718477, "phrase": "common_reference_frame"}, {"score": 0.003105168935158648, "phrase": "joint_localization_method"}, {"score": 0.003058515297281172, "phrase": "quadcopter's_kinematics"}, {"score": 0.003012560489169148, "phrase": "target's_dynamics"}, {"score": 0.0029672941061574375, "phrase": "joint_state_space_model"}, {"score": 0.002821247621250663, "phrase": "target_trajectories"}, {"score": 0.0027788478707700274, "phrase": "better_results"}, {"score": 0.002750934994181092, "phrase": "standard_approaches"}, {"score": 0.002709589081384597, "phrase": "relative_target_trajectories"}, {"score": 0.0025892330566358503, "phrase": "computationally_efficient_visual_tracking_method"}, {"score": 0.002524688179363081, "phrase": "temporarily_lost_target"}, {"score": 0.0024493494346360415, "phrase": "proposed_method"}, {"score": 0.0023287359930308864, "phrase": "real_quadcopter"}, {"score": 0.002214048743052355, "phrase": "visual_tracker"}, {"score": 0.002158836285985314, "phrase": "target_occlusions"}, {"score": 0.0021049977753042253, "phrase": "standard_localization_methods"}], "paper_keywords": ["Quadcopters", " Joint localization", " Monocular cues", " State estimation filters", " Visual tracking", " Redetection", " Backprojection", " Pursuit robot", " AR.Drone"], "paper_abstract": "Pursuit robots (autonomous robots tasked with tracking and pursuing a moving target) require accurate tracking of the target's position over time. One possibly effective pursuit platform is a quadcopter equipped with basic sensors and a monocular camera. However, the combined noise in the quadcopter's sensors causes large disturbances in the target's 3D position estimate. To solve this problem, in this paper, we propose a novel method for joint localization of a quadcopter pursuer with a monocular camera and an arbitrary target. Our method localizes both the pursuer and target with respect to a common reference frame. The joint localization method fuses the quadcopter's kinematics and the target's dynamics in a joint state space model. We show that predicting and correcting pursuer and target trajectories simultaneously produces better results than standard approaches to estimating relative target trajectories in a 3D coordinate system. Our method also comprises a computationally efficient visual tracking method capable of redetecting a temporarily lost target. The efficiency of the proposed method is demonstrated by a series of experiments with a real quadcopter pursuing a human. The results show that the visual tracker can deal effectively with target occlusions and that joint localization outperforms standard localization methods.", "paper_title": "Joint Localization of Pursuit Quadcopters and Target Using Monocular Cues", "paper_id": "WOS:000354490300016"}