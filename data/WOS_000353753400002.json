{"auto_keywords": [{"score": 0.0422978679900886, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "continuous_and_discrete_optimization"}, {"score": 0.004756805752518494, "phrase": "sparse_feature_selection"}, {"score": 0.00453113241842654, "phrase": "high-dimensional_data"}, {"score": 0.004342430078306461, "phrase": "convex_methods"}, {"score": 0.003988180913997414, "phrase": "parameter_estimation"}, {"score": 0.003775803846431323, "phrase": "continuous_and_discrete_nonconvex_paradigms"}, {"score": 0.0037301606780397456, "phrase": "sparse_group_feature_selection"}, {"score": 0.0034887749053459584, "phrase": "underlying_group_structure"}, {"score": 0.0033433365160336842, "phrase": "main_contribution"}, {"score": 0.003070340620983981, "phrase": "efficient_optimization_algorithms"}, {"score": 0.0030147970456037274, "phrase": "continuous_and_discrete_formulations"}, {"score": 0.0029244418026475832, "phrase": "key_step"}, {"score": 0.0026530590435527527, "phrase": "proposed_continuous_model"}, {"score": 0.0026050445177883005, "phrase": "oracle_estimator"}, {"score": 0.0025423706961391034, "phrase": "consistent_feature_selection"}, {"score": 0.002421499421848063, "phrase": "numerical_results"}, {"score": 0.002392188222609101, "phrase": "synthetic_and_real-world_data"}, {"score": 0.0023346234464901978, "phrase": "proposed_nonconvex_methods"}, {"score": 0.0022236070278432575, "phrase": "desired_goal"}, {"score": 0.00218334762335187, "phrase": "high_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Nonconvex optimization", " Error bound", " Discrete optimization", " Application", " EEC data analysis"], "paper_abstract": "Sparse feature selection has proven to be effective in analyzing high-dimensional data. While promising, most existing works apply convex methods, which may be suboptimal in terms of the accuracy of feature selection and parameter estimation. In this paper, we consider both continuous and discrete nonconvex paradigms to sparse group feature selection, which are motivated by applications that require identifying the underlying group structure and performing feature selection simultaneously. The main contribution of this article is twofold: (1) computationally, we develop efficient optimization algorithms for both continuous and discrete formulations, of which the key step is a projection with two coupled constraints; (2) statistically, we show that the proposed continuous model reconstructs the oracle estimator. Therefore, consistent feature selection and parameter estimation are achieved simultaneously. Numerical results on synthetic and real-world data suggest that the proposed nonconvex methods compare favorably against their competitors, thus achieving desired goal of delivering high performance. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Efficient nonconvex sparse group feature selection via continuous and discrete optimization", "paper_id": "WOS:000353753400002"}