{"auto_keywords": [{"score": 0.0497090303722539, "phrase": "spoken_document_retrieval"}, {"score": 0.04789998570434711, "phrase": "spoken_documents"}, {"score": 0.03843856552198325, "phrase": "top-ranked_feedback_documents"}, {"score": 0.032949086420073735, "phrase": "top-ranked_documents"}, {"score": 0.00481495049065317, "phrase": "query_formulation"}, {"score": 0.004490212943845175, "phrase": "research_interest"}, {"score": 0.004421115387064563, "phrase": "sdr"}, {"score": 0.004352974291381376, "phrase": "recent_past"}, {"score": 0.004236321075918639, "phrase": "robust_indexing"}, {"score": 0.0042035670399069485, "phrase": "modeling_techniques"}, {"score": 0.004106810349956121, "phrase": "recent_line"}, {"score": 0.004075053556360943, "phrase": "thought_targets"}, {"score": 0.003996727479807572, "phrase": "query_modeling"}, {"score": 0.003919900973086169, "phrase": "user's_information_need"}, {"score": 0.003889583851551197, "phrase": "pseudo-relevance_feedback"}, {"score": 0.0036838048761094933, "phrase": "small_amount"}, {"score": 0.0035989687070420977, "phrase": "initial_round"}, {"score": 0.0032786537599187125, "phrase": "initial_retrieval"}, {"score": 0.0029292922955739963, "phrase": "interesting_problem"}, {"score": 0.002861782260525497, "phrase": "useful_cues"}, {"score": 0.0026892447164623247, "phrase": "information_cues"}, {"score": 0.0025967927629150715, "phrase": "feedback_document_selection"}, {"score": 0.0025468074858862964, "phrase": "better_retrieval_effectiveness"}, {"score": 0.002421291757425244, "phrase": "different_granularities"}, {"score": 0.0024025371556472557, "phrase": "index_features"}, {"score": 0.002319918823705175, "phrase": "document_models"}, {"score": 0.0021049993427773544, "phrase": "sdr."}], "paper_keywords": ["spoken document retrieval", " language modeling", " query modeling", " pseudo-relevance feedback", " speech recognition"], "paper_abstract": "The popularity and ubiquity of multimedia associated with spoken documents has spurred a lot of research interest in spoken document retrieval (SDR) in the recent past. Beyond much effort devoted to developing robust indexing and modeling techniques for representing spoken documents, a recent line of thought targets at the improvement of query modeling for better reflecting the user's information need. Pseudo-relevance feedback is by far the most commonly-used paradigm for query reformulation, which assumes that a small amount of top-ranked feedback documents obtained from the initial round of retrieval are relevant and can be utilized for this purpose. Nevertheless, simply taking all of the top-ranked feedback documents obtained from the initial retrieval for query modeling does not always perform well, especially when the top-ranked documents contain much redundant or non-relevant information. In the view of this, we explore in this paper an interesting problem of how to effectively glean useful cues from the top-ranked documents so as to achieve more accurate query modeling. Towards this end, various sources of information cues are considered and integrated into the process of feedback document selection so as to achieve better retrieval effectiveness. Furthermore, we also investigate representing the query and documents with different granularities of index features to work in conjunction with the query and document models. A series of experiments conducted on the TDT (Topic Detection and Tracking) task seem to demonstrate the effectiveness of our query modeling framework for SDR.", "paper_title": "Enhancing Query Formulation for Spoken Document Retrieval", "paper_id": "WOS:000340075300002"}