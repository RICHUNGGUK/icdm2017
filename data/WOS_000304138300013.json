{"auto_keywords": [{"score": 0.05007659871240365, "phrase": "trainable_convolution_filters"}, {"score": 0.04566975605248225, "phrase": "volterra"}, {"score": 0.004571559854487074, "phrase": "novel_image_classification_system"}, {"score": 0.004438019162720755, "phrase": "trainable_filter_ensembles"}, {"score": 0.004198010835867604, "phrase": "possibly_overlapping_patches"}, {"score": 0.004000486064911652, "phrase": "single_patch_classification"}, {"score": 0.0038548668648948044, "phrase": "range_space"}, {"score": 0.0036327808996444904, "phrase": "different_classes"}, {"score": 0.003410768840300913, "phrase": "volterra_kernels"}, {"score": 0.003360527337581911, "phrase": "convolution_kernel"}, {"score": 0.0031786037839399055, "phrase": "volterra_classifiers"}, {"score": 0.002995361424576051, "phrase": "best_weighted_combination"}, {"score": 0.002929394386754424, "phrase": "higher_per-patch_classification_rate"}, {"score": 0.0028331500847209984, "phrase": "classification_information"}, {"score": 0.002740059168271987, "phrase": "parent_image_classification"}, {"score": 0.00265987582861194, "phrase": "proposed_technique"}, {"score": 0.0026401983633087267, "phrase": "face_recognition"}, {"score": 0.0026109540617641593, "phrase": "application_area"}, {"score": 0.002582032847722892, "phrase": "extensive_experiments"}, {"score": 0.0025534425731829078, "phrase": "yale"}, {"score": 0.002497172413754263, "phrase": "yale_b"}, {"score": 0.00247869598774022, "phrase": "multi-pie"}, {"score": 0.0024512358145634336, "phrase": "merl_dome_benchmark_face_data_sets"}, {"score": 0.002353120949568249, "phrase": "recognition_volterrafaces"}, {"score": 0.002258924405138231, "phrase": "broad_class"}, {"score": 0.002242206465278159, "phrase": "embedding-based_face"}], "paper_keywords": ["Face recognition", " convolution", " filtering classifier", " Volterra kernels", " Fisher's linear discriminant", " boosting"], "paper_abstract": "In this paper, we present a novel image classification system that is built around a core of trainable filter ensembles that we call Volterra kernel classifiers. Our system treats images as a collection of possibly overlapping patches and is composed of three components: 1) A scheme for a single patch classification that seeks a smooth, possibly nonlinear, functional mapping of the patches into a range space, where patches of the same class are close to one another, while patches from different classes are far apart-in the L-2 sense. This mapping is accomplished using trainable convolution filters (or Volterra kernels) where the convolution kernel can be of any shape or order. 2) Given a corpus of Volterra classifiers with various kernel orders and shapes for each patch, a boosting scheme for automatically selecting the best weighted combination of the classifiers to achieve higher per-patch classification rate. 3) A scheme for aggregating the classification information obtained for each patch via voting for the parent image classification. We demonstrate the effectiveness of the proposed technique using face recognition as an application area and provide extensive experiments on the Yale, CMU PIE, Extended Yale B, Multi-PIE, and MERL Dome benchmark face data sets. We call the Volterra kernel classifiers applied to face recognition Volterrafaces. We show that our technique, which falls into the broad class of embedding-based face image discrimination methods, consistently outperforms various state-of-the-art methods in the same category.", "paper_title": "Trainable Convolution Filters and Their Application to Face Recognition", "paper_id": "WOS:000304138300013"}