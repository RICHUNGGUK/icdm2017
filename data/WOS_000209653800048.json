{"auto_keywords": [{"score": 0.04897263249241297, "phrase": "cognitive_control"}, {"score": 0.014219724595579533, "phrase": "cognitive_dynamic_system"}, {"score": 0.010598398016088507, "phrase": "new_algorithm"}, {"score": 0.00481495049065317, "phrase": "engineering_point"}, {"score": 0.004612896435506914, "phrase": "prefrontal_cortex"}, {"score": 0.004559270778306828, "phrase": "human_brain"}, {"score": 0.004402088928254543, "phrase": "overarching_function"}, {"score": 0.004200874581076468, "phrase": "new_way"}, {"score": 0.0035383712891119937, "phrase": "distinctive_characteristic"}, {"score": 0.0033633514001658086, "phrase": "cognitive_control_learning_algorithm"}, {"score": 0.003324203391715804, "phrase": "special_form"}, {"score": 0.003298357357267836, "phrase": "bellman's_dynamic_programming"}, {"score": 0.0030387767523076528, "phrase": "optimal_policy"}, {"score": 0.002810520668490478, "phrase": "cognitive_controller"}, {"score": 0.0027240799841720957, "phrase": "intrinsic_properties"}, {"score": 0.0026609940110902666, "phrase": "computational_experiment"}, {"score": 0.0025892330566358503, "phrase": "cognitive_tracking_radar"}, {"score": 0.0025095811903520274, "phrase": "visual_brain"}, {"score": 0.0023391880766516285, "phrase": "new_cognitive_controller"}, {"score": 0.0022760856906838814, "phrase": "learning_curves"}, {"score": 0.002223351523626989, "phrase": "dynamic_optimization"}, {"score": 0.002206045784326466, "phrase": "traditional_q-learning"}, {"score": 0.002146527342660575, "phrase": "latter_two_algorithms"}, {"score": 0.0021049977753042253, "phrase": "two-state_model"}], "paper_keywords": ["Cognitive dyanamic systems", " cognitive control", " dynamic programming", " two-state model", " entropic state", " Shannon's entropy", " explore/exploit tradeoff", " learning", " planning", " Bayesian filtering"], "paper_abstract": "From an engineering point-of-view, cognitive control is inspired by the prefrontal cortex of the human brain; cognitive control may therefore be viewed as the overarching function of a cognitive dynamic system. In this paper, we describe a new way of thinking about cognitive control that embodies two basic components: learning and planning, both of which are based on two notions: 1) two-state model of the environment and the perceptor and 2) perception-action cycle, which is a distinctive characteristic of the cognitive dynamic system. Most importantly, it is shown that the cognitive control learning algorithm is a special form of Bellman's dynamic programming Distinctive properties of the new algorithm include the following: 1) optimality of performance; 2) algorithmic convergence to optimal policy; and 3) linear law of complexity measured in terms of the number of actions taken by the cognitive controller on the environment. To validate these intrinsic properties of the algorithm, a computational experiment is presented, which involves a cognitive tracking radar that is known to closely mimic the visual brain. The experiment illustrates two different scenarios: 1) the impact of planning on learning curves of the new cognitive controller and 2) comparison of the learning curves of three different controllers, based on dynamic optimization, traditional Q-learning, and the new algorithm. The latter two algorithms are based on the two-state model, and they both involve the use of planning.", "paper_title": "Cognitive Control: Theory and Application", "paper_id": "WOS:000209653800048"}