{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "speaker_group-dependent_modelling"}, {"score": 0.04922237591220716, "phrase": "affective_states"}, {"score": 0.03760896637952158, "phrase": "affective_state"}, {"score": 0.004623224002010226, "phrase": "successful_human-machine-interaction"}, {"score": 0.0045200127552893704, "phrase": "pure_textual_information"}, {"score": 0.004459190343665408, "phrase": "individual_skills"}, {"score": 0.004129607015893271, "phrase": "starting_point"}, {"score": 0.004074016501033133, "phrase": "user's_actual_affective_state"}, {"score": 0.0035095935622207956, "phrase": "automatic_speech_recognition"}, {"score": 0.0034311578789991363, "phrase": "age_and_gender_differences"}, {"score": 0.0029959082125682918, "phrase": "acted_and_natural_affected_speech"}, {"score": 0.0025804616931593897, "phrase": "channel_compensation"}, {"score": 0.0025572160146590623, "phrase": "contextual_characteristics"}, {"score": 0.0022733662000757318, "phrase": "age_information"}, {"score": 0.002202469129781332, "phrase": "acoustic_normalization"}, {"score": 0.0021049977753042253, "phrase": "group-dependent_modelling"}], "paper_keywords": ["Affect recognition", " Companion systems", " Vocal tract length normalization", " Speaker group-dependent classifiers"], "paper_abstract": "For successful human-machine-interaction (HCI) the pure textual information and the individual skills, preferences, and affective states of the user must be known. Therefore, as a starting point, the user's actual affective state has to be recognized. In this work we investigated how additional knowledge, for example age and gender of the user, can be used to improve recognition of affective state. Two methods from automatic speech recognition are used to incorporate age and gender differences in recognition of affective state: speaker group-dependent (SGD) modelling and vocal tract length normalisation (VTLN). The investigations were performed on four corpora with acted and natural affected speech. Different features and two methods of classification (Gaussian mixture models (GMMs) and multi-layer perceptrons (MLPs)) were used. In addition, the effects of channel compensation and contextual characteristics were analysed. The results are compared with our own baseline results and with results reported in the literature. Two hypotheses were tested. First, incorporation of age information further improves speaker group-dependent modelling. Second, acoustic normalization does not achieve the same improvement as achieved by speaker group-dependent modelling, because the age and gender of a speaker affects the way emotions are expressed.", "paper_title": "Investigation of Speaker Group-Dependent Modelling for Recognition of Affective States from Speech", "paper_id": "WOS:000345994900021"}