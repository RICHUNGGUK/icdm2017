{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "soccer_event_detection"}, {"score": 0.0399982426143156, "phrase": "simple_features"}, {"score": 0.0047527118741586055, "phrase": "collaborative_multimodal_feature_analysis"}, {"score": 0.004691273968935458, "phrase": "candidate_ranking"}, {"score": 0.004395742407834023, "phrase": "collaborative_analysis"}, {"score": 0.004065474891313382, "phrase": "match_video"}, {"score": 0.004012885020428863, "phrase": "smaller_segments"}, {"score": 0.0039097293657870584, "phrase": "desired_eventful_segment"}, {"score": 0.0035228596881051763, "phrase": "sports_websites"}, {"score": 0.0024939618994290016, "phrase": "labeled_training_examples"}, {"score": 0.0024616504443079512, "phrase": "event_detection"}, {"score": 0.0022763657774198184, "phrase": "soccer_video_show"}, {"score": 0.002132637840285576, "phrase": "yellow_cards"}, {"score": 0.0021049977753042253, "phrase": "red_cards"}], "paper_keywords": ["Soccer event detection", " sports video analysis", " semantic gap", " webcasting text"], "paper_abstract": "This paper presents a framework for soccer event detection through collaborative analysis of the textual, visual and aural modalities. The basic notion is to decompose a match video into smaller segments until ultimately the desired eventful segment is identified. Simple features are considered namely the minute-by-minute reports from sports websites (i.e., text), the semantic shot classes of far and closeup-views (i.e., visual), and the low-level features of pitch and log-energy (i.e., audio). The framework demonstrates that despite considering simple features, and by averting the use of labeled training examples, event detection can be achieved at very high accuracy. Experiments conducted on 30-hours of soccer video show very promising results for the detection of goals, penalties, yellow cards and red cards.", "paper_title": "Soccer Event Detection via Collaborative Multimodal Feature Analysis and Candidate Ranking", "paper_id": "WOS:000325785200010"}