{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "purely_functional_gpu_programs"}, {"score": 0.004515655183335171, "phrase": "simd_hardware"}, {"score": 0.004201033616196156, "phrase": "naive_compilation"}, {"score": 0.003971502222405927, "phrase": "code_explosion"}, {"score": 0.003876996400581697, "phrase": "excessive_use"}, {"score": 0.0038152404172111815, "phrase": "intermediate_data_structures"}, {"score": 0.003549245218355768, "phrase": "target_hardware"}, {"score": 0.0033552055241931346, "phrase": "high_performance"}, {"score": 0.0028115863316685937, "phrase": "superfluous_intermediate_structures"}, {"score": 0.0025326211341475903, "phrase": "unique_challenges"}, {"score": 0.002472269923319476, "phrase": "embedded_language"}, {"score": 0.002299689297293321, "phrase": "novel_methods"}], "paper_keywords": ["Arrays", " Data parallelism", " Embedded language", " Dynamic compilation", " GPGPU", " Haskell", " Sharing recovery", " Array fusion"], "paper_abstract": "Purely functional, embedded array programs are a good match for SIMD hardware, such as GPUs. However, the naive compilation of such programs quickly leads to both code explosion and an excessive use of intermediate data structures. The resulting slow-down is not acceptable on target hardware that is usually chosen to achieve high performance. In this paper, we discuss two optimisation techniques, sharing recovery and array fusion, that tackle code explosion and eliminate superfluous intermediate structures. Both techniques are well known from other contexts, but they present unique challenges for an embedded language compiled for execution on a GPU. We present novel methods for implementing sharing recovery and array fusion, and demonstrate their effectiveness on a set of benchmarks.", "paper_title": "Optimising Purely Functional GPU Programs", "paper_id": "WOS:000327696700006"}