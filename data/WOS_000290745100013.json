{"auto_keywords": [{"score": 0.04436828137594863, "phrase": "original_functions"}, {"score": 0.030612215044605498, "phrase": "information_loss"}, {"score": 0.00481495049065317, "phrase": "functional_learning_methods"}, {"score": 0.004674952036988355, "phrase": "real_world_applications"}, {"score": 0.0045581828632009795, "phrase": "functional_models"}, {"score": 0.004519908617935935, "phrase": "better_predictive_performances"}, {"score": 0.0043699845927285905, "phrase": "order_m"}, {"score": 0.004033464035028803, "phrase": "common_practice"}, {"score": 0.003999578057088828, "phrase": "functional_data_analysis"}, {"score": 0.0038996120252338556, "phrase": "theoretical_guarantees"}, {"score": 0.003850566273995209, "phrase": "asymptotically_achievable_performances"}, {"score": 0.003802135020791801, "phrase": "derivative_based_model"}, {"score": 0.0036450381529042103, "phrase": "smoothing_spline_approach"}, {"score": 0.0035539019235553897, "phrase": "multivariate_observations"}, {"score": 0.0034504423179340738, "phrase": "discrete_and_finite_sampling_grid"}, {"score": 0.003335873298309004, "phrase": "consistent_scheme"}, {"score": 0.0032938942910948096, "phrase": "original_infinite_dimensional_functional_problem"}, {"score": 0.003211746751603612, "phrase": "mas"}, {"score": 0.003117986133774198, "phrase": "nonparametric_approaches"}, {"score": 0.003091767402370757, "phrase": "incomplete_knowledge"}, {"score": 0.0029266219967426224, "phrase": "nonparametric_framework"}, {"score": 0.0025892330566358503, "phrase": "discrete_sampling"}, {"score": 0.002461241017147324, "phrase": "smoothing_spline"}, {"score": 0.002450864311898833, "phrase": "based_approach"}, {"score": 0.0023694065215394593, "phrase": "proposed_approach"}, {"score": 0.0022051664509486206, "phrase": "good_solution"}, {"score": 0.0021590588269751816, "phrase": "noisy_functional_predictors"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Functional Data Analysis", " Consistency", " Statistical learning", " Derivatives", " SVM", " Smoothing splines", " RKHS"], "paper_abstract": "In some real world applications, such as spectrometry, functional models achieve better predictive performances if they work on the derivatives of order m of their inputs rather than on the original functions. As a consequence, the use of derivatives is a common practice in Functional Data Analysis, despite a lack of theoretical guarantees on the asymptotically achievable performances of a derivative based model. In this paper, we show that a smoothing spline approach can be used to preprocess multivariate observations obtained by sampling functions on a discrete and finite sampling grid in a way that leads to a consistent scheme on the original infinite dimensional functional problem. This work extends (Mas and Pumo, 2009) to nonparametric approaches and incomplete knowledge. To be more precise, the paper tackles two difficulties in a nonparametric framework: the information loss due to the use of the derivatives instead of the original functions and the information loss due to the fact that the functions are observed through a discrete sampling and are thus also unperfectly known: the use of a smoothing spline based approach solves these two problems. Finally, the proposed approach is tested on two real world datasets and the approach is experimentaly proven to be a good solution in the case of noisy functional predictors. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Consistency of functional learning methods based on derivatives", "paper_id": "WOS:000290745100013"}