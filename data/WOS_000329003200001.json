{"auto_keywords": [{"score": 0.049529099900281724, "phrase": "imbalanced_datasets"}, {"score": 0.00481495049065317, "phrase": "validation_technique"}, {"score": 0.0047185649878632475, "phrase": "covariate_shift"}, {"score": 0.004584193430305955, "phrase": "data_mining"}, {"score": 0.004466519142879166, "phrase": "learned_models"}, {"score": 0.004427966503146096, "phrase": "key_step"}, {"score": 0.004215677131963292, "phrase": "k-fold_validation_technique"}, {"score": 0.004001938457469328, "phrase": "different_partitions"}, {"score": 0.003921763664916815, "phrase": "highest_average_performance"}, {"score": 0.0037880260900233064, "phrase": "\"random\"_division"}, {"score": 0.0036377310474678547, "phrase": "dataset_shift"}, {"score": 0.0035648266669315943, "phrase": "different_data_distribution"}, {"score": 0.0035340293330075483, "phrase": "training_and_test_folds"}, {"score": 0.0032309093154028663, "phrase": "minority_class_instances"}, {"score": 0.0031937337757356526, "phrase": "incorrect_learning"}, {"score": 0.003166132209407694, "phrase": "real_boundaries"}, {"score": 0.002936664639276662, "phrase": "specific_validation_technique"}, {"score": 0.002820052889643225, "phrase": "stratified_cross-validation"}, {"score": 0.0027795345823932406, "phrase": "harmful_situation"}, {"score": 0.0026307897899760383, "phrase": "different_folds"}, {"score": 0.0024899850926034567, "phrase": "wide_number"}, {"score": 0.002461321980140343, "phrase": "keel"}, {"score": 0.002398001586160856, "phrase": "different_paradigms"}, {"score": 0.002316105585203396, "phrase": "underlying_classifier"}, {"score": 0.0022176487309947266, "phrase": "proper_statistical_study"}, {"score": 0.002141898874982106, "phrase": "imbalanced_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Classification", " Imbalanced dataset", " Covariate shift", " Dataset shift", " Validation technique", " Partitioning"], "paper_abstract": "In the field of Data Mining, the estimation of the quality of the learned models is a key step in order to select the most appropriate tool for the problem to be solved. Traditionally, a k-fold validation technique has been carried out so that there is a certain degree of independency among the results for the different partitions. In this way, the highest average performance will be obtained by the most robust approach. However, applying a \"random\" division of the instances over the folds may result in a problem known as dataset shift, which consists in having a different data distribution between the training and test folds. In classification with imbalanced datasets, in which the number of instances of one class is much lower than the other class, this problem is more severe. The misclassification of minority class instances due to an incorrect learning of the real boundaries caused by a not well fitted data distribution, truly affects the measures of performance in this scenario. Regarding this fact, we propose the use of a specific validation technique for the partitioning of the data, known as \"Distribution optimally balanced stratified cross-validation\" to avoid this harmful situation in the presence of imbalance. This methodology makes the decision of placing close-by samples on different folds, so that each partition will end up with enough representatives of every region. We have selected a wide number of imbalanced datasets from KEEL dataset repository for our study, using several learning techniques from different paradigms, thus making the conclusions extracted to be independent of the underlying classifier. The analysis of the results has been carried out by means of the proper statistical study, which shows the goodness of this approach for dealing with imbalanced data. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "On the importance of the validation technique for classification with imbalanced datasets: Addressing covariate shift when data is skewed", "paper_id": "WOS:000329003200001"}