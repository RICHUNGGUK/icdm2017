{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "locally_convergent_random-search_algorithms"}, {"score": 0.003996727479807572, "phrase": "general_framework"}, {"score": 0.0035989687070420977, "phrase": "objective_function"}, {"score": 0.0033952989364738353, "phrase": "stochastic_simulation"}, {"score": 0.0032786537599187125, "phrase": "decision_variables"}, {"score": 0.0029867619862229853, "phrase": "desirable_asymptotic_properties"}, {"score": 0.002884111441153185, "phrase": "almost-sure_convergence"}, {"score": 0.002310915790114425, "phrase": "algorithm_designers"}, {"score": 0.002231441081806766, "phrase": "sophisticated_search_schemes"}, {"score": 0.0021799789348982516, "phrase": "complicated_statistical_procedures"}, {"score": 0.0021049977753042253, "phrase": "new_algorithms"}], "paper_keywords": ["random search", " discrete stochastic optimization"], "paper_abstract": "The goal of this article is to provide a general framework for locally convergent random-search algorithms for stochastic optimization problems when the objective function is embedded in a stochastic simulation and the decision variables are integer ordered. The framework guarantees desirable asymptotic properties, including almost-sure convergence and known rate of convergence, for any algorithms that conform to its mild conditions. Within this framework, algorithm designers can incorporate sophisticated search schemes and complicated statistical procedures to design new algorithms.", "paper_title": "A framework for locally convergent random-search algorithms for discrete optimization via simulation", "paper_id": "WOS:000249984700005"}