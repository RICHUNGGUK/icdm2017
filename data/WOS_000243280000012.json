{"auto_keywords": [{"score": 0.023560385454518527, "phrase": "total_memory-access_latency"}, {"score": 0.00481495049065317, "phrase": "code_scheduling"}, {"score": 0.004772818068176176, "phrase": "memory_allocation"}, {"score": 0.004648609688625397, "phrase": "memory-access_optimization"}, {"score": 0.004487989502479992, "phrase": "high_data_computations"}, {"score": 0.00439041997682389, "phrase": "memory_access"}, {"score": 0.004294962474996283, "phrase": "major_bottlenecks"}, {"score": 0.004238682850598745, "phrase": "system's_performance"}, {"score": 0.004074212307838049, "phrase": "high_variations"}, {"score": 0.0040385352882334235, "phrase": "memory-access_delays"}, {"score": 0.003916098498242888, "phrase": "memory_configurations"}, {"score": 0.0037311260623089436, "phrase": "efficient_access_modes"}, {"score": 0.00355485940716082, "phrase": "future_embedded-system_design"}, {"score": 0.003342471131048328, "phrase": "effective_solution"}, {"score": 0.003212663446866794, "phrase": "memory-access-code_generation"}, {"score": 0.0031151864044353245, "phrase": "total_memory-access_time"}, {"score": 0.00304737045343781, "phrase": "proposed_approach"}, {"score": 0.003007389443770562, "phrase": "memory-access-code_optimization"}, {"score": 0.002623669616798891, "phrase": "memory-access_operations"}, {"score": 0.002544017922741882, "phrase": "dram-access_modes"}, {"score": 0.0024776677004255104, "phrase": "storage_size_constraint"}, {"score": 0.0024559368099486647, "phrase": "embedded_systems"}, {"score": 0.002434396049547248, "phrase": "experimental_data"}, {"score": 0.002381365139274329, "phrase": "benchmark_designs"}, {"score": 0.002288797099841088, "phrase": "proposed_integrated_approach"}, {"score": 0.0021049977753042253, "phrase": "memory_mapping"}], "paper_keywords": ["embedded-system design", " memory allocation/binding", " memory-access scheduling"], "paper_abstract": "In many embedded systems, particularly those with high data computations, the delay of memory access is one of the major bottlenecks in the system's performance. It has been known that there are high variations in memory-access delays depending on the ways of designing memory configurations and assigning arrays to memories. Furthermore, embedded-DRAM technology that provides efficient access modes is actively being developed, possibly becoming a mainstream in future embedded-system design. In that context, in this paper, the authors propose an effective solution to the problem of (embedded DRAM) memory allocation and mapping in memory-access-code generation with the objective of minimizing the total memory-access time. Specifically, the proposed approach, called memory-access-code optimization (MACCESS-opt), solves the three problems simultaneously: 1) determination of memories; 2) mapping of arrays to memories; and 3) scheduling of memory-access operations, so that the use of DRAM-access modes is maximized while satisfying the storage size constraint of embedded systems. Experimental data on a set of benchmark designs are provided to show the effectiveness of the proposed integrated approach. In short, MACCESS-opt reduces the total memory-access latency by over 18%, from which the authors found that the memory mapping and scheduling techniques in MACCESS-opt contribute about 12% and 6% reductions of the total memory-access latency, respectively.", "paper_title": "Integration of code scheduling, memory allocation, and array binding for memory-access optimization", "paper_id": "WOS:000243280000012"}