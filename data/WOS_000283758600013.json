{"auto_keywords": [{"score": 0.04855973119679855, "phrase": "pixel-based_visualization"}, {"score": 0.0071698070821267605, "phrase": "block_resolution"}, {"score": 0.00481495049065317, "phrase": "task_demands"}, {"score": 0.0045691640746165045, "phrase": "popular_method"}, {"score": 0.004514241562580097, "phrase": "large_amounts"}, {"score": 0.004477992162329249, "phrase": "numerical_data"}, {"score": 0.004424160689087029, "phrase": "application_scenarios"}, {"score": 0.004283739213556286, "phrase": "remote_sensing"}, {"score": 0.004032302251481604, "phrase": "different_tasks"}, {"score": 0.003935892934907777, "phrase": "main_stimuli"}, {"score": 0.0038885527668812807, "phrase": "temporal_pixel-based_visualization"}, {"score": 0.0038417798012011155, "phrase": "white-red_color_map"}, {"score": 0.0037955672944969287, "phrase": "monthly_temperature_variation"}, {"score": 0.003749908582313067, "phrase": "six-year_period"}, {"score": 0.0036898803847106023, "phrase": "first_study"}, {"score": 0.003587125711973247, "phrase": "different_perceptual_loads"}, {"score": 0.0033223686422055834, "phrase": "low-load_tasks"}, {"score": 0.0032559935867182035, "phrase": "high-load_tasks"}, {"score": 0.0031909403420958752, "phrase": "small_but_consistent_effect"}, {"score": 0.003114584448820957, "phrase": "uniform_patch"}, {"score": 0.0030278017562213265, "phrase": "higher_block_resolution"}, {"score": 0.0029792984108210525, "phrase": "second_user_study"}, {"score": 0.002907992115184249, "phrase": "high-load_task"}, {"score": 0.0027929100418926725, "phrase": "different_regions"}, {"score": 0.002759279370360986, "phrase": "temperature_range"}, {"score": 0.0026716634658991213, "phrase": "rgb"}, {"score": 0.0025554669315362424, "phrase": "change-evaluation_errors"}, {"score": 0.0024742098091226203, "phrase": "compared_regions"}, {"score": 0.0024444073418288703, "phrase": "mapped_color_space"}, {"score": 0.002347628167175859, "phrase": "multiple_color_bands"}, {"score": 0.002263799931018574, "phrase": "final_study"}, {"score": 0.0021049977753042253, "phrase": "limited_impact"}], "paper_keywords": ["Pixel-based visualization", " evaluation", " user study", " visual search", " change detection"], "paper_abstract": "Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.", "paper_title": "Evaluating the Impact of Task Demands and Block Resolution on the Effectiveness of Pixel-based Visualization", "paper_id": "WOS:000283758600013"}