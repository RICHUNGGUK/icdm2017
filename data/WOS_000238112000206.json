{"auto_keywords": [{"score": 0.049331670369837356, "phrase": "support_vector_machines"}, {"score": 0.00481495049065317, "phrase": "genetic_algorithms"}, {"score": 0.0042452552248398445, "phrase": "original_data"}, {"score": 0.0035981701736904495, "phrase": "used_features"}, {"score": 0.0033518704336033874, "phrase": "parsimonious_feature_extraction_algorithm"}, {"score": 0.0027961342030212353, "phrase": "optimal_features"}, {"score": 0.0027307746993761035, "phrase": "genetic_algorithm"}, {"score": 0.0024842242921857705, "phrase": "proposed_algorithm"}, {"score": 0.002445347925313158, "phrase": "face_recognition"}, {"score": 0.0023881683972170422, "phrase": "yale_and_feret_databases"}, {"score": 0.002332322771009122, "phrase": "experimental_results"}, {"score": 0.002155412043665635, "phrase": "significant_factor"}, {"score": 0.0021049977753042253, "phrase": "efficient_feature_extraction_algorithms"}], "paper_keywords": [""], "paper_abstract": "Most existing feature extraction algorithms aim at best preserving information in the original data or at improving the separability of data, but fail to consider the possibility of further reducing the number of used features. In this paper, we propose a parsimonious feature extraction algorithm. Its motivation is using as few features as possible to achieve the same or even better classification performance. It searches for the optimal features using a genetic algorithm and evaluates the features referring to Support Vector Machines. We tested the proposed algorithm by face recognition on the Yale and FERET databases. The experimental results proved its effectiveness and demonstrated that parsimoniousness should be a significant factor in developing efficient feature extraction algorithms.", "paper_title": "Parsimonious feature extraction based on genetic algorithms and support vector machines", "paper_id": "WOS:000238112000206"}