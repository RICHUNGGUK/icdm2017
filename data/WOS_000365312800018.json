{"auto_keywords": [{"score": 0.036710449636736135, "phrase": "input_data"}, {"score": 0.00481495049065317, "phrase": "entropic_one-class_classifiers"}, {"score": 0.004761010795871555, "phrase": "one-class_classification_problem"}, {"score": 0.004707672504464783, "phrase": "well-known_research_endeavor"}, {"score": 0.004517137548648729, "phrase": "different_names"}, {"score": 0.004143196873246147, "phrase": "so-called_target_class"}, {"score": 0.003757480190200645, "phrase": "novel_one-class_classification_system"}, {"score": 0.0036461569988218267, "phrase": "different_techniques"}, {"score": 0.0035514484574435574, "phrase": "dissimilarity_representation-based_approach"}, {"score": 0.003446208270665051, "phrase": "dissimilarity_space"}, {"score": 0.003344076203780408, "phrase": "appropriate_parametric_dissimilarity_measure"}, {"score": 0.0032449610741097992, "phrase": "virtually_any_type"}, {"score": 0.0031845067058084583, "phrase": "dissimilarity_vectors"}, {"score": 0.003125175084962886, "phrase": "weighted_euclidean_graphs"}, {"score": 0.0029984960344766705, "phrase": "data_distribution"}, {"score": 0.0028877818105020434, "phrase": "effective_decision_regions"}, {"score": 0.0027706987570488084, "phrase": "dissimilarity_measure"}, {"score": 0.002628506002255396, "phrase": "global_optimization_scheme"}, {"score": 0.002493592357827492, "phrase": "proposed_one-class_classifier"}, {"score": 0.0023566987138026285, "phrase": "accurate_description"}, {"score": 0.002330233210731173, "phrase": "classification_process"}, {"score": 0.0022441378838655712, "phrase": "different_benchmarking_data_sets"}, {"score": 0.0021530945641993152, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_technique"}], "paper_keywords": ["Dissimilarity representation", " entropic spanning graph", " fuzzy set", " modularity measure", " one-class classification"], "paper_abstract": "The one-class classification problem is a well-known research endeavor in pattern recognition. The problem is also known under different names, such as outlier and novelty/anomaly detection. The core of the problem consists in modeling and recognizing patterns belonging only to a so-called target class. All other patterns are termed nontarget, and therefore, they should be recognized as such. In this paper, we propose a novel one-class classification system that is based on an interplay of different techniques. Primarily, we follow a dissimilarity representation-based approach; we embed the input data into the dissimilarity space (DS) by means of an appropriate parametric dissimilarity measure. This step allows us to process virtually any type of data. The dissimilarity vectors are then represented by weighted Euclidean graphs, which we use to determine the entropy of the data distribution in the DS and at the same time to derive effective decision regions that are modeled as clusters of vertices. Since the dissimilarity measure for the input data is parametric, we optimize its parameters by means of a global optimization scheme, which considers both mesoscopic and structural characteristics of the data represented through the graphs. The proposed one-class classifier is designed to provide both hard (Boolean) and soft decisions about the recognition of test patterns, allowing an accurate description of the classification process. We evaluate the performance of the system on different benchmarking data sets, containing either feature-based or structured patterns. Experimental results demonstrate the effectiveness of the proposed technique.", "paper_title": "Entropic One-Class Classifiers", "paper_id": "WOS:000365312800018"}