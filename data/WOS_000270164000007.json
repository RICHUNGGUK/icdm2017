{"auto_keywords": [{"score": 0.050067105662444995, "phrase": "acoustic-phonetic_information"}, {"score": 0.04924756060237546, "phrase": "automatic_speech_recognition"}, {"score": 0.041318788873943385, "phrase": "ann"}, {"score": 0.037877352928178704, "phrase": "knowledge_module"}, {"score": 0.004619295212985837, "phrase": "lattice_rescoring_approach"}, {"score": 0.004508878340498472, "phrase": "asr"}, {"score": 0.004431554974667461, "phrase": "additional_information"}, {"score": 0.004340553321613485, "phrase": "conventional_log-likelihood"}, {"score": 0.004207527897084009, "phrase": "speech_event_detectors"}, {"score": 0.004106877044437756, "phrase": "articulation_events"}, {"score": 0.004078562617505643, "phrase": "log-likelihood_ratios"}, {"score": 0.004008624230034271, "phrase": "confidence_levels"}, {"score": 0.003967235882351874, "phrase": "artificial_neural_network"}, {"score": 0.0038456073694665, "phrase": "raw_log-likelihood_ratio_scores"}, {"score": 0.0037796484923665855, "phrase": "easy_incorporation"}, {"score": 0.003663749926218976, "phrase": "event_detectors"}, {"score": 0.003466382911409222, "phrase": "generic_framework"}, {"score": 0.003325343504284345, "phrase": "existing_asr_system"}, {"score": 0.0031789986177545586, "phrase": "generic_knowledge_module"}, {"score": 0.003102875178186416, "phrase": "asr_system"}, {"score": 0.0030496164547515565, "phrase": "specific_data"}, {"score": 0.0029458177077921043, "phrase": "proposed_approach"}, {"score": 0.002720254890261961, "phrase": "data-driven_knowledge_module"}, {"score": 0.0026735459686033627, "phrase": "single_corpus"}, {"score": 0.0025914765323897604, "phrase": "experimental_results"}, {"score": 0.0025293860389728516, "phrase": "proposed_rescoring_framework"}, {"score": 0.0025119200240696824, "phrase": "better_results"}, {"score": 0.002451730979693715, "phrase": "confidence_scores"}, {"score": 0.0023437424558633013, "phrase": "rescoring_process"}, {"score": 0.0022639147412879487, "phrase": "large_vocabulary_continuous_speech_recognition"}, {"score": 0.0022096550791379033, "phrase": "lexical_and_language_models"}, {"score": 0.0021867999937268084, "phrase": "recognition_results"}, {"score": 0.002149231173009159, "phrase": "underlying_acoustic-phonetic_properties"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Knowledge based system", " Lattice rescoring", " Continuous phone recognition", " Large vocabulary continuous speech recognition"], "paper_abstract": "In this paper, a lattice rescoring approach to integrating acoustic-phonetic information into automatic speech recognition (ASR) is described. Additional information over what is used in conventional log-likelihood based decoding is provided by a bank of speech event detectors that score manner and place of articulation events with log-likelihood ratios that are treated as confidence levels. An artificial neural network (ANN) is then used to transform raw log-likelihood ratio scores into manageable terms for easy incorporation. We refer to the union of the event detectors and the ANN as knowledge module. A goal of this study is to design a generic framework which makes it easier to incorporate other sources of information into an existing ASR system. Another aim is to start investigating the possibility of building a generic knowledge module that can be plugged into an ASR system without being trained on specific data for the given task. To this end, the proposed approach is evaluated on three diverse ASR tasks: continuous phone recognition, connected digit recognition, and large vocabulary continuous speech recognition, but the data-driven knowledge module is trained with a single corpus and used in all three evaluation tasks without further training. Experimental results indicate that in all three cases the proposed rescoring framework achieves better results than those obtained without incorporating the confidence scores provided by the knowledge module. It is interesting to note that the rescoring process is especially effective in correcting utterances with errors in large vocabulary continuous speech recognition, where constraints imposed by the lexical and language models sometimes produce recognition results not strictly observing the underlying acoustic-phonetic properties. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "A study on integrating acoustic-phonetic information into lattice rescoring for automatic speech recognition", "paper_id": "WOS:000270164000007"}