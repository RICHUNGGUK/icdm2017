{"auto_keywords": [{"score": 0.024423970794191084, "phrase": "average_power_saving"}, {"score": 0.004756805752518494, "phrase": "intelligent_learning_methods"}, {"score": 0.004558748120167778, "phrase": "embedded_system_working_model"}, {"score": 0.004212453011596424, "phrase": "service_queue"}, {"score": 0.004061584718427419, "phrase": "power_manager"}, {"score": 0.003916098498242888, "phrase": "novel_approach"}, {"score": 0.003685067218455088, "phrase": "best_policy"}, {"score": 0.003640516896245813, "phrase": "existing_dpm_policies"}, {"score": 0.0035965032173588753, "phrase": "deterministic_markovian_nonstationary_policies"}, {"score": 0.0034465894339710864, "phrase": "reinforcement_learning"}, {"score": 0.0032431667821391044, "phrase": "goal-directed_learning"}, {"score": 0.0031845067058084613, "phrase": "different_devices"}, {"score": 0.003051713660488494, "phrase": "formal_framework"}, {"score": 0.0028195727965553367, "phrase": "response_action"}, {"score": 0.0025735173163957993, "phrase": "event-driven_simulator"}, {"score": 0.00252707821574736, "phrase": "java"}, {"score": 0.002481200970201421, "phrase": "power-manageable_machine-to-machine_device"}, {"score": 0.0023632309822037637, "phrase": "proposed_dynamic_power_management"}, {"score": 0.0022236070278432575, "phrase": "novel_dynamic_power_management"}, {"score": 0.0021966859554037174, "phrase": "dmnsp"}, {"score": 0.0021049977753042253, "phrase": "already_proposed_dpm_policies"}], "paper_keywords": ["Algorithms", " Design", " Performance", " Dynamic power management", " intelligent reinforcement and indexing"], "paper_abstract": "In this work, an embedded system working model is designed with one server that receives requests by a requester by a service queue that is monitored by a Power Manager (PM). A novel approach is presented based on reinforcement learning to predict the best policy amidst existing DPM policies and deterministic markovian nonstationary policies (DMNSP). We apply reinforcement learning, namely a computational approach to understanding and automating goal-directed learning that supports different devices according to their DPM. Reinforcement learning uses a formal framework defining the interaction between agent and environment in terms of states, response action, and reward points. The capability of this approach is demonstrated by an event-driven simulator designed using Java with a power-manageable machine-to-machine device. Our experiment result shows that the proposed dynamic power management with timeout policy gives average power saving from 4% to 21% and the novel dynamic power management with DMNSP gives average power saving from 10% to 28% more than already proposed DPM policies.", "paper_title": "Real-Time Power Management for Embedded M2M Using Intelligent Learning Methods", "paper_id": "WOS:000346416300004"}