{"auto_keywords": [{"score": 0.046174914978806214, "phrase": "visual_attention"}, {"score": 0.014326333312664627, "phrase": "human_visual_sensitivity"}, {"score": 0.011480191019888005, "phrase": "stereo_distortion_predictor"}, {"score": 0.00481495049065317, "phrase": "stereo_image_quality_assessment_using_visual_attention"}, {"score": 0.004523103062368843, "phrase": "stereo_image_quality"}, {"score": 0.004364310576600359, "phrase": "based_distortion_prediction"}, {"score": 0.004267896572751978, "phrase": "disparity_information"}, {"score": 0.004136469845987887, "phrase": "combined_aspects"}, {"score": 0.0040996651541091575, "phrase": "human_visual_processing"}, {"score": 0.003991196463806465, "phrase": "visual_attention_and_depth_assisted_stereo_image_quality_assessment_model"}, {"score": 0.0033227310662785293, "phrase": "inverse_contrast"}, {"score": 0.0031916366459252992, "phrase": "depth_variation"}, {"score": 0.0031210475158175432, "phrase": "attention_probability"}, {"score": 0.0030248298759040695, "phrase": "changed_depth"}, {"score": 0.0029978863469038914, "phrase": "distorted_stereo_images"}, {"score": 0.0028667159745494933, "phrase": "distortion_probability"}, {"score": 0.0027907771648224273, "phrase": "low-level_human_visual_system"}, {"score": 0.0027047136845332917, "phrase": "actual_attention_probabilities"}, {"score": 0.0025518429503461736, "phrase": "visually_significant_distortions"}, {"score": 0.0025178072071268534, "phrase": "stereo_image_pair"}, {"score": 0.0024620842899061614, "phrase": "based_picture_quality_metrics"}, {"score": 0.0023125191783901367, "phrase": "positive_correlation"}, {"score": 0.002291905937251069, "phrase": "ground-truth_attention"}, {"score": 0.0021334819307721785, "phrase": "pearson"}, {"score": 0.0021049977753042253, "phrase": "spearman_correlation_coefficients"}], "paper_keywords": ["Image quality assessment", " stereo image processing", " visual attention", " 3D depth", " distortion predictor"], "paper_abstract": "Several metrics have been reported in the literature to assess stereo image quality, mostly based on visual attention or human visual sensitivity based distortion prediction with the help of disparity information, which do not consider the combined aspects of human visual processing. In this paper, visual attention and depth assisted stereo image quality assessment model (VAD-SIQAM) is devised that consists of three main components, i.e., stereo attention predictor (SAP), depth variation (DV), and stereo distortion predictor (SDP). Visual attention is modeled based on entropy and inverse contrast to detect regions or objects of interest/ attention. Depth variation is fused into the attention probability to account for the amount of changed depth in distorted stereo images. Finally, the stereo distortion predictor is designed by integrating distortion probability, which is based on low-level human visual system (HVS), responses into actual attention probabilities. The results show that regions of attention are detected among the visually significant distortions in the stereo image pair. Drawbacks of human visual sensitivity based picture quality metrics are alleviated by integrating visual attention and depth information. We also show that positive correlation with ground-truth attention and depth maps are increased by up to 0.949 and 0.936 in terms of the Pearson and the Spearman correlation coefficients, respectively.", "paper_title": "Stereo Image Quality Assessment Using Visual Attention and Distortion Predictors", "paper_id": "WOS:000296499700007"}