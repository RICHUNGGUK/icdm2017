{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "rescue_robots"}, {"score": 0.004723847090183984, "phrase": "rescue_operation"}, {"score": 0.004612376827433774, "phrase": "great_deal"}, {"score": 0.004503525064934708, "phrase": "uneven_terrain"}, {"score": 0.004439445472040688, "phrase": "uncontrolled_environment"}, {"score": 0.004252602474733162, "phrase": "potential_vital_sign"}, {"score": 0.003939565240409143, "phrase": "high_accuracy"}, {"score": 0.0038834787946979863, "phrase": "false_alarms"}, {"score": 0.003791763445590174, "phrase": "existing_techniques"}, {"score": 0.0037556843869894566, "phrase": "motion_detection"}, {"score": 0.0037199473428123175, "phrase": "severe_limitations"}, {"score": 0.0036494864560524735, "phrase": "strong_levels"}, {"score": 0.003580355398511932, "phrase": "walking_robots"}, {"score": 0.0034790978593553794, "phrase": "optical_flow-based_method"}, {"score": 0.003332537728389913, "phrase": "single_camera"}, {"score": 0.00326939082861424, "phrase": "hexapod_robot"}, {"score": 0.003087017178815267, "phrase": "object_detection"}, {"score": 0.003043031131345537, "phrase": "continuously_moving_robot"}, {"score": 0.002985353542495357, "phrase": "first-order-flow_motion_model"}, {"score": 0.002887028262617443, "phrase": "strong_rotation"}, {"score": 0.0026742419973883134, "phrase": "motion-compensated_frame_differencing"}, {"score": 0.002549269480908849, "phrase": "slow-_and_fast-moving_objects"}, {"score": 0.0024771000236931836, "phrase": "optimized_resource_utilization"}, {"score": 0.0024185182010749273, "phrase": "video_frames"}, {"score": 0.0023388183537341213, "phrase": "new_algorithm"}, {"score": 0.002305468528385778, "phrase": "significant_improvement"}, {"score": 0.002166349705365602, "phrase": "harsh_environment"}, {"score": 0.0021049977753042253, "phrase": "smooth_motion"}], "paper_keywords": ["Embedded systems", " FPGA-based real-time processing", " Software/hardware codesign", " Optical flow", " Egomotion estimation", " Moving object detection"], "paper_abstract": "In a rescue operation walking robots offer a great deal of flexibility in traversing uneven terrain in an uncontrolled environment. For such a rescue robot, each motion is a potential vital sign and the robot should be sensitive enough to detect such motion, at the same time maintaining high accuracy to avoid false alarms. However, the existing techniques for motion detection have severe limitations in dealing with strong levels of ego-motion on walking robots. This paper proposes an optical flow-based method for the detection of moving objects using a single camera mounted on a hexapod robot. The proposed algorithm estimates and compensates ego-motion to allow for object detection from a continuously moving robot, using a first-order-flow motion model. Our algorithm can deal with strong rotation and translation in 3D, with four degrees of freedom. Two alternative object detection methods using a 2D-histogram based vector clustering and motion-compensated frame differencing, respectively, are examined for the detection of slow- and fast-moving objects. The FPGA implementation with optimized resource utilization using SW/HW codesign can process video frames in real-time at 31 fps. The new algorithm offers a significant improvement in performance over the state-of-the-art, under harsh environment and performs equally well under smooth motion.", "paper_title": "Real-time motion detection based on SW/HW-codesign for walking rescue robots", "paper_id": "WOS:000327437200002"}