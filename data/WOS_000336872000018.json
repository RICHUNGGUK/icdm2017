{"auto_keywords": [{"score": 0.04833698297204837, "phrase": "biometric_systems"}, {"score": 0.025888224151747474, "phrase": "frgc"}, {"score": 0.025422928359642962, "phrase": "binarization_algorithm"}, {"score": 0.00481495049065317, "phrase": "transform-based_binary-template_protection"}, {"score": 0.004674333455266527, "phrase": "increasing_deployment"}, {"score": 0.004487635647709636, "phrase": "essential_issue"}, {"score": 0.004438019162720755, "phrase": "serious_attention"}, {"score": 0.0043083624695326745, "phrase": "unauthorized_access"}, {"score": 0.004260719592945006, "phrase": "biometric_system"}, {"score": 0.004120915812750583, "phrase": "enrolled_biometric_templates"}, {"score": 0.003970930401776528, "phrase": "stored_information"}, {"score": 0.003784049616066444, "phrase": "illegal_access"}, {"score": 0.0037145284903339327, "phrase": "transform-based_template_protection"}, {"score": 0.0036734281414482735, "phrase": "binary_one-way-transformed_templates"}, {"score": 0.0035265659032655845, "phrase": "benchmark_template_protection_techniques"}, {"score": 0.0032987614613108345, "phrase": "transformed_binary_template"}, {"score": 0.0032501644753165555, "phrase": "corresponding_face_image"}, {"score": 0.0030288982511487835, "phrase": "transform-based_approach"}, {"score": 0.0029732094730218488, "phrase": "synthetic_face_image"}, {"score": 0.0029077288662492894, "phrase": "binary_template"}, {"score": 0.002875529792120695, "phrase": "stolen_token"}, {"score": 0.002760478838718213, "phrase": "highly-probable_positive_authentication_response"}, {"score": 0.00265987582861194, "phrase": "perceptron_learning"}, {"score": 0.0026401983633087267, "phrase": "customized_hill"}, {"score": 0.0026012779346272848, "phrase": "experimental_results"}, {"score": 0.0025251455169484557, "phrase": "best_setting"}, {"score": 0.00222561197623787, "phrase": "cmu_pie"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Masquerade attack", " Binary", " Template protection", " Perceptron learning"], "paper_abstract": "With the increasing deployment of biometric systems, security of the biometric systems has become an essential issue to which serious attention has to be given. To prevent unauthorized access to a biometric system, protection has to be provided to the enrolled biometric templates so that if the database is compromised, the stored information will not enable any adversary to impersonate the victim in gaining an illegal access. In the past decade, transform-based template protection that stores binary one-way-transformed templates (e.g. Biohash) has appeared being one of the benchmark template protection techniques. While the security of such approach lies in the non-invertibility of the transform (e.g. given a transformed binary template, deriving the corresponding face image is infeasible), we will prove in this paper that, irrespective of whether the algorithm of transform-based approach is revealed, a synthetic face image can be constructed from the binary template and the stolen token (storing projection and discretization parameters) to obtain a highly-probable positive authentication response. Our proposed masquerade attack algorithms are mainly composed of a combination of perceptron learning and customized hill climbing algorithms. Experimental results show that our attack algorithms achieve very promising results where the best setting of our attack achieves 100% and 98.3% rank one recognition rates for the CMU PIE and FRGC databases correspondingly when the binarization algorithm (transformation plus discretization) is known; and 85.29% and 46.57% rank one recognition rates for the CMU PIE and FRGC databases correspondingly when the binarization algorithm is unknown. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Masquerade attack on transform-based binary-template protection based on perceptron learning", "paper_id": "WOS:000336872000018"}