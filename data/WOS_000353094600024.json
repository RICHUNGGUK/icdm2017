{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "feature_selection"}, {"score": 0.004624751696958501, "phrase": "wrapper_method"}, {"score": 0.004288059466938456, "phrase": "irrelevant_or_redundant_features"}, {"score": 0.004139401327448807, "phrase": "cosine_distance"}, {"score": 0.0040978781692373005, "phrase": "support_vector_machines"}, {"score": 0.003799397093447221, "phrase": "svm_parameters"}, {"score": 0.003704797078215222, "phrase": "attribute_space"}, {"score": 0.003487222504700868, "phrase": "classification_process"}, {"score": 0.003366233863411861, "phrase": "classification_error"}, {"score": 0.0032824015751162752, "phrase": "svm."}, {"score": 0.0032494292163722065, "phrase": "proposed_csmsvm_framework"}, {"score": 0.0031208772639433145, "phrase": "svm_parameter_learning"}, {"score": 0.003073988343893906, "phrase": "low_relevance_features"}, {"score": 0.0029672941061574375, "phrase": "anisotropic_rbf_kernel"}, {"score": 0.0029374939071038146, "phrase": "feature_space"}, {"score": 0.0028642924503126154, "phrase": "bayesian_interpretation"}, {"score": 0.002821247621250663, "phrase": "novel_methodology"}, {"score": 0.002723301730223192, "phrase": "proposed_method"}, {"score": 0.0026959452932289797, "phrase": "solid_theory_foundation"}, {"score": 0.0026420518944303716, "phrase": "iteration_algorithm"}, {"score": 0.0025374674652885354, "phrase": "feature_weight"}, {"score": 0.0023405257495466352, "phrase": "novel_method"}, {"score": 0.0023170054862555896, "phrase": "well-known_feature_selection_techniques"}, {"score": 0.0022706700510423954, "phrase": "csmsvm"}, {"score": 0.0021917966722180132, "phrase": "pattern_recognition_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Cosine similarity measure", " Feature selection", " Support vector machines", " Bayesian interpretation"], "paper_abstract": "This paper introduces a wrapper method, namely cosine similarity measure support vector machines (CSMSVM), to eliminate irrelevant or redundant features during classifier construction by introducing the cosine distance into support vector machines (SVM). Traditionally, feature selection approaches typically extract features and learn SVM parameters independently or in the attribute space, which might result in a loss of information related to classification process or lead to the increase of classification error when introduce the kernel SVM. The proposed CSMSVM framework, however, jointly performs feature selection, SVM parameter learning and remove low relevance features by optimizing the shape of an anisotropic RBF kernel in feature space. Moreover, the Bayesian interpretation of the novel methodology reveals its Bayesian character, which builds the proposed method on solid theory foundation, and the iteration algorithm, which is proposed to optimize the feature weight, has achieved to maximize the maximum a posterior (MAP). Comparing the novel method with well-known feature selection techniques with experiments, CSMSVM outperformed the other methodologies in improving the pattern recognition accuracy with fewer features. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "A novel wrapper method for feature selection and its applications", "paper_id": "WOS:000353094600024"}