{"auto_keywords": [{"score": 0.04274518365190484, "phrase": "different_domains"}, {"score": 0.03381164258100083, "phrase": "base_dictionary"}, {"score": 0.031470281917134614, "phrase": "face_recognition"}, {"score": 0.030725265596084485, "phrase": "face_image"}, {"score": 0.03020359644689766, "phrase": "sparse_representations"}, {"score": 0.00481495049065317, "phrase": "domain_adaptive_face_recognition"}, {"score": 0.0047310525657970615, "phrase": "dictionary_learning_approach"}, {"score": 0.004519665344659923, "phrase": "view_point"}, {"score": 0.0043481611772332495, "phrase": "key_idea"}, {"score": 0.004257360656055417, "phrase": "domain-invariant_sparse_coding"}, {"score": 0.004153810449519519, "phrase": "consistent_sparse_representation"}, {"score": 0.0039264465913491356, "phrase": "sparse_codes"}, {"score": 0.003885216927966404, "phrase": "source_domain"}, {"score": 0.0038444185258456245, "phrase": "frontal_faces"}, {"score": 0.00376409764683147, "phrase": "target_domain"}, {"score": 0.00368544869176071, "phrase": "different_poses"}, {"score": 0.003659597920882104, "phrase": "illumination_conditions"}, {"score": 0.003545487140867762, "phrase": "recognition_accuracy"}, {"score": 0.003434922209075514, "phrase": "domain_base_dictionary"}, {"score": 0.0033631279928072314, "phrase": "domain_shift"}, {"score": 0.003235367401211807, "phrase": "sparse_representation"}, {"score": 0.0030689098754563982, "phrase": "sparse_linear_combinations"}, {"score": 0.002931569771634119, "phrase": "proposed_compositional_dictionary_approach"}, {"score": 0.0026750045328382717, "phrase": "extracted_sparse_representation"}, {"score": 0.0025462598594116373, "phrase": "insensitive_face_recognition"}, {"score": 0.0024066745849759706, "phrase": "illumination_condition"}, {"score": 0.002188219483646592, "phrase": "extensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Face recognition", " domain adaption", " sparse representation", " pose alignment", " illumination normalization", " multilinear image analysis"], "paper_abstract": "We present a dictionary learning approach to compensate for the transformation of faces due to the changes in view point, illumination, resolution, and so on. The key idea of our approach is to force domain-invariant sparse coding, i. e., designing a consistent sparse representation of the same face in different domains. In this way, the classifiers trained on the sparse codes in the source domain consisting of frontal faces can be applied to the target domain (consisting of faces in different poses, illumination conditions, and so on) without much loss in recognition accuracy. The approach is to first learn a domain base dictionary, and then describe each domain shift (identity, pose, and illumination) using a sparse representation over the base dictionary. The dictionary adapted to each domain is expressed as the sparse linear combinations of the base dictionary. In the context of face recognition, with the proposed compositional dictionary approach, a face image can be decomposed into sparse representations for a given subject, pose, and illumination. This approach has three advantages. First, the extracted sparse representation for a subject is consistent across domains, and enables pose and illumination insensitive face recognition. Second, sparse representations for pose and illumination can be subsequently used to estimate the pose and illumination condition of a face image. Last, by composing sparse representations for the subject and the different domains, we can also perform pose alignment and illumination normalization. Extensive experiments using two public face data sets are presented to demonstrate the effectiveness of the proposed approach for face recognition.", "paper_title": "Compositional Dictionaries for Domain Adaptive Face Recognition", "paper_id": "WOS:000362488900004"}