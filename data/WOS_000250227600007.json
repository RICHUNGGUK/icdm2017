{"auto_keywords": [{"score": 0.045463601775596024, "phrase": "compilation_techniques"}, {"score": 0.02510050144266026, "phrase": "processing_time"}, {"score": 0.00481495049065317, "phrase": "mpsoc_memory_optimization"}, {"score": 0.004758053266234474, "phrase": "program_transformation"}, {"score": 0.004028326293950714, "phrase": "data_locality"}, {"score": 0.0038640303886081444, "phrase": "parallel_architectures"}, {"score": 0.0036625643243684827, "phrase": "single_loop_nest"}, {"score": 0.0035551969986263553, "phrase": "new_techniques"}, {"score": 0.003450966222451678, "phrase": "loop_fusion"}, {"score": 0.0032709661258673206, "phrase": "resulting_code"}, {"score": 0.003232254571848865, "phrase": "different_processors"}, {"score": 0.0030819219279832224, "phrase": "memory_accesses"}, {"score": 0.0028865314258560214, "phrase": "exploitable_parallelism"}, {"score": 0.0026241684260044414, "phrase": "memory_space"}, {"score": 0.0025776913268808124, "phrase": "temporary_arrays"}, {"score": 0.0025471636425006155, "phrase": "smaller_buffers"}, {"score": 0.0024431289979171505, "phrase": "different_strategies"}, {"score": 0.002168664249034287, "phrase": "significant_reduction"}, {"score": 0.0021049977753042253, "phrase": "data_cache_misses"}], "paper_keywords": ["design", " performance", " experimentation", " data locality", " compiler transformations", " embedded systems", " data cache"], "paper_abstract": "Multiprocessor system-on-a-chip (MPSoC) architectures have received a lot of attention in the past years, but few advances in compilation techniques target these architectures. This is particularly true for the exploitation of data locality. Most of the compilation techniques for parallel architectures discussed in the literature are based on a single loop nest. This article presents new techniques that consist in applying loop fusion and tiling to several loop nests and to parallelize the resulting code across different processors. These two techniques reduce the number of memory accesses: However, they increase dependencies and thereby reduce the exploitable parallelism in the code. This article tries to address this contradiction. To optimize the memory space used by temporary arrays, smaller buffers are used as a replacement. Different strategies are studied to optimize the processing time spent accessing these buffers. The experiments show that these techniques yield a significant reduction in the number of data cache misses (30%) and in processing time (50%).", "paper_title": "MPSoC memory optimization using program transformation", "paper_id": "WOS:000250227600007"}