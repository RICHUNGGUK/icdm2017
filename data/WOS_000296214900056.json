{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "neighborhood_evidential_decision_error"}, {"score": 0.03718034097391593, "phrase": "decision_boundary_regions"}, {"score": 0.015036696411805035, "phrase": "feature_selection"}, {"score": 0.012145092827069187, "phrase": "bayes"}, {"score": 0.004645057834614705, "phrase": "evidence_theory"}, {"score": 0.004541918674719973, "phrase": "important_preprocessing_step"}, {"score": 0.00450130420152996, "phrase": "pattern_recognition"}, {"score": 0.004461051281091779, "phrase": "machine_learning"}, {"score": 0.004401342842183475, "phrase": "feature_evaluation"}, {"score": 0.004342430078306461, "phrase": "key_issues"}, {"score": 0.0042459818200777846, "phrase": "feature_selection_algorithms"}, {"score": 0.0040777192615062815, "phrase": "new_concept"}, {"score": 0.003933736547198066, "phrase": "candidate_features"}, {"score": 0.0038636556112977226, "phrase": "greedy_forward_algorithm"}, {"score": 0.003611751858608048, "phrase": "spatial_information"}, {"score": 0.0029236680654022664, "phrase": "misclassified_samples"}, {"score": 0.0028586409810976367, "phrase": "bayes_error_rate"}, {"score": 0.0027950561494657633, "phrase": "corresponding_feature_subspaces"}, {"score": 0.0026126405272417783, "phrase": "optimal_feature_subsets"}, {"score": 0.0025892330566358503, "phrase": "raw_data"}, {"score": 0.0025089420019955232, "phrase": "numerical_experiments"}, {"score": 0.0024421008630165046, "phrase": "proposed_technique"}, {"score": 0.0024093494406195386, "phrase": "nine_uci_classification_datasets"}, {"score": 0.0023770362063833903, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "neighborhood_dependency"}], "paper_keywords": ["Feature selection", " Feature evaluation", " Neighborhood evidential decision error", " Classification complexity", " Neighborhood rough set model", " Evidence theory"], "paper_abstract": "Feature selection is an important preprocessing step in pattern recognition and machine learning, and feature evaluation arises as key issues in the construction of feature selection algorithms. In this study, we introduce a new concept of neighborhood evidential decision error to evaluate the quality of candidate features and construct a greedy forward algorithm for feature selection. This technique considers both the Bayes error rate of classification and spatial information of samples in the decision boundary regions. Within the decision boundary regions, each sample x(i) in the neighborhood of x provides a piece of evidence reflecting the decision of x so as to separate the decision boundary regions into two subsets: recognizable and misclassified regions. The percentage of misclassified samples is viewed as the Bayes error rate of classification in the corresponding feature subspaces. By minimizing the neighborhood evidential decision error (i.e., Bayes error rate), the optimal feature subsets of raw data set can be selected. Some numerical experiments were conducted to validate the proposed technique by using nine UCI classification datasets. The experimental results showed that this technique is effective in most of the cases, and is insensitive to the size of neighborhood comparing with other feature evaluation functions such as the neighborhood dependency. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Minimizing neighborhood evidential decision error for feature evaluation and selection based on evidence theory", "paper_id": "WOS:000296214900056"}