{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "visual_saliency_estimation"}, {"score": 0.004748169052188766, "phrase": "video"}, {"score": 0.004455061431809975, "phrase": "probabilistic_multi-task_learning_approach"}, {"score": 0.0038407203087210775, "phrase": "stimulus-driven_and_task-related_factors"}, {"score": 0.0035533891890176823, "phrase": "stimulus-driven_component"}, {"score": 0.003478813491904962, "phrase": "low-level_processes"}, {"score": 0.0034299649219748513, "phrase": "human_vision_system"}, {"score": 0.0033817999428800457, "phrase": "multi-scale_wavelet_decomposition"}, {"score": 0.003195787852087248, "phrase": "task-related_component"}, {"score": 0.0031286936417685178, "phrase": "high-level_processes"}, {"score": 0.0029775511937434797, "phrase": "input_features"}, {"score": 0.0028944757265206332, "phrase": "existing_approaches"}, {"score": 0.002793874145713024, "phrase": "multi-task_learning_algorithm"}, {"score": 0.0027159094186967247, "phrase": "task-related_\"stimulus-saliency\"_mapping_functions"}, {"score": 0.002408052242408488, "phrase": "stimulus-driven_and_task-related_components"}, {"score": 0.00229164285862567, "phrase": "extensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": ["Visual saliency", " Probabilistic framework", " Visual search tasks", " Multi-task learning"], "paper_abstract": "In this paper, we present a probabilistic multi-task learning approach for visual saliency estimation in video. In our approach, the problem of visual saliency estimation is modeled by simultaneously considering the stimulus-driven and task-related factors in a probabilistic framework. In this framework, a stimulus-driven component simulates the low-level processes in human vision system using multi-scale wavelet decomposition and unbiased feature competition; while a task-related component simulates the high-level processes to bias the competition of the input features. Different from existing approaches, we propose a multi-task learning algorithm to learn the task-related \"stimulus-saliency\" mapping functions for each scene. The algorithm also learns various fusion strategies, which are used to integrate the stimulus-driven and task-related components to obtain the visual saliency. Extensive experiments were carried out on two public eye-fixation datasets and one regional saliency dataset. Experimental results show that our approach outperforms eight state-of-the-art approaches remarkably.", "paper_title": "Probabilistic Multi-Task Learning for Visual Saliency Estimation in Video", "paper_id": "WOS:000281087900002"}