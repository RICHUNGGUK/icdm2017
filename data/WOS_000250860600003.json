{"auto_keywords": [{"score": 0.04677598271843611, "phrase": "large_scale"}, {"score": 0.004690025569165577, "phrase": "recent_advances"}, {"score": 0.004517137548648729, "phrase": "efficient_exploitation"}, {"score": 0.004449772140968921, "phrase": "computing_platforms"}, {"score": 0.004399905285945236, "phrase": "computational_grids"}, {"score": 0.004366970206156021, "phrase": "huge_clusters"}, {"score": 0.004301834610818624, "phrase": "great_promise"}, {"score": 0.004253618550301311, "phrase": "highly_resource_demanding_task"}, {"score": 0.004174451361776433, "phrase": "large_models"}, {"score": 0.004112175423546628, "phrase": "model_checkers"}, {"score": 0.004020492138367616, "phrase": "high_degree"}, {"score": 0.003729335910488339, "phrase": "high_performance"}, {"score": 0.0037153426267756452, "phrase": "distributed_symbolic_model_checker"}, {"score": 0.0036324746826127997, "phrase": "distributed_environment"}, {"score": 0.0035648266669315943, "phrase": "hybrid_algorithm"}, {"score": 0.003511613254403125, "phrase": "state_space"}, {"score": 0.0033190180867511605, "phrase": "new_approach"}, {"score": 0.003172551230409948, "phrase": "previous_slicing_algorithms"}, {"score": 0.003101752151627964, "phrase": "checkpoint_restart_module"}, {"score": 0.0028446460307503343, "phrase": "computing_plat_form"}, {"score": 0.0028127163745564777, "phrase": "checkpoint_restart"}, {"score": 0.0027395968397212053, "phrase": "scheduling_system"}, {"score": 0.0026583500966092044, "phrase": "large_numbers"}, {"score": 0.0025989960809479104, "phrase": "distributed_computation_work"}, {"score": 0.0025219085140220773, "phrase": "fist_time"}, {"score": 0.0024563302149829, "phrase": "distributed_model_checker"}, {"score": 0.0024105326885334962, "phrase": "distributed_system"}, {"score": 0.002347843727281585, "phrase": "sequential_one"}, {"score": 0.0022441378838655712, "phrase": "distributed_scaiabie_scheme"}, {"score": 0.0022105951175680856, "phrase": "high_performance_industrial_model_checker"}, {"score": 0.0021940382641040465, "phrase": "intel"}, {"score": 0.0021049977753042253, "phrase": "real_life_models"}], "paper_keywords": ["distributed", " model checking", " BDDs", " slicing", " reorder"], "paper_abstract": "Recent advances in scheduling and networking have paved the way for efficient exploitation of large scale distributed computing platforms such as computational grids and huge clusters. Such infrastructures hold great promise for the highly resource demanding task of verifying and checking large models, given that model checkers would be designed with a high degree of scalability and flexibility in mind. In this paper we focus on the mechanisms required to execute a high performance distributed symbolic model checker on top of a large scale distributed environment. We develop a hybrid algorithm for slicing the state space and dynamically distribute the work among the worker processes. We show that the new approach is faster, more effective and thus much more scalable than previous slicing algorithms. We then present a checkpoint restart module that has very low overhead. This module can be used to combat failures the likelihood of which increases with the size of the computing plat form However, checkpoint restart is even more handy for the scheduling system it can be used te avoid reserving large numbers of workers thus making the distributed computation work efficient. Finally we discuss for the fist time the effect of reorder on the distributed model checker and show how the distributed system performs more efficient reordering than the sequential one. We implemented our contributions on a network of 200 processors using a distributed scaIabIe scheme that employs a high performance industrial model checker from Intel. Our results show that the system was able to verify real life models much larger than was previously possible.", "paper_title": "Verifying very large industrial circuits using 100 processes and beyond", "paper_id": "WOS:000250860600003"}