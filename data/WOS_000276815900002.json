{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "general_formulation"}, {"score": 0.004764220976404241, "phrase": "nonnegative_data_factorization"}, {"score": 0.004151188559520802, "phrase": "so-called_intrinsic_and_penalty_graphs"}, {"score": 0.003813669883040509, "phrase": "new_testing_sample"}, {"score": 0.0035408501923902477, "phrase": "training_samples"}, {"score": 0.0034482025128821548, "phrase": "nge"}, {"score": 0.0031845067058084583, "phrase": "conventional_approaches"}, {"score": 0.003150900886669123, "phrase": "out-of-sample_extension"}, {"score": 0.0030684249587688826, "phrase": "high_computational_cost"}, {"score": 0.0030039966201398966, "phrase": "basic_nonnegative_assumption"}, {"score": 0.0029098743621130004, "phrase": "pnge"}, {"score": 0.002863921785266393, "phrase": "unified_solution"}, {"score": 0.002833689453299307, "phrase": "out-of-sample_extension_problem"}, {"score": 0.002561892963059385, "phrase": "universal_nonnegative_transformation_matrix"}, {"score": 0.0025214217930287003, "phrase": "convergency_provable_multiplicative_nonnegative_updating_rule"}, {"score": 0.002429451930463481, "phrase": "basis_matrix"}, {"score": 0.0024037949232582462, "phrase": "transformation_matrix"}, {"score": 0.002378408229095287, "phrase": "extensive_experiments"}, {"score": 0.002231607958228148, "phrase": "nonnegative_data"}, {"score": 0.0021847119298612264, "phrase": "algorithmic_properties"}, {"score": 0.0021049977753042253, "phrase": "classification_power"}], "paper_keywords": ["Face recognition", " graph embedding", " nonnegative matrix factorization", " out-of-sample"], "paper_abstract": "We present in this paper a general formulation for nonnegative data factorization, called projective nonnegative graph embedding (PNGE), which 1) explicitly decomposes the data into two nonnegative components favoring the characteristics encoded by the so-called intrinsic and penalty graphs [31], respectively, and 2) explicitly describes how to transform each new testing sample into its low-dimensional nonnegative representation. In the past, such a nonnegative decomposition was often obtained for the training samples only, e. g., nonnegative matrix factorization (NMF) and its variants, nonnegative graph embedding (NGE) and its refined version multiplicative nonnegative graph embedding (MNGE). Those conventional approaches for out-of-sample extension either suffer from the high computational cost or violate the basic nonnegative assumption. In this work, PNGE offers a unified solution to out-of-sample extension problem, and the nonnegative coefficient vector of each datum is assumed to be projected from its original feature representation with a universal nonnegative transformation matrix. A convergency provable multiplicative nonnegative updating rule is then derived to learn the basis matrix and transformation matrix. Extensive experiments compared with the state-of-the-art algorithms on nonnegative data factorization demonstrate the algorithmic properties in convergency, sparsity, and classification power.", "paper_title": "Projective Nonnegative Graph Embedding", "paper_id": "WOS:000276815900002"}