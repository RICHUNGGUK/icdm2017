{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "degraded_reads"}, {"score": 0.013672452192245946, "phrase": "erasure_coding"}, {"score": 0.01206191993286103, "phrase": "temporarily_unavailable_data"}, {"score": 0.004768378525561471, "phrase": "heterogeneous_erasure-coded_storage_systems"}, {"score": 0.004631335513513859, "phrase": "large-scale_data_storage_services"}, {"score": 0.004476399615305783, "phrase": "frequent_node_failures"}, {"score": 0.004390192910013225, "phrase": "data_availability"}, {"score": 0.004326624385772596, "phrase": "storage_system"}, {"score": 0.004263972370406983, "phrase": "data_redundancy"}, {"score": 0.004081385289516914, "phrase": "significantly_less_redundancy_overhead"}, {"score": 0.003831310632470526, "phrase": "large-scale_storage_systems"}, {"score": 0.003775803846431323, "phrase": "erasure-coded_storage_systems"}, {"score": 0.003359647377874098, "phrase": "storage_nodes"}, {"score": 0.0032629585038738856, "phrase": "different_storage_capacities"}, {"score": 0.003018468582368033, "phrase": "node_heterogeneity"}, {"score": 0.0027922467043592597, "phrase": "fastdr"}, {"score": 0.002751751956416832, "phrase": "greedy_algorithm"}, {"score": 0.002672511078070529, "phrase": "data_transfer_cost"}, {"score": 0.0026337482179592422, "phrase": "surviving_data"}, {"score": 0.0025085435314540837, "phrase": "efficient_degraded_read_solution"}, {"score": 0.002436289099444074, "phrase": "timely_manner"}, {"score": 0.0023776656246300063, "phrase": "fastdr_prototype"}, {"score": 0.002331781764406665, "phrase": "extensive_evaluation"}, {"score": 0.0023091721866305426, "phrase": "simulation_studies"}, {"score": 0.002264607102799332, "phrase": "testbed_experiments"}, {"score": 0.002231747358665628, "phrase": "hadoop_cluster"}, {"score": 0.002135995282374723, "phrase": "efficient_degraded_reads"}, {"score": 0.0021049977753042253, "phrase": "existing_approaches"}], "paper_keywords": ["Erasure-coded storage system", " degraded reads", " node heterogeneity", " I/O parallelism"], "paper_abstract": "Distributed storage systems provide large-scale data storage services, yet they are confronted with frequent node failures. To ensure data availability, a storage system often introduces data redundancy via replication or erasure coding. As erasure coding incurs significantly less redundancy overhead than replication under the same fault tolerance, it has been increasingly adopted in large-scale storage systems. In erasure-coded storage systems, degraded reads to temporarily unavailable data are very common, and hence boosting the performance of degraded reads becomes important. One challenge is that storage nodes tend to be heterogeneous with different storage capacities and I/O bandwidths. To this end, we propose FastDR, a system that addresses node heterogeneity and exploits I/O parallelism, so as to boost the performance of degraded reads to temporarily unavailable data. FastDR incorporates a greedy algorithm that seeks to reduce the data transfer cost of reading surviving data for degraded reads, while allowing the search of the efficient degraded read solution to be completed in a timely manner. We implement a FastDR prototype, and conduct extensive evaluation through simulation studies as well as testbed experiments on a Hadoop cluster with 10 storage nodes. We demonstrate that our FastDR achieves efficient degraded reads compared to existing approaches.", "paper_title": "Boosting Degraded Reads in Heterogeneous Erasure-Coded Storage Systems", "paper_id": "WOS:000357929500004"}