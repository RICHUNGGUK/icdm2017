{"auto_keywords": [{"score": 0.05007712399672982, "phrase": "long_short-term_memory"}, {"score": 0.034455640193715116, "phrase": "lstm"}, {"score": 0.004392565073466714, "phrase": "acoustic_modeling"}, {"score": 0.004121960535174029, "phrase": "in-domain_language_model"}, {"score": 0.004035500442527029, "phrase": "adequate_context_modeling"}, {"score": 0.0038953958723049287, "phrase": "word_spotting"}, {"score": 0.0034543031591181546, "phrase": "decoding_process"}, {"score": 0.003334309053314909, "phrase": "novel_technique"}, {"score": 0.0031732652552570644, "phrase": "connectionist_temporal_classification"}, {"score": 0.0029775511937434797, "phrase": "self-learned_amount"}, {"score": 0.002853808773854451, "phrase": "considered_approaches"}, {"score": 0.0027741761880779535, "phrase": "read_speech"}, {"score": 0.002677744558540711, "phrase": "timit_corpus"}, {"score": 0.0025664295665392203, "phrase": "semaine_database"}, {"score": 0.0024947959375982614, "phrase": "spontaneous_and_emotionally_colored_speech"}, {"score": 0.00229164285862567, "phrase": "keyword_spotting"}, {"score": 0.0022276618873985445, "phrase": "chime_task"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Keyword spotting", " Long Short-Term Memory", " Recurrent neural networks", " Dynamic Bayesian Networks"], "paper_abstract": "We investigate various techniques for keyword spotting which are exclusively based on acoustic modeling and do not presume the existence of an in-domain language model. Since adequate context modeling is nevertheless necessary for word spotting, we show how the principle of Long Short-Term Memory (LSTM) can be incorporated into the decoding process. We propose a novel technique that exploits LSTM in combination with Connectionist Temporal Classification in order to improve performance by using a self-learned amount of contextual information. All considered approaches are evaluated on read speech as contained in the TIMIT corpus as well as on the SEMAINE database which consists of spontaneous and emotionally colored speech. As further evidence for the effectiveness of LSTM modeling for keyword spotting, results on the CHiME task are shown. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Keyword spotting exploiting Long Short-Term Memory", "paper_id": "WOS:000312511900004"}