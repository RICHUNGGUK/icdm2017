{"auto_keywords": [{"score": 0.049707293588616405, "phrase": "discriminating_power"}, {"score": 0.00481495049065317, "phrase": "environment_difficulty"}, {"score": 0.004506265705673849, "phrase": "task_instance"}, {"score": 0.003900853871728297, "phrase": "state_space"}, {"score": 0.0036221822903900725, "phrase": "agent_policies"}, {"score": 0.0034162643819889054, "phrase": "policy_complexity"}, {"score": 0.003298357357267836, "phrase": "algorithmic_complexity"}, {"score": 0.0031229578623834394, "phrase": "environment_response_curve"}, {"score": 0.0029800360974218836, "phrase": "ability_scale"}, {"score": 0.002810520668490478, "phrase": "agent-populated_elementary_cellular_automata"}, {"score": 0.002206045784326466, "phrase": "agent_performance"}, {"score": 0.002146527342660575, "phrase": "adaptive_tests"}, {"score": 0.0021049977753042253, "phrase": "agent_abilities"}], "paper_keywords": ["Environment difficulty", " Agent evaluation", " Discriminating power", " Agent policy", " Algorithmic information theory", " Universal psychometrics", " Reinforcement learning", " Elementary cellular automata"], "paper_abstract": "This paper presents a way to estimate the difficulty and discriminating power of any task instance. We focus on a very general setting for tasks: interactive (possibly multi-agent) environments where an agent acts upon observations and rewards. Instead of analysing the complexity of the environment, the state space or the actions that are performed by the agent, we analyse the performance of a population of agent policies against the task, leading to a distribution that is examined in terms of policy complexity. This distribution is then sliced by the algorithmic complexity of the policy and analysed through several diagrams and indicators. The notion of environment response curve is also introduced, by inverting the performance results into an ability scale. We apply all these concepts, diagrams and indicators to two illustrative problems: a class of agent-populated elementary cellular automata, showing how the difficulty and discriminating power may vary for several environments, and a multi-agent system, where agents can become predators or preys, and may need to coordinate. Finally, we discuss how these tools can be applied to characterise (interactive) tasks and (multi-agent) environments. These characterisations can then be used to get more insight about agent performance and to facilitate the development of adaptive tests for the evaluation of agent abilities.", "paper_title": "On environment difficulty and discriminating power", "paper_id": "WOS:000352641600003"}