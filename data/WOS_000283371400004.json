{"auto_keywords": [{"score": 0.02671093232151911, "phrase": "dm."}, {"score": 0.00481495049065317, "phrase": "preference-based_multiobjective_evolutionary_algorithm"}, {"score": 0.0046256566852302256, "phrase": "decision_maker"}, {"score": 0.0037847308929559163, "phrase": "smaller_territories"}, {"score": 0.003694652993546994, "phrase": "preferred_solutions"}, {"score": 0.003549245218355768, "phrase": "denser_coverage"}, {"score": 0.0029982770062678926, "phrase": "representative_solutions"}, {"score": 0.0027667539384678814, "phrase": "selected_solution"}, {"score": 0.0025736694380861604, "phrase": "final_preferred_region"}, {"score": 0.0022812715029149216, "phrase": "dm's_responses"}, {"score": 0.0021049977753042253, "phrase": "dm's_simulated_preferred_regions"}], "paper_keywords": ["Evolutionary algorithms", " guidance", " interactive", " multiobjective optimization", " preference incorporation"], "paper_abstract": "We develop a preference-based multiobjective evolutionary algorithm that interacts with the decision maker (DM) during the course of optimization. We create a territory around each solution where no other solutions are allowed. We define smaller territories around the preferred solutions in order to obtain denser coverage of these regions. At each interaction, the algorithm asks the DM to choose his/her best solution among a set of representative solutions to guide the search toward the neighborhood of the selected solution. The algorithm aims to converge to a final preferred region of the DM. We test the algorithm on three problems using three different utility function types to simulate the DM's responses. The results show that the algorithm converges the DM's simulated preferred regions well.", "paper_title": "An Interactive Territory Defining Evolutionary Algorithm: iTDEA", "paper_id": "WOS:000283371400004"}