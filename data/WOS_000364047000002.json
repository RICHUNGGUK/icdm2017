{"auto_keywords": [{"score": 0.032668893300942095, "phrase": "ncut"}, {"score": 0.004859451923008556, "phrase": "cssd"}, {"score": 0.00481495049065317, "phrase": "adaptive_multi-level_region_merging"}, {"score": 0.004773692073488661, "phrase": "existing_salient_object_detection_models"}, {"score": 0.004712463245074863, "phrase": "-segmented_regions"}, {"score": 0.004342430078306461, "phrase": "entire_salient_objects"}, {"score": 0.004213519983188574, "phrase": "existing_methods"}, {"score": 0.004106063237069123, "phrase": "entire_object"}, {"score": 0.0040708542958968605, "phrase": "complex_background"}, {"score": 0.0040186038781533946, "phrase": "better_grouping"}, {"score": 0.003592859432554987, "phrase": "saliency_detection"}, {"score": 0.003531474887552889, "phrase": "ncut_partitions"}, {"score": 0.0034562118159899772, "phrase": "normalized_energy_minimization_fashion"}, {"score": 0.0033391018638565715, "phrase": "good_cluster_information"}, {"score": 0.0032820385246266773, "phrase": "visual_contents"}, {"score": 0.003157174936641705, "phrase": "saliency_maps"}, {"score": 0.003037047249598515, "phrase": "accurate_saliency_estimation"}, {"score": 0.0030109772626153797, "phrase": "visual_clusters"}, {"score": 0.0028591768694918, "phrase": "moderate_number"}, {"score": 0.002762240719058935, "phrase": "intrinsic_color"}, {"score": 0.002703327151461985, "phrase": "image_data"}, {"score": 0.0026116610153271943, "phrase": "adaptive_multi-level_region"}, {"score": 0.0025122373359090454, "phrase": "ncut_eigenvectors"}, {"score": 0.0024799423362011582, "phrase": "developed_saliency_measures"}, {"score": 0.002448061472257196, "phrase": "merged_region"}, {"score": 0.002375253757224999, "phrase": "across-level_integration"}, {"score": 0.0021695394558562927, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "uniform_object_enhancement"}], "paper_keywords": ["Salient object detection", " normalized cut", " clustering", " region merging", " saliency map"], "paper_abstract": "Existing salient object detection models favor over-segmented regions upon which saliency is computed. Such local regions are less effective on representing object holistically and degrade emphasis of entire salient objects. As a result, the existing methods often fail to highlight an entire object in complex background. Toward better grouping of objects and background, in this paper, we consider graph cut, more specifically, the normalized graph cut (Ncut) for saliency detection. Since the Ncut partitions a graph in a normalized energy minimization fashion, resulting eigenvectors of the Ncut contain good cluster information that may group visual contents. Motivated by this, we directly induce saliency maps via eigenvectors of the Ncut, contributing to accurate saliency estimation of visual clusters. We implement the Ncut on a graph derived from a moderate number of superpixels. This graph captures both intrinsic color and edge information of image data. Starting from the superpixels, an adaptive multi-level region merging scheme is employed to seek such cluster information from Ncut eigenvectors. With developed saliency measures for each merged region, encouraging performance is obtained after across-level integration. Experiments by comparing with 13 existing methods on four benchmark datasets, including MSRA-1000, SOD, SED, and CSSD show the proposed method, Ncut saliency, results in uniform object enhancement and achieves comparable/better performance to the state-of-the-art methods.", "paper_title": "Normalized Cut-Based Saliency Detection by Adaptive Multi-Level Region Merging", "paper_id": "WOS:000364047000002"}