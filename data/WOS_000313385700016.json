{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multiple_kernel_learning"}, {"score": 0.02814111202666654, "phrase": "lmkl"}, {"score": 0.004638788604042707, "phrase": "single_kernel"}, {"score": 0.00452495123987801, "phrase": "mkl"}, {"score": 0.004413846562278824, "phrase": "weighted_sum"}, {"score": 0.003825849505589868, "phrase": "whole_input_space"}, {"score": 0.0037087324991876727, "phrase": "localized_multiple_kernel_learning"}, {"score": 0.003506851152129303, "phrase": "kernel-based_learning_algorithm"}, {"score": 0.0034420211080526094, "phrase": "parametric_gating_model"}, {"score": 0.003378385493203297, "phrase": "local_weights"}, {"score": 0.003336614511719501, "phrase": "kernel_functions"}, {"score": 0.0031746155143471725, "phrase": "coupled_manner"}, {"score": 0.0031159081999910694, "phrase": "two-step_alternating_optimization_algorithm"}, {"score": 0.0030204580407008214, "phrase": "benchmark_classification_and_regression_data_sets"}, {"score": 0.002803104254950008, "phrase": "higher_accuracy"}, {"score": 0.0027512482368183596, "phrase": "canonical_mkl"}, {"score": 0.0027172101552870973, "phrase": "classification_problems"}, {"score": 0.0026835920552084488, "phrase": "different_feature_representations"}, {"score": 0.0025691622090542304, "phrase": "relevant_parts"}, {"score": 0.0024904187737391807, "phrase": "gating_model"}, {"score": 0.002444333100610621, "phrase": "saliency_detector"}, {"score": 0.002414082940963702, "phrase": "image_recognition_problems"}, {"score": 0.0023694065215394593, "phrase": "regression_tasks"}, {"score": 0.002226357953581725, "phrase": "model_complexity"}, {"score": 0.0021851480717840484, "phrase": "significantly_fewer_support_vectors"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Multiple kernel learning", " Support vector machines", " Support vector regression", " Classification", " Regression", " Selective attention"], "paper_abstract": "Instead of selecting a single kernel, multiple kernel learning (MKL) uses a weighted sum of kernels where the weight of each kernel is optimized during training. Such methods assign the same weight to a kernel over the whole input space, and we discuss localized multiple kernel learning (LMKL) that is composed of a kernel-based learning algorithm and a parametric gating model to assign local weights to kernel functions. These two components are trained in a coupled manner using a two-step alternating optimization algorithm. Empirical results on benchmark classification and regression data sets validate the applicability of our approach. We see that LMKL achieves higher accuracy compared with canonical MKL on classification problems with different feature representations. LMKL can also identify the relevant parts of images using the gating model as a saliency detector in image recognition problems. In regression tasks, LMKL improves the performance significantly or reduces the model complexity by storing significantly fewer support vectors. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Localized algorithms for multiple kernel learning", "paper_id": "WOS:000313385700016"}