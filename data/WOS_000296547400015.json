{"auto_keywords": [{"score": 0.0464761395392292, "phrase": "large_margin"}, {"score": 0.04231925323252083, "phrase": "lmnmf"}, {"score": 0.02917248875176984, "phrase": "plsr"}, {"score": 0.00481495049065317, "phrase": "face_recognition"}, {"score": 0.0045411156682300695, "phrase": "new_method"}, {"score": 0.004145649381700967, "phrase": "latent_discriminant_information"}, {"score": 0.004092026656771699, "phrase": "training_data"}, {"score": 0.003960972732123083, "phrase": "nonnegative_sub-space"}, {"score": 0.003859146369720225, "phrase": "nearest_neighbors"}, {"score": 0.0035923719610602245, "phrase": "different_classes"}, {"score": 0.0033222630615013737, "phrase": "local_separation_structure"}, {"score": 0.0031741489723036255, "phrase": "large-margin_criterion"}, {"score": 0.0030924870122337905, "phrase": "new_objective_function"}, {"score": 0.003012919635505122, "phrase": "convergency_provable_multiplicative_nonnegative_updating_rule"}, {"score": 0.0028973794653974327, "phrase": "basis_matrix"}, {"score": 0.002859856368059419, "phrase": "encoding_vectors"}, {"score": 0.0027862576750944277, "phrase": "partial_least_squares_regression"}, {"score": 0.0026274936167233515, "phrase": "original_data"}, {"score": 0.0025934566395017424, "phrase": "low_dimensional_representations"}, {"score": 0.0025102759256260703, "phrase": "local_separation_information"}, {"score": 0.0024297565926197505, "phrase": "unified_solution"}, {"score": 0.002398274973378986, "phrase": "out-of-sample_extension_problem"}, {"score": 0.0022468671200629024, "phrase": "significant_improvements"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Face recognition", " Nonnegative matrix factorization", " Out-of-sample", " Feature extraction", " Large margin learning"], "paper_abstract": "In this paper, we present a new method, called large margin based nonnegative matrix factorization (LMNMF), to encode latent discriminant information in training data. LMNMF seeks a nonnegative sub-space such that k nearest neighbors of each sample always belong to same class and samples from different classes are separated by a large margin. In the subspace, the local separation structure of data is explicit. The large-margin criterion leads to a new objective function, and a convergency provable multiplicative nonnegative updating rule is derived to learn the basis matrix and encoding vectors. Then, partial least squares regression (PLSR) learns the mapping from the original data to low dimensional representations in order to capture local separation information. PLSR offers a unified solution to out-of-sample extension problem. Extensive experimental results demonstrate LMNMF with PLSR leads significant improvements on classification than several other commonly used NMF-based algorithms. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Large margin based nonnegative matrix factorization and partial least squares regression for face recognition", "paper_id": "WOS:000296547400015"}