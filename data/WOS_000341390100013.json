{"auto_keywords": [{"score": 0.049715817986079144, "phrase": "coprocessor-dominated_architectures"}, {"score": 0.00481495049065317, "phrase": "energy_scalability"}, {"score": 0.004670504053818028, "phrase": "chip_designers"}, {"score": 0.004582423717777699, "phrase": "increasingly_dark_silicon"}, {"score": 0.004513151518938864, "phrase": "increased_interest"}, {"score": 0.004461882369408972, "phrase": "energy-efficient_specialized_coprocessors"}, {"score": 0.004428025469002531, "phrase": "general-purpose_designs"}, {"score": 0.004311527998148399, "phrase": "viable_means"}, {"score": 0.004262539473250432, "phrase": "dark_silicon"}, {"score": 0.0041821205529541045, "phrase": "energy_savings"}, {"score": 0.003934795713147731, "phrase": "large_numbers"}, {"score": 0.0039049226745413224, "phrase": "recent_work"}, {"score": 0.0038166522763373434, "phrase": "application-specific_coprocessors"}, {"score": 0.0037589124802364384, "phrase": "energy_efficiency"}, {"score": 0.00364603066037512, "phrase": "current_techniques"}, {"score": 0.003276893480994257, "phrase": "energy_cost"}, {"score": 0.0032150101448578734, "phrase": "memory_system"}, {"score": 0.0029675701595142656, "phrase": "energy_gains"}, {"score": 0.0028565082986974602, "phrase": "detailed_study"}, {"score": 0.0028347983387988847, "phrase": "energy_costs"}, {"score": 0.0028025415122856973, "phrase": "wide_range"}, {"score": 0.0027812405653371503, "phrase": "tiled_coda_designs"}, {"score": 0.002739121808942775, "phrase": "careful_choice"}, {"score": 0.002718301574682098, "phrase": "cache_configuration"}, {"score": 0.0026976391682197133, "phrase": "tile_size"}, {"score": 0.0026771333996253783, "phrase": "coarse-grain_power_management"}, {"score": 0.002547583216040341, "phrase": "multithreaded_workloads"}, {"score": 0.0024615764782448214, "phrase": "excessive_contention"}, {"score": 0.002387560868354908, "phrase": "energy_consumption"}, {"score": 0.0022894012453842064, "phrase": "larger_workloads"}, {"score": 0.002263336340041527, "phrase": "shared_overheads"}, {"score": 0.0021049977753042253, "phrase": "smaller_designs"}], "paper_keywords": ["Design", " Performance", " CoDA", " coprocessor", " conservation core", " dark silicon", " energy efficiency", " scalable specialization"], "paper_abstract": "As chip designers face the prospect of increasingly dark silicon, there is increased interest in incorporating energy-efficient specialized coprocessors into general-purpose designs. For specialization to be a viable means of leveraging dark silicon, it must provide energy savings over the majority of execution for large, diverse workloads, and this will require deploying coprocessors in large numbers. Recent work has shown that automatically generated application-specific coprocessors can greatly improve energy efficiency, but it is not clear that current techniques will scale to Coprocessor-Dominated Architectures (CoDAs) with hundreds or thousands of coprocessors. We show that scaling CoDAs to include very large numbers of coprocessors is challenging because of the energy cost of interconnects, the memory system, and leakage. These overheads grow with the number of coprocessors and, left unchecked, will squander the energy gains that coprocessors can provide. The article presents a detailed study of energy costs across a wide range of tiled CoDA designs and shows that careful choice of cache configuration, tile size, coarse-grain power management and transistor implementation can limit the growth of these overheads. For multithreaded workloads, designer must also take care to avoid excessive contention for coprocessors, which can significantly increase energy consumption. The results suggest that, for CoDAs that target larger workloads, amortizing shared overheads via multithreading can provide up to 3.8x reductions in energy per instruction, retaining much of the 5.3x potential of smaller designs.", "paper_title": "Exploring Energy Scalability in Coprocessor-Dominated Architectures for Dark Silicon", "paper_id": "WOS:000341390100013"}