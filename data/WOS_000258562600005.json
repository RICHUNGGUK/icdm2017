{"auto_keywords": [{"score": 0.048929739366992464, "phrase": "human_skills"}, {"score": 0.008024937715042302, "phrase": "lhmm"}, {"score": 0.00481495049065317, "phrase": "assisted_applications"}, {"score": 0.0046184900568047565, "phrase": "key_research_areas"}, {"score": 0.004384098916012568, "phrase": "general_mathematical_model"}, {"score": 0.004263972370406983, "phrase": "common_approaches"}, {"score": 0.004061584718427419, "phrase": "low-level_subsystems"}, {"score": 0.003991646181215783, "phrase": "manageable_modelling"}, {"score": 0.0038419751490849133, "phrase": "layered_hidden_markov_model"}, {"score": 0.003697895355947004, "phrase": "gesteme_classifier"}, {"score": 0.0036341965226247028, "phrase": "basic_action-primitives"}, {"score": 0.003559199464487982, "phrase": "gesteme_classifiers"}, {"score": 0.0034376160364306637, "phrase": "teleoperated_task"}, {"score": 0.003401954670986958, "phrase": "proposed_methodology"}, {"score": 0.0033433365160336842, "phrase": "gesteme_level"}, {"score": 0.003285774181046916, "phrase": "hmm"}, {"score": 0.0031734538599865973, "phrase": "fourier_transform"}, {"score": 0.003140524241432171, "phrase": "online_and_off-line_classification_performance"}, {"score": 0.0029193609786176632, "phrase": "training_samples"}, {"score": 0.0027903049766389433, "phrase": "observation_symbols"}, {"score": 0.002648448458159033, "phrase": "trajectory_tracking_task"}, {"score": 0.002584733102974067, "phrase": "mobile_manipulator"}, {"score": 0.002540160379502092, "phrase": "qualitative_as_well_as_quantitative_results"}, {"score": 0.0024026156525362684, "phrase": "teleoperative_trajectory-tracking_tasks"}, {"score": 0.0023529740798601015, "phrase": "classification_performance"}, {"score": 0.002320449502337321, "phrase": "multidimensional_hmms"}, {"score": 0.0023043558058824572, "phrase": "gesteme_classification"}, {"score": 0.002149418970824546, "phrase": "underlying_gesteme_classifiers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Layered Hidden Markov Models", " human-machine collaboration", " motion intention recognition"], "paper_abstract": "Acquiring, representing and modelling human skills is one of the key research areas in teleoperation, programming-by-demonstration and human-machine collaborative settings. The problems are challenging mainly because of the lack of a general mathematical model to describe human skills. One of the common approaches is to divide the task that the operator is executing into several subtasks or low-level subsystems in order to provide manageable modelling. In this paper we consider the use of a Layered Hidden Markov Model (LHMM) to model human skills. We evaluate a gesteme classifier that classifies motions into basic action-primitives, or gestemes. The gesteme classifiers are then used in a LHMM to model a teleoperated task. The proposed methodology uses three different HMM models at the gesteme level: one-dimensional HMM, multi-dimensional HMM and multidimensional HMM with Fourier transform. The online and off-line classification performance of these three models is evaluated with respect to the number of gestemes, the influence of the number of training samples, the effect of noise and the effect of the number of observation symbols. We also apply the LHMM to data recorded during the execution of a trajectory tracking task in 2D and 3D with a mobile manipulator in order to provide qualitative as well as quantitative results for the proposed approach. The results indicate that the LHMM is suitable for modelling teleoperative trajectory-tracking tasks and that the difference in classification performance between one and multidimensional HMMs for gesteme classification is small. It can also be seen that the LHMM is robust with respect to misclassifications in the underlying gesteme classifiers. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Motion intention recognition in robot assisted applications", "paper_id": "WOS:000258562600005"}