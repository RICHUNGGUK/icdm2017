{"auto_keywords": [{"score": 0.04955111375780366, "phrase": "action_recognition"}, {"score": 0.04624924834040988, "phrase": "modified_sparse_model"}, {"score": 0.03283343504321645, "phrase": "dictionary_incoherence_term"}, {"score": 0.00481495049065317, "phrase": "sparse_modeling"}, {"score": 0.004530023871441992, "phrase": "new_supervised_classification_method"}, {"score": 0.004309434349688514, "phrase": "main_contributions"}, {"score": 0.004145287175409325, "phrase": "novel_hierarchical_descriptor"}, {"score": 0.004054299982508618, "phrase": "action_representation"}, {"score": 0.00396530196547293, "phrase": "spatial_information"}, {"score": 0.00392153537973826, "phrase": "neighboring_interest_points"}, {"score": 0.0038567860860362745, "phrase": "compound_motion"}, {"score": 0.003814212645832246, "phrase": "appearance_feature"}, {"score": 0.00370981613076245, "phrase": "interest_point"}, {"score": 0.003668859054928118, "phrase": "low_level"}, {"score": 0.0035684266744407485, "phrase": "high_level"}, {"score": 0.003509487090932835, "phrase": "continuous_motion_segment_descriptor"}, {"score": 0.0034134024569847264, "phrase": "temporal_ordering_information"}, {"score": 0.003158088307044493, "phrase": "constrained_term"}, {"score": 0.002921815042028607, "phrase": "similar_samples"}, {"score": 0.0027486060614330043, "phrase": "different_classes"}, {"score": 0.0025008468316682036, "phrase": "pure_reconstruction"}, {"score": 0.002418829014435841, "phrase": "sparse_model"}, {"score": 0.0023525345110929326, "phrase": "specific_dictionary"}, {"score": 0.0023136311468961125, "phrase": "action_class"}, {"score": 0.0022502133699402018, "phrase": "classification_loss_function"}, {"score": 0.0021763973978248005, "phrase": "class-specific_dictionaries"}, {"score": 0.0021049977753042253, "phrase": "proposed_framework"}], "paper_keywords": ["Compound feature", " Motion segment", " Sparse model", " Supervised dictionary learning", " Action recognition"], "paper_abstract": "In this paper, we propose a new supervised classification method based on a modified sparse model for action recognition. The main contributions are three-fold. First, a novel hierarchical descriptor is presented for action representation. To capture spatial information about neighboring interest points, a compound motion and appearance feature is proposed for the interest point at low level. Furthermore, at high level, a continuous motion segment descriptor is presented to combine temporal ordering information of motion. Second, we propose a modified sparse model which incorporates the similarity constrained term and the dictionary incoherence term for classification. Our sparse model not only captures the correlations between similar samples by sharing dictionary, but also encourages dictionaries associated with different classes to be independent by the dictionary incoherence term. The proposed sparse model targets classification, rather than pure reconstruction. Third, in the sparse model, we adopt a specific dictionary for each action class. Moreover, a classification loss function is proposed to optimize the class-specific dictionaries. Experiments validate that the proposed framework obtains the performance comparable to the state-of-the-art. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Supervised class-specific dictionary learning for sparse modeling in action recognition", "paper_id": "WOS:000306584200005"}