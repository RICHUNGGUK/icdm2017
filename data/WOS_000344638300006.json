{"auto_keywords": [{"score": 0.04295798374264587, "phrase": "log_likelihood"}, {"score": 0.00481495049065317, "phrase": "natural_image_patch"}, {"score": 0.004692227830462433, "phrase": "image_compression"}, {"score": 0.004644014990871423, "phrase": "recent_results"}, {"score": 0.004549063619065006, "phrase": "gaussian_mixture_models"}, {"score": 0.004297795905522757, "phrase": "natural_image_patches"}, {"score": 0.004060350364088702, "phrase": "real-valued_data"}, {"score": 0.003936389070602614, "phrase": "best_performing_techniques"}, {"score": 0.003757480190200645, "phrase": "deep_belief_networks"}, {"score": 0.0035497797026638033, "phrase": "image_denoising"}, {"score": 0.003301899275278983, "phrase": "sparse_coding"}, {"score": 0.0029013950320185573, "phrase": "student-t_mixture_model"}, {"score": 0.0025230952890994236, "phrase": "image_patch_modeling"}, {"score": 0.0024335778618734785, "phrase": "stm"}, {"score": 0.0023467391904246834, "phrase": "lossless_image_compression"}, {"score": 0.002298649369775623, "phrase": "efficient_coding_schemes"}, {"score": 0.002126907587540404, "phrase": "suggested_techniques"}, {"score": 0.002105011882358329, "phrase": "jpeg"}], "paper_keywords": ["image compression", " mixture models", " GMM", " density modeling", " unsupervised learning"], "paper_abstract": "Recent results have shown that Gaussian mixture models (GMMs) are remarkably good at density modeling of natural image patches, especially given their simplicity. In terms of log likelihood on real-valued data they are comparable with the best performing techniques published, easily outperforming more advanced ones, such as deep belief networks. They can be applied to various image processing tasks, such as image denoising, deblurring and inpainting, where they improve on other generic prior methods, such as sparse coding and field of experts. Based on this we propose the use of another, even richer mixture model based image prior: the Student-t mixture model (STM). We demonstrate that it convincingly surpasses GMMs in terms of log likelihood, achieving performance competitive with the state of the art in image patch modeling. We apply both the GMM and STM to the task of lossy and lossless image compression, and propose efficient coding schemes that can easily be extended to other unsupervised machine learning models. Finally, we show that the suggested techniques outperform JPEG, with results comparable to or better than JPEG 2000.", "paper_title": "The Student-t Mixture as a Natural Image Patch Prior with Application to Image Compression", "paper_id": "WOS:000344638300006"}