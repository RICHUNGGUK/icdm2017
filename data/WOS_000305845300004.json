{"auto_keywords": [{"score": 0.0444227308407221, "phrase": "human_actions"}, {"score": 0.00481495049065317, "phrase": "graph-embedded_spatio-temporal_subspace"}, {"score": 0.0046491050101721545, "phrase": "important_issue"}, {"score": 0.004579780586951551, "phrase": "pattern_recognition_field"}, {"score": 0.004444203710097837, "phrase": "remote_surveillance"}, {"score": 0.004334280585565239, "phrase": "commercial_video_content"}, {"score": 0.004164007198843467, "phrase": "non-linear_dynamics"}, {"score": 0.0038431888954930083, "phrase": "silhouette-based_human_action_recognition_system"}, {"score": 0.003766908559075843, "phrase": "three-step_procedure"}, {"score": 0.0036553070575015344, "phrase": "efficient_discriminant_spatio-temporal_subspace"}, {"score": 0.0036188435232325337, "phrase": "k-nn_classification_purposes"}, {"score": 0.00354700018079049, "phrase": "first_step"}, {"score": 0.0033905067962602515, "phrase": "low-dimensional_spatial_subspace"}, {"score": 0.00327356326590461, "phrase": "local_data_structure"}, {"score": 0.0030823667846259836, "phrase": "spatial_subspace"}, {"score": 0.002976019715894587, "phrase": "human_body_shape"}, {"score": 0.002946312377831317, "phrase": "different_action_classes"}, {"score": 0.0029169007179202164, "phrase": "temporal_data"}, {"score": 0.0027741761880779535, "phrase": "large_margin_nearest_neighbor"}, {"score": 0.0026516890043911836, "phrase": "efficient_spatio-temporal_subspace"}, {"score": 0.0025730425700096365, "phrase": "experimental_results"}, {"score": 0.0025219085140220773, "phrase": "proposed_system"}, {"score": 0.00242266141176955, "phrase": "real_time"}, {"score": 0.002315658491366464, "phrase": "robustness_test"}, {"score": 0.0022925278792429553, "phrase": "noisy_data"}, {"score": 0.0021693692831601745, "phrase": "input_images"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Human action recognition", " Adaptive locality preserving projection", " Large margin nearest neighbor"], "paper_abstract": "Human action recognition is an important issue in the pattern recognition field, with applications ranging from remote surveillance to the indexing of commercial video content. However, human actions are characterized by non-linear dynamics and are therefore not easily learned and recognized. Accordingly, this study proposes a silhouette-based human action recognition system in which a three-step procedure is used to construct an efficient discriminant spatio-temporal subspace for k-NN classification purposes. In the first step, an Adaptive Locality Preserving Projection (ALPP) method is proposed to obtain a low-dimensional spatial subspace in which the linearity in the local data structure is preserved. To resolve the problem of overlaps in the spatial subspace resulting from the ambiguity of the human body shape among different action classes, temporal data are extracted using a Non-base Central-Difference Action Vector (NCDAV) method. Finally, the Large Margin Nearest Neighbor (LMNN) metric learning method is applied to construct an efficient spatio-temporal subspace for classification purposes. The experimental results show that the proposed system accurately recognizes a variety of human actions in real time and outperforms most existing methods. In addition, a robustness test with noisy data indicates that our system is remarkably robust toward noise in the input images. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Human action recognition based on graph-embedded spatio-temporal subspace", "paper_id": "WOS:000305845300004"}