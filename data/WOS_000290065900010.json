{"auto_keywords": [{"score": 0.0496265667331732, "phrase": "robust_speech_recognition"}, {"score": 0.04395864843047525, "phrase": "fm_features"}, {"score": 0.043427068347763616, "phrase": "complemental_features"}, {"score": 0.04174150547126997, "phrase": "fm_patterns"}, {"score": 0.031875826771235016, "phrase": "conventional_am_system"}, {"score": 0.025997068589615587, "phrase": "multiconditional_training"}, {"score": 0.00481495049065317, "phrase": "temporal_am-fm"}, {"score": 0.004724365740062236, "phrase": "novel_method"}, {"score": 0.004694549334241098, "phrase": "feature_extraction"}, {"score": 0.004650175539595746, "phrase": "frequency_modulation"}, {"score": 0.004577145044601205, "phrase": "speech_signals"}, {"score": 0.004434491600123024, "phrase": "multistream_speech_recognizers"}, {"score": 0.004122964978180509, "phrase": "amplitude_modulation"}, {"score": 0.004007083686875716, "phrase": "effective_features"}, {"score": 0.003919201391494096, "phrase": "proposed_feature_extraction_method"}, {"score": 0.0038821277513157973, "phrase": "data-driven_modulation_analysis"}, {"score": 0.0037849637558311972, "phrase": "frequency_responses"}, {"score": 0.003749155155531426, "phrase": "temporal_filters"}, {"score": 0.0037019348293573675, "phrase": "proposed_method"}, {"score": 0.003344895435289136, "phrase": "noisy_speech_recognition_experiments"}, {"score": 0.0032508114149214407, "phrase": "noise_robustness"}, {"score": 0.0032302647179383915, "phrase": "speech_recognizers"}, {"score": 0.0030900173244612075, "phrase": "multistream_speech_recognition_experiments"}, {"score": 0.003060763239325022, "phrase": "experimental_results"}, {"score": 0.0029840952148215733, "phrase": "fm_system"}, {"score": 0.002965229277927781, "phrase": "word_error"}, {"score": 0.002881793492919646, "phrase": "baseline_mfcc_system"}, {"score": 0.0026875632003075804, "phrase": "speech_recognition_experiments"}, {"score": 0.0026705669656375197, "phrase": "artificial_noisy_environments"}, {"score": 0.002578985917923144, "phrase": "wide-band_noise"}, {"score": 0.0023899010501421186, "phrase": "proposed_combination_method"}, {"score": 0.0022933216359142736, "phrase": "proposed_fm_method"}, {"score": 0.0021728771392034462, "phrase": "independent_features"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Speech recognition", " Frequency modulation", " Multistream speech recognition", " HMM/MLP-tandem approach"], "paper_abstract": "A novel method for feature extraction from the frequency modulation (FM) in speech signals is proposed for robust speech recognition. To exploit of the multistream speech recognizers, each stream should compensate for the shortcomings of the other streams. In this light, FM features are promising as complemental features of amplitude modulation (AM). In order to extract effective features from FM patterns, we applied the proposed feature extraction method by the data-driven modulation analysis of instantaneous frequency. By evaluating the frequency responses of the temporal filters obtained by the proposed method, we confirmed that the modulation observed around 4 Hz is important for the discrimination of FM patterns, as in the case of AM features. We evaluated the robustness of our method by performing noisy speech recognition experiments. We confirmed that our FM features can improve the noise robustness of speech recognizers even when the FM features are not combined with conventional AM and/or spectral envelope features. We also performed multistream speech recognition experiments. The experimental results show that combination of the conventional AM system and proposed FM system reduced word error by 43.6% at 10 dB SNR as compared to the baseline MFCC system and by 20.2% as compared to the conventional AM system. We investigated the complementarity of the AM and FM features by performing speech recognition experiments in artificial noisy environments. We found the FM features to be robust to wide-band noise, which certainly degrades the performance of AM features. Further, we evaluated the efficiency of multiconditional training. Although the performance of the proposed combination method was degraded by multiconditional training, we confirmed that the performance of the proposed FM method improved. Through a series of experiments, we confirmed that our FM features can be used as independent features as well as complemental features. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Temporal AM-FM combination for robust speech recognition", "paper_id": "WOS:000290065900010"}