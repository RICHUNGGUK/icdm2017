{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "spatio-temporal_context"}, {"score": 0.004518442937844318, "phrase": "human_action_recognition"}, {"score": 0.004289419884432487, "phrase": "video_surveillance"}, {"score": 0.004240116703465252, "phrase": "video_retrieval"}, {"score": 0.004119313626110943, "phrase": "existing_local_interest_points"}, {"score": 0.00402514392911723, "phrase": "human_action_analysis"}, {"score": 0.003887894704361635, "phrase": "spatio-temporal_distribution"}, {"score": 0.0036482665232275583, "phrase": "defined_actions"}, {"score": 0.00344321906220063, "phrase": "feature_distribution"}, {"score": 0.0033644530302903513, "phrase": "spatio-temporal_domain"}, {"score": 0.003268516165008941, "phrase": "novel_projection_transform"}, {"score": 0.0031026497891826726, "phrase": "video_sequence"}, {"score": 0.003066945490483524, "phrase": "human_action"}, {"score": 0.002877769867854964, "phrase": "spatio-temporal_interest_points"}, {"score": 0.002608040688794517, "phrase": "visual_words"}, {"score": 0.002518989593177879, "phrase": "new_context-k-nearest-neighbor_classifier"}, {"score": 0.0024049552650867935, "phrase": "discriminative_feature_sets"}, {"score": 0.002377260665147444, "phrase": "action_matching"}, {"score": 0.0022048406330100697, "phrase": "novel_method"}, {"score": 0.0021049977753042253, "phrase": "weizmann_and_kth_datasets"}], "paper_keywords": ["Human action recognition", " Projection transform", " Spatio-temporal interest points", " Context", " Relation-weights", " Feature fusion"], "paper_abstract": "This paper discusses the task of human action recognition. This task is important to applications like video surveillance and video retrieval. Most of the existing local interest points based works on human action analysis, lost the information about spatio-temporal distribution of features and neglected the relationship between features and each defined actions. In this paper, through the analysis of feature distribution and their interactions over spatio-temporal domain, we propose a novel projection transform to take the two factors into account. A video sequence of human action in our perspective can be modeled by three types of features of spatio-temporal interest points: the global projection transform feature, the relative position distribution feature and the bag of visual words based feature. Then a new context-K-nearest-neighbor classifier is utilized to fuse them to form discriminative feature sets for action matching. In most of the case, our experiments have indicated that the novel method outperforms other previous published results on the Weizmann and KTH datasets.", "paper_title": "Projection transform on spatio-temporal context for action recognition", "paper_id": "WOS:000360377200014"}