{"auto_keywords": [{"score": 0.04748383477648566, "phrase": "interaction_partner"}, {"score": 0.03520414509610891, "phrase": "virtual_player"}, {"score": 0.027311811447342998, "phrase": "stroke_speed_variability"}, {"score": 0.015007343178059716, "phrase": "visual_information"}, {"score": 0.01086968743182166, "phrase": "task_performance"}, {"score": 0.010806570216037708, "phrase": "movement_kinematics"}, {"score": 0.009506198650405287, "phrase": "radial_error"}, {"score": 0.0047310525657970615, "phrase": "social_interaction"}, {"score": 0.004501160823792861, "phrase": "successful_interpersonal_action_coordination"}, {"score": 0.004332894955218135, "phrase": "interaction_partner's_behavior"}, {"score": 0.00395649432791084, "phrase": "action_understanding"}, {"score": 0.0038309141193444015, "phrase": "observed_actions"}, {"score": 0.003775152551576554, "phrase": "novel_immersive_virtual_environment"}, {"score": 0.003633927813203731, "phrase": "table_tennis_strokes"}, {"score": 0.003591542373891629, "phrase": "table_tennis_balls"}, {"score": 0.0035496495489801667, "phrase": "virtual_table_tennis_player"}, {"score": 0.0032315723330399375, "phrase": "minimum_distance"}, {"score": 0.003002979517391432, "phrase": "paddle_speed"}, {"score": 0.0029854041893236714, "phrase": "repeatedly_executed_table_tennis_strokes"}, {"score": 0.002717750004930131, "phrase": "virtual_players"}, {"score": 0.002258745901862197, "phrase": "virtual_player's_body"}, {"score": 0.002206290313627494, "phrase": "stroke_response"}, {"score": 0.0021613897794439227, "phrase": "first_time"}, {"score": 0.002142426911242168, "phrase": "online_control"}, {"score": 0.002129877319760485, "phrase": "arm_movements"}, {"score": 0.0021049977753042253, "phrase": "visual_body_information"}], "paper_keywords": [""], "paper_abstract": "Theories of social interaction (i.e., common coding theory) suggest that visual information about the interaction partner is critical for successful interpersonal action coordination. Seeing the interaction partner allows an observer to understand and predict the interaction partner's behavior. However, it is unknown which of the many sources of visual information about an interaction partner (e.g., body, end effectors, and/or interaction objects) are used for action understanding and thus for the control of movements in response to observed actions. We used a novel immersive virtual environment to investigate this further. Specifically, we asked participants to perform table tennis strokes in response to table tennis balls stroked by a virtual table tennis player. We tested the effect of the visibility of the ball, the paddle, and the body of the virtual player on task performance and movement kinematics. Task performance was measured as the minimum distance between the center of the paddle and the center of the ball (radial error). Movement kinematics was measured as variability in the paddle speed of repeatedly executed table tennis strokes (stroke speed variability). We found that radial error was reduced when the ball was visible compared to invisible. However, seeing the body and/or the racket of the virtual players only reduced radial error when the ball was invisible. There was no influence of seeing the ball on stroke speed variability. However, we found that stroke speed variability was reduced when either the body or the paddle of the virtual player was visible. Importantly, the differences in stroke speed variability were largest in the moment when the virtual player hit the ball. This suggests that seeing the virtual player's body or paddle was important for preparing the stroke response. These results demonstrate for the first time that the online control of arm movements is coupled with visual body information about an opponent.", "paper_title": "The Influence of Visual Information on the Motor Control of Table Tennis Strokes", "paper_id": "WOS:000309029000004"}