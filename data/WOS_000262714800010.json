{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "novel_video"}, {"score": 0.004606479650820579, "phrase": "video_summarization_techniques"}, {"score": 0.004456044928556639, "phrase": "comprehensive_understanding"}, {"score": 0.004406994912939125, "phrase": "whole_story"}, {"score": 0.004278807087784626, "phrase": "existing_approaches"}, {"score": 0.004123781267600542, "phrase": "static_storyboard"}, {"score": 0.0040334640350288, "phrase": "dynamic_skimming"}, {"score": 0.003930581102447622, "phrase": "traditional_methods"}, {"score": 0.0039016690475620185, "phrase": "brief_summaries"}, {"score": 0.0037463983616303786, "phrase": "concept-organized_and_systematic_view"}, {"score": 0.003623949225126944, "phrase": "structural_video_content_browsing_system"}, {"score": 0.003584025547693836, "phrase": "novel_summarization_method"}, {"score": 0.003304339421246321, "phrase": "video_contents"}, {"score": 0.0032199943889464873, "phrase": "above-mentioned_indexed_information"}, {"score": 0.002706659627293686, "phrase": "browsing_interface"}, {"score": 0.0026375303198093764, "phrase": "fundamental_system"}, {"score": 0.002598821419664902, "phrase": "maximum_entropy_criterion"}, {"score": 0.002570162055835289, "phrase": "visual_and_text_features"}, {"score": 0.002541817937194794, "phrase": "video_frames"}, {"score": 0.0025230952890994236, "phrase": "speech_transcripts"}, {"score": 0.002495268931035983, "phrase": "high-level_concept_entities"}, {"score": 0.0024677487011556427, "phrase": "novel_concept_expansion_method"}, {"score": 0.002343271162668978, "phrase": "relational_graph"}, {"score": 0.0023003498123420237, "phrase": "entropy_model"}, {"score": 0.0022749744354271816, "phrase": "meaningful_shots"}, {"score": 0.002120624523437494, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "information_coverage"}], "paper_keywords": ["Concept expansion tree", " graph entropy", " graph mining", " structural video contents", " video browsing", " video indexing", " video summarization"], "paper_abstract": "Video summarization techniques have been proposed for years to offer people comprehensive understanding of the whole story in the video. Roughly speaking, existing approaches can be classified into the two types: one is static storyboard, and the other is dynamic skimming. However, despite that these traditional methods give brief summaries for users, they still do not provide with a concept-organized and systematic view. In this paper, we present a structural video content browsing system and a novel summarization method by utilizing the four kinds of entities: who, what, where, and when to establish the framework of the video contents. With the assistance of the above-mentioned indexed information, the structure of the story can be built up according to the characters, the things, the places, and the time. Therefore, users can not only browse the video efficiently but also focus on what they are interested in via the browsing interface. In order to construct the fundamental system, we employ maximum entropy criterion to integrate visual and text features extracted from video frames and speech transcripts, generating high-level concept entities. A novel concept expansion method is introduced to explore the associations among these entities. After constructing the relational graph, we exploit graph entropy model to detect meaningful shots and relations, which serve as the indices for users. The results demonstrate that our system can achieve better performance and information coverage.", "paper_title": "A Novel Video Summarization Based on Mining the Story-Structure and Semantic Relations Among Concept Entities", "paper_id": "WOS:000262714800010"}