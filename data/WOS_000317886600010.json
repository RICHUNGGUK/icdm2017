{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "fast_frame-based_action_recognition"}, {"score": 0.004646852519870358, "phrase": "instant_action_recognition_method"}, {"score": 0.004176813329075736, "phrase": "computationally_efficient_but_perceptually_important_features_-_optical_flow"}, {"score": 0.0036229421570951807, "phrase": "video_quality"}, {"score": 0.0034963129868796033, "phrase": "strong_discriminative_power"}, {"score": 0.003434662174045939, "phrase": "combined_features"}, {"score": 0.003359119985242403, "phrase": "joint_distributions"}, {"score": 0.0032706520949775065, "phrase": "action_classes"}, {"score": 0.0032129675521135616, "phrase": "low-level_visual_features"}, {"score": 0.003128336741911927, "phrase": "video_frames"}, {"score": 0.003073154478201771, "phrase": "computational_expense"}, {"score": 0.0030189426536422577, "phrase": "compact_structural_representation"}, {"score": 0.002952516738708181, "phrase": "first_group"}, {"score": 0.002861961643289598, "phrase": "feature_groups"}, {"score": 0.002761856557698856, "phrase": "efficient_boosting_method"}, {"score": 0.0027252240573281163, "phrase": "action_recognition_engine"}, {"score": 0.0026771333996253783, "phrase": "grouped_features"}, {"score": 0.002629889135655667, "phrase": "experimental_results"}, {"score": 0.0025042115651986332, "phrase": "superior_performance"}, {"score": 0.002405853977978678, "phrase": "single_type"}, {"score": 0.0023424328921363585, "phrase": "whole_model"}, {"score": 0.0022705467477443417, "phrase": "action_recognition_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Frame-based action recognition", " Feature mining"], "paper_abstract": "In this paper we present an instant action recognition method, which is able to recognize an action in real-time from only two continuous video frames. For the sake of instantaneity, we employ two types of computationally efficient but perceptually important features - optical flow and edges - to capture motion and shape characteristics of actions. It is known that the two types of features can be unreliable or ambiguous due to noise and degradation of video quality. In order to endow them with strong discriminative power, we pursue combined features, of which the joint distributions are different in-between action classes. As the low-level visual features are usually densely distributed in video frames, to reduce computational expense and induce a compact structural representation, we propose to first group the learned discriminative joint features into feature groups according to their correlation, then adapt the efficient boosting method as the action recognition engine which take the grouped features as input. Experimental results show that the combination of the two types of features achieves superior performance in differentiating actions than that of using each single type of features alone. The whole model is computationally efficient, and the action recognition accuracy is comparable to the state-of-the-art approaches. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Learning discriminative features for fast frame-based action recognition", "paper_id": "WOS:000317886600010"}