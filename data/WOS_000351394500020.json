{"auto_keywords": [{"score": 0.02827025156412822, "phrase": "video-specific_gmms"}, {"score": 0.012007605863803518, "phrase": "local_spatio-temporal_features"}, {"score": 0.00481495049065317, "phrase": "action_recognition"}, {"score": 0.004663396040465122, "phrase": "dense_local_spatio-temporal_features"}, {"score": 0.00451659023910662, "phrase": "novel_framework"}, {"score": 0.004468684611798047, "phrase": "human_action_recognition"}, {"score": 0.004374385639298755, "phrase": "newly_proposed_mid-level_feature_representation_method"}, {"score": 0.004327981760540394, "phrase": "lie_algebrized_guassians"}, {"score": 0.004169394481182493, "phrase": "action_sequence"}, {"score": 0.003995226376780718, "phrase": "space-time_space"}, {"score": 0.0038900709793274484, "phrase": "action_recognition_problem"}, {"score": 0.0037076911119175455, "phrase": "probability_distributions"}, {"score": 0.00335016692413066, "phrase": "multiple_scales"}, {"score": 0.003244567402785763, "phrase": "human_body"}, {"score": 0.0031760175583084274, "phrase": "normalized_spatial_coordinates"}, {"score": 0.003108911488613549, "phrase": "local_descriptor"}, {"score": 0.0030270132320276096, "phrase": "spatial_position_information"}, {"score": 0.002931569771634119, "phrase": "local_features"}, {"score": 0.0028089634624677957, "phrase": "gaussian_mixture_model"}, {"score": 0.0026205405415623525, "phrase": "global_gmm"}, {"score": 0.0025514745448798385, "phrase": "training_data"}, {"score": 0.0024578219177450876, "phrase": "global_gmm."}, {"score": 0.00241882095327328, "phrase": "lag"}, {"score": 0.0022928991183989115, "phrase": "linear_svm"}, {"score": 0.002220551141101661, "phrase": "experimental_results"}, {"score": 0.0021620042653528846, "phrase": "ucf_sports_dataset"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_performance"}], "paper_keywords": ["Action recognition", " Dense sampling", " Local spatio-temporal feature", " Gaussian mixture model", " Lie algebrized gaussians"], "paper_abstract": "This paper presents a novel framework for human action recognition based on a newly proposed mid-level feature representation method named Lie Algebrized Guassians (LAG). As an action sequence can be treated as a 3D object in space-time space, we address the action recognition problem by recognizing 3D objects and characterize 3D objects by the probability distributions of local spatio-temporal features. First, for each video, we densely sample local spatio-temporal features (e.g. HOG3D) at multiple scales confined in bounding boxes of human body. Moreover, normalized spatial coordinates are appended to local descriptor in order to capture spatial position information. Then the distribution of local features in each video is modeled by a Gaussian Mixture Model (GMM). To estimate the parameters of video-specific GMMs, a global GMM is trained using all training data and video-specific GMMs are adapted from the global GMM. Then the LAG is adopted to vectorize those video-specific GMMs. Finally, linear SVM is employed for classification. Experimental results on the KTH and UCF Sports dataset show that our method achieves state-of-the-art performance.", "paper_title": "Action recognition using lie algebrized gaussians over dense local spatio-temporal features", "paper_id": "WOS:000351394500020"}