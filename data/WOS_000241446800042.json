{"auto_keywords": [{"score": 0.043788298932667113, "phrase": "minerva"}, {"score": 0.00481495049065317, "phrase": "increasing_use"}, {"score": 0.004674952036988355, "phrase": "semantic_web_and_enterprise_knowledge_management"}, {"score": 0.004439634831927606, "phrase": "scalable_and_efficient_ontology_management_systems"}, {"score": 0.003945117054416623, "phrase": "large-scale_owl_ontologies"}, {"score": 0.003830312347175889, "phrase": "relational_databases"}, {"score": 0.003664315990489347, "phrase": "scalability_requirements"}, {"score": 0.0036105923401756126, "phrase": "real_applications"}, {"score": 0.003531474887552889, "phrase": "practical_reasoning_capability"}, {"score": 0.003428665921276366, "phrase": "high_query_performance"}, {"score": 0.003304339421246321, "phrase": "description_logic_reasoners"}, {"score": 0.0032319109979344184, "phrase": "tbox_inference"}, {"score": 0.0031845067058084613, "phrase": "logic_rules"}, {"score": 0.0031146967095233586, "phrase": "abox_inference"}, {"score": 0.0029576827451501956, "phrase": "database_schema"}, {"score": 0.0028928306994090453, "phrase": "inference_requirements"}, {"score": 0.002850385670169814, "phrase": "user_queries"}, {"score": 0.002726740692380339, "phrase": "materialized_results"}, {"score": 0.00266693888510356, "phrase": "back-end_database"}, {"score": 0.0026084451971464867, "phrase": "effective_integration"}, {"score": 0.002570162055835289, "phrase": "ontology_inference"}, {"score": 0.0024405312482831646, "phrase": "reasoning_efficiency"}, {"score": 0.0023519508354777215, "phrase": "runtime_inference"}, {"score": 0.0022498783454674254, "phrase": "extensive_experiments"}, {"score": 0.0022168460543913787, "phrase": "university_ontology_benchmark"}, {"score": 0.0021682027434117095, "phrase": "high_efficiency"}, {"score": 0.0021049977753042253, "phrase": "minerva_system"}], "paper_keywords": [""], "paper_abstract": "With the increasing use of ontologies in Semantic Web and enterprise knowledge management, it is critical to develop scalable and efficient ontology management systems. In this paper, we present Minerva, a storage and inference system for large-scale OWL ontologies on top of relational databases. It aims to meet scalability requirements of real applications and provide practical reasoning capability as well as high query performance. The method combines Description Logic reasoners for the TBox inference with logic rules for the ABox inference. Furthermore, it customizes the database schema based on inference requirements. User queries are answered by directly retrieving materialized results from the back-end database. The effective integration of ontology inference and storage is expected to improve reasoning efficiency, while querying without runtime inference guarantees satisfactory response time. Extensive experiments on University Ontology Benchmark show the high efficiency and scalability of Minerva system.", "paper_title": "Minerva: A scalable OWL ontology storage and inference system", "paper_id": "WOS:000241446800042"}