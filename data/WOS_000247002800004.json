{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "rankboost"}, {"score": 0.004530552828603269, "phrase": "effective_algorithm"}, {"score": 0.003773870856027139, "phrase": "weak_learner"}, {"score": 0.0034894451015047875, "phrase": "rank_function"}, {"score": 0.003340768341189764, "phrase": "regularization_properties"}, {"score": 0.0031431690368229443, "phrase": "regularization_property"}, {"score": 0.002855934865505357, "phrase": "monotonic_concavity"}, {"score": 0.0027341763737751467, "phrase": "new_weak_ranking_learner"}, {"score": 0.002594880866651459, "phrase": "ranking_functions"}, {"score": 0.0023782753249846794, "phrase": "multiple_face_recognition_algorithms"}, {"score": 0.0022768346311104735, "phrase": "text_information_retrieval_systems"}, {"score": 0.0021797112385590913, "phrase": "mwgr"}, {"score": 0.0021049977753042253, "phrase": "binary_weak_learners"}], "paper_keywords": ["rankboost", " ranking", " convex/ concave", " regularization"], "paper_abstract": "Rankboost has been shown to be an effective algorithm for combining ranks. However, its ability to generalize well and not overfit is directly related to the choice of weak learner, in the sense that regularization of the rank function is due to the regularization properties of its weak learners. We present a regularization property called consistency in preference and confidence that mathematically translates into monotonic concavity, and describe a new weak ranking learner ( MWGR) that generates ranking functions with this property. In experiments combining ranks from multiple face recognition algorithms and an experiment combining text information retrieval systems, rank functions using MWGR proved superior to binary weak learners.", "paper_title": "Concave learners for rankboost", "paper_id": "WOS:000247002800004"}