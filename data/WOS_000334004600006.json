{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "nonlinear_support_vector_machines"}, {"score": 0.04920822493417558, "phrase": "feature_selection"}, {"score": 0.004473982381245469, "phrase": "challenging_non-convex_minimization_problem"}, {"score": 0.00428629884026304, "phrase": "suboptimal_solutions"}, {"score": 0.0041316803676012155, "phrase": "effective_algorithm"}, {"score": 0.004007083686875716, "phrase": "embedded_feature_selection_primal_problem"}, {"score": 0.0038862297330905836, "phrase": "trust-region_method"}, {"score": 0.0037231102027070724, "phrase": "non-convex_optimization"}, {"score": 0.0036553070575015344, "phrase": "line-search_methods"}, {"score": 0.0033961782274326948, "phrase": "alternating_optimization_approach"}, {"score": 0.0031553611552558986, "phrase": "convex_subproblem"}, {"score": 0.0030789331635764122, "phrase": "standard_svm_optimization"}, {"score": 0.0027741761880779535, "phrase": "straightforward_alternating_optimization_approach"}, {"score": 0.002673957615079041, "phrase": "point_solutions"}, {"score": 0.00259320616168125, "phrase": "novel_technique"}, {"score": 0.0025148871904409095, "phrase": "explicit_margin_variable"}, {"score": 0.002469032978674379, "phrase": "saddle_point_convergence"}, {"score": 0.002424012799998538, "phrase": "solution_quality"}, {"score": 0.0023944552329463035, "phrase": "experiment_results"}, {"score": 0.0023221248824337576, "phrase": "state-of-the-art_embedded_svm_feature_selection_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Feature selection", " Nonlinear", " Embedded", " Support vector machine", " Non-convex optimization", " Trust-region method", " Alternating optimization"], "paper_abstract": "Embedding feature selection in nonlinear support vector machines (SVMs) leads to a challenging non-convex minimization problem, which can be prone to suboptimal solutions. This paper develops an effective algorithm to directly solve the embedded feature selection primal problem. We use a trust-region method, which is better suited for non-convex optimization compared to line-search methods, and guarantees convergence to a minimizer. We devise an alternating optimization approach to tackle the problem efficiently, breaking it down into a convex subproblem, corresponding to standard SVM optimization, and a non-convex subproblem for feature selection. Importantly, we show that a straightforward alternating optimization approach can be susceptible to saddle point solutions. We propose a novel technique, which shares an explicit margin variable to overcome saddle point convergence and improve solution quality. Experiment results show our method outperforms the state-of-the-art embedded SVM feature selection method, as well as other leading filter and wrapper approaches. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Primal explicit max margin feature selection for nonlinear support vector machines", "paper_id": "WOS:000334004600006"}