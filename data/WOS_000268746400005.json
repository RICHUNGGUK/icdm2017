{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "generalization_performance"}, {"score": 0.004739056045644449, "phrase": "non-convex_optimization"}, {"score": 0.004664352260912174, "phrase": "extended_nu-support_vector_machine"}, {"score": 0.00385431710959668, "phrase": "support_vectors"}, {"score": 0.0034482025128821548, "phrase": "entire_range"}, {"score": 0.0030847461428168614, "phrase": "non-convex_extension"}, {"score": 0.002964415652865295, "phrase": "extended_method"}, {"score": 0.0027815466400771768, "phrase": "original_nu-svc."}, {"score": 0.0025892330566358503, "phrase": "optimization_algorithm"}, {"score": 0.0023346234464901978, "phrase": "new_theoretical_insights"}, {"score": 0.002208035721125305, "phrase": "novel_nu-svc_algorithm"}, {"score": 0.0021049977753042253, "phrase": "convergence_properties"}], "paper_keywords": ["Support Vector Machine", " Conditional Value-at-Risk", " E nu-SVC", " Generalization Error Bound", " Global Optimization"], "paper_abstract": "The nu-support vector classification (nu-SVC) algorithm was shown to work well and provide intuitive interpretations, e.g., the parameter nu roughly specifies the fraction of support vectors. Although nu corresponds to a fraction, it cannot take the entire range between 0 and 1 in its original form. This problem was settled by a non-convex extension of nu-SVC and the extended method was experimentally shown to generalize better than original nu-SVC. However, its good generalization performance and convergence properties of the optimization algorithm have not been studied yet. In this paper, we provide new theoretical insights into these issues and propose a novel nu-SVC algorithm that has guaranteed generalization performance and convergence properties.", "paper_title": "On Generalization Performance and Non-Convex Optimization of Extended nu-Support Vector Machine", "paper_id": "WOS:000268746400005"}