{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "mutual_information"}, {"score": 0.004271100220705305, "phrase": "bivariate_edas"}, {"score": 0.004217537792708984, "phrase": "discrete_optimization_problems"}, {"score": 0.004112411350177274, "phrase": "new_approach"}, {"score": 0.00406083086983316, "phrase": "hsmiec."}, {"score": 0.003984665807155269, "phrase": "current_edas"}, {"score": 0.0038608730929994696, "phrase": "statistical_learning_process"}, {"score": 0.00353426342004404, "phrase": "selfish_gene_theory"}, {"score": 0.0031346115554600003, "phrase": "probability_distribution"}, {"score": 0.003075765038696993, "phrase": "virtual_population"}, {"score": 0.0029613556844064713, "phrase": "hybrid_sampling_method"}, {"score": 0.0027976491158911514, "phrase": "incremental_learning"}, {"score": 0.0027625134766418266, "phrase": "resample_scheme"}, {"score": 0.0024038923350585962, "phrase": "hsmiec"}, {"score": 0.002256619934086924, "phrase": "bmda"}, {"score": 0.002228263890334039, "phrase": "comit"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Estimation of distribution algorithm", " Selfish gene theory", " Mutual information entropy", " Clustering ensembles"], "paper_abstract": "In this paper, we focus on the design of bivariate EDAs for discrete optimization problems and propose a new approach named HSMIEC. While the current EDAs require much time in the statistical learning process as the relationships among the variables are too complicated, we employ the Selfish gene theory (SG) in this approach, as well as a Mutual Information and Entropy based Cluster (MIEC) model is also set to optimize the probability distribution of the virtual population. This model uses a hybrid sampling method by considering both the clustering accuracy and clustering diversity and an incremental learning and resample scheme is also set to optimize the parameters of the correlations of the variables. Compared with several benchmark problems, our experimental results demonstrate that HSMIEC often performs better than some other EDAs, such as BMDA, COMIT, MIMIC and ECGA. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Hybrid sampling on mutual information entropy-based clustering ensembles for optimizations", "paper_id": "WOS:000276481200040"}