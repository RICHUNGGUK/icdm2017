{"auto_keywords": [{"score": 0.044294032470466274, "phrase": "virtual_camera"}, {"score": 0.00481495049065317, "phrase": "locally_adaptive_depth_regularization"}, {"score": 0.004357927940322685, "phrase": "novel_view"}, {"score": 0.004145882022189891, "phrase": "scene_description"}, {"score": 0.0031170783606525856, "phrase": "radiance_model"}, {"score": 0.002923214590192792, "phrase": "smooth_variation"}, {"score": 0.0027218799769229596, "phrase": "regularizing_constraint"}, {"score": 0.002445514186654732, "phrase": "visually_realistic_images"}, {"score": 0.0024108455980729284, "phrase": "negligible_artifacts"}, {"score": 0.002342972434255588, "phrase": "limited_number"}, {"score": 0.002309754152767196, "phrase": "input_views"}, {"score": 0.0022608057001451414, "phrase": "proposed_approach"}, {"score": 0.0021659920594094407, "phrase": "view_points"}, {"score": 0.0021049977753042253, "phrase": "input_images"}], "paper_keywords": [""], "paper_abstract": "In this paper we attempt to solve the problem of synthesizing a novel view corresponding to a virtual camera given the scene description in the form of images captured from other view points. We project each line of sight emerging from the virtual camera on each of the given views, align them geometrically and assign a color that is photo consistent as per the radiance model. This being ill-conditioned, a smooth variation of depth in the scene is utilized as the regularizing constraint. It leads to development of an algorithm which is computationally fast and generates visually realistic images with negligible artifacts even with a limited number of input views. The proposed approach puts no restriction on the view points from which the input images are captured.", "paper_title": "Novel view synthesis using locally adaptive depth regularization", "paper_id": "WOS:000235772300046"}