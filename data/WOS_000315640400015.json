{"auto_keywords": [{"score": 0.004685575787741084, "phrase": "reinforcement_learning"}, {"score": 0.004278807087784626, "phrase": "self-organized_approach"}, {"score": 0.003942877273973905, "phrase": "rational_peers"}, {"score": 0.0037336520904376687, "phrase": "whole_system"}, {"score": 0.003535489842686145, "phrase": "overall_welfare"}, {"score": 0.0034403745992576808, "phrase": "system-wide_performance_metric"}, {"score": 0.0031990183472675377, "phrase": "distributed_reinforcement_learning"}, {"score": 0.0031129269142224168, "phrase": "cooperation_policies"}, {"score": 0.0026427848602443267, "phrase": "pareto_optimality"}, {"score": 0.0024797072773840704, "phrase": "local_value_functions"}], "paper_keywords": ["Distributed decision making", " Pareto optimality", " particle swarm optimization", " Q-learning", " rational peers"], "paper_abstract": "In this paper, we have developed a self-organized approach to cooperation policy setting in a system of rational peers that have only partial views of the whole system in order to improve the overall welfare as a system-wide performance metric. The proposed approach is based on distributed reinforcement learning and sets cooperation policies of the peers through their self-organized interactions. We have analyzed this approach to demonstrate that it results in Pareto optimality in the system by disseminating the local value functions of the peers among the neighbors. We have also experimentally verified that this approach outperforms the other commonly used approaches in the literature, in terms of the performance of the system.", "paper_title": "Self-Organized Cooperation Policy Setting in P2P Systems Based on Reinforcement Learning", "paper_id": "WOS:000315640400015"}