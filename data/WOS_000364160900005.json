{"auto_keywords": [{"score": 0.036718790246924135, "phrase": "sparse_codes"}, {"score": 0.01275680917556451, "phrase": "data_points"}, {"score": 0.012487398913157168, "phrase": "complex_loss_function"}, {"score": 0.010985018032136324, "phrase": "linear_function"}, {"score": 0.01079870609582324, "phrase": "sparse_code"}, {"score": 0.009217011919366726, "phrase": "upper_bound"}, {"score": 0.00481495049065317, "phrase": "sparse_coding"}, {"score": 0.004773692073488661, "phrase": "hyper-predictor_learning"}, {"score": 0.004513957235071457, "phrase": "multivariate_performance_measures"}, {"score": 0.004417848254181138, "phrase": "novel_algorithm"}, {"score": 0.004305203085016233, "phrase": "traditional_machine_learning_methods"}, {"score": 0.004249957578636515, "phrase": "simple_loss_functions"}, {"score": 0.004195418010131832, "phrase": "prediction_function"}, {"score": 0.0039841418890102925, "phrase": "effective_hyper-predictor"}, {"score": 0.003751011827704279, "phrase": "multivariate_performance_measure"}, {"score": 0.0030239842475439814, "phrase": "joint_optimization_problem"}, {"score": 0.0029089095588612007, "phrase": "reconstruction_error"}, {"score": 0.0026570998719084153, "phrase": "loss_function"}, {"score": 0.002566997205079849, "phrase": "linear_function_parameter"}, {"score": 0.0024586427394152196, "phrase": "iterative_algorithm"}, {"score": 0.002427035025924384, "phrase": "descent_gradient_methods"}, {"score": 0.0023650305205893353, "phrase": "hyper-predictor_parameter"}, {"score": 0.0023346234464901978, "phrase": "experiment_results"}, {"score": 0.002304606411453748, "phrase": "benchmark_data_sets"}, {"score": 0.0022457226013538343, "phrase": "proposed_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Pattern classification", " Loss function", " Multivariate performance measures", " Sparse coding", " Joint learning", " Alternate optimization"], "paper_abstract": "In this paper, we investigate the problem of optimization of multivariate performance measures, and propose a novel algorithm for it. Different from traditional machine learning methods which optimize simple loss functions to learn prediction function, the problem studied in this paper is how to learn effective hyper-predictor for a tuple of data points, so that a complex loss function corresponding to a multivariate performance measure can be minimized. We propose to present the tuple of data points to a tuple of sparse codes via a dictionary, and then apply a linear function to compare a sparse code against a given candidate class label. To learn the dictionary, sparse codes, and parameter of the linear function, we propose a joint optimization problem. In this problem, the both the reconstruction error and sparsity of sparse code, and the upper bound of the complex loss function are minimized. Moreover, the upper bound of the loss function is approximated by the sparse codes and the linear function parameter. To optimize this problem, we develop an iterative algorithm based on descent gradient methods to learn the sparse codes and hyper-predictor parameter alternately. Experiment results on some benchmark data sets show the advantage of the proposed methods over other state-of-the-art algorithms. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "A novel multivariate performance optimization method based on sparse coding and hyper-predictor learning", "paper_id": "WOS:000364160900005"}