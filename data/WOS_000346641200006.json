{"auto_keywords": [{"score": 0.04812305996521061, "phrase": "frequent_pattern_mining"}, {"score": 0.015370087770275934, "phrase": "noise_constraints"}, {"score": 0.012787318100075789, "phrase": "frequent_patterns"}, {"score": 0.00481495049065317, "phrase": "mining_weighted"}, {"score": 0.004531637625717547, "phrase": "weighted_frequent_pattern_mining"}, {"score": 0.004412965940679449, "phrase": "search_space"}, {"score": 0.004363058588000252, "phrase": "important_patterns"}, {"score": 0.004297388539539564, "phrase": "previous_definition"}, {"score": 0.004264923517966271, "phrase": "weighted_closed_patterns"}, {"score": 0.00373474182086791, "phrase": "weighted_closed_frequent_patterns"}, {"score": 0.0035685175471526823, "phrase": "exactly_same_weighted_support"}, {"score": 0.0034226302212225206, "phrase": "slight_changes"}, {"score": 0.0033967510986397946, "phrase": "items'_supports"}, {"score": 0.003320277992107974, "phrase": "significantly_negative_effects"}, {"score": 0.0032826873794020253, "phrase": "mining_results"}, {"score": 0.0031845067058084583, "phrase": "exact_and_valid_analysis_results"}, {"score": 0.0031010029460927864, "phrase": "original_characteristics"}, {"score": 0.0026338658998573752, "phrase": "precise_equality"}, {"score": 0.002613935123129054, "phrase": "patterns'_weighted_supports"}, {"score": 0.0025453546203590364, "phrase": "weighted_approximate"}, {"score": 0.0025260919226344305, "phrase": "frequent_pattern_mining_algorithm"}, {"score": 0.0024227171881502636, "phrase": "tolerant_pattern_mining"}, {"score": 0.0023235629819760018, "phrase": "pruning_and_subset_checking_methods"}, {"score": 0.0022454559805729717, "phrase": "extensive_performance_study"}, {"score": 0.0021782296784218923, "phrase": "memory_usage"}], "paper_keywords": ["Data mining", " approximate bound", " weighted approximate closed pattern mining", " noise constraints"], "paper_abstract": "Based on the frequent pattern mining, closed frequent pattern mining and weighted frequent pattern mining have been studied to reduce the search space and discover important patterns. In the previous definition of weighted closed patterns, supports of patterns are only considered to compute the closures of the patterns. It means that the closures of weighted frequent patterns cannot be perfectly checked. Moreover, the usefulness of weighted closed frequent patterns depends on the presence of frequent patterns that have supersets with the exactly same weighted support. However, from the errors such as noise, slight changes in items' supports or weights by them have significantly negative effects on the mining results, which may prevent us from obtaining exact and valid analysis results since the errors can break the original characteristics of items and patterns. In this paper, to solve the above problems, we propose a concept of robust weighted closed frequent pattern mining, and an approximate bound is defined on the basis of the concept, which can relax requirements for precise equality among patterns' weighted supports. Thereafter, we propose a weighted approximate closed frequent pattern mining algorithm which not only considers the two approaches but also suggests fault tolerant pattern mining in the noise constraints. To efficiently mine weighted approximate closed frequent patterns, we suggest pruning and subset checking methods which reduce search space. We also report extensive performance study to demonstrate the effectiveness, efficiency, memory usage, scalability, and quality of patterns in our algorithm.", "paper_title": "An Efficient Approach for Mining Weighted Approximate Closed Frequent Patterns Considering Noise Constraints", "paper_id": "WOS:000346641200006"}