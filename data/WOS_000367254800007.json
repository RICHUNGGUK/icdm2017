{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "distributed_memory_code_generation_for_mixed"}, {"score": 0.004598933498016774, "phrase": "irregular_and_regular_computational_structures"}, {"score": 0.004437613070853689, "phrase": "adaptive_mesh_refinement"}, {"score": 0.004392769991899406, "phrase": "amr"}, {"score": 0.004238452771031322, "phrase": "regular_blocks"}, {"score": 0.003906116922372891, "phrase": "computational_structure"}, {"score": 0.003711723285313348, "phrase": "innermost_loops"}, {"score": 0.0036553070575015344, "phrase": "outer_loops"}, {"score": 0.0034556603183020407, "phrase": "indirect_array_access_patterns"}, {"score": 0.0033685408148574846, "phrase": "distributed_memory_parallelization"}, {"score": 0.0032008144731234265, "phrase": "loop_nests"}, {"score": 0.0031042018721479385, "phrase": "polyhedral_frameworks"}, {"score": 0.0029196116767956273, "phrase": "generated_distributed_memory_code"}, {"score": 0.002831462722290752, "phrase": "regular_nature"}, {"score": 0.0028026735035370206, "phrase": "previously_affine_innermost_loops"}, {"score": 0.0027041907335656782, "phrase": "subsequent_optimizations"}, {"score": 0.0026630475331025955, "phrase": "on-node_performance"}, {"score": 0.0025958582759972315, "phrase": "code_generation_framework"}, {"score": 0.002479150189700726, "phrase": "distributed_memory_systems"}, {"score": 0.0024289743270061157, "phrase": "distributed_memory_code"}, {"score": 0.002392008392892289, "phrase": "program_properties"}, {"score": 0.00235560370536971, "phrase": "subsequent_polyhederal_optimizations"}, {"score": 0.002272794656458419, "phrase": "major_memory_bottleneck"}, {"score": 0.002249672943553135, "phrase": "prior_techniques"}, {"score": 0.0021705796895687864, "phrase": "generated_code"}, {"score": 0.0021049977753042253, "phrase": "proposed_framework"}], "paper_keywords": ["Distributed Memory", " Inspector/Executor", " Polyhedral Compilation", " Irregular Computation"], "paper_abstract": "Many applications feature a mix of irregular and regular computational structures. For example, codes using adaptive mesh refinement (AMR) typically use a collection of regular blocks, where the number of blocks and the relationship between blocks is irregular. The computational structure in such applications generally involves regular (affine) loop computations within some number of innermost loops, while outer loops exhibit irregularity due to data-dependent control flow and indirect array access patterns. Prior approaches to distributed memory parallelization do not handle such computations effectively. They either target loop nests that are completely affine using polyhedral frameworks, or treat all loops as irregular. Consequently, the generated distributed memory code contains artifacts that disrupt the regular nature of previously affine innermost loops of the computation. This hampers subsequent optimizations to improve on-node performance. We propose a code generation framework that can effectively transform such applications for execution on distributed memory systems. Our approach generates distributed memory code which preserves program properties that enable subsequent polyhederal optimizations. Simultaneously, it addresses a major memory bottleneck of prior techniques that limits the scalability of the generated code. The effectiveness of the proposed framework is demonstrated on computations that are mixed regular/irregular, completely regular, and completely irregular.", "paper_title": "Distributed Memory Code Generation for Mixed Irregular/Regular Computations", "paper_id": "WOS:000367254800007"}