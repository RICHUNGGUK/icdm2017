{"auto_keywords": [{"score": 0.03711522701821289, "phrase": "relaxation_parameter"}, {"score": 0.007247724202406431, "phrase": "signal-to-noise_ratio"}, {"score": 0.00481495049065317, "phrase": "sparse_recovery_with_unknown_variance"}, {"score": 0.00456020621016909, "phrase": "regression_vector_beta"}, {"score": 0.0045108906244892165, "phrase": "generic_s-sparse_linear_model"}, {"score": 0.0034118234596993836, "phrase": "first_strategy"}, {"score": 0.003266443127727596, "phrase": "cap_root_log_p"}, {"score": 0.0031272381208680613, "phrase": "empirical_variance"}, {"score": 0.0030821633718368206, "phrase": "second_strategy"}, {"score": 0.002897710777957041, "phrase": "penalty_terms"}, {"score": 0.002734182070890917, "phrase": "candes"}, {"score": 0.0026949131301178385, "phrase": "ann"}, {"score": 0.002487835869510301, "phrase": "exact_recovery"}, {"score": 0.0023990982005125763, "phrase": "high_probability"}, {"score": 0.0023644936731468252, "phrase": "simulation_results"}, {"score": 0.0023303871145705954, "phrase": "first_estimator"}, {"score": 0.0023135183406982414, "phrase": "nearly_the_same_performances"}, {"score": 0.0021049977753042253, "phrase": "false_detection"}], "paper_keywords": ["LASSO", " sparse regression", " l(1) penalization", " high dimensional regression", " unknown variance"], "paper_abstract": "We address the issue of estimating the regression vector beta in the generic s-sparse linear model y = X beta + z, with beta is an element of R-p, y is an element of R-n, z similar to N(0, sigma I-2), and p > n when the variance sigma(2) is unknown. We study two least absolute shrinkage and selection operator (LASSO)-type methods that jointly estimate beta and the variance. These estimators are minimizers of the l(1) penalized least-squares functional, where the relaxation parameter is tuned according to two different strategies. In the first strategy, the relaxation parameter is of the order (sigma) over cap root log p, where (sigma) over cap (2) is the empirical variance. In the second strategy, the relaxation parameter is chosen so as to enforce a tradeoff between the fidelity and the penalty terms at optimality. For both estimators, our assumptions are similar to the ones proposed by Candes and Plan in Ann. Stat. (2009), for the case where sigma(2) is known. We prove that our estimators ensure exact recovery of the support and sign pattern of beta with high probability. We present simulation results showing that the first estimator enjoys nearly the same performances in practice as the standard LASSO (known variance case) for a wide range of the signal-to-noise ratio. Our second estimator is shown to outperform both in terms of false detection, when the signal-to-noise ratio is low.", "paper_title": "Sparse Recovery With Unknown Variance: A LASSO-Type Approach", "paper_id": "WOS:000341982200021"}