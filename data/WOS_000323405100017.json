{"auto_keywords": [{"score": 0.033755177978306364, "phrase": "dfds"}, {"score": 0.03160672834103565, "phrase": "memory_request"}, {"score": 0.031388704174305886, "phrase": "noc"}, {"score": 0.026845587719274873, "phrase": "memory_requests"}, {"score": 0.004815315857347625, "phrase": "distributed"}, {"score": 0.004797835176186123, "phrase": "fair_dram_scheduling"}, {"score": 0.004763785973620115, "phrase": "network-on-chips_architecture"}, {"score": 0.004646496622257368, "phrase": "effective_manner"}, {"score": 0.00456448259718331, "phrase": "chip_multi-processors"}, {"score": 0.004420472010542188, "phrase": "timing_characteristics"}, {"score": 0.004373480870285314, "phrase": "dram._a_memory_access_scheduler"}, {"score": 0.004296264970612285, "phrase": "resources_utilization"}, {"score": 0.004131135118662576, "phrase": "different_dram_banks"}, {"score": 0.004043744293248725, "phrase": "different_threads"}, {"score": 0.004000741805312148, "phrase": "different_cores"}, {"score": 0.003958194802333944, "phrase": "different_performance"}, {"score": 0.003633652174971415, "phrase": "dram_system"}, {"score": 0.003569451476205552, "phrase": "system_throughput"}, {"score": 0.00335950642866031, "phrase": "distributed_fair_dram_scheduling"}, {"score": 0.003128216758835217, "phrase": "key_design_points"}, {"score": 0.003018595266561849, "phrase": "total_waiting_cycles"}, {"score": 0.002830839166653185, "phrase": "waiting_cycles"}, {"score": 0.002751174423568564, "phrase": "additional_flit"}, {"score": 0.0025800088089364737, "phrase": "semi-dynamic_virtual_channel_allocation"}, {"score": 0.0025073851194697397, "phrase": "memory_controllers"}, {"score": 0.002419466507425567, "phrase": "simple_scheduling_algorithm"}, {"score": 0.002402346168959094, "phrase": "mcs"}, {"score": 0.002368198542691635, "phrase": "complex_algorithms"}, {"score": 0.0023015232625177755, "phrase": "synthetic_and_real_workload"}, {"score": 0.0022851491693940272, "phrase": "parsec_benchmark_suite"}, {"score": 0.002181514206602054, "phrase": "waiting_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Many core processors", " Network on chip", " DRAM scheduling"], "paper_abstract": "Memory access scheduling is an effective manner to improve performance of Chip Multi-Processors (CMPs) by taking advantage of the timing characteristics of a DRAM. A memory access scheduler can sub-divide resources utilization (banks and rows) to increase throughput by accessing different DRAM banks in parallel. However, different threads running on different cores may exhibit different performance. One thread may experience starvation while the others are serviced normally. Therefore, designing a scheduler which reduces the unfairness in the DRAM system, while also improving system throughput on a variety of workloads and systems, is necessary. In this paper, a distributed fair DRAM scheduling for two-dimensional mesh network-on-chips (NoCs), called DFDS, is presented. The key design points in DFDS are: (i) assessing the total waiting cycles of a memory request in NoC and considering it as a metric in arbitration. For this purpose waiting cycles of a memory request are put in an additional flit in a packet and are updated while traversing the NoC, and (ii) proposing a semi-dynamic virtual channel allocation to provide in-order memory requests to memory controllers (MCs). Consequently, we use a simple scheduling algorithm in MCs, instead of complex algorithms. To validate our approach, we apply synthetic and real workload from Parsec benchmark suite. The results show effectiveness of our approach, as we reduce the waiting time of memory requests by up to 15%. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Distributed fair DRAM scheduling in network-on-chips architecture", "paper_id": "WOS:000323405100017"}