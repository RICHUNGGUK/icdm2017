{"auto_keywords": [{"score": 0.015548237087755759, "phrase": "real-time_facial_tracking"}, {"score": 0.00481495049065317, "phrase": "displaced_dynamic_expression_regression"}, {"score": 0.004580550308652044, "phrase": "fully_automatic_approach"}, {"score": 0.004406121974246201, "phrase": "single_video_camera"}, {"score": 0.004168349927332055, "phrase": "individual_user"}, {"score": 0.004054299982508618, "phrase": "generic_regressor"}, {"score": 0.004009555045206973, "phrase": "public_image_datasets"}, {"score": 0.0037931018103829427, "phrase": "arbitrary_video_cameras"}, {"score": 0.0033945024593626675, "phrase": "camera_matrix"}, {"score": 0.0033384259516301223, "phrase": "user_identity"}, {"score": 0.0032470094613727433, "phrase": "facial_expressions"}, {"score": 0.0031933617014256676, "phrase": "current_user"}, {"score": 0.0030208364972341096, "phrase": "alternating_manner"}, {"score": 0.002857605453835429, "phrase": "whole_process"}, {"score": 0.002794802975530612, "phrase": "accurate_facial_tracking"}, {"score": 0.0023920904611571783, "phrase": "time-consuming_calibration_step"}, {"score": 0.002152332983488664, "phrase": "attractive_solution"}, {"score": 0.0021285340816566906, "phrase": "wide_deployment"}, {"score": 0.0021049977753042253, "phrase": "consumer-level_applications"}], "paper_keywords": ["face tracking", " face animation", " performance capture", " blendshape models"], "paper_abstract": "We present a fully automatic approach to real-time facial tracking and animation with a single video camera. Our approach does not need any calibration for each individual user. It learns a generic regressor from public image datasets, which can be applied to any user and arbitrary video cameras to infer accurate 2D facial landmarks as well as the 3D facial shape from 2D video frames. The inferred 2D landmarks are then used to adapt the camera matrix and the user identity to better match the facial expressions of the current user. The regression and adaptation are performed in an alternating manner. With more and more facial expressions observed in the video, the whole process converges quickly with accurate facial tracking and animation. In experiments, our approach demonstrates a level of robustness and accuracy on par with state-of-the-art techniques that require a time-consuming calibration step for each individual user, while running at 28 fps on average. We consider our approach to be an attractive solution for wide deployment in consumer-level applications.", "paper_title": "Displaced Dynamic Expression Regression for Real-time Facial Tracking and Animation", "paper_id": "WOS:000340000100010"}