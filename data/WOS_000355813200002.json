{"auto_keywords": [{"score": 0.0494713765104406, "phrase": "large-scale_image_search"}, {"score": 0.00481495049065317, "phrase": "bsift"}, {"score": 0.004673530058379246, "phrase": "great_advance"}, {"score": 0.004575053987970206, "phrase": "large-scale_content-based_image_search"}, {"score": 0.004310173770196077, "phrase": "bag-of-visual-words_model"}, {"score": 0.004183539869393214, "phrase": "sift"}, {"score": 0.004130376386308024, "phrase": "image_representation"}, {"score": 0.004095323392273661, "phrase": "visual_matching"}, {"score": 0.003991932110277654, "phrase": "vector_quantization"}, {"score": 0.003958049372486465, "phrase": "local_features"}, {"score": 0.0039244530915794025, "phrase": "feature_quantization"}, {"score": 0.003841699919521703, "phrase": "hierarchical_k-nn"}, {"score": 0.0037928847801943404, "phrase": "severe_quantization_loss"}, {"score": 0.003728980912282212, "phrase": "ann"}, {"score": 0.0035883942463601688, "phrase": "k-d_tree"}, {"score": 0.0034532961266947734, "phrase": "feature_matching"}, {"score": 0.0033804443117334535, "phrase": "vector_distance"}, {"score": 0.0031440159350875057, "phrase": "supporting_visual_word_table"}, {"score": 0.003104038398386081, "phrase": "visual_words"}, {"score": 0.0030776686414001964, "phrase": "visual_word_expansion"}, {"score": 0.003025597247856977, "phrase": "initial_quantization_result"}, {"score": 0.0029998918671747168, "phrase": "multiple_approximate_nearest_visual_words"}, {"score": 0.002924074850256874, "phrase": "visual_word_table"}, {"score": 0.0028623555849897632, "phrase": "retrieval_recall"}, {"score": 0.0027781249331615813, "phrase": "matching_verification_scheme"}, {"score": 0.0026734504926268442, "phrase": "original_sift_descriptors"}, {"score": 0.002550842302473891, "phrase": "hamming_distance"}, {"score": 0.0025183881730011597, "phrase": "corresponding_binary_sift_signatures"}, {"score": 0.002475755804232436, "phrase": "bsift_verification"}, {"score": 0.0024547103576350233, "phrase": "false-positive_matches"}, {"score": 0.0022442249871042026, "phrase": "proposed_approach"}], "paper_keywords": ["Visual word expansion", " Binary SIFT", " Matching verification", " Image search"], "paper_abstract": "Recently, great advance has been made in large-scale content-based image search. Most state-of-the-art approaches are based on the bag-of-visual-words model with local features, such as SIFT, for image representation. Visual matching between images is obtained by vector quantization of local features. Feature quantization is either performed with hierarchical k-NN which introduces severe quantization loss, or with ANN (approximate nearest neighbors) search such as k-d tree, which is computationally inefficient. Besides, feature matching by quantization ignores the vector distance between features, which may cause many false-positive matches. In this paper, we propose constructing a supporting visual word table for all visual words by visual word expansion. Given the initial quantization result, multiple approximate nearest visual words are identified by checking supporting visual word table, which benefits the retrieval recall. Moreover, we present a matching verification scheme based on binary SIFT (BSIFT) signature. The L-2 distance between original SIFT descriptors is demonstrated to be well kept with the metric of Hamming distance between the corresponding binary SIFT signatures. With the BSIFT verification, false-positive matches can be effectively and efficiently identified and removed, which greatly improves the precision of large-scale image search. We evaluate the proposed approach on two public datasets for large-scale image search. The experimental results demonstrate the effectiveness and efficiency of our scheme.", "paper_title": "Visual word expansion and BSIFT verification for large-scale image search", "paper_id": "WOS:000355813200002"}