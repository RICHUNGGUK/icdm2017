{"auto_keywords": [{"score": 0.045898129462504406, "phrase": "first-order_state_abstraction"}, {"score": 0.03896845531319547, "phrase": "fomdp"}, {"score": 0.038064293214854265, "phrase": "state_abstraction"}, {"score": 0.00481495049065317, "phrase": "first-order_mdps"}, {"score": 0.004670896353428476, "phrase": "heuristic_search_algorithm"}, {"score": 0.004586531354697466, "phrase": "first-order_markov_decision_processes"}, {"score": 0.00386876598761639, "phrase": "existing_systems"}, {"score": 0.003051713660488494, "phrase": "admissible_heuristic"}, {"score": 0.002802462902794585, "phrase": "initial_state"}, {"score": 0.002348883765159185, "phrase": "probabilistic_track"}, {"score": 0.0021049977753042253, "phrase": "first-order_terms"}], "paper_keywords": [""], "paper_abstract": "We present a heuristic search algorithm for solving first-order Markov Decision Processes (FOMDPs). Our approach combines first-order state abstraction that avoids evaluating states individually, and heuristic search that avoids evaluating all states. Firstly, in contrast to existing systems, which start with propositionalizing the FOMDP and then perform state abstraction on its propositionalized version we apply state abstraction directly on the FOMDP avoiding propositionalization. This kind of abstraction is referred to as first-order state abstraction. Secondly, guided by an admissible heuristic, the search is restricted to those states that are reachable from the initial state. We demonstrate the usefulness of the above techniques for solving FOMDPs with a system, referred to as FluCaP (formerly, FCPlanner), that entered the probabilistic track of the 2004 International Planning Competition (IPC'2004) and demonstrated an advantage over other planners on the problems represented in first-order terms.", "paper_title": "FluCaP: A heuristic search planner for first-order MDPs", "paper_id": "WOS:000242943700001"}