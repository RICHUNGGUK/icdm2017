{"auto_keywords": [{"score": 0.03612471185821751, "phrase": "constant_rate"}, {"score": 0.015719716506582538, "phrase": "human_navigational_principles"}, {"score": 0.004714869813251479, "phrase": "passive_tracking_algorithms"}, {"score": 0.0045846424310611745, "phrase": "projected_object"}, {"score": 0.004457995891964028, "phrase": "navigational_algorithms"}, {"score": 0.004426882270402403, "phrase": "mobile_robots"}, {"score": 0.004380616732302083, "phrase": "perceptual_principles"}, {"score": 0.004334832612029898, "phrase": "viewer-based_geometry"}, {"score": 0.004156411748278609, "phrase": "time-consuming_calculations"}, {"score": 0.003971367134498762, "phrase": "human_research"}, {"score": 0.0038887521594153608, "phrase": "optical_acceleration_cancellation"}, {"score": 0.003689628075766217, "phrase": "running_path"}, {"score": 0.003587616378156851, "phrase": "retinal_image"}, {"score": 0.00355009076716969, "phrase": "approaching_ball"}, {"score": 0.00329813918116714, "phrase": "oac_strategy"}, {"score": 0.0031845067058084613, "phrase": "sagittal_plane"}, {"score": 0.0030002172602367682, "phrase": "\"passive\"_algorithm"}, {"score": 0.0029069972482610403, "phrase": "camera_constant"}, {"score": 0.00275800486983114, "phrase": "\"active\"_algorithm"}, {"score": 0.0027005626126039204, "phrase": "camera_fixation"}, {"score": 0.0025531499687505483, "phrase": "camera_angle"}, {"score": 0.002456486927713543, "phrase": "active_algorithm"}, {"score": 0.0024307637980373552, "phrase": "computer_simulations"}, {"score": 0.002396883802324751, "phrase": "actual_mobile_robots"}, {"score": 0.002371783323468861, "phrase": "performance_advantage"}, {"score": 0.0023223663501882896, "phrase": "higher_gain"}, {"score": 0.0022187920251626257, "phrase": "ball_image"}, {"score": 0.0021422669204408263, "phrase": "human_perceptual_principles"}, {"score": 0.0021049977753042253, "phrase": "mobile_robot_algorithms"}], "paper_keywords": ["mobile robot navigation", " visual servoing", " perceptual principles"], "paper_abstract": "We examined human navigational principles for intercepting a projected object and tested their application in the design of navigational algorithms for mobile robots. These perceptual principles utilize a viewer-based geometry that allows the robot to approach the target without need of time-consuming calculations to determine the world coordinates of either itself or the target. Human research supports the use of an Optical Acceleration Cancellation (OAC) strategy to achieve interception. Here, the fielder selects a running path that nulls out the acceleration of the retinal image of an approaching ball, and maintains an image that rises at a constant rate throughout the task. We compare two robotic control algorithms for implementing the OAC strategy in cases in which the target remains in the sagittal plane headed directly toward the robot (which only moves forward or backward). In the \"passive\" algorithm, the robot keeps the orientation of the camera constant, and the image of the ball rises at a constant rate. In the \"active\" algorithm, the robot maintains a camera fixation that is centered on the image of the ball and keeps the tangent of the camera angle rising at a constant rate. Performance was superior with the active algorithm in both computer simulations and trials with actual mobile robots. The performance advantage is principally due to the higher gain and effectively wider viewing angle when the camera remains centered on the ball image. The findings confirm the viability and robustness of human perceptual principles in the design of mobile robot algorithms for tasks like interception.", "paper_title": "Mobile robot interception using human navigational principles: Comparison of active versus passive tracking algorithms", "paper_id": "WOS:000238858600004"}