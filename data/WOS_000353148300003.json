{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "tcd-timit"}, {"score": 0.004641351004344458, "phrase": "continuous_speech"}, {"score": 0.004598933498016774, "phrase": "automatic_audio-visual_speech_recognition"}, {"score": 0.00443308765153716, "phrase": "major_progress"}, {"score": 0.004157058883925715, "phrase": "suitable_research_corpora"}, {"score": 0.003988719758707836, "phrase": "new_corpus"}, {"score": 0.0039341294012600085, "phrase": "continuous_audio-visual_speech_recognition_research"}, {"score": 0.003809628721278519, "phrase": "high-quality_audio_and_video_footage"}, {"score": 0.003555902292752528, "phrase": "professionally-trained_lipspeakers"}, {"score": 0.003334309053314909, "phrase": "regular_speakers"}, {"score": 0.0033037970113095577, "phrase": "automatic_visual_speech_recognition_systems"}, {"score": 0.0025892330566358503, "phrase": "non-lipspeaker_data"}, {"score": 0.0025071862539276283, "phrase": "visual_and_audio-visual_baseline_results"}, {"score": 0.002214297250267208, "phrase": "publicly_available_database"}, {"score": 0.0021049977753042253, "phrase": "audio-visual_speech_recognition_research"}], "paper_keywords": ["Audio-visual speech recognition"], "paper_abstract": "Automatic audio-visual speech recognition currently lags behind its audio-only counterpart in terms of major progress. One of the reasons commonly cited by researchers is the scarcity of suitable research corpora. This paper details the creation of a new corpus designed for continuous audio-visual speech recognition research. TCD-TIMIT consists of high-quality audio and video footage of 62 speakers reading a total of 6913 phonetically rich sentences. Three of the speakers are professionally-trained lipspeakers, recorded to test the hypothesis that lipspeakers may have an advantage over regular speakers in automatic visual speech recognition systems. Video footage was recorded from two angles: straight on, and at. The paper outlines the recording of footage, and the required post-processing to yield video and audio clips for each sentence. Audio, visual, and joint audio-visual baseline experiments are reported. Separate experiments were run on the lipspeaker and non-lipspeaker data, and the results compared. Visual and audio-visual baseline results on the non-lipspeakers were low overall. Results on the lipspeakers were found to be significantly higher. It is hoped that as a publicly available database, TCD-TIMIT will now help further state of the art in audio-visual speech recognition research.", "paper_title": "TCD-TIMIT: An Audio-Visual Corpus of Continuous Speech", "paper_id": "WOS:000353148300003"}