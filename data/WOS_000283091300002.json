{"auto_keywords": [{"score": 0.031580847435344256, "phrase": "aspara"}, {"score": 0.004815340879031441, "phrase": "adaptive"}, {"score": 0.004715908063787721, "phrase": "distributed_heterogeneous_architectures"}, {"score": 0.004477083974172596, "phrase": "algorithmic_skeletons"}, {"score": 0.004339609346924681, "phrase": "parallel_computation"}, {"score": 0.004119762981892093, "phrase": "algorithmic_skeleton_concept"}, {"score": 0.0040771431404398855, "phrase": "structured_parallelism"}, {"score": 0.004014035333627087, "phrase": "high-level_parallel_programming_technique"}, {"score": 0.003870541730075597, "phrase": "parallel_programs"}, {"score": 0.0038106195546165574, "phrase": "platform_independence"}, {"score": 0.003771185758226876, "phrase": "algorithm_abstraction"}, {"score": 0.003598705020845104, "phrase": "skeletal_parallel_programming"}, {"score": 0.0035614563596982306, "phrase": "heterogeneous_distributed_systems"}, {"score": 0.0034700069041302003, "phrase": "resource_awareness"}, {"score": 0.003345895878114341, "phrase": "skeletal_program"}, {"score": 0.0032094634756436595, "phrase": "dynamic_resource_conditions"}, {"score": 0.0030625949549620475, "phrase": "adaptive_structured_parallelism"}, {"score": 0.0029376803941247084, "phrase": "generic_methodology"}, {"score": 0.0028921584725218642, "phrase": "structural_information"}, {"score": 0.0028178463431115562, "phrase": "parallel_program"}, {"score": 0.002360607691114015, "phrase": "independent_case_studies"}, {"score": 0.0021831803612759855, "phrase": "non-dedicated_heterogeneous_multi-cluster_system"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["structured parallelism", " algorithmic skeletons", " parallel patterns", " parallel programming", " concurrent programming structures", " cluster computing"], "paper_abstract": "Algorithmic skeletons abstract commonly used patterns of parallel computation, communication, and interaction. Based on the algorithmic skeleton concept, structured parallelism provides a high-level parallel programming technique that allows the conceptual description of parallel programs while fostering platform independence and algorithm abstraction. This work presents a methodology to improve skeletal parallel programming in heterogeneous distributed systems by introducing adaptivity through resource awareness. As we hypothesise that a skeletal program should be able to adapt to the dynamic resource conditions over time using its structural forecasting information, we have developed adaptive structured parallelism (ASPARA). ASPARA is a generic methodology to incorporate structural information at compilation into a parallel program, which will help it to adapt at execution. ASPARA comprises four phases: programming, compilation, calibration, and execution. We illustrate the feasibility of this approach and its associated performance improvements using independent case studies based on two algorithmic skeletons-the task farm and the pipeline-evaluated in a non-dedicated heterogeneous multi-cluster system. Copyright (C) 2010 John Wiley & Sons, Ltd.", "paper_title": "Adaptive structured parallelism for distributed heterogeneous architectures: a methodological approach with pipelines and farms", "paper_id": "WOS:000283091300002"}