{"auto_keywords": [{"score": 0.04890702046127258, "phrase": "global_illumination"}, {"score": 0.00481495049065317, "phrase": "guided_image_filtering"}, {"score": 0.004775335634705251, "phrase": "interactive_high-quality_global_illumination"}, {"score": 0.004736045157669388, "phrase": "interactive_computation"}, {"score": 0.0046392209103157936, "phrase": "major_challenge"}, {"score": 0.004601045179623499, "phrase": "current_computer_graphics_research"}, {"score": 0.00446987606516801, "phrase": "visual_quality"}, {"score": 0.00443308765153716, "phrase": "generated_images"}, {"score": 0.004324521292490181, "phrase": "key_attribute"}, {"score": 0.004236074477264561, "phrase": "photo-realistic_images"}, {"score": 0.004081385289516914, "phrase": "physical_behaviour"}, {"score": 0.004014452814186653, "phrase": "monte_carlo_techniques"}, {"score": 0.0039323225960857956, "phrase": "computational_burden"}, {"score": 0.0038518661517315533, "phrase": "interactive_rendering_times"}, {"score": 0.003820144626025562, "phrase": "standard_commodity_hardware"}, {"score": 0.0036958398682001015, "phrase": "monte_carlo_integration"}, {"score": 0.0036352070472201086, "phrase": "characteristic_noisy_images"}, {"score": 0.003590383760209319, "phrase": "filtering_methods"}, {"score": 0.003444912629614206, "phrase": "neighbouring_pixels"}, {"score": 0.003360464999544279, "phrase": "averaging_samples"}, {"score": 0.0033327768024847397, "phrase": "similar_characteristics"}, {"score": 0.0031582637043009562, "phrase": "visible_outliers"}, {"score": 0.003042812778470762, "phrase": "novel_path"}, {"score": 0.002968192753809507, "phrase": "edge-aware_filtering_method"}, {"score": 0.002883439044844259, "phrase": "visually_more_pleasing_results"}, {"score": 0.0028127163745564777, "phrase": "key_idea"}, {"score": 0.0027437235598539904, "phrase": "noisy_path"}, {"score": 0.0025999744005191713, "phrase": "second_image"}, {"score": 0.0025678829712650437, "phrase": "characteristic_scene_attributes"}, {"score": 0.0023540387251475615, "phrase": "previous_methods"}, {"score": 0.0022773309395419427, "phrase": "completely_inscreen-space"}, {"score": 0.0022214412809055013, "phrase": "fully_dynamic_scenes"}, {"score": 0.0021049977753042253, "phrase": "inter_active_frame_rates"}], "paper_keywords": [""], "paper_abstract": "Interactive computation of global illumination is a major challenge in current computer graphics research. Global illumination heavily affects the visual quality of generated images. It is therefore a key attribute for the perception of photo-realistic images. Path tracing is able to simulate the physical behaviour of light using Monte Carlo techniques. However, the computational burden of this technique prohibits interactive rendering times on standard commodity hardware in high-quality. Trying to solve the Monte Carlo integration with fewer samples results in characteristic noisy images. Global illumination filtering methods take advantage of the fact that the integral for neighbouring pixels may be very similar. Averaging samples of similar characteristics in screen-space may approximate the correct integral, but may result in visible outliers. In this paper,we present a novel path tracing pipeline based on an edge-aware filtering method for the indirect illumination which produces visually more pleasing results without noticeable outliers. The key idea is not to filter the noisy path traced images but to use it as a guidance to filter a second image composed from characteristic scene attributes that do not contain noise by default. We show that our approach better approximates the Monte Carlo integral compared to previous methods . Since the computation is carried out completely inscreen-space it is therefore applicable to fully dynamic scenes, arbitrary lighting and allows for high-quality path tracing at inter active frame rates on commodity hardware.", "paper_title": "Guided Image Filtering for Interactive High-quality Global Illumination", "paper_id": "WOS:000292884700022"}