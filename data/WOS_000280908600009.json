{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "illustrative_rendering"}, {"score": 0.004562362497952548, "phrase": "novel_framework"}, {"score": 0.004271490815763164, "phrase": "scientific_illustration"}, {"score": 0.0041703614123283165, "phrase": "traditional_scientific_illustrations"}, {"score": 0.003999089046152065, "phrase": "composition_stages"}, {"score": 0.003927848423072668, "phrase": "different_pictorial_elements"}, {"score": 0.0037664981403399064, "phrase": "layer_metaphor"}, {"score": 0.0035051129798529, "phrase": "new_compositing_approach"}, {"score": 0.0033812801309408514, "phrase": "selective_transparency"}, {"score": 0.0030904433394138963, "phrase": "common_manipulation_techniques"}, {"score": 0.0026760974046034854, "phrase": "single_viewpoint"}, {"score": 0.002612640527241776, "phrase": "presented_approach"}, {"score": 0.0025202582748972122, "phrase": "underlying_rendering_algorithms"}, {"score": 0.00240213106042981, "phrase": "polygonal_geometry"}, {"score": 0.002373472641477602, "phrase": "volumetric_data"}, {"score": 0.0023451553255837317, "phrase": "point-based_representations"}, {"score": 0.0022486729928886885, "phrase": "current_graphics_hardware"}, {"score": 0.0022085455097790537, "phrase": "real-time_interaction"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Compositing", " Masking", " Illustration"], "paper_abstract": "In this paper, we introduce a novel framework for the compositing of interactively rendered 3D layers tailored to the needs of scientific illustration. Currently, traditional scientific illustrations are produced in a series of composition stages, combining different pictorial elements using 2D digital layering. Our approach extends the layer metaphor into 3D without giving up the advantages of 2D methods. The new compositing approach allows for effects such as selective transparency, occlusion overrides, and soft depth buffering. Furthermore, we show how common manipulation techniques such as masking can be integrated into this concept. These tools behave just like in 2D, but their influence extends beyond a single viewpoint. Since the presented approach makes no assumptions about the underlying rendering algorithms, layers can be generated based on polygonal geometry, volumetric data, point-based representations, or others. Our implementation exploits current graphics hardware and permits real-time interaction and rendering. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Hybrid visibility compositing and masking for illustrative rendering", "paper_id": "WOS:000280908600009"}