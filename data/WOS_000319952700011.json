{"auto_keywords": [{"score": 0.03465088506029132, "phrase": "proposed_method"}, {"score": 0.014844994658644091, "phrase": "gbml"}, {"score": 0.01150339676164283, "phrase": "computational_cost"}, {"score": 0.00890719065796417, "phrase": "rule_population"}, {"score": 0.00481495049065317, "phrase": "genetic-based_machine_learning_systems"}, {"score": 0.004457388497044933, "phrase": "evolutionary_algorithms"}, {"score": 0.004386291308906104, "phrase": "search_mechanisms"}, {"score": 0.004344176114026701, "phrase": "rule-based_classification_models"}, {"score": 0.004193169496350484, "phrase": "pittsburgh-style_gbml"}, {"score": 0.0040343909885467485, "phrase": "standard_recombination_operators"}, {"score": 0.003944550453282929, "phrase": "effective_evolutionary_search"}, {"score": 0.003906660012576505, "phrase": "sophisticated_problems"}, {"score": 0.003869132124880576, "phrase": "strong_interactions"}, {"score": 0.00373457643282356, "phrase": "real-world_classification_tasks"}, {"score": 0.0035931003474699583, "phrase": "unnecessary_matchings"}, {"score": 0.0035700457562655246, "phrase": "gbml_systems"}, {"score": 0.003379939505148497, "phrase": "integrated_manner"}, {"score": 0.003347454359929038, "phrase": "new_pittsburgh-style_gbml_system"}, {"score": 0.0031589756301986763, "phrase": "high_level"}, {"score": 0.003098530474496842, "phrase": "rule-wise_uniform_crossover_operators"}, {"score": 0.0030294669203999565, "phrase": "variable-size_rule"}, {"score": 0.0029810774705309536, "phrase": "low_level"}, {"score": 0.002961938159281582, "phrase": "single_rules"}, {"score": 0.002895910285227502, "phrase": "sampling_bayesian_networks"}, {"score": 0.0028588411455879037, "phrase": "global_statistical_information"}, {"score": 0.002831350132465098, "phrase": "promising_rules"}, {"score": 0.0027416032255956585, "phrase": "statistical_information"}, {"score": 0.0026891227034884536, "phrase": "embedded_approach"}, {"score": 0.002629160426591144, "phrase": "redundant_features"}, {"score": 0.0025458060790109647, "phrase": "empirical_evaluation_show"}, {"score": 0.0024970641749396784, "phrase": "original_pittsburgh-style_gbml_system"}, {"score": 0.0022596753843232755, "phrase": "proposed_embedded_approach"}, {"score": 0.002209267746036577, "phrase": "higher_classification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Genetic-based machine learning systems", " Estimation of distribution algorithms", " Features reduction", " Evolutionary computation"], "paper_abstract": "Genetic-based machine learning (GBML) systems, which employ evolutionary algorithms (EAs) as search mechanisms, evolve rule-based classification models to represent target concepts. Compared to Michigan-style GBML, Pittsburgh-style GBML is expected to achieve more compact solutions. It has been shown that standard recombination operators in EAs do not assure an effective evolutionary search to solve sophisticated problems that contain strong interactions between features. On the other hand, when dealing with real-world classification tasks, irrelevant features not only complicate the problem but also incur unnecessary matchings in GBML systems, which increase the computational cost a lot. To handle the two problems mentioned above in an integrated manner, a new Pittsburgh-style GBML system is proposed. In the proposed method, classifiers are generated and recombined at two levels. At the high level, classifiers are recombined by rule-wise uniform crossover operators since each classifier consists of a variable-size rule set. At the low level, single rules contained in classifiers are reproduced via sampling Bayesian networks that characterize the global statistical information extracted from promising rules found so far. Furthermore, according to the statistical information in the rule population, an embedded approach is presented to detect and remove redundant features incrementally following the evolution of rule population. Results of empirical evaluation show that the proposed method outperforms the original Pittsburgh-style GBML system in terms of classification accuracy while reducing the computational cost. Furthermore, the proposed method is also competitive to other non-evolutionary, highly used machine learning methods. With respect to the performance of feature reduction, the proposed embedded approach is able to deliver solutions with higher classification accuracy when removing the same number of features as other feature reduction techniques do. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Effective search for genetic-based machine learning systems via estimation of distribution algorithms and embedded feature reduction techniques", "paper_id": "WOS:000319952700011"}