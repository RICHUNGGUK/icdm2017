{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "role-playing_game_strategy_decision_systems"}, {"score": 0.004734448316824488, "phrase": "role-playing_game"}, {"score": 0.004674952036988355, "phrase": "optimal_trajectories"}, {"score": 0.004463096299091981, "phrase": "strategy_decision_system"}, {"score": 0.004406994912939125, "phrase": "key_component"}, {"score": 0.004351595642056769, "phrase": "game_engine"}, {"score": 0.003999578057088828, "phrase": "consumed_resources"}, {"score": 0.003965975628742746, "phrase": "decision_making"}, {"score": 0.0037543106253910313, "phrase": "major_degree"}, {"score": 0.0037070855410818986, "phrase": "game_performance"}, {"score": 0.003660452313567116, "phrase": "classical_search_algorithms"}, {"score": 0.003378385493203297, "phrase": "precise_and_complete_models"}, {"score": 0.003335873298309004, "phrase": "search_space"}, {"score": 0.003144426503333397, "phrase": "model_free_methods"}, {"score": 0.003117986133774198, "phrase": "sequential_decision"}, {"score": 0.0030399874838260886, "phrase": "best_choice"}, {"score": 0.0029266219967426224, "phrase": "heuristic_planning_strategy"}, {"score": 0.002853396755102163, "phrase": "dyna_agent"}, {"score": 0.0027123819773059127, "phrase": "proposed_dyna-h_algorithm"}, {"score": 0.0023996317685956213, "phrase": "model-free_online_reinforcement_learning_algorithm"}, {"score": 0.0023100907305651872, "phrase": "one-step_q-learning"}, {"score": 0.0021590588269751816, "phrase": "clearly_superior_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Decision-making", " Path-finding", " Heuristic-search", " A-star", " Reinforcement-learning"], "paper_abstract": "In a role-playing game, finding optimal trajectories is one of the most important tasks. In fact, the strategy decision system becomes a key component of a game engine. Determining the way in which decisions are taken (e.g. online, batch or simulated) and the consumed resources in decision making (e.g. execution time, memory) will influence, to a major degree, the game performance. When classical search algorithms such as A* can be used, they are the very first option. Nevertheless, such methods rely on precise and complete models of the search space so there are many interesting scenarios where its application is not possible, and hence, model free methods for sequential decision making under uncertainty are the best choice. In this paper, we propose a heuristic planning strategy to incorporate, into a Dyna agent, the ability of heuristic-search in path-finding. The proposed Dyna-H algorithm selects branches more likely to produce outcomes than other branches, just as A* does. However, unlike A*, it has the advantages of a model-free online reinforcement learning algorithm. We evaluate our proposed algorithm against the one-step Q-learning and Dyna-Q algorithms and found that the Dyna-H, with its advantages, produced clearly superior results. (c) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Dyna-H: A heuristic planning reinforcement learning algorithm applied to role-playing game strategy decision systems", "paper_id": "WOS:000305722900004"}