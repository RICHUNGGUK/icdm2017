{"auto_keywords": [{"score": 0.04263916161140362, "phrase": "data_samples"}, {"score": 0.00481495049065317, "phrase": "nu-tube_support_vector_regression"}, {"score": 0.004632039024076267, "phrase": "small_width"}, {"score": 0.004427366754240748, "phrase": "training_data_samples"}, {"score": 0.004342430078306461, "phrase": "robust_way"}, {"score": 0.0038908817250961633, "phrase": "direct_influence"}, {"score": 0.003742941972172613, "phrase": "well-known_nu-tube"}, {"score": 0.003486123304074186, "phrase": "effective_method"}, {"score": 0.002427035025924384, "phrase": "effective_way"}, {"score": 0.0023650305205893353, "phrase": "skewed_noise"}, {"score": 0.0023346234464901978, "phrase": "regression_problems"}, {"score": 0.002304606411453748, "phrase": "numerical_experiments"}, {"score": 0.002260301305523054, "phrase": "computational_efficacy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Robust regression", " nu-tube support vector regression", " Asymmetric loss", " Quantile regression"], "paper_abstract": "Finding a tube of small width that covers a certain percentage of the training data samples is a robust way to estimate a location: the values of the data samples falling outside the tube have no direct influence on the estimate. The well-known nu-tube Support Vector Regression (nu-SVR) is an effective method for implementing this idea in the context of covariates. However, the nu-SVR considers only one possible location of this tube: it imposes that the amount of data samples above and below the tube are equal. The method is generalized such that those outliers can be divided asymmetrically over both regions. This extension gives an effective way to deal with skewed noise in regression problems. Numerical experiments illustrate the computational efficacy of this extension to the nu-SVR. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Asymmetric nu-tube support vector regression", "paper_id": "WOS:000337869500026"}