{"auto_keywords": [{"score": 0.045171522171843934, "phrase": "stacking"}, {"score": 0.00481495049065317, "phrase": "novel_method"}, {"score": 0.004589763483242731, "phrase": "weighted_combination"}, {"score": 0.004271490815763164, "phrase": "based_methods"}, {"score": 0.0041703614123283165, "phrase": "regression_problems"}, {"score": 0.003927848423072668, "phrase": "major_computational_overhead"}, {"score": 0.003053598205821532, "phrase": "individual_stacking_methods"}, {"score": 0.002910545717767559, "phrase": "different_data_sets"}, {"score": 0.0024901940672239784, "phrase": "empirical_analysis"}], "paper_keywords": ["Ensemble learning", " meta learning", " regression"], "paper_abstract": "In this paper we present a novel method that forms a weighted combination of a range of Stacking based methods for regression problems, without adding any major computational overhead in comparison to stacking itself. The intention of the technique is to benefit from the variation in performance of individual Stacking methods as demonstrated with different data sets, in order to provide a more robust technique overall. We detail an empirical analysis of the technique referred to as weighted Meta-Combiner (wMetaComb) and compare its performance to its underlying techniques.", "paper_title": "A WEIGHTED COMBINER OF STACKING BASED METHODS", "paper_id": "WOS:000313370300010"}