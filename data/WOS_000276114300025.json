{"auto_keywords": [{"score": 0.04366536734234884, "phrase": "different_expertise_levels"}, {"score": 0.00481495049065317, "phrase": "dynamic_multi-representational_learning_environments"}, {"score": 0.0045765783794477505, "phrase": "important_form"}, {"score": 0.004431041346291019, "phrase": "complex_multimedia_materials"}, {"score": 0.004231089088705995, "phrase": "self-explaining_prompt_formats"}, {"score": 0.003966162568548304, "phrase": "dynamic_multi-representational_materials"}, {"score": 0.0036496814103475174, "phrase": "reasoning-based_prompts"}, {"score": 0.0035335154419206634, "phrase": "action_run"}, {"score": 0.0034368818187904744, "phrase": "predicting-based_prompts"}, {"score": 0.0033274664434575136, "phrase": "upcoming_action"}, {"score": 0.003118942369691329, "phrase": "wrong_prediction"}, {"score": 0.0030617935728586006, "phrase": "multiple_indicators"}, {"score": 0.002991823455621222, "phrase": "cognitive_load_demand"}, {"score": 0.0028172726995962173, "phrase": "prompts'_effects"}, {"score": 0.002396179086883187, "phrase": "learning_effects"}, {"score": 0.0022878396720586044, "phrase": "learner_expertise"}, {"score": 0.002164264600379492, "phrase": "adaptive_self-explaining_prompt_design"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Self-explanation", " Expertise reversal effect", " Cognitive load theory", " Computer-based learning", " Data structures"], "paper_abstract": "Self-explanation prompts are considered to be an important form of scaffolding in the comprehension of complex multimedia materials. However, there is little theoretical understanding to date of self-explaining prompt formats tailored to different expertise levels of learners to help them fully exploit the advantages of dynamic multi-representational materials. To address this issue, this study designed two types of self-explaining prompts: the reasoning-based prompts asked the learners to reason the action run of the animation; the predicting-based prompts asked the learners to predict the upcoming action of the animation, and then asked for reasoning if they made a wrong prediction. Furthermore, multiple indicators including learning outcome, cognitive load demand, learning time, and learning efficiency were used to interpret the prompts' effects on different expertise levels of learners. A total of 244 undergraduate students were randomly assigned to one of the three conditions: a control and two different self-explaining prompt conditions. The results indicate that the learning effects of self-explaining prompts depend on levels of learner expertise. Based on the results, this study makes recommendations for adaptive self-explaining prompt design. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Optimal self-explanation prompt design in dynamic multi-representational learning environments", "paper_id": "WOS:000276114300025"}