{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "research_tools"}, {"score": 0.004608997772926119, "phrase": "clone_detection"}, {"score": 0.004548939310612501, "phrase": "research_technique"}, {"score": 0.0044896599221451216, "phrase": "software_systems"}, {"score": 0.004354315061804687, "phrase": "software_understanding"}, {"score": 0.0042415434489566995, "phrase": "license_enforcement"}, {"score": 0.004149792080414689, "phrase": "nicad_near-miss_clone_detection_method"}, {"score": 0.004042295865725559, "phrase": "highly_accurate_results"}, {"score": 0.003818807671883534, "phrase": "parsing_first_step"}, {"score": 0.0037361664435836845, "phrase": "code_fragments"}, {"score": 0.0036553070575015344, "phrase": "text_line-based_second_step"}, {"score": 0.0032908057622663732, "phrase": "large_scale_research_applications"}, {"score": 0.0032054891061528896, "phrase": "nicad_tool"}, {"score": 0.0030017207229983385, "phrase": "initial_rapid_prototype"}, {"score": 0.002962543869356265, "phrase": "practical_scalable_research_tool"}, {"score": 0.0028857130140890787, "phrase": "overall_performance"}, {"score": 0.00266693888510356, "phrase": "memory_and_processor_requirements"}, {"score": 0.0026091594819333654, "phrase": "standard_laptop"}, {"score": 0.002508284945907166, "phrase": "performance_optimizations"}, {"score": 0.0022777800735119405, "phrase": "research_prototype"}, {"score": 0.0022579036318895753, "phrase": "production_performance"}, {"score": 0.0021610874773389096, "phrase": "similar_problem"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Clone detection", " Longest common subsequence", " Optimization", " NiCad"], "paper_abstract": "Clone detection is a research technique for analyzing software systems for similarities, with applications in software understanding, maintenance, evolution, license enforcement and many other issues. The NiCad near-miss clone detection method has been shown to yield highly accurate results in both precision and recall. However, its naive two-step method, involving a parsing first step to identify and normalize code fragments, followed by a text line-based second step using longest common subsequence (LCS) to compare fragments, has proven difficult to migrate to the efficiency and scalability required for large scale research applications. Rather than presenting the NiCad tool itself in detail, this paper focuses on our experience in migrating NiCad from an initial rapid prototype to a practical scalable research tool. The process has increased overall performance by a factor of up to 40 and clone detection speed by a factor of over 400, while reducing memory and processor requirements to fit on a standard laptop. We apply a sequence of four different kinds of performance optimizations and analyze the effect of each optimization in detail. We believe that the lessons of our experience in migrating NiCad from research prototype to production performance may be beneficial to others who are facing a similar problem. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Tuning research tools for scalability and performance: The NiCad experience", "paper_id": "WOS:000326556300012"}