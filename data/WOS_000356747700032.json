{"auto_keywords": [{"score": 0.04119507495012033, "phrase": "depth_images"}, {"score": 0.01134606326320356, "phrase": "rgb_images"}, {"score": 0.004816845528402785, "phrase": "subset"}, {"score": 0.004721602309430702, "phrase": "rgb-d_object_recognition"}, {"score": 0.00468476935399643, "phrase": "rgb-d_camera"}, {"score": 0.004504850679320975, "phrase": "previous_works"}, {"score": 0.0043148760739240575, "phrase": "rgb-d_based_object_recognition_accuracy"}, {"score": 0.0041981583430961734, "phrase": "new_method"}, {"score": 0.0041328796505374155, "phrase": "subset_approach"}, {"score": 0.004052701031142039, "phrase": "higher_level_features"}, {"score": 0.004005339423663657, "phrase": "raw_data"}, {"score": 0.003958529104387973, "phrase": "raw_rgb"}, {"score": 0.003561017335579207, "phrase": "rgb-subset-sparse_auto-encoder"}, {"score": 0.003424107910734022, "phrase": "depth-subset-sparse_auto-encoder"}, {"score": 0.003241203549050267, "phrase": "learned_features"}, {"score": 0.0031907572162427978, "phrase": "recursive_neural_networks"}, {"score": 0.0030321497870310077, "phrase": "robust_hierarchical_feature_representations"}, {"score": 0.0029966788947444535, "phrase": "feature_representations"}, {"score": 0.002881403688962202, "phrase": "final_features"}, {"score": 0.0028143720888311537, "phrase": "softmax_classifier"}, {"score": 0.0027597018725736165, "phrase": "proposed_method"}, {"score": 0.002695495637232689, "phrase": "rgb-d"}, {"score": 0.0026639507068734907, "phrase": "lai_et_al"}, {"score": 0.0026019646284747024, "phrase": "browatzki_et_al"}, {"score": 0.0025715131759585052, "phrase": "aharon_dataset"}, {"score": 0.002551409948440577, "phrase": "aharon_et_al"}, {"score": 0.002250272652754455, "phrase": "extra_experiments"}, {"score": 0.0022152149658434916, "phrase": "subsets_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["RGB-D object recognition", " Subset based feature extracting", " Sparse auto-encoder", " Recursive neural networks", " Deep learning"], "paper_abstract": "RGB-D camera can easily record both color and depth images and previous works have proved that combining them together could dramatically improve the RGB-D based object recognition accuracy. In this paper, a new method based on a subset approach was introduced to learn higher level features from the raw data. The raw RGB and depth images were divided into several subsets according to their shapes and colors, guaranteeing that any two different objects in each subset are nearly not similar. Then a RGB-Subset-Sparse auto-encoder was trained to extract features from RGB images and a Depth-Subset-Sparse auto-encoder was trained to extract features from depth images for each subset. Then the learned features were transmitted to recursive neural networks (RNNs) to reduce the dimensionality of the features and learn robust hierarchical feature representations. The feature representations learned from RGB images and depth images were concatenated as the final features and then sent to a softmax classifier for classification. The proposed method is evaluated on three benchmark RGB-D datasets, RGB-D dataset of Lai et al., 2D3D dataset of Browatzki et al. and Aharon dataset of Aharon et al. Compared with other methods, ours achieves state-of-the-art performance on the first two datasets. Furthermore, to validate the generalization of our subset approach, we also do some extra experiments of applying the subsets approach to several previous works, these accuracies improved significantly. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Subset based deep learning for RGB-D object recognition", "paper_id": "WOS:000356747700032"}