{"auto_keywords": [{"score": 0.04931727328027492, "phrase": "eye_gaze"}, {"score": 0.00481495049065317, "phrase": "ict_device_control"}, {"score": 0.004515655183335171, "phrase": "computer_method"}, {"score": 0.00426900754050533, "phrase": "limited_mobility"}, {"score": 0.004035777314816881, "phrase": "ict_devices"}, {"score": 0.0038152404172111815, "phrase": "user's_eye_gaze"}, {"score": 0.003549245218355768, "phrase": "ict_device"}, {"score": 0.002722634472231842, "phrase": "suitable_interface"}, {"score": 0.0023940274498526213, "phrase": "state-of-the-art_technology"}, {"score": 0.002244876254113051, "phrase": "able_bodied_people"}], "paper_keywords": [""], "paper_abstract": "This paper presents a computer method to help people, typically having limited mobility, to be able to operate ICT devices with eye gaze in their living/work environment. The user's eye gaze is recorded and analyzed in real-time. Any ICT device in the environment that is being looked at for a certain time period is identified, located and assumed to be the object of interest that the user wants to utilise. Through a suitable interface, the user can then decide whether to operate the device. By using this state-of-the-art technology, people with impaired mobility, or able bodied people whose movements are restricted can attain a more independent life style.", "paper_title": "Helping people with ICT device control by eye gaze", "paper_id": "WOS:000239519000072"}