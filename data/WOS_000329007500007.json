{"auto_keywords": [{"score": 0.043616210216916355, "phrase": "hpc"}, {"score": 0.00481495049065317, "phrase": "extreme-scale_computing"}, {"score": 0.004392565073466714, "phrase": "future_large-scale_systems"}, {"score": 0.004223032986655664, "phrase": "dominant_fault_tolerance_mechanism"}, {"score": 0.0040334640350288, "phrase": "checkpoint_performance"}, {"score": 0.003852371777780562, "phrase": "nearly_all_capability_applications"}, {"score": 0.003802135020791801, "phrase": "custom_checkpoint_strategies"}, {"score": 0.0036553070575015344, "phrase": "checkpoint_time"}, {"score": 0.0034911335714333507, "phrase": "incremental_checkpointing"}, {"score": 0.003334309053314909, "phrase": "known_limitations"}, {"score": 0.002943147037670826, "phrase": "page_protection"}, {"score": 0.0027741761880779535, "phrase": "application_data"}, {"score": 0.00268452026617243, "phrase": "real_capability_workloads"}, {"score": 0.002547043222086858, "phrase": "application_efficiency_increase"}, {"score": 0.002416589459425828, "phrase": "hash-based_incremental_checkpointing"}, {"score": 0.0023694065215394593, "phrase": "significantly_lower_overheads"}, {"score": 0.0023384629381463054, "phrase": "increased_efficiency"}, {"score": 0.0023079225317714815, "phrase": "traditional_coordinated_checkpointing_approaches"}, {"score": 0.002218668420806254, "phrase": "future_extreme-class_systems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Fault-tolerance", " Checkpointing", " Incremental checkpointing", " Graphics processing units"], "paper_abstract": "Concern is beginning to grow in the high-performance computing (HPC) community regarding the reliability of future large-scale systems. Disk-based coordinated checkpoint/restart has been the dominant fault tolerance mechanism in HPC systems for the past 30 years. Checkpoint performance is so fundamental to scalability that nearly all capability applications have custom checkpoint strategies to minimize state and reduce checkpoint time. One well-known optimization to traditional checkpoint/restart is incremental checkpointing, which has a number of known limitations. To address these limitations, we describe libhashckpt, a hybrid incremental checkpointing solution that uses both page protection and hashing on GPUs to determine changes in application data with very low overhead. Using real capability workloads and a model outlining the viability and application efficiency increase of this technique, we show that hash-based incremental checkpointing can have significantly lower overheads and increased efficiency than traditional coordinated checkpointing approaches at the scales expected for future extreme-class systems. (C) 2013 Published by Elsevier B.V.", "paper_title": "Accelerating incremental checkpointing for extreme-scale computing", "paper_id": "WOS:000329007500007"}