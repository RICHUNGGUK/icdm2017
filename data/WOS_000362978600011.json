{"auto_keywords": [{"score": 0.04810005512165039, "phrase": "smvp"}, {"score": 0.04729777405587172, "phrase": "smtvp"}, {"score": 0.019676110255679946, "phrase": "csb"}, {"score": 0.004815072515226682, "phrase": "gpu"}, {"score": 0.004781215097314411, "phrase": "sparse_matrix-vector_multiplication"}, {"score": 0.004747714939490445, "phrase": "sparse_matrix-transpose_vector_multiplication"}, {"score": 0.004648609688625397, "phrase": "sparse_matrix-vector_product"}, {"score": 0.004567596860086148, "phrase": "sparse_matrix-transpose_vector_product"}, {"score": 0.004487989502479992, "phrase": "better_overall_performance"}, {"score": 0.004317682099870507, "phrase": "similarly_high_throughput"}, {"score": 0.004227515355865597, "phrase": "underlying_sparse_matrix"}, {"score": 0.004168448339217754, "phrase": "single_storage_format"}, {"score": 0.003996133359116611, "phrase": "buluc_et_al"}, {"score": 0.0038989120088094185, "phrase": "multi-core_cpus"}, {"score": 0.0038715697646612766, "phrase": "nearly_identical_throughputs"}, {"score": 0.0037773674108196376, "phrase": "direct_porting"}, {"score": 0.003724566354526513, "phrase": "graphics_processing_units"}, {"score": 0.0035705347414368696, "phrase": "powerful_general_purpose_computing_platform"}, {"score": 0.0033868916699805224, "phrase": "new_data_structure"}, {"score": 0.003235367401211807, "phrase": "throughput_gap"}, {"score": 0.0030689098754563982, "phrase": "high_computing_throughput"}, {"score": 0.0030047427137652218, "phrase": "hybrid_storage_format"}, {"score": 0.00284009509859163, "phrase": "experimental_results"}, {"score": 0.002800358658581207, "phrase": "proposed_techniques"}, {"score": 0.002761176640988626, "phrase": "kepler_gpu"}, {"score": 0.0027417911324611917, "phrase": "similar_throughput"}, {"score": 0.0025642664420937327, "phrase": "cpu-based_csb_implementation"}, {"score": 0.0024929933447362554, "phrase": "previous_gpu_results"}, {"score": 0.0023151639346874883, "phrase": "wall-clock_time"}, {"score": 0.002298902547676131, "phrase": "bi-conjugate_gradient_algorithm"}, {"score": 0.002234988641498543, "phrase": "compressed_sparse_rows"}, {"score": 0.0022192989456794013, "phrase": "csr"}, {"score": 0.002172848441928838, "phrase": "hyb"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["sparse matrix-transpose vector product", " sparse matrix-vector product", " compressed sparse block", " CSB", " compressed sparse rows", " CSR", " GPU"], "paper_abstract": "Many high performance computing applications require computing both sparse matrix-vector product (SMVP) and sparse matrix-transpose vector product (SMTVP) for better overall performance. Under such a circumstance, it is critical to maintain a similarly high throughput for these two computing patterns with the underlying sparse matrix encoded in a single storage format. The compressed sparse block (CSB) format proposed by Buluc et al. allows computing both problems on multi-core CPUs with nearly identical throughputs. On the other hand, a direct porting of CSB to graphics processing units (GPUs), which have been recently recognized as a powerful general purpose computing platform, turns out to be inefficient. In this work, we propose a new data structure, designated as expanded CSB (eCSB), to minimize the throughput gap between SMVP and SMTVP computations on GPUs, while at the same time enable a high computing throughput. We also use a hybrid storage format to store elements in each block, which can be selected dynamically at runtime. Experimental results show that the proposed techniques implemented on a Kepler GPU delivers similar throughput on both SMVP and SMTVP and the throughput is up to 13 times faster than that of the CPU-based CSB implementation. In addition, our eCSB procedure outperforms the previous GPU results by up to 188% and 914% in computing SMVP and SMTVP, and we validate the effectiveness of eCSB by means of wall-clock time of bi-conjugate gradient algorithm; our eCSB is 25% faster than Compressed Sparse Rows (CSR) and 6% faster than HYB, respectively. Copyright (C) 2014 John Wiley & Sons, Ltd.", "paper_title": "GPU accelerated sparse matrix-vector multiplication and sparse matrix-transpose vector multiplication", "paper_id": "WOS:000362978600011"}