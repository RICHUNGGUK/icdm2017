{"auto_keywords": [{"score": 0.049604883316905664, "phrase": "virtual_agents"}, {"score": 0.00481495049065317, "phrase": "video_surveillance_footage"}, {"score": 0.004720043307726269, "phrase": "incremental_event_evaluation"}, {"score": 0.004513255056769647, "phrase": "behavior_analysis_demand"}, {"score": 0.004446349752828045, "phrase": "video_resources"}, {"score": 0.004315487055548749, "phrase": "scalable_manner"}, {"score": 0.004209369306023422, "phrase": "crowded_environments"}, {"score": 0.004126349202545883, "phrase": "high_semantics"}, {"score": 0.0040449598280454645, "phrase": "existing_public_databases"}, {"score": 0.003906357144047631, "phrase": "appearing_agents"}, {"score": 0.0037537380967196123, "phrase": "long-term_occlusions"}, {"score": 0.0034660938095219846, "phrase": "specific_needs"}, {"score": 0.003380791705551809, "phrase": "augmented_reality_framework"}, {"score": 0.003281186608301359, "phrase": "image_sequences"}, {"score": 0.003121636289442593, "phrase": "scalable_and_controllable_manner"}, {"score": 0.00299958349498286, "phrase": "augmented_sequences"}, {"score": 0.0027148677103585985, "phrase": "behavior_recognition"}, {"score": 0.0026086775334428617, "phrase": "desired_contents"}, {"score": 0.002544422946205545, "phrase": "natural_language_interface"}, {"score": 0.0025066304722422463, "phrase": "input_sentences"}, {"score": 0.002481747081849503, "phrase": "virtual_agent_behaviors"}, {"score": 0.0024571101010891347, "phrase": "experimental_tests"}, {"score": 0.0023727863021828547, "phrase": "soccer_environments"}, {"score": 0.002268598551466928, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Human behavior analysis", " Smart video surveillance", " Benchmarking", " Ontologies"], "paper_abstract": "The fields of segmentation, tracking and behavior analysis demand for challenging video resources to test, in a scalable manner, complex scenarios like crowded environments or scenes with high semantics. Nevertheless, existing public databases cannot scale the presence of appearing agents, which would be useful to study long-term occlusions and crowds. Moreover, creating these resources is expensive and often too particularized to specific needs. We propose an augmented reality framework to increase the complexity of image sequences in terms of occlusions and crowds, in a scalable and controllable manner. Existing datasets can be increased with augmented sequences containing virtual agents. Such sequences are automatically annotated, thus facilitating evaluation in terms of segmentation, tracking, and behavior recognition. In order to easily specify the desired contents, we propose a natural language interface to convert input sentences into virtual agent behaviors. Experimental tests and validation in indoor, street, and soccer environments are provided to show the feasibility of the proposed approach in terms of robustness, scalability, and semantics. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Augmenting video surveillance footage with virtual agents for incremental event evaluation", "paper_id": "WOS:000288922200015"}