{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multiple_labels"}, {"score": 0.015364937444782074, "phrase": "multi-label_learning"}, {"score": 0.004748740786945996, "phrase": "generative_probabilistic_model"}, {"score": 0.004555499634179394, "phrase": "considerable_surge"}, {"score": 0.004451546786101008, "phrase": "multi-label_learning_problem"}, {"score": 0.004290112502811656, "phrase": "key_factor"}, {"score": 0.004231089088705995, "phrase": "successful_multi-label_learning_algorithm"}, {"score": 0.003966162568548304, "phrase": "previous_work"}, {"score": 0.003929689573550262, "phrase": "label_relations"}, {"score": 0.0038756055612167942, "phrase": "pairwise_relations"}, {"score": 0.0037177622939493084, "phrase": "intrinsic_correlations"}, {"score": 0.0035335154419206634, "phrase": "generative_model"}, {"score": 0.002991823455621222, "phrase": "proposed_model"}, {"score": 0.002936997013291548, "phrase": "training_data"}, {"score": 0.0027784560880013886, "phrase": "test_data"}, {"score": 0.0026899455459275575, "phrase": "pruned_gibbs_sampling_algorithm"}, {"score": 0.002652878591019016, "phrase": "test_stage"}, {"score": 0.0026042472337367015, "phrase": "inference_time"}, {"score": 0.0025565050791036973, "phrase": "extensive_experiments"}, {"score": 0.0023741093119014436, "phrase": "significant_improvements"}, {"score": 0.0023305762840188145, "phrase": "labeled_lda"}, {"score": 0.0021843879253500894, "phrase": "computational_efficiency"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multi-label learning", " Ranking", " Label correlation", " Generative model"], "paper_abstract": "Recent years have witnessed a considerable surge of interest in the multi-label learning problem. It has been shown that a key factor for a successful multi-label learning algorithm is to effectively exploit relations between labels. However, most of the previous work exploiting label relations focuses on pairwise relations. To handle the situations where there are intrinsic correlations among multiple labels, in this paper, we propose a generative model, Labeled Four-Level Pachinko Allocation Model (L-F-L-PAM), to capture correlations among multiple labels. In our approach of multi-label learning on text data, we apply the proposed model for inferring the training data and the standard Four-Level Pachinko Allocation Model for the test data. Furthermore, we propose a pruned Gibbs Sampling algorithm in the test stage to reduce the inference time. Finally, extensive experiments have been performed to validate the effectiveness and efficiency of our new approach. The results demonstrate significant improvements of our model over Labeled LDA (L-LDA) and superiority in terms of both effectiveness and computational efficiency over other high-performing multi-label learning methods. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Capturing correlations of multiple labels: A generative probabilistic model for multi-label learning", "paper_id": "WOS:000305659800014"}