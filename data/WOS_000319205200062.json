{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "distributed"}, {"score": 0.0047288446833200545, "phrase": "lamarckian"}, {"score": 0.004615375342240406, "phrase": "baldwinian"}, {"score": 0.004456044928556639, "phrase": "population-based_optimizer"}, {"score": 0.004188198923320451, "phrase": "global_search"}, {"score": 0.004145143433523008, "phrase": "numerical_robustness"}, {"score": 0.0036616109902631293, "phrase": "distributed_way"}, {"score": 0.003405948098114941, "phrase": "lamarckian_learning"}, {"score": 0.003370907075333389, "phrase": "baldwinian_learning"}, {"score": 0.00330189927527898, "phrase": "proposed_algorithm"}, {"score": 0.0032510690712452147, "phrase": "whole_population"}, {"score": 0.0031193028729331667, "phrase": "von_neumann_topology"}, {"score": 0.0030083825666563898, "phrase": "better_tradeoff"}, {"score": 0.0029013950320185573, "phrase": "differential_evolution"}, {"score": 0.0028567126120064546, "phrase": "evolutionary_frame"}, {"score": 0.0027837615811247963, "phrase": "hooke-jeeves_algorithm"}, {"score": 0.002740885774408238, "phrase": "powerful_local_search_ability"}, {"score": 0.002670884656785558, "phrase": "lamarckian_learning_and_baldwinian_learning_by_analyzing_their_characteristics_in_the_process_of_migration_among_subpopulations_as_well_as_in_the_hybridization_of_de_and_hooke-jeeves_local_search"}, {"score": 0.0024438487159093836, "phrase": "elsevier"}, {"score": 0.0023225701080913388, "phrase": "excellent_performance"}, {"score": 0.0022749744354271816, "phrase": "solution_quality"}, {"score": 0.002251542790734307, "phrase": "convergence_speed"}, {"score": 0.0022168460543913787, "phrase": "test_problems"}], "paper_keywords": ["Distributed differential evolution", " Memetic algorithm", " Lamarckian learning", " Baldwinian learning", " Hooke-Jeeves algorithm"], "paper_abstract": "As a population-based optimizer, the differential evolution (DE) algorithm has a very good reputation for its competence in global search and numerical robustness. In view of the fact that each member of the population is evaluated individually, DE can be easily parallelized in a distributed way. This paper proposes a novel distributed memetic differential evolution algorithm which integrates Lamarckian learning and Baldwinian learning. In the proposed algorithm, the whole population is divided into several subpopulations according to the von Neumann topology. In order to achieve a better tradeoff between exploration and exploitation, the differential evolution as an evolutionary frame is assisted by the Hooke-Jeeves algorithm which has powerful local search ability. We incorporate the Lamarckian learning and Baldwinian learning by analyzing their characteristics in the process of migration among subpopulations as well as in the hybridization of DE and Hooke-Jeeves local search. The proposed algorithm was run on a set of classic benchmark functions and compared with several state-of-the-art distributed DE schemes. Numerical results show that the proposed algorithm has excellent performance in terms of solution quality and convergence speed for all test problems given in this study. (C) 2012 Elsevier B. V. All rights reserved.", "paper_title": "Distributed memetic differential evolution with the synergy of Lamarckian and Baldwinian learning", "paper_id": "WOS:000319205200062"}