{"auto_keywords": [{"score": 0.04572578451187989, "phrase": "surviving_disks"}, {"score": 0.01365032514295226, "phrase": "spare_disk"}, {"score": 0.012287990200691006, "phrase": "rebuild_time"}, {"score": 0.004745056850725867, "phrase": "single_disk_failures"}, {"score": 0.004591466267316524, "phrase": "requested_block"}, {"score": 0.004541377162789232, "phrase": "failed_disk"}, {"score": 0.0044104497301196794, "phrase": "increased_loads"}, {"score": 0.004236539316738291, "phrase": "normal_mode_operation"}, {"score": 0.004099340908974491, "phrase": "rebuild_process"}, {"score": 0.004054598617367474, "phrase": "successive_disk_tracks"}, {"score": 0.0039665679106594106, "phrase": "lost_tracks"}, {"score": 0.003659768899837118, "phrase": "single_disk_failure"}, {"score": 0.0036065830625093883, "phrase": "data_loss"}, {"score": 0.0035671997165370403, "phrase": "second_disk"}, {"score": 0.003489714006817602, "phrase": "vacationing_server_model"}, {"score": 0.0034139056533151, "phrase": "read_requests"}, {"score": 0.0033397385936467204, "phrase": "lower_priority"}, {"score": 0.003315374849824563, "phrase": "external_user_requests"}, {"score": 0.0031728680535262083, "phrase": "disk_loads"}, {"score": 0.0028323704970618395, "phrase": "vsm"}, {"score": 0.002680932410366204, "phrase": "previous_analysis"}, {"score": 0.002575042977852052, "phrase": "disk_zoning"}, {"score": 0.0025098414374397308, "phrase": "heuristic_method"}, {"score": 0.002401875938287542, "phrase": "new_analysis"}, {"score": 0.0022158306933307685, "phrase": "design_tradeoff_studies"}, {"score": 0.0021049977753042253, "phrase": "detailed_simulation_results"}], "paper_keywords": ["disk arrays", " RAID5", " rebuild processing", " rebuild time", " M/G/1 queueing system", " vacationing server model", " zoned disks"], "paper_abstract": "RAID5 tolerates single disk failures by exclusive-ORing (XORing) the blocks corresponding to a requested block on the failed disk to reconstruct it. This results in increased loads on surviving disks and degraded disk response times with respect to normal mode operation. Provided a spare disk is available, a rebuild process systematically reads successive disk tracks, XORs them to recreate lost tracks and writes them onto a spare disk, thus returning the system to its original state. Rebuild time is important since RAID5 disk arrays with a single disk failure are susceptible to data loss if a second disk fails. According to the vacationing server model (VSM), rebuild read requests on surviving disks are given a lower priority than external user requests, so as to have less impact on their response time. Given that disk loads are balanced due to striping, rebuild time can be approximated by the time to read the contents of any one of the surviving disks. The analysis of the M/G/1 queueing model of VSM, given in this article, is more accurate and yet simpler than a previous analysis, but it also takes into account the effect of disk zoning explicitly. We also present a heuristic method to estimate rebuild time, which can be combined with the new analysis. The ability to quickly and accurately estimate rebuild time is useful in computing the reliability of RAID5 systems, especially during design tradeoff studies. The accuracy of the various analyses to estimate rebuild time are checked against detailed simulation results.", "paper_title": "Analysis of rebuild processing in RAID5 disk arrays", "paper_id": "WOS:000244840100009"}