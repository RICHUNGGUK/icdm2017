{"auto_keywords": [{"score": 0.04714419941447486, "phrase": "alice"}, {"score": 0.046910204846572455, "phrase": "bob"}, {"score": 0.004730543931242763, "phrase": "finite_nonempty_sets"}, {"score": 0.004566123591480369, "phrase": "communication_protocols"}, {"score": 0.004429727701202369, "phrase": "y._alice"}, {"score": 0.0038352452380298464, "phrase": "shared_random_string"}, {"score": 0.0036460731590599645, "phrase": "expected_number"}, {"score": 0.0032373188881118452, "phrase": "worst_case_communication"}, {"score": 0.0031404908484224626, "phrase": "average_number"}, {"score": 0.0030775481952377017, "phrase": "worst_case_x"}, {"score": 0.003038849308602444, "phrase": "x._we"}, {"score": 0.0029035072519058925, "phrase": "channel_e"}, {"score": 0.002697985402593072, "phrase": "required_communication"}, {"score": 0.002519703390732195, "phrase": "first_result"}, {"score": 0.002488001663771768, "phrase": "direct-sum_theorem"}, {"score": 0.0024381044087411975, "phrase": "previous_such_result"}, {"score": 0.0024196917282238274, "phrase": "jain"}, {"score": 0.0024074354450099715, "phrase": "radhakrishnan"}, {"score": 0.0022943233255875517, "phrase": "computer_science"}, {"score": 0.002169968849836984, "phrase": "rejection_sampling_procedure"}, {"score": 0.0021480924850273806, "phrase": "relative_entropy"}, {"score": 0.002121056250381627, "phrase": "communication_complexity"}], "paper_keywords": ["Communication complexity", " direct sum", " mutual information", " rejection sampling", " relative entropy"], "paper_abstract": "Let X and Y be finite nonempty sets and (X, Y) a pair of random variables taking values in X x Y. We consider communication protocols between two parties, ALICE and BOB, for generating X and Y. ALICE is provided an x is an element of X generated according to the distribution of X, and is required to send a message to BOB in order to enable him to generate y is an element of Y, whose distribution is the same as that of Y vertical bar(X=x). Both parties have access to a shared random string generated in advance. Let T[X : T] be the minimum (over all protocols) of the expected number of bits ALICE needs to transmit to achieve this. We show that I[X : Y] <= T[X : Y] <= I[X : Y] + 2 log(2)(I[X : Y] + 1) + O(1). We also consider the worst case communication required for this problem, where we seek to minimize the average number of bits ALICE must transmit for the worst case x is an element of X. We show that the communication required in this case is related to the capacity C(E) of the channel E, derived from (X, Y), that maps x is an element of X to the distribution of Y vertical bar(X=x). We also show that the required communication T(E) satisfies C(E) <= T(E) <= C(E) + 2 log(2)(C(E) + 1) + O(1). Using the first result, we derive a direct-sum theorem in communication complexity that substantially improves the previous such result shown by Jain, Radhakrishnan, and Sen [In Proc. 30th International Colloquium of Automata, Languages and Programming (ICALP), ser. Lecture Notes in Computer Science, vol. 2719. 2003, pp. 300-315]. These results are obtained by employing a rejection sampling procedure that relates the relative entropy between two distributions to the communication complexity of generating one distribution from the other.", "paper_title": "The Communication Complexity of Correlation", "paper_id": "WOS:000273134100031"}