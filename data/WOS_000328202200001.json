{"auto_keywords": [{"score": 0.047424185998726213, "phrase": "receptive_field_profiles"}, {"score": 0.008401543827476378, "phrase": "visual_stimuli"}, {"score": 0.007873626091912798, "phrase": "symmetry_properties"}, {"score": 0.0075912740207151105, "phrase": "galilean_transformations"}, {"score": 0.0065082422696712185, "phrase": "gaussian"}, {"score": 0.005677664007532796, "phrase": "biological_vision"}, {"score": 0.005276884233229797, "phrase": "lgn"}, {"score": 0.00481495049065317, "phrase": "visual_receptive_fields"}, {"score": 0.004785647033025688, "phrase": "receptive_field"}, {"score": 0.004727571512462628, "phrase": "visual_field"}, {"score": 0.0046987973264610685, "phrase": "visual_cell"}, {"score": 0.0046701974516684015, "phrase": "visual_operator"}, {"score": 0.0044747919503484055, "phrase": "idealized_vision_system"}, {"score": 0.004420472010542188, "phrase": "structural_requirements"}, {"score": 0.004393558722869138, "phrase": "first_stages"}, {"score": 0.004375707224065104, "phrase": "visual_processing"}, {"score": 0.004322584860929494, "phrase": "surrounding_world"}, {"score": 0.004252752618463944, "phrase": "covariance_properties"}, {"score": 0.0042354707960660706, "phrase": "scale_changes"}, {"score": 0.004218258903946393, "phrase": "affine_image_deformations"}, {"score": 0.004141663280057689, "phrase": "real-world_image_data"}, {"score": 0.004108066884382925, "phrase": "specific_requirements"}, {"score": 0.0038962096720793443, "phrase": "genuine_real-time_system"}, {"score": 0.003771282384646587, "phrase": "internal_representations"}, {"score": 0.003755949722774176, "phrase": "different_spatial_and_temporal_scales"}, {"score": 0.0036727235025069828, "phrase": "idealized_receptive_field_profiles"}, {"score": 0.0035404802532494834, "phrase": "closely_related_operators"}, {"score": 0.003447932289587852, "phrase": "large_number"}, {"score": 0.003433909720151841, "phrase": "visual_operations"}, {"score": 0.003419943984098415, "phrase": "computer_vision"}, {"score": 0.003399101442453873, "phrase": "feature_detection"}, {"score": 0.0033852767910317032, "phrase": "feature_classification"}, {"score": 0.003371508176308189, "phrase": "motion_estimation"}, {"score": 0.003357795372688944, "phrase": "object_recognition"}, {"score": 0.003344138155475241, "phrase": "spatio-temporal_recognition"}, {"score": 0.00332375606483146, "phrase": "shape_estimation"}, {"score": 0.0032900606878567412, "phrase": "associated_so-called_scale-space_theory"}, {"score": 0.0031780228058373235, "phrase": "scale-space_theory"}, {"score": 0.0031458001717235263, "phrase": "cell_recordings"}, {"score": 0.0030448603154946577, "phrase": "idealized_models"}, {"score": 0.002881793492919646, "phrase": "simple_cells"}, {"score": 0.002870066750788841, "phrase": "spatial_directional_preference"}, {"score": 0.0025343769150179764, "phrase": "receptive_fields"}, {"score": 0.002508663916554954, "phrase": "new_receptive_field_profiles"}, {"score": 0.0024832111447057833, "phrase": "pre-wiring_covariance"}, {"score": 0.0023936956017015696, "phrase": "basic_structure"}, {"score": 0.002379092507901856, "phrase": "necessity_results"}, {"score": 0.0023549512570712246, "phrase": "mathematical_foundation"}, {"score": 0.002316832571794284, "phrase": "proposed_theory"}, {"score": 0.0022424321129226425, "phrase": "receptive_field_responses"}, {"score": 0.0021971473452127126, "phrase": "relative_variations"}, {"score": 0.0021882004864194975, "phrase": "surface_structure"}, {"score": 0.0021571717917276724, "phrase": "logarithmic_brightness_scale"}, {"score": 0.0021352776064254195, "phrase": "field_measurements"}, {"score": 0.002113605165164895, "phrase": "multiplicative_illumination_variations"}, {"score": 0.0021049977753042253, "phrase": "exposure_control_mechanisms"}], "paper_keywords": ["Receptive field", " Scale space", " Gaussian derivative", " Scale covariance", " Affine covariance", " Galilean covariance", " Illumination invariance", " LGN", " Primary visual cortex", " Visual area V1", " Functional model", " Simple cell", " Double-opponent cell", " Complex cell", " Vision", " Theoretical neuroscience", " Theoretical biology"], "paper_abstract": "A receptive field constitutes a region in the visual field where a visual cell or a visual operator responds to visual stimuli. This paper presents a theory for what types of receptive field profiles can be regarded as natural for an idealized vision system, given a set of structural requirements on the first stages of visual processing that reflect symmetry properties of the surrounding world. These symmetry properties include (i) covariance properties under scale changes, affine image deformations, and Galilean transformations of space-time as occur for real-world image data as well as specific requirements of (ii) temporal causality implying that the future cannot be accessed and (iii) a time-recursive updating mechanism of a limited temporal buffer of the past as is necessary for a genuine real-time system. Fundamental structural requirements are also imposed to ensure (iv) mutual consistency and a proper handling of internal representations at different spatial and temporal scales. It is shown how a set of families of idealized receptive field profiles can be derived by necessity regarding spatial, spatio-chromatic, and spatio-temporal receptive fields in terms of Gaussian kernels, Gaussian derivatives, or closely related operators. Such image filters have been successfully used as a basis for expressing a large number of visual operations in computer vision, regarding feature detection, feature classification, motion estimation, object recognition, spatio-temporal recognition, and shape estimation. Hence, the associated so-called scale-space theory constitutes a both theoretically well-founded and general framework for expressing visual operations. There are very close similarities between receptive field profiles predicted from this scale-space theory and receptive field profiles found by cell recordings in biological vision. Among the family of receptive field profiles derived by necessity from the assumptions, idealized models with very good qualitative agreement are obtained for (i) spatial on-center/off-surround and off-center/on-surround receptive fields in the fovea and the LGN, (ii) simple cells with spatial directional preference in V1, (iii) spatio-chromatic double-opponent neurons in V1, (iv) space-time separable spatio-temporal receptive fields in the LGN and V1, and (v) non-separable space-time tilted receptive fields in V1, all within the same unified theory. In addition, the paper presents a more general framework for relating and interpreting these receptive fields conceptually and possibly predicting new receptive field profiles as well as for pre-wiring covariance under scaling, affine, and Galilean transformations into the representations of visual stimuli. This paper describes the basic structure of the necessity results concerning receptive field profiles regarding the mathematical foundation of the theory and outlines how the proposed theory could be used in further studies and modelling of biological vision. It is also shown how receptive field responses can be interpreted physically, as the superposition of relative variations of surface structure and illumination variations, given a logarithmic brightness scale, and how receptive field measurements will be invariant under multiplicative illumination variations and exposure control mechanisms.", "paper_title": "A computational theory of visual receptive fields", "paper_id": "WOS:000328202200001"}