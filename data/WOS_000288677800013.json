{"auto_keywords": [{"score": 0.048313706083567, "phrase": "dimension_reduction"}, {"score": 0.042335347716798616, "phrase": "c_classes"}, {"score": 0.04083167311579895, "phrase": "mmda"}, {"score": 0.00481495049065317, "phrase": "max-min_distance"}, {"score": 0.004695900553353526, "phrase": "sequential_sdp_relaxation"}, {"score": 0.004494570360108983, "phrase": "new_criterion"}, {"score": 0.004438642216475526, "phrase": "discriminative_dimension_reduction"}, {"score": 0.0040916230716372265, "phrase": "data_set"}, {"score": 0.003940706575253453, "phrase": "homoscedastic_gaussians"}, {"score": 0.003819187440994939, "phrase": "minimum_pairwise_distance"}, {"score": 0.0036782824183282823, "phrase": "selected_low-dimensional_subspace"}, {"score": 0.0035648266669315943, "phrase": "fisher's_linear_discriminant_analysis"}, {"score": 0.0035204284381641737, "phrase": "flda"}, {"score": 0.003265365666305185, "phrase": "class_pairs"}, {"score": 0.0031646057802503526, "phrase": "general_case"}, {"score": 0.003125175084962886, "phrase": "data_distribution"}, {"score": 0.0027741761880779535, "phrase": "nonsmooth_max-min_optimization_problem"}, {"score": 0.0026384167183586015, "phrase": "sequential_convex_relaxation_algorithm"}, {"score": 0.002447101794397243, "phrase": "proposed_criterion"}, {"score": 0.0024014759148123736, "phrase": "corresponding_algorithm"}, {"score": 0.0023127544795063263, "phrase": "data_visualization_experiments"}, {"score": 0.002255431275670053, "phrase": "real_data_sets"}, {"score": 0.0022273034991008326, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_optimization_algorithm"}], "paper_keywords": ["Fisher's linear discriminant analysis", " dimension reduction", " convex relaxation", " data visualization", " pattern classification"], "paper_abstract": "We propose a new criterion for discriminative dimension reduction, max-min distance analysis (MMDA). Given a data set with C classes, represented by homoscedastic Gaussians, MMDA maximizes the minimum pairwise distance of these C classes in the selected low-dimensional subspace. Thus, unlike Fisher's linear discriminant analysis (FLDA) and other popular discriminative dimension reduction criteria, MMDA duly considers the separation of all class pairs. To deal with general case of data distribution, we also extend MMDA to kernel MMDA (KMMDA). Dimension reduction via MMDA/KMMDA leads to a nonsmooth max-min optimization problem with orthonormal constraints. We develop a sequential convex relaxation algorithm to solve it approximately. To evaluate the effectiveness of the proposed criterion and the corresponding algorithm, we conduct classification and data visualization experiments on both synthetic data and real data sets. Experimental results demonstrate the effectiveness of MMDA/KMMDA associated with the proposed optimization algorithm.", "paper_title": "Max-Min Distance Analysis by Using Sequential SDP Relaxation for Dimension Reduction", "paper_id": "WOS:000288677800013"}