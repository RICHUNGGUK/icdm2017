{"auto_keywords": [{"score": 0.04449264151645753, "phrase": "n_distinct_samples"}, {"score": 0.00481495049065317, "phrase": "interpolation_neural_networks"}, {"score": 0.004526503177267299, "phrase": "single_hidden_layer_feed-forward_neural_networks"}, {"score": 0.004190019394361629, "phrase": "zero_error"}, {"score": 0.0040002088320302935, "phrase": "input_neurons"}, {"score": 0.0039085400187964196, "phrase": "hidden_neurons"}, {"score": 0.0038189638340666936, "phrase": "hidden_node_thresholds"}, {"score": 0.0034806529881619454, "phrase": "n_hidden_neurons"}, {"score": 0.003051887221639784, "phrase": "approximated_target_functions"}, {"score": 0.002675797331220082, "phrase": "functional_approach"}, {"score": 0.0024957862318504753, "phrase": "slfn"}, {"score": 0.0022222152430170254, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b_v"}], "paper_keywords": ["Neural networks", " Best approximation", " Interpolation"], "paper_abstract": "It is well-known that single hidden layer feed-forward neural networks (SLFNs) with at most n hidden neurons can learn n distinct samples with zero error and the weights connecting the Input neurons and the hidden neurons and the hidden node thresholds can be chosen randomly Namely for n distinct samples there exist SLFNs with n hidden neurons that interpolate them These networks are called exact interpolation networks for the samples However for some approximated target functions (as continuous or integrable functions) not all exact interpolation networks have good approximation effect This paper by using a functional approach rigorously proves that for given distinct samples there exists an SLFN which not only exactly interpolates samples but also near best approximates the target function Crown Copyright (C) 2010 Published by Elsevier B V All rights reserved", "paper_title": "Approximation capability of interpolation neural networks", "paper_id": "WOS:000285805800043"}