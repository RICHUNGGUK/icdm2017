{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "data_streams"}, {"score": 0.009811694848386166, "phrase": "sliding_windows"}, {"score": 0.008323234683878028, "phrase": "detection_accuracy"}, {"score": 0.004741110256890275, "phrase": "windows"}, {"score": 0.004549063619065006, "phrase": "important_problem"}, {"score": 0.004456044928556639, "phrase": "wide_range"}, {"score": 0.004188198923320451, "phrase": "unbounded_data_stream"}, {"score": 0.0035681790580031998, "phrase": "data_stream"}, {"score": 0.003513264130359459, "phrase": "fixed_time_frame"}, {"score": 0.003353521531649663, "phrase": "novel_data_structure"}, {"score": 0.0033190180867511605, "phrase": "decaying_bloom_filter"}, {"score": 0.0030872017736888113, "phrase": "stale_elements"}, {"score": 0.0030554300179552415, "phrase": "new_elements"}, {"score": 0.002931569771634119, "phrase": "dbf_basis"}, {"score": 0.0028715299874549245, "phrase": "efficient_algorithm"}, {"score": 0.0027126684113045756, "phrase": "false_positive_errors"}, {"score": 0.0025625729433234623, "phrase": "time_complexity"}, {"score": 0.002471400498582011, "phrase": "tight_upper_bound"}, {"score": 0.002445950676329976, "phrase": "false_positive_rate"}, {"score": 0.002358917661465133, "phrase": "window_size_w"}, {"score": 0.002298649369775623, "phrase": "amortized_time_complexity"}, {"score": 0.0022749744354271816, "phrase": "experimental_results"}, {"score": 0.002251542790734307, "phrase": "synthetic_data"}, {"score": 0.0021601997088758957, "phrase": "execution_time"}, {"score": 0.0021049977753042253, "phrase": "previous_results"}], "paper_keywords": ["data stream", " duplicate detection", " bloom filter", " approximate query", " sliding window"], "paper_abstract": "Detecting duplicates in data streams is an important problem that has a wide range of applications. In general, precisely detecting duplicates in an unbounded data stream is not feasible in most streaming scenarios, and, on the other hand, the elements in data streams are always time sensitive. These make it particular significant approximately detecting duplicates among newly arrived elements of a data stream within a fixed time frame. In this paper, we present a novel data structure, Decaying Bloom Filter (DBF), as an extension of the Counting Bloom Filter, that effectively removes stale elements as new elements continuously arrive over sliding windows. On the DBF basis we present an efficient algorithm to approximately detect duplicates over sliding windows. Our algorithm may produce false positive errors, but not false negative errors as in many previous results. We analyze the time complexity and detection accuracy, and give a tight upper bound of false positive rate. For a given space G bits and sliding window size W, our algorithm has an amortized time complexity. Experimental results on synthetic data demonstrate that our algorithm is superior in both execution time and detection accuracy to the previous results.", "paper_title": "Improved Approximate Detection of Duplicates for Data Streams Over Sliding Windows", "paper_id": "WOS:000261179300008"}