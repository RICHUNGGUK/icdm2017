{"auto_keywords": [{"score": 0.04107868567004354, "phrase": "one-class_classification"}, {"score": 0.00481495049065317, "phrase": "soft_one-class_classifiers"}, {"score": 0.004440277230269978, "phrase": "remaining_ones"}, {"score": 0.004144723510171449, "phrase": "pattern_classifier"}, {"score": 0.004045157344249484, "phrase": "known_and_unknown_cases"}, {"score": 0.003700037700138249, "phrase": "high_robustness"}, {"score": 0.0035819501337406596, "phrase": "unknown_class"}, {"score": 0.0035100601949451028, "phrase": "ensemble_learning"}, {"score": 0.003453584878128719, "phrase": "attractive_perspective"}, {"score": 0.0033029038236817372, "phrase": "novel_one-class_ensemble_classifier"}, {"score": 0.0032366043532903437, "phrase": "bagging"}, {"score": 0.003210446135114967, "phrase": "wagging_method"}, {"score": 0.0031459887611258765, "phrase": "randomized_weights"}, {"score": 0.00303319936111073, "phrase": "training_weighted_one-class_support_vector_machines"}, {"score": 0.0029126002350975634, "phrase": "one-class_classifiers"}, {"score": 0.0028425481299483254, "phrase": "formed_ensemble"}, {"score": 0.0027741761880779535, "phrase": "similar_or_weak_classifiers"}, {"score": 0.002707444334463544, "phrase": "clustering-based_pruning_procedure"}, {"score": 0.002526938673434697, "phrase": "base_model"}, {"score": 0.0024761702541879213, "phrase": "similar_predictors"}, {"score": 0.002311047934798247, "phrase": "single_representative"}, {"score": 0.002264607102799332, "phrase": "experimental_analysis"}, {"score": 0.0021394674440767124, "phrase": "statistical_analysis"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Classifier Ensemble", " One-Class Classification", " Bagging", " Wagging", " Ensemble Pruning", " Soft Classifier"], "paper_abstract": "For many real-life problems obtaining representative examples from a given class is relatively easy, while for the remaining ones are difficult, or even impossible. However, we would still like to construct a pattern classifier that could distinguish between the known and unknown cases. In such cases we are dealing with one-class classification, or learning in the absence of counterexamples. Such recognition systems must display a high robustness to new, unseen objects that may belong to an unknown class. That is why ensemble learning has become an attractive perspective in this field. In our work, we propose a novel one-class ensemble classifier, based on weighted Bagging. Wagging method is used to obtain randomized weights and utilize them directly in the process of training Weighted One-Class Support Vector Machines. This introduces a diversity into the pool of one-class classifiers and extends the competence of formed ensemble. Additionally, to discard similar or weak classifiers we propose to add a clustering-based pruning procedure to our ensemble. It works on the basis of similarities between weights used by each base model and detecting groups of similar predictors. This allows us to reduce the number of classifiers in the pool by selecting a single representative for each cluster. Experimental analysis, carried out on a number of benchmarks and backed-up with statistical analysis proves that the proposed method can outperform state-of-the-art ensembles dedicated to one-class classification.", "paper_title": "Forming Ensembles of Soft One-Class Classifiers with Weighted Bagging", "paper_id": "WOS:000363956700007"}