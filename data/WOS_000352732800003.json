{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "facial_emotions"}, {"score": 0.004757227624616643, "phrase": "extreme_sparse_learning"}, {"score": 0.004643839937761046, "phrase": "natural_emotions"}, {"score": 0.004588158931776543, "phrase": "human_faces"}, {"score": 0.004505881071218599, "phrase": "interesting_topic"}, {"score": 0.004425072111844721, "phrase": "wide_range"}, {"score": 0.004372002674739612, "phrase": "potential_applications"}, {"score": 0.004267757384195032, "phrase": "human-computer_interaction"}, {"score": 0.004216566615939546, "phrase": "automated_tutoring_systems"}, {"score": 0.004116012194714212, "phrase": "video_retrieval"}, {"score": 0.00406663414150229, "phrase": "smart_environments"}, {"score": 0.00399367108161192, "phrase": "driver_warning_systems"}, {"score": 0.003898411343926653, "phrase": "facial_emotion_recognition_systems"}, {"score": 0.0037825134619339537, "phrase": "laboratory_controlled_data"}, {"score": 0.003539479990299223, "phrase": "real-world_applications"}, {"score": 0.0033725614574134396, "phrase": "real-world_natural_situations"}, {"score": 0.0028477727736832283, "phrase": "nonlinear_classification_model"}, {"score": 0.002796616969627065, "phrase": "proposed_approach"}, {"score": 0.0027463775689957255, "phrase": "discriminative_power"}, {"score": 0.0027133856739937133, "phrase": "extreme_learning_machine"}, {"score": 0.0026646374739979694, "phrase": "reconstruction_property"}, {"score": 0.0026326249204932733, "phrase": "sparse_representation"}, {"score": 0.0025853238923610076, "phrase": "accurate_classification"}, {"score": 0.0025235718883452564, "phrase": "noisy_signals"}, {"score": 0.0024932498388507084, "phrase": "imperfect_data"}, {"score": 0.002448446849997207, "phrase": "natural_settings"}, {"score": 0.002318799760022913, "phrase": "new_local_spatio-temporal_descriptor"}, {"score": 0.0021827653135510225, "phrase": "proposed_framework"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_recognition_accuracy"}], "paper_keywords": ["Emotion recognition", " facial emotion", " pose-invariance", " dictionary learning", " sparse representation", " extreme learning machine", " extreme sparse learning"], "paper_abstract": "Recognition of natural emotions from human faces is an interesting topic with a wide range of potential applications, such as human-computer interaction, automated tutoring systems, image and video retrieval, smart environments, and driver warning systems. Traditionally, facial emotion recognition systems have been evaluated on laboratory controlled data, which is not representative of the environment faced in real-world applications. To robustly recognize the facial emotions in real-world natural situations, this paper proposes an approach called extreme sparse learning, which has the ability to jointly learn a dictionary (set of basis) and a nonlinear classification model. The proposed approach combines the discriminative power of extreme learning machine with the reconstruction property of sparse representation to enable accurate classification when presented with noisy signals and imperfect data recorded in natural settings. In addition, this paper presents a new local spatio-temporal descriptor that is distinctive and pose-invariant. The proposed framework is able to achieve the state-of-the-art recognition accuracy on both acted and spontaneous facial emotion databases.", "paper_title": "Robust Representation and Recognition of Facial Emotions Using Extreme Sparse Learning", "paper_id": "WOS:000352732800003"}