{"auto_keywords": [{"score": 0.04680478981285888, "phrase": "training_images"}, {"score": 0.03857701375589246, "phrase": "subsequent_recognition"}, {"score": 0.03830059436786332, "phrase": "classification_tasks"}, {"score": 0.00481495049065317, "phrase": "visual_codebook"}, {"score": 0.004743806810821005, "phrase": "fundamental_component"}, {"score": 0.004536592536813498, "phrase": "local_feature_descriptors"}, {"score": 0.004322267755421529, "phrase": "high-dimensional_bag-of-words_histogram"}, {"score": 0.0038224221344037236, "phrase": "visual_statistics"}, {"score": 0.0037940502405699765, "phrase": "local_descriptors"}, {"score": 0.003724034990158436, "phrase": "supervise_labels"}, {"score": 0.0035216195857272403, "phrase": "task-dependent_codebook_compression_framework"}, {"score": 0.0033550841271846065, "phrase": "compression_function"}, {"score": 0.0033054391731615618, "phrase": "originally_high-dimensional_codebook"}, {"score": 0.003137377828938824, "phrase": "codeword_sparse_coding_scheme"}, {"score": 0.0031143332484389248, "phrase": "lasso"}, {"score": 0.0030451958332949735, "phrase": "descriptor_distortions"}, {"score": 0.0030001224724395354, "phrase": "codebook_compression"}, {"score": 0.0027741761880779535, "phrase": "label_constraint_kernel"}, {"score": 0.0026428931714865115, "phrase": "heterogeneous_kinds"}, {"score": 0.002345535736297701, "phrase": "pascal_visual_object_class"}, {"score": 0.002276566401216226, "phrase": "image_retrieval"}, {"score": 0.002259642580775186, "phrase": "ukbench"}, {"score": 0.0021207658298095845, "phrase": "superior_performances"}], "paper_keywords": ["Image retrieval", " indexing", " local feature", " object classification", " supervised quantization", " visual codebook"], "paper_abstract": "A visual codebook serves as a fundamental component in many state-of-the-art computer vision systems. Most existing codebooks are built based on quantizing local feature descriptors extracted from training images. Subsequently, each image is represented as a high-dimensional bag-of-words histogram. Such highly redundant image description lacks efficiency in both storage and retrieval, in which only a few bins are nonzero and distributed sparsely. Furthermore, most existing codebooks are built based solely on the visual statistics of local descriptors, without considering the supervise labels coming from the subsequent recognition or classification tasks. In this paper, we propose a task-dependent codebook compression framework to handle the above two problems. First, we propose to learn a compression function to map an originally high-dimensional codebook into a compact codebook while maintaining its visual discriminability. This is achieved by a codeword sparse coding scheme with Lasso regression, which minimizes the descriptor distortions of training images after codebook compression. Second, we propose to adapt our codebook compression to the subsequent recognition or classification tasks. This is achieved by introducing a label constraint kernel (LCK) into our compression loss function. In particular, our LCK can model heterogeneous kinds of supervision, i.e., (partial) category labels, correlative semantic annotations, and image query logs. We validated our codebook compression in three computer vision tasks: 1) object recognition in PASCAL Visual Object Class 07; 2) near-duplicate image retrieval in UKBench; and 3) web image search in a collection of 0.5 million Flickr photographs. Our compressed codebook has shown superior performances over several state-of-the-art supervised and unsupervised codebooks.", "paper_title": "Task-Dependent Visual-Codebook Compression", "paper_id": "WOS:000302181800069"}