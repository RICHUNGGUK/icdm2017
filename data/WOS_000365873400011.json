{"auto_keywords": [{"score": 0.050077919073053874, "phrase": "cognitive_power_management"}, {"score": 0.048653361714131045, "phrase": "dpm"}, {"score": 0.04291065790847702, "phrase": "event_occurrences"}, {"score": 0.004766683200410046, "phrase": "wireless_sensor_networks"}, {"score": 0.004718897469501381, "phrase": "dynamic_power_management"}, {"score": 0.004601508848655033, "phrase": "wireless_sensor_nodes"}, {"score": 0.0045324756541157574, "phrase": "well-known_technique"}, {"score": 0.0044644734709113985, "phrase": "idle_energy_consumption"}, {"score": 0.0043533862892678864, "phrase": "node's_operating_mode"}, {"score": 0.003975781274672803, "phrase": "mode_change"}, {"score": 0.0038186039088445524, "phrase": "dpm's_efficiency"}, {"score": 0.00376127170364341, "phrase": "mean_feat"}, {"score": 0.0036125439380579626, "phrase": "unknown_statistics"}, {"score": 0.003383283537388849, "phrase": "cpm"}, {"score": 0.0032989853590079153, "phrase": "principled_attempt"}, {"score": 0.003216804708106142, "phrase": "statistically_unknown_settings"}, {"score": 0.003012560489169148, "phrase": "better-than-pure-chance_dpm"}, {"score": 0.0029374939071038146, "phrase": "non-stationary_event_processes"}, {"score": 0.002821247621250663, "phrase": "even_more_general_setting"}, {"score": 0.002709589081384597, "phrase": "adversarial_character"}, {"score": 0.0025503112711036994, "phrase": "individual_mote"}, {"score": 0.0024617483174454113, "phrase": "repeated_zero-sum_game"}, {"score": 0.0023642842046859274, "phrase": "no-external-regret_procedure"}, {"score": 0.0022365262201954643, "phrase": "numerical_experiments"}, {"score": 0.0021263705039915198, "phrase": "network_lifetime"}, {"score": 0.0021049977753042253, "phrase": "event_loss_percentage"}], "paper_keywords": ["wireless sensor network", " cognitive power management", " learning automata", " external regret", " zero-sum game"], "paper_abstract": "Dynamic power management (DPM) in wireless sensor nodes is a well-known technique for reducing idle energy consumption. DPM controls a node's operating mode by dynamically toggling the on/off status of its units based on predictions of event occurrences. However, since each mode change induces some overhead in its own right, guaranteeing DPM's efficiency is no mean feat in environments exhibiting non-determinism and uncertainty with unknown statistics. Our solution suite in this paper, collectively referred to as cognitive power management (CPM), is a principled attempt toward enabling DPM in statistically unknown settings and gives two different analytical guarantees. Our first design is based on learning automata and guarantees better-than-pure-chance DPM in the face of non-stationary event processes. Our second solution caters for an even more general setting in which event occurrences may take on an adversarial character. In this case, we formulate the interaction of an individual mote with its environment in terms of a repeated zero-sum game in which the node relies on a no-external-regret procedure to learn its mini-max strategies in an online fashion. We conduct numerical experiments to measure the performance of our schemes in terms of network lifetime and event loss percentage.", "paper_title": "Cognitive Power Management in Wireless Sensor Networks", "paper_id": "WOS:000365873400011"}