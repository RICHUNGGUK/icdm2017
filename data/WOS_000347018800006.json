{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "monte_carlo"}, {"score": 0.004717723626157272, "phrase": "robust_nuclear_reactor_analysis"}, {"score": 0.004483120978156604, "phrase": "nuclear_simulations"}, {"score": 0.004260134699483774, "phrase": "high-fidelity_nuclear_reactor_analysis"}, {"score": 0.004089725258435817, "phrase": "tally_data"}, {"score": 0.003946195919158241, "phrase": "large_amount"}, {"score": 0.003906116922372891, "phrase": "aggregate_data"}, {"score": 0.0038467574225322086, "phrase": "typical_high_performance_computer"}, {"score": 0.0038080467230465053, "phrase": "mc"}, {"score": 0.0036553070575015344, "phrase": "key_data_structures"}, {"score": 0.003563172322934695, "phrase": "processing_element"}, {"score": 0.003403122817578447, "phrase": "future_machines"}, {"score": 0.003351381374975648, "phrase": "present_work"}, {"score": 0.0032668821950788533, "phrase": "spatial_domain_decomposition"}, {"score": 0.0032172054825137866, "phrase": "full-scale_nuclear_reactor_simulations"}, {"score": 0.003088384809415812, "phrase": "simple_implementation"}, {"score": 0.0030414140732789186, "phrase": "production-scale_code"}, {"score": 0.0028606915359675814, "phrase": "tb"}, {"score": 0.0027600360731762997, "phrase": "full-core_reactor_benchmark"}, {"score": 0.0025826247025542213, "phrase": "load_imbalances"}, {"score": 0.0025174594088331853, "phrase": "updated_performance_model"}, {"score": 0.002441422510910065, "phrase": "observed_timing_results"}, {"score": 0.0022382002476510573, "phrase": "new_and_efficient_way"}, {"score": 0.0022041312401435346, "phrase": "extra_compute_resources"}, {"score": 0.0021817065300196634, "phrase": "finer_domain"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Monte Carlo", " Domain decomposition", " Load balancing", " Neutron transport", " Nuclear reactor analyses"], "paper_abstract": "Monte Carlo (MC) neutral particle transport codes are considered the gold-standard for nuclear simulations, but they cannot be robustly applied to high-fidelity nuclear reactor analysis without accommodating several terabytes of materials and tally data. While this is not a large amount of aggregate data for a typical high performance computer, MC methods are only embarrassingly parallel when the key data structures are replicated for each processing element, an approach which is likely infeasible on future machines. The present work explores the use of spatial domain decomposition to make full-scale nuclear reactor simulations tractable with Monte Carlo methods, presenting a simple implementation in a production-scale code. Good performance is achieved for mesh-tallies of up to 2.39 TB distributed across 512 compute nodes while running a full-core reactor benchmark on the Mira Blue Gene/Q supercomputer at the Argonne National Laboratory. In addition, the effects of load imbalances are explored with an updated performance model that is empirically validated against observed timing results. Several load balancing techniques are also implemented to demonstrate that imbalances can be largely mitigated, including a new and efficient way to distribute extra compute resources across finer domain meshes. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Monte Carlo domain decomposition for robust nuclear reactor analysis", "paper_id": "WOS:000347018800006"}