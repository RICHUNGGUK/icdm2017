{"auto_keywords": [{"score": 0.048929739366992464, "phrase": "joint_attention"}, {"score": 0.015719716506582538, "phrase": "gaze_interpolation"}, {"score": 0.010690574406026844, "phrase": "gaze_direction"}, {"score": 0.004756828714593367, "phrase": "saliency"}, {"score": 0.004422325007817267, "phrase": "common_point"}, {"score": 0.004289966839994858, "phrase": "communicating_party"}, {"score": 0.004161553532799662, "phrase": "key_factor"}, {"score": 0.003964007795174772, "phrase": "image-based_method"}, {"score": 0.003685067218455088, "phrase": "precise_analysis"}, {"score": 0.003618443379266972, "phrase": "experimenter's_eye_region"}, {"score": 0.003531474887552889, "phrase": "high-resolution_image_acquisition"}, {"score": 0.0033230588808076267, "phrase": "regression-based_interpolation"}, {"score": 0.0032039415997394817, "phrase": "head_pose"}, {"score": 0.0029965060407413898, "phrase": "gaussian_process_regression_and_neural_networks"}, {"score": 0.002751751956416832, "phrase": "image-based_saliency"}, {"score": 0.002685558057339722, "phrase": "target_point_estimates"}, {"score": 0.0025578967205807843, "phrase": "proposed_method"}, {"score": 0.002511600086227215, "phrase": "human-robot_interaction_scenario"}, {"score": 0.002481200970201421, "phrase": "cross-subject_evaluations"}, {"score": 0.0023776656246300063, "phrase": "adverse_conditions"}, {"score": 0.0021049977753042253, "phrase": "rapid_gaze_estimation"}], "paper_keywords": ["Developmental robotics", " gaze following", " head pose estimation", " joint visual attention", " saliency", " selective attention"], "paper_abstract": "Joint attention, which is the ability of coordination of a common point of reference with the communicating party, emerges as a key factor in various interaction scenarios. This paper presents an image-based method for establishing joint attention between an experimenter and a robot. The precise analysis of the experimenter's eye region requires stability and high-resolution image acquisition, which is not always available. We investigate regression-based interpolation of the gaze direction from the head pose of the experimenter, which is easier to track. Gaussian process regression and neural networks are contrasted to interpolate the gaze direction. Then, we combine gaze interpolation with image-based saliency to improve the target point estimates and test three different saliency schemes. We demonstrate the proposed method on a human-robot interaction scenario. Cross-subject evaluations, as well as experiments under adverse conditions (such as dimmed or artificial illumination or motion blur), show that our method generalizes well and achieves rapid gaze estimation for establishing joint attention.", "paper_title": "Joint Attention by Gaze Interpolation and Saliency", "paper_id": "WOS:000319010000003"}