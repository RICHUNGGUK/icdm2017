{"auto_keywords": [{"score": 0.036026636783294624, "phrase": "three-action_discrimination"}, {"score": 0.00481495049065317, "phrase": "real-time_decoding"}, {"score": 0.004691136491297242, "phrase": "assistive_interfaces"}, {"score": 0.00465634671242413, "phrase": "prosthesis_control"}, {"score": 0.0044696209776899955, "phrase": "hmi"}, {"score": 0.004370814742381778, "phrase": "volitional_bioacoustic_activity"}, {"score": 0.004322267755421529, "phrase": "prescribed_tongue_motions"}, {"score": 0.004211069233133584, "phrase": "heterogeneous_decoding_framework"}, {"score": 0.004133390261297075, "phrase": "effective_real-time_polychotomous_classification"}, {"score": 0.004027031316965272, "phrase": "dichotomous_discrimination"}, {"score": 0.00399714680711765, "phrase": "unintended_bioacoustic_activity"}, {"score": 0.00395273370234774, "phrase": "volitional_signals"}, {"score": 0.00389427992231721, "phrase": "customised_framework"}, {"score": 0.003808209866576388, "phrase": "real-time_performance"}, {"score": 0.0035744997458371335, "phrase": "healthy_subjects"}, {"score": 0.00353476609156032, "phrase": "false_negative_rejections"}, {"score": 0.0033177813460815346, "phrase": "tested_subjects"}, {"score": 0.003280891942617853, "phrase": "interference_rejection"}, {"score": 0.0031140747752837826, "phrase": "challenging_offline_data_sets"}, {"score": 0.0030338645940033875, "phrase": "low_frequency_interference_signals"}, {"score": 0.0030113280682863234, "phrase": "similar_temporal_characteristics"}, {"score": 0.0029889584492584073, "phrase": "frequency_distributions"}, {"score": 0.00295571428544335, "phrase": "volitional_tongue_activity"}, {"score": 0.0029228387900175554, "phrase": "ir_subsystem"}, {"score": 0.0028903278985330117, "phrase": "average_specificity"}, {"score": 0.0028053842615436706, "phrase": "four-action_discrimination"}, {"score": 0.0026726283357752585, "phrase": "existing_assistive_interfaces"}, {"score": 0.0026428931714865115, "phrase": "case_study"}, {"score": 0.002574788013427524, "phrase": "tmep_signals"}, {"score": 0.0025556529150386168, "phrase": "hand_prosthesis_control"}, {"score": 0.0025366596616434793, "phrase": "full_tongue_control"}, {"score": 0.0023107943665108465, "phrase": "everyday_object_manipulation_task"}, {"score": 0.0022096205841489786, "phrase": "hybrid_strategy"}, {"score": 0.0021526564019119466, "phrase": "proportional-based_control_strategy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Human-machine interfaces", " Tongue-movement ear pressure signals", " Volitional bioacoustic activity", " Pattern classification", " Heterogeneous ensembles", " Prosthetic hand control"], "paper_abstract": "Tongue-movement ear pressure (TMEP) signals provide an unobtrusive, completely non-invasive, wearable and assistive human-machine interface (HMI). The HMI concept is based on monitoring volitional bioacoustic activity generated through prescribed tongue motions. In this paper, a heterogeneous decoding framework is presented, enabling effective real-time polychotomous classification between the various tongue actions and dichotomous discrimination of unintended bioacoustic activity from the volitional signals. Using this customised framework and developed software, the real-time performance was evaluated for both three (six subjects) and four action (four subjects) discrimination, using healthy subjects. Ignoring false negative rejections, the system achieved sensitivities of >90% for three-action discrimination and >80% for four action discrimination, across all tested subjects. The interference rejection (IR) capabilities of the framework were also fully demonstrated, using challenging offline data sets. This included a subset of low frequency interference signals with similar temporal characteristics and frequency distributions as the volitional tongue activity. The IR subsystem achieved an average specificity of 76.2% during three-action discrimination and 79.9% during four-action discrimination. To highlight the potential of the system for substituting or augmenting existing assistive interfaces, a case study is presented demonstrating the utility of TMEP signals for hand prosthesis control. Full tongue control was evaluated against three alternative control strategies, namely natural human-hand manipulation, proportional-based control and a hybrid strategy, when performing an everyday object manipulation task. In all cases, the task was completed with the hybrid strategy performing comparably and even outperforming the proportional-based control strategy. (c) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "A heterogeneous framework for real-time decoding of bioacoustic signals: Applications to assistive interfaces and prosthesis control", "paper_id": "WOS:000320210900002"}