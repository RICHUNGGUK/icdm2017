{"auto_keywords": [{"score": 0.049558064870310475, "phrase": "feature_selection"}, {"score": 0.04557529632101767, "phrase": "regularization_problems"}, {"score": 0.00481495049065317, "phrase": "linear_programming"}, {"score": 0.004558564684763264, "phrase": "statistical_procedures"}, {"score": 0.004315771670213371, "phrase": "convex_piecewise_linear_loss_functions"}, {"score": 0.0033363396054797044, "phrase": "'parametric_cost_lp"}, {"score": 0.0030899524399043863, "phrase": "optimization_theory"}, {"score": 0.0029736479837154843, "phrase": "lp_theory"}, {"score": 0.0028932554846476718, "phrase": "general_algorithms"}, {"score": 0.002709045632654716, "phrase": "regularized_solution_paths"}, {"score": 0.002664850766529523, "phrase": "feature_selection_problems"}, {"score": 0.002508867228980776, "phrase": "complete_exploration"}, {"score": 0.0024679299547216956, "phrase": "model_space"}, {"score": 0.0023749823753904204, "phrase": "broad_view"}, {"score": 0.002349073225500705, "phrase": "persistent_features"}, {"score": 0.0022359278646792153, "phrase": "general_path-finding_algorithms"}, {"score": 0.0021049977753042253, "phrase": "numerical_examples"}], "paper_keywords": ["Grouped regularization", " l(1)-norm penalty", " Parametric linear programming", " Quantile regression", " Simplex method", " Structured learning", " Support vector machines"], "paper_abstract": "We consider statistical procedures for feature selection defined by a family of regularization problems with convex piecewise linear loss functions and penalties of l (1) nature. Many known statistical procedures (e.g. quantile regression and support vector machines with l (1)-norm penalty) are subsumed under this category. Computationally, the regularization problems are linear programming (LP) problems indexed by a single parameter, which are known as 'parametric cost LP' or 'parametric right-hand-side LP' in the optimization theory. Exploiting the connection with the LP theory, we lay out general algorithms, namely, the simplex algorithm and its variant for generating regularized solution paths for the feature selection problems. The significance of such algorithms is that they allow a complete exploration of the model space along the paths and provide a broad view of persistent features in the data. The implications of the general path-finding algorithms are outlined for several statistical procedures, and they are illustrated with numerical examples.", "paper_title": "Another look at linear programming for feature selection via methods of regularization", "paper_id": "WOS:000339380000014"}