{"auto_keywords": [{"score": 0.04497163234841055, "phrase": "rbfnn"}, {"score": 0.00481495049065317, "phrase": "memetic_rbfnns_design"}, {"score": 0.00478579024367007, "phrase": "feature_selection"}, {"score": 0.004756805752518494, "phrase": "function_approximation_problems"}, {"score": 0.004685106586595599, "phrase": "radial_basis_function_neural_networks"}, {"score": 0.0045726187330434025, "phrase": "difficult_task"}, {"score": 0.004449280529563265, "phrase": "regression_problems"}, {"score": 0.003857022173615399, "phrase": "real_world_applications"}, {"score": 0.003531474887552889, "phrase": "intrinsic_parallelism"}, {"score": 0.0034994014234054397, "phrase": "genetic_algorithms"}, {"score": 0.0034676182423067307, "phrase": "parallel_implementation"}, {"score": 0.003079696561895752, "phrase": "crossover_and_mutation_operators"}, {"score": 0.0030239842475439814, "phrase": "different_elements"}, {"score": 0.0029422942175866057, "phrase": "subjacent_genetic_algorithm"}, {"score": 0.0028978654846251047, "phrase": "genetic_algorithm"}, {"score": 0.002685558057339722, "phrase": "overfitted_networks"}, {"score": 0.0026209522797963447, "phrase": "proposed_algorithm"}, {"score": 0.0025813632575129933, "phrase": "local_search_algorithms"}, {"score": 0.0024511688853030168, "phrase": "final_optimization"}, {"score": 0.0024288830311280573, "phrase": "pareto_front"}, {"score": 0.0022440136394950632, "phrase": "different_paradigms"}, {"score": 0.002203385580030364, "phrase": "presented_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Parallel genetic algorithms", " RBF", " Neural networks", " Function approximation", " RBFNN", " MPI"], "paper_abstract": "The design of radial basis function neural networks (RBFNNs) still remains as a difficult task when they are applied to classification or to regression problems. The difficulty arises when the parameters that define an RBFNN have to be set, these are: the number of RBFs, the position of their centers and the length of their radii. Another issue that has to be faced when applying these models to real world applications is to select the variables that the RBFNN will use as inputs. The literature presents several methodologies to perform these two tasks separately, however, due to the intrinsic parallelism of the genetic algorithms, a parallel implementation will allow the algorithm proposed in this paper to evolve solutions for both problems at the same time. The parallelization of the algorithm not only consists in the evolution of the two problems but in the specialization of the crossover and mutation operators in order to evolve the different elements to be optimized when designing RBFNNs. The subjacent genetic algorithm is the non-sorting dominated genetic algorithm II (NSGA-II) that helps to keep a balance between the size of the network and its approximation accuracy in order to avoid overfitted networks. Another of the novelties of the proposed algorithm is the incorporation of local search algorithms in three stages of the algorithm: initialization of the population, evolution of the individuals and final optimization of the Pareto front. The initialization of the individuals is performed hybridizing clustering techniques with the mutual information (MI) theory to select the input variables. As the experiments will show, the synergy of the different paradigms and techniques combined by the presented algorithm allow to obtain very accurate models using the most significant input variables. (C) 2009 Published by Elsevier B.V.", "paper_title": "Parallel multiobjective memetic RBFNNs design and feature selection for function approximation problems", "paper_id": "WOS:000270336100014"}