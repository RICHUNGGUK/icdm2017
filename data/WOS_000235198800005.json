{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "human_action_recognition"}, {"score": 0.0046364836476864325, "phrase": "viewpoint_invariant_human_action_recognition"}, {"score": 0.004485735417293941, "phrase": "scant_attention"}, {"score": 0.004339867166576126, "phrase": "overall_body"}, {"score": 0.003475582268210954, "phrase": "model_actions"}, {"score": 0.0031920445513574907, "phrase": "simple_and_effective_way"}, {"score": 0.0031174595932694036, "phrase": "human_actions"}, {"score": 0.003073545175760353, "phrase": "general_viewpoint"}, {"score": 0.0029039692582303904, "phrase": "straightforward_application"}, {"score": 0.0027178867838199734, "phrase": "inherent_problems"}, {"score": 0.002679585860537941, "phrase": "straightforward_approach"}, {"score": 0.0026293540353514075, "phrase": "recognition_algorithm"}, {"score": 0.002519739850807611, "phrase": "publicly_available_human_motion_capture_data"}, {"score": 0.00247249708860822, "phrase": "manually_segmented_real_image_sequences"}, {"score": 0.002391938519840648, "phrase": "viewpoint_change"}, {"score": 0.002292199117499287, "phrase": "different_people"}, {"score": 0.0022706045233150795, "phrase": "minor_variabilities"}, {"score": 0.0021049977753042253, "phrase": "sufficient_distinction"}], "paper_keywords": ["human action recognition", " 2D invariance", " invariance space trajectories"], "paper_abstract": "This paper presents an approach for viewpoint invariant human action recognition, an area that has received scant attention so far, relative to the overall body of work in human action recognition. It has been established previously that there exist no invariants for 3D to 2D projection. However, there exist a wealth of techniques in 2D invariance that can be used to advantage in 3D to 2D projection. We exploit these techniques and model actions in terms of view-invariant canonical body poses and trajectories in 2D invariance space, leading to a simple and effective way to represent and recognize human actions from a general viewpoint. We first evaluate the approach theoretically and show why a straightforward application of the 2D invariance idea will not work. We describe strategies designed to overcome inherent problems in the straightforward approach and outline the recognition algorithm. We then present results on 2D projections of publicly available human motion capture data as well on manually segmented real image sequences. In addition to robustness to viewpoint change, the approach is robust enough to handle different people, minor variabilities in a given action, and the speed of aciton (and hence, frame-rate) while encoding sufficient distinction among actions.", "paper_title": "View invariance for human action recognition", "paper_id": "WOS:000235198800005"}