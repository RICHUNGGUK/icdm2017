{"auto_keywords": [{"score": 0.004569293780076254, "phrase": "resulting_perspective_distortions"}, {"score": 0.004386887374401584, "phrase": "parallel_lines"}, {"score": 0.003927516959113487, "phrase": "unwarping_process"}, {"score": 0.003662410853488772, "phrase": "automatic_algorithm"}, {"score": 0.003516079377293321, "phrase": "repeated_elements"}, {"score": 0.003435092524339692, "phrase": "unknown_plane"}, {"score": 0.003259604990188875, "phrase": "image_self-similarity"}, {"score": 0.0031660031870090434, "phrase": "homography_transformations"}, {"score": 0.003039445153076014, "phrase": "detected_regional_descriptors"}, {"score": 0.002952146666681891, "phrase": "transformation_space"}, {"score": 0.002884111441153185, "phrase": "intersection_points"}, {"score": 0.0026892447164623247, "phrase": "projected_intersection_points"}, {"score": 0.0026272523687965615, "phrase": "correcting_transform"}, {"score": 0.0024496978447849835, "phrase": "explicit_or_accurate_detection"}, {"score": 0.0022841153001549193, "phrase": "challenging_textures"}, {"score": 0.0022184630090454132, "phrase": "rectified_outputs"}, {"score": 0.002129701089817251, "phrase": "texture_synthesis"}, {"score": 0.0021049977753042253, "phrase": "image_completion"}], "paper_keywords": [""], "paper_abstract": "Many photographs are taken in perspective. Techniques for rectifying resulting perspective distortions typically rely on the existence of parallel lines in the scene. In scenarios where such parallel lines are hard to automatically extract or manually annotate, the unwarping process remains a challenge. In this paper, we introduce an automatic algorithm to rectifying images containing textures of repeated elements lying on an unknown plane. We unwrap the input by maximizing for image self-similarity over the space of homography transformations. We map a set of detected regional descriptors to surfaces in a transformation space, compute the intersection points among triplets of such surfaces, and then use consensus among the projected intersection points to extract the correcting transform. Our algorithm is global, robust, and does not require explicit or accurate detection of similar elements. We evaluate our method on a variety of challenging textures and images. The rectified outputs are directly useful for various tasks including texture synthesis, image completion, etc.", "paper_title": "Repetition Maximization based Texture Rectification", "paper_id": "WOS:000306181100007"}