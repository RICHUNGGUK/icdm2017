{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "least_absolute_policy_iteration-a_robust_approach"}, {"score": 0.004716520738331953, "phrase": "value_function_approximation"}, {"score": 0.004620093797504386, "phrase": "least-squares_policy_iteration"}, {"score": 0.004479120557712926, "phrase": "useful_reinforcement_learning_method"}, {"score": 0.003757480190200645, "phrase": "observed_rewards"}, {"score": 0.0034236045013591437, "phrase": "alternative_method"}, {"score": 0.0032848684681050745, "phrase": "absolute_loss"}, {"score": 0.0030239842475439814, "phrase": "proposed_method"}, {"score": 0.0028715299874549245, "phrase": "linear_programming_problem"}, {"score": 0.002670884656785558, "phrase": "standard_optimization_software"}, {"score": 0.0025625729433234623, "phrase": "computational_advantage"}, {"score": 0.0021714122348552747, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "simulated_robot-control_task"}], "paper_keywords": ["reinforcement learning", " value function approximation", " least-squares policy iteration", " outlier", " l(1)-loss function", " linear programming"], "paper_abstract": "Least-squares policy iteration is a useful reinforcement learning method in robotics due to its computational efficiency. However, it tends to be sensitive to outliers in observed rewards. In this paper, we propose an alternative method that employs the absolute loss for enhancing robustness and reliability. The proposed method is formulated as a linear programming problem which can be solved efficiently by standard optimization software, so the computational advantage is not sacrificed for gaining robustness and reliability. We demonstrate the usefulness of the proposed approach through a simulated robot-control task.", "paper_title": "Least Absolute Policy Iteration-A Robust Approach to Value Function Approximation", "paper_id": "WOS:000282245100022"}