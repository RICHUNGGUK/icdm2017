{"auto_keywords": [{"score": 0.04483396309490216, "phrase": "bayes"}, {"score": 0.01996088375246408, "phrase": "nbtree"}, {"score": 0.014598838643759144, "phrase": "mnbtree"}, {"score": 0.008576219145162326, "phrase": "built_decision_tree"}, {"score": 0.00481495049065317, "phrase": "naive_bayes_tree"}, {"score": 0.004773904938276846, "phrase": "text_classification"}, {"score": 0.00473320761888448, "phrase": "naive_bayes"}, {"score": 0.004074397977869244, "phrase": "hybrid_algorithm"}, {"score": 0.003988055287053139, "phrase": "naive_bayes_classifier"}, {"score": 0.003937126962709418, "phrase": "leaf_node"}, {"score": 0.0038207994186834015, "phrase": "remarkable_classification_performance"}, {"score": 0.0037398106866046972, "phrase": "text_classification_tasks"}, {"score": 0.0036448789403566123, "phrase": "mnb"}, {"score": 0.0035676056286816915, "phrase": "dominant_modeling_approach"}, {"score": 0.003522027550662857, "phrase": "multi-variate_bernoulli_model"}, {"score": 0.0033454448643854525, "phrase": "new_algorithm"}, {"score": 0.003177687211289478, "phrase": "multinomial_naive_bayes_text_classifier"}, {"score": 0.00296698375549856, "phrase": "binary_tree"}, {"score": 0.002879237498994052, "phrase": "'_values"}, {"score": 0.0026882700311968025, "phrase": "information_gain_measure"}, {"score": 0.0026425357050743003, "phrase": "classification_accuracy_measure"}, {"score": 0.002553382046204689, "phrase": "time_consumption"}, {"score": 0.002477837342313456, "phrase": "classification_performance"}, {"score": 0.002283839204519042, "phrase": "multiclass_technique"}, {"score": 0.002235356010935877, "phrase": "experimental_results"}, {"score": 0.0022067604433257814, "phrase": "large_number"}, {"score": 0.00218789980093445, "phrase": "widely_used_text_classification_benchmark_datasets"}, {"score": 0.0021049977753042253, "phrase": "mmnbtree"}], "paper_keywords": ["Text classification", " Multinomial naive Bayes", " Multinomial naive Bayes tree", " Multiclass learning"], "paper_abstract": "Naive Bayes (NB) is one of the top 10 algorithms thanks to its simplicity, efficiency, and interpretability. To weaken its attribute independence assumption, naive Bayes tree (NBTree) has been proposed. NBTree is a hybrid algorithm, which deploys a naive Bayes classifier on each leaf node of the built decision tree and has demonstrated remarkable classification performance. When comes to text classification tasks, multinomial naive Bayes (MNB) has been a dominant modeling approach after the multi-variate Bernoulli model. Inspired by the success of NBTree, we propose a new algorithm called multinomial naive Bayes tree (MNBTree) by deploying a multinomial naive Bayes text classifier on each leaf node of the built decision tree. Different from NBTree, MNBTree builds a binary tree, in which the split attributes' values are just divided into zero and nonzero. At the same time, MNBTree uses the information gain measure instead of the classification accuracy measure to build the tree for reducing the time consumption. To further scale up the classification performance of MNBTree, we propose its multiclass learning version called multiclass multinomial naive Bayes tree (MMNBTree) by applying the multiclass technique to MNBTree. The experimental results on a large number of widely used text classification benchmark datasets validate the effectiveness of our proposed algorithms: MNBTree and MMNBTree.", "paper_title": "Adapting naive Bayes tree for text classification", "paper_id": "WOS:000356297500004"}