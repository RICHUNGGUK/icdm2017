{"auto_keywords": [{"score": 0.034933767948205935, "phrase": "machine_learning_methods"}, {"score": 0.01572155408246309, "phrase": "ga"}, {"score": 0.015525702520202127, "phrase": "feature_selection"}, {"score": 0.015220171637851516, "phrase": "software_effort_estimation"}, {"score": 0.013077332778796, "phrase": "software_development_effort"}, {"score": 0.011895919025337614, "phrase": "input_features"}, {"score": 0.009175461454450914, "phrase": "data_sets"}, {"score": 0.004695543202451537, "phrase": "machine_learning_regression"}, {"score": 0.0046021431217333824, "phrase": "software_industry"}, {"score": 0.004579083503344774, "phrase": "project_managers"}, {"score": 0.004443121295775668, "phrase": "software_project"}, {"score": 0.00435472022650742, "phrase": "key_factor"}, {"score": 0.00432202319518621, "phrase": "efficient_application"}, {"score": 0.0043003610892184945, "phrase": "human_resources"}, {"score": 0.004225391538112801, "phrase": "radial_basis_function"}, {"score": 0.004089598384268605, "phrase": "bagging_predictors"}, {"score": 0.004069096437466151, "phrase": "regression-based_trees"}, {"score": 0.0038793622859517227, "phrase": "software_effort"}, {"score": 0.003588533760251239, "phrase": "important_influence"}, {"score": 0.0035705347414368696, "phrase": "estimation_accuracy"}, {"score": 0.003455713955564303, "phrase": "genetic_algorithm_method"}, {"score": 0.0033868916699805224, "phrase": "optimal_input_feature_subset"}, {"score": 0.0032697235411641695, "phrase": "higher_accuracy_level"}, {"score": 0.003245146558861112, "phrase": "software_effort_estimates"}, {"score": 0.0031725149598665395, "phrase": "six_benchmark_data_sets"}, {"score": 0.003117146879222012, "phrase": "desharnais"}, {"score": 0.003101561589182953, "phrase": "nasa"}, {"score": 0.003085940815980883, "phrase": "cocomo"}, {"score": 0.0030704562564542897, "phrase": "albrecht"}, {"score": 0.0030550471113988415, "phrase": "kemerer"}, {"score": 0.003039714383234862, "phrase": "koten"}, {"score": 0.0030244853735170644, "phrase": "gray"}, {"score": 0.0029051384526361424, "phrase": "neural_networks"}, {"score": 0.002890557197908352, "phrase": "support_vector_machines"}, {"score": 0.0028760489172318516, "phrase": "multiple_additive_regression_trees"}, {"score": 0.00284009509859163, "phrase": "bayesian_statistical_models"}, {"score": 0.0027417911324611917, "phrase": "proposed_ga-based_method"}, {"score": 0.0026203703585853987, "phrase": "proposed_method"}, {"score": 0.002600661525224505, "phrase": "recent_methods"}, {"score": 0.0025746128852814983, "phrase": "recent_literature"}, {"score": 0.002375378322770973, "phrase": "input_features_selection"}, {"score": 0.002275869477027725, "phrase": "model_complexity"}, {"score": 0.0022192891418394514, "phrase": "input_feature"}, {"score": 0.0021915275079238358, "phrase": "input_parameters"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Software effort estimation", " Genetic algorithms", " Feature selection", " Support vector regression", " Regression"], "paper_abstract": "Context: In software industry, project managers usually rely on their previous experience to estimate the number men/hours required for each software project. The accuracy of such estimates is a key factor for the efficient application of human resources. Machine learning techniques such as radial basis function (RBF) neural networks, multi-layer perceptron (MLP) neural networks, support vector regression (SVR), bagging predictors and regression-based trees have recently been applied for estimating software development effort. Some works have demonstrated that the level of accuracy in software effort estimates strongly depends on the values of the parameters of these methods. In addition, it has been shown that the selection of the input features may also have an important influence on estimation accuracy. Objective: This paper proposes and investigates the use of a genetic algorithm method for simultaneously (1) select an optimal input feature subset and (2) optimize the parameters of machine learning methods, aiming at a higher accuracy level for the software effort estimates. Method: Simulations are carried out using six benchmark data sets of software projects, namely, Desharnais, NASA, COCOMO, Albrecht, Kemerer and Koten and Gray. The results are compared to those obtained by methods proposed in the literature using neural networks, support vector machines, multiple additive regression trees, bagging, and Bayesian statistical models. Results: In all data sets, the simulations have shown that the proposed GA-based method was able to improve the performance of the machine learning methods. The simulations have also demonstrated that the proposed method outperforms some recent methods reported in the recent literature for software effort estimation. Furthermore, the use of GA for feature selection considerably reduced the number of input features for five of the data sets used in our analysis. Conclusions: The combination of input features selection and parameters optimization of machine learning methods improves the accuracy of software development effort. In addition, this reduces model complexity, which may help understanding the relevance of each input feature. Therefore, some input parameters can be ignored without loss of accuracy in the estimations. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "GA-based method for feature selection and parameters optimization for machine learning regression applied to software effort estimation", "paper_id": "WOS:000282905700002"}