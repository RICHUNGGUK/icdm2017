{"auto_keywords": [{"score": 0.049450454172374286, "phrase": "facial_expressions"}, {"score": 0.04882985100763263, "phrase": "speech_prosody"}, {"score": 0.00481495049065317, "phrase": "natural_emotions"}, {"score": 0.004506968388996092, "phrase": "multimodal_database"}, {"score": 0.004447766706144458, "phrase": "natural_expressivity"}, {"score": 0.004274766964161756, "phrase": "careful_planning"}, {"score": 0.004027751272984522, "phrase": "feature_extraction"}, {"score": 0.0039748192550806815, "phrase": "recognition_algorithms"}, {"score": 0.0036472537997966938, "phrase": "acted_behaviour"}, {"score": 0.0035052810710060893, "phrase": "unconstrained_expressivity"}, {"score": 0.0034363735647539267, "phrase": "human_participants"}, {"score": 0.0032807941194429235, "phrase": "expressed_emotions"}, {"score": 0.002798780784517325, "phrase": "multimodal_data"}, {"score": 0.002761954897932813, "phrase": "dynamic_emotion_recognition"}, {"score": 0.002602127996667857, "phrase": "dynamic_recognition_algorithm"}, {"score": 0.0025340874787959195, "phrase": "recurrent_neural_networks"}, {"score": 0.00240328454980006, "phrase": "visual_analysis"}, {"score": 0.0023559890904375526, "phrase": "wide_margin"}, {"score": 0.0023096222276192194, "phrase": "sal_database"}, {"score": 0.002161542155696987, "phrase": "common_ground"}], "paper_keywords": ["Affective computing", " Multimodal emotion recognition", " Emotion induction methods"], "paper_abstract": "Recording and annotating a multimodal database of natural expressivity is a task that requires careful planning and implementation, before even starting to apply feature extraction and recognition algorithms. Requirements and characteristics of such databases are inherently different than those of acted behaviour, both in terms of unconstrained expressivity of the human participants, and in terms of the expressed emotions. In this paper, we describe a method to induce, record and annotate natural emotions, which was used to provide multimodal data for dynamic emotion recognition from facial expressions and speech prosody; results from a dynamic recognition algorithm, based on recurrent neural networks, indicate that multimodal processing surpasses both speech and visual analysis by a wide margin. The SAL database was used in the framework of the Humaine Network of Excellence as a common ground for research in everyday, natural emotions.", "paper_title": "Induction, recording and recognition of natural emotions from facial expressions and speech prosody", "paper_id": "WOS:000327382500003"}