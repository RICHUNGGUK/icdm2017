{"auto_keywords": [{"score": 0.046678304051851256, "phrase": "human_action_recognition"}, {"score": 0.04002190278673307, "phrase": "video_sequence"}, {"score": 0.00481495049065317, "phrase": "key-frame_selection"}, {"score": 0.004752873752686246, "phrase": "pyramidal_motion-feature_representation"}, {"score": 0.0045124316982387315, "phrase": "novel_method"}, {"score": 0.004415857432588371, "phrase": "boosted_key-frame_selection"}, {"score": 0.004358903464536199, "phrase": "pyramidal_motion_feature_representations"}, {"score": 0.004247180402119585, "phrase": "unsupervised_method"}, {"score": 0.004192392802008709, "phrase": "interest_points"}, {"score": 0.004138309011478741, "phrase": "pyramidal_motion_feature"}, {"score": 0.004014800383343256, "phrase": "optical_flow"}, {"score": 0.003962998498942111, "phrase": "biologically_inspired_feature"}, {"score": 0.0037623642073222547, "phrase": "adaboost_learning_algorithm"}, {"score": 0.003602922164562919, "phrase": "large_feature_pool"}, {"score": 0.0033182992967343916, "phrase": "key_frames"}, {"score": 0.00308269056870936, "phrase": "probabilistic_distributions"}, {"score": 0.002990592465417758, "phrase": "temporal_relationships"}, {"score": 0.0029519664912853938, "phrase": "action_sequence"}, {"score": 0.0029012378668247397, "phrase": "classification_phase"}, {"score": 0.002863762666256937, "phrase": "support-vector_machine"}, {"score": 0.002766171878646582, "phrase": "final_classifier"}, {"score": 0.0024606422183102382, "phrase": "action_recognition"}, {"score": 0.0024183363693242943, "phrase": "previous_work"}, {"score": 0.0023767561522363367, "phrase": "overall_accuracies"}, {"score": 0.002246492918032836, "phrase": "kth"}, {"score": 0.002207851585508636, "phrase": "ixmas"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Action recognition", " Pyramidal motion features", " Boosted key-frame selection", " Correlograms"], "paper_abstract": "In this paper we propose a novel method for human action recognition based on boosted key-frame selection and correlated pyramidal motion feature representations. Instead of using an unsupervised method to detect interest points, a Pyramidal Motion Feature (PMF), which combines optical flow with a biologically inspired feature, is extracted from each frame of a video sequence. The AdaBoost learning algorithm is then applied to select the most discriminative frames from a large feature pool. In this way, we obtain the top-ranked boosted frames of each video sequence as the key frames which carry the most representative motion information. Furthermore, we utilise the correlogram which focuses not only on probabilistic distributions within one frame but also on the temporal relationships of the action sequence. In the classification phase, a Support-Vector Machine (SVM) is adopted as the final classifier for human action recognition. To demonstrate generalizability, our method has been systematically tested on a variety of datasets and shown to be more effective and accurate for action recognition compared to the previous work. We obtain overall accuracies of: 95.5%, 93.7%, and 36.5% with our proposed method on the KTH, the multiview IXMAS and the challenging HMDB51 datasets, respectively. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Boosted key-frame selection and correlated pyramidal motion-feature representation for human action recognition", "paper_id": "WOS:000317886600008"}