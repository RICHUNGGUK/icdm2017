{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "convex_quadratic_programming_algorithms"}, {"score": 0.0045318666714939905, "phrase": "state-of-the-art_decomposable_convex_quadratic_programming"}, {"score": 0.004218602458288531, "phrase": "original_problem"}, {"score": 0.004014452814186653, "phrase": "dual_variables"}, {"score": 0.0039269071382230444, "phrase": "hierarchical_optimization_scheme"}, {"score": 0.003841263262252044, "phrase": "lower_level"}, {"score": 0.003675517796014622, "phrase": "parametric_qps"}, {"score": 0.0034975571855450373, "phrase": "high-level_problem"}, {"score": 0.003440166097491567, "phrase": "gradient-based_method"}, {"score": 0.003328184259386487, "phrase": "optimal_dual_solution"}, {"score": 0.00325555555110395, "phrase": "optimal_dual_variables"}, {"score": 0.0032021226849872054, "phrase": "hard_problem"}, {"score": 0.0031495640320537283, "phrase": "dual_function"}, {"score": 0.00282048824450047, "phrase": "convex_qps"}, {"score": 0.002713604305939145, "phrase": "theoretical_worst-case_convergence_properties"}, {"score": 0.00240328454980006, "phrase": "open-source_software"}, {"score": 0.0022741894748181243, "phrase": "alternating_direction_method"}, {"score": 0.0022122603123901114, "phrase": "restarted_version"}, {"score": 0.002175913488493802, "phrase": "fast_gradient_method"}, {"score": 0.0021401625519713577, "phrase": "best_methods"}, {"score": 0.0021049977753042253, "phrase": "decomposable_qps"}], "paper_keywords": ["large-scale optimization", " quadratic programming", " distributed optimization", " dual decomposition"], "paper_abstract": "This paper aims to collect, benchmark and implement state-of-the-art decomposable convex quadratic programming (QP) methods employing duality. In order to decouple the original problem, these methods relax some constraints by introducing dual variables and apply a hierarchical optimization scheme. In the lower level of this scheme, a sequence of parametric QPs is solved in parallel, while in the high-level problem, a gradient-based method is applied to achieve an optimal dual solution. Finding the optimal dual variables is a hard problem since the dual function is not twice continuously differentiable and not strongly convex. We investigate and compare several gradient-based methods using a set of convex QPs as benchmarks. We discuss the theoretical worst-case convergence properties of the investigated methods, but we also evaluate their practical convergence behaviour. The benchmark set as well as the suite of implemented algorithms are released as open-source software. From our experiments, it turns out that the alternating direction method of multipliers and the restarted version of the fast gradient method are the best methods for solving decomposable QPs in terms of the number of necessary, lower level QP solutions.", "paper_title": "Benchmarking large-scale distributed convex quadratic programming algorithms", "paper_id": "WOS:000345371800008"}