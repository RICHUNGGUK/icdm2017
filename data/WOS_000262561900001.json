{"auto_keywords": [{"score": 0.04260675614564952, "phrase": "new_model"}, {"score": 0.00481495049065317, "phrase": "highly_accurate_method"}, {"score": 0.004681525814235883, "phrase": "redundant_arrays"}, {"score": 0.00462919213721188, "phrase": "inexpensive_disks"}, {"score": 0.004475659507646842, "phrase": "statistical_bases"}, {"score": 0.004425616928975799, "phrase": "current_models"}, {"score": 0.004376131419366239, "phrase": "raid_reliability"}, {"score": 0.004230956171850591, "phrase": "highly_accurate_alternative"}, {"score": 0.004022137057452406, "phrase": "statistical_errors"}, {"score": 0.003932654396285872, "phrase": "pervasive_assumption"}, {"score": 0.0036347979916389467, "phrase": "homogeneous_poisson_process"}, {"score": 0.003104849179057156, "phrase": "statistical_justification"}, {"score": 0.002951444412262927, "phrase": "repairable_systems"}, {"score": 0.002853396755102163, "phrase": "field_data"}, {"score": 0.002727700630869639, "phrase": "catastrophic_failure"}, {"score": 0.0025208755851561368, "phrase": "model_results"}, {"score": 0.002264982416465872, "phrase": "system-level_field_data"}, {"score": 0.0021529842700733974, "phrase": "excellent_correlation"}, {"score": 0.0021288561076024844, "phrase": "greater_accuracy"}], "paper_keywords": ["Monte Carlo simulation", " redundant systems", " reliability modeling", " repairable systems"], "paper_abstract": "The statistical bases for current models of RAID reliability are reviewed, and a highly accurate alternative is provided and justified. This new model corrects statistical errors associated with the pervasive assumption that system (RAID group) times-to-failure follow a homogeneous Poisson process, and it corrects errors associated with the assumption that the time-to-failure and time-to-restore distributions are exponentially distributed. Statistical justification for the new model uses theories of reliability of repairable systems. Four critical component distributions are developed from field data. These distributions are for times to catastrophic failure, reconstruction and restoration, read errors, and disk data scrubs. Model results have been verified to predict between 2 and 1,500 times as many double disk failures as estimates made using the mean time-to-data-loss (MTTDL) method. Model results are compared to system-level field data for a RAID group of 14 drives and show excellent correlation and greater accuracy than either MTTDL or Markov models.", "paper_title": "A Highly Accurate Method for Assessing Reliability of Redundant Arrays of Inexpensive Disks (RAID)", "paper_id": "WOS:000262561900001"}