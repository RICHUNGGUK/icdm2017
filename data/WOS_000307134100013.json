{"auto_keywords": [{"score": 0.04938622488322166, "phrase": "phase_feature"}, {"score": 0.04520816487989676, "phrase": "proposed_method"}, {"score": 0.03855906999782288, "phrase": "background_model"}, {"score": 0.00481495049065317, "phrase": "background_subtraction"}, {"score": 0.004608879242346434, "phrase": "novel_background_subtraction_method"}, {"score": 0.004498213310668266, "phrase": "complex_environments"}, {"score": 0.004101281992566145, "phrase": "based_background_model"}, {"score": 0.0040027552011993005, "phrase": "foreground_refinement"}, {"score": 0.003721098220825489, "phrase": "background_modeling"}, {"score": 0.0034423989472667756, "phrase": "adaptive_phase_features"}, {"score": 0.003376037544631762, "phrase": "foreground_detection_result"}, {"score": 0.0032471155306148156, "phrase": "sparse_pixels"}, {"score": 0.003200045185608395, "phrase": "basic_structure"}, {"score": 0.003003809128328864, "phrase": "next_stage"}, {"score": 0.0027651847105654363, "phrase": "final_result"}, {"score": 0.002608218347502229, "phrase": "dynamic_background"}, {"score": 0.0025207920578878894, "phrase": "sudden_illumination_change"}, {"score": 0.002436289099444074, "phrase": "bootstrapping_limitations"}, {"score": 0.0023546121947302877, "phrase": "background_initialization_constraints"}, {"score": 0.0023091721866305426, "phrase": "real_data_sets"}, {"score": 0.0022536005664642294, "phrase": "existing_techniques"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Background subtraction", " Phase feature", " Phase based background model", " Distance transform"], "paper_abstract": "A novel background subtraction method that can work under complex environments is presented in this paper. The proposed method consists of two stages: coarse foreground detection through the phase based background model we present, and foreground refinement using the distance transform. We first propose a phase feature which is suitable for background modeling. The background model is then built where each pixel is modeled as a group of adaptive phase features. Although the foreground detection result produced by the background model only contains some sparse pixels, the basic structure of the foreground has been captured as a whole. In the next stage, we adopt the distance transform to aggregate the pixels surrounding the foreground so that the final result is more clear and integrated. Our method can handle many complex situations including dynamic background and illumination variations, especially for sudden illumination change. Besides, it has no bootstrapping limitations, which means our method is without background initialization constraints. Experiments on real data sets and comparison with the existing techniques show that the proposed method is effective and robust. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Background subtraction based on phase feature and distance transform", "paper_id": "WOS:000307134100013"}