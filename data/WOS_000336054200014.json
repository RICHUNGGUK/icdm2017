{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "movable_platforms"}, {"score": 0.004621148492564008, "phrase": "novel_probabilistic_generative_model"}, {"score": 0.0037798652680135106, "phrase": "impressive_driving_capabilities"}, {"score": 0.003545625043276134, "phrase": "map_knowledge"}, {"score": 0.0034027387694902287, "phrase": "diverse_set"}, {"score": 0.003371773890338284, "phrase": "visual_cues"}, {"score": 0.0032955848190195343, "phrase": "vehicle_tracklets"}, {"score": 0.0032211117623834828, "phrase": "semantic_scene_labels"}, {"score": 0.0031917943932454314, "phrase": "scene_flow"}, {"score": 0.003148316319108045, "phrase": "occupancy_grids"}, {"score": 0.0030076088903023034, "phrase": "likelihood_functions"}, {"score": 0.002926212333939311, "phrase": "probabilistic_generative_model"}, {"score": 0.0028600623410146796, "phrase": "model_parameters"}, {"score": 0.0028340217672278975, "phrase": "training_data"}, {"score": 0.0028082176224611542, "phrase": "contrastive_divergence"}, {"score": 0.002634031703695684, "phrase": "correct_layout"}, {"score": 0.0024819522818492284, "phrase": "feature_cue"}, {"score": 0.00243694486220507, "phrase": "different_feature_combinations"}, {"score": 0.002275299774554847, "phrase": "proposed_method"}, {"score": 0.0021243539405631866, "phrase": "object_orientation_estimation"}, {"score": 0.0021049977753042253, "phrase": "challenging_and_cluttered_urban_environments"}], "paper_keywords": ["3D scene understanding", " autonomous driving", " 3D scene layout estimation"], "paper_abstract": "In this paper, we present a novel probabilistic generative model for multi-object traffic scene understanding from movable platforms which reasons jointly about the 3D scene layout as well as the location and orientation of objects in the scene. In particular, the scene topology, geometry, and traffic activities are inferred from short video sequences. Inspired by the impressive driving capabilities of humans, our model does not rely on GPS, lidar, or map knowledge. Instead, it takes advantage of a diverse set of visual cues in the form of vehicle tracklets, vanishing points, semantic scene labels, scene flow, and occupancy grids. For each of these cues, we propose likelihood functions that are integrated into a probabilistic generative model. We learn all model parameters from training data using contrastive divergence. Experiments conducted on videos of 113 representative intersections show that our approach successfully infers the correct layout in a variety of very challenging scenarios. To evaluate the importance of each feature cue, experiments using different feature combinations are conducted. Furthermore, we show how by employing context derived from the proposed method we are able to improve over the state-of-the-art in terms of object detection and object orientation estimation in challenging and cluttered urban environments.", "paper_title": "3D Traffic Scene Understanding from Movable Platforms", "paper_id": "WOS:000336054200014"}