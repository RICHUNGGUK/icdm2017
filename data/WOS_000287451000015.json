{"auto_keywords": [{"score": 0.050062327084529346, "phrase": "nelder-mead"}, {"score": 0.0370524624129902, "phrase": "nmr"}, {"score": 0.030946196190118187, "phrase": "equal_constraints"}, {"score": 0.02523441798393272, "phrase": "main_index"}, {"score": 0.004701985831087475, "phrase": "nonlinear_optimization_algorithms"}, {"score": 0.00459165923324494, "phrase": "local_exploitation_methods"}, {"score": 0.004485252194987703, "phrase": "nm"}, {"score": 0.004275904315753662, "phrase": "differential_evolution"}, {"score": 0.00398177607914381, "phrase": "local_optimum"}, {"score": 0.0038698476651328898, "phrase": "better_convergence_quality"}, {"score": 0.0037789720824759503, "phrase": "hybrid_differential_evolution"}, {"score": 0.0037432199549135826, "phrase": "nm_algorithm"}, {"score": 0.003569451476205552, "phrase": "modified_nm"}, {"score": 0.003355515315708125, "phrase": "optimum_point"}, {"score": 0.003307988966112615, "phrase": "first_time"}, {"score": 0.0031096747349602344, "phrase": "better_properties"}, {"score": 0.002895535087931938, "phrase": "adaptive_penalty_function_method"}, {"score": 0.0027610089418453614, "phrase": "unequal_constrained_functions"}, {"score": 0.0027218799769229596, "phrase": "adaptive_relaxation_parameter"}, {"score": 0.0026452734009203764, "phrase": "benchmark_optimization_problems"}, {"score": 0.0025954008219792337, "phrase": "engineering_design_problems"}, {"score": 0.0024281181691350085, "phrase": "function_evaluation_times"}, {"score": 0.002337403139264533, "phrase": "convergence_speed"}, {"score": 0.002304263635960015, "phrase": "objective_function_values"}, {"score": 0.0022500695985527668, "phrase": "optimum's_quality"}, {"score": 0.0022287497627555895, "phrase": "non-parametric_tests"}, {"score": 0.0021049977753042253, "phrase": "fast_convergence_speed"}], "paper_keywords": ["Nelder-Mead algorithm", " Differential evolution", " Hybrid algorithm", " Memetic algorithm"], "paper_abstract": "Nonlinear optimization algorithms could be divided into local exploitation methods such as Nelder-Mead (NM) algorithm and global exploration ones, such as differential evolution (DE). The former searches fast yet could be easily trapped by local optimum, whereas the latter possesses better convergence quality. This paper proposes hybrid differential evolution and NM algorithm with re-optimization, called as DE-NMR. At first a modified NM, called NMR is presented. It re-optimizes from the optimum point at the first time and thus being able to jump out of local optimum, exhibits better properties than NM. Then, NMR is combined with DE. To deal with equal constraints, adaptive penalty function method is adopted in DE-NMR, which relaxes equal constraints into unequal constrained functions with an adaptive relaxation parameter that varies with iteration. Benchmark optimization problems as well as engineering design problems are used to experiment the performance of DE-NMR, with the number of function evaluation times being employed as the main index of measuring convergence speed, and objective function values as the main index of optimum's quality. Non-parametric tests are employed in comparing results with other global optimization algorithms. Results illustrate the fast convergence speed of DE-NMR.", "paper_title": "Hybrid differential evolution and Nelder-Mead algorithm with re-optimization", "paper_id": "WOS:000287451000015"}