{"auto_keywords": [{"score": 0.026558765099497162, "phrase": "average_classification_accuracies"}, {"score": 0.00481495049065317, "phrase": "retinal_images"}, {"score": 0.004750527930368202, "phrase": "context-aware_hybrid_features"}, {"score": 0.0046242451772036145, "phrase": "important_problem"}, {"score": 0.004582897918101983, "phrase": "medical_image_analysis"}, {"score": 0.004441059405327222, "phrase": "large_variations"}, {"score": 0.004401342842183475, "phrase": "vessel_appearance"}, {"score": 0.0042650992966174065, "phrase": "image_noises"}, {"score": 0.004023120753104693, "phrase": "heterogeneous_context-aware_features"}, {"score": 0.003969250376327401, "phrase": "discriminative_learning_framework"}, {"score": 0.00374399358035391, "phrase": "hybrid_feature_pool"}, {"score": 0.003628024127607343, "phrase": "stroke_width_transform"}, {"score": 0.0035955592608027213, "phrase": "swt"}, {"score": 0.0035474484871285826, "phrase": "weber"}, {"score": 0.0033160345607565565, "phrase": "intensity_values"}, {"score": 0.00328640556310295, "phrase": "gabor"}, {"score": 0.003141830113006653, "phrase": "context_information"}, {"score": 0.003085813569061001, "phrase": "hybrid_features"}, {"score": 0.003044455555031339, "phrase": "orientation_invariant_local_context"}, {"score": 0.002963390095037466, "phrase": "pixel-level_vessel_segmentation"}, {"score": 0.0029236680654022664, "phrase": "discriminative_classification_problem"}, {"score": 0.0028586409810976367, "phrase": "random_forest"}, {"score": 0.0028076592725295646, "phrase": "rich_information"}, {"score": 0.0027575842698911173, "phrase": "hybrid_context-aware_features"}, {"score": 0.0026841368358805407, "phrase": "proposed_method"}, {"score": 0.0026362590493392785, "phrase": "retinal_vessel_segmentation"}, {"score": 0.0025661707289153135, "phrase": "drive"}, {"score": 0.002543043781904587, "phrase": "stare_datasets"}, {"score": 0.002398529964696261, "phrase": "high-resolution_dataset_hrfid"}, {"score": 0.0021336208506092173, "phrase": "hybrid_feature_fusion"}, {"score": 0.0021049977753042253, "phrase": "individual_component"}], "paper_keywords": ["Vessel segmentation", " Random forest", " Stroke width transform", " Weber's local descriptors"], "paper_abstract": "Vessel segmentation is an important problem in medical image analysis and is often challenging due to large variations in vessel appearance and profiles, as well as image noises. To address these challenges, we propose a solution by combining heterogeneous context-aware features with a discriminative learning framework. Our solution is characterized by three key ingredients: First, we design a hybrid feature pool containing recently invented descriptors including the stroke width transform (SWT) and Weber's local descriptors (WLD), as well as classical local features including intensity values, Gabor responses and vesselness measurements. Second, we encode context information by sampling the hybrid features from an orientation invariant local context. Third, we treat pixel-level vessel segmentation as a discriminative classification problem, and use a random forest to fuse the rich information encoded in the hybrid context-aware features. For evaluation, the proposed method is applied to retinal vessel segmentation using three publicly available benchmark datasets. On the DRIVE and STARE datasets, our approach achieves average classification accuracies of 0.9474 and 0.9633, respectively. On the high-resolution dataset HRFID, our approach achieves average classification accuracies of 0.9647, 0.9561 and 0.9634 on three different categories, respectively. Experiments are also conducted to validate the superiority of hybrid feature fusion over each individual component.", "paper_title": "Discriminative vessel segmentation in retinal images by fusing context-aware hybrid features", "paper_id": "WOS:000342435800013"}