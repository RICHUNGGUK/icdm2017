{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "expressive_hand_gestures"}, {"score": 0.0046970764288494764, "phrase": "handheld_device"}, {"score": 0.00446987606516801, "phrase": "mobile_phone_application"}, {"score": 0.004396600680348434, "phrase": "moodifierlive"}, {"score": 0.004218602458288531, "phrase": "expressive_music_performances"}, {"score": 0.004047781270412204, "phrase": "expressive_gestures"}, {"score": 0.0038518661517315533, "phrase": "phone's_accelerometer_data"}, {"score": 0.003757480190200645, "phrase": "performance_parameters"}, {"score": 0.0032109670662222416, "phrase": "sonification_principle"}, {"score": 0.0028360962841331634, "phrase": "perceived_matching"}, {"score": 0.0026986685585382347, "phrase": "music_performance"}, {"score": 0.002305799666781492, "phrase": "consistent_performances"}, {"score": 0.0021049977753042253, "phrase": "real_gestures"}], "paper_keywords": ["Sonification", " Automatic music performance", " Emotional hand gestures", " Mobile phone"], "paper_abstract": "We present here a mobile phone application called MoodifierLive which aims at using expressive music performances for the sonification of expressive gestures through the mapping of the phone's accelerometer data to the performance parameters (i.e. tempo, sound level, and articulation). The application, and in particular the sonification principle, is described in detail. An experiment was carried out to evaluate the perceived matching between the gesture and the music performance that it produced, using two distinct mappings between gestures and performance. The results show that the application produces consistent performances, and that the mapping based on data collected from real gestures works better than one defined a priori by the authors.", "paper_title": "Interactive sonification of expressive hand gestures on a handheld device", "paper_id": "WOS:000309998800006"}