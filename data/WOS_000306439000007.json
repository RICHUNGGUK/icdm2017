{"auto_keywords": [{"score": 0.04048126372530425, "phrase": "large_number"}, {"score": 0.03924349302513645, "phrase": "training_examples"}, {"score": 0.00481495049065317, "phrase": "convolution_tree_kernels"}, {"score": 0.004780633011300165, "phrase": "feature_engineering"}, {"score": 0.004662427600500598, "phrase": "system_design"}, {"score": 0.00462919213721188, "phrase": "machine_learning"}, {"score": 0.004563427013973105, "phrase": "kernel_methods"}, {"score": 0.004482526999029664, "phrase": "formidable_tools"}, {"score": 0.004187917910692495, "phrase": "structured_data"}, {"score": 0.0041580507929967645, "phrase": "diverse_domains"}, {"score": 0.00406971620207041, "phrase": "data_mining"}, {"score": 0.004040688646993605, "phrase": "natural_language_processing"}, {"score": 0.003829455440282146, "phrase": "kernel_computations"}, {"score": 0.0034271313706984658, "phrase": "redundant_kernel_evaluations"}, {"score": 0.0032947371184395237, "phrase": "directed_acyclic_graphs"}, {"score": 0.0032246835734680377, "phrase": "represent_trees"}, {"score": 0.0031902155632863236, "phrase": "training_algorithm"}, {"score": 0.003167441161387607, "phrase": "support_vector_machines"}, {"score": 0.003023307182674672, "phrase": "cutting_plane_algorithm"}, {"score": 0.0028446460307503343, "phrase": "dag_kernels"}, {"score": 0.0027741761880779535, "phrase": "current_model"}, {"score": 0.002676514445417281, "phrase": "total_computation"}, {"score": 0.0026289770980696286, "phrase": "redundant_evaluations"}, {"score": 0.002610198789888055, "phrase": "shared_substructures"}, {"score": 0.0024296194239886676, "phrase": "empirical_results"}, {"score": 0.0023440589015485077, "phrase": "significant_speedups"}, {"score": 0.002327310963701377, "phrase": "previous_state-of-the-art_methods"}, {"score": 0.0022615046141708987, "phrase": "alternative_sampling_strategy"}, {"score": 0.0022054488653549175, "phrase": "class-imbalance_problem"}, {"score": 0.0021662599012740127, "phrase": "fast_learning_methods"}, {"score": 0.0021430808503936963, "phrase": "viable_tk_learning_framework"}, {"score": 0.0021201492891323587, "phrase": "large_class"}, {"score": 0.0021049977753042253, "phrase": "real-world_applications"}], "paper_keywords": ["Kernel methods", " Tree kernels", " Natural language processing", " Large scale learning"], "paper_abstract": "Feature engineering is one of the most complex aspects of system design in machine learning. Fortunately, kernel methods provide the designer with formidable tools to tackle such complexity. Among others, tree kernels (TKs) have been successfully applied for representing structured data in diverse domains, ranging from bioinformatics and data mining to natural language processing. One drawback of such methods is that learning with them typically requires a large number of kernel computations (quadratic in the number of training examples) between training examples. However, in practice substructures often repeat in the data which makes it possible to avoid a large number of redundant kernel evaluations. In this paper, we propose the use of Directed Acyclic Graphs (DAGs) to compactly represent trees in the training algorithm of Support Vector Machines. In particular, we use DAGs for each iteration of the cutting plane algorithm (CPA) to encode the model composed by a set of trees. This enables DAG kernels to efficiently evaluate TKs between the current model and a given training tree. Consequently, the amount of total computation is reduced by avoiding redundant evaluations over shared substructures. We provide theory and algorithms to formally characterize the above idea, which we tested on several datasets. The empirical results confirm the benefits of the approach in terms of significant speedups over previous state-of-the-art methods. In addition, we propose an alternative sampling strategy within the CPA to address the class-imbalance problem, which coupled with fast learning methods provides a viable TK learning framework for a large class of real-world applications.", "paper_title": "Fast support vector machines for convolution tree kernels", "paper_id": "WOS:000306439000007"}