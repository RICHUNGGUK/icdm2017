{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "nondeterministic_and_probabilistic_planning"}, {"score": 0.00464976086880886, "phrase": "markov_decision_processes"}, {"score": 0.004336115760817672, "phrase": "unifying_formulation"}, {"score": 0.003996727479807572, "phrase": "ai_planning"}, {"score": 0.003859500298805362, "phrase": "different_strategies"}, {"score": 0.003726967166630923, "phrase": "nondeterministic_planning"}, {"score": 0.0032786537599187125, "phrase": "probabilistic_planning_attempts"}, {"score": 0.0031660031870090434, "phrase": "expected_reward"}, {"score": 0.00278497898719426, "phrase": "special_cases"}, {"score": 0.0024784363584530976, "phrase": "resulting_structures"}, {"score": 0.002421291757425244, "phrase": "markov_decision"}, {"score": 0.0023380300046435187, "phrase": "imprecise_probabilities"}, {"score": 0.0021049977753042253, "phrase": "existing_algorithms"}], "paper_keywords": [""], "paper_abstract": "This paper proposes an unifying formulation for nondeterministic and probabilistic planning. These two strands of AI planning have followed different strategies: while nondeterministic planning usually looks for minimax (or worst-case) policies, probabilistic planning attempts to maximize expected reward. In this paper we show that both problems are special cases of a more general approach, and we demonstrate that the resulting structures are Markov Decision Processes with Imprecise Probabilities (MDPIPs). We also show how existing algorithms for MDPIPs can be adapted to planning under uncertainty.", "paper_title": "Unifying nondeterministic and probabilistic planning through imprecise Markov Decision Processes", "paper_id": "WOS:000242128100054"}