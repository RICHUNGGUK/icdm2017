{"auto_keywords": [{"score": 0.042074474479433896, "phrase": "new_information"}, {"score": 0.00481495049065317, "phrase": "incremental_algorithm"}, {"score": 0.004752873752686246, "phrase": "error_margins"}, {"score": 0.004651177631663439, "phrase": "quite_relevant_task"}, {"score": 0.004611108249179507, "phrase": "data_analysis_field"}, {"score": 0.004473552224535518, "phrase": "trivial_task"}, {"score": 0.004435006247087171, "phrase": "different_difficulties"}, {"score": 0.003894963476923956, "phrase": "incremental_learning"}, {"score": 0.003697760799674494, "phrase": "classification_task"}, {"score": 0.003465189575252443, "phrase": "limited_time"}, {"score": 0.0034353020860809404, "phrase": "memory_resources"}, {"score": 0.0033762956164519286, "phrase": "concentration_bounds"}, {"score": 0.003205268682789165, "phrase": "iadem"}, {"score": 0.0028762004595878714, "phrase": "different_ways"}, {"score": 0.002790254164160135, "phrase": "induced_models"}, {"score": 0.0026951616152303373, "phrase": "continuous_data"}, {"score": 0.0025920406425973368, "phrase": "new_criteria"}, {"score": 0.0024183363693242943, "phrase": "new_properties"}, {"score": 0.002387083859537412, "phrase": "new_system"}, {"score": 0.0022562464662197867, "phrase": "standard_learning_algorithms"}, {"score": 0.0022174469839432013, "phrase": "datasets_size"}, {"score": 0.0021418339161425994, "phrase": "basic_algorithm"}, {"score": 0.0021049977753042253, "phrase": "short_time"}], "paper_keywords": ["data mining", " incremental learning", " no example memory", " Chernoff and Hoeffding bounds", " decision trees", " continuous attributes", " functional leaves"], "paper_abstract": "Classification is a quite relevant task within data analysis field. This task is not a trivial task and different difficulties can arise depending on the nature of the problem. All these difficulties can become worse when the datasets are too large or when new information can arrive at any time. Incremental learning is an approach that can be used to deal with the classification task in these cases. It must alleviate, or solve, the problem of limited time and memory resources. One emergent approach uses concentration bounds to ensure that decisions are made when enough information supports them. IADEM is one of the most recent algorithms that use this approach. The aim of this paper is to improve the performance of this algorithm in different ways: simplifying the complexity of the induced models, adding the ability to deal with continuous data, improving the detection of noise, selecting new criteria for evolutionating the model, including the use of more powerful prediction techniques, etc. Besides these new properties, the new system, IADEM-2, preserves the ability to obtain a performance similar to standard learning algorithms independently of the datasets size and it can incorporate new information as the basic algorithm does: using short time per example.", "paper_title": "Improving the performance of an incremental algorithm driven by error margins", "paper_id": "WOS:000257115300005"}