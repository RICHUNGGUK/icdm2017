{"auto_keywords": [{"score": 0.04820929802388968, "phrase": "depth_maps"}, {"score": 0.008599330805647409, "phrase": "depth-image-based_rendering"}, {"score": 0.00831971339884566, "phrase": "multiview_images"}, {"score": 0.005045573750484617, "phrase": "quantization_levels"}, {"score": 0.005012211267155034, "phrase": "corresponding_texture"}, {"score": 0.00481495049065317, "phrase": "dependent_bit_allocation"}, {"score": 0.004783105609960904, "phrase": "multiview_image_coding"}, {"score": 0.004490842671590769, "phrase": "spatially_correlated_cameras"}, {"score": 0.004160740888748725, "phrase": "efficient_bit_allocation"}, {"score": 0.0039323878878973284, "phrase": "coding_tool"}, {"score": 0.003716520760680603, "phrase": "intermediate_views"}, {"score": 0.0036553070575015344, "phrase": "neighboring_encoded_texture"}, {"score": 0.0035124618008923504, "phrase": "captured_views"}, {"score": 0.0034545974376846687, "phrase": "available_bits"}, {"score": 0.003375179864844835, "phrase": "selected_coded_views"}, {"score": 0.003319569552937513, "phrase": "visual_distortion"}, {"score": 0.0032975819773787985, "phrase": "desired_constructed_views"}, {"score": 0.0031476805104529377, "phrase": "low_complexity_estimate"}, {"score": 0.0031164532805849432, "phrase": "visual_quality"}, {"score": 0.0030855348881460107, "phrase": "large_number"}, {"score": 0.003065092702656417, "phrase": "desired_synthesized_views"}, {"score": 0.003014576010931602, "phrase": "cubic_distortion_model"}, {"score": 0.0029846653187175012, "phrase": "basic_dibr_properties"}, {"score": 0.002820675782452964, "phrase": "optimal_selection"}, {"score": 0.002801983400946225, "phrase": "coded_views"}, {"score": 0.002701361707441567, "phrase": "shortest_path"}, {"score": 0.002544422946205545, "phrase": "predictor's_quantization_level"}, {"score": 0.002510801832283111, "phrase": "suboptimal_solutions"}, {"score": 0.002453027723284009, "phrase": "feasible_space"}, {"score": 0.002436765760924074, "phrase": "solution_search"}, {"score": 0.0023028105026714533, "phrase": "alternative_scheme"}, {"score": 0.002287542098172185, "phrase": "constant_quantization_levels"}, {"score": 0.0022274718912558343, "phrase": "video_standard_implementations"}, {"score": 0.0021049977753042253, "phrase": "full_solution_search"}], "paper_keywords": ["Bit allocation", " depth-image-based rendering", " 3-D image coding"], "paper_abstract": "The encoding of both texture and depth maps of multiview images, captured by a set of spatially correlated cameras, is important for any 3-D visual communication system based on depth-image-based rendering (DIBR). In this paper, we address the problem of efficient bit allocation among texture and depth maps of multiview images. More specifically, suppose we are given a coding tool to encode texture and depth maps at the encoder and a view-synthesis tool to construct intermediate views at the decoder using neighboring encoded texture and depth maps. Our goal is to determine how to best select captured views for encoding and distribute available bits among texture and depth maps of selected coded views, such that the visual distortion of desired constructed views is minimized. First, in order to obtain at the encoder a low complexity estimate of the visual quality of a large number of desired synthesized views, we derive a cubic distortion model based on basic DIBR properties, whose parameters are obtained using only a small number of viewpoint samples. Then, we demonstrate that the optimal selection of coded views and quantization levels for corresponding texture and depth maps is equivalent to the shortest path in a specially constructed 3-D trellis. Finally, we show that, using the assumptions of monotonicity in the predictor's quantization level and distance, suboptimal solutions can be efficiently pruned from the feasible space during solution search. Experiments show that our proposed efficient selection of coded views and quantization levels for corresponding texture and depth maps outperforms an alternative scheme using constant quantization levels for all maps (commonly used in video standard implementations) by up to 1.5 dB. Moreover, the complexity of our scheme can be reduced by at least 80% over the full solution search.", "paper_title": "On Dependent Bit Allocation for Multiview Image Coding With Depth-Image-Based Rendering", "paper_id": "WOS:000296016200015"}