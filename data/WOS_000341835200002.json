{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "class_probability_estimates"}, {"score": 0.049613254104042076, "phrase": "imbalanced_data"}, {"score": 0.04074141016787776, "phrase": "imbalanced_scenarios"}, {"score": 0.0046986841646790315, "phrase": "good_probability_estimates"}, {"score": 0.004540591176992658, "phrase": "increased_uncertainty"}, {"score": 0.004496402246090618, "phrase": "typically_asymmetric_costs"}, {"score": 0.004452641437293878, "phrase": "rare_events"}, {"score": 0.00428179779071721, "phrase": "classification_systems"}, {"score": 0.003920891569777894, "phrase": "supervised_learning"}, {"score": 0.003770373393393271, "phrase": "minority_class_instances"}, {"score": 0.003715425273229361, "phrase": "ostensibly_good_overall_calibration"}, {"score": 0.0034355662264234864, "phrase": "new_metric"}, {"score": 0.003368950018828122, "phrase": "brier"}, {"score": 0.003287482882222731, "phrase": "class-specific_calibration"}, {"score": 0.0032079813320482304, "phrase": "per-class_metrics"}, {"score": 0.003115105266246263, "phrase": "discriminative_performance"}, {"score": 0.0028944757265206332, "phrase": "probability_estimates"}, {"score": 0.002769650208851401, "phrase": "balanced_bootstrap_samples"}, {"score": 0.0026501935378083663, "phrase": "minority_instances"}, {"score": 0.002598764579760562, "phrase": "overall_calibration"}, {"score": 0.002474505516708906, "phrase": "ample_additional_empirical_evidence"}, {"score": 0.002356173823922118, "phrase": "support_vector_machines"}, {"score": 0.002321787726770895, "phrase": "decision_trees"}, {"score": 0.00229914226836813, "phrase": "base_learners"}, {"score": 0.0022216045996270974, "phrase": "additional_uncertainty"}, {"score": 0.002157223877108711, "phrase": "bayesian_approach"}, {"score": 0.002125735077004312, "phrase": "posterior_distributions"}, {"score": 0.0021049977753042253, "phrase": "bagged_probability_estimates"}], "paper_keywords": ["Classification", " Imbalance", " Unbalance", " SVM", " Boosted decision-trees", " Platt", " Calibration", " Brier-score"], "paper_abstract": "Obtaining good probability estimates is imperative for many applications. The increased uncertainty and typically asymmetric costs surrounding rare events increase this need. Experts (and classification systems) often rely on probabilities to inform decisions. However, we demonstrate that class probability estimates obtained via supervised learning in imbalanced scenarios systematically underestimate the probabilities for minority class instances, despite ostensibly good overall calibration. To our knowledge, this problem has not previously been explored. We propose a new metric, the stratified Brier score, to capture class-specific calibration, analogous to the per-class metrics widely used to assess the discriminative performance of classifiers in imbalanced scenarios. We propose a simple, effective method to mitigate the bias of probability estimates for imbalanced data that bags estimators independently calibrated over balanced bootstrap samples. This approach drastically improves performance on the minority instances without greatly affecting overall calibration. We extend our previous work in this direction by providing ample additional empirical evidence for the utility of this strategy, using both support vector machines and boosted decision trees as base learners. Finally, we show that additional uncertainty can be exploited via a Bayesian approach by considering posterior distributions over bagged probability estimates.", "paper_title": "Improving class probability estimates for imbalanced data", "paper_id": "WOS:000341835200002"}