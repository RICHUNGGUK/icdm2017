{"auto_keywords": [{"score": 0.02799186975526375, "phrase": "youtube"}, {"score": 0.015753030866510732, "phrase": "cue"}, {"score": 0.00457553517865013, "phrase": "single_view_geometry"}, {"score": 0.004089725258435817, "phrase": "human_actions"}, {"score": 0.004007083686875716, "phrase": "scene_geometry"}, {"score": 0.0038862297330905836, "phrase": "human_pose"}, {"score": 0.0034733518170738517, "phrase": "recent_advances"}, {"score": 0.003403122817578447, "phrase": "still-image_pose_estimation"}, {"score": 0.0033004240095380623, "phrase": "functional_and_geometric_constraints"}, {"score": 0.002690406375639144, "phrase": "monocular_time-lapse_sequences"}, {"score": 0.0025826247025542235, "phrase": "still_images"}, {"score": 0.002530359917257626, "phrase": "indoor_scenes"}, {"score": 0.0022382002476510573, "phrase": "different_actions"}], "paper_keywords": ["Scene understanding", " Action recognition", " 3D reconstruction"], "paper_abstract": "We present an approach which exploits the coupling between human actions and scene geometry to use human pose as a cue for single-view 3D scene understanding. Our method builds upon recent advances in still-image pose estimation to extract functional and geometric constraints on the scene. These constraints are then used to improve single-view 3D scene understanding approaches. The proposed method is validated on monocular time-lapse sequences from YouTube and still images of indoor scenes gathered from the Internet. We demonstrate that observing people performing different actions can significantly improve estimates of 3D scene geometry.", "paper_title": "People Watching: Human Actions as a Cue for Single View Geometry", "paper_id": "WOS:000344754500003"}