{"auto_keywords": [{"score": 0.03503242712598693, "phrase": "sdaft"}, {"score": 0.015719716506582538, "phrase": "scalable_data"}, {"score": 0.0047152877145889656, "phrase": "parallel_blast."}, {"score": 0.004522080178250592, "phrase": "parallel_and_load-balanced_fashion"}, {"score": 0.0042692243768616455, "phrase": "data-initializing_stage"}, {"score": 0.004202741104973709, "phrase": "database_fragments"}, {"score": 0.0041589926969138585, "phrase": "shared_storage"}, {"score": 0.004115697805448384, "phrase": "local_cluster_nodes"}, {"score": 0.003988487841970088, "phrase": "exponentially_increasing_size"}, {"score": 0.003946960862020283, "phrase": "sequence_databases"}, {"score": 0.003905864553426306, "phrase": "today's_big_data_era"}, {"score": 0.003610929883213109, "phrase": "scalable_data_access_framework"}, {"score": 0.0035361001070845677, "phrase": "data_movement_problem"}, {"score": 0.0034992667091713813, "phrase": "scientific_applications"}, {"score": 0.0034088473318056537, "phrase": "\"read\"_operation"}, {"score": 0.0032689949867583633, "phrase": "distributed_file_system"}, {"score": 0.003118486096035156, "phrase": "parallel_sequence_searches"}, {"score": 0.002750056254309311, "phrase": "data-process_locality"}, {"score": 0.0025824645404044617, "phrase": "hdfs"}, {"score": 0.0025025186963415, "phrase": "real-world_database"}, {"score": 0.0024377918036784336, "phrase": "wide_variety"}, {"score": 0.002412371116984224, "phrase": "computing_platforms"}, {"score": 0.002218299213266519, "phrase": "double_the_overall_execution_performance"}, {"score": 0.002172266188075892, "phrase": "existing_schemes"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["MPI/POSIX I/O", " HDFS", " Parallel sequence search", " mpiBLAST"], "paper_abstract": "In order to run tasks in a parallel and load-balanced fashion, existing scientific parallel applications such as mpiBLAST introduce a data-initializing stage to move database fragments from shared storage to local cluster nodes. Unfortunately, with the exponentially increasing size of sequence databases in today's big data era, such an approach is inefficient. In this paper, we develop a scalable data access framework to solve the data movement problem for scientific applications that are dominated by \"read\" operation for data analysis. SDAFT employs a distributed file system (DFS) to provide scalable data access for parallel sequence searches. SDAFT consists of two interlocked components: (1) a data centric load-balanced scheduler (DC-scheduler) to enforce data-process locality and (2) a translation layer to translate conventional parallel I/O operations into HDFS I/O. By experimenting our SDAFT prototype system with real-world database and queries at a wide variety of computing platforms, we found that SDAFT can reduce I/O cost by a factor of 4-10 and double the overall execution performance as compared with existing schemes. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "SDAFT: A novel scalable data access framework for parallel BLAST", "paper_id": "WOS:000347018800010"}