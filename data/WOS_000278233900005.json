{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "interactive_learning"}, {"score": 0.042146579845206075, "phrase": "observed_data"}, {"score": 0.03927191262393186, "phrase": "negative_examples"}, {"score": 0.004565007074039171, "phrase": "gaussian-kernel-based_online_kernel_density_estimation"}, {"score": 0.004327981760540394, "phrase": "online_probability_density_estimation"}, {"score": 0.004103212598803194, "phrase": "gaussian_mixture_model"}, {"score": 0.003942299471749811, "phrase": "online_adaptation"}, {"score": 0.0038900709793274484, "phrase": "positive_examples"}, {"score": 0.0034730657554172405, "phrase": "novel_concept"}, {"score": 0.003381607100127276, "phrase": "mixture_models"}, {"score": 0.0033367819052051995, "phrase": "low_complexity"}, {"score": 0.003163326114997034, "phrase": "novel_compression_algorithm"}, {"score": 0.003039159447717346, "phrase": "existing_approaches"}, {"score": 0.0029198522863606953, "phrase": "fine-tuning_parameters"}, {"score": 0.002861961643289598, "phrase": "specific_application"}, {"score": 0.0027495914857929584, "phrase": "specific_forms"}, {"score": 0.0026950674053179404, "phrase": "target_distributions"}, {"score": 0.0026593184154220123, "phrase": "temporal_constraints"}, {"score": 0.0024545413637350765, "phrase": "proposed_approach"}, {"score": 0.00235813005446246, "phrase": "online_estimation"}, {"score": 0.0023268399760599336, "phrase": "complex_distributions"}, {"score": 0.0021476098263617954, "phrase": "basic_visual_concepts"}], "paper_keywords": ["Online learning", " Kernel density estimation", " Mixture models", " Unlearning", " Compression", " Hellinger distance", " Unscented transform"], "paper_abstract": "In this paper we propose a Gaussian-kernel-based online kernel density estimation which can be used for applications of online probability density estimation and online learning. Our approach generates a Gaussian mixture model of the observed data and allows online adaptation from positive examples as well as from the negative examples. The adaptation from the negative examples is realized by a novel concept of unlearning in mixture models. Low complexity of the mixtures is maintained through a novel compression algorithm. In contrast to the existing approaches, our approach does not require fine-tuning parameters for a specific application, we do not assume specific forms of the target distributions and temporal constraints are not assumed on the observed data. The strength of the proposed approach is demonstrated with examples of online estimation of complex distributions, an example of unlearning, and with an interactive learning of basic visual concepts. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Online kernel density estimation for interactive learning", "paper_id": "WOS:000278233900005"}