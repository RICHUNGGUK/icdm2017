{"auto_keywords": [{"score": 0.04816656693925314, "phrase": "feature_space"}, {"score": 0.009897085932812019, "phrase": "ranking_space"}, {"score": 0.006699317639801389, "phrase": "ranking_loss"}, {"score": 0.0058630020363755675, "phrase": "cluster_membership"}, {"score": 0.00481495049065317, "phrase": "label_preference_information"}, {"score": 0.004782366519650462, "phrase": "paper_studies"}, {"score": 0.004707188147442449, "phrase": "label_ranking_data"}, {"score": 0.0046018264570209765, "phrase": "k_clusters"}, {"score": 0.004358438393001596, "phrase": "target_marketing"}, {"score": 0.004280191565553763, "phrase": "k_different_offers"}, {"score": 0.004260849402060646, "phrase": "marketing_strategies"}, {"score": 0.004156012879026324, "phrase": "customers'_feature_space"}, {"score": 0.004053745316167863, "phrase": "potentially_incomplete_customer_preferences"}, {"score": 0.0037617394143447044, "phrase": "supervised_clustering"}, {"score": 0.00372779984173696, "phrase": "first_baseline"}, {"score": 0.0036608332080581884, "phrase": "unsupervised_manner"}, {"score": 0.003611396021719888, "phrase": "representative_label"}, {"score": 0.003546513036085932, "phrase": "second_baseline"}, {"score": 0.003522482515043419, "phrase": "label_ranking_space"}, {"score": 0.0034202112870283115, "phrase": "central_rankings"}, {"score": 0.0033893426032054366, "phrase": "third_baseline"}, {"score": 0.003335989038630716, "phrase": "new_feature_space"}, {"score": 0.003290924173136047, "phrase": "label_rankings"}, {"score": 0.0032317801670285477, "phrase": "original_feature"}, {"score": 0.003195354416820364, "phrase": "ranktree_principled_approach"}, {"score": 0.003159337923955675, "phrase": "ranking_tree_algorithm"}, {"score": 0.0031308163228919773, "phrase": "label_ranking_prediction"}, {"score": 0.0030955250132409964, "phrase": "k_random_label_rankings"}, {"score": 0.0029852361561542046, "phrase": "k_rankings"}, {"score": 0.002964997427833753, "phrase": "cluster_assignments"}, {"score": 0.002944895504859249, "phrase": "mm-pl_approach"}, {"score": 0.002814311589018427, "phrase": "voronoi_cells"}, {"score": 0.0027017308406240563, "phrase": "pl_label_scores"}, {"score": 0.0026411384812121503, "phrase": "ranking_prediction"}, {"score": 0.0026232264620319476, "phrase": "new_instance"}, {"score": 0.002570214113280047, "phrase": "unknown_cluster_pl_parameters"}, {"score": 0.0024785947526160296, "phrase": "expectation-maximization_algorithm"}, {"score": 0.00245063736667847, "phrase": "proposed_algorithms"}, {"score": 0.002428498125329827, "phrase": "synthetic_and_real-life_label"}, {"score": 0.002390233483029975, "phrase": "cluster_goodness"}, {"score": 0.002263549360744245, "phrase": "ranking_prediction_loss"}, {"score": 0.002253299769886694, "phrase": "experimental_results"}, {"score": 0.0022329393005738147, "phrase": "proposed_mm-pl_and_ranktree_models"}, {"score": 0.0021828376285310614, "phrase": "mm-pl"}, {"score": 0.002114574214145874, "phrase": "significant_fraction"}, {"score": 0.0021049977753042253, "phrase": "missing_label_preferences"}], "paper_keywords": ["Label ranking", " Supervised clustering", " Preference learning"], "paper_abstract": "This paper studies supervised clustering in the context of label ranking data. The goal is to partition the feature space into K clusters, such that they are compact in both the feature and label ranking space. This type of clustering has many potential applications. For example, in target marketing we might want to come up with K different offers or marketing strategies for our target audience. Thus, we aim at clustering the customers' feature space into K clusters by leveraging the revealed or stated, potentially incomplete customer preferences over products, such that the preferences of customers within one cluster are more similar to each other than to those of customers in other clusters. We establish several baseline algorithms and propose two principled algorithms for supervised clustering. In the first baseline, the clusters are created in an unsupervised manner, followed by assigning a representative label ranking to each cluster. In the second baseline, the label ranking space is clustered first, followed by partitioning the feature space based on the central rankings. In the third baseline, clustering is applied on a new feature space consisting of both features and label rankings, followed by mapping back to the original feature and ranking space. The RankTree principled approach is based on a Ranking Tree algorithm previously proposed for label ranking prediction. Our modification starts with K random label rankings and iteratively splits the feature space to minimize the ranking loss, followed by re-calculation of the K rankings based on cluster assignments. The MM-PL approach is a multi-prototype supervised clustering algorithm based on the Plackett-Luce (PL) probabilistic ranking model. It represents each cluster with a union of Voronoi cells that are defined by a set of prototypes, and assign each cluster with a set of PL label scores that determine the cluster central ranking. Cluster membership and ranking prediction for a new instance are determined by cluster membership of its nearest prototype. The unknown cluster PL parameters and prototype positions are learned by minimizing the ranking loss, based on two variants of the expectation-maximization algorithm. Evaluation of the proposed algorithms was conducted on synthetic and real-life label ranking data by considering several measures of cluster goodness: (1) cluster compactness in feature space, (2) cluster compactness in label ranking space and (3) label ranking prediction loss. Experimental results demonstrate that the proposed MM-PL and RankTree models are superior to the baseline models. Further, MM-PL is has shown to be much better than other algorithms at handling situations with significant fraction of missing label preferences.", "paper_title": "Supervised clustering of label ranking data using label preference information", "paper_id": "WOS:000324140400002"}