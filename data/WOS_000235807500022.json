{"auto_keywords": [{"score": 0.04858132305104682, "phrase": "neural_network"}, {"score": 0.03302176259272706, "phrase": "hidden_population"}, {"score": 0.00481495049065317, "phrase": "self-organizing_input"}, {"score": 0.004489810932879285, "phrase": "unsupervised_learning"}, {"score": 0.004133627071344356, "phrase": "general_information_processing_architecture"}, {"score": 0.0033508547759861186, "phrase": "input_population_form"}, {"score": 0.0030847461428168614, "phrase": "competitive_learning"}, {"score": 0.0029691377785333872, "phrase": "forward_projections"}, {"score": 0.002857849698346116, "phrase": "attractor_memory"}, {"score": 0.0028037753646260937, "phrase": "back_projection"}, {"score": 0.0026986685585382347, "phrase": "input_population"}, {"score": 0.0026140878612307536, "phrase": "hebbian_learning_rule"}, {"score": 0.0024842242921857705, "phrase": "correlated_and_densely_coded_patterns"}, {"score": 0.0024372021710656585, "phrase": "regular_attractor_neural_networks"}, {"score": 0.0023013968622710847, "phrase": "good_performance"}, {"score": 0.0022292394795878643, "phrase": "typical_attractor_neural_network_tasks"}, {"score": 0.0021456243019466843, "phrase": "noise_reduction"}, {"score": 0.0021049977753042253, "phrase": "prototype_extraction"}], "paper_keywords": [""], "paper_abstract": "We propose a neural network based autoassociative memory system for unsupervised learning. This system is intended to be an example of how a general information processing architecture, similar to that of neocortex, could be organized. The neural network has its units arranged into two separate groups called populations, one input and one hidden population. The units in the input population form receptive fields that sparsely projects onto the units of the hidden population. Competitive learning is used to train these forward projections. The hidden population implements an attractor memory. A back projection from the hidden to the input population is trained with a Hebbian learning rule. This system is capable of processing correlated and densely coded patterns, which regular attractor neural networks are very poor at. The system shows good performance on a number of typical attractor neural network tasks such as pattern completion, noise reduction, and prototype extraction.", "paper_title": "Attractor memory with self-organizing input", "paper_id": "WOS:000235807500022"}