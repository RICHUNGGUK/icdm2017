{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "sensor_fusion"}, {"score": 0.04811914031577569, "phrase": "multiple_sensors"}, {"score": 0.004575272950516775, "phrase": "ego-motion_estimation"}, {"score": 0.004228016636379321, "phrase": "discrete_series"}, {"score": 0.004092774981286263, "phrase": "unsynchronized_sensors"}, {"score": 0.003817306032290766, "phrase": "unified_solution"}, {"score": 0.003764469758319617, "phrase": "ego-motion_estimation_problems"}, {"score": 0.00372965096877929, "phrase": "high-rate_unsynchronized_devices"}, {"score": 0.003644001325962353, "phrase": "discrete-time_pose_representation"}, {"score": 0.0035603115570447467, "phrase": "continuous-time_formulation"}, {"score": 0.0032745778756077693, "phrase": "trajectory_representation"}, {"score": 0.0031113369425402287, "phrase": "local_control"}, {"score": 0.0030398432591176357, "phrase": "window_implementations"}, {"score": 0.002874870266177579, "phrase": "inertial_measurements"}, {"score": 0.0027698788736535865, "phrase": "torque-minimal_motions"}, {"score": 0.0024772998651215964, "phrase": "different_times"}, {"score": 0.002331909406363425, "phrase": "rolling_shutter_cameras"}, {"score": 0.002267708463966758, "phrase": "continuous-time_framework"}, {"score": 0.0022467024793003812, "phrase": "visual-inertial_simultaneous_localization"}, {"score": 0.0021049977753042253, "phrase": "entire_system"}], "paper_keywords": ["Sensor fusion", " Visual-inertial", " SLAM", " Rolling shutter", " Calibration"], "paper_abstract": "The use of multiple sensors for ego-motion estimation is an approach often used to provide more accurate and robust results. However, when representing ego-motion as a discrete series of poses, fusing information of unsynchronized sensors is not straightforward. The framework described in this paper aims to provide a unified solution for solving ego-motion estimation problems involving high-rate unsynchronized devices. Instead of a discrete-time pose representation, we present a continuous-time formulation that makes use of cumulative cubic B-Splines parameterized in the Lie Algebra of the group . This trajectory representation has several advantages for sensor fusion: (1) it has local control, which enables sliding window implementations; (2) it is continuous, allowing predictions of inertial measurements; (3) it closely matches torque-minimal motions; (4) it has no singularities when representing rotations; (5) it easily handles measurements from multiple sensors arriving a different times when timestamps are available; and (6) it deals with rolling shutter cameras naturally. We apply this continuous-time framework to visual-inertial simultaneous localization and mapping and show that it can also be used to calibrate the entire system.", "paper_title": "A Spline-Based Trajectory Representation for Sensor Fusion and Rolling Shutter Cameras", "paper_id": "WOS:000356091900005"}