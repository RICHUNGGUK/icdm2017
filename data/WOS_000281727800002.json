{"auto_keywords": [{"score": 0.05007852962010534, "phrase": "gpu"}, {"score": 0.004565609517511076, "phrase": "graphics_processing_unit"}, {"score": 0.004418601451254075, "phrase": "flexible_and_powerful_processor"}, {"score": 0.004382591802405206, "phrase": "relatively_low_cost"}, {"score": 0.004038183610525504, "phrase": "simulation_communities"}, {"score": 0.003782174375003052, "phrase": "regular_time_increments"}, {"score": 0.0036008372531664726, "phrase": "time_delta"}, {"score": 0.0033176589215021353, "phrase": "continuous-time_systems"}, {"score": 0.0030944828434567966, "phrase": "parameter_space"}, {"score": 0.003056682083784002, "phrase": "prior_studies"}, {"score": 0.0030317376771013672, "phrase": "discrete_event_simulation"}, {"score": 0.0029460197288680864, "phrase": "inefficient_application"}, {"score": 0.0028510114763213596, "phrase": "inherent_synchronicity"}, {"score": 0.0028161764476743257, "phrase": "gpu_organization"}, {"score": 0.0027817658627604653, "phrase": "apparent_mismatch"}, {"score": 0.0027477745788313163, "phrase": "classic_event_scheduling_cycle"}, {"score": 0.0027141975147496264, "phrase": "gpu's_basic_functionality"}, {"score": 0.002626645763725465, "phrase": "irregular_time_advances"}, {"score": 0.0025628355581338563, "phrase": "discrete_event_models"}, {"score": 0.0024099937116733227, "phrase": "discrete_event_systems"}, {"score": 0.002380534385718454, "phrase": "inexpensive_personal_computer_platform"}, {"score": 0.002229380111189829, "phrase": "special_purpose_code_library"}, {"score": 0.0021751997984619585, "phrase": "approximate_time-based_event_scheduling_approach"}, {"score": 0.0021050011608453783, "phrase": "nvidia"}], "paper_keywords": ["Discrete event simulation", " parallel event scheduling", " GPU", " CUDA", " simulation libraries"], "paper_abstract": "The graphics processing unit (GPU) has evolved into a flexible and powerful processor of relatively low cost, compared to processors used for other available parallel computing systems. The majority of studies using the GPU within the graphics and simulation communities have focused on the use of the GPU for models that are traditionally simulated using regular time increments, whether these increments are accomplished through the addition of a time delta (i.e., numerical integration) or event scheduling using the delta (i.e., discrete event approximations of continuous-time systems). These types of models have the property of being decomposable over a variable or parameter space. In prior studies, discrete event simulation has been characterized as being an inefficient application for the GPU primarily due to the inherent synchronicity of the GPU organization and an apparent mismatch between the classic event scheduling cycle and the GPU's basic functionality. However, we have found that irregular time advances of the sort common in discrete event models can be successfully mapped to a GPU, thus making it possible to execute discrete event systems on an inexpensive personal computer platform at speedups close to 10x. This speedup is achieved through the development of a special purpose code library we developed that uses an approximate time-based event scheduling approach. We present the design and implementation of this library, which is based on the compute unified device architecture (CUDA) general purpose parallel applications programming interface for the NVIDIA class of GPUs.", "paper_title": "A GPU-Based Application Framework Supporting Fast Discrete-Event Simulation", "paper_id": "WOS:000281727800002"}