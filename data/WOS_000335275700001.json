{"auto_keywords": [{"score": 0.04963419481547922, "phrase": "georeferenced_video_search"}, {"score": 0.04832350902760219, "phrase": "video_recording_devices"}, {"score": 0.03433183203055727, "phrase": "georeferenced_videos"}, {"score": 0.00481495049065317, "phrase": "spatial_information"}, {"score": 0.004681971826924847, "phrase": "rapid_popularization"}, {"score": 0.004406260054779782, "phrase": "current_video_search_engines"}, {"score": 0.004344965512058521, "phrase": "textual_data"}, {"score": 0.00428451995524549, "phrase": "video_titles"}, {"score": 0.003957477564354679, "phrase": "car_blackboxes"}, {"score": 0.0038661089070527424, "phrase": "gps_sensors"}, {"score": 0.0037242701420971062, "phrase": "spatiotemporal_information"}, {"score": 0.003587616378156851, "phrase": "camera_direction"}, {"score": 0.0033919477901198716, "phrase": "efficient_spatial_indexing_method"}, {"score": 0.0033447157263095223, "phrase": "geotree"}, {"score": 0.0032827577713351336, "phrase": "rapid_searching"}, {"score": 0.0031328221096543823, "phrase": "new_data_structure"}, {"score": 0.0030891871245908665, "phrase": "mbtr"}, {"score": 0.0030319482153908037, "phrase": "tilted_rectangle"}, {"score": 0.0025028892126605124, "phrase": "real_georeferenced_video_data"}, {"score": 0.0024336086025284836, "phrase": "previous_indexing_methods"}, {"score": 0.0023551955270737215, "phrase": "index_size"}, {"score": 0.002311525062244175, "phrase": "search_speed"}, {"score": 0.002289993730291136, "phrase": "georeferenced_video_data"}, {"score": 0.0022580713471027996, "phrase": "online_demo"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Georeferencing", " Geotagging", " Video search", " Spatial indexing", " R-tree"], "paper_abstract": "With the rapid popularization of video recording devices, more multimedia content is available to the public. However, current video search engines rely on textual data such as video titles, annotations, and text around the video. Video recording devices such as cameras, smartphones and car blackboxes are nowadays equipped with GPS sensors and the ability to capture videos with spatiotemporal information such as time, location, and camera direction. We call such videos georeferenced videos. This paper proposes an efficient spatial indexing method, called GeoTree, which facilitates rapid searching of georeferenced videos. In particular, we propose a new data structure, called MBTR (Minimum Bounding Tilted Rectangle) to efficiently store the areas of moving scenes in the tree. We also propose algorithms for building MBTRs from georeferenced videos and algorithms for efficiently processing point and range queries on GeoTree. The results of experiments conducted on real georeferenced video data show that, compared to previous indexing methods for georeferenced video search, GeoTree substantially reduces index size and also improves search speed for georeferenced video data. An online demo of the system is available at \"http://dm.postech.ac.kr/geosearch\". (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "GeoTree: Using spatial information for georeferenced video search", "paper_id": "WOS:000335275700001"}