{"auto_keywords": [{"score": 0.03870719807060688, "phrase": "soft_labels"}, {"score": 0.02233670974356364, "phrase": "unlabeled_examples"}, {"score": 0.009270706510190982, "phrase": "proposed_method"}, {"score": 0.00813316521270831, "phrase": "proposed_algorithm"}, {"score": 0.005833435169471516, "phrase": "labeled_examples"}, {"score": 0.00481495049065317, "phrase": "linear_discriminant_clustering"}, {"score": 0.00469159356595623, "phrase": "semi-supervised_learning_method"}, {"score": 0.004651177631663439, "phrase": "semi-supervised_linear_discriminant_clustering"}, {"score": 0.004321366583699087, "phrase": "k-means"}, {"score": 0.004284100953217494, "phrase": "linear_discriminant_analysis"}, {"score": 0.004247290036180376, "phrase": "lda"}, {"score": 0.004084920064588169, "phrase": "feature_space"}, {"score": 0.003928834302530914, "phrase": "new_space"}, {"score": 0.00327545462323687, "phrase": "soft_lda"}, {"score": 0.0032471982781283374, "phrase": "hard_labels"}, {"score": 0.003109519872758431, "phrase": "projection_matrix"}, {"score": 0.002990592465417758, "phrase": "new_feature_space"}, {"score": 0.0028762004595878714, "phrase": "experimental_results"}, {"score": 0.002637377202509382, "phrase": "classification_performance"}, {"score": 0.0025808284847319528, "phrase": "different_percentages"}, {"score": 0.002387083859537412, "phrase": "available_labeled_examples"}, {"score": 0.0023257824499250653, "phrase": "robust_and_accurate_model"}, {"score": 0.002188784900536406, "phrase": "different_soft_label_estimation_methods"}, {"score": 0.0021049977753042253, "phrase": "application_requirements"}], "paper_keywords": ["Clustering", " linear discriminant analysis", " semi-supervised learning", " soft label", " text mining"], "paper_abstract": "This paper devises a semi-supervised learning method called semi-supervised linear discriminant clustering (Semi-LDC). The proposed algorithm considers clustering and dimensionality reduction simultaneously by connecting K-means and linear discriminant analysis (LDA). The goal is to find a feature space where the K-means can perform well in the new space. To exploit the information brought by unlabeled examples, this paper proposes to use soft labels to denote the labels of unlabeled examples. The Semi-LDC uses the proposed algorithm, called constrained-PLSA, to estimate the soft labels of unlabeled examples. We use soft LDA with hard labels of labeled examples and soft labels of unlabeled examples to find a projection matrix. The clustering is then performed in the new feature space. We conduct experiments on three data sets. The experimental results indicate that the proposed method can generally outperform other semi-supervised methods. We further discuss and analyze the influence of soft labels on classification performance by conducting experiments with different percentages of labeled examples. The finding shows that using soft labels can improve performance particularly when the number of available labeled examples is insufficient to train a robust and accurate model. Additionally, the proposed method can be viewed as a framework, since different soft label estimation methods can be used in the proposed method according to application requirements.", "paper_title": "Semi-supervised Linear Discriminant Clustering", "paper_id": "WOS:000342225800001"}