{"auto_keywords": [{"score": 0.028143043112209682, "phrase": "original_mtann"}, {"score": 0.017049290082382207, "phrase": "input_voxels"}, {"score": 0.010436368534099242, "phrase": "ct_colonography"}, {"score": 0.009230912792932084, "phrase": "mtann"}, {"score": 0.0062644937110258635, "phrase": "actual_polyps"}, {"score": 0.006160140980488023, "phrase": "rectal_tubes"}, {"score": 0.00481495049065317, "phrase": "laplacian-eigenfunction-based_dimensionality_reduction"}, {"score": 0.004708152527097594, "phrase": "major_challenge"}, {"score": 0.004681823487694425, "phrase": "current_computer-aided_detection"}, {"score": 0.004664373970176484, "phrase": "cad"}, {"score": 0.004603730445606184, "phrase": "ctc"}, {"score": 0.004459691536881611, "phrase": "pattern-recognition_technique"}, {"score": 0.00440170067770959, "phrase": "artificial_neural_network"}, {"score": 0.004146015717402716, "phrase": "massive_number"}, {"score": 0.0041074234667687875, "phrase": "input_volumes"}, {"score": 0.004076807411344387, "phrase": "teaching_volumes"}, {"score": 0.003897825805855961, "phrase": "large_number"}, {"score": 0.003861534816807933, "phrase": "high_dimensionality"}, {"score": 0.0038255804199548798, "phrase": "input_subvolume"}, {"score": 0.0037058116979705857, "phrase": "time_issue"}, {"score": 0.0036781781340563748, "phrase": "mtann_work"}, {"score": 0.0036235254023315798, "phrase": "dimension_reduction_method"}, {"score": 0.003583067515485422, "phrase": "laplacian_eigenfunctions"}, {"score": 0.0034773669221269594, "phrase": "dependence_structures"}, {"score": 0.0034385353123700885, "phrase": "selected_laps"}, {"score": 0.003343336516033681, "phrase": "input_vector"}, {"score": 0.003324614337607016, "phrase": "mtann."}, {"score": 0.003196452688100276, "phrase": "seventeen_patients"}, {"score": 0.0030502854924662837, "phrase": "test_set"}, {"score": 0.0029271812818615042, "phrase": "seven_patients"}, {"score": 0.0028890603352364273, "phrase": "basic_properties"}, {"score": 0.0028195727965553367, "phrase": "single_source"}, {"score": 0.002762079051902704, "phrase": "trained_lap-mtann"}, {"score": 0.002751751956416832, "phrase": "simulated_polyps"}, {"score": 0.0026956374041441126, "phrase": "lap-mtanns"}, {"score": 0.002463830258460528, "phrase": "polyp_sensitivity"}, {"score": 0.002450021074868533, "phrase": "fp_rate"}, {"score": 0.0023865921651439175, "phrase": "comparable_performance"}, {"score": 0.0023643797618565824, "phrase": "fp"}, {"score": 0.0022859244876449396, "phrase": "dimension_reduction_architecture"}, {"score": 0.002226734412397011, "phrase": "classification_performance"}, {"score": 0.002193600680263771, "phrase": "receiver-operating-characteristic_curve"}, {"score": 0.0021049977753042253, "phrase": "statistically_significant_difference"}], "paper_keywords": ["Computer-aided diagnosis (CAD)", " nonlinear dimension reduction", " pixel-based machine learning", " virtual colonoscopy"], "paper_abstract": "A major challenge in the current computer-aided detection (CAD) of polyps in CT colonography (CTC) is to reduce the number of false-positive (FP) detections while maintaining a high sensitivity level. A pattern-recognition technique based on the use of an artificial neural network (ANN) as a filter, which is called a massive-training ANN (MTANN), has been developed recently for this purpose. The MTANN is trained with a massive number of subvolumes extracted from input volumes together with the teaching volumes containing the distribution for the \"likelihood of being a polyp;\" hence the term \" massive training.\" Because of the large number of subvolumes and the high dimensionality of voxels in each input subvolume, the training of an MTANN is time-consuming. In order to solve this time issue and make an MTANN work more efficiently, we propose here a dimension reduction method for an MTANN by using Laplacian eigenfunctions (LAPs), denoted as LAP-MTANN. Instead of input voxels, the LAP-MTANN uses the dependence structures of input voxels to compute the selected LAPs of the input voxels from each input subvolume and thus reduces the dimensions of the input vector to the MTANN. Our database consisted of 246 CTC datasets obtained from 123 patients, each of whom was scanned in both supine and prone positions. Seventeen patients had 29 polyps, 15 of which were 5-9 mm and 14 were 10-25 mm in size. We divided our database into a training set and a test set. The training set included 10 polyps in 10 patients and 20 negative patients. The test set had 93 patients including 19 polyps in seven patients and 86 negative patients. To investigate the basic properties of a LAP-MTANN, we trained the LAP-MTANN with actual polyps and a single source of FPs, which were rectal tubes. We applied the trained LAP-MTANN to simulated polyps and rectal tubes. The results showed that the performance of LAP-MTANNs with 20 LAPs was advantageous over that of the original MTANN with 171 inputs. To test the feasibility of the LAP-MTANN, we compared the LAP-MTANN with the original MTANN in the distinction between actual polyps and various types of FPs. The original MTANN yielded a 95% (18/19) by-polyp sensitivity at an FP rate of 3.6 (338/93) per patient, whereas the LAP-MTANN achieved a comparable performance, i.e., an FP rate of 3.9 (367/93) per patient at the same sensitivity level. With the use of the dimension reduction architecture, the time required for training was reduced from 38 h to 4 h. The classification performance in terms of the area under the receiver-operating-characteristic curve of the LAP-MTANN (0.84) was slightly higher than that of the original MTANN (0.82) with no statistically significant difference (p-value= 0.48).", "paper_title": "Massive-Training Artificial Neural Network Coupled With Laplacian-Eigenfunction-Based Dimensionality Reduction for Computer-Aided Detection of Polyps in CT Colonography", "paper_id": "WOS:000283941800008"}