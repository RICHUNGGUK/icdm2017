{"auto_keywords": [{"score": 0.03546730795101328, "phrase": "different_emotional_states"}, {"score": 0.00481495049065317, "phrase": "music_videos"}, {"score": 0.004715908063787721, "phrase": "participants'_rating"}, {"score": 0.004667149874736771, "phrase": "emotional_experience"}, {"score": 0.004547438494330851, "phrase": "vital_role"}, {"score": 0.004453874101119545, "phrase": "multimedia_content"}, {"score": 0.004339609346924681, "phrase": "brain_electrical_activity"}, {"score": 0.004272456401437226, "phrase": "emotional_cues"}, {"score": 0.004206338218873218, "phrase": "emotion_detection"}, {"score": 0.003870541730075597, "phrase": "novel_machine_learning_approach"}, {"score": 0.0038304902197108643, "phrase": "dual-tree_complex_wavelet_packet_transform"}, {"score": 0.00339853518227171, "phrase": "brain_activity"}, {"score": 0.0032940691998512963, "phrase": "dt-cwpt"}, {"score": 0.0032094634756436595, "phrase": "time-frequency_emotional_features"}, {"score": 0.0031597433845085092, "phrase": "non-redundant_and_most_discriminating_emotional_features"}, {"score": 0.002803213985198645, "phrase": "reduced_emotional_feature"}, {"score": 0.0026888503045081505, "phrase": "support_vector_machine"}, {"score": 0.0026611607346872556, "phrase": "svm"}, {"score": 0.002579140290642792, "phrase": "-one-out_cross-validation_scheme"}, {"score": 0.0024103044278902916, "phrase": "eeg_signals"}, {"score": 0.002385326947545194, "phrase": "significant_correlation"}, {"score": 0.002360607691114015, "phrase": "participants'_self"}, {"score": 0.002311933249234786, "phrase": "emotional_features"}, {"score": 0.0021945833590668973, "phrase": "brain_region"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Dual-Tree Complex Wavelet Packet Transform (DT-CWPT)", " Electroencephalogram (EEG)", " Singular Value Decomposition (SVD)", " QR factorization with column pivoting (QRcp)", " F-Ratio", " Support Vector Machine (SVM)", " Human-computer interaction (HCI)"], "paper_abstract": "Emotional experience and preference play a vital role in selection of multimedia content for an individual. Brain electrical activity bears the emotional cues needed for emotion detection, but very modest research has been done to extract those cues. This paper presents a novel machine learning approach using Dual-Tree Complex Wavelet Packet Transform (DT-CWPT) time-frequency features from electroencephalogram (EEG) to detect emotions together with an analysis of brain activity in different emotional states. Firstly, DT-CWPT is used to extract time-frequency emotional features. Then non-redundant and most discriminating emotional features are selected through singular value decomposition (SVD), QR factorization with column pivoting (QRcp) and F-Ratio based feature selection (FS) method. The reduced emotional feature set is used to classify emotion using support vector machine (SVM) and validated by leave-one-out cross-validation scheme. Results confirm the robustness and consistency in classification of emotions from EEG signals and significant correlation between participants' self assessed ratings with emotional features. It also gives an analysis of activities in brain region during different emotional states. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Classification of emotions induced by music videos and correlation with participants' rating", "paper_id": "WOS:000336872300034"}