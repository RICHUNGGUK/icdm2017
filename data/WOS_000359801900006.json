{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "measurement_complexity"}, {"score": 0.010512667468117895, "phrase": "differentially_private_query_answering"}, {"score": 0.004657542074154025, "phrase": "important_problem"}, {"score": 0.004613516457919661, "phrase": "machine_learning"}, {"score": 0.004569905085027681, "phrase": "data_analysis"}, {"score": 0.004296264970612285, "phrase": "empirical_errors"}, {"score": 0.004175533280178052, "phrase": "training_data"}, {"score": 0.0040969285074699, "phrase": "sensitive_information"}, {"score": 0.00388828234270598, "phrase": "database_holder"}, {"score": 0.0037969755088553326, "phrase": "previous_results"}, {"score": 0.003725470458263889, "phrase": "large_number"}, {"score": 0.0036553070575015344, "phrase": "differential_privacy"}, {"score": 0.0035356745476539885, "phrase": "almost_all_the_hardness_results"}, {"score": 0.003371508176308189, "phrase": "unproved_conjectures"}, {"score": 0.003261133560558666, "phrase": "stateless_mechanisms"}, {"score": 0.0027610089418453614, "phrase": "stateless_restriction"}, {"score": 0.002632716358833918, "phrase": "natural_class"}, {"score": 0.0026077803487003, "phrase": "stateful_sanitizer"}, {"score": 0.002439756579884691, "phrase": "boolean"}, {"score": 0.002382329940096419, "phrase": "data_point"}, {"score": 0.0022824314760583834, "phrase": "running_time"}, {"score": 0.0021049977753042253, "phrase": "epsilon-differential_privacy"}], "paper_keywords": ["privacy", " differential privacy", " query", " measurement complexity", " learning"], "paper_abstract": "Differentially private query answering is an important problem in machine learning and data analysis. As an example, the users may want to know the empirical errors of some classifiers on a training data set which contains sensitive information. In this case, the answers returned by the database holder must preserve privacy. Previous results show that answering large number of queries with differential privacy is computationally expensive. However, almost all the hardness results are conditional, which means that they rely on unproved conjectures. One exception is the hardness for stateless mechanisms, in which the sanitizer is assumed to have very limited memory and can only answer the queries separately. In this work, we explore the hardness for differentially private query answering mechanisms beyond the stateless restriction. Specifically, we investigate the measurement complexity of a natural class of stateful sanitizer. Here, measurement refers to the evaluation of a query (a Boolean function) on a data point. Measurement complexity is a lower bound for the running time. We prove unconditional subexponential lower bound for the measurement complexity of the class of sanitizer with epsilon-differential privacy. Possible generalization of the results is also discussed.", "paper_title": "On the measurement complexity of differentially private query answering", "paper_id": "WOS:000359801900006"}