{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "conditional_random_fields"}, {"score": 0.004757643419056999, "phrase": "large-scale_applications"}, {"score": 0.004672953146379813, "phrase": "sequence_data"}, {"score": 0.0042459818200777846, "phrase": "structured_data"}, {"score": 0.00414545383888272, "phrase": "natural_language_tagging"}, {"score": 0.004047296286849109, "phrase": "image_segmentation"}, {"score": 0.003999089046152065, "phrase": "object_recognition"}, {"score": 0.003927848423072668, "phrase": "protein_secondary_structure_prediction"}, {"score": 0.003857871979942733, "phrase": "key_advantages"}, {"score": 0.003361069456060196, "phrase": "global_normalization"}, {"score": 0.0030171910207671205, "phrase": "intensive_forward-backward_computation"}, {"score": 0.0029280552768499056, "phrase": "likelihood_function"}, {"score": 0.0027575842698911173, "phrase": "high-performance_training"}, {"score": 0.002692200353719145, "phrase": "massively_parallel_processing_systems"}, {"score": 0.002597012212823168, "phrase": "huge_datasets"}, {"score": 0.002373472641477602, "phrase": "important_natural_language_processing_task"}, {"score": 0.0022895278869126848, "phrase": "large-scale_corpora"}, {"score": 0.0022486729928886885, "phrase": "significant_results"}, {"score": 0.002169132543304098, "phrase": "computational_time"}, {"score": 0.0021049977753042253, "phrase": "prediction_accuracy"}], "paper_keywords": ["parallel computing", " probabilistic graphical models", " conditional random.fields", " structured prediction", " text processing"], "paper_abstract": "Conditional random fields (CRFs) have been successfully applied to various applications of predicting and labeling structured data, such as natural language tagging & parsing, image segmentation & object recognition, and protein secondary structure prediction. The key advantages of CRFs are the ability to encode a variety of overlapping, nonindependent features from empirical data as well as the capability of reaching the global normalization and optimization. However, estimating parameters for CRFs is very time-consuming due to an intensive forward-backward computation needed to estimate the likelihood function and its gradient during training. This paper presents a high-performance training of CRFs on massively parallel processing systems that allows us to handle huge datasets with hundreds of thousand data sequences and millions of features. We performed the experiments on an important natural language processing task (text chunking) on large-scale corpora and achieved significant results in terms of both the reduction of computational time and the improvement of prediction accuracy.", "paper_title": "High-performance training of conditional random fields for large-scale applications of labeling sequence data", "paper_id": "WOS:000243703600003"}