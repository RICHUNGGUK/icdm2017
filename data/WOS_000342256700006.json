{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "non-manual_grammatical_marker_recognition"}, {"score": 0.04521793700326864, "phrase": "non-manual_grammatical_markers"}, {"score": 0.004723622989145559, "phrase": "spatio-temporal_analysis"}, {"score": 0.00465944657565638, "phrase": "facial_expressions"}, {"score": 0.004608730887154718, "phrase": "eyebrow_configuration"}, {"score": 0.0045212970824266485, "phrase": "head_gestures"}, {"score": 0.004447669334871974, "phrase": "essential_grammatical_information"}, {"score": 0.004423392979866108, "phrase": "signed_languages"}, {"score": 0.004351352597487985, "phrase": "automatic_recognition_system"}, {"score": 0.004303975853361081, "phrase": "american_sign_language"}, {"score": 0.0040192915527630995, "phrase": "gestural_components"}, {"score": 0.0038893838564184107, "phrase": "different_types"}, {"score": 0.003868142906199082, "phrase": "periodic_head_movements"}, {"score": 0.0037124763118311734, "phrase": "novel_multi-scale_learning_approach"}, {"score": 0.003682100144121148, "phrase": "spatio-temporally_low-level"}, {"score": 0.003661987063211563, "phrase": "high-level_facial_features"}, {"score": 0.0036419834462626125, "phrase": "low-level_features"}, {"score": 0.0035826234811610316, "phrase": "facial_geometry"}, {"score": 0.0033363396054797044, "phrase": "gestural_events"}, {"score": 0.003309030835969531, "phrase": "varying_duration"}, {"score": 0.003246173672295418, "phrase": "linguistic_non-manual_markers"}, {"score": 0.0031240075437664314, "phrase": "head_nods"}, {"score": 0.003098431361922705, "phrase": "head_shakes"}, {"score": 0.0030312441544072056, "phrase": "temporal_phases"}, {"score": 0.002989991779830814, "phrase": "anticipatory_transitional_movement"}, {"score": 0.0029331771326095504, "phrase": "linguistically_significant_portion"}, {"score": 0.002807324685396813, "phrase": "transitional_movement"}, {"score": 0.0027389142053945246, "phrase": "neutral_position"}, {"score": 0.0026070408483940535, "phrase": "temporally_accurate_localization"}, {"score": 0.0025856860837060224, "phrase": "grammatical_markers"}, {"score": 0.0024951467586005094, "phrase": "previous_computer_vision_methods"}, {"score": 0.0024276590297034064, "phrase": "motion_patterns"}, {"score": 0.0024077700683153886, "phrase": "non-manual_events"}, {"score": 0.002273025527678093, "phrase": "high-level_features"}, {"score": 0.0021814110467069346, "phrase": "learning_methods"}, {"score": 0.0021694774708817498, "phrase": "accurate_recognition"}, {"score": 0.002145814978981307, "phrase": "asl"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["American Sign Language (ASL)", " Non-manual grammatical markers", " Eyebrow height", " Head gestures", " Facial expressions", " Conditional Random Field (CRF)"], "paper_abstract": "Changes in eyebrow configuration, in conjunction with other facial expressions and head gestures, are used to signal essential grammatical information in signed languages. This paper proposes an automatic recognition system for non-manual grammatical markers in American Sign Language (ASL) based on a multi-scale, spatio-temporal analysis of head pose and facial expressions. The analysis takes account of gestural components of these markers, such as raised or lowered eyebrows and different types of periodic head movements. To advance the state of the art in non-manual grammatical marker recognition, we propose a novel multi-scale learning approach that exploits spatio-temporally low-level and high-level facial features. Low-level features are based on information about facial geometry and appearance, as well as head pose, and are obtained through accurate 3D deformable model-based face tracking. High-level features are based on the identification of gestural events, of varying duration, that constitute the components of linguistic non-manual markers. Specifically, we recognize events such as raised and lowered eyebrows, head nods, and head shakes. We also partition these events into temporal phases. We separate the anticipatory transitional movement (the onset) from the linguistically significant portion of the event, and we further separate the core of the event from the transitional movement that occurs as the articulators return to the neutral position towards the end of the event (the offset). This partitioning is essential for the temporally accurate localization of the grammatical markers, which could not be achieved at this level of precision with previous computer vision methods. In addition, we analyze and use the motion patterns of these non-manual events. Those patterns, together with the information about the type of event and its temporal phases, are defined as the high-level features. Using this multi-scale, spatio-temporal combination of low- and high-level features, we employ learning methods for accurate recognition of non-manual grammatical markers in ASL sentences. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Non-manual grammatical marker recognition based on multi-scale, spatio-temporal analysis of head pose and facial expressions", "paper_id": "WOS:000342256700006"}