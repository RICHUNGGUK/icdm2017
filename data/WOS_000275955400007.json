{"auto_keywords": [{"score": 0.01422117867075365, "phrase": "statistical_constraints"}, {"score": 0.011139128460067869, "phrase": "j._comput"}, {"score": 0.009804191182969232, "phrase": "proceedings"}, {"score": 0.00481495049065317, "phrase": "aerial_image_parsing"}, {"score": 0.00471071771178029, "phrase": "hierarchical_and_contextual_model"}, {"score": 0.004685012337701536, "phrase": "aerial_image_understanding"}, {"score": 0.004459857205489101, "phrase": "aerial_scenes"}, {"score": 0.004435514622798228, "phrase": "hierarchical_groups"}, {"score": 0.004164905340575487, "phrase": "non-recursive_grammar"}, {"score": 0.004119550201381466, "phrase": "aerial_images"}, {"score": 0.003964646257072569, "phrase": "different_configurations"}, {"score": 0.003857565803059891, "phrase": "vast_number"}, {"score": 0.0038155447176837, "phrase": "relatively_few_rules"}, {"score": 0.0037636590459094762, "phrase": "minimax_entropy_framework"}, {"score": 0.0036519716087768253, "phrase": "learned_context"}, {"score": 0.003592449435568323, "phrase": "unlikely_scene_configurations"}, {"score": 0.0035728243060262305, "phrase": "hallucinate_undetected_objects"}, {"score": 0.003524227590204673, "phrase": "similar_algorithm"}, {"score": 0.003485824905231454, "phrase": "texture_synthesis"}, {"score": 0.0034196936699869497, "phrase": "int"}, {"score": 0.0032909488752766503, "phrase": "hierarchical_information"}, {"score": 0.003228434077467506, "phrase": "different_bottom-up_detectors"}, {"score": 0.00319324425647735, "phrase": "textonboost"}, {"score": 0.0031498012076224984, "phrase": "freund"}, {"score": 0.003132582882710462, "phrase": "schapire"}, {"score": 0.0030986309003263194, "phrase": "syst"}, {"score": 0.0030312441544072056, "phrase": "shotton"}, {"score": 0.002925149105307855, "phrase": "wu_et_al"}, {"score": 0.002877438939246423, "phrase": "ieee_conference"}, {"score": 0.002861708609922034, "phrase": "computer_vision"}, {"score": 0.002709045632654716, "phrase": "new_aerial_images"}, {"score": 0.002679501909303057, "phrase": "cluster_sampling_algorithm"}, {"score": 0.0024611721532928742, "phrase": "alternate_competing_sub-solutions"}, {"score": 0.0024210112323786374, "phrase": "image_patch"}, {"score": 0.0023815040848961435, "phrase": "parking_lot"}, {"score": 0.0022054750513000854, "phrase": "parsed_aerial_images"}, {"score": 0.002193410120879393, "phrase": "experimental_results"}, {"score": 0.002163535133532765, "phrase": "top-down_prediction_algorithms"}, {"score": 0.0021458053922984725, "phrase": "learned_contextual_cues"}, {"score": 0.002116577422058574, "phrase": "detection_results"}, {"score": 0.0021049977753042253, "phrase": "traditional_bottom-up_detectors"}], "paper_keywords": ["Hierarchical models", " Scene-level context", " Statistical learning", " Image understanding", " Aerial images", " Swendsen-Wang clustering", " Bayesian inference"], "paper_abstract": "In this paper we present a hierarchical and contextual model for aerial image understanding. Our model organizes objects (cars, roofs, roads, trees, parking lots) in aerial scenes into hierarchical groups whose appearances and configurations are determined by statistical constraints (e.g. relative position, relative scale, etc.). Our hierarchy is a non-recursive grammar for objects in aerial images comprised of layers of nodes that can each decompose into a number of different configurations. This allows us to generate and recognize a vast number of scenes with relatively few rules. We present a minimax entropy framework for learning the statistical constraints between objects and show that this learned context allows us to rule out unlikely scene configurations and hallucinate undetected objects during inference. A similar algorithm was proposed for texture synthesis (Zhu et al. in Int. J. Comput. Vis. 2:107-126, 1998) but didn't incorporate hierarchical information. We use a range of different bottom-up detectors (AdaBoost, TextonBoost, Compositional Boosting (Freund and Schapire in J. Comput. Syst. Sci. 55, 1997; Shotton et al. in Proceedings of the European Conference on Computer Vision, pp. 1-15, 2006; Wu et al. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2007)) to propose locations of objects in new aerial images and employ a cluster sampling algorithm (C4 (Porway and Zhu, 2009)) to choose the subset of detections that best explains the image according to our learned prior model. The C4 algorithm can quickly and efficiently switch between alternate competing sub-solutions, for example whether an image patch is better explained by a parking lot with cars or by a building with vents. We also show that our model can predict the locations of objects our detectors missed. We conclude by presenting parsed aerial images and experimental results showing that our cluster sampling and top-down prediction algorithms use the learned contextual cues from our model to improve detection results over traditional bottom-up detectors alone.", "paper_title": "A Hierarchical and Contextual Model for Aerial Image Parsing", "paper_id": "WOS:000275955400007"}