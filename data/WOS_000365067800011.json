{"auto_keywords": [{"score": 0.04233053722268817, "phrase": "hidden_nodes"}, {"score": 0.0418568761606081, "phrase": "hidden_layer"}, {"score": 0.029795339227408884, "phrase": "fknn_networks"}, {"score": 0.00481495049065317, "phrase": "image_classification"}, {"score": 0.004648995193787914, "phrase": "feedforward_kernel_neural_networks"}, {"score": 0.004612896435506914, "phrase": "fknn"}, {"score": 0.004453874101119545, "phrase": "considerably_large_family"}, {"score": 0.0044192837023190445, "phrase": "existing_feedforward_neural_networks"}, {"score": 0.004250302819248558, "phrase": "common_understanding"}, {"score": 0.003900853871728297, "phrase": "adopted_kernel"}, {"score": 0.003885668358145471, "phrase": "based_activation_functions"}, {"score": 0.003781005930058317, "phrase": "special_kernel_principal_component_analysis"}, {"score": 0.003751628827795802, "phrase": "kpca"}, {"score": 0.0032727116186194584, "phrase": "training_data"}, {"score": 0.0032094634756436595, "phrase": "least_learning_machine"}, {"score": 0.003184515707040545, "phrase": "llm"}, {"score": 0.0029453365339797933, "phrase": "additional_merit"}, {"score": 0.002865929543375884, "phrase": "rigorous_mercer_kernel_condition"}, {"score": 0.002766963729586353, "phrase": "proposed_architecture"}, {"score": 0.0026923527275481804, "phrase": "layer-by-layer_way"}, {"score": 0.002490053106007765, "phrase": "extracted_principal_components"}, {"score": 0.0024610448251906453, "phrase": "explicit_execution"}, {"score": 0.002385326947545194, "phrase": "fknn's_deep_architecture"}, {"score": 0.002311933249234786, "phrase": "strong_theoretical_guarantee"}, {"score": 0.0022583704173318123, "phrase": "image_classification_manifest"}, {"score": 0.0022320551224679526, "phrase": "proposed_fknn's_deep_architecture"}, {"score": 0.00220604611283725, "phrase": "dlf"}, {"score": 0.002154930852763048, "phrase": "classification_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Feedforward kernel neural networks", " Least learning machine", " Kernel principal component analysis (KPCA)", " Hidden-layer-tuning-free learning", " Deep architecture and learning"], "paper_abstract": "In this paper, the architecture of feedforward kernel neural networks (FKNN) is proposed, which can include a considerably large family of existing feedforward neural networks and hence can meet most practical requirements. Different from the common understanding of learning, it is revealed that when the number of the hidden nodes of every hidden layer and the type of the adopted kernel based activation functions are pre-fixed, a special kernel principal component analysis (KPCA) is always implicitly executed, which can result in the fact that all the hidden layers of such networks need not be tuned and their parameters can be randomly assigned and even may be independent of the training data. Therefore, the least learning machine (LLM) is extended into its generalized version in the sense of adopting much more error functions rather than mean squared error (MSE) function only. As an additional merit, it is also revealed that rigorous Mercer kernel condition is not required in FKNN networks. When the proposed architecture of FKNN networks is constructed in a layer-by-layer way, i.e., the number of the hidden nodes of every hidden layer may be determined only in terms of the extracted principal components after the explicit execution of a KPCA, we can develop FKNN's deep architecture such that its deep learning framework (DLF) has strong theoretical guarantee. Our experimental results about image classification manifest that the proposed FKNN's deep architecture and its DLF based learning indeed enhance the classification performance. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Feedforward kernel neural networks, generalized least learning machine, and its deep learning with application to image classification", "paper_id": "WOS:000365067800011"}