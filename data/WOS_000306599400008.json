{"auto_keywords": [{"score": 0.04583834963802334, "phrase": "generic_framework"}, {"score": 0.00481495049065317, "phrase": "video_annotation"}, {"score": 0.004785356349906913, "phrase": "semi-supervised_learning"}, {"score": 0.004741304218199546, "phrase": "-based_video_annotation"}, {"score": 0.004683195250422422, "phrase": "video_analysis"}, {"score": 0.004513087388483271, "phrase": "intensive_labor_costs"}, {"score": 0.0044853402274804815, "phrase": "purely_manual_annotation"}, {"score": 0.004269391057037737, "phrase": "domain_knowledge"}, {"score": 0.004217041305117441, "phrase": "training_data"}, {"score": 0.004178198896815672, "phrase": "precise_localization"}, {"score": 0.0041269626762569095, "phrase": "large-scale_video_dataset"}, {"score": 0.004013957450249313, "phrase": "novel_approach"}, {"score": 0.003832423454781517, "phrase": "interesting_event"}, {"score": 0.0034294219963679857, "phrase": "small-scale_expert"}, {"score": 0.0032641439000713306, "phrase": "labeled_videos"}, {"score": 0.0030972277169783098, "phrase": "unlabeled_data"}, {"score": 0.0030497740719977835, "phrase": "related_events"}, {"score": 0.0030216505272259884, "phrase": "video_search_engine"}, {"score": 0.00297539962486966, "phrase": "youtube"}, {"score": 0.00295716323346273, "phrase": "google"}, {"score": 0.0028848643090508205, "phrase": "event_modeling"}, {"score": 0.002849442549612025, "phrase": "fgssmil"}, {"score": 0.002771321260809228, "phrase": "weight_assignment"}, {"score": 0.0027457584014804574, "phrase": "graph_construction"}, {"score": 0.0024416087858984644, "phrase": "large-scale_dataset"}, {"score": 0.0024190798397126924, "phrase": "optimization_approach"}, {"score": 0.002367315484467406, "phrase": "concave-convex_procedure"}, {"score": 0.002352743694538005, "phrase": "cccp"}, {"score": 0.002331018915674993, "phrase": "nonnegative_multiplicative_updating_rule"}, {"score": 0.0022811346113905295, "phrase": "extensive_experiments"}], "paper_keywords": ["Broadcast video", " concave-convex procedure (CCCP)", " event detection", " graph", " Internet", " multiple instance learning", " semi-supervised learning", " web-casting text"], "paper_abstract": "Learning-based video annotation is essential for video analysis and understanding, and many various approaches have been proposed to avoid the intensive labor costs of purely manual annotation. However, there lacks a generic framework due to several difficulties, such as dependence of domain knowledge, insufficiency of training data, no precise localization and inefficacy for large-scale video dataset. In this paper, we propose a novel approach based on semi-supervised learning by means of information from the Internet for interesting event annotation in videos. Concretely, a Fast Graph-based Semi-Supervised Multiple Instance Learning (FGSSMIL) algorithm, which aims to simultaneously tackle these difficulties in a generic framework for various video domains (e. g., sports, news, and movies), is proposed to jointly explore small-scale expert labeled videos and large-scale unlabeled videos to train the models. The expert labeled videos are obtained from the analysis and alignment of well-structured video related text (e. g., movie scripts, web-casting text, close caption). The unlabeled data are obtained by querying related events from the video search engine (e. g., YouTube, Google) in order to give more distributive information for event modeling. Two critical issues of FGSSMIL are: 1) how to calculate the weight assignment for a graph construction, where the weight of an edge specifies the similarity between two data points. To tackle this problem, we propose a novel Multiple Instance Learning Induced Similarity (MILIS) measure by learning instance sensitive classifiers; 2) how to solve the algorithm efficiently for large-scale dataset through an optimization approach. To address this issue, Concave-Convex Procedure (CCCP) and nonnegative multiplicative updating rule are adopted. We perform the extensive experiments in three popular video domains: movies, sports, and news. The results compared with the state-of-the-arts are promising and demonstrate the effectiveness and efficiency of our proposed approach.", "paper_title": "A Generic Framework for Video Annotation via Semi-Supervised Learning", "paper_id": "WOS:000306599400008"}