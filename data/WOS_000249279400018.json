{"auto_keywords": [{"score": 0.04957466661795797, "phrase": "bit_streams"}, {"score": 0.007941037840874847, "phrase": "distributed_systems"}, {"score": 0.00757249981514996, "phrase": "functional_elements"}, {"score": 0.00481495049065317, "phrase": "network_implementation"}, {"score": 0.00468912237497774, "phrase": "new_method"}, {"score": 0.004615202066192795, "phrase": "parallel_hardware_implementation"}, {"score": 0.004566567411073082, "phrase": "artificial_neural_networks"}, {"score": 0.004447201233380302, "phrase": "digital_techniques"}, {"score": 0.004262643556463569, "phrase": "uniformly_weighted_single-bit_streams"}, {"score": 0.0041074234667687875, "phrase": "analog_or_multibit_inputs"}, {"score": 0.003978866233891427, "phrase": "single-bit_representation"}, {"score": 0.0038748022659578865, "phrase": "multibit_representations"}, {"score": 0.0036942726653704213, "phrase": "fan-out_issues"}, {"score": 0.003466536738232506, "phrase": "anns_concepts"}, {"score": 0.0028487656293168795, "phrase": "differentiable_nonlinear_squashing_functions"}, {"score": 0.002687235334499192, "phrase": "multilayer_perceptron"}, {"score": 0.002365815362517737, "phrase": "functional_element"}, {"score": 0.0021616339773325704, "phrase": "bit-stream_technique"}, {"score": 0.0021049977753042253, "phrase": "hardware_implementation"}], "paper_keywords": ["artificial neural networks (ANNs)", " neural network (NN) implementation"], "paper_abstract": "A new method for the parallel hardware implementation of artificial neural networks (ANNs) using digital techniques is presented. Signals are represented using uniformly weighted single-bit streams. Techniques for generating bit streams from analog or multibit inputs are also presented. This single-bit representation offers significant advantages over multibit representations since they mitigate the fan-in and fan-out issues which are typical to distributed systems. To process these bit streams using ANNs concepts, functional elements which perform summing, scaling, and squashing have been implemented. These elements are modular and have been designed such that they can be easily interconnected. Two new architectures which act as monotonically increasing differentiable nonlinear squashing functions have also been presented. Using these functional elements, a multilayer perceptron (MLP) can be easily constructed. Two examples successfully demonstrate the use of bit streams in the implementation of ANNs. Since every functional element is individually instantiated, the implementation is genuinely parallel. The results clearly show that this bit-stream technique is viable for the hardware implementation of a variety of distributed systems and for ANNs in particular.", "paper_title": "Neural network implementation using bit streams", "paper_id": "WOS:000249279400018"}