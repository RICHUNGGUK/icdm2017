{"auto_keywords": [{"score": 0.04807157020342475, "phrase": "decision_trees"}, {"score": 0.00481495049065317, "phrase": "multi-valued_categorical_data"}, {"score": 0.00473320761888448, "phrase": "multi-valued_categorical_attributes"}, {"score": 0.0045543011700929096, "phrase": "high_branching_factor"}, {"score": 0.004476963405985556, "phrase": "data_fragmentation"}, {"score": 0.004216434794603139, "phrase": "new_ensemble_method"}, {"score": 0.00418046991987597, "phrase": "random_ordinality_ensembles"}, {"score": 0.003971006689166329, "phrase": "significantly_improved_accuracies"}, {"score": 0.003937126962709418, "phrase": "current_ensemble_methods"}, {"score": 0.00385368199735867, "phrase": "random_projection"}, {"score": 0.0038044630943383497, "phrase": "categorical_data"}, {"score": 0.0037558704408683905, "phrase": "continuous_space"}, {"score": 0.0036605323485683983, "phrase": "continuous_data"}, {"score": 0.0036137713873827374, "phrase": "random_process"}, {"score": 0.003522027550662857, "phrase": "different_imposed_ordinality"}, {"score": 0.003477029725200912, "phrase": "decision_tree"}, {"score": 0.0034033029171804106, "phrase": "new_continuous_space"}, {"score": 0.003331134183901191, "phrase": "binary_splits"}, {"score": 0.0032604908177429493, "phrase": "data_fragmentation_problem"}, {"score": 0.00319134078848996, "phrase": "binary_trees"}, {"score": 0.003137074867443131, "phrase": "diverse_training_datasets"}, {"score": 0.0031102878400698143, "phrase": "diverse_decision_trees"}, {"score": 0.002954287204671032, "phrase": "roe."}, {"score": 0.0029165216647792924, "phrase": "first_variant"}, {"score": 0.0028302635493019867, "phrase": "base_models"}, {"score": 0.0027583557819362034, "phrase": "second_variant"}, {"score": 0.0026998264237910884, "phrase": "attribute_randomisation"}, {"score": 0.0026767629720554397, "phrase": "random_subspaces"}, {"score": 0.0026538960171433985, "phrase": "random_ordinality"}, {"score": 0.0024252458095689847, "phrase": "random_ordinality_trees"}, {"score": 0.0023434058350520763, "phrase": "multi-way_split_decision_trees"}, {"score": 0.002274059352027924, "phrase": "random_ordinality_attributes"}, {"score": 0.0022162571224921056, "phrase": "bagging"}, {"score": 0.002197335779539365, "phrase": "adaboost"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Classifier ensemble", " Decision tree", " Categorical data", " Multi-way split", " Binary split"], "paper_abstract": "Data with multi-valued categorical attributes can cause major problems for decision trees. The high branching factor can lead to data fragmentation, where decisions have little or no statistical support. In this paper, we propose a new ensemble method, Random Ordinality Ensembles (ROE), that reduces this problem, and provides significantly improved accuracies over current ensemble methods. We perform a random projection of the categorical data into a continuous space. As the transformation to continuous data is a random process, each dataset has a different imposed ordinality. A decision tree that learns on this new continuous space is able to use binary splits, hence reduces the data fragmentation problem. Generally, these binary trees are accurate. Diverse training datasets ensure diverse decision trees in the ensemble. We created two variants of the technique, ROE. In the first variant, we used decision trees as the base models for ensembles. In the second variant, we combined the attribute randomisation of Random Subspaces with Random Ordinality. These methods match or outperform other popular ensemble methods. Different properties of these ensembles were studied. The study suggests that random ordinality trees are generally more accurate and smaller than multi-way split decision trees. It is also shown that random ordinality attributes can be used to improve Bagging and AdaBoost. M1 ensemble methods. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Random Ordinality Ensembles: Ensemble methods for multi-valued categorical data", "paper_id": "WOS:000347363500007"}