{"auto_keywords": [{"score": 0.035210473688554816, "phrase": "gaussian_noise"}, {"score": 0.015719716506582538, "phrase": "unsupervised_learning"}, {"score": 0.004764859786310636, "phrase": "noisy_data."}, {"score": 0.004569630374630379, "phrase": "topological_view"}, {"score": 0.0040942189695983185, "phrase": "connected_components"}, {"score": 0.004030449969901066, "phrase": "underlying_geometrically_structured_probability_distribution"}, {"score": 0.0037456980766939836, "phrase": "geometrically_structured_probability_distribution"}, {"score": 0.0035361001070845677, "phrase": "special_case"}, {"score": 0.0032689949867583633, "phrase": "finite_set"}, {"score": 0.0030062165552187086, "phrase": "low_dimensional_manifold"}, {"score": 0.0028527866590859967, "phrase": "underlying_geometric_core"}, {"score": 0.002412371116984224, "phrase": "high_confidence"}, {"score": 0.0022653055209664284, "phrase": "ambient_dimension"}, {"score": 0.002206700502606511, "phrase": "natural_interpretation"}, {"score": 0.002172266188075892, "phrase": "spectral_learning_algorithm"}, {"score": 0.0021383680500215267, "phrase": "combinatorial_laplacian"}, {"score": 0.0021049977753042253, "phrase": "suitable_data-derived_simplicial_complex"}], "paper_keywords": ["topology", " data", " manifolds"], "paper_abstract": "In this paper, we take a topological view of unsupervised learning. From this point of view, clustering may be interpreted as trying to find the number of connected components of any underlying geometrically structured probability distribution in a certain sense that we will make precise. We construct a geometrically structured probability distribution that seems appropriate for modeling data in very high dimensions. A special case of our construction is the mixture of Gaussians where there is Gaussian noise concentrated around a finite set of points (the means). More generally we consider Gaussian noise concentrated around a low dimensional manifold and discuss how to recover the homology of this underlying geometric core from data that do not lie on it. We show that if the variance of the Gaussian noise is small in a certain sense, then the homology can be learned with high confidence by an algorithm that has a weak (linear) dependence on the ambient dimension. Our algorithm has a natural interpretation as a spectral learning algorithm using a combinatorial Laplacian of a suitable data-derived simplicial complex.", "paper_title": "A TOPOLOGICAL VIEW OF UNSUPERVISED LEARNING FROM NOISY DATA", "paper_id": "WOS:000292108900003"}