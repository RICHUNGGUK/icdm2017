{"auto_keywords": [{"score": 0.04977793821547788, "phrase": "human_adversaries"}, {"score": 0.034367457885539014, "phrase": "new_models"}, {"score": 0.00481495049065317, "phrase": "resource_allocation_strategies"}, {"score": 0.004754600386388821, "phrase": "security_games"}, {"score": 0.00470983237900705, "phrase": "extended_study"}, {"score": 0.004680220363692397, "phrase": "stackelberg_games"}, {"score": 0.0046361494357125355, "phrase": "significant_attention"}, {"score": 0.004549242970806199, "phrase": "real_world_security"}, {"score": 0.004421919334823349, "phrase": "armor"}, {"score": 0.004394216586512652, "phrase": "iris"}, {"score": 0.004366503674288722, "phrase": "guards"}, {"score": 0.00431171604706364, "phrase": "standard_game-theoretical_assumption"}, {"score": 0.0041515244239033145, "phrase": "game_theory_literature"}, {"score": 0.0040480367430410545, "phrase": "real-world_security_problems"}, {"score": 0.003997260449163666, "phrase": "bounded_rationality"}, {"score": 0.003717368939083015, "phrase": "unrealistic_assumption"}, {"score": 0.003693973656103879, "phrase": "perfectly_rational_adversary"}, {"score": 0.0036707250689857348, "phrase": "stackelberg_security_games"}, {"score": 0.0035904971126313316, "phrase": "new_mathematical_models"}, {"score": 0.0035678974387440914, "phrase": "human_adversaries'_behavior"}, {"score": 0.0034899090274046014, "phrase": "human_decision_making"}, {"score": 0.003467940281748612, "phrase": "prospect_theory"}, {"score": 0.003446831656779453, "phrase": "pt"}, {"score": 0.0031544754107802413, "phrase": "standard_quantal_response"}, {"score": 0.003105049327888471, "phrase": "rank-dependent_expected_utility_theory"}, {"score": 0.0030563953060027175, "phrase": "efficient_algorithms"}, {"score": 0.00301801991152303, "phrase": "best_response"}, {"score": 0.002989553951264878, "phrase": "security_forces"}, {"score": 0.0029427043216782604, "phrase": "different_models"}, {"score": 0.0027976491158911514, "phrase": "comprehensive_experiments"}, {"score": 0.002780025943393764, "phrase": "human_subjects"}, {"score": 0.002753798541636975, "phrase": "web-based_game"}, {"score": 0.002634629612115397, "phrase": "perfect_rationality_assumption"}, {"score": 0.002544616720630384, "phrase": "subjects'_responses"}, {"score": 0.0024654516678953658, "phrase": "previous_perfect_rationality_assumption"}, {"score": 0.002411502601063177, "phrase": "defender_strategy"}, {"score": 0.0023071120479647325, "phrase": "perfect_rationality"}, {"score": 0.0022637650216685906, "phrase": "separate_set"}, {"score": 0.0021589195238286233, "phrase": "standard_model"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Bounded rationality", " Stackelberg games", " Decision-making"], "paper_abstract": "Stackelberg games have garnered significant attention in recent years given their deployment for real world security. Most of these systems, such as ARMOR, IRIS and GUARDS have adopted the standard game-theoretical assumption that adversaries are perfectly rational, which is standard in the game theory literature. This assumption may not hold in real-world security problems due to the bounded rationality of human adversaries, which could potentially reduce the effectiveness of these systems. In this paper, we focus on relaxing the unrealistic assumption of perfectly rational adversary in Stackelberg security games. In particular, we present new mathematical models of human adversaries' behavior, based on using two fundamental theory/method in human decision making: Prospect Theory (PT) and stochastic discrete choice model. We also provide methods for tuning the parameters of these new models. Additionally, we propose a modification of the standard quantal response based model inspired by rank-dependent expected utility theory. We then develop efficient algorithms to compute the best response of the security forces when playing against the different models of adversaries. In order to evaluate the effectiveness of the new models, we conduct comprehensive experiments with human subjects using a web-based game, comparing them with models previously proposed in the literature to address the perfect rationality assumption on part of the adversary. Our experimental results show that the subjects' responses follow the assumptions of our new models more closely than the previous perfect rationality assumption. We also show that the defender strategy produced by our new stochastic discrete choice model outperform the previous leading contender for relaxing the assumption of perfect rationality. Furthermore, in a separate set of experiments, we show the benefits of our modified stochastic model (QRRU) over the standard model (QR).(1) (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Improving resource allocation strategies against human adversaries in security games: An extended study", "paper_id": "WOS:000315839600017"}