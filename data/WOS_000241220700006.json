{"auto_keywords": [{"score": 0.048839643896770986, "phrase": "hicl"}, {"score": 0.008713768692145013, "phrase": "reduced_pattern_training"}, {"score": 0.004834903344857847, "phrase": "rpt"}, {"score": 0.004752221133109136, "phrase": "hierarchical_incremental_class_learning"}, {"score": 0.004568871736067739, "phrase": "new_task_decomposition_method"}, {"score": 0.004450568197899267, "phrase": "pattern_classification_problem"}, {"score": 0.004195418010131832, "phrase": "good_classifier"}, {"score": 0.004140726362519362, "phrase": "closer_examination"}, {"score": 0.0040334640350288, "phrase": "potential_improvement"}, {"score": 0.003877737556673229, "phrase": "theoretical_model"}, {"score": 0.003537275726870251, "phrase": "classification_accuracy"}, {"score": 0.0032266093099550955, "phrase": "theoretical_analysis"}, {"score": 0.0031019373572233706, "phrase": "better_classification_accuracy"}, {"score": 0.003021660123926208, "phrase": "li"}, {"score": 0.002982068153662372, "phrase": "ieee_transaction"}, {"score": 0.002943147037670826, "phrase": "neural_networks"}, {"score": 0.002547043222086858, "phrase": "original_training_procedure"}, {"score": 0.0023850311572318496, "phrase": "training_data"}, {"score": 0.0021049977753042253, "phrase": "improved_model"}], "paper_keywords": ["classifier systems", " hierarchical learning", " instance selection", " Output Parallelism", " reduced pattern training"], "paper_abstract": "Hierarchical Incremental Class Learning (HICL) is a new task decomposition method that addresses the pattern classification problem. The HICL is proven to be a good classifier but closer examination reveals areas for potential improvement. This paper proposes a theoretical model to evaluate the performance of HICL and presents an approach to improve the classification accuracy of HICL by applying the concept of Reduced Pattern Training (RPT). The theoretical analysis shows that HICL can achieve better classification accuracy than Output Parallelism [Guan and Li: IEEE Transaction on Neural Networks, 13 (2002), 542-550]. The procedure for RPT is described and compared with the original training procedure. The RPT reduces systematically the size of the training data set based on the order of sub-networks built. The results from four benchmark classification problems show much promise for the improved model.", "paper_title": "Hierarchical incremental class learning with reduced pattern training", "paper_id": "WOS:000241220700006"}