{"auto_keywords": [{"score": 0.04458957169940881, "phrase": "k-means"}, {"score": 0.033268437971235375, "phrase": "original_high-dimensional_data"}, {"score": 0.010714102267531734, "phrase": "single_random_projection"}, {"score": 0.008352999489726764, "phrase": "better_solution"}, {"score": 0.00481495049065317, "phrase": "high-dimensional_data"}, {"score": 0.004600870784042767, "phrase": "random_projection"}, {"score": 0.004497410940849537, "phrase": "k-means_algorithm"}, {"score": 0.0036924762294207633, "phrase": "proposed_algorithm"}, {"score": 0.0032209766681045365, "phrase": "k-means_clustering"}, {"score": 0.0026438880533289893, "phrase": "squared_error"}, {"score": 0.0026040262154057607, "phrase": "proposed_method"}], "paper_keywords": ["Clustering", " K-means", " High-dimensional data", " Random projections"], "paper_abstract": "In this text we propose a method which efficiently performs clustering of high-dimensional data. The method builds on random projection and the K-means algorithm. The idea is to apply K-means several times, increasing the dimensionality of the data after each convergence of K-means. We compare the proposed algorithm on four high-dimensional datasets, image, text and two synthetic, with K-means clustering using a single random projection and K-means clustering of the original high-dimensional data. Regarding time we observe that the algorithm reduces drastically the time when compared to K-means on the original high-dimensional data. Regarding mean squared error the proposed method reaches a better solution than clustering using a single random projection. More notably in the experiments performed it also reaches a better solution than clustering on the original high-dimensional data. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Iterative random projections for high-dimensional data clustering", "paper_id": "WOS:000308385800011"}