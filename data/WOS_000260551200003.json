{"auto_keywords": [{"score": 0.033695946878404825, "phrase": "rdma"}, {"score": 0.00481495049065317, "phrase": "rdma_based_collectives"}, {"score": 0.004666228956744244, "phrase": "symmetric_multiprocessors"}, {"score": 0.004633848367507574, "phrase": "smp"}, {"score": 0.004459445258869177, "phrase": "scientific_applications"}, {"score": 0.004382364826200616, "phrase": "collective_communications"}, {"score": 0.004321656690200878, "phrase": "memory_communication"}, {"score": 0.004173524877260367, "phrase": "multi-rail_networks"}, {"score": 0.004072851768196397, "phrase": "increasing_demand"}, {"score": 0.004016413965935386, "phrase": "inter-node_communications"}, {"score": 0.0038651944848734133, "phrase": "emerging_multi-core_smp_clusters"}, {"score": 0.0037719307016238998, "phrase": "paper_designs"}, {"score": 0.0037066895459425824, "phrase": "collective_communication_algorithms"}, {"score": 0.0036553070575015344, "phrase": "elan_user-level"}, {"score": 0.0035920758080335655, "phrase": "message_striping"}, {"score": 0.0032462487283717546, "phrase": "large_messages"}, {"score": 0.003027286031578399, "phrase": "small_to_medium_size_messages"}, {"score": 0.002345868044122465, "phrase": "best_algorithm"}, {"score": 0.0021875036343988806, "phrase": "real_applications"}, {"score": 0.0021049977753042253, "phrase": "proposed_all-gather_algorithms"}], "paper_keywords": ["Collective communications", " RDMA", " Multi-rail networks", " Clusters", " Shared-memory", " SMP"], "paper_abstract": "Clusters of Symmetric Multiprocessors (SMP) are more commonplace than ever in achieving high-performance. Scientific applications running on clusters employ collective communications extensively. Shared memory communication and Remote Direct Memory Access (RDMA) over multi-rail networks are promising approaches in addressing the increasing demand on intra-node and inter-node communications, and thereby in boosting the performance of collectives in emerging multi-core SMP clusters. In this regard, this paper designs and evaluates two classes of collective communication algorithms directly at the Elan user-level over multi-rail Quadrics QsNet(II) with message striping: 1) RDMA-based traditional multi-port algorithms for gather, all-gather, and all-to-all collectives for medium to large messages, and 2) RDMA-based and SMP-aware multi-port all-gather algorithms for small to medium size messages. The multi-port RDMA-based Direct algorithm for gather and all-to-all collectives gain an improvement of up to 2.15 for 4 KB messages over elan_gather(), and up to 2.26 for 2 KB messages over elan_alltoall(), respectively. For the all-gather, our SMP-aware Bruck algorithm outperforms all other all-gather algorithms including elan_gather() for 512 B to 8 KB messages, with a 1.96 improvement factor for 4 KB messages. Our multi-port Direct all-gather is the best algorithm for 16 KB to 1 MB, and outperforms elan_gather() by a factor of 1.49 for 32 KB messages. Experimentation with real applications has shown up to 1.47 communication speedup can be achieved using the proposed all-gather algorithms.", "paper_title": "Efficient shared memory and RDMA based collectives on multi-rail QsNet(II) SMP clusters", "paper_id": "WOS:000260551200003"}