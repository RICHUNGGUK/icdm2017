{"auto_keywords": [{"score": 0.04897776997473009, "phrase": "neural_networks"}, {"score": 0.011088707367163836, "phrase": "proposed_approach"}, {"score": 0.00481495049065317, "phrase": "objective_video_quality_assessment"}, {"score": 0.004636252403395063, "phrase": "objective_measurement_method"}, {"score": 0.004556018017257075, "phrase": "perceived_quality"}, {"score": 0.004529581568905548, "phrase": "digital_videos"}, {"score": 0.004490212943845175, "phrase": "challenging_issue"}, {"score": 0.004438250823243621, "phrase": "human_judgment"}, {"score": 0.004150878736797479, "phrase": "general_framework"}, {"score": 0.004114787982556699, "phrase": "different_stages"}, {"score": 0.004043541331944951, "phrase": "complex_problems"}, {"score": 0.003792657064634775, "phrase": "original_way"}, {"score": 0.0036838048761094933, "phrase": "reduced_reference"}, {"score": 0.003415137969569376, "phrase": "quality_scores"}, {"score": 0.003326762498260742, "phrase": "objective_metrics"}, {"score": 0.0032882197112190756, "phrase": "subjective_quality_score"}, {"score": 0.0032501220121903475, "phrase": "single_stimulus_continuous_quality_evaluation"}, {"score": 0.0032312384727026747, "phrase": "sscqe"}, {"score": 0.0031384486687892274, "phrase": "video_quality_expert_group"}, {"score": 0.00312021216379517, "phrase": "vqeg"}, {"score": 0.0029009722548088306, "phrase": "previous_attempts"}, {"score": 0.002859003260874958, "phrase": "quality_assessment"}, {"score": 0.0027931086065664354, "phrase": "convolutional_neural_network"}, {"score": 0.002776945484209396, "phrase": "cnn"}, {"score": 0.002736694413701639, "phrase": "continuous_time_scoring"}, {"score": 0.002697095634192932, "phrase": "objective_features"}, {"score": 0.002658068304632523, "phrase": "frame-by-frame_basis"}, {"score": 0.0026043744834099306, "phrase": "distorted_sequences"}, {"score": 0.002551762519273805, "phrase": "perceptual-based_representation"}, {"score": 0.0025148328760856505, "phrase": "temporal_axis"}, {"score": 0.00249293148301837, "phrase": "time-delay_neural_network"}, {"score": 0.002414241727802253, "phrase": "bit_rates"}, {"score": 0.0023041863978014113, "phrase": "plausible_model"}, {"score": 0.002290786209279345, "phrase": "temporal_pooling"}, {"score": 0.0022708315711029423, "phrase": "human_vision_system"}, {"score": 0.0021049977753042253, "phrase": "typical_tv_videos"}], "paper_keywords": ["convolutional neural network (CNN)", " MPEG-2", " temporal pooling", " video quality assessment"], "paper_abstract": "This paper describes an application of neural networks in the field of objective measurement method designed to automatically assess the perceived quality of digital videos. This challenging issue aims to emulate human judgment and to replace very,complex and time consuming subjective quality assessment. Several metrics have been proposed in literature to tackle this issue. They are based on a general framework that combines different stages, each of them addressing complex problems. The ambition of this paper is not to present a global perfect quality metric but rather to focus on an original way to use neural networks in such a framework in the context of reduced reference (RR) quality metric. Especially, we point out the interest of such a tool for combining features and pooling them in order to compute quality scores. The proposed approach solves some problems inherent to objective metrics that should predict subjective quality score obtained using the single stimulus continuous quality evaluation (SSCQE) method. This latter has been adopted by video quality expert group (VQEG) in its recently finalized reduced referenced and no reference (RRNR-TV) test plan. The originality of such approach compared to previous attempts to use neural networks for quality assessment, relies on the use of a convolutional neural network (CNN) that allows a continuous time scoring of the video. Objective features are extracted on a frame-by-frame basis on both the reference and the distorted sequences; they are derived from a perceptual-based representation and integrated along the temporal axis using a time-delay neural network (TDNN). Experiments conducted on different MPEG-2 videos, with bit rates ranging 2-6 Mb/s, show the effectiveness of the proposed approach to get a plausible model of temporal pooling from the human vision system (HVS) point of view. More specifically, a linear correlation criteria, between objective and subjective scoring, up to 0.92 has been obtained on a set of typical TV videos.", "paper_title": "A convolutional neural network approach for objective video quality assessment", "paper_id": "WOS:000240511600018"}