{"auto_keywords": [{"score": 0.03805447680550302, "phrase": "mincq"}, {"score": 0.022815065768808197, "phrase": "lmnn"}, {"score": 0.00481495049065317, "phrase": "priori_constrained_weighted_majority_votes"}, {"score": 0.004362226376603478, "phrase": "recent_algorithm"}, {"score": 0.003870541730075597, "phrase": "elegant_pac-bayesian_generalization_guarantees"}, {"score": 0.003712796038920873, "phrase": "good_performance"}, {"score": 0.0036553070575015344, "phrase": "weak_classifiers"}, {"score": 0.0034881076466982226, "phrase": "useful_a_priori_knowledge"}, {"score": 0.00331125524068286, "phrase": "weak_and_strong_voters"}, {"score": 0.0027886573969044042, "phrase": "general_proofs"}, {"score": 0.0026888503045081505, "phrase": "sample_compression"}, {"score": 0.0026471739851621143, "phrase": "data-dependent_voters"}, {"score": 0.002512850690695835, "phrase": "-nn_classifiers"}, {"score": 0.002473895542219933, "phrase": "specific_modeling"}, {"score": 0.002435542816459651, "phrase": "voters'_performance"}, {"score": 0.002360607691114015, "phrase": "classic_-nn_classifier"}, {"score": 0.0021049977753042253, "phrase": "popular_metric_learning_algorithm"}], "paper_keywords": ["Ensemble learning", " Weighted majority vote", " PAC-Bayesian bounds", " Sample compression", " Nearest neighbors"], "paper_abstract": "Weighted majority votes allow one to combine the output of several classifiers or voters. MinCq is a recent algorithm for optimizing the weight of each voter based on the minimization of a theoretical bound over the risk of the vote with elegant PAC-Bayesian generalization guarantees. However, while it has demonstrated good performance when combining weak classifiers, MinCq cannot make use of the useful a priori knowledge that one may have when using a mixture of weak and strong voters. In this paper, we propose P-MinCq, an extension of MinCq that can incorporate such knowledge in the form of a constraint over the distribution of the weights, along with general proofs of convergence that stand in the sample compression setting for data-dependent voters. The approach is applied to a vote of -NN classifiers with a specific modeling of the voters' performance. P-MinCq significantly outperforms the classic -NN classifier, a symmetric NN and MinCq using the same voters. We show that it is also competitive with LMNN, a popular metric learning algorithm, and that combining both approaches further reduces the error.", "paper_title": "Learning a priori constrained weighted majority votes", "paper_id": "WOS:000341431300007"}