{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "shared-control_haptic_guidance_paradigms"}, {"score": 0.004681525814235883, "phrase": "haptic_guidance"}, {"score": 0.004603244077348199, "phrase": "common_form"}, {"score": 0.004551781491498328, "phrase": "robot-mediated_training"}, {"score": 0.004450568197899267, "phrase": "novice_subjects"}, {"score": 0.004376131419366239, "phrase": "dynamic_tasks"}, {"score": 0.004327196832280818, "phrase": "shared-control_guidance"}, {"score": 0.00413684709497912, "phrase": "virtual_fixtures"}, {"score": 0.003954837422946628, "phrase": "real-time_visual_and_haptic_feedback"}, {"score": 0.00378080526397273, "phrase": "previous_studies"}, {"score": 0.003717528595128948, "phrase": "varying_levels"}, {"score": 0.0036759314172445934, "phrase": "training_efficacy"}, {"score": 0.0036347979916389467, "phrase": "shared-control_guidance_paradigms"}, {"score": 0.0034944094552943, "phrase": "mixed_results"}, {"score": 0.003378385493203297, "phrase": "specific_guidance_implementations"}, {"score": 0.003140004304719746, "phrase": "novel_guidance_paradigm_taxonomy"}, {"score": 0.0028214413724451442, "phrase": "revised_proxy_rendering_model"}, {"score": 0.0025638362414466278, "phrase": "controlled_study"}, {"score": 0.0024234059612683032, "phrase": "guidance_paradigms"}, {"score": 0.0023428586429492713, "phrase": "task's_dynamic_characteristics"}, {"score": 0.0023035922232490106, "phrase": "effective_training"}, {"score": 0.0022777800735119405, "phrase": "low_workload"}, {"score": 0.0021288561076024844, "phrase": "future_development"}, {"score": 0.0021049977753042253, "phrase": "improved_haptic_guidance_paradigms"}], "paper_keywords": ["Shared control", " haptic rendering", " haptic guidance", " robot-mediated training"], "paper_abstract": "Shared-control haptic guidance is a common form of robot-mediated training used to teach novice subjects to perform dynamic tasks. Shared-control guidance is distinct from more traditional guidance controllers, such as virtual fixtures, in that it provides novices with real-time visual and haptic feedback from a real or virtual expert. Previous studies have shown varying levels of training efficacy using shared-control guidance paradigms; it is hypothesized that these mixed results are due to interactions between specific guidance implementations (\"paradigms\") and tasks. This work proposes a novel guidance paradigm taxonomy intended to help classify and compare the multitude of implementations in the literature, as well as a revised proxy rendering model to allow for the implementation of more complex guidance paradigms. The efficacies of four common paradigms are compared in a controlled study with 50 healthy subjects and two dynamic tasks. The results show that guidance paradigms must be matched to a task's dynamic characteristics to elicit effective training and low workload. Based on these results, we provide suggestions for the future development of improved haptic guidance paradigms.", "paper_title": "The Task-Dependent Efficacy of Shared-Control Haptic Guidance Paradigms", "paper_id": "WOS:000307452300003"}