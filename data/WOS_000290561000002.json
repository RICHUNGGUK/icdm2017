{"auto_keywords": [{"score": 0.04508079597991672, "phrase": "edge_weight"}, {"score": 0.04344466112767363, "phrase": "algorithm"}, {"score": 0.03351806422483542, "phrase": "learning_rate"}, {"score": 0.012674774514976351, "phrase": "proposed_algorithm"}, {"score": 0.011656137035345883, "phrase": "spanning_tree"}, {"score": 0.011567647148172143, "phrase": "minimum_expected_weight"}, {"score": 0.00481495049065317, "phrase": "automata-based_algorithms"}, {"score": 0.004778145748896516, "phrase": "stochastic_minimum"}, {"score": 0.004753764934589345, "phrase": "tree_problem"}, {"score": 0.004645574499882206, "phrase": "minimum_spanning_tree"}, {"score": 0.004574812666721017, "phrase": "stochastic_environments"}, {"score": 0.00440256713630382, "phrase": "probability_distribution_function"}, {"score": 0.004380454275134083, "phrase": "pdf"}, {"score": 0.004172218066893155, "phrase": "learning_automata-based_sampling_algorithm"}, {"score": 0.004087658051566714, "phrase": "mst_problem"}, {"score": 0.004066786100652281, "phrase": "stochastic_graphs"}, {"score": 0.0036057249778792388, "phrase": "sampling_process"}, {"score": 0.003496601848177069, "phrase": "proposed_sampling_method"}, {"score": 0.00342568771304873, "phrase": "unnecessary_samplings"}, {"score": 0.0033476211806800753, "phrase": "smst."}, {"score": 0.0032131888231888626, "phrase": "proper_choice"}, {"score": 0.0030526912121620143, "phrase": "numerical_results"}, {"score": 0.002998426187835658, "phrase": "standard_sampling_method"}, {"score": 0.002967850512345855, "phrase": "proper_learning_rate"}, {"score": 0.0028853608895253492, "phrase": "good_trade"}, {"score": 0.002590892903301456, "phrase": "resultant_algorithms"}, {"score": 0.0024995563056109224, "phrase": "probabilistic_distribution_parameters"}, {"score": 0.0024176223097104664, "phrase": "simulation_experiments"}, {"score": 0.002261705456576993, "phrase": "multiple_edge_sensitivity_method"}, {"score": 0.0022271736946235703, "phrase": "obtained_results"}, {"score": 0.002148631647473042, "phrase": "running_time"}, {"score": 0.0021376392890704674, "phrase": "sampling_rate"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Learning automata", " Minimum spanning tree", " Stochastic graph"], "paper_abstract": "Due to the hardness of solving the minimum spanning tree (MST) problem in stochastic environments, the stochastic MST (SMST) problem has not received the attention it merits, specifically when the probability distribution function (PDF) of the edge weight is not a priori known. In this paper, we first propose a learning automata-based sampling algorithm (Algorithm 1) to solve the MST problem in stochastic graphs where the PDF of the edge weight is assumed to be unknown. At each stage of the proposed algorithm, a set of learning automata is randomly activated and determines the graph edges that must be sampled in that stage. As the proposed algorithm proceeds, the sampling process focuses on the spanning tree with the minimum expected weight. Therefore, the proposed sampling method is capable of decreasing the rate of unnecessary samplings and shortening the time required for finding the SMST. The convergence of this algorithm is theoretically proved and it is shown that by a proper choice of the learning rate the spanning tree with the minimum expected weight can be found with a probability close enough to unity. Numerical results show that Algorithm 1 outperforms the standard sampling method. Selecting a proper learning rate is the most challenging issue in learning automata theory by which a good trade off can be achieved between the cost and efficiency of algorithm. To improve the efficiency (i.e., the convergence speed and convergence rate) of Algorithm 1, we also propose four methods to adjust the learning rate in Algorithm 1 and the resultant algorithms are called as Algorithm 2 through Algorithm 5. In these algorithms, the probabilistic distribution parameters of the edge weight are taken into consideration for adjusting the learning rate. Simulation experiments show the superiority of Algorithm 5 over the others. To show the efficiency of Algorithm 5, its results are compared with those of the multiple edge sensitivity method (MESM). The obtained results show that Algorithm 5 performs better than MESM both in terms of the running time and sampling rate. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Learning automata-based algorithms for solving stochastic minimum spanning tree problem", "paper_id": "WOS:000290561000002"}