{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "cross-modal_multimedia_retrieval"}, {"score": 0.0047057084749407485, "phrase": "cross-modal_retrieval"}, {"score": 0.00443308765153716, "phrase": "retrieval_systems"}, {"score": 0.004332471656145115, "phrase": "content_modalities"}, {"score": 0.004062682236016889, "phrase": "mathematical_formulation"}, {"score": 0.003916098498242888, "phrase": "cross-modal_retrieval_systems"}, {"score": 0.0038447943243941685, "phrase": "isomorphic_feature_spaces"}, {"score": 0.003809628721278519, "phrase": "different_content_modalities"}, {"score": 0.0036721416244816455, "phrase": "fundamental_attributes"}, {"score": 0.0035233696341819437, "phrase": "low-level_cross-modal_correlations"}, {"score": 0.0033037970113095577, "phrase": "semantic_abstraction"}, {"score": 0.0032287289440915187, "phrase": "cross-modal_retrieval_problem"}, {"score": 0.0029586543333524904, "phrase": "cross-modal_correlations"}, {"score": 0.0027741761880779535, "phrase": "semantic_representation"}, {"score": 0.0025892330566358503, "phrase": "extensive_evaluation"}, {"score": 0.0025655216052760093, "phrase": "retrieval_performance"}, {"score": 0.0023725232579531273, "phrase": "text_retrieval"}, {"score": 0.002329258721870127, "phrase": "image_queries"}, {"score": 0.0023079225317714815, "phrase": "vice_versa"}, {"score": 0.002183938718432764, "phrase": "complementary_form"}, {"score": 0.0021049977753042253, "phrase": "abstraction_hypothesis"}], "paper_keywords": ["Multimedia", " content-based retrieval", " multimodal", " cross-modal", " image and text", " retrieval model", " semantic spaces", " kernel correlation", " logistic regression"], "paper_abstract": "The problem of cross-modal retrieval from multimedia repositories is considered. This problem addresses the design of retrieval systems that support queries across content modalities, for example, using an image to search for texts. A mathematical formulation is proposed, equating the design of cross-modal retrieval systems to that of isomorphic feature spaces for different content modalities. Two hypotheses are then investigated regarding the fundamental attributes of these spaces. The first is that low-level cross-modal correlations should be accounted for. The second is that the space should enable semantic abstraction. Three new solutions to the cross-modal retrieval problem are then derived from these hypotheses: correlation matching (CM), an unsupervised method which models cross-modal correlations, semantic matching (SM), a supervised technique that relies on semantic representation, and semantic correlation matching (SCM), which combines both. An extensive evaluation of retrieval performance is conducted to test the validity of the hypotheses. All approaches are shown successful for text retrieval in response to image queries and vice versa. It is concluded that both hypotheses hold, in a complementary form, although evidence in favor of the abstraction hypothesis is stronger than that for correlation.", "paper_title": "On the Role of Correlation and Abstraction in Cross-Modal Multimedia Retrieval", "paper_id": "WOS:000331450100010"}