{"auto_keywords": [{"score": 0.03503987270340682, "phrase": "ml"}, {"score": 0.00481495049065317, "phrase": "distributed_streaming_sources"}, {"score": 0.004767546015485477, "phrase": "distributed_source_coding"}, {"score": 0.004628101576367193, "phrase": "block_coding_context"}, {"score": 0.0045599093158915326, "phrase": "source_symbols"}, {"score": 0.0042336638794732255, "phrase": "source_coding_ideas"}, {"score": 0.0040491842732233154, "phrase": "streaming_data"}, {"score": 0.003969784439380027, "phrase": "streaming_setting"}, {"score": 0.00393066798511457, "phrase": "source_symbol_pairs"}, {"score": 0.003853583126988071, "phrase": "separate_encoders"}, {"score": 0.003815607281455725, "phrase": "real_time"}, {"score": 0.003577691211998842, "phrase": "tolerable_end-to-end_delay"}, {"score": 0.003455765987713262, "phrase": "causal_sequential_random_binning_encoder"}, {"score": 0.0033545600622020464, "phrase": "maximum_likelihood"}, {"score": 0.0032724821705972357, "phrase": "universal_decoders"}, {"score": 0.003176626803985225, "phrase": "novel_weighted_empirical_suffix_entropy_decoding_rule"}, {"score": 0.003038066486989815, "phrase": "error_exponent"}, {"score": 0.0028911669203979156, "phrase": "upper_bounds"}, {"score": 0.0028484940955893134, "phrase": "special_case"}, {"score": 0.0027925723953701083, "phrase": "decoder_side_information"}, {"score": 0.002737745536992088, "phrase": "upper_and_lower_bounds"}, {"score": 0.0024793019587009035, "phrase": "slepian-wolf_achievable_rate_region"}, {"score": 0.002278856202878812, "phrase": "different_exponents"}, {"score": 0.002234092591045251, "phrase": "sequential_random_binning_scheme"}, {"score": 0.002147180332779021, "phrase": "resulting_code"}, {"score": 0.0021049977753042253, "phrase": "source_symbol"}], "paper_keywords": ["Distributed source coding", " lossless source coding", " Slepian-Wolf coding", " streaming data", " universal decoding"], "paper_abstract": "Distributed source coding is traditionally viewed in a block coding context wherein all source symbols are known in advance by the encoders. However, many modern applications to which distributed source coding ideas are applied, are better modeled as having streaming data. In a streaming setting, source symbol pairs are revealed to separate encoders in real time and need to be reconstructed at the decoder with subject to some tolerable end-to-end delay. In this paper, a causal sequential random binning encoder is introduced and paired with maximum likelihood (ML) and universal decoders. The latter uses a novel weighted empirical suffix entropy decoding rule. We derive a lower bounds on the error exponent with delay for each decoder. We also provide upper bounds for the special case of streaming with decoder side information and discuss when upper and lower bounds match. We show that both ML and universal decoders achieve the same (positive) error exponents for all rate pairs inside the Slepian-Wolf achievable rate region. The dominant error events in streaming are different from those in block-coding and result in different exponents. Because the sequential random binning scheme is also universal over delays, the resulting code eventually reconstructs every source symbol correctly with probability one.", "paper_title": "Lossless Coding for Distributed Streaming Sources", "paper_id": "WOS:000331902400005"}