{"auto_keywords": [{"score": 0.04861823021267309, "phrase": "speech_understanding"}, {"score": 0.03177904419579679, "phrase": "complete_face"}, {"score": 0.00481495049065317, "phrase": "tongue_movements"}, {"score": 0.0047003115977448905, "phrase": "tongue_display"}, {"score": 0.0045726187330434025, "phrase": "visible_articulators"}, {"score": 0.004180992206290323, "phrase": "important_part"}, {"score": 0.004138010495069077, "phrase": "articulatory_information"}, {"score": 0.004081385289516914, "phrase": "lip_reading"}, {"score": 0.003970439654470374, "phrase": "direct_and_full_vision"}, {"score": 0.0037704502704526996, "phrase": "audiovisual_vcv_stimuli"}, {"score": 0.003731673223879279, "phrase": "audiovisual_talking_head"}, {"score": 0.003667925754747227, "phrase": "speech_articulators"}, {"score": 0.0035804980565263024, "phrase": "augmented_speech_mode"}, {"score": 0.003543667617024855, "phrase": "talking_head"}, {"score": 0.0035072146967082083, "phrase": "virtual_clone"}, {"score": 0.003471135453226184, "phrase": "human_speaker"}, {"score": 0.003435426082776884, "phrase": "articulatory_movements"}, {"score": 0.0033304797419738182, "phrase": "electromagnetic_articulography"}, {"score": 0.003307610013199923, "phrase": "ema"}, {"score": 0.0031845067058084583, "phrase": "audiovisual_perception_tests"}, {"score": 0.0030659842174709656, "phrase": "profile_cutaway_display"}, {"score": 0.002841971477743441, "phrase": "implicit_learning"}, {"score": 0.002310578855290687, "phrase": "tongue_reading_capabilities"}, {"score": 0.0022322004700942267, "phrase": "speech_therapy"}, {"score": 0.0022092084106039834, "phrase": "retarded_children"}, {"score": 0.0021714122348552747, "phrase": "production_rehabilitation"}, {"score": 0.0021490449563443025, "phrase": "impaired_children"}, {"score": 0.0021195791482462004, "phrase": "pronunciation_training"}, {"score": 0.0021049977753042253, "phrase": "second_language_learners"}], "paper_keywords": ["Lip reading", " Tongue reading", " Audiovisual speech perception", " Virtual audiovisual talking head", " Augmented speech", " ElectroMagnetic Articulography (EMA)"], "paper_abstract": "Lip reading relies on visible articulators to ease speech understanding. However, lips and face alone provide very incomplete phonetic information: the tongue, that is generally not entirely seen, carries an important part of the articulatory information not accessible through lip reading. The question is thus whether the direct and full vision of the tongue allows tongue reading. We have therefore generated a set of audiovisual VCV stimuli with an audiovisual talking head that can display all speech articulators, including tongue, in an augmented speech mode. The talking head is a virtual clone of a human speaker and the articulatory movements have also been captured on this speaker using ElectroMagnetic Articulography (EMA). These stimuli have been played to subjects in audiovisual perception tests in various presentation conditions (audio signal alone, audiovisual signal with profile cutaway display with or without tongue, complete face), at various Signal-to-Noise Ratios. The results indicate: (1) the possibility of implicit learning of tongue reading, (2) better consonant identification with the cutaway presentation with the tongue than without the tongue, (3) no significant difference between the cutaway presentation with the tongue and the more ecological rendering of the complete face, (4) a predominance of lip reading over tongue reading, but (5) a certain natural human capability for tongue reading when the audio signal is strongly degraded or absent. We conclude that these tongue reading capabilities could be used for applications in the domains of speech therapy for speech retarded children, of perception and production rehabilitation of hearing impaired children, and of pronunciation training for second language learners. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Can you 'read' tongue movements? Evaluation of the contribution of tongue display to speech understanding", "paper_id": "WOS:000278282000003"}