{"auto_keywords": [{"score": 0.04958720442967606, "phrase": "bfa"}, {"score": 0.043819293605899395, "phrase": "model_selection"}, {"score": 0.00481495049065317, "phrase": "bayesian_ying-yang_learning_on_orthogonal_binary_factor_analysis._binary_factor_analysis"}, {"score": 0.004549063619065006, "phrase": "high_dimensional_data"}, {"score": 0.004364919932563366, "phrase": "exponential_computational_complexity"}, {"score": 0.004297795905522757, "phrase": "large_number"}, {"score": 0.004253618550301311, "phrase": "local_optima"}, {"score": 0.004102528738941734, "phrase": "latent_binary_dimension"}, {"score": 0.003757480190200645, "phrase": "parameter_learning"}, {"score": 0.0036616109902631293, "phrase": "candidate_model_scale"}, {"score": 0.003513264130359459, "phrase": "optimal_scale"}, {"score": 0.003405948098114941, "phrase": "model_selection_criterion"}, {"score": 0.0032176163279340206, "phrase": "performance_oil_large_scale_structures"}, {"score": 0.0031193028729331667, "phrase": "bayesian_ying-yang"}, {"score": 0.0030554300179552415, "phrase": "harmony_learning"}, {"score": 0.0029928611380840757, "phrase": "high_dimensional_model"}, {"score": 0.0027126684113045756, "phrase": "orthogonal_binary_factor_analysis"}, {"score": 0.0026297428083782875, "phrase": "bayesian_inference"}, {"score": 0.0025892330566358503, "phrase": "latent_binary_code"}, {"score": 0.002471400498582011, "phrase": "byy_machine"}, {"score": 0.002408265305704217, "phrase": "harmony_measure"}, {"score": 0.0023467391904246834, "phrase": "objective_function"}, {"score": 0.0023225701080913388, "phrase": "byy_learning"}, {"score": 0.0022283519468680475, "phrase": "regularisation_term"}, {"score": 0.0022053994402287925, "phrase": "experimental_comparison"}, {"score": 0.0021714122348552747, "phrase": "two-phase_implementations"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Binary factor analysis", " model selection", " Bayesian Ying-Yang learning"], "paper_abstract": "Binary Factor Analysis (BFA) aims to discover latent binary structures in high dimensional data. Parameter learning in BFA faces an exponential computational complexity and a large number of local optima. The model selection to determine the latent binary dimension is therefore difficult. Traditionally, it is implemented in two separate stages with two different objectives. First, parameter learning is performed for each candidate model scale to maximise the likelihood; then the optimal scale is selected to minimise a model selection criterion. Such a two-phase implementation suffers from huge computational cost and deteriorated learning performance oil large scale structures. In contrast, the Bayesian Ying-Yang (BYY) harmony learning starts from a high dimensional model and automatically deducts the dimension during learning. This paper investigates model selection on a subclass of BFA called Orthogonal Binary Factor Analysis (OBFA). The Bayesian inference of the latent binary code is analytically solved, based oil which a BYY machine is constructed. The harmony measure that serves as the objective function in BYY learning is more accurately estimated by recovering a regularisation term. Experimental comparison with the two-phase implementations shows superior performance of the proposed approach.", "paper_title": "BAYESIAN YING-YANG LEARNING ON ORTHOGONAL BINARY FACTOR ANALYSIS", "paper_id": "WOS:000271688500015"}