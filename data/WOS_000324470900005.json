{"auto_keywords": [{"score": 0.04880638758905068, "phrase": "vm"}, {"score": 0.009846697000099602, "phrase": "network-attached_storage_device"}, {"score": 0.00861096091333833, "phrase": "target_host"}, {"score": 0.00481495049065317, "phrase": "efficient_live_migration_of_virtual_machines_using_shared_storage"}, {"score": 0.00477190623242136, "phrase": "live_migration"}, {"score": 0.0047292449487169345, "phrase": "virtual_machines"}, {"score": 0.0046242451772036145, "phrase": "distinct_physical_hosts"}, {"score": 0.004562362497952548, "phrase": "important_feature"}, {"score": 0.004521566043596533, "phrase": "virtualization_technology"}, {"score": 0.004401342842183475, "phrase": "energy_reduction"}, {"score": 0.004303591748086452, "phrase": "data_centers_operators"}, {"score": 0.0042650992966174065, "phrase": "cluster_service_providers"}, {"score": 0.0038636556112977226, "phrase": "total_migration_time"}, {"score": 0.0036443694410100507, "phrase": "total_time"}, {"score": 0.0032716011062067286, "phrase": "modern_operating_systems"}, {"score": 0.0032277611129050234, "phrase": "better_part"}, {"score": 0.0031845067058084583, "phrase": "physical_memory"}, {"score": 0.003113696267229798, "phrase": "secondary_storage"}, {"score": 0.00295008998986066, "phrase": "updated_mapping"}, {"score": 0.0029236680654022664, "phrase": "memory_pages"}, {"score": 0.0028586409810976367, "phrase": "identical_form"}, {"score": 0.002820319063320601, "phrase": "storage_device"}, {"score": 0.00277001889871322, "phrase": "iterative_pre-copy_live_migration_process"}, {"score": 0.0025892330566358503, "phrase": "memory-to-disk_mapping"}, {"score": 0.0023451553255837317, "phrase": "xen_hypervisor"}, {"score": 0.002262209824105154, "phrase": "linux_hvm_guests"}, {"score": 0.0022019274077124795, "phrase": "presented_technique"}, {"score": 0.0021049977753042253, "phrase": "total_transfer_time"}], "paper_keywords": ["Design", " Measurement", " Performance", " Reliability", " Virtualization", " Live migration", " Storage", " Xen"], "paper_abstract": "Live migration of virtual machines (VM) across distinct physical hosts is an important feature of virtualization technology for maintenance, load-balancing and energy reduction, especially so for data centers operators and cluster service providers. Several techniques have been proposed to reduce the downtime of the VM being transferred, often at the expense of the total migration time. In this work, we present a technique to reduce the total time required to migrate a running VM from one host to another while keeping the downtime to a minimum. Based on the observation that modern operating systems use the better part of the physical memory to cache data from secondary storage, our technique tracks the VM's I/O operations to the network-attached storage device and maintains an updated mapping of memory pages that currently reside in identical form on the storage device. During the iterative pre-copy live migration process, instead of transferring those pages from the source to the target host, the memory-to-disk mapping is sent to the target host which then fetches the contents directly from the network-attached storage device. We have implemented our approach into the Xen hypervisor and ran a series of experiments with Linux HVM guests. On average, the presented technique shows a reduction of up over 30% on average of the total transfer time for a series of benchmarks.", "paper_title": "Efficient Live Migration of Virtual Machines Using Shared Storage", "paper_id": "WOS:000324470900005"}