{"auto_keywords": [{"score": 0.04755730354600057, "phrase": "real-time_implementation"}, {"score": 0.004816265469549797, "phrase": "bayesian"}, {"score": 0.004686649943692675, "phrase": "gpu."}, {"score": 0.004509057381424944, "phrase": "bayesian_framework"}, {"score": 0.004474366340935036, "phrase": "robotic_multisensory_perception"}, {"score": 0.004422827355213055, "phrase": "graphics_processing_unit"}, {"score": 0.004389130637448888, "phrase": "gpu"}, {"score": 0.004222515162635615, "phrase": "additional_objective"}, {"score": 0.004078232992955235, "phrase": "parallel_computing"}, {"score": 0.004046843083499649, "phrase": "similar_problems"}, {"score": 0.003789632898151737, "phrase": "cuda"}, {"score": 0.003745881316228299, "phrase": "programming_tool"}, {"score": 0.0036459007842756983, "phrase": "biological_systems"}, {"score": 0.0034672240102960644, "phrase": "prohibitory_factor"}, {"score": 0.0034405207528624983, "phrase": "real-time_implementations"}, {"score": 0.0032972747743006603, "phrase": "large_data_structures"}, {"score": 0.0032216622984027558, "phrase": "bayesian_inference"}, {"score": 0.00297037471252423, "phrase": "relatively_simple_and_highly_parallelisable_algorithms"}, {"score": 0.0027813397260607487, "phrase": "regular_cpu_implementation"}, {"score": 0.0026043035241045394, "phrase": "implemented_multimodal_perception_module"}, {"score": 0.002476546030310661, "phrase": "egocentric_representation"}, {"score": 0.0024385083712241988, "phrase": "local_motion"}, {"score": 0.0023099082804523044, "phrase": "active_exploration"}, {"score": 0.0022481685132781626, "phrase": "bvm._experimental_results"}, {"score": 0.0021796224306652326, "phrase": "robotic_system"}, {"score": 0.0021049977753042253, "phrase": "high_uncertainty"}], "paper_keywords": ["GPU", " NVIDIA CUDA", " Multimodal Bayesian perception"], "paper_abstract": "In this text we present the real-time implementation of a Bayesian framework for robotic multisensory perception on a graphics processing unit (GPU) using the Compute Unified Device Architecture (CUDA). As an additional objective, we intend to show the benefits of parallel computing for similar problems (i.e. probabilistic grid-based frameworks), and the user-friendly nature of CUDA as a programming tool. Inspired by the study of biological systems, several Bayesian inference algorithms for artificial perception have been proposed. Their high computational cost has been a prohibitory factor for real-time implementations. However in some cases the bottleneck is in the large data structures involved, rather than the Bayesian inference per se. We will demonstrate that the SIMD (single-instruction, multiple-data) features of GPUs provide a means for taking a complicated framework of relatively simple and highly parallelisable algorithms operating on large data structures, which might take up to several minutes of execution with a regular CPU implementation, and arrive at an implementation that executes in the order of tenths of a second. The implemented multimodal perception module (including stereovision, binaural sensing and inertial sensing) builds an egocentric representation of occupancy and local motion, the Bayesian Volumetric Map (BVM), based on which gaze shift decisions are made to perform active exploration and reduce the entropy of the BVM. Experimental results show that the real-time implementation successfully drives the robotic system to explore areas of the environment mapped with high uncertainty.", "paper_title": "Bayesian real-time perception algorithms on GPU", "paper_id": "WOS:000293958100004"}