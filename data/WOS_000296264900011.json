{"auto_keywords": [{"score": 0.04014175749838657, "phrase": "user_level"}, {"score": 0.027579572033278706, "phrase": "ulcc"}, {"score": 0.015719716506582538, "phrase": "shared_cache_performance"}, {"score": 0.015500728800089328, "phrase": "scientific_applications"}, {"score": 0.014861626425527113, "phrase": "access_contention"}, {"score": 0.010790780205930448, "phrase": "cache_space"}, {"score": 0.009985404470209151, "phrase": "cache_pollution"}, {"score": 0.004713594814274419, "phrase": "serious_performance_challenges"}, {"score": 0.004680283709974884, "phrase": "multicore_processors"}, {"score": 0.004517210371632577, "phrase": "last_level"}, {"score": 0.0044535760439663235, "phrase": "multiple_running_threads"}, {"score": 0.0043289723873340255, "phrase": "long_latency_memory_accesses"}, {"score": 0.004252864101987588, "phrase": "application_execution_times"}, {"score": 0.004119211418949265, "phrase": "execution_times"}, {"score": 0.004090083576606688, "phrase": "multi-threaded_programs"}, {"score": 0.0038918527536981897, "phrase": "cache_optimization_techniques"}, {"score": 0.0037031937016576695, "phrase": "last_level_cache"}, {"score": 0.0035740424892197155, "phrase": "shared_space"}, {"score": 0.0035236476185949565, "phrase": "cache_conscious_algorithms"}, {"score": 0.0034987163424726546, "phrase": "single_cores"}, {"score": 0.003247319029344241, "phrase": "running_threads"}, {"score": 0.003212906206685004, "phrase": "shared_cache"}, {"score": 0.0031451673059794236, "phrase": "strong_locality"}, {"score": 0.0030788521585190802, "phrase": "sufficient_cache_space"}, {"score": 0.0027092368768921542, "phrase": "last_level_cache_usage"}, {"score": 0.0026805109390121706, "phrase": "proper_cache_space"}, {"score": 0.00266152927283908, "phrase": "different_data_sets"}, {"score": 0.002642681666526916, "phrase": "different_threads"}, {"score": 0.002532359001507531, "phrase": "page-coloring_technique"}, {"score": 0.0025144238077014114, "phrase": "last_level_cache_usage_management"}, {"score": 0.0024701382170046462, "phrase": "multiple_case_studies"}, {"score": 0.0024439412207268355, "phrase": "intel_multicore_processor"}, {"score": 0.0023502347146791285, "phrase": "significant_performance_improvements"}, {"score": 0.0022924784914292026, "phrase": "cache_optimization_algorithms"}, {"score": 0.002220296517089146, "phrase": "frequently_reused_data_sets"}, {"score": 0.0021049977753042253, "phrase": "application_performance"}], "paper_keywords": ["Multicore", " Cache", " Scientific Computing", " Algorithms", " Design", " Performance"], "paper_abstract": "Scientific applications face serious performance challenges on multicore processors, one of which is caused by access contention in last level shared caches from multiple running threads. The contention increases the number of long latency memory accesses, and consequently increases application execution times. Optimizing shared cache performance is critical to significantly reduce execution times of multi-threaded programs on multicores. However, there are two unique problems to be solved before implementing cache optimization techniques on multicores at the user level. First, available cache space for each running thread in a last level cache is difficult to predict due to access contention in the shared space, which makes cache conscious algorithms for single cores ineffective on multicores. Second, at the user level, programmers are not able to allocate cache space at will to running threads in the shared cache, thus data sets with strong locality may not be allocated with sufficient cache space, and cache pollution can easily happen. To address these two critical issues, we have designed ULCC (User Level Cache Control), a software runtime library that enables programmers to explicitly manage and optimize last level cache usage by allocating proper cache space for different data sets of different threads. We have implemented ULCC at the user level based on a page-coloring technique for last level cache usage management. By means of multiple case studies on an Intel multicore processor, we show that with ULCC, scientific applications can achieve significant performance improvements by fully exploiting the benefit of cache optimization algorithms and by partitioning the cache space accordingly to protect frequently reused data sets and to avoid cache pollution. Our experiments with various applications show that ULCC can significantly improve application performance by nearly 40%.", "paper_title": "ULCC: A User-Level Facility for Optimizing Shared Cache Performance on Multicores", "paper_id": "WOS:000296264900011"}