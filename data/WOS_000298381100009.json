{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "high_performance_computing_systems"}, {"score": 0.043733065812188825, "phrase": "scientific_applications"}, {"score": 0.0332712604336944, "phrase": "lock_contention"}, {"score": 0.004760765880314089, "phrase": "massively_parallel_applications"}, {"score": 0.004680624753255133, "phrase": "periodic_data"}, {"score": 0.0046018264570209765, "phrase": "program_restart"}, {"score": 0.004550029253278477, "phrase": "post-run_data_analysis"}, {"score": 0.004348580182733617, "phrase": "computing_power"}, {"score": 0.004251210982670317, "phrase": "crucial_requirements"}, {"score": 0.004062937864702115, "phrase": "high-end_applications"}, {"score": 0.003949508242904001, "phrase": "strict_data_consistency_semantics"}, {"score": 0.003882970272082245, "phrase": "traditional_file_systems"}, {"score": 0.0037959868107895053, "phrase": "homogeneous_parallel_computing_platforms"}, {"score": 0.0037320255482878365, "phrase": "high_performance_parallel_applications"}, {"score": 0.0035666632046674153, "phrase": "checkpointing_data"}, {"score": 0.003332210257373994, "phrase": "large_number"}, {"score": 0.0032575241721857343, "phrase": "large-scale_systems"}, {"score": 0.003078028357912228, "phrase": "file_system_layer"}, {"score": 0.002843180211561427, "phrase": "process_synchronization"}, {"score": 0.002763709443278514, "phrase": "great_challenge"}, {"score": 0.0025383451160985488, "phrase": "parallel_storage_systems"}, {"score": 0.002495521662819317, "phrase": "static_file_domain"}, {"score": 0.0023313149689465386, "phrase": "client-server_mapping"}, {"score": 0.002279011030331704, "phrase": "file_lock_acquisition_costs"}], "paper_keywords": ["Parallel I/O", " I/O delegation", " MPI-IO", " non collective I/O", " collaborative caching", " parallel file systems", " file locking"], "paper_abstract": "Massively parallel applications often require periodic data checkpointing for program restart and post-run data analysis. Although high performance computing systems provide massive parallelism and computing power to fulfill the crucial requirements of the scientific applications, the I/O tasks of high-end applications do not scale. Strict data consistency semantics adopted from traditional file systems are inadequate for homogeneous parallel computing platforms. For high performance parallel applications independent I/O is critical, particularly if checkpointing data are dynamically created or irregularly partitioned. In particular, parallel programs generating a large number of unrelated I/O accesses on large-scale systems often face serious I/O serializations introduced by lock contention and conflicts at file system layer. As these applications may not be able to utilize the I/O optimizations requiring process synchronization, they pose a great challenge for parallel I/O architecture and software designs. We propose an I/O mechanism to bridge the gap between scientific applications and parallel storage systems. A static file domain partitioning method is developed to align the I/O requests and produce a client-server mapping that minimizes the file lock acquisition costs and eliminates the lock contention. Our performance evaluations of production application I/O kernels demonstrate scalable performance and achieve high I/O bandwidths.", "paper_title": "Delegation-Based I/O Mechanism for High Performance Computing Systems", "paper_id": "WOS:000298381100009"}