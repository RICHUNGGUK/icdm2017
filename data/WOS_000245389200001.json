{"auto_keywords": [{"score": 0.04455909671406697, "phrase": "human_feedback"}, {"score": 0.00481495049065317, "phrase": "traditional_active_learning_framework"}, {"score": 0.004580550308652044, "phrase": "labeling_instances"}, {"score": 0.004430629452265786, "phrase": "careful_study"}, {"score": 0.004309434349688514, "phrase": "feature_selection"}, {"score": 0.004099542199088835, "phrase": "text_categorization"}, {"score": 0.0039433581938239926, "phrase": "categorization_tasks"}, {"score": 0.0038354405231002323, "phrase": "significant_potential"}, {"score": 0.0037721073763702486, "phrase": "classifier_performance"}, {"score": 0.0035684266744407485, "phrase": "membership_queries"}, {"score": 0.003123203316511694, "phrase": "human_subjects"}, {"score": 0.0030376623293574905, "phrase": "feature_relevance"}, {"score": 0.002970914475538276, "phrase": "sufficient_proportion"}, {"score": 0.002486987042061596, "phrase": "labeling_features"}, {"score": 0.0024054226746197706, "phrase": "standard_active_learning"}, {"score": 0.0023525345110929326, "phrase": "feature_feedback"}, {"score": 0.0023136311468961125, "phrase": "traditional_active_learning"}, {"score": 0.0022502133699402018, "phrase": "news_filtering"}, {"score": 0.0022253345930383257, "phrase": "e-mail_classification"}, {"score": 0.002140400526572388, "phrase": "human_teacher"}, {"score": 0.0021049977753042253, "phrase": "significant_knowledge"}], "paper_keywords": ["active learning", " feature selection", " relevance feedback", " term feedback", " text classification"], "paper_abstract": "We extend the traditional active learning framework to include feedback on features in addition to labeling instances, and we execute a careful study of the effects of feature selection and human feedback on features in the setting of text categorization. Our experiments on a variety of categorization tasks indicate that there is significant potential in improving classifier performance by feature re-weighting, beyond that achieved via membership queries alone (traditional active learning) if we have access to an oracle that can point to the important (most predictive) features. Our experiments on human subjects indicate that human feedback on feature relevance can identify a sufficient proportion of the most relevant features (over 50% in our experiments). We find that on average, labeling a feature takes much less time than labeling a document. We devise an algorithm that interleaves labeling features and documents which significantly accelerates standard active learning in our simulation experiments. Feature feedback can complement traditional active learning in applications such as news filtering, e-mail classification, and personalization, where the human teacher can have significant knowledge on the relevance of features.", "paper_title": "Active learning with feedback on both features and instances", "paper_id": "WOS:000245389200001"}