{"auto_keywords": [{"score": 0.04601284855430019, "phrase": "underlying_computing_platforms"}, {"score": 0.031763843900136826, "phrase": "memory_footprint"}, {"score": 0.0048149748050576435, "phrase": "cuda."}, {"score": 0.004721162131188487, "phrase": "sparse_matrix-vector_multiplication"}, {"score": 0.004583878086896926, "phrase": "memory_bandwidth"}, {"score": 0.004450568197899267, "phrase": "input_matrices"}, {"score": 0.004133940019630129, "phrase": "optimization_techniques"}, {"score": 0.003954837422946628, "phrase": "storage_formats"}, {"score": 0.003896871009090446, "phrase": "sparse_matrices"}, {"score": 0.0037834649508375544, "phrase": "prior_storage_formats"}, {"score": 0.003566422652043389, "phrase": "unsatisfactory_performance"}, {"score": 0.003531474887552889, "phrase": "large_memory_footprint"}, {"score": 0.003445591238183763, "phrase": "novel_storage_format"}, {"score": 0.0029722900280316216, "phrase": "graphics_processing_unit"}, {"score": 0.0029433712274545333, "phrase": "gpu"}, {"score": 0.002899965889623787, "phrase": "shec_format"}, {"score": 0.0028574164693918433, "phrase": "interleaved_combination_pattern"}, {"score": 0.0027741761880779535, "phrase": "compressed_rows"}, {"score": 0.0027200305495826797, "phrase": "new_shec_row"}, {"score": 0.0025137856138000014, "phrase": "empirical_data"}, {"score": 0.0024768883044869023, "phrase": "automatic_shec-based_spmv"}, {"score": 0.0023811153883132536, "phrase": "experimental_results"}, {"score": 0.002346160830406661, "phrase": "shec_approach"}, {"score": 0.0023117182131967523, "phrase": "best_results"}, {"score": 0.0022890371899188466, "phrase": "nvidia_spmv_library"}, {"score": 0.0022443390559699974, "phrase": "comparable_performance"}, {"score": 0.0022223176391038785, "phrase": "state-of-the-art_storage_formats"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["GPU", " sparse matrix-vector multiplication", " hybrid", " interleaved combination", " segmentation", " memory footprint"], "paper_abstract": "The challenge for Sparse Matrix-Vector multiplication (SpMV) performance is memory bandwidth, which mostly depends on input matrices and underlying computing platforms. To solve this challenge, many researchers have explored a variety of optimization techniques. One of the most promising aspects focuses on designing storage formats to represent sparse matrices. However, lots of prior storage formats cannot fully take advantage of the underlying computing platforms, resulting in unsatisfactory performance and large memory footprint. Therefore, a novel storage format, called Segmented Hybrid ELL + Compressed Sparse Row (CSR) (SHEC for short), is proposed to further improve the throughput and lessen memory footprint on Graphics Processing Unit (GPU). SHEC format employs an interleaved combination pattern, which combines certain amount of compressed rows to form a new SHEC row. Segmentation is brought in to balance load and reduce memory footprint. According to the empirical data, an automatic SHEC-based SpMV is developed to fit for all the matrices. Experimental results show that SHEC approach outperforms the best results of NVIDIA SpMV library and exhibits a comparable performance with state-of-the-art storage formats on the standard dataset. Copyright (c) 2012 John Wiley & Sons, Ltd.", "paper_title": "A segment-based sparse matrix-vector multiplication on CUDA", "paper_id": "WOS:000328162500012"}