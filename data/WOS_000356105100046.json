{"auto_keywords": [{"score": 0.049469816714638924, "phrase": "proxy-based_local_consistency_propagation"}, {"score": 0.04191047267508905, "phrase": "unlabeled_ones"}, {"score": 0.00481495049065317, "phrase": "semi-supervised_annotation"}, {"score": 0.0044873778175404475, "phrase": "novel_label_propagation_algorithm"}, {"score": 0.004208881856146758, "phrase": "label_information"}, {"score": 0.004076157223660074, "phrase": "labeled_examples"}, {"score": 0.0037262941538784094, "phrase": "steady_state"}, {"score": 0.003362944428837724, "phrase": "online_semi-supervised_annotation_framework"}, {"score": 0.002977062277517556, "phrase": "plcp"}, {"score": 0.0028830690329478465, "phrase": "inductive_setting"}, {"score": 0.0028100102841877835, "phrase": "incremental_model_updating_method"}, {"score": 0.0027212777001495176, "phrase": "new_examples"}, {"score": 0.0026865721000905235, "phrase": "labeled_and_unlabeled_examples"}, {"score": 0.002635339648135844, "phrase": "comprehensive_experiments"}, {"score": 0.002568542343945288, "phrase": "pie_datasets"}, {"score": 0.0024874156497091994, "phrase": "superior_performance"}, {"score": 0.0022302306304023602, "phrase": "nearly_identical_accuracy"}, {"score": 0.0021050078070343043, "phrase": "elsevier"}], "paper_keywords": ["Image annotation", " Label propagation", " Semi-supervised learning", " Incremental learning", " Online learning"], "paper_abstract": "In this paper, we propose a novel label propagation algorithm named Proxy-based Local Consistency Propagation (PLCP), in which the label information is first propagated from labeled examples to the unlabeled ones, and then spreads only among unlabeled ones mutually until a steady state is reached. To meet the requirements of efficiency in many real-world image annotation applications, we propose an online semi-supervised annotation framework where the new examples can be predicted and used to update the model. Specifically, we extend PLCP to work under an inductive setting and propose an incremental model updating method that can incorporate the new examples including labeled and unlabeled examples. The comprehensive experiments on MNIST. CIFAR-10 and PIE datasets show that our proposed PLCP achieves superior performance compared with the baselines, and our proposed incremental model updating method can achieve significant promotion in efficiency, with the nearly identical accuracy compared to re-training. (C) 2014 Elsevier BM. All rights reserved.", "paper_title": "Online semi-supervised annotation via proxy-based local consistency propagation", "paper_id": "WOS:000356105100046"}