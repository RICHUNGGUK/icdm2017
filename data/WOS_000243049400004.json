{"auto_keywords": [{"score": 0.05007830243554293, "phrase": "high-level_image_concepts"}, {"score": 0.04354035476465974, "phrase": "mmm"}, {"score": 0.037489238569685335, "phrase": "high-level_concepts"}, {"score": 0.004706305193222972, "phrase": "image_database_retrieval"}, {"score": 0.004475798524102238, "phrase": "markov_model_mediator"}, {"score": 0.004335000368745273, "phrase": "efficient_and_effective_capturing"}, {"score": 0.004256533389293113, "phrase": "content-based_image_retrieval"}, {"score": 0.004085115444878828, "phrase": "retrieval_engine"}, {"score": 0.004029517895918228, "phrase": "cbir_system"}, {"score": 0.003974673997871831, "phrase": "affinity-based_similarity_measures"}, {"score": 0.003832031470970347, "phrase": "subjective_user_concepts"}, {"score": 0.003660879039645457, "phrase": "global_image_features"}, {"score": 0.003433987036569199, "phrase": "user_access_patterns"}, {"score": 0.0034027387694902287, "phrase": "access_frequencies"}, {"score": 0.003310684108128973, "phrase": "image_database"}, {"score": 0.0032064196784562017, "phrase": "common_methods"}, {"score": 0.003177237023016464, "phrase": "cbir."}, {"score": 0.002993887707344862, "phrase": "structured_description"}, {"score": 0.0029666322924554274, "phrase": "visual_contents"}, {"score": 0.0026582395558737855, "phrase": "low-level_features"}, {"score": 0.002493333098814506, "phrase": "principal_component_analysis"}, {"score": 0.002470894656693388, "phrase": "pca"}, {"score": 0.002403724423251419, "phrase": "image_search_space"}, {"score": 0.002370955769074803, "phrase": "low_cost"}, {"score": 0.0023386327847292805, "phrase": "exact_similarity"}, {"score": 0.0022962183207691188, "phrase": "off-line_training_subsystem"}, {"score": 0.0021735249249471614, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "user's_high-level_concept"}], "paper_keywords": ["Content-Based Image Retrieval (CBIR)", " Markov Model Mediator (MMM)", " Principal Component Analysis (PCA)"], "paper_abstract": "In this paper, we present a mechanism called Markov Model Mediator (MMM) to facilitate the efficient and effective capturing of high-level image concepts in content-based image retrieval (CBIR). MMM serves as the retrieval engine of the CBIR system and uses affinity-based similarity measures. This mechanism is effective in capturing subjective user concepts in that it not only takes into consideration the global image features, but also learns the high-level concepts of the images from the history of user access patterns and access frequencies on the images in the image database, which differentiates it from the common methods in CBIR. The advantage of our proposed mechanism is that it exploits the richness in the structured description of visual contents as well as the relative affinity relationships among the images. Consequently, it provides the capability to bridge the gap between the low-level features and the high-level concepts. This mechanism is also efficient in that it integrates Principal Component Analysis (PCA) to significantly reduce the image search space at a low cost before performing exact similarity matching. An off-line training subsystem for this framework was implemented and integrated into our system. The experimental results demonstrate that MMM can effectively capture user's high-level concept more quickly.", "paper_title": "Capturing high-level image concepts via affinity relationships in image database retrieval", "paper_id": "WOS:000243049400004"}