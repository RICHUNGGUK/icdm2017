{"auto_keywords": [{"score": 0.038899833657713954, "phrase": "training_data"}, {"score": 0.00481495049065317, "phrase": "single_sample"}, {"score": 0.004726579360618152, "phrase": "generic_learning"}, {"score": 0.004691684576246597, "phrase": "incremental_learning"}, {"score": 0.004605565335682916, "phrase": "parameter-free_face_recognition_algorithm"}, {"score": 0.00452101969521343, "phrase": "large_variations"}, {"score": 0.004324361008753555, "phrase": "single_gallery_sample"}, {"score": 0.00407533728096378, "phrase": "optimal_embedding"}, {"score": 0.0037421829222825964, "phrase": "local_structure"}, {"score": 0.0035792893638135976, "phrase": "lra"}, {"score": 0.0035135084960705816, "phrase": "least-square_regression_technique"}, {"score": 0.003423445743298995, "phrase": "equally_distant_locations"}, {"score": 0.003360527337581911, "phrase": "true_structure"}, {"score": 0.0032743731084995515, "phrase": "novel_generic_learning_method"}, {"score": 0.0032141856243404618, "phrase": "intraclass_facial_differences"}, {"score": 0.0031786037839399055, "phrase": "generic_faces"}, {"score": 0.0031434146012468307, "phrase": "zero_vectors"}, {"score": 0.0030628094110419697, "phrase": "generalization_capability"}, {"score": 0.003006499028632742, "phrase": "novel_method"}, {"score": 0.002929394386754424, "phrase": "generic_classes"}, {"score": 0.002875529792120695, "phrase": "face_recognition_performance"}, {"score": 0.002822652835367827, "phrase": "generic_data"}, {"score": 0.002770745509774383, "phrase": "different_database_and_camera_set-up"}, {"score": 0.002689666606553487, "phrase": "greville_algorithm"}, {"score": 0.00265987582861194, "phrase": "mapping_matrix"}, {"score": 0.0026109540617641593, "phrase": "newly_coming_gallery_classes"}, {"score": 0.002553431170229379, "phrase": "generic_variations"}, {"score": 0.0024061422012437344, "phrase": "commonly_used_local_descriptors"}, {"score": 0.002370663905320869, "phrase": "gabor_representation"}, {"score": 0.002353120949568249, "phrase": "local_binary_patterns"}, {"score": 0.00222561197623787, "phrase": "extended_yale_b"}, {"score": 0.00216045626773865, "phrase": "feret"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Face recognition", " One sample problem", " Linear regression", " Feature extraction", " Generic learning"], "paper_abstract": "We develop a parameter-free face recognition algorithm which is insensitive to large variations in lighting, expression, occlusion, and age using a single gallery sample per subject. We take advantage of the observation that equidistant prototypes embedding is an optimal embedding that maximizes the minimum one-against-the-rest margin between the classes. Rather than preserving the global or the local structure of the training data, our method, called linear regression analysis (LRA), applies a least-square regression technique to map gallery samples to the equally distant locations, regardless of the true structure of training data. Further, a novel generic learning method, which maps the intraclass facial differences of the generic faces to the zero vectors, is incorporated to enhance the generalization capability of LEA. Using this novel method, learning based on only a handful of generic classes can largely improve the face recognition performance, even when the generic data are collected from a different database and camera set-up. The incremental learning based on the Greville algorithm makes the mapping matrix efficiently updated from the newly coming gallery classes, training samples, or generic variations. Although it is fairly simple and parameter-free, LEA, combined with commonly used local descriptors, such as Gabor representation and local binary patterns, outperforms the state-of-the-art methods for several standard experiments on the Extended Yale B, CMU PIE, AR, and FERET databases. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Equidistant prototypes embedding for single sample based face recognition with generic learning and incremental learning", "paper_id": "WOS:000342870900001"}