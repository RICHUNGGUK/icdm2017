{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "immersive_virtual_reality"}, {"score": 0.004718897469501381, "phrase": "visual_information"}, {"score": 0.0043533862892678864, "phrase": "computational_method"}, {"score": 0.004295269532032448, "phrase": "fast_synthesis"}, {"score": 0.004237925318473508, "phrase": "plausible_fire_sound"}, {"score": 0.0040978781692373005, "phrase": "physically_based_fire_animations"}, {"score": 0.003704797078215222, "phrase": "high_frequency"}, {"score": 0.0033268412940032103, "phrase": "novel_combustion_sound_model"}, {"score": 0.003216804708106142, "phrase": "gpu_parallel_computing"}, {"score": 0.003152531962718477, "phrase": "marching-cube-like_manner"}, {"score": 0.0029672941061574375, "phrase": "low-frequency_part"}, {"score": 0.0027741761880779535, "phrase": "time-stepping_fire_simulation"}, {"score": 0.0027187231747900814, "phrase": "relative_low_frequency"}, {"score": 0.002646501671714952, "phrase": "audio_rate"}, {"score": 0.0025761937402886954, "phrase": "synchronized_mid-and_high-frequency_wavelet_details"}, {"score": 0.0023762535034673017, "phrase": "complete_fire_sound"}, {"score": 0.0022215160785078797, "phrase": "solid_physically_based_basis"}, {"score": 0.0021917966722180132, "phrase": "real-time_acoustic_rendering"}, {"score": 0.0021049977753042253, "phrase": "immersive_virtual_reality_scenarios"}], "paper_keywords": ["Fire sound", " Physically based simulation", " GPU", " Immersive virtual reality"], "paper_abstract": "Both visual information and sound are required in immersive virtual reality. This paper proposes a computational method for fast synthesis of plausible fire sound that is synchronized with physically based fire animations. We divide fire sound into two parts: low frequency and mid-to high frequency, and use two processes to separately synthesize these two parts. By simplifying calculations using a novel combustion sound model as well as leveraging GPU parallel computing in a marching-cube-like manner, our method speeds up the computation of low-frequency part by an order of magnitude. To run the time-stepping fire simulation at a relative low frequency rather than the audio rate, we add synchronized mid-and high-frequency wavelet details to low-frequency simulation contents with a post-process to generate complete fire sound. We validated our method with various experiments to build a solid physically based basis for real-time acoustic rendering that can be used for immersive virtual reality scenarios.", "paper_title": "Sounding fire for immersive virtual reality", "paper_id": "WOS:000363862800012"}