{"auto_keywords": [{"score": 0.03142328343288371, "phrase": "aec"}, {"score": 0.00481495049065317, "phrase": "shaped_motion_prediction"}, {"score": 0.004786315041142917, "phrase": "depth_video_compression"}, {"score": 0.004757849078050144, "phrase": "arithmetic_edge_coding"}, {"score": 0.00472955160788118, "phrase": "depth_image_compression"}, {"score": 0.004673458200854065, "phrase": "compact_representation"}, {"score": 0.00461802698572959, "phrase": "texture-plus-depth_format"}, {"score": 0.004402770481509365, "phrase": "freely_chosen_virtual_view"}, {"score": 0.004376575566619566, "phrase": "depth-image-based_rendering"}, {"score": 0.0042989181990989965, "phrase": "depth_maps"}, {"score": 0.004222632929330698, "phrase": "depth_information"}, {"score": 0.0040740829470571425, "phrase": "object_identification"}, {"score": 0.003860961077439364, "phrase": "neighboring_pixels"}, {"score": 0.003837977308651303, "phrase": "similar_depth"}, {"score": 0.0038151298350627065, "phrase": "similar_motion"}, {"score": 0.0037698405700547608, "phrase": "depth_video"}, {"score": 0.003691869399440961, "phrase": "depth_block"}, {"score": 0.003648037996175166, "phrase": "distinct_values"}, {"score": 0.00345712586265106, "phrase": "dividing_boundary"}, {"score": 0.0034262895977021854, "phrase": "separate_motion_prediction"}, {"score": 0.003256657868307919, "phrase": "residual_coding"}, {"score": 0.003160812175253167, "phrase": "dividing_boundaries"}, {"score": 0.003141983150118255, "phrase": "sub-block_identification"}, {"score": 0.0029421002892899015, "phrase": "efficiently_code_boundaries"}, {"score": 0.0028215560905969304, "phrase": "boundary_geometrical_correlation"}, {"score": 0.0027963729616768784, "phrase": "adaptive_arithmetic_coder"}, {"score": 0.002746677144043828, "phrase": "statistical_model"}, {"score": 0.002649912326113785, "phrase": "coding_performance"}, {"score": 0.0025872989069543892, "phrase": "first_procedure"}, {"score": 0.002556547771670116, "phrase": "code_block"}, {"score": 0.0025261612008752534, "phrase": "lossy_compression"}, {"score": 0.002503607929521596, "phrase": "detected_block_boundary"}, {"score": 0.0024081753091661396, "phrase": "boundary_depth_pixel_values"}, {"score": 0.00238667288163314, "phrase": "new_boundary"}, {"score": 0.0023583006329955403, "phrase": "augmented_pixels"}, {"score": 0.002323308052177842, "phrase": "synthesized_view_distortion"}, {"score": 0.002302561649365666, "phrase": "second_procedure"}, {"score": 0.002282000081594605, "phrase": "code_blocks"}, {"score": 0.0022280604516919417, "phrase": "object_contour"}, {"score": 0.002188442250414479, "phrase": "sub-block_mp"}, {"score": 0.0021688975382614366, "phrase": "rate-distortion_optimized_trellis"}, {"score": 0.0021303290947326517, "phrase": "average_overall_bitrate_reduction"}], "paper_keywords": ["Depth map", " adaptive coding", " video coding"], "paper_abstract": "Depth image compression is important for compact representation of 3D visual data in texture-plus-depth format, where texture and depth maps from one or more viewpoints are encoded and transmitted. A decoder can then synthesize a freely chosen virtual view via depth-image-based rendering using nearby coded texture and depth maps as reference. Further, depth information can be used in other image processing applications beyond view synthesis, such as object identification, segmentation, and so on. In this paper, we leverage on the observation that neighboring pixels of similar depth have similar motion to efficiently encode depth video. Specifically, we divide a depth block containing two zones of distinct values (e. g., foreground and background) into two arbitrarily shaped regions (sub-blocks) along the dividing boundary before performing separate motion prediction (MP). While such arbitrarily shaped sub-block MP can lead to very small prediction residuals (resulting in few bits required for residual coding), it incurs an overhead to transmit the dividing boundaries for sub-block identification at decoder. To minimize this overhead, we first devise a scheme called arithmetic edge coding (AEC) to efficiently code boundaries that divide blocks into sub-blocks. Specifically, we propose to incorporate the boundary geometrical correlation in an adaptive arithmetic coder in the form of a statistical model. Then, we propose two optimization procedures to further improve the edge coding performance of AEC for a given depth image. The first procedure operates within a code block, and allows lossy compression of the detected block boundary to lower the cost of AEC, with an option to augment boundary depth pixel values matching the new boundary, given the augmented pixels do not adversely affect synthesized view distortion. The second procedure operates across code blocks, and systematically identifies blocks along an object contour that should be coded using sub-block MP via a rate-distortion optimized trellis. Experimental results show an average overall bitrate reduction of up to 33% over classical H.264/AVC.", "paper_title": "Arbitrarily Shaped Motion Prediction for Depth Video Compression Using Arithmetic Edge Coding", "paper_id": "WOS:000346054700004"}