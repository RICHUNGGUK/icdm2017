{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "audio_and_multimodal_interactions"}, {"score": 0.0047057084749407485, "phrase": "health_smart_home"}, {"score": 0.004634254474150777, "phrase": "health_smart_homes"}, {"score": 0.0036274201504044685, "phrase": "cheap_and_efficient_sensors"}, {"score": 0.003018196463874475, "phrase": "real_data"}, {"score": 0.0027529929913806066, "phrase": "fully_equipped_health_smart_home"}, {"score": 0.0026091594819333654, "phrase": "distress_detection"}, {"score": 0.0022211005680689666, "phrase": "seven_activities"}, {"score": 0.0021872912745910127, "phrase": "daily_living"}, {"score": 0.0021049977753042253, "phrase": "multimodal_data"}], "paper_keywords": ["Health smart home", " Environmental sensors", " Audio and speech analysis", " Activity monitoring", " Activity recognition"], "paper_abstract": "Health Smart Homes are nowadays a very explored research area due to the needs for automation and telemedicine to support people in loss of autonomy and also due to the evolution of the technology that led in cheap and efficient sensors. However, collecting data in this area is still very challenging. As a consequence, many studies cannot be validated on real data. In this paper, we present two realistic datasets acquired in a fully equipped Health Smart Home. The first is related to distress detection from speech (450 recorded sentences) and involved 10 participants, the second involved 15 participants who were performing several instances of seven activities of daily living (16 h of multimodal data).", "paper_title": "A french corpus of audio and multimodal interactions in a health smart home", "paper_id": "WOS:000316062300009"}