{"auto_keywords": [{"score": 0.04401349045433906, "phrase": "ga"}, {"score": 0.010539145321133186, "phrase": "data_fusion"}, {"score": 0.005145261145929795, "phrase": "similar_runs"}, {"score": 0.00481495049065317, "phrase": "combination_weights"}, {"score": 0.004748832495727873, "phrase": "genetic_algorithms"}, {"score": 0.0046352930395962685, "phrase": "weighted_linear_combination"}, {"score": 0.00455585162011571, "phrase": "better_results"}, {"score": 0.0045088388224419, "phrase": "unweighted_combination"}, {"score": 0.0043706785731816265, "phrase": "linear_combination_weights"}, {"score": 0.0036764506727132253, "phrase": "information_retrieval"}, {"score": 0.003551392586900308, "phrase": "optimum_fusion_weights"}, {"score": 0.0035147084172295123, "phrase": "entire_set"}, {"score": 0.003490462324829042, "phrase": "relevance_assessment"}, {"score": 0.0033717094055177995, "phrase": "relevance_assessments"}, {"score": 0.0031789986177545586, "phrase": "twofold_training"}, {"score": 0.0030180996912267683, "phrase": "trec."}, {"score": 0.0028852371404397862, "phrase": "significant_improvements"}, {"score": 0.0028554143163813947, "phrase": "best_candidate_run"}, {"score": 0.002835703398546821, "phrase": "combsum"}, {"score": 0.0027108484507501907, "phrase": "multiple_linear_regression-based_weight_learning_scheme"}, {"score": 0.0026367554281038572, "phrase": "lambdamerge"}, {"score": 0.0024347998826121497, "phrase": "redundant_runs"}, {"score": 0.0023114798074455453, "phrase": "similar_contributions"}, {"score": 0.0021716944668428865, "phrase": "fusion_performance"}, {"score": 0.002149231173009159, "phrase": "significant_way"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Information retrieval", " Data fusion", " Linear combination", " Genetic Algorithms"], "paper_abstract": "Researchers have shown that a weighted linear combination in data fusion can produce better results than an unweighted combination. Many techniques have been used to determine the linear combination weights. In this work, we have used the Genetic Algorithm (GA) for the same purpose. The GA is not new and it has been used earlier in several other applications. But, to the best of our knowledge, the GA has not been used for fusion of runs in information retrieval. First, we use GA to learn the optimum fusion weights using the entire set of relevance assessment. Next, we learn the weights from the relevance assessments of the top retrieved documents only. Finally, we also learn the weights by a twofold training and testing on the queries. We test our method on the runs submitted in TREC. We see that our weight learning scheme, using both full and partial sets of relevance assessment, produces significant improvements over the best candidate run, CombSUM, CombMNZ, Z-Score, linear combination method with performance level, performance level square weighting scheme, multiple linear regression-based weight learning scheme, mixture model result merging scheme, LambdaMerge, ClustFuseCombSUM and ClustFuseCombMNZ. Furthermore, we study how the correlation among the scores in the runs can be used to eliminate redundant runs in a set of runs to be fused. We observe that similar runs have similar contributions in fusion. So, eliminating the redundant runs in a group of similar runs does not hurt fusion performance in any significant way. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Learning combination weights in data fusion using Genetic Algorithms", "paper_id": "WOS:000351791700006"}