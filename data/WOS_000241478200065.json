{"auto_keywords": [{"score": 0.03748443929333412, "phrase": "wavelet_trees"}, {"score": 0.00481495049065317, "phrase": "bwt_compression"}, {"score": 0.004780926543714981, "phrase": "data_compression"}, {"score": 0.004647206916983993, "phrase": "algorithm_design"}, {"score": 0.0045012241233855065, "phrase": "burrows"}, {"score": 0.004469400468609653, "phrase": "wheeler_compression"}, {"score": 0.004267978415344142, "phrase": "compressed_indexes"}, {"score": 0.004192937957960497, "phrase": "considerable_debate"}, {"score": 0.004090083576606688, "phrase": "compression_algorithms"}, {"score": 0.004032441847334232, "phrase": "bwt_paradigm"}, {"score": 0.003905689096176873, "phrase": "front_encoding"}, {"score": 0.0038098540814166695, "phrase": "\"inefficient\"_part"}, {"score": 0.00376950244909, "phrase": "burrows-wheeler_compression_process"}, {"score": 0.0035867530188337933, "phrase": "compression_boosting"}, {"score": 0.0035236476185949565, "phrase": "main_contribution"}, {"score": 0.003424972304865554, "phrase": "first_experimental_comparison"}, {"score": 0.0033054920459613018, "phrase": "current_debate"}, {"score": 0.003212906206685001, "phrase": "carefully_engineered_compression"}, {"score": 0.0030462191741660346, "phrase": "myriad_new_compression_algorithms"}, {"score": 0.0028779128559032956, "phrase": "first_experimental_assessment"}, {"score": 0.002738269813657276, "phrase": "main_conclusion"}, {"score": 0.0026146595609362715, "phrase": "quite_close_compression_performance"}, {"score": 0.0025055037815033725, "phrase": "new_fact"}, {"score": 0.0024094425220967273, "phrase": "fast_adapting_order-zero_compressor"}, {"score": 0.002341895788806396, "phrase": "art_bwt_compression"}, {"score": 0.0023006418600072325, "phrase": "run_length"}, {"score": 0.0021049977753042253, "phrase": "fast_learner"}], "paper_keywords": [""], "paper_abstract": "Data Compression is one of the most challenging arenas both for algorithm design and engineering. This is particularly true for Burrows and Wheeler Compression a technique that is important in itself and for the design of compressed indexes. There has been considerable debate on how to design and engineer compression algorithms based on the BWT paradigm. In particular; Move-to-Front Encoding is generally believed to be an \"inefficient\" part of the Burrows-Wheeler compression process. However, only recently two theoretically superior alternatives to Move-to-Front have been proposed, namely Compression Boosting and Wavelet Trees. The main contribution of this paper is to provide the first experimental comparison of these three techniques, giving a much needed methodological contribution to the current debate. We do so by providing a carefully engineered compression boosting library that can be used, on the one hand, to investigate the myriad new compression algorithms that can be based on boosting, and on the other hand, to make the first experimental assessment of how Move-to-Front behaves with respect to its recently proposed competitors. The main conclusion is that Boosting, Wavelet Trees and Move-to-Front yield quite close compression performance. Finally, our extensive experimental study of boosting technique brings to light a new fact overlooked in 10 years of experiments in the area: a fast adapting order-zero compressor is enough to provide state of the art BWT compression by simply compressing the run length encoded transform. In other words, Move-to-Front, Wavelet Trees, and Boosters can all be by-passed by a fast learner.", "paper_title": "The engineering of a compression boosting library: Theory vs practice in BWT compression", "paper_id": "WOS:000241478200065"}