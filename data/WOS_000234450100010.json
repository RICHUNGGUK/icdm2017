{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "online_exchanges"}, {"score": 0.004267468074128779, "phrase": "reverse_auctions"}, {"score": 0.004036141321779216, "phrase": "seller_pricing_behavior"}, {"score": 0.003888905257972882, "phrase": "mixed-strategy_equilibria"}, {"score": 0.0037820003983334476, "phrase": "real_life"}, {"score": 0.0034785371344994197, "phrase": "complex_ideal_behavior"}, {"score": 0.0032593915869553714, "phrase": "two-seller_game"}, {"score": 0.0031697368057340895, "phrase": "synthetic_environment"}, {"score": 0.002997735656669146, "phrase": "reinforcement_learning"}, {"score": 0.0024658019116387845, "phrase": "theoretical_nash_equilibrium"}, {"score": 0.0022052711621931144, "phrase": "artificial_learning_mechanisms"}, {"score": 0.002164602220179823, "phrase": "electronic_marketplace_transactions"}], "paper_keywords": ["B2B marketplaces", " reinforcement learning", " experimental economics", " game theory", " mixed-strategy equilibrium"], "paper_abstract": "Business-to-business (B2B) exchanges are expected to bring about lower prices for buyers through reverse auctions. Analysis of such settings for seller pricing behavior often points to mixed-strategy equilibria. In real life, it is plausible that managers learn this complex ideal behavior over time. We modeled the two-seller game in a synthetic environment, where two agents use a reinforcement learning (RL) algorithm to change their pricing strategy over time. We find that the agents do indeed converge towards the theoretical Nash equilibrium. The results are promising enough to consider the use of artificial learning mechanisms in electronic marketplace transactions. (c) 2004 Elsevier B.V. All rights reserved.", "paper_title": "Simulating sellers in online exchanges", "paper_id": "WOS:000234450100010"}