{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "term_frequency"}, {"score": 0.010526856153452762, "phrase": "text_categorization"}, {"score": 0.009360676011535986, "phrase": "document_frequency"}, {"score": 0.00828891761883307, "phrase": "low-frequency_terms"}, {"score": 0.004737201825299411, "phrase": "feature_selection_techniques"}, {"score": 0.0046797114400479135, "phrase": "important_role"}, {"score": 0.004493045859210086, "phrase": "largescale_tc_tasks"}, {"score": 0.004158563941891469, "phrase": "famous_chi-square_statistic"}, {"score": 0.0032967724149749853, "phrase": "high-frequency_term"}, {"score": 0.003076052206618737, "phrase": "real-life_corpus"}, {"score": 0.002881793492919646, "phrase": "feature_selection_function"}, {"score": 0.0027893011631269873, "phrase": "new_approach"}, {"score": 0.0027666443986705453, "phrase": "student_t-test"}, {"score": 0.0027330029055210926, "phrase": "t-test_function"}, {"score": 0.002570817338292482, "phrase": "specific_category"}, {"score": 0.002539550974361945, "phrase": "entire_corpus"}, {"score": 0.0025189177411152645, "phrase": "extensive_comparative_experiments"}, {"score": 0.002438043578514396, "phrase": "proposed_approach"}, {"score": 0.002388817995161952, "phrase": "state-of-the-art_feature_selection_methods"}, {"score": 0.0022378620428620782, "phrase": "slightly_better_performance"}, {"score": 0.0022196753855386353, "phrase": "reuters"}], "paper_keywords": ["Feature selection", " Term frequency", " Student t-test", " Text classification"], "paper_abstract": "Feature selection techniques play an important role in text categorization (TC), especially for the largescale TC tasks. Many new and improved methods have been proposed, and most of them are based on document frequency, such as the famous Chi-square statistic and information gain etc. These methods based on document frequency, however, have two shortcomings: (1) they are not reliable for low-frequency terms, that is, low-frequency terms will be filtered because of their smaller weights; and (2) they only count whether one term occurs within a document and ignore term frequency. Actually, high-frequency term (except stop words) occurred in few documents is often regards as a discriminators in the real-life corpus. Aimed at solving the above drawbacks, the paper focuses on how to construct a feature selection function based on term frequency, and proposes a new approach using student t-test. The t-test function is used to measure the diversity of the distributions of a term frequency between the specific category and the entire corpus. Extensive comparative experiments on two text corpora using three classifiers show that the proposed approach is comparable to the state-of-the-art feature selection methods in terms of macro-F1 and micro-F1. Especially on micro-F1, our method achieves slightly better performance on Reuters with kNN and SVMs classifiers, compared to x(2), and IG. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "t-Test feature selection approach based on term frequency for text categorization", "paper_id": "WOS:000337219200001"}