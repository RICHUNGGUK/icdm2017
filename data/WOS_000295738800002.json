{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "sum-rate_loss"}, {"score": 0.015583657937346082, "phrase": "quadratic_gaussian_multiterminal_source_coding"}, {"score": 0.012979996599875806, "phrase": "nondegraded_assumption"}, {"score": 0.011792559978899428, "phrase": "joint_encoding"}, {"score": 0.009645792037901163, "phrase": "minimum_sum-rate"}, {"score": 0.004448705308279165, "phrase": "minimum_sum-rates"}, {"score": 0.004257360656055417, "phrase": "joint_decoding"}, {"score": 0.004201571673071299, "phrase": "correlated_gaussian_sources"}, {"score": 0.004146510711518748, "phrase": "mse_distortion_constraints"}, {"score": 0.0041102032028337366, "phrase": "individual_sources"}, {"score": 0.0038818006513785977, "phrase": "target_distortions"}, {"score": 0.003780692127133743, "phrase": "gaussian_berger-tung_scheme"}, {"score": 0.003540569023962758, "phrase": "gaussian"}, {"score": 0.0033277936960179892, "phrase": "asymptotic_slope"}, {"score": 0.002981026404927824, "phrase": "full_knowledge"}, {"score": 0.002903311792572216, "phrase": "distributed_encoding_case"}, {"score": 0.0028652153774536967, "phrase": "main_idea"}, {"score": 0.0028276174348291923, "phrase": "upper-bound_the_minimum_sum-rate"}, {"score": 0.002717750004930131, "phrase": "parallel_gaussian_test_channels"}, {"score": 0.0025778546800417808, "phrase": "reverse_water-filling_solution"}, {"score": 0.002544017922741882, "phrase": "relaxed_joint_encoding_problem"}, {"score": 0.002488604965680912, "phrase": "gaussian_sources"}, {"score": 0.0024559368099486647, "phrase": "sum-distortion_constraint"}, {"score": 0.0023708980662168525, "phrase": "individual_target_distortions"}, {"score": 0.002258745901862197, "phrase": "supremum_difference"}, {"score": 0.0022290883852844057, "phrase": "upper_bound"}, {"score": 0.0022095328812245852, "phrase": "distributed_encoding"}, {"score": 0.0021049977753042253, "phrase": "bi-eigen_equal-variance"}], "paper_keywords": ["Bi-eigen equal-variance with equal distortion", " joint encoding", " quadratic Gaussian multiterminal source coding", " reverse water-filling", " sum-rate", " supremum sum-rate loss"], "paper_abstract": "This work studies the sum-rate loss of quadratic Gaussian multiterminal source coding, i.e., the difference between the minimum sum-rates of distributed encoding and joint encoding (both with joint decoding) of correlated Gaussian sources subject to MSE distortion constraints on individual sources. It is shown that under the nondegraded assumption, i.e., all target distortions are simultaneously achievable by a Gaussian Berger-Tung scheme, the supremum of the sum-rate loss of distributed encoding over joint encoding of L jointly Gaussian sources increases almost linearly in the number of sources L, with an asymptotic slope of 0.1083 bit per sample per source as L goes to infinity. This result is obtained even though we currently do not have the full knowledge of the minimum sum-rate for the distributed encoding case. The main idea is to upper-bound the minimum sum-rate of multiterminal source coding by that achieved by parallel Gaussian test channels while lower-bounding the minimum sum-rate of joint encoding by a reverse water-filling solution to a relaxed joint encoding problem of the same set of Gaussian sources with a sum-distortion constraint (that equals the sum of the individual target distortions). We show that under the nondegraded assumption, the supremum difference between the upper bound for distributed encoding and the lower bound for joint encoding is achieved in the bi-eigen equal-variance with equal distortion case, in which both bounds are known to be tight.", "paper_title": "On the Sum-Rate Loss of Quadratic Gaussian Multiterminal Source Coding", "paper_id": "WOS:000295738800002"}