{"auto_keywords": [{"score": 0.039754322867329286, "phrase": "convergence_rate"}, {"score": 0.028291676544600766, "phrase": "sai_preconditioner"}, {"score": 0.025541735950978393, "phrase": "parasails"}, {"score": 0.00481495049065317, "phrase": "sparse_approximate_inverse_preconditioning"}, {"score": 0.004764859786310636, "phrase": "graphic_processing_units"}, {"score": 0.004690694501758065, "phrase": "numerical_algorithms"}, {"score": 0.0046176782475198085, "phrase": "sparse_linear_systems"}, {"score": 0.004569630374630379, "phrase": "parallel_architectures"}, {"score": 0.004202741104973709, "phrase": "sparse_systems"}, {"score": 0.004115697805448384, "phrase": "overall_execution_time"}, {"score": 0.003946960862020283, "phrase": "iterative_methods"}, {"score": 0.0036489343475053187, "phrase": "total_execution_time"}, {"score": 0.003536103262313136, "phrase": "sai"}, {"score": 0.003444732262403694, "phrase": "popular_class"}, {"score": 0.003320756562046789, "phrase": "condition_number"}, {"score": 0.0032861588691414667, "phrase": "large_sparse_matrices"}, {"score": 0.003201472192208642, "phrase": "gpu"}, {"score": 0.0031678720736808574, "phrase": "sai_preconditioning_technique"}, {"score": 0.0031348622158167195, "phrase": "gsai"}, {"score": 0.002974886152979993, "phrase": "nvidia_graphic_cards"}, {"score": 0.0027790254309734428, "phrase": "biconjugate_gradient_stabilized"}, {"score": 0.0026930643521432137, "phrase": "gpu."}, {"score": 0.0023254633298356894, "phrase": "sai_preconditioners"}, {"score": 0.0023013250204984618, "phrase": "cpu"}, {"score": 0.002241679436497571, "phrase": "proposed_gsai_technique"}, {"score": 0.002183684303511462, "phrase": "approximately_the_same_time"}], "paper_keywords": ["Numerical algorithms", " parallel algorithms", " graphics processors", " parallel programming", " conditioning"], "paper_abstract": "Accelerating numerical algorithms for solving sparse linear systems on parallel architectures has attracted the attention of many researchers due to their applicability to many engineering and scientific problems. The solution of sparse systems often dominates the overall execution time of such problems and is mainly solved by iterative methods. Preconditioners are used to accelerate the convergence rate of these solvers and reduce the total execution time. Sparse approximate inverse (SAI) preconditioners are a popular class of preconditioners designed to improve the condition number of large sparse matrices. We propose a GPU accelerated SAI preconditioning technique called GSAI, which parallelizes the computation of this preconditioner on NVIDIA graphic cards. The preconditioner is then used to enhance the convergence rate of the BiConjugate Gradient Stabilized (BiCGStab) iterative solver on the GPU. The SAI preconditioner is generated on average 28 and 23 times faster on the NVIDIA GTX480 and TESLA M2070 graphic cards, respectively, compared to ParaSails (a popular implementation of SAI preconditioners on CPU) single processor/core results. The proposed GSAI technique computes the SAI preconditioner in approximately the same time as ParaSails generates the same preconditioner on 16 AMD Opteron 252 processors.", "paper_title": "Parallel Sparse Approximate Inverse Preconditioning on Graphic Processing Units", "paper_id": "WOS:000322516200014"}