{"auto_keywords": [{"score": 0.02747173684490633, "phrase": "consistent_hashing"}, {"score": 0.00481495049065317, "phrase": "scalable_self-tuning"}, {"score": 0.004712065638657606, "phrase": "distributed_key-value_stores"}, {"score": 0.00441635700580562, "phrase": "data_placement"}, {"score": 0.00436890075128947, "phrase": "replicated_key-value_stores"}, {"score": 0.0041840994704406866, "phrase": "replica_placement"}, {"score": 0.004050625770007516, "phrase": "locality_patterns"}, {"score": 0.004007083686875716, "phrase": "data_accesses"}, {"score": 0.003921393143378986, "phrase": "internode_communication"}, {"score": 0.0035386420095120706, "phrase": "lightweight_and_scalable_ways"}, {"score": 0.0034629341517018438, "phrase": "right_assignment"}, {"score": 0.00342568771304873, "phrase": "data_replicas"}, {"score": 0.003298441494378465, "phrase": "fast_data_lookup"}, {"score": 0.003210446135114967, "phrase": "new_techniques"}, {"score": 0.0030911702059432224, "phrase": "first_challenge"}, {"score": 0.0029602552900111407, "phrase": "decentralized_way"}, {"score": 0.0028195727965553367, "phrase": "largest_number"}, {"score": 0.002789226820897593, "phrase": "remote_operations"}, {"score": 0.0027001292153471202, "phrase": "second_challenge"}, {"score": 0.0025440911575156755, "phrase": "novel_data_structure"}, {"score": 0.0024896081630179194, "phrase": "efficient_probabilistic_data_placement"}, {"score": 0.0023712394008737958, "phrase": "popular_open-source_key-value_store"}, {"score": 0.002234165013865669, "phrase": "optimized_system"}, {"score": 0.0021394674440767124, "phrase": "baseline_system"}, {"score": 0.0021049977753042253, "phrase": "widely_used_static_placement"}], "paper_keywords": ["Performance", " Distributed data management", " data placement", " probabilistic algorithms", " machine learning"], "paper_abstract": "This article addresses the problem of self-tuning the data placement in replicated key-value stores. The goal is to automatically optimize replica placement in a way that leverages locality patterns in data accesses, such that internode communication is minimized. To do this efficiently is extremely challenging, as one needs not only to find lightweight and scalable ways to identify the right assignment of data replicas to nodes but also to preserve fast data lookup. The article introduces new techniques that address these challenges. The first challenge is addressed by optimizing, in a decentralized way, the placement of the objects generating the largest number of remote operations for each node. The second challenge is addressed by combining the usage of consistent hashing with a novel data structure, which provides efficient probabilistic data placement. These techniques have been integrated in a popular open-source key-value store. The performance results show that the throughput of the optimized system can be six times better than a baseline system employing the widely used static placement based on consistent hashing.", "paper_title": "AUTOPLACER: Scalable Self-Tuning Data Placement in Distributed Key-Value Stores", "paper_id": "WOS:000348362200003"}