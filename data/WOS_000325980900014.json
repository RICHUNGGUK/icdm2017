{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "quantized_kernel"}, {"score": 0.004481132747216135, "phrase": "recent_paper"}, {"score": 0.004284302478991387, "phrase": "novel_quantized_kernel"}, {"score": 0.0041703614123283165, "phrase": "square_algorithm"}, {"score": 0.003987126862293129, "phrase": "input_space"}, {"score": 0.003777800904236079, "phrase": "smaller_regions"}, {"score": 0.0036443694410100507, "phrase": "network_size"}, {"score": 0.0034529760173586583, "phrase": "quantization_codebook_size"}, {"score": 0.0028076592725295646, "phrase": "optimal_solution"}, {"score": 0.0026841368358805407, "phrase": "simple_online_vector_quantization_method"}, {"score": 0.0025660347613972573, "phrase": "recursive_algorithm"}, {"score": 0.0022419349154472806, "phrase": "good_performance"}, {"score": 0.0021821915946356168, "phrase": "new_algorithm"}, {"score": 0.0021049977753042253, "phrase": "monte_carlo_simulations"}], "paper_keywords": ["Kernel recursive least squares (KRLS)", " quantization", " quantized kernel recursive least squares (QKRLS)", " sparsification"], "paper_abstract": "In a recent paper, we developed a novel quantized kernel least mean square algorithm, in which the input space is quantized (partitioned into smaller regions) and the network size is upper bounded by the quantization codebook size (number of the regions). In this brief, we propose the quantized kernel least squares regression, and derive the optimal solution. By incorporating a simple online vector quantization method, we derive a recursive algorithm to update the solution, namely the quantized kernel recursive least squares algorithm. The good performance of the new algorithm is demonstrated by Monte Carlo simulations.", "paper_title": "Quantized Kernel Recursive Least Squares Algorithm", "paper_id": "WOS:000325980900014"}