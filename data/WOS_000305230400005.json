{"auto_keywords": [{"score": 0.049303832954618126, "phrase": "multi-label_classification"}, {"score": 0.048540508174724384, "phrase": "data_point"}, {"score": 0.03600918903432029, "phrase": "prior_label_correlations"}, {"score": 0.00481495049065317, "phrase": "zero-shot_learning"}, {"score": 0.004584769330512473, "phrase": "relevant_labels"}, {"score": 0.004540064673326908, "phrase": "pre-specified_set"}, {"score": 0.00445195298244008, "phrase": "l_labels"}, {"score": 0.004143196873246147, "phrase": "exponentially_large_label_space"}, {"score": 0.003945001936004421, "phrase": "efficient_algorithms"}, {"score": 0.0037195959056754444, "phrase": "zero-shot_learning_scenario"}, {"score": 0.003518508991483203, "phrase": "test_set"}, {"score": 0.003461454328850212, "phrase": "max-margin_formulation"}, {"score": 0.003361069456060196, "phrase": "pairwise_label_interaction_terms"}, {"score": 0.0033282568196683886, "phrase": "prediction_function"}, {"score": 0.003263586288720322, "phrase": "problem_complexity"}, {"score": 0.0031585736196310726, "phrase": "dense_pairwise"}, {"score": 0.003107337317471694, "phrase": "relevant_correlation_priors"}, {"score": 0.0030369955065974222, "phrase": "training_and_test_set_statistics"}, {"score": 0.0029200834042804333, "phrase": "principled_interpretation"}, {"score": 0.00285396838599055, "phrase": "efficient_optimisation_algorithms"}, {"score": 0.0026297965957221554, "phrase": "training_time"}, {"score": 0.0024391051991149663, "phrase": "kernel_cache"}, {"score": 0.0022109570100232352, "phrase": "specialised_algorithm"}, {"score": 0.002196527318006187, "phrase": "linear_kernels"}, {"score": 0.002175058780645677, "phrase": "dual_co-ordinate_ascent"}, {"score": 0.0021049977753042253, "phrase": "million_points"}], "paper_keywords": ["Multi-label classification", " Zero-shot learning", " Max-margin methods", " SMO optimization", " 1-vs-all classification"], "paper_abstract": "The goal in multi-label classification is to tag a data point with the subset of relevant labels from a pre-specified set. Given a set of L labels, a data point can be tagged with any of the 2 (L) possible subsets. The main challenge therefore lies in optimising over this exponentially large label space subject to label correlations. Our objective, in this paper, is to design efficient algorithms for multi-label classification when the labels are densely correlated. In particular, we are interested in the zero-shot learning scenario where the label correlations on the training set might be significantly different from those on the test set. We propose a max-margin formulation where we model prior label correlations but do not incorporate pairwise label interaction terms in the prediction function. We show that the problem complexity can be reduced from exponential to linear while modelling dense pairwise prior label correlations. By incorporating relevant correlation priors we can handle mismatches between the training and test set statistics. Our proposed formulation generalises the effective 1-vs-All method and we provide a principled interpretation of the 1-vs-All technique. We develop efficient optimisation algorithms for our proposed formulation. We adapt the Sequential Minimal Optimisation (SMO) algorithm to multi-label classification and show that, with some book-keeping, we can reduce the training time from being super-quadratic to almost linear in the number of labels. Furthermore, by effectively re-utilizing the kernel cache and jointly optimising over all variables, we can be orders of magnitude faster than the competing state-of-the-art algorithms. We also design a specialised algorithm for linear kernels based on dual co-ordinate ascent with shrinkage that lets us effortlessly train on a million points with a hundred labels.", "paper_title": "Efficient max-margin multi-label classification with applications to zero-shot learning", "paper_id": "WOS:000305230400005"}