{"auto_keywords": [{"score": 0.049324540543845156, "phrase": "multiple_views"}, {"score": 0.00481495049065317, "phrase": "different_domain_data"}, {"score": 0.004447201233380302, "phrase": "data_mining"}, {"score": 0.004042635935882651, "phrase": "training_data"}, {"score": 0.002988101395789399, "phrase": "multi-view_information"}, {"score": 0.0028715299874549245, "phrase": "knowledge_transfer"}, {"score": 0.0027594936602962075, "phrase": "novel_transfer_learning_model"}, {"score": 0.00267301171407926, "phrase": "domain_distance"}, {"score": 0.002316105585203396, "phrase": "optimal_feature_mapping"}, {"score": 0.002190519728921395, "phrase": "classification_margin"}], "paper_keywords": ["Transfer learning", " Multi-view learning", " Domain distance", " View consistency", " Support vector machine"], "paper_abstract": "In many real-world applications in the areas of data mining, the distributions of testing data are different from that of training data. And on the other hand, many data are often represented by multiple views which are of importance to learning. However, little work has been done for it. In this paper, we explored to leverage the multi-view information across different domains for knowledge transfer. We proposed a novel transfer learning model which integrates the domain distance and view consistency into a 2-view support vector machine framework, namely DV2S. The objective of DV2S is to find the optimal feature mapping such that under the projections the classification margin is maximized, while both the domain distance and the disagreement between multiple views are minimized simultaneously. Experiments showed that DV2S outperforms a variety of state-of-the-art algorithms.", "paper_title": "Knowledge transfer across different domain data with multiple views", "paper_id": "WOS:000338191300002"}