{"auto_keywords": [{"score": 0.04733190377720633, "phrase": "external_assessors"}, {"score": 0.04153021766515564, "phrase": "searcher's_actual_intent"}, {"score": 0.039061505171951075, "phrase": "interassessor_agreement"}, {"score": 0.00481495049065317, "phrase": "query_intent_assessments"}, {"score": 0.004664352260912174, "phrase": "query_intent"}, {"score": 0.004201774694043468, "phrase": "better_understanding"}, {"score": 0.0037848978618663684, "phrase": "query_intent_annotation_process"}, {"score": 0.00297454367746853, "phrase": "seven_dimensions"}, {"score": 0.0028422946420821075, "phrase": "query_annotation"}, {"score": 0.0027035833504191233, "phrase": "spatial_sensitivity_dimension"}, {"score": 0.0026188490199688013, "phrase": "searcher's_annotations"}, {"score": 0.0025137856138000014, "phrase": "assessor-searcher_agreement"}, {"score": 0.0023372808856170386, "phrase": "good_estimator"}, {"score": 0.0022743274702883456, "phrase": "intent_classifications"}, {"score": 0.002203016940021265, "phrase": "research_community"}, {"score": 0.0021632743048552536, "phrase": "query_intent_classifications"}, {"score": 0.0021049977753042253, "phrase": "test_data"}], "paper_keywords": [""], "paper_abstract": "In most intent recognition studies, annotations of query intent are created post hoc by external assessors who are not the searchers themselves. It is important for the field to get a better understanding of the quality of this process as an approximation for determining the searcher's actual intent. Some studies have investigated the reliability of the query intent annotation process by measuring the interassessor agreement. However, these studies did not measure the validity of the judgments, that is, to what extent the annotations match the searcher's actual intent. In this study, we asked both the searchers themselves and external assessors to classify queries using the same intent classification scheme. We show that of the seven dimensions in our intent classification scheme, four can reliably be used for query annotation. Of these four, only the annotations on the topic and spatial sensitivity dimension are valid when compared with the searcher's annotations. The difference between the interassessor agreement and the assessor-searcher agreement was significant on all dimensions, showing that the agreement between external assessors is not a good estimator of the validity of the intent classifications. Therefore, we encourage the research community to consider using query intent classifications by the searchers themselves as test data.", "paper_title": "Reliability and Validity of Query Intent Assessments", "paper_id": "WOS:000328743400004"}