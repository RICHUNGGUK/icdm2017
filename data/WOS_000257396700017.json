{"auto_keywords": [{"score": 0.039763904214538855, "phrase": "memory_consumption"}, {"score": 0.03180746519800056, "phrase": "mtk"}, {"score": 0.01541561245947513, "phrase": "memory_constraint"}, {"score": 0.012759194315527715, "phrase": "frequent_itemsets"}, {"score": 0.009790028539058217, "phrase": "mtk_close"}, {"score": 0.00481495049065317, "phrase": "top-k_frequent_patterns"}, {"score": 0.00459809245936039, "phrase": "practicably_interesting_mining_task"}, {"score": 0.004193115761705178, "phrase": "mining_efficiency"}, {"score": 0.004124630249202334, "phrase": "memory_size"}, {"score": 0.0040975489787831955, "phrase": "best_effort"}, {"score": 0.003990983268804689, "phrase": "available_upper_memory_size"}, {"score": 0.0038236703468417215, "phrase": "upper_bound"}, {"score": 0.0034866619130264048, "phrase": "subtle_minimum_support"}, {"score": 0.003076152130543236, "phrase": "top-k_itemsets"}, {"score": 0.00294707794932759, "phrase": "level-wise_search_algorithms"}, {"score": 0.002804842518176471, "phrase": "database_scan"}, {"score": 0.0027498840401059418, "phrase": "novel_search_approach"}, {"score": 0.0025913692304671675, "phrase": "available_memory"}, {"score": 0.002565850749422255, "phrase": "candidate_itemsets"}, {"score": 0.0024990202385797252, "phrase": "small_number"}, {"score": 0.002482585701725093, "phrase": "required_database_scans"}, {"score": 0.002433926157079375, "phrase": "empirical_study"}, {"score": 0.0024179186667595436, "phrase": "real_data"}, {"score": 0.002402016201299179, "phrase": "synthetic_data"}, {"score": 0.002293582591899972, "phrase": "execution_efficiency"}, {"score": 0.0022118223311537954, "phrase": "high_efficiency"}, {"score": 0.002182817892930808, "phrase": "constrained_memory"}, {"score": 0.0021470954708827125, "phrase": "prominent_advantage"}, {"score": 0.002125942645854997, "phrase": "practical_algorithms"}, {"score": 0.0021049977753042253, "phrase": "frequent_patterns"}], "paper_keywords": [""], "paper_abstract": "We explore in this paper a practicably interesting mining task to retrieve top-k (closed) itemsets in the presence of the memory constraint. Specifically, as opposed to most previous works that concentrate on improving the mining efficiency or on reducing the memory size by best effort, we first attempt to specify the available upper memory size that can be utilized by mining frequent itemsets. To comply with the upper bound of the memory consumption, two efficient algorithms, called MTK and MTK_Close, are devised for mining frequent itemsets and closed itemsets, respectively, without specifying the subtle minimum support. Instead, users only need to give a more human-understandable parameter, namely the desired number of frequent (closed) itemsets k. In practice, it is quite challenging to constrain the memory consumption while also efficiently retrieving top-k itemsets. To effectively achieve this, MTK and MTK_Close are devised as level-wise search algorithms, where the number of candidates being generated-and-tested in each database scan will be limited. A novel search approach, called delta-stair search, is utilized in MTK and MTK_Close to effectively assign the available memory for testing candidate itemsets with various itemset-lengths, which leads to a small number of required database scans. As demonstrated in the empirical study on real data and synthetic data, instead of only providing the flexibility of striking a compromise between the execution efficiency and the memory consumption, MTK and MTK_Close can both achieve high efficiency and have a constrained memory bound, showing the prominent advantage to be practical algorithms of mining frequent patterns.", "paper_title": "Mining top-k frequent patterns in the presence of the memory constraint", "paper_id": "WOS:000257396700017"}