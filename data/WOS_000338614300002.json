{"auto_keywords": [{"score": 0.045526138066185134, "phrase": "gpu"}, {"score": 0.00481495049065317, "phrase": "cache_locality"}, {"score": 0.0047588556219929756, "phrase": "gpu-based_volume"}, {"score": 0.004594443767709888, "phrase": "cache-aware_method"}, {"score": 0.0045143706249204905, "phrase": "texture-based_volume"}, {"score": 0.00440976345264104, "phrase": "graphics_processing_unit"}, {"score": 0.004183137595671171, "phrase": "hierarchical_architecture"}, {"score": 0.00408617426304956, "phrase": "processing_and_memory_units"}, {"score": 0.0038534477978822133, "phrase": "memory-intensive_applications"}, {"score": 0.003742084495435749, "phrase": "texture_memory_reference"}, {"score": 0.0034068225125064586, "phrase": "thread_blocks"}, {"score": 0.0030295361111006866, "phrase": "memory_access_strides"}, {"score": 0.002941913249957503, "phrase": "transposed_indexing"}, {"score": 0.0028568174308720167, "phrase": "tb-level_cache_optimization"}, {"score": 0.00270978310478061, "phrase": "tb_size"}, {"score": 0.0026624684547385718, "phrase": "spatial_locality"}, {"score": 0.002555247330102505, "phrase": "relatively_large_strides"}, {"score": 0.0024236964502593254, "phrase": "regular_intervals"}, {"score": 0.002381365139274329, "phrase": "synchronous_ray_propagation"}, {"score": 0.002353554841514325, "phrase": "experimental_results"}, {"score": 0.002272053079580848, "phrase": "worst_rendering_performance"}, {"score": 0.0021805201234139475, "phrase": "cuda_and_opencl_software_development_kits"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Volume rendering", " CUDA", " Cache optimization", " Texture memory"], "paper_abstract": "We present a cache-aware method for accelerating texture-based volume rendering on a graphics processing unit (GPU). Because a GPU has hierarchical architecture in terms of processing and memory units, cache optimization is important to maximize performance for memory-intensive applications. Our method localizes texture memory reference according to the location of the viewpoint and dynamically selects the width and height of thread blocks (TBs) so that each warp, which is a series of 32 threads processed simultaneously, can minimize memory access strides. We also incorporate transposed indexing of threads to perform TB-level cache optimization for specific viewpoints. Furthermore, we maximize TB size to exploit spatial locality with fewer resident TBs. For viewpoints with relatively large strides, we synchronize threads of the same TB at regular intervals to realize synchronous ray propagation. Experimental results indicate that our cache-aware method doubles the worst rendering performance compared to those provided by the CUDA and OpenCL software development kits. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Improving cache locality for GPU-based volume rendering", "paper_id": "WOS:000338614300002"}