{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "talking_heads"}, {"score": 0.00865901620294223, "phrase": "media_context"}, {"score": 0.0071228956432869365, "phrase": "talking_head"}, {"score": 0.004774115617883476, "phrase": "different_interaction_and_media_contexts"}, {"score": 0.004440648141548589, "phrase": "spoken_dialogue_system"}, {"score": 0.0043842558719324526, "phrase": "smart_home_domain"}, {"score": 0.004328576620172571, "phrase": "main_focus"}, {"score": 0.004219321533320583, "phrase": "voice_and_head_characteristics"}, {"score": 0.0041835168653521, "phrase": "audio_and_video_quality"}, {"score": 0.004095323392273661, "phrase": "overall_quality"}, {"score": 0.003891140864902669, "phrase": "user_perception"}, {"score": 0.0036191240628152205, "phrase": "non-interactive_rating_test"}, {"score": 0.0034977560416755726, "phrase": "second_experiment"}, {"score": 0.0030908254851076005, "phrase": "redundant_information"}, {"score": 0.003025597247856977, "phrase": "additional_visual_output_channel"}, {"score": 0.0029116257477000617, "phrase": "secondary_effect"}, {"score": 0.002850168497994985, "phrase": "participants'_gender"}, {"score": 0.002754516260621121, "phrase": "perceived_quality_differences"}, {"score": 0.0027078974645805736, "phrase": "non-interactive_setting"}, {"score": 0.0026507289852980512, "phrase": "interactivity_and_media_contexts"}, {"score": 0.002539978170928796, "phrase": "simple_additional_feedback_screen"}, {"score": 0.0025076619172878945, "phrase": "perceived_quality"}, {"score": 0.0024547103576350233, "phrase": "gender_effects"}, {"score": 0.00235213013487844, "phrase": "female_and_male_participants"}, {"score": 0.002187464225869713, "phrase": "external_validity"}, {"score": 0.002159623311924437, "phrase": "obtained_quality_judgements"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Embodied conversational agent", " Smart home", " Talking head", " Usability", " WOZ"], "paper_abstract": "We investigate the impact of three different factors on the quality of talking heads as metaphors of a spoken dialogue system in the smart home domain. The main focus lies on the effect of voice and head characteristics on audio and video quality, as well as overall quality. Furthermore, the influence of interactivity and of media context on user perception is analysed. For this purpose two subsequent experiments were conducted: the first was designed as a non-interactive rating test of videos of talking heads, while the second experiment was interactive. Here, the participants had to solve a number of tasks in dialogue with a talking head. To assess the impact of the media context, redundant information was provided via an additional visual output channel to half of the participants. As a secondary effect, the importance of participants' gender is examined. It is shown that perceived quality differences observed in the non-interactive setting are blurred when the interactivity and media contexts provide distraction from the talking head. Furthermore, a simple additional feedback screen improves the perceived quality of the talking heads. Gender effects are negligible concerning the ratings in interaction, but female and male participants exhibit different behaviour in the experiment. This advocates for more realistic evaluation settings in order to increase the external validity of the obtained quality judgements. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Quality of talking heads in different interaction and media contexts", "paper_id": "WOS:000278282000002"}