{"auto_keywords": [{"score": 0.04445490561004347, "phrase": "proximity_information"}, {"score": 0.00481495049065317, "phrase": "heterogeneous_proximity_measures"}, {"score": 0.004767261858417823, "phrase": "supervised_spectral_embedding"}, {"score": 0.004720043307726269, "phrase": "spectral_embedding_methods"}, {"score": 0.004581162468419365, "phrase": "dimensionality_reduction"}, {"score": 0.0045357787854931894, "phrase": "feature_generation"}, {"score": 0.004490842671590769, "phrase": "machine_learning"}, {"score": 0.004446349752828045, "phrase": "supervised_spectral_embedding_methods"}, {"score": 0.004315487055548749, "phrase": "labeled_data"}, {"score": 0.004126349202545883, "phrase": "class_labels"}, {"score": 0.003906357144047631, "phrase": "intraclass_similarities"}, {"score": 0.003716520760680603, "phrase": "interclass_samples"}, {"score": 0.003380791705551809, "phrase": "different_proximity_function"}, {"score": 0.003281186608301359, "phrase": "class_pair"}, {"score": 0.003075296862372287, "phrase": "evolutionary_programming"}, {"score": 0.003029643234751066, "phrase": "automated_powerful_formula_induction_engine"}, {"score": 0.0029403531729828574, "phrase": "computational_efficiency"}, {"score": 0.0029111767710750117, "phrase": "expressive_power"}, {"score": 0.0028394925080958205, "phrase": "compact_matrix_tree_representation"}, {"score": 0.0027834145465170292, "phrase": "broad_set"}, {"score": 0.0026480044868438875, "phrase": "new_ones"}, {"score": 0.0026217213613095322, "phrase": "model_selection"}, {"score": 0.0025317627242523104, "phrase": "entire_model"}, {"score": 0.002420611343093316, "phrase": "user-selected_functions"}, {"score": 0.0023259039577313294, "phrase": "thorough_comparative_experimentations"}, {"score": 0.0023028105026714533, "phrase": "multiple_classification_datasets"}, {"score": 0.002126111716875142, "phrase": "classification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "generalization_ability"}], "paper_keywords": ["Distance metric learning", " evolutionary optimization", " heterogeneous proximity information", " spectral dimensionality reduction"], "paper_abstract": "Spectral embedding methods have played a very important role in dimensionality reduction and feature generation in machine learning. Supervised spectral embedding methods additionally improve the classification of labeled data, using proximity information that considers both features and class labels. However, these calculate the proximity information by treating all intraclass similarities homogeneously for all classes, and similarly for all interclass samples. In this paper, we propose a very novel and generic method which can treat all the intra- and interclass sample similarities heterogeneously by potentially using a different proximity function for each class and each class pair. To handle the complexity of selecting these functions, we employ evolutionary programming as an automated powerful formula induction engine. In addition, for computational efficiency and expressive power, we use a compact matrix tree representation equipped with a broad set of functions that can build most currently used similarity functions as well as new ones. Model selection is data driven, because the entire model is symbolically instantiated using only problem training data, and no user-selected functions or parameters are required. We perform thorough comparative experimentations with multiple classification datasets and many existing state-of-the-art embedding methods, which show that the proposed algorithm is very competitive in terms of classification accuracy and generalization ability.", "paper_title": "Automated Induction of Heterogeneous Proximity Measures for Supervised Spectral Embedding", "paper_id": "WOS:000325981400006"}