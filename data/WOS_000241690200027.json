{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "support_vector_machines"}, {"score": 0.004761132425263795, "phrase": "automatic_text_chunking"}, {"score": 0.004551781491498328, "phrase": "phrase_structures"}, {"score": 0.004500891637057374, "phrase": "natural_language_text"}, {"score": 0.004376131419366239, "phrase": "key_technology"}, {"score": 0.004327196832280818, "phrase": "knowledge-based_system"}, {"score": 0.004207230913063179, "phrase": "important_syntactic_information"}, {"score": 0.004160177106153782, "phrase": "knowledge_representation"}, {"score": 0.0041136473765874815, "phrase": "support_vector_machine"}, {"score": 0.003802135020791801, "phrase": "high_performance"}, {"score": 0.0036144035798673967, "phrase": "actual_use"}, {"score": 0.00357395617690842, "phrase": "large_dataset"}, {"score": 0.0029348729207661225, "phrase": "conventional_svm_learning"}, {"score": 0.002853396755102163, "phrase": "off-the-shelf_svm_classifiers"}, {"score": 0.002743105561254975, "phrase": "phrase_types"}, {"score": 0.0023560952790080943, "phrase": "slightly_decrease"}, {"score": 0.0023296961971785357, "phrase": "system_performance"}, {"score": 0.0023035922232490106, "phrase": "experimental_result"}, {"score": 0.0022145052062614514, "phrase": "f_rate"}], "paper_keywords": [""], "paper_abstract": "Automatic text chunking is a task which aims to recognize phrase structures in natural language text. It is the key technology of knowledge-based system where phrase structures provide important syntactic information for knowledge representation. Support Vector Machine (SVM-based) phrase chunking system had been shown to achieve high performance for text chunking. But its inefficiency limits the actual use on large dataset that only handles several thousands tokens per second. In this paper, we firstly show that the state-of-the-art performance (94.25) in the CoNLL-2000 shared task based on conventional SVM learning. However, the off-the-shelf SVM classifiers are inefficient when the number of phrase types scales to high. Therefore, we present two novel methods that make the system substantially faster in terms of training and testing while only results in a slightly decrease of system performance. Experimental result shows that our method achieves 94.09 in F rate, which handles 13000 tokens per second in the CoNLL-2000 chunking task.", "paper_title": "Efficient and robust phrase chunking using support vector machines", "paper_id": "WOS:000241690200027"}