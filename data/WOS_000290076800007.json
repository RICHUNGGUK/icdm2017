{"auto_keywords": [{"score": 0.04944505928414034, "phrase": "minimum_classification_error"}, {"score": 0.03778643369744083, "phrase": "classification_error"}, {"score": 0.034579496502095304, "phrase": "pca"}, {"score": 0.02654937116463678, "phrase": "proposed_methods"}, {"score": 0.00481495049065317, "phrase": "speech_features"}, {"score": 0.004710854091689325, "phrase": "feature_extraction"}, {"score": 0.004649474569983707, "phrase": "important_component"}, {"score": 0.004608997772926119, "phrase": "pattern_classification"}, {"score": 0.004568871736067739, "phrase": "speech_recognition"}, {"score": 0.004529093447865156, "phrase": "extracted_features"}, {"score": 0.004316396683332752, "phrase": "environmental_conditions"}, {"score": 0.003752550907120244, "phrase": "data-dependent_transformation"}, {"score": 0.003498782065781398, "phrase": "classifier's_performance"}, {"score": 0.0033197446406648626, "phrase": "data-dependent_feature_transformations"}, {"score": 0.003247868216333148, "phrase": "principal_component_analysis"}, {"score": 0.003191485583025302, "phrase": "linear_discriminant_analysis"}, {"score": 0.0030547888561224547, "phrase": "mce"}, {"score": 0.0030017207229983385, "phrase": "main_objective"}, {"score": 0.002898378776839434, "phrase": "hidden_markov_model"}, {"score": 0.00266693888510356, "phrase": "mapped_features"}, {"score": 0.0025863988422430797, "phrase": "feature_vector"}, {"score": 0.0024218895273910943, "phrase": "timit_phone_recognition"}, {"score": 0.0022482629722452734, "phrase": "lda"}, {"score": 0.002228413978209167, "phrase": "hlda"}, {"score": 0.0021896891011033105, "phrase": "mel-frequency_cepstral_coefficients"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Minimum classification error", " Principal Component Analysis", " Linear Discriminant Analysis", " Feature transformation", " Hidden Markov Model"], "paper_abstract": "Feature extraction is an important component of pattern classification and speech recognition. Extracted features should discriminate classes from each other while being robust to environmental conditions such as noise. For this purpose, several feature transformations are proposed which can be divided into two main categories: data-dependent transformation and classifier-dependent transformation. The drawback of data-dependent transformation is that its optimization criteria are different from the measure of classification error which can potentially degrade the classifier's performance. In this paper, we propose a framework to optimize data-dependent feature transformations such as PCA (Principal Component Analysis), LDA (Linear Discriminant Analysis) and HLDA (Heteroscedastic LDA) using minimum classification error (MCE) as the main objective. The classifier itself is based on Hidden Markov Model (HMM). In our proposed HMM minimum classification error technique, the transformation matrices are modified to minimize the classification error for the mapped features, and the dimension of the feature vector is not changed. To evaluate the proposed methods, we conducted several experiments on the TIMIT phone recognition and the Aurora2 isolated word recognition tasks. The experimental results show that the proposed methods improve performance of PCA, LDA and HLDA transformation for mapping Mel-frequency cepstral coefficients (MFCC). (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Optimized discriminative transformations for speech features based on minimum classification error", "paper_id": "WOS:000290076800007"}