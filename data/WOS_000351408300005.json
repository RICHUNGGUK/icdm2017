{"auto_keywords": [{"score": 0.04177709856406238, "phrase": "numerical_vectors"}, {"score": 0.015719716506582538, "phrase": "text_categorization"}, {"score": 0.013217993614640156, "phrase": "encoding_texts"}, {"score": 0.011993076490642345, "phrase": "previous_version"}, {"score": 0.004552648949390462, "phrase": "improved_version"}, {"score": 0.004489327204473076, "phrase": "table-based_matching_algorithm"}, {"score": 0.004334832612029898, "phrase": "text_categorization_tasks"}, {"score": 0.003741712498615481, "phrase": "text_lengths"}, {"score": 0.0032294837250130327, "phrase": "similarity_measure"}, {"score": 0.0030532878377173885, "phrase": "normalized_value"}, {"score": 0.0025801648787263662, "phrase": "better_performance"}, {"score": 0.002149799391146313, "phrase": "proposed_approach"}], "paper_keywords": [""], "paper_abstract": "This research is concerned with the improved version of table-based matching algorithm as the approach to text categorization tasks. It is intended to tackle the three problems in encoding texts into numerical vectors and the unstable performance by the fluctuations from text lengths in the previous version. In this research, we encode texts into tables rather than into numerical vectors, define the similarity measure between two tables which is always as a normalized value between zero and one, and apply it to the tasks of text categorization. As the benefits from this research, we expect better performance by solving the three problems resulting from encoding texts into numerical vectors, and more stable performance by improving the previous version. Therefore, we empirically validate the proposed approach through the four sets of experiments, with respect to both performance and stability.", "paper_title": "Normalized table-matching algorithm as approach to text categorization", "paper_id": "WOS:000351408300005"}