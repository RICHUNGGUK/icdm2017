{"auto_keywords": [{"score": 0.04121746831918884, "phrase": "mi"}, {"score": 0.01571919876322481, "phrase": "mutual_information"}, {"score": 0.004747997855358171, "phrase": "supervised_linear_feature_extraction"}, {"score": 0.004457995891964028, "phrase": "novel_scheme"}, {"score": 0.004395984840790689, "phrase": "linear_feature_extraction"}, {"score": 0.00314015410819199, "phrase": "whole_output_vector"}, {"score": 0.0030319482153908037, "phrase": "component-by-component_gradient-ascent_method"}, {"score": 0.002767696345005216, "phrase": "gradient-based_entropy_optimization"}, {"score": 0.0027100527874262446, "phrase": "independent_component_analysis"}, {"score": 0.002598333022293788, "phrase": "simulation_results"}, {"score": 0.002388487669097511, "phrase": "existing_supervised_feature_extraction_methods"}, {"score": 0.0021049977753042253, "phrase": "strongly_nonlinear_boundaries"}], "paper_keywords": ["feature extraction", " information theory", " pattern recognition"], "paper_abstract": "In this paper, we present a novel scheme for linear feature extraction in classification. The method is,based on the maximization of the mutual information (MI) between the features extracted and the classes. The sum of the MI corresponding to each of the features is taken as an heuristic that approximates the MI of the whole output vector. Then, a component-by-component gradient-ascent method is proposed for the maximization of the MI, similar to the gradient-based entropy optimization used in independent component analysis (ICA). The simulation results show that not only is the method competitive when compared to existing supervised feature extraction methods in all cases studied, but it also remarkably outperform them when the data are characterized by strongly nonlinear boundaries between classes.", "paper_title": "Maximization of mutual information for supervised linear feature extraction", "paper_id": "WOS:000249279400013"}