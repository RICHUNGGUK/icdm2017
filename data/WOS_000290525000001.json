{"auto_keywords": [{"score": 0.039682325996342485, "phrase": "multicore_computers"}, {"score": 0.027276244740677438, "phrase": "processor_cores"}, {"score": 0.00481495049065317, "phrase": "hybrid_openmp"}, {"score": 0.004767546015485477, "phrase": "mpi_programming"}, {"score": 0.004720606036240263, "phrase": "multicore_smp_clusters"}, {"score": 0.004492717291734985, "phrase": "distributed_systems"}, {"score": 0.004404658750724105, "phrase": "critical_problem"}, {"score": 0.004150661689086371, "phrase": "emerging_heterogeneous_cluster_computing_environments"}, {"score": 0.004009288598277725, "phrase": "self-scheduling_schemes"}, {"score": 0.0038727120021750973, "phrase": "heterogeneous_cluster_computing_environments"}, {"score": 0.0036673959568781734, "phrase": "cluster_systems"}, {"score": 0.0035424245257172234, "phrase": "parallel_loop_self-scheduling"}, {"score": 0.0032724821705972357, "phrase": "shared-memory_multiprocessors"}, {"score": 0.0032241994368246065, "phrase": "open_multi-processing"}, {"score": 0.0031453010852936334, "phrase": "parallel_programming"}, {"score": 0.0030081030319492343, "phrase": "performance-based_approach"}, {"score": 0.0029784342137867776, "phrase": "hybrid_openmp_and_mpi_parallel_programming"}, {"score": 0.0028484940955893134, "phrase": "performance_weighting"}, {"score": 0.0028203950416405585, "phrase": "multicore_nodes"}, {"score": 0.002618278365749875, "phrase": "openmp_threads"}, {"score": 0.002467038647952607, "phrase": "loop_iterations"}, {"score": 0.002394719113232821, "phrase": "scheduling_step"}, {"score": 0.0022675820982741347, "phrase": "experimental_results"}, {"score": 0.002223039450439376, "phrase": "proposed_approach"}, {"score": 0.0021793698531006197, "phrase": "previous_schemes"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["parallel loop", " self-scheduling", " multicore", " SMP cluster", " hybrid", " OpenMP", " MPI"], "paper_abstract": "Parallel loop self-scheduling on parallel and distributed systems has been a critical problem and it is becoming more difficult to deal with in the emerging heterogeneous cluster computing environments. In the past, some self-scheduling schemes have been proposed as applicable to heterogeneous cluster computing environments. In recent years, multicore computers have been widely included in cluster systems. However, previous researches into parallel loop self-scheduling did not consider certain aspects of multicore computers; for example, it is more appropriate for shared-memory multiprocessors to adopt Open Multi-Processing (OpenMP) for parallel programming. In this paper, we propose a performance-based approach using hybrid OpenMP and MPI parallel programming, which partition loop iterations according to the performance weighting of multicore nodes in a cluster. Because iterations assigned to one MPI process are processed in parallel by OpenMP threads run by the processor cores in the same computational node, the number of loop iterations allocated to one computational node at each scheduling step depends on the number of processor cores in that node. Experimental results show that the proposed approach performs better than previous schemes. Copyright (C) 2010 John Wiley & Sons, Ltd.", "paper_title": "Performance-based parallel loop self-scheduling using hybrid OpenMP and MPI programming on multicore SMP clusters", "paper_id": "WOS:000290525000001"}