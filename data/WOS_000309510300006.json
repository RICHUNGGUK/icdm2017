{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "disparity_map"}, {"score": 0.004775335634705251, "phrase": "color_segmentation"}, {"score": 0.004736045157669388, "phrase": "depth_perception"}, {"score": 0.004677711903652145, "phrase": "crucial_but_greedy_task"}, {"score": 0.00428892403807229, "phrase": "permanent_full_precision"}, {"score": 0.004098291340525772, "phrase": "fine_strategy"}, {"score": 0.004031082737449308, "phrase": "present_paper"}, {"score": 0.0039813976794342, "phrase": "novel_method"}, {"score": 0.003820144626025562, "phrase": "block_matching_strategy"}, {"score": 0.003590383760209319, "phrase": "initial_image"}, {"score": 0.0034306925765832633, "phrase": "sole_chrominance_information"}, {"score": 0.0033883824438527316, "phrase": "stable_and_homogeneous_regions"}, {"score": 0.0033053159828082095, "phrase": "real_boundaries"}, {"score": 0.0032242793143795454, "phrase": "particular_attention"}, {"score": 0.0030554300179552415, "phrase": "depth_and_region_maps"}, {"score": 0.0029928611380840757, "phrase": "second_stage"}, {"score": 0.0029559346879594254, "phrase": "luminance_variations"}, {"score": 0.0028715299874549245, "phrase": "depth_map"}, {"score": 0.0028127163745564777, "phrase": "edge_map"}, {"score": 0.0027665315772006575, "phrase": "luminance_component"}, {"score": 0.0025999744005191713, "phrase": "initial_disparity_map"}, {"score": 0.0025361866386341796, "phrase": "minimization_process"}, {"score": 0.0024535580495414783, "phrase": "segmentation_method"}, {"score": 0.002373615081691254, "phrase": "spatial_domain"}, {"score": 0.0022679195103377124, "phrase": "color_and_space_domains"}, {"score": 0.0021049977753042253, "phrase": "phi_theta"}], "paper_keywords": ["Disparity map", " occlusion handling", " color segmentation", " chrominance", " luminance"], "paper_abstract": "Depth perception is a crucial but greedy task for most mobile robots to navigate in their environment and avoid obstacles. Generally, it does not need to be completed at permanent full precision but can be done in a coarse-to-fine strategy. In the present paper, a novel method is proposed to enhance a very sparse disparity map provided by a block matching strategy for example. To that purpose, the region and edge maps of the initial image are successively analyzed. The segmentation is achieved on the sole chrominance information to produce stable and homogeneous regions, closely related to the real boundaries of the objects. A particular attention is given to remove errors due to occlusions, by making the depth and region maps cooperate. In a second stage, the luminance variations are analyzed to fill up the depth map. Finally, the edge map computed on the luminance component is used to alleviate problems due to under-segmentation. The experiments show that the initial disparity map is successfully improved without any minimization process. A comparison is made regarding the segmentation method, whether it performs directly in the spatial domain (region-growing) or it jointly uses the color and space domains (mean-shift). In addition, two luminance-chrominance color spaces are studied: L*u*v* and rho phi theta.", "paper_title": "Enhancing a disparity map by color segmentation", "paper_id": "WOS:000309510300006"}