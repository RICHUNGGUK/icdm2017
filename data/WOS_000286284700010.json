{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "environmental_models"}, {"score": 0.03759767722202089, "phrase": "considerable_variation"}, {"score": 0.02994554883027827, "phrase": "common_vision"}, {"score": 0.004669026573960951, "phrase": "collective_views"}, {"score": 0.004614081478934359, "phrase": "independent_researchers"}, {"score": 0.004581423845101698, "phrase": "technical_assessment"}, {"score": 0.004359173705488354, "phrase": "improved_quality"}, {"score": 0.004338575266640439, "phrase": "model_development"}, {"score": 0.004217004035331687, "phrase": "positive_outcomes"}, {"score": 0.004089127275533214, "phrase": "model_evaluation_process"}, {"score": 0.004021877785031447, "phrase": "funding_agencies"}, {"score": 0.0039557298818491205, "phrase": "continued_support"}, {"score": 0.003937030300970066, "phrase": "modelling_efforts"}, {"score": 0.0038357455009733654, "phrase": "environmental_modelling_studies"}, {"score": 0.0037637181095425587, "phrase": "submitted_papers"}, {"score": 0.003505414008379761, "phrase": "consequent_risk"}, {"score": 0.003423300183616815, "phrase": "resulting_publication"}, {"score": 0.003351038095502741, "phrase": "review_process"}, {"score": 0.0032958869945139617, "phrase": "submitted_manuscript"}, {"score": 0.0031135758917600754, "phrase": "best_practice"}, {"score": 0.0030915055800372093, "phrase": "environmental_modelling_results"}, {"score": 0.0030550677676608896, "phrase": "unique_contribution"}, {"score": 0.0030047730356199116, "phrase": "model-based_research"}, {"score": 0.002934352120961826, "phrase": "entire_environmental_modelling_community"}, {"score": 0.002852015921489843, "phrase": "environmental_modellers"}, {"score": 0.0028117158265039107, "phrase": "minimum_standards"}, {"score": 0.002791779231329709, "phrase": "environmental_model"}, {"score": 0.002732811297967071, "phrase": "good_model"}, {"score": 0.002681438988019335, "phrase": "good_modelling_practice"}, {"score": 0.0024972255527646882, "phrase": "professional_journals"}, {"score": 0.0024736371348038043, "phrase": "peer-review_process"}, {"score": 0.002375840949858925, "phrase": "additional_time"}, {"score": 0.002325637971807746, "phrase": "model_credibility"}, {"score": 0.0022283850005033923, "phrase": "realistic_evaluation_criteria"}, {"score": 0.0021864742767095414, "phrase": "standardized_evaluation_tools"}, {"score": 0.002160680432287145, "phrase": "key_issue"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Model evaluation", " Model credibility", " Software verification", " Environmental assessment"], "paper_abstract": "This letter details the collective views of a number of independent researchers on the technical assessment and evaluation of environmental models and software. The purpose is to stimulate debate and initiate action that leads to an improved quality of model development and evaluation, so increasing the capacity for models to have positive outcomes from their use. As such, we emphasize the relationship between the model evaluation process and credibility with stakeholders (including funding agencies) with a view to ensure continued support for modelling efforts. Many journals, including EM&S, publish the results of environmental modelling studies and must judge the work and the submitted papers based solely on the material that the authors have chosen to present and on how they present it. There is considerable variation in how this is done with the consequent risk of considerable variation in the quality and usefulness of the resulting publication. Part of the problem is that the review process is reactive, responding to the submitted manuscript. In this letter, we attempt to be proactive and give guidelines for researchers, authors and reviewers as to what constitutes best practice in presenting environmental modelling results. This is a unique contribution to the organisation and practice of model-based research and the communication of its results that will benefit the entire environmental modelling community. For a start, our view is that the community of environmental modellers should have a common vision of minimum standards that an environmental model must meet. A common vision of what a good model should be is expressed in various guidelines on Good Modelling Practice. The guidelines prompt modellers to codify their practice and to be more rigorous in their model testing. Our statement within this letter deals with another aspect of the issue it prompts professional journals to codify the peer-review process. Introducing a more formalized approach to peer-review may discourage reviewers from accepting invitations to review given the additional time and labour requirements. The burden of proving model credibility is thus shifted to the authors. Here we discuss how to reduce this burden by selecting realistic evaluation criteria and conclude by advocating the use of standardized evaluation tools as this is a key issue that needs to be tackled. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Technical assessment and evaluation of environmental models and software: Letter to the Editor", "paper_id": "WOS:000286284700010"}