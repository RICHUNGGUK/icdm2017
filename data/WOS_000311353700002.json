{"auto_keywords": [{"score": 0.03499287706783538, "phrase": "recognition"}, {"score": 0.00481495049065317, "phrase": "humanoid_robot_task_recognition"}, {"score": 0.0046928556063004214, "phrase": "motion_recognition"}, {"score": 0.004593467306126913, "phrase": "statistical_tools"}, {"score": 0.004476963405985556, "phrase": "primitive_learning"}, {"score": 0.004419819325202464, "phrase": "suitable_space"}, {"score": 0.004270960586542813, "phrase": "adequate_task_spaces"}, {"score": 0.004234532601573088, "phrase": "learned_primitives"}, {"score": 0.0040223714916651845, "phrase": "time_axis"}, {"score": 0.003920295222165263, "phrase": "humanoid_robot"}, {"score": 0.003788196352457501, "phrase": "parallel_subtasks"}, {"score": 0.0036762529165489644, "phrase": "waiter_scenario"}, {"score": 0.00319134078848996, "phrase": "consecutive_segment"}, {"score": 0.0027702126237754625, "phrase": "known_controllers"}, {"score": 0.0027114323601885666, "phrase": "reverse_engineering"}, {"score": 0.0026767629720554397, "phrase": "observed_motion"}, {"score": 0.002586457551025025, "phrase": "parallel_tasks"}, {"score": 0.0024252458095689847, "phrase": "task-function_formalism"}, {"score": 0.0023942269247089277, "phrase": "projection_operation"}, {"score": 0.0023636038312749245, "phrase": "null_space"}, {"score": 0.0022067604433257814, "phrase": "real_robot"}, {"score": 0.00218789980093445, "phrase": "disambiguate_motion"}, {"score": 0.0021692000054033956, "phrase": "different_scenarios"}, {"score": 0.0021049977753042253, "phrase": "different_purposes"}], "paper_keywords": ["Humanoid robot", " inverse kinematics", " task-function formalism", " task recognition"], "paper_abstract": "Efficient methods to perform motion recognition have been developed using statistical tools. Those methods rely on primitive learning in a suitable space, for example, the latent space of the joint angle and/or adequate task spaces. Learned primitives are often sequential: A motion is segmented according to the time axis. When working with a humanoid robot, a motion can be decomposed into parallel subtasks. For example, in a waiter scenario, the robot has to keep some plates horizontal with one of its arms while placing a plate on the table with its free hand. Recognition can thus not be limited to one task per consecutive segment of time. The method presented in this paper takes advantage of the knowledge of what tasks the robot is able to do and how the motion is generated from this set of known controllers, to perform a reverse engineering of an observed motion. This analysis is intended to recognize parallel tasks that have been used to generate a motion. The method relies on the task-function formalism and the projection operation into the null space of a task to decouple the controllers. The approach is successfully applied on a real robot to disambiguate motion in different scenarios where two motions look similar but have different purposes.", "paper_title": "Reverse Control for Humanoid Robot Task Recognition", "paper_id": "WOS:000311353700002"}