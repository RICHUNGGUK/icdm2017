{"auto_keywords": [{"score": 0.04665430102855293, "phrase": "online_unsupervised_incremental_learning"}, {"score": 0.00481495049065317, "phrase": "machine_learning"}, {"score": 0.004760394308239882, "phrase": "feature_extraction"}, {"score": 0.004706453355638515, "phrase": "pattern_recognition"}, {"score": 0.004653120760786245, "phrase": "image_analysis"}, {"score": 0.004600389726895716, "phrase": "information_retrieval"}, {"score": 0.0043953478557600565, "phrase": "important_branch"}, {"score": 0.004345525254560329, "phrase": "data_clustering"}, {"score": 0.004199406257273994, "phrase": "high-density_overlapped_areas"}, {"score": 0.004058180509184539, "phrase": "direct_impact"}, {"score": 0.0039216854691927865, "phrase": "clustering_algorithm"}, {"score": 0.003725470458263889, "phrase": "load-balancing_self-organizing_incremental_neural_network"}, {"score": 0.003559284776569813, "phrase": "good_clustering_results"}, {"score": 0.0033619033669956317, "phrase": "enhanced_soinn"}, {"score": 0.002881793492919646, "phrase": "topology_structure"}, {"score": 0.002675654549462983, "phrase": "input_data"}, {"score": 0.0025127604406208668, "phrase": "composite_class"}, {"score": 0.002373276186210053, "phrase": "distance_combination_framework"}, {"score": 0.0023329572140896237, "phrase": "good_performance"}, {"score": 0.0023064582783867645, "phrase": "high-dimensional_space-clustering_tasks"}, {"score": 0.0022160547331029757, "phrase": "lb-soinn"}], "paper_keywords": ["Document clustering", " incremental learning", " load-balancing", " self-organizing neural network"], "paper_abstract": "Clustering is widely used in machine learning, feature extraction, pattern recognition, image analysis, information retrieval, and bioinformatics. Online unsupervised incremental learning is an important branch of data clustering. However, accurately separating high-density overlapped areas in a network has a direct impact on the performance of the clustering algorithm. In this paper, we propose a load-balancing self-organizing incremental neural network (LB-SOINN) to achieve good clustering results and demonstrate that it is more stable than an enhanced SOINN (E-SOINN). LB-SOINN has all the advantages of E-SOINN, such as robustness to noise and online unsupervised incremental learning. It overcomes the shortcomings of the topology structure generated by E-SOINN, such as dependence on the sequence of the input data, and avoids the turbulence that occurs when separating a composite class into subclasses. Furthermore, we also introduce a distance combination framework to obtain good performance for high-dimensional space-clustering tasks. Experiments involving both artificial and real world data sets indicate that LB-SOINN has superior performance in comparison with E-SOINN and other methods.", "paper_title": "A Load-Balancing Self-Organizing Incremental Neural Network", "paper_id": "WOS:000336917000007"}