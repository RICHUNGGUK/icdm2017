{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "record_linkage"}, {"score": 0.030615222000682292, "phrase": "previous_best-known_algorithm"}, {"score": 0.004777034835192062, "phrase": "background_and_objective_integrating_data"}, {"score": 0.0046650615456476155, "phrase": "crucial_and_challenging_problem"}, {"score": 0.0045557008859819234, "phrase": "numerous_algorithms"}, {"score": 0.0043790755286923794, "phrase": "large_time"}, {"score": 0.004062057297453209, "phrase": "efficient_sequential_and_parallel_algorithms"}, {"score": 0.0038737214010638745, "phrase": "previous_algorithms"}, {"score": 0.0037978390554858766, "phrase": "hierarchical_clustering_algorithms"}, {"score": 0.0037087324991876727, "phrase": "key_idea"}, {"score": 0.0035507457285983268, "phrase": "identical_records"}, {"score": 0.0034674164050273568, "phrase": "novel_idea"}, {"score": 0.003359334465113303, "phrase": "similar_records"}, {"score": 0.003306559295382181, "phrase": "connected_components"}, {"score": 0.003190817088774159, "phrase": "real_dataset"}, {"score": 0.003140680985599885, "phrase": "synthetic_datasets"}, {"score": 0.0027999339042953076, "phrase": "faster_computation"}, {"score": 0.0027668603377225564, "phrase": "edit_distance"}, {"score": 0.0026175952455594277, "phrase": "almost_linear"}, {"score": 0.002447101794397243, "phrase": "single_node"}, {"score": 0.0021049977753042253, "phrase": "previous_one"}], "paper_keywords": ["Data Integration", " Healthcare Records", " Algorithms", " Parallel Algorithms", " Speedups"], "paper_abstract": "Background and objective Integrating data from multiple sources is a crucial and challenging problem. Even though there exist numerous algorithms for record linkage or deduplication, they suffer from either large time needs or restrictions on the number of datasets that they can integrate. In this paper we report efficient sequential and parallel algorithms for record linkage which handle any number of datasets and outperform previous algorithms. Methods Our algorithms employ hierarchical clustering algorithms as the basis. A key idea that we use is radix sorting on certain attributes to eliminate identical records before any further processing. Another novel idea is to form a graph that links similar records and find the connected components. Results Our sequential and parallel algorithms have been tested on a real dataset of 1083878 records and synthetic datasets ranging in size from 50000 to 9000000 records. Our sequential algorithm runs at least two times faster, for any dataset, than the previous best-known algorithm, the two-phase algorithm using faster computation of the edit distance (TPA (FCED)). The speedups obtained by our parallel algorithm are almost linear. For example, we get a speedup of 7.5 with 8 cores (residing in a single node), 14.1 with 16 cores (residing in two nodes), and 26.4 with 32 cores (residing in four nodes). Conclusions We have compared the performance of our sequential algorithm with TPA (FCED) and found that our algorithm outperforms the previous one. The accuracy is the same as that of this previous best-known algorithm.", "paper_title": "Efficient sequential and parallel algorithms for record linkage", "paper_id": "WOS:000331263600011"}