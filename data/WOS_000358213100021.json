{"auto_keywords": [{"score": 0.04847167377939251, "phrase": "adaptive_algorithm"}, {"score": 0.03929279272887132, "phrase": "inertial_sensors"}, {"score": 0.00481495049065317, "phrase": "mobile_robots"}, {"score": 0.004749646583168342, "phrase": "omnidirectional_vision"}, {"score": 0.004405919996432158, "phrase": "simple_adaptive_algorithm"}, {"score": 0.004200197763119297, "phrase": "mobile_robot"}, {"score": 0.004143196873246147, "phrase": "high_accuracy"}, {"score": 0.0040591367766929344, "phrase": "unknown_and_unstructured_environment"}, {"score": 0.0038960785110831162, "phrase": "omnidirectional_vision_system"}, {"score": 0.003613899384402803, "phrase": "new_derivation"}, {"score": 0.003540539868937462, "phrase": "omnidirectional_projection"}, {"score": 0.0032616462517547477, "phrase": "natural_feature_points"}, {"score": 0.003152006152091526, "phrase": "novel_adaptive_algorithm"}, {"score": 0.003004655258223784, "phrase": "slotine-li_algorithm"}, {"score": 0.002963830787280652, "phrase": "model-based_adaptive_control"}, {"score": 0.0028641729745364952, "phrase": "robot's_position"}, {"score": 0.002786858120570499, "phrase": "tracked_feature_points"}, {"score": 0.002748984715897838, "phrase": "image_sequence"}, {"score": 0.002693134880651768, "phrase": "robot's_velocity"}, {"score": 0.0026384167183586015, "phrase": "orientation_angles"}, {"score": 0.0023810183846557486, "phrase": "global_exponential_convergence"}, {"score": 0.002332626862738603, "phrase": "position_estimation_errors"}, {"score": 0.002238767763626708, "phrase": "real-world_experiments"}, {"score": 0.0021049977753042253, "phrase": "proposed_algorithm"}], "paper_keywords": ["Adaptive control", " localization", " mobile robots"], "paper_abstract": "This paper presents a novel and simple adaptive algorithm for estimating the position of a mobile robot with high accuracy in an unknown and unstructured environment by fusing images of an omnidirectional vision system with measurements of odometry and inertial sensors. Based on a new derivation where the omnidirectional projection can be linearly parameterized by the positions of the robot and natural feature points, we propose a novel adaptive algorithm, which is similar to the Slotine-Li algorithm in model-based adaptive control, to estimate the robot's position by using the tracked feature points in image sequence, the robot's velocity, and orientation angles measured by odometry and inertial sensors. It is proved that the adaptive algorithm leads to global exponential convergence of the position estimation errors to zero. Simulations and real-world experiments are performed to demonstrate the performance of the proposed algorithm.", "paper_title": "Estimating Position of Mobile Robots From Omnidirectional Vision Using an Adaptive Algorithm", "paper_id": "WOS:000358213100021"}