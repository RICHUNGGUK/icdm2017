{"auto_keywords": [{"score": 0.032475287473738255, "phrase": "eight_existing_feature-selection_methods"}, {"score": 0.00481495049065317, "phrase": "increasing_number"}, {"score": 0.004768649568826951, "phrase": "digital_documents"}, {"score": 0.004267004541988167, "phrase": "major_problems"}, {"score": 0.004225950334493496, "phrase": "text_classification"}, {"score": 0.004165105357908494, "phrase": "high_dimensionality"}, {"score": 0.004125027493339274, "phrase": "feature_space"}, {"score": 0.004026505114417176, "phrase": "ambiguity_measure"}, {"score": 0.0036908381347418805, "phrase": "unambiguous_features"}, {"score": 0.003516558537200823, "phrase": "strong_degree"}, {"score": 0.0033021988455635403, "phrase": "feature_selection"}, {"score": 0.0032546105164772995, "phrase": "naive_bayes_text"}, {"score": 0.002954361295811154, "phrase": "statistical_significance"}, {"score": 0.002883718207958817, "phrase": "support_vector_machine"}, {"score": 0.00269475174341129, "phrase": "naiive_bayes_text_classifier"}, {"score": 0.002579847272930948, "phrase": "time_complexity"}, {"score": 0.002285674008055581, "phrase": "training_time"}, {"score": 0.002252701813819903, "phrase": "svm_algorithm"}, {"score": 0.0021049977753042253, "phrase": "text_classifier"}], "paper_keywords": [""], "paper_abstract": "With the increasing number of digital documents, the ability to automatically classify those documents both efficiently and accurately is becoming more critical and difficult. One of the major problems in text classification is the high dimensionality of feature space. We present the ambiguity measure (AM) feature-selection algorithm, which selects the most unambiguous features from the feature set. Unambiguous features are those features whose presence in a document indicate a strong degree of confidence that a document belongs to only one specific category. We apply AM feature selection on a naive Bayes text classifier. We favorably show the effectiveness of our approach in outperforming eight existing feature-selection methods, using five benchmark datasets with a statistical significance of at least 95% confidence. The support vector machine (SVM) text classifier is shown to perform consistently better than the naiive Bayes text classifier. The drawback, however, is the time complexity in training a model. We further explore the effect of using the AM feature-selection method on an SVM text classifier. Our results indicate that the training time for the SVM algorithm can be reduced by more than 50%, while still improving the accuracy of the text classifier. We favorably show the effectiveness of our approach by demonstrating that it statistically significantly (99% confidence) outperforms eight existing feature-selection methods using four standard benchmark datasets.", "paper_title": "Ambiguity Measure Feature-Selection Algorithm", "paper_id": "WOS:000265420700012"}