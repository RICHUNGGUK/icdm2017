{"auto_keywords": [{"score": 0.048110796759132816, "phrase": "virtual_campus"}, {"score": 0.03753015918322821, "phrase": "massive_processing"}, {"score": 0.01451341103421732, "phrase": "user_models"}, {"score": 0.004815133171259446, "phrase": "distributed"}, {"score": 0.004722613498487908, "phrase": "activity_logs"}, {"score": 0.004513957235071457, "phrase": "multi-fold_approach"}, {"score": 0.004356472679444647, "phrase": "navigation_patterns"}, {"score": 0.004163925706345031, "phrase": "actual_learners'_needs"}, {"score": 0.004084022274429013, "phrase": "great_stimulation"}, {"score": 0.004044645056447888, "phrase": "learning_experience"}, {"score": 0.003992729692096799, "phrase": "user_modeling"}, {"score": 0.003916098498242888, "phrase": "constant_processing"}, {"score": 0.003865826699096508, "phrase": "user_interaction_data"}, {"score": 0.0038409323908446297, "phrase": "long-term_learning_activities"}, {"score": 0.003791621842185417, "phrase": "huge_amounts"}, {"score": 0.003767203575060969, "phrase": "valuable_data"}, {"score": 0.0037188360359702182, "phrase": "server_log_files"}, {"score": 0.0036592457471262894, "phrase": "large_or_very_large_size"}, {"score": 0.003531474887552889, "phrase": "foremost_step"}, {"score": 0.0034974064973871833, "phrase": "useful_information"}, {"score": 0.0034191818674096453, "phrase": "work_studies"}, {"score": 0.003342700977158772, "phrase": "processing_large_log_data_files"}, {"score": 0.003310447652300423, "phrase": "real_virtual_campus"}, {"score": 0.003289117944111902, "phrase": "different_distributed_infrastructures"}, {"score": 0.0032051601987130207, "phrase": "time_performance"}, {"score": 0.003163985877966426, "phrase": "daily_log_files"}, {"score": 0.0031233388358844188, "phrase": "master-slave_paradigm"}, {"score": 0.0030832123624449028, "phrase": "cluster_computing_and_planetlab_platforms"}, {"score": 0.002956316987429418, "phrase": "big_data_era"}, {"score": 0.002862260172272785, "phrase": "log_file_processing"}, {"score": 0.002825478348161608, "phrase": "chunk_log_data_size"}, {"score": 0.0027801631944598206, "phrase": "slave_nodes"}, {"score": 0.0027004145919012736, "phrase": "truly_geographically_distributed_infrastructures"}, {"score": 0.0026314443645799913, "phrase": "communication_time"}, {"score": 0.0026060359255636444, "phrase": "master_and_slave_nodes"}, {"score": 0.0025394700487126414, "phrase": "massive_processing_approach"}, {"score": 0.002514947446797848, "phrase": "log_data"}, {"score": 0.002466608618694819, "phrase": "well-structured_format"}, {"score": 0.002372693822379709, "phrase": "log_data_analysis"}, {"score": 0.0023421884529240882, "phrase": "weka_framework"}, {"score": 0.00232708281718627, "phrase": "data_mining_purposes"}, {"score": 0.0022457226013538343, "phrase": "interesting_navigation_patters"}, {"score": 0.0022312377180023282, "phrase": "on-line_learners"}, {"score": 0.0021393317071153844, "phrase": "actual_data_logs"}], "paper_keywords": ["Massive processing", " Log files", " Cluster computing", " PlanetLab", " Web mining usage", " WEKA framework", " Navigation patterns", " Virtual Campus"], "paper_abstract": "This paper reports on a multi-fold approach for the building of user models based on the identification of navigation patterns in a virtual campus, allowing for adapting the campus' usability to the actual learners' needs, thus resulting in a great stimulation of the learning experience. However, user modeling in this context implies a constant processing and analysis of user interaction data during long-term learning activities, which produces huge amounts of valuable data stored typically in server log files. Due to the large or very large size of log files generated daily, the massive processing is a foremost step in extracting useful information. To this end, this work studies, first, the viability of processing large log data files of a real Virtual Campus using different distributed infrastructures. More precisely, we study the time performance of massive processing of daily log files implemented following the master-slave paradigm and evaluated using Cluster Computing and PlanetLab platforms. The study reveals the complexity and challenges of massive processing in the big data era, such as the need to carefully tune the log file processing in terms of chunk log data size to be processed at slave nodes as well as the bottleneck in processing in truly geographically distributed infrastructures due to the overhead caused by the communication time among the master and slave nodes. Then, an application of the massive processing approach resulting in log data processed and stored in a well-structured format is presented. We show how to extract knowledge from the log data analysis by using the WEKA framework for data mining purposes showing its usefulness to effectively build user models in terms of identifying interesting navigation patters of on-line learners. The study is motivated and conducted in the context of the actual data logs of the Virtual Campus of the Open University of Catalonia.", "paper_title": "Distributed-based massive processing of activity logs for efficient user modeling in a Virtual Campus", "paper_id": "WOS:000327854400018"}