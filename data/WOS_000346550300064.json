{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "staged_learning-based_resource_allocation_network"}, {"score": 0.043528350819261416, "phrase": "slran"}, {"score": 0.004528301408585875, "phrase": "novel_learning_classifier"}, {"score": 0.00406214911915987, "phrase": "preliminary_learning_phase"}, {"score": 0.0040049806975968145, "phrase": "refined_learning_phase"}, {"score": 0.003930000775297499, "phrase": "former_phase"}, {"score": 0.003784209997115174, "phrase": "input_data"}, {"score": 0.0037486121194392564, "phrase": "agglomerate_hierarchical_k-means_method"}, {"score": 0.003643807817480753, "phrase": "initial_structure"}, {"score": 0.0036095259108028105, "phrase": "hidden_layer"}, {"score": 0.003525220627709056, "phrase": "novelty_criterion"}, {"score": 0.0033943947596098583, "phrase": "hidden_layer_centers"}, {"score": 0.0033308077968426937, "phrase": "latter_phase"}, {"score": 0.003299460925313939, "phrase": "least_square_method"}, {"score": 0.003207173639414978, "phrase": "convergence_rate"}, {"score": 0.003030247482854539, "phrase": "learning-based_approach"}, {"score": 0.002987557906013826, "phrase": "compact_structure"}, {"score": 0.002931569771634119, "phrase": "computational_complexity"}, {"score": 0.0027567336518542858, "phrase": "text_categorization"}, {"score": 0.0026922926476971453, "phrase": "semantic_similarity_approach"}, {"score": 0.002641823250595624, "phrase": "input_scales"}, {"score": 0.002616943519478975, "phrase": "neural_network"}, {"score": 0.0025678829712650437, "phrase": "latent_semantics"}, {"score": 0.0025436978068459565, "phrase": "text_features"}, {"score": 0.002507845411496512, "phrase": "benchmark_reuter"}, {"score": 0.002391938519840648, "phrase": "extensive_experimental_results"}, {"score": 0.0023470862747075228, "phrase": "dynamic_learning_process"}, {"score": 0.002259883463607508, "phrase": "conventional_classifiers"}, {"score": 0.0022385926290967263, "phrase": "e.g._ran"}, {"score": 0.0022176528166308576, "phrase": "bp"}, {"score": 0.002196636000896251, "phrase": "rbf"}, {"score": 0.0021554239200302174, "phrase": "svm."}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Resource allocation network", " Neural network", " Staged learning algorithm", " Text categorization", " Novelty criteria"], "paper_abstract": "In this paper, we propose a novel learning classifier which utilizes a staged learning-based resource allocation network (SLRAN) for text categorization. In the light of its learning progress, SLRAN is divided into a preliminary learning phase and a refined learning phase. In the former phase, to reduce the sensitivity corresponding to input data an agglomerate hierarchical k-means method is utilized to create the initial structure of hidden layer. Subsequently, a novelty criterion is put forward to dynamically regulate the hidden layer centers. In the latter phase a least square method is used to enhance the convergence rate of network and further improve its ability for classification. Such staged learning-based approach builds a compact structure which decreases the computational complexity of network and boosts its learning capability. In order to implement SLRAN to text categorization, we utilize a semantic similarity approach which reduces the input scales of neural network and reveals the latent semantics between text features. The benchmark Reuter and 20-newsgroup datasets are tested in our experiments and the extensive experimental results reveal that the dynamic learning process of SLRAN improves its classifying performance in comparison with conventional classifiers, e.g. RAN, BP, RBF neural networks and SVM. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Application of a staged learning-based resource allocation network to automatic text categorization", "paper_id": "WOS:000346550300064"}