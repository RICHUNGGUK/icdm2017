{"auto_keywords": [{"score": 0.04699094318179279, "phrase": "sparse_signals"}, {"score": 0.0435901678868039, "phrase": "orthonormal_basis"}, {"score": 0.00481495049065317, "phrase": "sparse_recovery"}, {"score": 0.004777392826700429, "phrase": "redundant_dictionaries"}, {"score": 0.004558091785667046, "phrase": "powerful_framework"}, {"score": 0.0044002186469797476, "phrase": "cs_literature"}, {"score": 0.004264463695140275, "phrase": "acquired_signal"}, {"score": 0.004214637810698362, "phrase": "sparse_or_compressible_representation"}, {"score": 0.003761900996118551, "phrase": "sparse_representations"}, {"score": 0.003717925116469845, "phrase": "redundant_dictionary"}, {"score": 0.003688892770976908, "phrase": "standard_results"}, {"score": 0.0036608277372302427, "phrase": "cs"}, {"score": 0.0032539388572032563, "phrase": "truly_redundant_or_overcomplete_dictionary"}, {"score": 0.00310435218261112, "phrase": "iterative_recovery_algorithm"}, {"score": 0.002926973459215349, "phrase": "sensing_matrix"}, {"score": 0.002881403688962202, "phrase": "well-known_restricted_isometry_property"}, {"score": 0.002825435048559866, "phrase": "prior_work"}, {"score": 0.002472552537325604, "phrase": "near-optimal_scheme"}, {"score": 0.0024245061478930558, "phrase": "signal_space"}, {"score": 0.0023961265476627166, "phrase": "model_family"}, {"score": 0.002331189621118592, "phrase": "provable_recovery_guarantees"}, {"score": 0.0022948742034852917, "phrase": "practical_algorithm"}, {"score": 0.0022414566728770745, "phrase": "required_near-optimal_projections"}, {"score": 0.0022152149658434916, "phrase": "significant_open_problem"}, {"score": 0.0021721582450016, "phrase": "simulation_results"}, {"score": 0.0021215910859085146, "phrase": "superior_performance"}, {"score": 0.0021049977753042253, "phrase": "traditional_recovery_algorithms"}], "paper_keywords": ["Compressive sensing (CS)", " greedy algorithms", " redundant dictionaries", " sparse approximation"], "paper_abstract": "Compressive sensing (CS) has recently emerged as a powerful framework for acquiring sparse signals. The bulk of the CS literature has focused on the case where the acquired signal has a sparse or compressible representation in an orthonormal basis. In practice, however, there are many signals that cannot be sparsely represented or approximated using an orthonormal basis, but that do have sparse representations in a redundant dictionary. Standard results in CS can sometimes be extended to handle this case provided that the dictionary is sufficiently incoherent or well conditioned, but these approaches fail to address the case of a truly redundant or overcomplete dictionary. In this paper, we describe a variant of the iterative recovery algorithm CoSaMP for this more challenging setting. We utilize the D-RIP, a condition on the sensing matrix analogous to the well-known restricted isometry property. In contrast to prior work, the method and analysis are \"signal-focused\"; that is, they are oriented around recovering the signal rather than its dictionary coefficients. Under the assumption that we have a near-optimal scheme for projecting vectors in signal space onto the model family of candidate sparse signals, we provide provable recovery guarantees. Developing a practical algorithm that can provably compute the required near-optimal projections remains a significant open problem, but we include simulation results using various heuristics that empirically exhibit superior performance to traditional recovery algorithms.", "paper_title": "Signal Space CoSaMP for Sparse Recovery With Redundant Dictionaries", "paper_id": "WOS:000324573500044"}