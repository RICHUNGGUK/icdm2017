{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "learning"}, {"score": 0.004741845603430361, "phrase": "integral_operators"}, {"score": 0.004634254474150777, "phrase": "large_number"}, {"score": 0.004359078118356132, "phrase": "spectral_clustering"}, {"score": 0.0042928648367867835, "phrase": "kernel_principal_components_analysis"}, {"score": 0.0038271712887391015, "phrase": "similarity_function"}, {"score": 0.0036553070575015344, "phrase": "empirical_data"}, {"score": 0.003334309053314909, "phrase": "important_problem"}, {"score": 0.002711109302199029, "phrase": "concentration_inequality"}, {"score": 0.0026698611202305715, "phrase": "hilbert_spaces"}, {"score": 0.0026091594819333654, "phrase": "new_much_simplified_proofs"}, {"score": 0.002472822097373027, "phrase": "spectral_approximation"}, {"score": 0.002255431275670053, "phrase": "spectral_properties"}, {"score": 0.0022041312401435346, "phrase": "graph_laplacian_operator"}, {"score": 0.0021049977753042253, "phrase": "von_luxburg_et_al"}], "paper_keywords": ["spectral convergence", " empirical operators", " learning integral operators", " perturbation methods"], "paper_abstract": "A large number of learning algorithms, for example, spectral clustering, kernel Principal Components Analysis and many manifold methods are based on estimating eigenvalues and eigenfunctions of operators defined by a similarity function or a kernel, given empirical data. Thus for the analysis of algorithms, it is an important problem to be able to assess the quality of such approximations. The contribution of our paper is two-fold: 1. We use a technique based on a concentration inequality for Hilbert spaces to provide new much simplified proofs for a number of results in spectral approximation. 2. Using these methods we provide several new results for estimating spectral properties of the graph Laplacian operator extending and strengthening results from von Luxburg et al. (2008).", "paper_title": "On Learning with Integral Operators", "paper_id": "WOS:000277186500018"}