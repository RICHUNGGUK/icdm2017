{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "bayesian"}, {"score": 0.04919531957169835, "phrase": "singular_learning_machines"}, {"score": 0.011149779729542132, "phrase": "monte_carlo"}, {"score": 0.004586531354697466, "phrase": "neural_networks"}, {"score": 0.00453113241842654, "phrase": "normal_mixtures"}, {"score": 0.004476399615305783, "phrase": "bayesian_networks"}, {"score": 0.004395532072377065, "phrase": "hidden_markov_models"}, {"score": 0.004161553532799662, "phrase": "practical_information_systems"}, {"score": 0.004061584718427419, "phrase": "learning_machines"}, {"score": 0.0038923605771735838, "phrase": "bayesian_learning"}, {"score": 0.0038453138708790385, "phrase": "better_generalization_performance"}, {"score": 0.0037988336463795963, "phrase": "maximum-likelihood_estimation"}, {"score": 0.0036627245728600073, "phrase": "huge_computational_cost"}, {"score": 0.0035530197642369464, "phrase": "bayesian_posterior_distribution"}, {"score": 0.0034887749053459584, "phrase": "singular_learning_machine"}, {"score": 0.00342568771304873, "phrase": "conventional_markov_chain"}, {"score": 0.003223494720348768, "phrase": "metropolis_algorithm"}, {"score": 0.0029966486574952715, "phrase": "mc"}, {"score": 0.0028195727965553367, "phrase": "improved_algorithm"}, {"score": 0.0027854565462509095, "phrase": "mcmc_method"}, {"score": 0.0023776656246300063, "phrase": "exchange_mc_method"}, {"score": 0.0023346234464901978, "phrase": "better_effect"}, {"score": 0.0022101055924375725, "phrase": "regular_learning_machines"}, {"score": 0.0021049977753042253, "phrase": "numerical_stochastic_complexity"}], "paper_keywords": ["Bayesian learning", " exchange Monte Carlo (MC) method", " Markov chain Monte Carlo (MCMC) method", " singular learning machines", " stochastic complexity"], "paper_abstract": "Many singular learning machines such as neural networks, normal mixtures, Bayesian networks, and hidden Markov models belong to singular learning machines and are widely used in practical information systems. In these learning machines, it is well known that Bayesian learning provides better generalization performance than maximum-likelihood estimation. However, it needs huge computational cost to sample from a Bayesian posterior distribution of a singular learning machine by a conventional Markov chain Monte Carlo (MCMC) method, such as the metropolis algorithm, because of singularities. Recently, the exchange Monte Carlo (MC) method, which is well known as an improved algorithm of MCMC method, has been proposed to apply to Bayesian neural network learning in the literature. In this paper, we propose the idea that the exchange MC method has a better effect on Bayesian learning in singular learning machines than that in regular learning machines, and show its effectiveness by comparing the numerical stochastic complexity with the theoretical one.", "paper_title": "Exchange Monte Carlo sampling from Bayesian posterior for singular learning machines", "paper_id": "WOS:000258182700009"}