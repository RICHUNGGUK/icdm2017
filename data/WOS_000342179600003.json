{"auto_keywords": [{"score": 0.004067635935640407, "phrase": "parallel_library"}, {"score": 0.0038668462001710314, "phrase": "data_management_details"}, {"score": 0.0035539019235553897, "phrase": "third_approach"}, {"score": 0.0034359094594153304, "phrase": "good_performance"}, {"score": 0.003349984456443527, "phrase": "underlying_library_structure"}, {"score": 0.003131178497790961, "phrase": "dense_and_sparse_data_management"}, {"score": 0.0029020077365708966, "phrase": "data_representation"}, {"score": 0.0027123819773059127, "phrase": "algorithmic_and_parallel_strategy_decisions"}, {"score": 0.002556625752785268, "phrase": "different_parallel_environments"}, {"score": 0.002471661547432869, "phrase": "new_approach"}], "paper_keywords": ["Data partition", " mapping techniques", " sparse structures", " parallel libraries"], "paper_abstract": "Dealing with both dense and sparse data in parallel environments usually leads to two different approaches: To rely on a monolithic, hard-to-modify parallel library, or to code all data management details by hand. In this paper we propose a third approach, that delivers good performance while the underlying library structure remains modular and extensible. Our solution integrates dense and sparse data management using a common interface, that also decouples data representation, partitioning, and layout from the algorithmic and parallel strategy decisions of the programmer. Our experimental results in different parallel environments show that this new approach combines the flexibility obtained when the programmer handles all the details with a performance comparable to the use of a state-of-the-art, sparse matrix parallel library.", "paper_title": "Blending Extensibility and Performance in Dense and Sparse Parallel Data Management", "paper_id": "WOS:000342179600003"}