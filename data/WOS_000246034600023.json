{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "expected_length"}, {"score": 0.0496729815270419, "phrase": "optimal_one-to-one_codes"}, {"score": 0.008351817717340806, "phrase": "one-to-one_encodings"}, {"score": 0.005345253402507028, "phrase": "source_symbol_probabilities"}, {"score": 0.004566139263029594, "phrase": "arbitrarily_tight_lower_bounds"}, {"score": 0.0045556080393342165, "phrase": "discrete_memoryless_source"}, {"score": 0.0044786435725543685, "phrase": "\"one-shot\"_encodings"}, {"score": 0.004347057700479576, "phrase": "source_symbol"}, {"score": 0.004112812699639956, "phrase": "source_symbols"}, {"score": 0.00387459052649752, "phrase": "last_message"}, {"score": 0.003776750773624222, "phrase": "next_message"}, {"score": 0.003542786326740931, "phrase": "empty_codeword"}, {"score": 0.003423969509052361, "phrase": "lower_and_upper_bounds"}, {"score": 0.0032255172568437965, "phrase": "known_tight"}, {"score": 0.0030127172247606812, "phrase": "source_alphabet"}, {"score": 0.0029871209444889716, "phrase": "finite_and_partial_information"}, {"score": 0.0027194778713860715, "phrase": "side_information"}, {"score": 0.0021049977753042253, "phrase": "upper_bound"}], "paper_keywords": ["nonprefix codes", " one-to-one codes", " source coding"], "paper_abstract": "In this correspondence, we consider one-to-one encodings for a discrete memoryless source, which are \"one-shot\" encodings associating a distinct codeword with each source symbol. Such encodings could be employed when only a single source symbol rather than a sequence of source symbols needs to be transmitted. For example, such a situation can arise when the last message must be acknowledged before the next message can be transmitted. We consider two slightly different types of one-to-one encodings (depending on whether the empty codeword is used or not) and obtain lower and upper bounds on the expected length of optimal one-to-one codes. We first give an extension of a known tight lower bound on the expected length of optimal one-to-one codes for the case that the the size of the source alphabet is finite and partial information about the source symbol probabilities is available. As expected, our lower bound is no less than the previously known lower bound obtained without side information about the source symbol probabilities. We then consider the case that the source entropy is available and derive arbitrarily tight lower bounds on the expected length of optimal one-to-one codes. We also derive arbitrarily tight lower bounds for the case that the source entropy and the probability of the most likely source symbol are available. Finally, given that the probability of the most likely source symbol is available, we obtain an upper bound on the expected length of optimal one-to-one codes. Our upper bound is tighter than the best upper bound known in the literature.", "paper_title": "Bounds on the expected length of optimal one-to-one codes", "paper_id": "WOS:000246034600023"}