{"auto_keywords": [{"score": 0.04058608302065266, "phrase": "hmm"}, {"score": 0.00481495049065317, "phrase": "encoded_signal_processing_and_fast_artificial_neural_networks"}, {"score": 0.004494570360108983, "phrase": "frequency_domain_analysis"}, {"score": 0.004248294537944227, "phrase": "shape_analysis"}, {"score": 0.003916098498242888, "phrase": "k-nn_classifiers"}, {"score": 0.003819187440994939, "phrase": "kohonen_som"}, {"score": 0.003771631577951067, "phrase": "neural_networks"}, {"score": 0.003454858296390957, "phrase": "musical_instruments"}, {"score": 0.0034118234596993836, "phrase": "isolated_notes"}, {"score": 0.0032246835734680377, "phrase": "time_encoded_signal_processing_method"}, {"score": 0.0031646057802503526, "phrase": "simple_matrices"}, {"score": 0.003125175084962886, "phrase": "complex_sound_waveforms"}, {"score": 0.003066945490483524, "phrase": "instrument_note_encoding"}, {"score": 0.0028805474861014722, "phrase": "fast_artificial_neural_network"}, {"score": 0.0027741761880779535, "phrase": "instrument_recognition"}, {"score": 0.0027395968397212053, "phrase": "promising_results"}, {"score": 0.0027054473441439422, "phrase": "organ_classification"}, {"score": 0.0025892330566358503, "phrase": "evaluation_material"}, {"score": 0.002431797888365548, "phrase": "microsoft_synth"}, {"score": 0.0024014759148123736, "phrase": "creative_sb"}, {"score": 0.002327310963701377, "phrase": "yamaha"}, {"score": 0.002255431275670053, "phrase": "edirol_soft-synth"}, {"score": 0.0022273034991008326, "phrase": "kontakt_player"}, {"score": 0.0021049977753042253, "phrase": "iowa_university_database"}], "paper_keywords": [""], "paper_abstract": "Traditionally, musical instrument recognition is mainly based on frequency domain analysis (sinusoidal analysis, cepstral coefficients) and shape analysis to extract a set of various features. Instruments are usually classified using k-NN classifiers, HMM, Kohonen SOM and Neural Networks. In this work, we describe a system for the recognition of musical instruments from isolated notes. We are introducing the use of a Time Encoded Signal Processing method to produce simple matrices from complex sound waveforms, for instrument note encoding and recognition. These matrices are presented to a Fast Artificial Neural Network (FANN) to perform instrument recognition with promising results in organ classification and reduced computational cost. The evaluation material consists of 470 tones from 19 musical instruments synthesized with 5 wide used synthesizers (Microsoft Synth, Creative SB Live! Synth, Yamaha VL-70m Tone Generator, Edirol Soft-Synth, Kontakt Player) and 84 isolated notes from 20 western orchestral instruments (Iowa University Database).", "paper_title": "Musical instrument recognition and classification using time encoded signal processing and fast artificial neural networks", "paper_id": "WOS:000238053100024"}