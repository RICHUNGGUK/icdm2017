{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "video_sequences"}, {"score": 0.013757171567815652, "phrase": "spatio-temporal_pattern"}, {"score": 0.0047292449487169345, "phrase": "local_feature_dynamics"}, {"score": 0.0038119123317396954, "phrase": "visual_content"}, {"score": 0.0037104876694493815, "phrase": "video_sequence"}, {"score": 0.003044455555031339, "phrase": "captured_scene"}, {"score": 0.0026841368358805433, "phrase": "estimated_global_motion_model"}, {"score": 0.002543043781904587, "phrase": "extracted_local_features"}, {"score": 0.002366361492754389, "phrase": "probabilistic_model"}, {"score": 0.0023033100935570755, "phrase": "visual_pattern"}, {"score": 0.0022019274077124795, "phrase": "user_interaction"}, {"score": 0.0021049977753042253, "phrase": "relevance-feedback_loop"}], "paper_keywords": [""], "paper_abstract": "This paper addresses the problem of retrieving video sequences that contain a spatio-temporal pattern queried by a user. To achieve this, the visual content of each video sequence is first decomposed through the analysis of its local feature dynamics. Camera motion of the sequence, background and objects present in the captured scene and events occurring within it are represented respectively by the parameters of the estimated global motion model, the appearance of the extracted local features and their trajectories. At query-time, a probabilistic model of the visual pattern is estimated from the user interaction, captured through a relevance-feedback loop. We show that the method permits to efficiently retrieve video sequences that share, even partially, a spatio-temporal pattern.", "paper_title": "Interactive retrieval of video sequences from local feature dynamics", "paper_id": "WOS:000236463100011"}