{"auto_keywords": [{"score": 0.04793931676065058, "phrase": "new_set"}, {"score": 0.04141908209413028, "phrase": "face_identification"}, {"score": 0.02916651766323831, "phrase": "computer_vision"}, {"score": 0.00481495049065317, "phrase": "biologically_inspired_features"}, {"score": 0.0047784273577245505, "phrase": "face_processing"}, {"score": 0.004565007074039171, "phrase": "visual_features"}, {"score": 0.004478907336898875, "phrase": "feed-forward_model"}, {"score": 0.004428025469002531, "phrase": "primate_visual_object_recognition_pathway"}, {"score": 0.004377719744570291, "phrase": "riesenhuber"}, {"score": 0.00434450062249438, "phrase": "poggio"}, {"score": 0.003980032599437366, "phrase": "best_current_representations"}, {"score": 0.003919830848124645, "phrase": "facial_expression_recognition"}, {"score": 0.0038900709793274484, "phrase": "previous_work"}, {"score": 0.0038166522763373434, "phrase": "riesenhuber_and_poggio_model_features"}, {"score": 0.0037589124802364384, "phrase": "high_level"}, {"score": 0.0037020429480068653, "phrase": "object_recognition_tasks"}, {"score": 0.003674086678852706, "phrase": "serre"}, {"score": 0.00356359155432419, "phrase": "ieee_comput"}, {"score": 0.003190584226787897, "phrase": "expression_recognition"}, {"score": 0.0031065494839328956, "phrase": "feret"}, {"score": 0.0028783840417661694, "phrase": "local_binary_patterns"}, {"score": 0.0028565082986974602, "phrase": "ahonen"}, {"score": 0.002616544154458438, "phrase": "gradient_features"}, {"score": 0.0025966551471586987, "phrase": "dalal"}, {"score": 0.0025573230377914143, "phrase": "triggs"}, {"score": 0.0025185863209688016, "phrase": "international_conference"}, {"score": 0.002324620886282579, "phrase": "shared_lower_level_features"}, {"score": 0.0022719915771356354, "phrase": "recognition_specific_higher_level_features"}, {"score": 0.0022120914337992034, "phrase": "electrophysiology_and_functional_magnetic_resonance_imaging_experiments"}, {"score": 0.002129243122440408, "phrase": "complete_recognition_problem"}, {"score": 0.0021049977753042253, "phrase": "biologically_plausible_way"}], "paper_keywords": ["biologically motivated computer vision", " face identification", " face recognition", " learning distance measures", " kernel methods"], "paper_abstract": "In this paper, we show that a new set of visual features, derived from a feed-forward model of the primate visual object recognition pathway proposed by Riesenhuber and Poggio (R&P Model) (Nature Neurosci. 2(11):10191025, 1999) is capable of matching the performance of some of the best current representations for face identification and facial expression recognition. Previous work has shown that the Riesenhuber and Poggio Model features can achieve a high level of performance on object recognition tasks (Serre, T., et al. in IEEE Comput. Vis. Pattern Recognit. 2:994-1000, 2005). Here we modify the R&P model in order to create a new set of features useful for face identification and expression recognition. Results from tests on the FERET, ORL and AR datasets show that these features are capable of matching and sometimes outperforming other top visual features such as local binary patterns (Ahonen, T., et al. in 8th European Conference on Computer Vision, pp. 469-481, 2004) and histogram of gradient features (Dalal, N., Triggs, B. in International Conference on Computer Vision & Pattern Recognition, pp. 886-893, 2005). Having a model based on shared lower level features, and face and object recognition specific higher level features, is consistent with findings from electrophysiology and functional magnetic resonance imaging experiments. Thus, our model begins to address the complete recognition problem in a biologically plausible way.", "paper_title": "Using biologically inspired features for face processing", "paper_id": "WOS:000252185800006"}