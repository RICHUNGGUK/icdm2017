{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "linear_discriminant_analysis"}, {"score": 0.0314742454486009, "phrase": "least_square_solution"}, {"score": 0.004718801082937621, "phrase": "lda"}, {"score": 0.0044398358177815305, "phrase": "batch_way"}, {"score": 0.00395101799538683, "phrase": "concept_drift"}, {"score": 0.0032251796659158696, "phrase": "large_computational_cost"}, {"score": 0.0030811340338342454, "phrase": "new_online_lda_algorithm"}, {"score": 0.0030500051941781034, "phrase": "ls-olda"}, {"score": 0.0027276279046603755, "phrase": "lda."}, {"score": 0.002618995204424126, "phrase": "exact_least_square_solution"}, {"score": 0.002342048999008582, "phrase": "n_instances"}, {"score": 0.0023183698048498797, "phrase": "d-dimensional_space"}, {"score": 0.002260211578368138, "phrase": "experimental_results"}, {"score": 0.0021923400552366756, "phrase": "high_accuracy"}, {"score": 0.00217017119491777, "phrase": "low_time_cost"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Dimensionality reduction", " Linear discriminant analysis", " Online learning", " Data stream", " Least squares"], "paper_abstract": "Linear discriminant analysis (LDA) is one of the most widely used supervised dimensionality reduction algorithms. Standard LDA performs in batch way which needs all the data be available before learning. However, in many real world applications, data is coming continuously over time and sometimes undergoing concept drift, so it is more desirable to only keep the most recent data by using a certain slide window. Several incremental LDA algorithms have been developed and achieved success, however, they do not consider the case when an instance is deleted and require large computational cost. In this paper, we propose a new online LDA algorithm, LS-OLDA, based on the least square solution of LDA. When an instance is inserted or deleted, it dynamically updates the least square solution of LDA. Our analysis reveals that this algorithm produces the exact least square solution of batch LDA, while its computational cost is O(min(n; d) x d + nk) for one update on dataset containing n instances in d-dimensional space with k classes. Experimental results show that our proposed algorithm could achieve high accuracy with low time cost. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Least squares online linear discriminant analysis", "paper_id": "WOS:000296214900157"}