{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "human_behavior_recognition"}, {"score": 0.04971245563968758, "phrase": "machine_vision"}, {"score": 0.049348918639928865, "phrase": "intelligent_environments"}, {"score": 0.029237135610446486, "phrase": "proposed_fuzzy_system"}, {"score": 0.004687159050154687, "phrase": "recent_years"}, {"score": 0.004633429997452688, "phrase": "significant_progress"}, {"score": 0.004323690117778359, "phrase": "users'_actions"}, {"score": 0.0042250952759280225, "phrase": "needed_services"}, {"score": 0.004065721092116729, "phrase": "user_comfort"}, {"score": 0.003636605792981828, "phrase": "known_spatial_locations"}, {"score": 0.003608732492631878, "phrase": "temporal_segmentations"}, {"score": 0.0035673211706948576, "phrase": "computationally_expensive_approaches"}, {"score": 0.0034993519231560637, "phrase": "window_search"}, {"score": 0.003459191419478298, "phrase": "spatio-temporal_volume"}, {"score": 0.0032526334220034326, "phrase": "high_uncertainty_levels"}, {"score": 0.0031906408161077766, "phrase": "real-world_applications"}, {"score": 0.0031178024467857215, "phrase": "novel_fuzzy_machine_vision-based_framework"}, {"score": 0.003011641380351577, "phrase": "model-based_feature"}, {"score": 0.0029428772818833166, "phrase": "visual_feature_cues"}, {"score": 0.0029203055813347874, "phrase": "silhouette_slices"}, {"score": 0.0028979065012624044, "phrase": "movement_speed"}, {"score": 0.002864628676257225, "phrase": "human_silhouette"}, {"score": 0.002842655426951218, "phrase": "video_sequences"}, {"score": 0.0026218430041123164, "phrase": "membership_functions"}, {"score": 0.0025619562094446884, "phrase": "behavior_recognition"}, {"score": 0.0025034338848015166, "phrase": "best_candidate's_behavior_category"}, {"score": 0.002474674704809152, "phrase": "highest_output_degree"}, {"score": 0.002446245096967702, "phrase": "recognized_behavior"}, {"score": 0.00236289633510808, "phrase": "publicly_available_weizmann_human_action_dataset"}, {"score": 0.0023178219772486868, "phrase": "average_recognition_accuracy"}, {"score": 0.002256155453630723, "phrase": "traditional_non-fuzzy_systems"}, {"score": 0.0022302306304023602, "phrase": "hidden_markov_models"}, {"score": 0.0021049977753042253, "phrase": "weizmann_dataset"}], "paper_keywords": ["Fuzzy logic system", " Human behavior recognition", " Action classification"], "paper_abstract": "The recent years have witnessed significant progress in the automation of human behavior recognition using machine vision in order to realize intelligent environments which are capable of detecting users' actions and gestures so that the needed services can be provided automatically and instantly for maximizing the user comfort and safety as well as minimizing energy. However, the majority of traditional human behavior machine vision-based recognition approaches rely on assumptions (such as known spatial locations and temporal segmentations) or computationally expensive approaches (such as sliding window search through a spatio-temporal volume). Hence, it is difficult for such methods to scale up and handle the high uncertainty levels and complexities available in real-world applications. This paper proposes a novel fuzzy machine vision-based framework for efficient humans' behavior recognition. A model-based feature set is utilized to extract visual feature cues including silhouette slices and movement speed from the human silhouette in video sequences which are analyzed as inputs by the proposed fuzzy system. We have employed fuzzy c-means clustering to learn the membership functions of the proposed fuzzy system. The behavior recognition was implemented via selecting the best candidate's behavior category with the highest output degree as the recognized behavior. We have successfully tested our system on the publicly available Weizmann human action dataset where our fuzzy-based system produced an average recognition accuracy of 94.03 %, which outperformed the traditional non-fuzzy systems based on hidden Markov models and other state-of-the-art approaches which were applied on the Weizmann dataset.", "paper_title": "A fuzzy logic-based system for the automation of human behavior recognition using machine vision in intelligent environments", "paper_id": "WOS:000347836800019"}