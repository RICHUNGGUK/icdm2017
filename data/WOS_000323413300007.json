{"auto_keywords": [{"score": 0.04768967676542323, "phrase": "neural_networks"}, {"score": 0.007530829432661563, "phrase": "naphtha_dry_point_soft_sensor"}, {"score": 0.007184443750789889, "phrase": "predicting_performance"}, {"score": 0.0057887001511306956, "phrase": "hidden_layer"}, {"score": 0.0051649624949949, "phrase": "redundant_nodes"}, {"score": 0.00481495049065317, "phrase": "neural_network"}, {"score": 0.004521179256835894, "phrase": "important_role"}, {"score": 0.004312622975366672, "phrase": "main_flaws"}, {"score": 0.00409748471133883, "phrase": "computational_resource"}, {"score": 0.003986103192038901, "phrase": "multiple_linear_regression"}, {"score": 0.003684213587410217, "phrase": "initial_three-layer_network"}, {"score": 0.003528046880781907, "phrase": "bp"}, {"score": 0.003405109584265324, "phrase": "correlation_analysis"}, {"score": 0.0033651019362620866, "phrase": "hidden-layer_output"}, {"score": 0.00327356326590461, "phrase": "redundant_hidden_nodes"}, {"score": 0.003085681391556093, "phrase": "multiple_linear_regression_model"}, {"score": 0.0029781530607129653, "phrase": "expected_input"}, {"score": 0.002943147037670826, "phrase": "output_layer"}, {"score": 0.002851790448644913, "phrase": "inverse_function"}, {"score": 0.00281826552772148, "phrase": "output-layer_node"}, {"score": 0.0026986685585382347, "phrase": "optimal_structure"}, {"score": 0.002594342451017824, "phrase": "best_predicting_performance"}, {"score": 0.002259883463607508, "phrase": "soft_sensor"}, {"score": 0.002146926767291475, "phrase": "optimal_predicting_performance"}, {"score": 0.0021049977753042253, "phrase": "optimal_hidden_nodes"}], "paper_keywords": ["Neural networks", " Correlation pruning algorithm", " Multiple linear regression", " Soft sensor"], "paper_abstract": "Structure and weight of neural networks play an important role in the predicting performance of neural networks. In order to overcome the main flaws of neural networks, such as under-fitting, over-fitting or wasting computational resource, correlation pruning algorithm combined with multiple linear regression (CPA-MLR) is proposed to optimize the structure and weight of neural networks. Firstly, an initial three-layer network with the maximum nodes of hidden layer is selected, and BP is employed to train it. Secondly, correlation analysis of the hidden-layer output is carried out to confirm the redundant hidden nodes. Thirdly, the redundant nodes will be deleted one by one, and a multiple linear regression model between the output of the hidden layer and the expected input of the output layer, which can be obtained through the inverse function of the output-layer node, is employed to obtain their optimal weight. Finally, the optimal structure of the neural networks, which is corresponding to the best predicting performance of the neural networks, is obtained. Further, a practical example, that is developing naphtha dry point soft sensor, is employed to illustrate the performance of CPA-MLR. The results show that the predicting performance of the soft sensor is improved and then decreased with deleting the redundant nodes, and the optimal predicting performance is obtained with the optimal hidden nodes.", "paper_title": "Structure and weight optimization of neural network based on CPA-MLR and its application in naphtha dry point soft sensor", "paper_id": "WOS:000323413300007"}