{"auto_keywords": [{"score": 0.04583834963802334, "phrase": "input_images"}, {"score": 0.04282129453947795, "phrase": "common_labels"}, {"score": 0.00481495049065317, "phrase": "continuity-biased_bi-layer_sparsity_priors"}, {"score": 0.004640079189342692, "phrase": "fully_annotated_labels"}, {"score": 0.004611554879923759, "phrase": "image_level"}, {"score": 0.004569095351567258, "phrase": "contextually_derived_semantic_regions"}, {"score": 0.004471530397729526, "phrase": "collective_manner"}, {"score": 0.004362564831572539, "phrase": "label_annotations"}, {"score": 0.004322387850491499, "phrase": "basic_idea"}, {"score": 0.004191106618363275, "phrase": "patch_correspondence"}, {"score": 0.00405127920820053, "phrase": "image_pairs"}, {"score": 0.004013957450249313, "phrase": "correlated_patches"}, {"score": 0.0036477941360224435, "phrase": "rich_cues"}, {"score": 0.003625347557965931, "phrase": "variant_scales"}, {"score": 0.0035808664384880213, "phrase": "individual_patches"}, {"score": 0.0035369291417564606, "phrase": "patch-level_feature_descriptors"}, {"score": 0.0034613276345111573, "phrase": "sparse_representation_formulation"}, {"score": 0.003397809453525626, "phrase": "semantic_region"}, {"score": 0.0032540816985401704, "phrase": "underlying_philosophy"}, {"score": 0.003194354458513131, "phrase": "image_region"}, {"score": 0.0031260524791486347, "phrase": "image_patches"}, {"score": 0.0030123335878664064, "phrase": "label_propagation"}, {"score": 0.0029570303644956128, "phrase": "selected_patches"}, {"score": 0.0028494425496120228, "phrase": "patch_and_image_level"}, {"score": 0.0027036751290702406, "phrase": "larger-size_patches"}, {"score": 0.002471973283582411, "phrase": "reconstruction_coefficients"}, {"score": 0.0024416087858984644, "phrase": "image_labels"}, {"score": 0.0024190798397126924, "phrase": "matched_patches"}, {"score": 0.0022740957662393223, "phrase": "proposed_continuity-biased_bi-layer_sparse_representation_formulation"}, {"score": 0.0022048882869630114, "phrase": "new_testing_images"}, {"score": 0.0021913010538173825, "phrase": "extensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "image_annotation"}], "paper_keywords": ["Algorithms", " Measurement", " Theory", " Label-to-Region", " sparse representation", " bag-of-hierarchical-patch", " image annotation"], "paper_abstract": "In this work, we investigate how to reassign the fully annotated labels at image level to those contextually derived semantic regions, namely Label-to-Region (L2R), in a collective manner. Given a set of input images with label annotations, the basic idea of our approach to L2R is to first discover the patch correspondence across images, and then propagate the common labels shared in image pairs to these correlated patches. Specially, our approach consists of following aspects. First, each of the input images is encoded as a Bag-of-Hierarchical-Patch (BOP) for capturing the rich cues at variant scales, and the individual patches are expressed by patch-level feature descriptors. Second, we present a sparse representation formulation for discovering how well an image or a semantic region can be robustly reconstructed by all the other image patches from the input image set. The underlying philosophy of our formulation is that an image region can be sparsely reconstructed with the image patches belonging to the other images with common labels, while the robustness in label propagation across images requires that these selected patches come from very few images. This preference of being sparse at both patch and image level is named bi-layer sparsity prior. Meanwhile, we enforce the preference of choosing larger-size patches in reconstruction, referred to as continuity-biased prior in this work, which may further enhance the reliability of L2R assignment. Finally, we harness the reconstruction coefficients to propagate the image labels to the matched patches, and fuse the propagation results over all patches to finalize the L2R task. As a by-product, the proposed continuity-biased bi-layer sparse representation formulation can be naturally applied to perform image annotation on new testing images. Extensive experiments on three public image datasets clearly demonstrate the effectiveness of our proposed framework in both L2R assignment and image annotation.", "paper_title": "Label-to-Region with Continuity-Biased Bi-Layer Sparsity Priors", "paper_id": "WOS:000312211900002"}