{"auto_keywords": [{"score": 0.04762225647372066, "phrase": "feature_selection"}, {"score": 0.015719716506582538, "phrase": "differential_evolution"}, {"score": 0.0047395356621991935, "phrase": "statistical_repair_mechanism"}, {"score": 0.0046164478775379105, "phrase": "fundamental_motivations"}, {"score": 0.004402854153653114, "phrase": "dimensionality_problem"}, {"score": 0.004265953661191515, "phrase": "novel_feature_selection_method"}, {"score": 0.004068510313497539, "phrase": "optimization_method"}, {"score": 0.0040047396607954325, "phrase": "proposed_repair_mechanism"}, {"score": 0.003941964605885606, "phrase": "feature_distribution_measures"}, {"score": 0.00388016972840459, "phrase": "new_method"}, {"score": 0.003799275630862259, "phrase": "defs"}, {"score": 0.003720060615588018, "phrase": "de_float_number_optimizer"}, {"score": 0.0036617315529835497, "phrase": "combinatorial_optimization_problem"}, {"score": 0.003312901888725435, "phrase": "roulette_wheel_structure"}, {"score": 0.0028432828877281388, "phrase": "proposed_defs"}, {"score": 0.0027547408718334603, "phrase": "optimal_subsets"}, {"score": 0.0026689487424251907, "phrase": "varying_dimensionality"}, {"score": 0.0025052769325080255, "phrase": "wavelet_packet_transform"}, {"score": 0.0024789919010024188, "phrase": "wpt"}, {"score": 0.0024529757621396717, "phrase": "best_basis"}, {"score": 0.0024272350606639147, "phrase": "classification_problems"}, {"score": 0.0023146962503449186, "phrase": "feature_extraction_process"}, {"score": 0.0022904032758108775, "phrase": "practical_results"}, {"score": 0.002219040041886641, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Feature evaluation and selection", " Feature extraction or construction", " Pattern recognition"], "paper_abstract": "One of the fundamental motivations for feature selection is to overcome the curse of dimensionality problem. This paper presents a novel feature selection method utilizing a combination of differential evolution (DE) optimization method and a proposed repair mechanism based on feature distribution measures. The new method, abbreviated as DEFS, utilizes the DE float number optimizer in the combinatorial optimization problem of feature selection. In order to make the solutions generated by the float-optimizer suitable for feature selection, a roulette wheel structure is constructed and supplied with the probabilities of features distribution. These probabilities are constructed during iterations by identifying the features that contribute to the most promising solutions. The proposed DEFS is used to search for optimal subsets of features in datasets with varying dimensionality. It is then utilized to aid in the selection of Wavelet Packet Transform (WPT) best basis for classification problems, thus acting as a part of a feature extraction process. Practical results indicate the significance of the proposed method in comparison with other feature selection methods. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Feature subset selection using differential evolution and a statistical repair mechanism", "paper_id": "WOS:000291118500089"}