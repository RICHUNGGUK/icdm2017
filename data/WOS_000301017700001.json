{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "generative_mixture_models"}, {"score": 0.003916098498242888, "phrase": "multiple_classes"}, {"score": 0.0038326698261576023, "phrase": "single-cluster_assignment_assumptions"}, {"score": 0.0036395944934310524, "phrase": "single-cluster_data_assignment"}, {"score": 0.003486123304074186, "phrase": "modeled_data_points"}, {"score": 0.0033831020259469085, "phrase": "mm"}, {"score": 0.0032820385246266773, "phrase": "membership_probabilities"}, {"score": 0.0032398798149196432, "phrase": "data_point"}, {"score": 0.0029980260560551982, "phrase": "clustered_data_sets"}, {"score": 0.0028591768694918, "phrase": "equal_evidence"}, {"score": 0.002680114113899346, "phrase": "possibilistic_formulation"}, {"score": 0.0026342827320931937, "phrase": "possibilistic_clustering"}, {"score": 0.002566997205079849, "phrase": "possibilistic_data_partitions"}, {"score": 0.0025230952890994236, "phrase": "obtained_membership_values"}, {"score": 0.0023958326775913165, "phrase": "data_points"}, {"score": 0.002294686545883412, "phrase": "efficient_maximum-likelihood_fitting_algorithm"}, {"score": 0.002197801146305747, "phrase": "objective_evaluation"}, {"score": 0.0021601997088758957, "phrase": "benchmark_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Possibilistic clustering", " Finite mixture models"], "paper_abstract": "Generative mixture models (MMs) provide one of the most popular methodologies for unsupervised data clustering. MMs are formulated on the basis of the assumption that each observation derives from (belongs to) a single cluster. However, in many applications, data may intuitively belong to multiple classes, thus rendering the single-cluster assignment assumptions of MMs irrelevant. Furthermore, even in applications where a single-cluster data assignment is required, the induced multinomial allocation of the modeled data points to the clusters derived by a MM, imposing the constraint that the membership probabilities of a data point across clusters sum to one, makes MMs very vulnerable to the presence of outliers in the clustered data sets, and renders them ineffective in discriminating between cases of equal evidence or ignorance. To resolve these issues, in this paper we introduce a possibilistic formulation of MMs. Possibilistic clustering is a methodology that yields possibilistic data partitions, with the obtained membership values being interpreted as degrees of possibility (compatibilities) of the data points with respect to the various clusters. We provide an efficient maximum-likelihood fitting algorithm for the proposed model, and we conduct an objective evaluation of its efficacy using benchmark data. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "A possibilistic clustering approach toward generative mixture models", "paper_id": "WOS:000301017700001"}