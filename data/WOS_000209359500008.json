{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "non-stationary_partially_observable_dynamical_systems"}, {"score": 0.004617328272121826, "phrase": "distributed_recurrent_self-organizing_architecture"}, {"score": 0.004401342842183475, "phrase": "current_state"}, {"score": 0.004322967486451877, "phrase": "dynamical_system"}, {"score": 0.0041703614123283165, "phrase": "recent_observations"}, {"score": 0.003857871979942733, "phrase": "recurrent_network"}, {"score": 0.0035687137873965684, "phrase": "large_scale"}, {"score": 0.003526186748088922, "phrase": "neural_architectures"}, {"score": 0.0033812801309408514, "phrase": "strictly_local_fine-grained_computation"}, {"score": 0.0032036590920314725, "phrase": "recurrent_architecture"}, {"score": 0.0030171910207671205, "phrase": "unexpected_dynamical_effects"}, {"score": 0.0028931405607654495, "phrase": "learned_mappings"}, {"score": 0.002841545331522694, "phrase": "presented_architecture"}, {"score": 0.002790867657645595, "phrase": "cognitive_ability"}, {"score": 0.002644179117033107, "phrase": "mesoscopic_level"}, {"score": 0.002581477142020187, "phrase": "intermediate_level"}, {"score": 0.0025051811853674215, "phrase": "neurons_simulation"}, {"score": 0.0024604876113911173, "phrase": "complex_dynamics"}, {"score": 0.0022085455097790537, "phrase": "neuronal_activities"}, {"score": 0.0021821915946356168, "phrase": "high_level_cognition"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Recurrent self-organization", " Partially observable", " dynamical systems", " Neural fields"], "paper_abstract": "In this paper, a distributed recurrent self-organizing architecture is presented. It can extract the current state of a dynamical system from the sequence of the recent observations provided by this system, even if they are ambiguous. The recurrent network is an adaptation of RecSOM to the context of the simulation of large scale distributed neural architectures, since it relies on a strictly local fine-grained computation. The experiments show the ability of the recurrent architecture to capture the states, but also exhibit some unexpected dynamical effects, like some instabilities of the learned mappings. The presented architecture addresses the cognitive ability to set up representations from sequences at a mesoscopic level. At that intermediate level, between cognition and neurons simulation, some complex dynamics is unveiled. It needs to be identified and understood in order to bridge the gap between neuronal activities and high level cognition. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Distributed recurrent self-organization for tracking the state of non-stationary partially observable dynamical systems", "paper_id": "WOS:000209359500008"}