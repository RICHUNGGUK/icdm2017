{"auto_keywords": [{"score": 0.04961597900198376, "phrase": "deep_neural_networks"}, {"score": 0.00481495049065317, "phrase": "short_utterances"}, {"score": 0.004476399615305783, "phrase": "automatic_language_identification"}, {"score": 0.004433109387551987, "phrase": "lid"}, {"score": 0.0043477114072437316, "phrase": "short_test_utterances"}, {"score": 0.004222707054751191, "phrase": "acoustic_modelling"}, {"score": 0.004181839414007266, "phrase": "speech_recognition"}, {"score": 0.0038499929374478125, "phrase": "short-term_acoustic_features"}, {"score": 0.003614044704141927, "phrase": "real-time_applications"}, {"score": 0.0034760655218366, "phrase": "language_identification"}, {"score": 0.003409057326528229, "phrase": "new_frame"}, {"score": 0.003359647377874098, "phrase": "test_utterance"}, {"score": 0.003278878522165818, "phrase": "different_aspects"}, {"score": 0.00312310128226407, "phrase": "required_training_data"}, {"score": 0.003048001809453513, "phrase": "hidden_layers"}, {"score": 0.0029747028229638625, "phrase": "contextual_information"}, {"score": 0.0028890603352364273, "phrase": "test_utterance_duration"}, {"score": 0.002711842889248926, "phrase": "frame_posteriors"}, {"score": 0.0025829353063908256, "phrase": "nist_language_recognition_evaluation"}, {"score": 0.0023431692392929353, "phrase": "different_google_services"}, {"score": 0.002320449502337321, "phrase": "reported_results"}, {"score": 0.002297949552105756, "phrase": "relative_improvements"}, {"score": 0.002242647404307089, "phrase": "i-vector_system"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["DNNs", " Real-time LID", " i-vectors"], "paper_abstract": "This work addresses the use of deep neural networks (DNNs) in automatic language identification (LID) focused on short test utterances. Motivated by their recent success in acoustic modelling for speech recognition, we adapt DNNs to the problem of identifying the language in a given utterance from the short-term acoustic features. We show how DNNs are particularly suitable to perform LID in real-time applications, due to their capacity to emit a language identification posterior at each new frame of the test utterance. We then analyse different aspects of the system, such as the amount of required training data, the number of hidden layers, the relevance of contextual information and the effect of the test utterance duration. Finally, we propose several methods to combine frame-by-frame posteriors. Experiments are conducted on two different datasets: the public NIST Language Recognition Evaluation 2009 (3 s task) and a much larger corpus (of 5 million utterances) known as oogle 5M LID, obtained from different Google Services. Reported results show relative improvements of DNNs versus the i-vector system of 40% in LRE09 3 second task and 76% in Google 5M LID. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Frame-by-frame language identification in short utterances using deep neural networks", "paper_id": "WOS:000350926600007"}