{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "visual_odometry"}, {"score": 0.04197982453634864, "phrase": "inertial_navigation_system"}, {"score": 0.0045855181084455444, "phrase": "monocular_visual_odometry"}, {"score": 0.004383406949799696, "phrase": "visual_odometry_algorithm"}, {"score": 0.004205973752866551, "phrase": "klt"}, {"score": 0.004081385289516914, "phrase": "rigid_transformation"}, {"score": 0.0040508247605225214, "phrase": "ransac_algorithm"}, {"score": 0.0039308449157320815, "phrase": "pedometer_and_digital_compass"}, {"score": 0.003785836059995376, "phrase": "incremental_movements"}, {"score": 0.003485304124598714, "phrase": "even_more_robust_and_accurate_localization_system"}, {"score": 0.003407549468745519, "phrase": "mentioned_localization_approaches"}, {"score": 0.0033315236647127734, "phrase": "extended_kalman_filter"}, {"score": 0.0030554300179552415, "phrase": "multiple_processor_cores"}, {"score": 0.003021141590548526, "phrase": "proposed_system"}, {"score": 0.002942619810718864, "phrase": "camera_and_inertial_sensors"}, {"score": 0.0028553693643045795, "phrase": "powerful_mobile_sensor_unit"}, {"score": 0.0028233196851239753, "phrase": "so-called_virtual_sensor"}, {"score": 0.002729307099580315, "phrase": "starting_point"}, {"score": 0.0026986685585382347, "phrase": "virtual_sensor"}, {"score": 0.0026384167183586015, "phrase": "advanced_sensor_unit"}, {"score": 0.0026186324161493225, "phrase": "mobile_robots"}, {"score": 0.002560162916190598, "phrase": "smartphone_application"}, {"score": 0.0025314183270805355, "phrase": "personal_navigation_system"}, {"score": 0.0024748913336907923, "phrase": "localization_system"}, {"score": 0.002437907960209364, "phrase": "experimental_results"}, {"score": 0.0023040642263522505, "phrase": "reference_trajectory"}, {"score": 0.002218933616777076, "phrase": "described_system"}, {"score": 0.0022022878843247257, "phrase": "big_potential"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual odometry", " Pedometer", " Compass", " Fusion", " Kalman filter", " Smartphone", " Robot", " Pedestrian"], "paper_abstract": "The paper presents the monocular visual odometry, inertial navigation system and the fusion of both these localization approaches. The visual odometry algorithm consists of four other algorithms, namely the camera calibration algorithm, KLT algorithm, algorithm for the estimation of rigid transformation and RANSAC algorithm. The inertial navigation system is based on a pedometer and digital compass. Both visual odometry and the inertial navigation system can determine the incremental movements and the positions of a robot or a pedestrian according to the world coordinate system. In order to get an even more robust and accurate localization system, the advantages of each mentioned localization approaches were combined by using the Extended Kalman Filter. The algorithms were fully implemented on a smartphone, where they were divided into several threads that could be performed simultaneously on multiple processor cores. The proposed system, which fuses information from the camera and inertial sensors, can convert the smartphone into a powerful mobile sensor unit or the so-called virtual sensor that returns relative position in relation to the starting point. This virtual sensor can be used as an advanced sensor unit on mobile robots or as part of a smartphone application which requires personal navigation system. The operation of the localization system is proved by experimental results which were obtained by attaching a smartphone on a pedestrian who walked along the reference trajectory drawn on the floor. In the experiments the described system showed big potential in many aspects since very good results were obtained. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Fusion of visual odometry and inertial navigation system on a smartphone", "paper_id": "WOS:000364893000010"}