{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "facial_animation_parameters"}, {"score": 0.0047563776685277314, "phrase": "multistream_hmms"}, {"score": 0.00458488025289647, "phrase": "automatic_facial_expression_recognition_system"}, {"score": 0.004312622975366676, "phrase": "different_streams"}, {"score": 0.004260134699483774, "phrase": "facial_expression_information"}, {"score": 0.0041825926310470616, "phrase": "hidden_markov_models"}, {"score": 0.0038862297330905836, "phrase": "automatic_multistream_hmm_facial_expression_recognition_system"}, {"score": 0.0037231102027070724, "phrase": "proposed_system"}, {"score": 0.0033961782274326948, "phrase": "facial_expression_classification"}, {"score": 0.0031747618267940155, "phrase": "outer-lip_contours"}, {"score": 0.002931569771634119, "phrase": "single-stream_hmms"}, {"score": 0.0028430608076324727, "phrase": "outer-lip_and_eyebrow_faps"}, {"score": 0.0027403605798830984, "phrase": "multistream_hmm_approach"}, {"score": 0.0026576091519087065, "phrase": "facial_expression"}, {"score": 0.0026252188942022282, "phrase": "fap"}, {"score": 0.00259320616168125, "phrase": "dependent_stream_reliability_weights"}, {"score": 0.0025459275963373496, "phrase": "stream_weights"}, {"score": 0.002453934333239467, "phrase": "facial_expression_recognition_results"}, {"score": 0.002409188797323273, "phrase": "fap_streams"}, {"score": 0.0023221248824337576, "phrase": "proposed_multistream_hmm_facial_expression_system"}, {"score": 0.002265833357217618, "phrase": "stream_reliability_weights"}, {"score": 0.002224510044064184, "phrase": "relative_reduction"}, {"score": 0.002183938718432764, "phrase": "facial_expression_recognition_error"}, {"score": 0.0021049977753042253, "phrase": "single-stream_hmm_system"}], "paper_keywords": ["facial expression recognition", " multistream HMMs", " facial animation parameters"], "paper_abstract": "The performance of an automatic facial expression recognition system can be significantly improved by modeling the reliability of different streams of facial expression information utilizing multistream hidden Markov models (HMMs). In this paper, we present an automatic multistream HMM facial expression recognition system and analyze its performance. The proposed system utilizes facial animation parameters (FAPs), supported by the MPEG-4 standard, as features for facial expression classification. Specifically, the FAPs describing the movement of the outer-lip contours and eyebrows are used as observations. Experiments are first performed employing single-stream HMMs under several different scenarios, utilizing outer-lip and eyebrow FAPs individually and jointly. A multistream HMM approach is proposed for introducing facial expression and FAP group dependent stream reliability weights. The stream weights are determined based on the facial expression recognition results obtained when FAP streams are utilized individually. The proposed multistream HMM facial expression system, which utilizes stream reliability weights, achieves relative reduction of the facial expression recognition error of 44% compared to the single-stream HMM system.", "paper_title": "Automatic facial expression recognition using facial animation parameters and multistream HMMs", "paper_id": "WOS:000246106400002"}