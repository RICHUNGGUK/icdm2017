{"auto_keywords": [{"score": 0.03437781888328544, "phrase": "image_texts"}, {"score": 0.010612387000973441, "phrase": "augmented_game"}, {"score": 0.01010932701044004, "phrase": "virtual_objects"}, {"score": 0.009987295078388702, "phrase": "real_environment"}, {"score": 0.004420472010542188, "phrase": "accurate_location_estimation"}, {"score": 0.004296264970612285, "phrase": "important_issues"}, {"score": 0.004192571571622019, "phrase": "users'_positions"}, {"score": 0.003960210592458847, "phrase": "active_badge"}, {"score": 0.003771282384646587, "phrase": "low-cost_vision-based_navigation_system"}, {"score": 0.0032833625797814474, "phrase": "matching_method"}, {"score": 0.0031650944584992726, "phrase": "natural_scenes"}, {"score": 0.002688781336915723, "phrase": "edge_density"}, {"score": 0.0024984517279573906, "phrase": "hand-held_devices"}, {"score": 0.0024680632991561074, "phrase": "low_resolution"}, {"score": 0.0023310544011985253, "phrase": "text_recognition"}, {"score": 0.002265422518417868, "phrase": "image_matching"}, {"score": 0.0022378620428620782, "phrase": "matching_window"}, {"score": 0.0021222476760114914, "phrase": "discriminated_places"}], "paper_keywords": [""], "paper_abstract": "In an augmented game is a game, which is overlapping virtual objects on a real environment and attacking the virtual objects, accurate location estimation in a real environment is one of important issues. Existing global positioning systems(GPS) to track users' positions do not work inside a building, and systems using sensors such as Active Badge are expensive to install and maintain. Therefore, researches for low-cost vision-based navigation system have been attempted. Since most of scenes include a floor, ceiling and wall in a building, it is difficult to represent characteristics of those scenes. We propose an image matching method using image texts instead of objects included uniformly in natural scenes for navigation. The image texts are widely distributed in our environments, are very useful for describing the contents of an image, and can be sassily extracted compared to other semantic contents, and we obtain image texts using a method combining edge density and multi-layer perceptrons with CAMShift. However, since a camera attached to moving vehicles(robots) or hand-held devices has a low resolution, it is not easy to perform extraction using a binarization and a text recognition. Therefore, we perform an image matching using a matching window based on a scale and orientation of image texts and its neighborhood to recognize discriminated places including same image texts.", "paper_title": "Image texts-based navigation for augmented game", "paper_id": "WOS:000238089300141"}