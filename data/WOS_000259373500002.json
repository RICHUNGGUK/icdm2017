{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "evaluator_effect"}, {"score": 0.026202274774208056, "phrase": "usability_problems"}, {"score": 0.005480586663614288, "phrase": "independent_experts"}, {"score": 0.004769958800452922, "phrase": "usability_testing"}, {"score": 0.004594137808658537, "phrase": "usability_evaluators"}, {"score": 0.004551199992546761, "phrase": "similar_conditions"}, {"score": 0.004508661664944657, "phrase": "substantially_different_sets"}, {"score": 0.003861288537079326, "phrase": "resulting_usability_problems"}, {"score": 0.00348202932445197, "phrase": "substantial_evaluator_effect"}, {"score": 0.0034494494982242187, "phrase": "team_matching"}, {"score": 0.003369322866499541, "phrase": "individual_matching"}, {"score": 0.0032145922365231093, "phrase": "greater_satisfaction"}, {"score": 0.0031695693589575916, "phrase": "teams'_matchings"}, {"score": 0.002995677265350124, "phrase": "evaluator_effects"}, {"score": 0.0029676344710756553, "phrase": "similar_sizes"}, {"score": 0.002752513434446804, "phrase": "previous_claims"}, {"score": 0.002613709503583786, "phrase": "large_variability"}, {"score": 0.002470237978694949, "phrase": "key_determinant"}, {"score": 0.0024014759148123736, "phrase": "alternative_view"}, {"score": 0.0023566987138026285, "phrase": "evaluator_agreement"}, {"score": 0.0021049977753042253, "phrase": "correct_matching"}], "paper_keywords": [""], "paper_abstract": "The evaluator effect names the observation that usability evaluators in similar conditions identify substantially different sets of usability problems. Yet little is known about the factors involved in the evaluator effect. We present a study of 50 novice evaluators' usability tests and subsequent comparisons, in teams and individually, of the resulting usability problems. The same problems were analyzed independently by 10 human-computer interaction experts. The study shows an agreement between evaluators of about 40%, indicating a substantial evaluator effect. Team matching of problems following the individual matching appears to improve the agreement, and evaluators express greater satisfaction with the teams' matchings. The matchings of individuals, teams, and independent experts show evaluator effects of similar sizes; yet individuals, teams, and independent experts fundamentally disagree about which problems are similar. Previous claims in the literature about the evaluator effect are challenged by the large variability in the matching of usability problems; we identify matching as a key determinant of the evaluator effect. An alternative view of usability problems and evaluator agreement is proposed in which matching is seen as an activity that helps to make sense of usability problems and where the existence of a correct matching is not assumed.", "paper_title": "A study of the evaluator effect in usability testing", "paper_id": "WOS:000259373500002"}