{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "building_models"}, {"score": 0.004586531354697466, "phrase": "deeply_roots"}, {"score": 0.004333642054036135, "phrase": "general_aspects"}, {"score": 0.0041279612688488445, "phrase": "chemical_problems"}, {"score": 0.003964007795174772, "phrase": "chemical_models"}, {"score": 0.0037150687722055727, "phrase": "iterative_reweighting_procedure"}, {"score": 0.003567455727660992, "phrase": "base_learner"}, {"score": 0.0035100601949451028, "phrase": "reweighted_versions"}, {"score": 0.00342568771304873, "phrase": "training_data"}, {"score": 0.0031845067058084583, "phrase": "previous_learners"}, {"score": 0.0030086877092638945, "phrase": "different_loss_criteria"}, {"score": 0.0028195727965553367, "phrase": "regression_problems"}, {"score": 0.0026638482306228575, "phrase": "basic_idea"}, {"score": 0.002246292543825748, "phrase": "significant_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["AdaBoost", " Gradient boosting (GB)", " Classification and Regression Tree (CART)", " Bagging", " Ensemble learning"], "paper_abstract": "The idea of boosting deeply roots in our daily life practice, which constructs the general aspects of how to think about chemical problems and how to build chemical models. In mathematics, boosting is an iterative reweighting procedure by sequentially applying a base learner to reweighted versions of the training data whose current weights are modified based on how accurately the previous learners predict these samples. By using different loss criteria, boosting copes with not only classification problems but also regression problems. In this paper, the basic idea and algorithms of commonly used boosting are discussed in detail. The applications to two datasets are conducted to illustrate the significant performance of boosting. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "The boosting: A new idea of building models", "paper_id": "WOS:000274352500001"}