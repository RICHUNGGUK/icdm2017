{"auto_keywords": [{"score": 0.040845749728847636, "phrase": "gpu"}, {"score": 0.00481495049065317, "phrase": "graphics_processors"}, {"score": 0.004730458558634266, "phrase": "fast_computation"}, {"score": 0.004674952036988355, "phrase": "acoustic_likelihoods"}, {"score": 0.004620093797504386, "phrase": "speech_recognition"}, {"score": 0.004539005582217309, "phrase": "large_vocabulary_continuous_speech_recognition"}, {"score": 0.0044857387493858715, "phrase": "lvcsr"}, {"score": 0.004406994912939125, "phrase": "acoustic_model_computations"}, {"score": 0.004278807087784626, "phrase": "largest_processing_overhead"}, {"score": 0.004081385896110623, "phrase": "wfst"}, {"score": 0.0040334640350288, "phrase": "based_decoding_engine"}, {"score": 0.003939296259436904, "phrase": "commodity_graphics_processing_unit"}, {"score": 0.0037797419108291227, "phrase": "acoustic_computations"}, {"score": 0.003626626504149897, "phrase": "main_processor"}, {"score": 0.003338690782620756, "phrase": "recognition_speed"}, {"score": 0.0032223742018434856, "phrase": "recognition_accuracy"}, {"score": 0.0031285355811105915, "phrase": "gpu_technique"}, {"score": 0.0030735451757603555, "phrase": "large_vocabulary_spontaneous_speech_recognition_task"}, {"score": 0.002984027623988469, "phrase": "acoustic_models"}, {"score": 0.0029489527539649737, "phrase": "varying_complexity"}, {"score": 0.0026827569390113822, "phrase": "recognition_time"}, {"score": 0.002651213849567608, "phrase": "largest_improvements"}, {"score": 0.002573965014439041, "phrase": "large_numbers"}, {"score": 0.0025437988938520908, "phrase": "gaussians"}, {"score": 0.002426137929553722, "phrase": "best_accuracy"}, {"score": 0.002286781334850213, "phrase": "faster_decoding_times"}, {"score": 0.0021049977753042253, "phrase": "standard_hardware"}], "paper_keywords": ["LVCSR", " GPGPU", " Novel hardware for ASR", " WFST"], "paper_abstract": "In large vocabulary continuous speech recognition (LVCSR) the acoustic model computations often account for the largest processing overhead. Our weighted finite state transducer (WFST) based decoding engine can utilize a commodity graphics processing unit (GPU) to perform the acoustic computations to move this burden off the main processor. In this paper we describe our new GPU scheme that can achieve a very substantial improvement in recognition speed whilst incurring no reduction in recognition accuracy. We evaluate the GPU technique on a large vocabulary spontaneous speech recognition task using a set of acoustic models with varying complexity and the results consistently show by using the GPU it is possible to reduce the recognition time with largest improvements occurring in systems with large numbers of Gaussians. For the systems which achieve the best accuracy we obtained between 2.5 and 3 times speed-ups. The faster decoding times translate to reductions in space, power and hardware costs by only requiring standard hardware that is already widely installed. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Harnessing graphics processors for the fast computation of acoustic likelihoods in speech recognition", "paper_id": "WOS:000266536400007"}