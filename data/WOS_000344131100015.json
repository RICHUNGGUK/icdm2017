{"auto_keywords": [{"score": 0.039442374606482145, "phrase": "sklrg"}, {"score": 0.03864783489310989, "phrase": "low-rank_representation"}, {"score": 0.03215695170565396, "phrase": "proposed_sklrg"}, {"score": 0.00481495049065317, "phrase": "kernel_low-rank_representation_graph"}, {"score": 0.004774530554776604, "phrase": "sparse_representation"}, {"score": 0.004655285779819366, "phrase": "increasing_interests"}, {"score": 0.004500891637057374, "phrase": "global_constraints"}, {"score": 0.0043150485532080065, "phrase": "data_structure"}, {"score": 0.004050514095922329, "phrase": "robust_classification"}, {"score": 0.004016485454498076, "phrase": "wide_range"}, {"score": 0.0037861265016041813, "phrase": "new_semi-supervised_kernel_low-rank_representation_graph"}, {"score": 0.003568932067237836, "phrase": "kernel_trick"}, {"score": 0.0035240305920962766, "phrase": "kernel_projection"}, {"score": 0.0034359094594153304, "phrase": "high-dimensional_space"}, {"score": 0.003378385493203297, "phrase": "possible_low-rank_structure"}, {"score": 0.0032800186243040663, "phrase": "projected_data"}, {"score": 0.0031577303835881964, "phrase": "sklrg_matrix"}, {"score": 0.003117986133774198, "phrase": "data_affinity"}, {"score": 0.0030787405733989615, "phrase": "corrupted_patterns"}, {"score": 0.002914288956035066, "phrase": "projected_space"}, {"score": 0.00284137141260141, "phrase": "global_structure"}, {"score": 0.0028174721236762317, "phrase": "complex_data"}, {"score": 0.002735392281320413, "phrase": "connected_weights"}, {"score": 0.002633355582628613, "phrase": "label_information"}, {"score": 0.002556625752785268, "phrase": "classification_results"}, {"score": 0.002471661547432869, "phrase": "benchmark_datasets"}, {"score": 0.0023395610923736595, "phrase": "speckle_noise"}, {"score": 0.002242758902593467, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Low-rank representation", " Kernel trick", " Sparse graphs", " Semi-supervised learning", " Pairwise constraints"], "paper_abstract": "Sparse Representation based Graphs (SRGs) have attracted increasing interests in very recent years. However, for lacking global constraints on solutions to sparse representation, SRGs cannot accurately reveal data structure when data are grossly corrupted. In this paper, in order to achieve robust classification of wide range of datasets when only a small number of labeled samples are available, we advance a new semi-supervised kernel low-rank representation graph (SKLRG), by combining low-rank representation (LRR) with graphs and kernel trick. A kernel projection is first learned to find high-dimensional space where data have possible low-rank structure. Then a low-rank representation of the projected data is calculated from which we can derive a SKLRG matrix to evaluate data affinity and classify corrupted patterns. The proposed SKLRG can naturally reveal the relationship among data in the projected space, and can capture the global structure of complex data and implements more robust subspace segmentation. Moreover, connected weights of SKLRG are refined by pairwise constrains where label information is explored to further improve the classification results. Some experiments are taken on some benchmark datasets and Synthetic Aperture Radar (SAR) images that are corrupted by speckle noise. The results show that the proposed SKLRG can achieve better performance than its counterparts when there are only a small number of labeled samples. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Semi-supervised classification via kernel low-rank representation graph", "paper_id": "WOS:000344131100015"}