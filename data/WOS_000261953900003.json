{"auto_keywords": [{"score": 0.04928674718599398, "phrase": "streaming_applications"}, {"score": 0.04302051049727595, "phrase": "streaming_application"}, {"score": 0.041772357680559515, "phrase": "timing_properties"}, {"score": 0.03782349251688888, "phrase": "data_item"}, {"score": 0.004815112813718618, "phrase": "cache"}, {"score": 0.004618166136069052, "phrase": "considerable_interest"}, {"score": 0.004368185635518971, "phrase": "potentially_infinite_streams"}, {"score": 0.004319830179921363, "phrase": "network_packets"}, {"score": 0.004248294537944227, "phrase": "wide_range"}, {"score": 0.00417793854311445, "phrase": "mobile_phones"}, {"score": 0.004154745345684458, "phrase": "set-top_boxes"}, {"score": 0.004040688646993609, "phrase": "timing_analysis_problem"}, {"score": 0.003951692879298571, "phrase": "processed_data_stream"}, {"score": 0.0038754247183799885, "phrase": "input_stream"}, {"score": 0.003685972800046028, "phrase": "hardware_architectures"}, {"score": 0.00363500457963438, "phrase": "maximum_delay"}, {"score": 0.003535165233011893, "phrase": "maximum_backlog"}, {"score": 0.003505749731180509, "phrase": "buffer_requirement"}, {"score": 0.0034669081259719884, "phrase": "incoming_stream"}, {"score": 0.003418958653159371, "phrase": "previous_work"}, {"score": 0.003325033439910555, "phrase": "high-level_view"}, {"score": 0.0032699173589777948, "phrase": "micro-architectural_features"}, {"score": 0.0031536033289228252, "phrase": "accurate_estimation"}, {"score": 0.0030584113653132168, "phrase": "appropriate_modeling"}, {"score": 0.0030329507760490973, "phrase": "processor_micro-architecture"}, {"score": 0.002966084234963723, "phrase": "novel_framework"}, {"score": 0.002949598537993663, "phrase": "cache-aware_timing_analysis"}, {"score": 0.0028446460307503343, "phrase": "instruction_cache"}, {"score": 0.0028209599545587745, "phrase": "underlying_processor"}, {"score": 0.002728166176898541, "phrase": "execution_time"}, {"score": 0.0026164433143193015, "phrase": "main_contribution"}, {"score": 0.002551612225562499, "phrase": "program_analysis_techniques"}, {"score": 0.002537424329317581, "phrase": "micro-architectural_modeling"}, {"score": 0.0025233151233862734, "phrase": "known_analytical_methods"}, {"score": 0.002453934333239467, "phrase": "event_streams"}, {"score": 0.0024402882329924934, "phrase": "mathematical_functions"}, {"score": 0.00225700428055894, "phrase": "event_arrivals"}, {"score": 0.002182720878764192, "phrase": "detailed_modeling"}, {"score": 0.0021645343888637304, "phrase": "cache_behavior"}], "paper_keywords": ["Timing analysis", " Instruction cache", " Streaming applications"], "paper_abstract": "Of late, there has been a considerable interest in models, algorithms and methodologies specifically targeted towards designing hardware and software for streaming applications. Such applications process potentially infinite streams of audio/video data or network packets and are found in a wide range of devices, starting from mobile phones to set-top boxes. Given a streaming application and an architecture, the timing analysis problem is to determine the timing properties of the processed data stream, given the timing properties of the input stream. This problem arises while determining many common performance metrics related to streaming applications and the mapping of such applications onto hardware architectures. Such metrics include the maximum delay experienced by any data item of the stream and the maximum backlog or the buffer requirement to store the incoming stream. Most of the previous work related to estimating or optimizing these metrics take a high-level view of the architecture and neglect micro-architectural features such as caches. In this paper, we show that an accurate estimation of these metrics, however, heavily relies on an appropriate modeling of the processor micro-architecture. Towards this, we present a novel framework for cache-aware timing analysis of stream processing applications. Our framework accurately models the evolution of the instruction cache of the underlying processor as a stream is processed, and the fact that the execution time involved in processing any data item depends on all the previous data items occurring in the stream. The main contribution of our method lies in its ability to seamlessly integrate program analysis techniques for micro-architectural modeling with known analytical methods for analyzing streaming applications, which treat the arrival/service of event streams as mathematical functions. This combination is powerful as it allows to model the code/cache-behavior of the streaming application, as well as the manner in which it is triggered by event arrivals. We employ our analysis method to an MPEG-2 encoder application and our experiments indicate that detailed modeling of the cache behavior is efficient, scalable and leads to more accurate timing/buffer size estimates.", "paper_title": "Cache-aware timing analysis of streaming applications", "paper_id": "WOS:000261953900003"}