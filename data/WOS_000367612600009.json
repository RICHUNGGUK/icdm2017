{"auto_keywords": [{"score": 0.04360247103779728, "phrase": "academic_age"}, {"score": 0.00481495049065317, "phrase": "scientific_impact"}, {"score": 0.004786620949516712, "phrase": "citation_metrics"}, {"score": 0.0047026237903774895, "phrase": "quantitative_evaluation"}, {"score": 0.0045122922461952805, "phrase": "funding_decisions"}, {"score": 0.004420022113586985, "phrase": "impact_metrics"}, {"score": 0.004304144138805271, "phrase": "scientific_output"}, {"score": 0.004081385289516914, "phrase": "single_papers"}, {"score": 0.0040097139701644165, "phrase": "citation-based_metrics"}, {"score": 0.003974349782102708, "phrase": "entire_publication_record"}, {"score": 0.003768594674768144, "phrase": "different_rates"}, {"score": 0.003735349093835257, "phrase": "different_disciplines"}, {"score": 0.0036914757355166966, "phrase": "different_periods"}, {"score": 0.003531474887552889, "phrase": "statistical_baseline"}, {"score": 0.003479692058963528, "phrase": "academic_profile"}, {"score": 0.002914288956035066, "phrase": "nobel_laureates"}, {"score": 0.0027961342030212353, "phrase": "traditional_metrics"}, {"score": 0.0027796495180095657, "phrase": "low_impact"}, {"score": 0.002763261749602258, "phrase": "absolute_terms"}, {"score": 0.002643386043540555, "phrase": "fair_comparison"}, {"score": 0.002620040660435039, "phrase": "arbitrary_collections"}, {"score": 0.0025892330566358503, "phrase": "scholar_publication_records"}, {"score": 0.0024915819531646645, "phrase": "similar_technique"}, {"score": 0.002426137929553722, "phrase": "research_units"}, {"score": 0.0023976048394496446, "phrase": "specific_disciplines"}, {"score": 0.002362408791114333, "phrase": "ortuno-orti"}, {"score": 0.002253208464566164, "phrase": "almost_a_million_scholars"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Citation analysis", " Scientific impact", " Research evaluation", " Quality", " Quantity"], "paper_abstract": "Citation metrics are becoming pervasive in the quantitative evaluation of scholars, journals, and institutions. Hiring, promotion, and funding decisions increasingly rely on a variety of impact metrics that cannot disentangle quality from quantity of scientific output, and are biased by factors such as discipline and academic age. Biases affecting the evaluation of single papers are compounded when one aggregates citation-based metrics across an entire publication record. It is not trivial to compare the quality of two scholars that during their careers have published at different rates, in different disciplines, and in different periods of time. Here we evaluate a method based on the generation of a statistical baseline specifically tailored on the academic profile of each researcher. We demonstrate the effectiveness of the approach in decoupling the roles of quantity and quality of publications to explain how a certain level of impact is achieved. The method can be extended to simultaneously suppress any source of bias. As an illustration, we use it to capture the quality of the work of Nobel laureates irrespective of number of publications, academic age, and discipline, even when traditional metrics indicate low impact in absolute terms. The procedure is flexible enough to allow for the evaluation of, and fair comparison among, arbitrary collections of papers - scholar publication records, journals, and institutions; in fact, it extends a similar technique that was previously applied to the ranking of research units and countries in specific disciplines (Crespo), Ortuno-Orti, & Ruiz-Castillo, 2012). We further apply the methodology to almost a million scholars and over six thousand journals to measure the impact that cannot be explained by the volume of publications alone. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Quality versus quantity in scientific impact", "paper_id": "WOS:000367612600009"}