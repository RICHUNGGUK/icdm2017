{"auto_keywords": [{"score": 0.029523122975463494, "phrase": "cab"}, {"score": 0.013063299411733903, "phrase": "medline"}, {"score": 0.00481495049065317, "phrase": "corporate_source_data"}, {"score": 0.004563427013973105, "phrase": "data_quality"}, {"score": 0.004514714250357749, "phrase": "corporate_sources"}, {"score": 0.004371660146981191, "phrase": "bibliometric_purposes"}, {"score": 0.004329431572550293, "phrase": "inspec"}, {"score": 0.004324985524216987, "phrase": "research_management"}, {"score": 0.004255902303152008, "phrase": "bibliographic_databases"}, {"score": 0.004210458358142504, "phrase": "citation_index_systems"}, {"score": 0.004165497627464024, "phrase": "analytical_tools"}, {"score": 0.004077005481951783, "phrase": "raw_resources"}, {"score": 0.0040334640350288, "phrase": "bibliometric_studies"}, {"score": 0.003781772207256374, "phrase": "institution_data"}, {"score": 0.0037213333316218522, "phrase": "present_contribution"}, {"score": 0.0036422425344358037, "phrase": "natural_language_processing"}, {"score": 0.0034332736827447654, "phrase": "corporate_data"}, {"score": 0.003342280102112269, "phrase": "standardized_format"}, {"score": 0.0032888418378433037, "phrase": "proposed_unification_process"}, {"score": 0.003167441161387607, "phrase": "address_patterns"}, {"score": 0.0031167895790050405, "phrase": "ensuing_application"}, {"score": 0.0030834712590249863, "phrase": "enhanced_finite-state_transducers"}, {"score": 0.0029064676523923886, "phrase": "address_formats"}, {"score": 0.0025822818714499795, "phrase": "close_control"}, {"score": 0.002382182688788248, "phrase": "computational_efficacy"}, {"score": 0.0021049977753042253, "phrase": "application_domain"}], "paper_keywords": [""], "paper_abstract": "This paper describe an approach for improving the data quality of corporate sources when databases are used for bibliometric purposes. Research management relies on bibliographic databases and citation index systems as analytical tools, yet the raw resources for bibliometric studies are plagued by a lack of consistency in fied formatting for institution data. The present contribution puts forth a Natural Language Processing (NLP)-oriented method for the identification of the structures guiding corporate data and their mapping into a standardized format. The proposed unification process is based on the definition of address patterns and the ensuing application of Enhanced Finite-State Transducers (E-FST). Our procedure was tested on address formats downloaded from the INSPEC, MEDLINE and CAB Abstracts. The results demonstrate the helpfulness of the method as long as close control of errors is exercised as far as the formats to be unified. The computational efficacy of the model is noteworthy, due to the fact that it is firmly guided by the definition of data in the application domain.", "paper_title": "Standardizing formats of corporate source data", "paper_id": "WOS:000243471400001"}