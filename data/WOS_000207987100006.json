{"auto_keywords": [{"score": 0.049651030276363105, "phrase": "emotional_speech_characterization"}, {"score": 0.00481495049065317, "phrase": "time-scale_feature_extractions"}, {"score": 0.0046659637258752535, "phrase": "important_issue"}, {"score": 0.004441059405327222, "phrase": "time-scale_analysis_problem"}, {"score": 0.004342430078306461, "phrase": "emotional_speech_processing"}, {"score": 0.0042459818200777846, "phrase": "computational_framework"}, {"score": 0.0041891398413899435, "phrase": "segmental_and_supra-segmental_features"}, {"score": 0.004059438255358923, "phrase": "statistical_fusion"}, {"score": 0.003933736547198066, "phrase": "local_a_posteriori_class_probabilities"}, {"score": 0.0038290829316346654, "phrase": "weighting_factors"}, {"score": 0.003693846909452865, "phrase": "individual_speech_segments"}, {"score": 0.003563370084662192, "phrase": "real-world_application"}, {"score": 0.003499864176875713, "phrase": "italian_motherese"}, {"score": 0.0034685354330506605, "phrase": "authentic_and_longitudinal_parent-infant_interaction"}, {"score": 0.0033459905006404207, "phrase": "short-and_long-term_information"}, {"score": 0.0032423089921154503, "phrase": "short-term_spectrum"}, {"score": 0.003198860258228543, "phrase": "prosody_parameters"}, {"score": 0.003071965703296204, "phrase": "robust_and_efficient_time-scale_analysis"}, {"score": 0.0028844769395018595, "phrase": "phonetic-specific_characterization_process"}, {"score": 0.002708399936381754, "phrase": "emotional_states"}, {"score": 0.0026720866990543744, "phrase": "phoneme_level"}, {"score": 0.0024864612830452254, "phrase": "relevant_and_discriminant_feature_space"}, {"score": 0.0024093494406195386, "phrase": "experimental_results"}, {"score": 0.002377051954957122, "phrase": "berlin"}, {"score": 0.002355760732819676, "phrase": "german"}, {"score": 0.0023241387549221408, "phrase": "aholab"}, {"score": 0.002303310950959055, "phrase": "basque"}, {"score": 0.0022520496048464406, "phrase": "best_performance"}, {"score": 0.0021049977753042253, "phrase": "phoneme_dependency"}], "paper_keywords": ["Emotional speech", " Time-scales analysis", " Feature extraction", " Statistical fusion", " Data-driven approach"], "paper_abstract": "Emotional speech characterization is an important issue for the understanding of interaction. This article discusses the time-scale analysis problem in feature extraction for emotional speech processing. We describe a computational framework for combining segmental and supra-segmental features for emotional speech detection. The statistical fusion is based on the estimation of local a posteriori class probabilities and the overall decision employs weighting factors directly related to the duration of the individual speech segments. This strategy is applied to a real-world application: detection of Italian motherese in authentic and longitudinal parent-infant interaction at home. The results suggest that short-and long-term information, respectively, represented by the short-term spectrum and the prosody parameters (fundamental frequency and energy) provide a robust and efficient time-scale analysis. A similar fusion methodology is also investigated by the use of a phonetic-specific characterization process. This strategy is motivated by the fact that there are variations across emotional states at the phoneme level. A time-scale based on both vowels and consonants is proposed and it provides a relevant and discriminant feature space for acted emotion recognition. The experimental results on two different databases Berlin (German) and Aholab (Basque) show that the best performance are obtained by our phoneme-dependent approach. These findings demonstrate the relevance of taking into account phoneme dependency (vowels/consonants) for emotional speech characterization.", "paper_title": "Time-Scale Feature Extractions for Emotional Speech Characterization", "paper_id": "WOS:000207987100006"}