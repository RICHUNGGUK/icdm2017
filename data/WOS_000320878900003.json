{"auto_keywords": [{"score": 0.03531917121851837, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "single_template"}, {"score": 0.004761494044422926, "phrase": "constrained_warping_deformation"}, {"score": 0.004579005794486596, "phrase": "automatic_face_image_annotation_method"}, {"score": 0.004403480614319231, "phrase": "different_expressions"}, {"score": 0.004330321475256457, "phrase": "annotated_neutral_face"}, {"score": 0.004141093507753515, "phrase": "tedious_manual_work"}, {"score": 0.004072275820209647, "phrase": "image_data"}, {"score": 0.004027031316965272, "phrase": "large_databases"}, {"score": 0.003808209866576388, "phrase": "appearance_variations"}, {"score": 0.0037449033166879874, "phrase": "non-rigid_face_deformations"}, {"score": 0.003601235776892337, "phrase": "conventional_approaches"}, {"score": 0.003561205990687285, "phrase": "sufficient_image_templates"}, {"score": 0.0034824716857663114, "phrase": "query_appearance"}, {"score": 0.003202361402737197, "phrase": "dense_image_alignment"}, {"score": 0.0031315358193567708, "phrase": "image_warping"}, {"score": 0.0030794433253250476, "phrase": "alignment_process"}, {"score": 0.003011328068286321, "phrase": "prior_knowledge"}, {"score": 0.002977835845437357, "phrase": "facial_shape_deformation"}, {"score": 0.002847540262784593, "phrase": "appearance_model"}, {"score": 0.0027535633837592597, "phrase": "unseen_faces"}, {"score": 0.0026478260192958924, "phrase": "warping_parameters"}, {"score": 0.0025604233506352375, "phrase": "robust_patch-based_estimation_method"}, {"score": 0.002541321464585762, "phrase": "context"}, {"score": 0.0024897902536499005, "phrase": "feature_points"}, {"score": 0.0023941575109692336, "phrase": "searching_path"}, {"score": 0.0023675132064088803, "phrase": "local_patch_matching"}, {"score": 0.0023281003994670714, "phrase": "face_annotation_experiments"}, {"score": 0.002263861731320045, "phrase": "large_expressions"}, {"score": 0.0022261705957258506, "phrase": "noisy_image_qualities"}, {"score": 0.002189105604712615, "phrase": "low_image_resolutions"}, {"score": 0.002164738347530832, "phrase": "comparison_results"}, {"score": 0.0021406417439887907, "phrase": "conventional_methods"}, {"score": 0.0021049977753042253, "phrase": "proposed_method's_superiority"}], "paper_keywords": [""], "paper_abstract": "In this study, an automatic face image annotation method is proposed by aligning faces with different expressions to an annotated neutral face. This work is useful in reducing tedious manual work for labelling image data in large databases. However, it is challenging because of the appearance variations caused by non-rigid face deformations under various expressions. Unlike some conventional approaches acquiring sufficient image templates to model the query appearance, only a single given template is necessary for the proposed method. The authors address the problem through dense image alignment. Specifically, image warping in the alignment process is constrained by prior knowledge about facial shape deformation. The proposed method is independent of the appearance model, and is available for unseen faces. In addition, to initialise warping parameters, the authors present a robust patch-based estimation method. Context information for feature points is carefully modelled to propagate the searching path for local patch matching. The face annotation experiments are performed on some large expressions, with noisy image qualities and in low image resolutions. Comparison results with conventional methods demonstrate the proposed method's superiority on both accuracy and robustness.", "paper_title": "Automatic face image annotation based on a single template with constrained warping deformation", "paper_id": "WOS:000320878900003"}