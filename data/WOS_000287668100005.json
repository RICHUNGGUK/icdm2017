{"auto_keywords": [{"score": 0.04573629565804587, "phrase": "internal_state"}, {"score": 0.038354821270219504, "phrase": "cache_contents"}, {"score": 0.0352221792849628, "phrase": "transfer_time"}, {"score": 0.00481495049065317, "phrase": "compressing_cache_state_for_postsilicon_processor_debug"}, {"score": 0.00471811808206897, "phrase": "postsilicon_processor_debugging"}, {"score": 0.004120289747942224, "phrase": "memory_elements"}, {"score": 0.0035016702571862165, "phrase": "logic_analyser"}, {"score": 0.003272083495778595, "phrase": "expensive_logic_analyser_memory"}, {"score": 0.002955533639862811, "phrase": "hardware_compression_engine"}, {"score": 0.002915701586760994, "phrase": "cache_data"}, {"score": 0.0028569549040495163, "phrase": "cache-aware_compression_strategy"}, {"score": 0.0027429789393362703, "phrase": "cache_fields"}, {"score": 0.0026335379469691997, "phrase": "effective_compression"}, {"score": 0.002598034157587518, "phrase": "experimental_results"}, {"score": 0.00222249726328354, "phrase": "parallel_compression_architecture"}, {"score": 0.0021776870246727233, "phrase": "multiple_compression_engines"}], "paper_keywords": ["Postsilicon validation", " processor debug", " cache compression"], "paper_abstract": "During postsilicon processor debugging, we need to frequently capture and dump out the internal state of the processor. Since internal state constitutes all memory elements, the bulk of which is composed of cache, the problem is essentially that of transferring cache contents off-chip, to a logic analyser. In order to reduce the transfer time and save expensive logic analyser memory, we propose to compress the cache contents on their way out. We present a hardware compression engine for cache data using a Cache-Aware Compression strategy that exploits knowledge of the cache fields and their behavior to achieve an effective compression. Experimental results indicate that the technique results in 7-31 percent better compression than one that treats the data as just one long bit stream. We also describe and evaluate a parallel compression architecture that uses multiple compression engines, resulting in a 54 percent reduction in transfer time.", "paper_title": "Compressing Cache State for Postsilicon Processor Debug", "paper_id": "WOS:000287668100005"}