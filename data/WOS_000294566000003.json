{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "matching_graph"}, {"score": 0.013382964706868115, "phrase": "particular_objects"}, {"score": 0.010865537451028376, "phrase": "glda_model"}, {"score": 0.004782455247247007, "phrase": "large-scale_image_datasets"}, {"score": 0.00471811808206897, "phrase": "large-scale_collection"}, {"score": 0.004335081499311714, "phrase": "significant_entities"}, {"score": 0.004204904449336037, "phrase": "geometric_latent_dirichlet_allocation"}, {"score": 0.004120289747942224, "phrase": "unsupervised_discovery"}, {"score": 0.0040648241451154525, "phrase": "unordered_image_collections"}, {"score": 0.003863370968575808, "phrase": "rich_latent_topic_models"}, {"score": 0.0037600281647068522, "phrase": "visual_words"}, {"score": 0.003671865026158296, "phrase": "geometrically_consistent_way"}, {"score": 0.0036347141744359442, "phrase": "standard_inference_techniques"}, {"score": 0.003362060602812933, "phrase": "computational_cost"}, {"score": 0.003294350220187021, "phrase": "large_datasets"}, {"score": 0.0032389643666649094, "phrase": "scalable_method"}, {"score": 0.003006087482938274, "phrase": "rough_image_groups"}, {"score": 0.0029256091368059446, "phrase": "standard_clustering_techniques"}, {"score": 0.0027336881691956186, "phrase": "\"hub_images"}, {"score": 0.0025284524249379265, "phrase": "publicly_available_oxford_buildings"}, {"score": 0.0024607296642187846, "phrase": "automatically_mined_objects"}, {"score": 0.0023625233416109917, "phrase": "ground_truth"}, {"score": 0.0023148964315569866, "phrase": "oxford_landmarks"}, {"score": 0.002252880693912436, "phrase": "matching_graph_method"}, {"score": 0.00222249726328354, "phrase": "qualitative_results"}, {"score": 0.0021050115686086705, "phrase": "rome"}], "paper_keywords": ["Object discovery", " Large-scale retrieval", " Topic/generative models"], "paper_abstract": "Given a large-scale collection of images our aim is to efficiently associate images which contain the same entity, for example a building or object, and to discover the significant entities. To achieve this, we introduce the Geometric Latent Dirichlet Allocation (gLDA) model for unsupervised discovery of particular objects in unordered image collections. This explicitly represents images as mixtures of particular objects or facades, and builds rich latent topic models which incorporate the identity and locations of visual words specific to the topic in a geometrically consistent way. Applying standard inference techniques to this model enables images likely to contain the same object to be probabilistically grouped and ranked. Additionally, to reduce the computational cost of applying the gLDA model to large datasets, we propose a scalable method that first computes a matching graph over all the images in a dataset. This matching graph connects images that contain the same object, and rough image groups can be mined from this graph using standard clustering techniques. The gLDA model can then be applied to generate a more nuanced representation of the data. We also discuss how \"hub images\" (images representative of an object or landmark) can easily be extracted from our matching graph representation. We evaluate our techniques on the publicly available Oxford buildings dataset (5K images) and show examples of automatically mined objects. The methods are evaluated quantitatively on this dataset using a ground truth labeling for a number of Oxford landmarks. To demonstrate the scalability of the matching graph method, we show qualitative results on two larger datasets of images taken of the Statue of Liberty (37K images) and Rome (1M+ images).", "paper_title": "Geometric Latent Dirichlet Allocation on a Matching Graph for Large-scale Image Datasets", "paper_id": "WOS:000294566000003"}