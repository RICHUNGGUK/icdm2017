{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "lasso"}, {"score": 0.0060140992397681465, "phrase": "tikhonov"}, {"score": 0.003974349782102708, "phrase": "supervised_learning"}, {"score": 0.0036373553416391823, "phrase": "iterative_algorithm"}, {"score": 0.003479692058963528, "phrase": "umanita"}, {"score": 0.0033928313873033316, "phrase": "villa"}, {"score": 0.002914288956035066, "phrase": "consistent_way"}, {"score": 0.0028293966058473476, "phrase": "relevant_features"}, {"score": 0.002706659627293686, "phrase": "regression_function"}, {"score": 0.002404706573379854, "phrase": "sparse_representation"}, {"score": 0.0023003498123420237, "phrase": "fixed_dictionary"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Learning theory", " Regularization", " Sparsity", " Consistent estimator"], "paper_abstract": "In the framework of supervised learning, we prove that the iterative algorithm introduced in Umanita and Villa (2010)[22] allows us to estimate in a consistent way the relevant features of the regression function under the a priori assumption that it admits a sparse representation on a fixed dictionary. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "A consistent algorithm to solve Lasso, elastic-net and Tikhonov regularization", "paper_id": "WOS:000289135400005"}