{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "marl-ped"}, {"score": 0.004632039024076267, "phrase": "pedestrian_groups"}, {"score": 0.004602233424629559, "phrase": "pedestrian_simulation"}, {"score": 0.004513957235071457, "phrase": "different_levels"}, {"score": 0.004413096646892175, "phrase": "lowest_level"}, {"score": 0.0043846936613643256, "phrase": "local_interactions"}, {"score": 0.004286708921931472, "phrase": "middle_level"}, {"score": 0.0042591158963728665, "phrase": "strategic_and_tactical_behaviors"}, {"score": 0.004190904630161064, "phrase": "route_choices"}, {"score": 0.004123781267600542, "phrase": "highest_level_path-planning"}, {"score": 0.004057728601458481, "phrase": "agent-based_pedestrian_simulators"}, {"score": 0.003992729692096799, "phrase": "specific_level"}, {"score": 0.0038285451859508815, "phrase": "layered_architectures"}, {"score": 0.003767203575060969, "phrase": "different_behavioral_levels"}, {"score": 0.0035543706594585076, "phrase": "embodied_agent"}, {"score": 0.003430249143748777, "phrase": "virtual_environment"}, {"score": 0.0033971539563683174, "phrase": "main_goal"}, {"score": 0.003278504512223807, "phrase": "learned_behaviors"}, {"score": 0.003194816815998026, "phrase": "pedestrian_scenario"}, {"score": 0.0031233388358844188, "phrase": "pedestrian_modeling_literature"}, {"score": 0.002985130390111069, "phrase": "shortest_path"}, {"score": 0.0029658905122290536, "phrase": "quickest_path"}, {"score": 0.00281635677605879, "phrase": "narrow_corridor"}, {"score": 0.002622947550220266, "phrase": "different_problems"}, {"score": 0.002597620940221604, "phrase": "individual_behaviors"}, {"score": 0.002514947446797848, "phrase": "adequate_fundamental_diagrams"}, {"score": 0.0024987304152852873, "phrase": "route-choice_capability"}, {"score": 0.002466608618694819, "phrase": "collective_behaviors"}, {"score": 0.0023650305205893353, "phrase": "helbing's_social_forces"}, {"score": 0.002260301305523054, "phrase": "pedestrian_dynamics"}, {"score": 0.0021672007484097575, "phrase": "variate_plausible_behaviors"}, {"score": 0.0021462652605453163, "phrase": "human-like_macroscopic_pedestrian_flow"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Route-choice", " Path-planning", " Sarsa(lambda)"], "paper_abstract": "Pedestrian simulation is complex because there are different levels of behavior modeling. At the lowest level, local interactions between agents occur; at the middle level, strategic and tactical behaviors appear like overtakings or route choices; and at the highest level path-planning is necessary. The agent-based pedestrian simulators either focus on a specific level (mainly in the lower one) or define strategies like the layered architectures to independently manage the different behavioral levels. In our Multi-Agent Reinforcement-Learning-based Pedestrian simulation framework (MARL-Ped) the situation is addressed as a whole. Each embodied agent uses a model-free Reinforcement Learning (RL) algorithm to learn autonomously to navigate in the virtual environment. The main goal of this work is to demonstrate empirically that MARL-Ped generates learned behaviors adapted to the level required by the pedestrian scenario. Three different experiments, described in the pedestrian modeling literature, are presented to test our approach: (i) election of the shortest path vs. quickest path; (ii) a crossing between two groups of pedestrians walking in opposite directions inside a narrow corridor; (iii) two agents that move in opposite directions inside a maze. The results show that MARL-Ped solves the different problems, learning individual behaviors with characteristics of pedestrians (local control that produces adequate fundamental diagrams, route-choice capability, emergence of collective behaviors and path-planning). Besides, we compared our model with that of Helbing's social forces, a well-known model of pedestrians, showing similarities between the pedestrian dynamics generated by both approaches. These results demonstrate empirically that MARL-Ped generates variate plausible behaviors, producing human-like macroscopic pedestrian flow. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "MARL-Ped: A multi-agent reinforcement learning based framework to simulate pedestrian groups", "paper_id": "WOS:000343524000019"}