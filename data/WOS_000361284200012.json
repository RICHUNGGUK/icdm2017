{"auto_keywords": [{"score": 0.04934553301452922, "phrase": "fifo"}, {"score": 0.00481495049065317, "phrase": "structured_streams"}, {"score": 0.004777917315737992, "phrase": "stream_programming_languages"}, {"score": 0.004526503177267299, "phrase": "model_data_channels"}, {"score": 0.004190019394361629, "phrase": "read-and_write-pointers"}, {"score": 0.004046843083499649, "phrase": "producer's_write-operations"}, {"score": 0.0038934666267504596, "phrase": "dataflow_implicit"}, {"score": 0.003804234575698981, "phrase": "indirect_token-access"}, {"score": 0.0037170399498025215, "phrase": "standard_optimizations"}, {"score": 0.0036459007842756983, "phrase": "program_performance"}, {"score": 0.0034941337957136013, "phrase": "structured_stream_programming_languages"}, {"score": 0.0034008496666026585, "phrase": "buffer_management"}, {"score": 0.002993439939273828, "phrase": "c_compilation_framework"}, {"score": 0.0027599042621376624, "phrase": "enabling_effect"}, {"score": 0.002707033618304716, "phrase": "llvm's_optimizations"}, {"score": 0.0025942468561537682, "phrase": "randomized_input"}, {"score": 0.0025347150832077175, "phrase": "partial_results"}, {"score": 0.002429090371567499, "phrase": "amd_opteron"}, {"score": 0.0022744242010653997, "phrase": "platform-specific_speedups"}, {"score": 0.00218807532188779, "phrase": "memory_accesses"}, {"score": 0.0021461354559957234, "phrase": "energy_savings"}], "paper_keywords": ["Languages", " Algorithms", " Performance", " stream programming", " synchronous data flow", " program transformation", " performance analysis", " compiler optimization"], "paper_abstract": "Stream programming languages employ FIFO (first-in, first-out) semantics to model data channels between producers and consumers. A FIFO data channel stores tokens in a buffer that is accessed indirectly via read-and write-pointers. This indirect token-access decouples a producer's write-operations from the read-operations of the consumer, thereby making dataflow implicit. For a compiler, indirect token-access obscures data-dependencies, which renders standard optimizations ineffective and impacts stream program performance negatively. In this paper we propose a transformation for structured stream programming languages such as StreamIt that shifts FIFO buffer management from run-time to compile-time and eliminates splitters and joiners, whose task is to distribute and merge streams. To show the effectiveness of our lowering transformation, we have implemented a StreamIt to C compilation framework. We have developed our own intermediate representation (IR) called LaminarIR, which facilitates the transformation. We report on the enabling effect of the LaminarIR on LLVM's optimizations, which required the conversion of several standard StreamIt benchmarks from static to randomized input, to prevent computation of partial results at compile-time. We conducted our experimental evaluation on the Intel i7-2600K, AMD Opteron 6378, Intel Xeon Phi 3120A and ARM Cortex-A15 platforms. Our LaminarIR reduces data-communication on average by 35.9% and achieves platform-specific speedups between 3.73x and 4.98x over StreamIt. We reduce memory accesses by more than 60% and achieve energy savings of up to 93.6% on the Intel i7-2600K.", "paper_title": "LaminarIR: Compile-Time Queues for Structured Streams", "paper_id": "WOS:000361284200012"}