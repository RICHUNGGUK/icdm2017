{"auto_keywords": [{"score": 0.044454016803517404, "phrase": "shape_feature"}, {"score": 0.034496156070108086, "phrase": "distance_distribution_function"}, {"score": 0.00481495049065317, "phrase": "local_information"}, {"score": 0.004781777766309739, "phrase": "shape_representation"}, {"score": 0.004716113134313215, "phrase": "content-based_image_retrieval"}, {"score": 0.004571630734130793, "phrase": "research_community"}, {"score": 0.0045088388224419, "phrase": "content_features"}, {"score": 0.0043706785731816265, "phrase": "effective_shape_representation"}, {"score": 0.004295752645085445, "phrase": "challenging_task"}, {"score": 0.004135387221172467, "phrase": "content-based_systems"}, {"score": 0.004078562617505643, "phrase": "meaningful_semantics"}, {"score": 0.003926273177600597, "phrase": "humans'_perception"}, {"score": 0.0037148167062767096, "phrase": "image_retrieval"}, {"score": 0.0036259093827331725, "phrase": "effective_image_decomposition_method"}, {"score": 0.0036008989464331835, "phrase": "crawling_window"}, {"score": 0.003360057874429478, "phrase": "individual_shape"}, {"score": 0.0033023994098455457, "phrase": "novel_representation_model"}, {"score": 0.0030708096989903945, "phrase": "shape's_contour"}, {"score": 0.002865320947289691, "phrase": "distance_values"}, {"score": 0.002655087144676306, "phrase": "component_ddfs"}, {"score": 0.0026004698404274483, "phrase": "local_signal_information"}, {"score": 0.002538164420139397, "phrase": "transformation_technique"}, {"score": 0.0024859463164240603, "phrase": "feature_vector"}, {"score": 0.002401286805515306, "phrase": "circular_order"}, {"score": 0.0023764543399388658, "phrase": "final_shape_representation"}, {"score": 0.0022404996930993413, "phrase": "similarity_measure_model"}, {"score": 0.0022096550791379033, "phrase": "new_representation"}, {"score": 0.0021049977753042253, "phrase": "existing_representation_model"}], "paper_keywords": ["image retrieval", " shape representation", " local", " component distance distribution function"], "paper_abstract": "Research in content-based image retrieval has been around for over a decade. While the research community has successfully exploited content features such as color and texture, finding an effective shape representation and measure remains a challenging task. The shape feature is particularly crucial for the success of content-based systems as it carries meaningful semantics of the objects of interest and fits more naturally into humans' perception of similarity. In this paper, we present our approach to use the shape feature for image retrieval. First, we introduce an effective image decomposition method called Crawling Window (CW) to distinguish the outline of each object in the image. Second, to represent each individual shape, we propose a novel representation model called component Distance Distribution Function and its measure. Traditionally, an object is represented by a set of points on the shape's contour. Our idea is to first compute the distance between each point and the center of the object. The distance values for all points form a signal, which we call Distance Distribution Function (DDF). Each DDF is then divided into component DDFs (cDDF) by taking local signal information into account. Finally, a transformation technique is employed to generate the feature vector for each cDDF. All vectors from the cDDFs in circular order construct the final shape representation. The model is invariant to position, scaling, rotation and starting point. The similarity measure model based on the new representation is also introduced. Our extensive experiments show that our models are more effective than the existing representation model, both in the shape and the image level.", "paper_title": "Capture local information in shape representation", "paper_id": "WOS:000245134000003"}