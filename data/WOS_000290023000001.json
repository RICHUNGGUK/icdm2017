{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "heuristic_planning"}, {"score": 0.008836263147142517, "phrase": "node_evaluations"}, {"score": 0.0055474943715526255, "phrase": "learned_classifiers"}, {"score": 0.004773904938276846, "phrase": "relational_decision_trees"}, {"score": 0.00473320761888448, "phrase": "current_evaluation_functions"}, {"score": 0.0045543011700929096, "phrase": "numerous_planning_problems"}, {"score": 0.004476963405985556, "phrase": "good_guidance"}, {"score": 0.0041984140090404985, "phrase": "evaluation_functions"}, {"score": 0.0038207994186834015, "phrase": "heuristic_planners"}, {"score": 0.0036762529165489644, "phrase": "novel_solution"}, {"score": 0.0035523480068927614, "phrase": "machine_learning"}, {"score": 0.0034033029171804106, "phrase": "search_control"}, {"score": 0.003331134183901191, "phrase": "relational_classification_task"}, {"score": 0.0032465423581390625, "phrase": "off-the-shelf_relational_classification_tool"}, {"score": 0.0031102878400698143, "phrase": "preferred_action"}, {"score": 0.003044313656896057, "phrase": "different_planning_contexts"}, {"score": 0.0030054007508185858, "phrase": "specific_planning_domain"}, {"score": 0.00296698375549856, "phrase": "planning_contexts"}, {"score": 0.002879237498994052, "phrase": "helpful_actions"}, {"score": 0.002842428606954139, "phrase": "current_state"}, {"score": 0.0027114323601885666, "phrase": "static_predicates"}, {"score": 0.0026767629720554397, "phrase": "planning_task"}, {"score": 0.0025424508991051483, "phrase": "heuristic_planner"}, {"score": 0.0024148618915672353, "phrase": "resulting_classifier"}, {"score": 0.0023839754995935184, "phrase": "action_policy"}, {"score": 0.002353483216544667, "phrase": "second_one"}, {"score": 0.002274059352027924, "phrase": "lookahead_states"}, {"score": 0.0022449697898020947, "phrase": "best_first_search_algorithm"}, {"score": 0.0021049977753042253, "phrase": "larger_problems"}], "paper_keywords": [""], "paper_abstract": "Current evaluation functions for heuristic planning are expensive to compute. In numerous planning problems these functions provide good guidance to the solution, so they are worth the expense. However, when evaluation functions are misguiding or when planning problems are large enough, lots of node evaluations must be computed, which severely limits the scalability of heuristic planners. In this paper, we present a novel solution for reducing node evaluations in heuristic planning based on machine learning. Particularly, we define the task of learning search control for heuristic planning as a relational classification task, and we use an off-the-shelf relational classification tool to address this learning task. Our relational classification task captures the preferred action to select in the different planning contexts of a specific planning domain. These planning contexts are defined by the set of helpful actions of the current state, the goals remaining to be achieved, and the static predicates of the planning task. This paper shows two methods for guiding the search of a heuristic planner with the learned classifiers. The first one consists of using the resulting classifier as an action policy. The second one consists of applying the classifier to generate lookahead states within a Best First Search algorithm. Experiments over a variety of domains reveal that our heuristic planner using the learned classifiers solves larger problems than state-of-the-art planners.", "paper_title": "Scaling up Heuristic Planning with Relational Decision Trees", "paper_id": "WOS:000290023000001"}