{"auto_keywords": [{"score": 0.03397510895700812, "phrase": "simplification"}, {"score": 0.00481495049065317, "phrase": "real-time_action_model"}, {"score": 0.004497129150551236, "phrase": "logic-based_representation"}, {"score": 0.004436116555817464, "phrase": "action's_effects"}, {"score": 0.0042579795015449005, "phrase": "essential_requirement"}, {"score": 0.004143196873246147, "phrase": "intelligent_behavior"}, {"score": 0.0038695436922618876, "phrase": "complex_domains"}, {"score": 0.0037395458116642306, "phrase": "time-consuming_and_error-prone_task"}, {"score": 0.0034686643139273934, "phrase": "action_models"}, {"score": 0.003306559295382181, "phrase": "novel_action_learning_algorithm"}, {"score": 0.002883833572486452, "phrase": "first_experimental_results"}, {"score": 0.002825251837733693, "phrase": "real-world_robots"}, {"score": 0.002767856819656175, "phrase": "syrotek_platform"}, {"score": 0.002730240935688002, "phrase": "simulated_agents"}, {"score": 0.002693134880651768, "phrase": "action_computer_game"}, {"score": 0.0026747708876640377, "phrase": "unreal_tournament"}, {"score": 0.002532284627202572, "phrase": "available_alternatives"}, {"score": 0.002463906556781983, "phrase": "probabilistic_action_models"}, {"score": 0.002430411367515404, "phrase": "conditional_effects"}, {"score": 0.002364777610365689, "phrase": "action_failures"}, {"score": 0.002332626862738603, "phrase": "sensoric_noise"}, {"score": 0.002285216591220303, "phrase": "incomplete_observations"}, {"score": 0.002238767763626708, "phrase": "main_difference"}, {"score": 0.0021049977753042253, "phrase": "online_algorithm"}], "paper_keywords": [""], "paper_abstract": "An action model, as a logic-based representation of action's effects and preconditions, constitutes an essential requirement for planning and intelligent behavior. Writing these models by hand, especially in complex domains, is often a time-consuming and error-prone task. An alternative approach is to let the agents learn action models from their own observations. We introduce a novel action learning algorithm called 3SG (Simultaneous Specification, Simplification, and Generalization), analyze and prove some of its properties, and present the first experimental results (using real-world robots of the SyRoTek platform and simulated agents in action computer game Unreal Tournament 2004). Unlike the majority of available alternatives, 3SG produces probabilistic action models with conditional effects and deals with action failures, sensoric noise, and incomplete observations. The main difference, however, is that 3SG is an online algorithm, which means it is rather fast (polynomial in the size of the input) but potentially less precise.", "paper_title": "REAL-TIME ACTION MODEL LEARNING WITH ONLINE ALGORITHM 3SG", "paper_id": "WOS:000340389400003"}