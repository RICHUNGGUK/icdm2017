{"auto_keywords": [{"score": 0.04890702046127258, "phrase": "useful_metrics"}, {"score": 0.00481495049065317, "phrase": "metrics_collection"}, {"score": 0.00443308765153716, "phrase": "software_organisation"}, {"score": 0.0038518661517315533, "phrase": "organisational_goals"}, {"score": 0.0035461111918923117, "phrase": "potential_causes"}, {"score": 0.003132236287543072, "phrase": "useful_software_metrics"}, {"score": 0.003005271873916767, "phrase": "qualitative_research"}, {"score": 0.002907405102646616, "phrase": "case_study"}, {"score": 0.0027211030647461324, "phrase": "previously_conducted_study"}, {"score": 0.0026764185202909395, "phrase": "project_post-mortem_reviews"}, {"score": 0.0022122603123901114, "phrase": "previous_case_study"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["emperical software engineering", " postmortem analysis"], "paper_abstract": "Defining useful metrics to measure the goals of a software organisation is difficult. Defining useful metrics to measure the causes of the (failure) to fulfil those organisational goals is even more difficult, as the diversity of potential causes makes their measurement illusive. In this article, we describe a method to select useful software metrics based on findings from qualitative research. In a case study, we apply this method to a previously conducted study of project post-mortem reviews to assess the validity of our prior claims. For this we collected data on 109 new software projects in the organisation in which we conducted the previous case study. (C) 2007 Elsevier Inc. All rights reserved.", "paper_title": "Measuring where it matters: Determining starting points for metrics collection", "paper_id": "WOS:000255295900002"}