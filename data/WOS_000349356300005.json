{"auto_keywords": [{"score": 0.040417210564764244, "phrase": "target_concept"}, {"score": 0.00481495049065317, "phrase": "semantic_multimedia_indexing"}, {"score": 0.0045817497454044565, "phrase": "large_number"}, {"score": 0.004549366134876482, "phrase": "visual_concepts"}, {"score": 0.0044852808671980325, "phrase": "video_shots"}, {"score": 0.004406436661912347, "phrase": "art_systems"}, {"score": 0.004046775982578706, "phrase": "direct_multi-label_approaches"}, {"score": 0.003947492797744999, "phrase": "detection_scores"}, {"score": 0.0037295765964056255, "phrase": "\"conceptual_feedback"}, {"score": 0.0035487559182107112, "phrase": "overall_concepts_detection_performance"}, {"score": 0.003511159930253876, "phrase": "conceptual_descriptor"}, {"score": 0.003449379912099073, "phrase": "system's_output_scores"}, {"score": 0.0033172506969692626, "phrase": "already_available_descriptors"}, {"score": 0.0030570583408091488, "phrase": "conceptual_dimensions"}, {"score": 0.00285753732066807, "phrase": "explicit_selection"}, {"score": 0.0026710032893246154, "phrase": "video_indexing"}, {"score": 0.002623967178291655, "phrase": "third_extension"}, {"score": 0.0025869338215971536, "phrase": "temporal_dimension"}, {"score": 0.002559501330352064, "phrase": "feedback_process"}, {"score": 0.0024701382170046462, "phrase": "temporal_dimensions"}, {"score": 0.002435270624076196, "phrase": "high-level_descriptor"}, {"score": 0.0022441016229967025, "phrase": "temporal_re-scoring"}, {"score": 0.002220296517089146, "phrase": "proposed_method"}, {"score": 0.0021967433763351884, "phrase": "global_system_performance"}, {"score": 0.0021049977753042253, "phrase": "relative_improvement"}], "paper_keywords": ["Semantic indexing", " Multimedia", " Fusion", " Conceptual feedback", " Inter-concepts relationships", " Ontology", " Temporal context", " Semantic context", " TRECVid"], "paper_abstract": "In this paper, we consider the problem of automatically detecting a large number of visual concepts in images or video shots. State of the art systems generally involve feature (descriptor) extraction, classification (supervised learning) and fusion when several descriptors and/or classifiers are used. Though direct multi-label approaches are considered in some works, detection scores are often computed independently for each target concept. We propose a method that we call \"conceptual feedback\" which implicitly takes into account the relations between concepts to improve the overall concepts detection performance. A conceptual descriptor is built from the system's output scores and fed back by adding it to the pool of already available descriptors. Our proposal can be iterated several times. Moreover, we propose three extensions of our method. Firstly, a weighting of the conceptual dimensions is performed to give more importance to concepts which are more correlated to the target concept. Secondly, an explicit selection of a set of concepts that are semantically or statically related to the target concept is introduced. For video indexing, we propose a third extension which integrates the temporal dimension in the feedback process by taking into account simultaneously the conceptual and the temporal dimensions to build the high-level descriptor. Our proposals have been evaluated in the context of the TRECVid 2012 semantic indexing task involving the detection of 346 visual or multi-modal concepts. Overall, combined with temporal re-scoring, the proposed method increased the global system performance (MAP) from 0.2613 to 0.3082 ( + 17.9 % of relative improvement) while the temporal re-scoring alone increased it only from 0.2613 to 0.2691 ( + 3.0 %).", "paper_title": "Extended conceptual feedback for semantic multimedia indexing", "paper_id": "WOS:000349356300005"}