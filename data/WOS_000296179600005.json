{"auto_keywords": [{"score": 0.04503881805285862, "phrase": "strict_throughput_requirements"}, {"score": 0.00481495049065317, "phrase": "application_workflows"}, {"score": 0.0045324756541157574, "phrase": "multiple_performance_metrics"}, {"score": 0.0043533862892678864, "phrase": "real-time_constraints"}, {"score": 0.004202472962684885, "phrase": "low_latency_or_response_time"}, {"score": 0.004016072233242585, "phrase": "novel_algorithm"}, {"score": 0.003780286517897356, "phrase": "input_data"}, {"score": 0.003152531962718477, "phrase": "latency_requirements"}, {"score": 0.003012560489169148, "phrase": "data_parallelism"}, {"score": 0.0029672941061574375, "phrase": "coordinated_manner"}, {"score": 0.002821247621250663, "phrase": "task_duplication"}, {"score": 0.0027788478707700274, "phrase": "communication_overheads"}, {"score": 0.0027370835853738626, "phrase": "pipelined_schedule"}, {"score": 0.002709589081384597, "phrase": "different_workflow_characteristics"}, {"score": 0.0026688629249775925, "phrase": "proposed_algorithm"}, {"score": 0.0026023381988430666, "phrase": "realistic_bounded_multi-port_communication_model"}, {"score": 0.0024125253170522816, "phrase": "experimental_evaluation"}, {"score": 0.002388283252319309, "phrase": "synthetic_benchmarks"}, {"score": 0.0023053339328456234, "phrase": "real_applications"}, {"score": 0.0022365262201954643, "phrase": "lower_latency_schedules"}, {"score": 0.002202894673025544, "phrase": "throughput_requirements"}, {"score": 0.0021807544600219216, "phrase": "even_when_previously_proposed_schemes"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Streaming applications", " Throughput", " Latency", " Task-parallelism", " Data-parallelism", " Pipelined-parallelism"], "paper_abstract": "Scheduling, in many application domains, involves optimization of multiple performance metrics. For example, application workflows with real-time constraints have strict throughput requirements and also desire a low latency or response time. In this paper, we present a novel algorithm for the scheduling of workflows that act on a stream of input data. Our algorithm focuses on the two performance metrics, latency and throughput, and minimizes the latency of workflows while satisfying strict throughput requirements. We also describe steps to use the above approach to solve the problem of meeting latency requirements while maximizing throughput. We leverage pipelined, task and data parallelism in a coordinated manner to meet these objectives and investigate the benefit of task duplication in alleviating communication overheads in the pipelined schedule for different workflow characteristics. The proposed algorithm is designed for a realistic bounded multi-port communication model, where each processor can simultaneously communicate with at most k distinct processors. Experimental evaluation using synthetic benchmarks as well as those derived from real applications shows that our algorithm consistently produces lower latency schedules that meet throughput requirements, even when previously proposed schemes fail. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Optimizing latency and throughput of application workflows on clusters", "paper_id": "WOS:000296179600005"}