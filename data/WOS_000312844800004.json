{"auto_keywords": [{"score": 0.04702000392375609, "phrase": "robust_face_recognition"}, {"score": 0.03407225739055563, "phrase": "sparse_representation"}, {"score": 0.013917025542657257, "phrase": "tsr"}, {"score": 0.00481495049065317, "phrase": "large-scale_face_recognition"}, {"score": 0.004689650818647484, "phrase": "novel_nonnegative_sparse_representation_approach"}, {"score": 0.004628223381645729, "phrase": "two-stage_sparse_representation"}, {"score": 0.004448705308279165, "phrase": "large-scale_database"}, {"score": 0.004128317208406523, "phrase": "outlier_detection_stage"}, {"score": 0.004092168350316413, "phrase": "recognition_stage"}, {"score": 0.004020813632357377, "phrase": "first_stage"}, {"score": 0.0039333604469462356, "phrase": "general_multisubspace_framework"}, {"score": 0.0038647641000798135, "phrase": "robust_metric"}, {"score": 0.003747575730190958, "phrase": "image_pixels"}, {"score": 0.003682207422331339, "phrase": "potential_loss_functions"}, {"score": 0.00346223706087128, "phrase": "second_stage"}, {"score": 0.0033868916699805224, "phrase": "learned_metric_and_collaborative_representation"}, {"score": 0.0033131804981786747, "phrase": "efficient_nonnegative_sparse_representation_algorithm"}, {"score": 0.003255364511414329, "phrase": "approximation_solution"}, {"score": 0.00308788133472785, "phrase": "approximated_solution"}, {"score": 0.002941913249957503, "phrase": "filtering_strategy"}, {"score": 0.002790511479398411, "phrase": "whole_large-scale_dataset"}, {"score": 0.0027417911324611917, "phrase": "theoretical_analysis"}, {"score": 0.002693919110230191, "phrase": "necessary_condition"}, {"score": 0.0025892330566358503, "phrase": "sparse_solution"}, {"score": 0.0025665261770229757, "phrase": "extensive_experiments"}, {"score": 0.002488604965680912, "phrase": "proposed_tsr_approach"}, {"score": 0.0024236964502593254, "phrase": "better_classification_accuracy"}, {"score": 0.0023918783117166326, "phrase": "state-of-the-art_sparse_representation_methods"}, {"score": 0.002298902547676131, "phrase": "computational_costs"}, {"score": 0.002238930800075706, "phrase": "sparse_representation_classifier"}, {"score": 0.0021049977753042253, "phrase": "large-scale_dataset"}], "paper_keywords": ["Correntropy", " L-1 regularization", " large-scale", " nonnegative sparse representation", " robust face recognition"], "paper_abstract": "This paper proposes a novel nonnegative sparse representation approach, called two-stage sparse representation (TSR), for robust face recognition on a large-scale database. Based on the divide and conquer strategy, TSR decomposes the procedure of robust face recognition into outlier detection stage and recognition stage. In the first stage, we propose a general multisubspace framework to learn a robust metric in which noise and outliers in image pixels are detected. Potential loss functions, including L-1, L-2,L-1, and correntropy are studied. In the second stage, based on the learned metric and collaborative representation, we propose an efficient nonnegative sparse representation algorithm to find an approximation solution of sparse representation. According to the L1 ball theory in sparse representation, the approximated solution is unique and can be optimized efficiently. Then a filtering strategy is developed to avoid the computation of the sparse representation on the whole large-scale dataset. Moreover, theoretical analysis also gives the necessary condition for nonnegative least squares technique to find a sparse solution. Extensive experiments on several public databases have demonstrated that the proposed TSR approach, in general, achieves better classification accuracy than the state-of-the-art sparse representation methods. More importantly, a significant reduction of computational costs is reached in comparison with sparse representation classifier; this enables the TSR to be more suitable for robust face recognition on a large-scale dataset.", "paper_title": "Two-Stage Nonnegative Sparse Representation for Large-Scale Face Recognition", "paper_id": "WOS:000312844800004"}