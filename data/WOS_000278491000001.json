{"auto_keywords": [{"score": 0.03816309879143336, "phrase": "automatic_annotation_system"}, {"score": 0.00481495049065317, "phrase": "automatic_annotation"}, {"score": 0.0046390482426405324, "phrase": "richly_annotated_dialogue_corpora"}, {"score": 0.004570491683870396, "phrase": "new_research_directions"}, {"score": 0.004536592536813498, "phrase": "statistical_learning_approaches"}, {"score": 0.004502943680955863, "phrase": "dialogue_management"}, {"score": 0.0044695432851061525, "phrase": "context-sensitive_interpretation"}, {"score": 0.004419904580451831, "phrase": "context-sensitive_speech_recognition"}, {"score": 0.004338390136272005, "phrase": "large_dialogue_corpora"}, {"score": 0.004290201740122912, "phrase": "contextual_information_and_speech_acts"}, {"score": 0.0041642891310893, "phrase": "existing_dialogue_corpora"}, {"score": 0.004087469540575263, "phrase": "utterance_transcriptions"}, {"score": 0.0039674831861175935, "phrase": "new_corpora"}, {"score": 0.0039380388343479384, "phrase": "dialogue_context_and_speech_acts"}, {"score": 0.0038224221344037236, "phrase": "conceptual_and_computational_framework"}, {"score": 0.0034309482755326016, "phrase": "human_machine_dialogues"}, {"score": 0.0032444113660668743, "phrase": "reinforcement_learning"}, {"score": 0.003220315882881027, "phrase": "dialogue_policies"}, {"score": 0.0031726587374218277, "phrase": "user_simulations"}, {"score": 0.0031257046538823354, "phrase": "different_dialogue_strategies"}, {"score": 0.0030451958332949735, "phrase": "training_models"}, {"score": 0.0030225753906647935, "phrase": "context-dependent_interpretation"}, {"score": 0.002911961514073769, "phrase": "user_utterances"}, {"score": 0.0028903278985330117, "phrase": "speech_acts"}, {"score": 0.002826383890518307, "phrase": "dialogue_context_representations"}, {"score": 0.0027949428646076627, "phrase": "isu_dialogue_manager"}, {"score": 0.0026826140171754675, "phrase": "detailed_example"}, {"score": 0.0026330549554033876, "phrase": "system_components"}, {"score": 0.00247128526955136, "phrase": "task_completion_metrics"}, {"score": 0.002443784721651744, "phrase": "original_corpus"}, {"score": 0.002398627220761345, "phrase": "hand-annotated_data"}, {"score": 0.002345535736297701, "phrase": "baseline_automatic_system"}, {"score": 0.002319431279824863, "phrase": "automatic_annotations"}, {"score": 0.002259642580775186, "phrase": "baseline_automatic_annotations"}, {"score": 0.0022096205841489786, "phrase": "resulting_annotated_corpus"}, {"score": 0.0021607035327962246, "phrase": "high-quality_user_simulations"}, {"score": 0.002128694000627911, "phrase": "successful_dialogue_strategies"}, {"score": 0.0021049977753042253, "phrase": "final_corpus"}], "paper_keywords": [""], "paper_abstract": "Richly annotated dialogue corpora are essential for new research directions in statistical learning approaches to dialogue management, context-sensitive interpretation, and context-sensitive speech recognition. In particular, large dialogue corpora annotated with contextual information and speech acts are urgently required. We explore how existing dialogue corpora (usually consisting of utterance transcriptions) can be automatically processed to yield new corpora where dialogue context and speech acts are accurately represented. We present a conceptual and computational framework for generating such corpora. As an example. we present and evaluate an automatic annotation system which builds 'Information State Update' (ISU) representations of dialogue context for the COMMUNICATOR (2000 and 2001) corpora of human machine dialogues (2,331 dialoguest. The purposes of this annotation are to generate corpora for reinforcement learning of dialogue policies, for building user simulations, for evaluating different dialogue strategies against a baseline, and for training models for context-dependent interpretation and speech recognition. The automatic annotation system parses system and user utterances into speech acts and builds up sequences of dialogue context representations using an ISU dialogue manager. We present the architecture of the automatic annotation system and a detailed example to illustrate how the system components interact to produce the annotations. We also evaluate the annotations, with respect to the task completion metrics of the original corpus and in comparison to hand-annotated data and annotations produced by a baseline automatic system. The automatic annotations perform well and largely outperform the baseline automatic annotations in all measures. The resulting annotated corpus has been used to train high-quality user simulations and to learn successful dialogue strategies. The final corpus will be made publicly available.", "paper_title": "Automatic annotation of context and speech acts for dialogue corpora", "paper_id": "WOS:000278491000001"}