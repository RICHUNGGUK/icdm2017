{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "web_video_categorization"}, {"score": 0.004330099613414957, "phrase": "automatic_web_video_categorization"}, {"score": 0.004075198669927074, "phrase": "content_descriptors"}, {"score": 0.0034226302212225206, "phrase": "classification_system"}, {"score": 0.0032702516771609957, "phrase": "information_retrieval_approach"}, {"score": 0.0030542703032534766, "phrase": "real-world_scenario"}, {"score": 0.0029182434479165884, "phrase": "blip.tv_media_platform"}, {"score": 0.0027671619871474764, "phrase": "video_footage"}, {"score": 0.0026040262154057607, "phrase": "descriptor_semantic_gap"}, {"score": 0.0025069746344846397, "phrase": "new_relevance_feedback_technique"}, {"score": 0.002413531395475291, "phrase": "hierarchical_clustering"}, {"score": 0.002288519595829552, "phrase": "technique_retrieval_performance"}, {"score": 0.0021049977753042253, "phrase": "high_level_semantic_textual_descriptors"}], "paper_keywords": ["Audio block-based descriptors", " Color perception", " Action assessment", " Video relevance feedback", " Video genre classification"], "paper_abstract": "In this paper, we discuss and audio-visual approach to automatic web video categorization. To this end, we propose content descriptors which exploit audio, temporal, and color content. The power of our descriptors was validated both in the context of a classification system and as part of an information retrieval approach. For this purpose, we used a real-world scenario, comprising 26 video categories from the blip.tv media platform (up to 421 h of video footage). Additionally, to bridge the descriptor semantic gap, we propose a new relevance feedback technique which is based on hierarchical clustering. Experiments demonstrated that with this technique retrieval performance can be increased significantly and becomes comparable to that of high level semantic textual descriptors.", "paper_title": "An audio-visual approach to web video categorization", "paper_id": "WOS:000336995900019"}