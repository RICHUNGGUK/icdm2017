{"auto_keywords": [{"score": 0.03498206979223964, "phrase": "location_privacy"}, {"score": 0.010612387000973441, "phrase": "distance_bounding"}, {"score": 0.008404152078712595, "phrase": "distance-bounding_protocols"}, {"score": 0.0067811129626374955, "phrase": "security_game"}, {"score": 0.004357061494162031, "phrase": "particular_location"}, {"score": 0.00429057323623293, "phrase": "automobile_or_building_access_control"}, {"score": 0.0040971095888461045, "phrase": "signal_attenuation"}, {"score": 0.004003660777805554, "phrase": "additional_transmitters"}, {"score": 0.003764713814123286, "phrase": "main_countermeasure"}, {"score": 0.003459191419478298, "phrase": "distance-bounding_protocol"}, {"score": 0.00334144503360907, "phrase": "formal_model"}, {"score": 0.0029428772818833166, "phrase": "adversarial_model"}, {"score": 0.002381169982803105, "phrase": "polynomially-bounded_adversary"}, {"score": 0.002308910575113746, "phrase": "so-called_limited_adversaries"}, {"score": 0.0022302306304023602, "phrase": "arbitrary_provers"}, {"score": 0.002213112756450354, "phrase": "carefully_chosen_parameters"}, {"score": 0.002154226045704907, "phrase": "computational_location_privacy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Location privacy", " Distance-bounting", " Authentication", " Location indistinguishability", " Relay attacks"], "paper_abstract": "In many cases, we can only have access to a service by proving we are sufficiently close to a particular location (e.g. in automobile or building access control). In these cases, proximity can be guaranteed through signal attenuation. However, by using additional transmitters an attacker can relay signals between the prover and the verifier. Distance-bounding protocols are the main countermeasure against such attacks; however, such protocols may leak information regarding the location of the prover and/or the verifier who run the distance-bounding protocol. In this paper, we consider a formal model for location privacy in the context of distance-bounding. In particular, our contributions are threefold: we first define a security game for location privacy in distance bounding; secondly, we define an adversarial model for this game, with two adversary classes; finally, we assess the feasibility of attaining location privacy for distance-bounding protocols. Concretely, we prove that for protocols with a beginning or a termination, it is theoretically impossible to achieve location privacy for either of the two adversary classes, in the sense that there always exists a polynomially-bounded adversary winning the security game. However, for so-called limited adversaries, who cannot see the location of arbitrary provers, carefully chosen parameters do, in practice, enable computational location privacy. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Location leakage in distance bounding: Why location privacy does not work", "paper_id": "WOS:000341340600014"}