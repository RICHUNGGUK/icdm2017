{"auto_keywords": [{"score": 0.049331670369837356, "phrase": "large_number"}, {"score": 0.00481495049065317, "phrase": "linear_discriminant_analysis"}, {"score": 0.004485735417293941, "phrase": "challenging_problem"}, {"score": 0.003954837422946628, "phrase": "different_dimensionality-reduction"}, {"score": 0.003772306776343196, "phrase": "different_classes"}, {"score": 0.0035699363258657212, "phrase": "intuitive_idea"}, {"score": 0.00348655247465418, "phrase": "traditional_linear_discriminant_analysis"}, {"score": 0.003432399017695478, "phrase": "lda"}, {"score": 0.0029547698888028697, "phrase": "class-adaptive_feature_selection"}, {"score": 0.0025038930574283174, "phrase": "single-subspace_counterparts"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Linear Discriminant Analysis", " Trace-ratio", " Subspace learning", " Face recognition", " Pattern recognition"], "paper_abstract": "We study the challenging problem to classify samples into a large number of classes, and propose the idea of using different Dimensionality-Reduction (DR) projections for different classes of samples. Based on this intuitive idea, the traditional Linear Discriminant Analysis (LDA) and the trace-ratio LDA are formulated to their corresponding new multi-subspace objectives. We justify that certain effects of class-adaptive feature selection are naturally achieved via our multi-subspace DR methods. Experiments on seven datasets show that, our multi-subspace trace-ratio LDA outperform its ratio-trace and single-subspace counterparts, and its advantage is more apparent when the number of classes to be classified is large. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "On the linear discriminant analysis for large number of classes", "paper_id": "WOS:000356118900002"}