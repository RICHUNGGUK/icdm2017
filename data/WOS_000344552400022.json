{"auto_keywords": [{"score": 0.03570147413252297, "phrase": "host_thread"}, {"score": 0.00481495049065317, "phrase": "multi-gpu_heterogeneous_architectures"}, {"score": 0.004603115982404017, "phrase": "single_application"}, {"score": 0.004509919457793852, "phrase": "multiple_gpu_accelerators"}, {"score": 0.0044549056501745074, "phrase": "parallel_task_programming_paradigm"}, {"score": 0.004241451614311598, "phrase": "parallel_for_template"}, {"score": 0.0041555469216463855, "phrase": "heterogeneous_architectures"}, {"score": 0.004021689117050817, "phrase": "computing_resources"}, {"score": 0.003892126266260425, "phrase": "dynamic_scheduling_strategy"}, {"score": 0.003828912548622257, "phrase": "adaptive_partitioning_scheme"}, {"score": 0.0037055370870874484, "phrase": "load_imbalance"}, {"score": 0.00342816445816304, "phrase": "cpu_core"}, {"score": 0.002970487219127993, "phrase": "gpu"}, {"score": 0.0028862761537904206, "phrase": "useful_chunk_processing"}, {"score": 0.002626645763725465, "phrase": "scheduling_threads"}, {"score": 0.002605201547405916, "phrase": "available_cpu_cores"}, {"score": 0.002500571634075998, "phrase": "useful_work"}], "paper_keywords": ["Heterogeneous computing", " Dynamic scheduling", " Adaptive partitioning", " Task parallelism", " Oversubscription", " Synchronization"], "paper_abstract": "This paper explores the possibility of efficiently executing a single application using multicores simultaneously with multiple GPU accelerators under a parallel task programming paradigm. In particular, we address the challenge of extending a parallel_for template to allow its exploitation on heterogeneous architectures. Due to the asymmetry of the computing resources, we propose in this work a dynamic scheduling strategy coupled with an adaptive partitioning scheme that resizes chunks to prevent underutilization and load imbalance of CPUs and GPUs. In this paper we also address the problem of the underutilization of the CPU core where a host thread operates. To solve it, we propose two different approaches: (1) a collaborative host thread strategy, in which the host thread, instead of busy-waiting for the GPU to complete, it carries out useful chunk processing; and (2) a host thread blocking strategy combined with oversubscription, that delegates on the OS the duty of scheduling threads to available CPU cores in order to guarantee that all cores are doing useful work. Using two benchmarks we evaluate the overhead introduced by our scheduling and partitioning algorithms, finding that it is negligible. We also evaluate the efficiency of the strategies proposed finding that allowing oversubscription controlled by the OS can be beneficial under certain scenarios.", "paper_title": "Strategies for maximizing utilization on multi-CPU and multi-GPU heterogeneous architectures", "paper_id": "WOS:000344552400022"}