{"auto_keywords": [{"score": 0.044585905779495894, "phrase": "tsqr"}, {"score": 0.0434024291727597, "phrase": "orthogonal_factor"}, {"score": 0.033411018633315234, "phrase": "numerical_stability"}, {"score": 0.030372402321608233, "phrase": "householder_qr"}, {"score": 0.00481495049065317, "phrase": "householder_vectors"}, {"score": 0.004770211811866158, "phrase": "tall-skinny_qr."}, {"score": 0.004725886853744007, "phrase": "tall-skinny_qr"}, {"score": 0.004510336430422002, "phrase": "standard_householder_algorithm"}, {"score": 0.004468415400599571, "phrase": "qr_decomposition"}, {"score": 0.004205226397573506, "phrase": "different_representation"}, {"score": 0.003994624397219346, "phrase": "new_representation"}, {"score": 0.003812299519486331, "phrase": "trailing_matrix"}, {"score": 0.003689628075766217, "phrase": "square_matrix"}, {"score": 0.0035376693476114733, "phrase": "householder_representation"}, {"score": 0.0033447157263095223, "phrase": "householder_vector_representation"}, {"score": 0.0031919592786945126, "phrase": "high_performance"}, {"score": 0.0030178044717552605, "phrase": "new_householder_reconstruction_algorithm"}, {"score": 0.0029069972482610403, "phrase": "significantly_lower_latency_cost"}, {"score": 0.002839812512030847, "phrase": "lower_bandwidth"}, {"score": 0.0028133741785871867, "phrase": "latency_costs"}, {"score": 0.0026474076254702525, "phrase": "communication_cost_improvements"}, {"score": 0.002562123444678208, "phrase": "substantial_improvements"}, {"score": 0.002538263784314365, "phrase": "tuned_library_implementations"}, {"score": 0.002514625755809045, "phrase": "tall-and-skinny_matrices"}, {"score": 0.002456486927713543, "phrase": "algorithmic_improvements"}, {"score": 0.0023996894085785273, "phrase": "caqr"}, {"score": 0.002300734266971646, "phrase": "householder_reconstruction_algorithm"}, {"score": 0.0021649437083408425, "phrase": "higher_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["QR decomposition", " Dense linear algebra", " Communication-avoiding algorithms"], "paper_abstract": "The Tall-Skinny QR (TSQR) algorithm is more communication efficient than the standard Householder algorithm for QR decomposition of matrices with many more rows than columns. However, TSQR produces a different representation of the orthogonal factor and therefore requires more software development to support the new representation. Further, implicitly applying the orthogonal factor to the trailing matrix in the context of factoring a square matrix is more complicated and costly than with the Householder representation. We show how to perform TSQR and then reconstruct the Householder vector representation with the same asymptotic communication efficiency and little extra computational cost. We demonstrate the high performance and numerical stability of this algorithm both theoretically and empirically. The new Householder reconstruction algorithm allows us to design more efficient parallel QR algorithms, with significantly lower latency cost compared to Householder QR and lower bandwidth and latency costs compared with Communication-Avoiding QR (CAQR) algorithm. Experiments on supercomputers demonstrate the benefits of the communication cost improvements: in particular, our experiments show substantial improvements over tuned library implementations for tall-and-skinny matrices. We also provide algorithmic improvements to the Householder QR and CAQR algorithms, and we investigate several alternatives to the Householder reconstruction algorithm that sacrifice guarantees on numerical stability in some cases in order to obtain higher performance. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Reconstructing Householder vectors from Tall-Skinny QR", "paper_id": "WOS:000362620200002"}