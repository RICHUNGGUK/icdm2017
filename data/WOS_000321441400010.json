{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "milp"}, {"score": 0.011729272190581981, "phrase": "perseus"}, {"score": 0.004786002454145624, "phrase": "based_value_backups"}, {"score": 0.004672583662761684, "phrase": "markov"}, {"score": 0.004293584349522444, "phrase": "markov_decision"}, {"score": 0.004116012194714212, "phrase": "powerful_tools"}, {"score": 0.004042166795461166, "phrase": "stochastic_systems"}, {"score": 0.00399367108161192, "phrase": "partial_state_information"}, {"score": 0.003898411343926653, "phrase": "exact_solution_methods"}, {"score": 0.003626000977962191, "phrase": "approximate_point-based_solution_methods"}, {"score": 0.0033725614574134396, "phrase": "mixed_integer_linear_program"}, {"score": 0.00306189690236109, "phrase": "similar_algorithms"}, {"score": 0.0029708119219485126, "phrase": "pomdp"}, {"score": 0.0026485829604700833, "phrase": "observation_space"}, {"score": 0.0025697460140513932, "phrase": "post-decision_belief_space"}, {"score": 0.002389956401870098, "phrase": "flow_network"}, {"score": 0.0021827653135510225, "phrase": "existing_techniques"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Markov decision processes", " Dynamic programming", " Mathematical programming", " Partial observation", " Network reliability"], "paper_abstract": "Partially observed Markov decision processes (POMDPs) serve as powerful tools to model stochastic systems with partial state information. Since the exact solution methods for POMDPs are limited to problems with very small sizes of state, action and observation spaces, approximate point-based solution methods like PERSEUS have gained popularity. In this work, a mixed integer linear program (MILP) is developed for calculation of exact value updates (in PERSEUS and similar algorithms), when the POMDP has very large or continuous action space. Since the solution time of the MILP is very sensitive to the size of the observation space, the concept of post-decision belief space is introduced to generate a more efficient and flexible model. An example involving a flow network is presented to illustrate the concepts and compare the results with those of the existing techniques. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "MILP based value backups in partially observed Markov decision processes (POMDPs) with very large or continuous action and observation spaces", "paper_id": "WOS:000321441400010"}