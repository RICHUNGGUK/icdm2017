{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "regularized_least_squares"}, {"score": 0.0047468516620285525, "phrase": "toeplitz_matrix"}, {"score": 0.0046797114400479135, "phrase": "machine_learning"}, {"score": 0.004296264970612285, "phrase": "linear_equations"}, {"score": 0.0042354707960660706, "phrase": "direct-solution_methods"}, {"score": 0.00388828234270598, "phrase": "large-scale_problems"}, {"score": 0.003752126270661821, "phrase": "approximate_solutions"}, {"score": 0.0036990033106718183, "phrase": "lower_complexities"}, {"score": 0.0032766780632972363, "phrase": "toeplitz_matrixes"}, {"score": 0.003029382820031577, "phrase": "memory_space"}, {"score": 0.002923214590192792, "phrase": "rls-based_machine"}, {"score": 0.0025892330566358503, "phrase": "one-dimensional_case"}, {"score": 0.0024984517279573906, "phrase": "analytical_criterion"}, {"score": 0.002445514186654732, "phrase": "effective_approximation"}, {"score": 0.0024108455980729284, "phrase": "multidimensional_domains"}, {"score": 0.002359759876402679, "phrase": "approach_validity"}, {"score": 0.0021971473452127126, "phrase": "highly_dimensional_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Regularized Least Squares", " Toeplitz matrix", " Levinson-Trench-Zohar algorithm", " Digital signal processor", " Large-scale learning", " Resources limited device"], "paper_abstract": "Machine Learning based on the Regularized Least Squares (RLS) model requires one to solve a system of linear equations. Direct-solution methods exhibit predictable complexity and storage, but often prove impractical for large-scale problems; iterative methods attain approximate solutions at lower complexities, but heavily depend on learning parameters. The paper shows that applying the properties of Toeplitz matrixes to RLS yields two benefits: first, both the computational cost and the memory space required to train an RLS-based machine reduce dramatically; secondly, timing and storage requirements are defined analytically. The paper proves this result formally for the one-dimensional case, and gives an analytical criterion for an effective approximation in multidimensional domains. The approach validity is demonstrated in several real-world problems involving huge data sets with highly dimensional data. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Efficient approximate Regularized Least Squares by Toeplitz matrix", "paper_id": "WOS:000286560600008"}