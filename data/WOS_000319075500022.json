{"auto_keywords": [{"score": 0.04540775794209852, "phrase": "slow_tasks"}, {"score": 0.010612387000973441, "phrase": "heterogeneous_environments"}, {"score": 0.008027343303541398, "phrase": "hadoop"}, {"score": 0.004760518730536645, "phrase": "mapreduce_model"}, {"score": 0.004583464412234181, "phrase": "map_tasks"}, {"score": 0.004480394224548146, "phrase": "execution_time"}, {"score": 0.004090682761004765, "phrase": "current_mapreduce_schedulers"}, {"score": 0.0040444053843446326, "phrase": "backup_task"}, {"score": 0.003879138659123195, "phrase": "traditional_mapreduce_schedulers"}, {"score": 0.0035415392642831616, "phrase": "zaharia_et_al"}, {"score": 0.0034749794034364197, "phrase": "operating_systems_design"}, {"score": 0.0034226458316767793, "phrase": "acm"}, {"score": 0.0033967510986397946, "phrase": "new_york"}, {"score": 0.0031484483754909026, "phrase": "history-based_auto-tuning"}, {"score": 0.002940487679224863, "phrase": "continuously_varying_environment"}, {"score": 0.0028095140358025, "phrase": "map_task"}, {"score": 0.0026843584448921565, "phrase": "history_tasks"}, {"score": 0.002643888053328987, "phrase": "accurate_weights"}, {"score": 0.002555040841339798, "phrase": "current_tasks"}, {"score": 0.0025069746344846375, "phrase": "accurate-calculated_progress"}, {"score": 0.0024411935317269705, "phrase": "remaining_time"}, {"score": 0.0023771343615901185, "phrase": "backup_tasks"}, {"score": 0.002314752262613559, "phrase": "longest_remaining_time"}, {"score": 0.0022972306948217548, "phrase": "experimental_results"}, {"score": 0.0022115879730677, "phrase": "mapreduce_applications"}, {"score": 0.0021049977753042253, "phrase": "late_scheduler"}], "paper_keywords": ["History-based auto-tuning", " Scheduling algorithm", " Heterogeneous environments", " MapReduce"], "paper_abstract": "In MapReduce model, a job is divided into a series of map tasks and reduce tasks. The execution time of the job is prolonged by some slow tasks seriously, especially in heterogeneous environments. To finish the slow tasks as soon as possible, current MapReduce schedulers launch a backup task on other nodes for each of the slow tasks. However, traditional MapReduce schedulers cannot detect slow tasks correctly since they cannot estimate the progress of tasks accurately (Hadoop home page http://hadoop.apache.org/, 2011; Zaharia et al. in 8th USENIX symposium on operating systems design and implementation, ACM, New York, pp. 29-42, 2008). To solve this problem, this paper proposes a History-based Auto-Tuning (HAT) MapReduce scheduler, which calculates the progress of tasks accurately and adapts to the continuously varying environment automatically. HAT tunes the weight of each phase of a map task and a reduce task according to the value of them in history tasks and uses the accurate weights of the phases to calculate the progress of current tasks. Based on the accurate-calculated progress of tasks, HAT estimates the remaining time of tasks accurately and further launches backup tasks for the tasks that have the longest remaining time. Experimental results show that HAT can significantly improve the performance of MapReduce applications up to 37% compared with Hadoop and up to 16% compared with LATE scheduler.", "paper_title": "HAT: history-based auto-tuning MapReduce in heterogeneous environments", "paper_id": "WOS:000319075500022"}