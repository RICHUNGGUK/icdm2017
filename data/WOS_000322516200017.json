{"auto_keywords": [{"score": 0.049581014501477026, "phrase": "iterative_computations"}, {"score": 0.00481495049065317, "phrase": "distributed_framework_for_prioritizing_iterative_computations"}, {"score": 0.004666228956744244, "phrase": "data_analysis_applications"}, {"score": 0.004593591780245872, "phrase": "web_search"}, {"score": 0.004545793387330536, "phrase": "online_social_network_analysis"}, {"score": 0.004246947739596565, "phrase": "data_sets"}, {"score": 0.004202741104973709, "phrase": "massive_scale"}, {"score": 0.0041589926969138585, "phrase": "fast_convergence"}, {"score": 0.004030449969901066, "phrase": "massive_data_set"}, {"score": 0.0034992667091713813, "phrase": "data_points"}, {"score": 0.0032012284065895537, "phrase": "convergence_speed"}, {"score": 0.0031678720736808574, "phrase": "iterative_process"}, {"score": 0.0030378759123133644, "phrase": "distributed_computing_framework"}, {"score": 0.0029284999172756103, "phrase": "prioritized_execution"}, {"score": 0.002823050755743821, "phrase": "intermediate_data"}, {"score": 0.0027645030021576926, "phrase": "fast_convergence_or_stores_intermediate_data"}, {"score": 0.002678944072162297, "phrase": "larger_data_sets"}, {"score": 0.0025824576209656676, "phrase": "local_cluster"}, {"score": 0.0023623290494119674, "phrase": "hadoop"}, {"score": 0.002301211274459965, "phrase": "iterative_algorithms"}, {"score": 0.002241679436497569, "phrase": "priter"}, {"score": 0.002206700502606511, "phrase": "better_performance"}, {"score": 0.0021271916073946715, "phrase": "spark"}, {"score": 0.0021049977753042253, "phrase": "piccolo"}], "paper_keywords": ["PrIter", " prioritized iteration", " iterative algorithms", " MapReduce", " distributed framework"], "paper_abstract": "Iterative computations are pervasive among data analysis applications, including web search, online social network analysis, recommendation systems, and so on. These applications typically involve data sets of massive scale. Fast convergence of the iterative computations on the massive data set is essential for these applications. In this paper, we explore the opportunity for accelerating iterative computations by prioritization. Instead of performing computations on all data points without discrimination, we prioritize the computations that help convergence the most, so that the convergence speed of iterative process is significantly improved. We develop a distributed computing framework, PrIter, which supports the prioritized execution of iterative computations. PrIter either stores intermediate data in memory for fast convergence or stores intermediate data in files for scaling to larger data sets. We evaluate PrIter on a local cluster of machines as well as on Amazon EC2 Cloud. The results show that PrIter achieves up to 50 x speedup over Hadoop for a series of iterative algorithms. In addition, PrIter is shown better performance for iterative computations than other state-of-the-art distributed frameworks such as Spark and Piccolo.", "paper_title": "PrIter: A Distributed Framework for Prioritizing Iterative Computations", "paper_id": "WOS:000322516200017"}