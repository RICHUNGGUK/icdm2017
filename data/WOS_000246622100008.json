{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "parallel_jobs"}, {"score": 0.004248294537944227, "phrase": "n_independent_parallel_jobs"}, {"score": 0.003990385737207714, "phrase": "parallel_job"}, {"score": 0.0028446460307503343, "phrase": "due_date"}, {"score": 0.0025730425700096365, "phrase": "total_number"}, {"score": 0.002509284173541882, "phrase": "early_jobs"}, {"score": 0.0023566987138026285, "phrase": "optimal_polynomial_time_algorithm"}, {"score": 0.0022696277881969896, "phrase": "unit_processing_time_job_system"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["analysis of algorithms", " parallel jobs", " hypercubes"], "paper_abstract": "We study a problem of scheduling n independent parallel jobs on hypercubes. A parallel job is required to be scheduled on a subcube of processors. All jobs are available at the beginning, each of which is associated with a due date. The objective is to maximize the total number of early jobs. We provide an optimal polynomial time algorithm for the unit processing time job system. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Maximizing the throughput of parallel jobs on hypercubes", "paper_id": "WOS:000246622100008"}