{"auto_keywords": [{"score": 0.04249428016321193, "phrase": "data_set"}, {"score": 0.03517083259120442, "phrase": "dfa_induction"}, {"score": 0.00481495049065317, "phrase": "grammar_induction"}, {"score": 0.004655576530003855, "phrase": "minimum_description_length_principle"}, {"score": 0.004419538941706716, "phrase": "recent_developments"}, {"score": 0.004392565073466714, "phrase": "kolmogorov_complexity_theory"}, {"score": 0.004234129588974058, "phrase": "effective_compression_algorithms"}, {"score": 0.004169806294929081, "phrase": "independent_measure"}, {"score": 0.003644126753595137, "phrase": "optimal_theory"}, {"score": 0.0036218682585355895, "phrase": "minimal_randomness_deficiency"}, {"score": 0.003459191419478298, "phrase": "-_shorter_code"}, {"score": 0.0034066004178183117, "phrase": "better_theories"}, {"score": 0.003253560798692431, "phrase": "single_deterministic_merge"}, {"score": 0.0031942814007173254, "phrase": "randomness_deficiency"}, {"score": 0.0031747618267940155, "phrase": "mdl_code"}, {"score": 0.002985988377995789, "phrase": "fundamental_difference"}, {"score": 0.0029677378488677983, "phrase": "positive_and_negative_data"}, {"score": 0.0029405703787004824, "phrase": "mdl_perspective"}, {"score": 0.0029225966332070462, "phrase": "-_mdl"}, {"score": 0.002869329994644954, "phrase": "correct_calculation"}, {"score": 0.002851790448644913, "phrase": "code_length"}, {"score": 0.0027741761880779535, "phrase": "model_code"}, {"score": 0.002641360377825228, "phrase": "theoretical_results"}, {"score": 0.002585266023089103, "phrase": "effective_algorithm"}, {"score": 0.002499537118656142, "phrase": "mdl"}, {"score": 0.0024766170166319735, "phrase": "global_optimization_criterion"}, {"score": 0.002461472107682778, "phrase": "mdl_based_solutions"}, {"score": 0.0023798115577749225, "phrase": "local_optimization_criteria"}, {"score": 0.0022938068444116827, "phrase": "abbadingo_problems"}, {"score": 0.0022178188094522724, "phrase": "java"}, {"score": 0.0021506938783242215, "phrase": "divide-and-conquer_system"}, {"score": 0.0021050300641064306, "phrase": "ibis"}], "paper_keywords": [""], "paper_abstract": "In this paper we study the application of the Minimum Description Length principle (or two-part-code optimization) to grammar induction in the light of recent developments in Kolmogorov complexity theory. We focus on issues that are important for construction of effective compression algorithms. We define an independent measure for the quality of a theory given a data set: the randomness deficiency. This is a measure of how typical the data set is for the theory. It can not be computed, but it can in many relevant cases be approximated. An optimal theory has minimal randomness deficiency. Using results from [41 and [2] we show that: - Shorter code not necessarily leads to better theories. We prove that, in DFA induction, already as a result of a single deterministic merge of two nodes, divergence of randomness deficiency and MDL code can occur. - Contrary to what is suggested by the results of [6] there is no fundamental difference between positive and negative data from an MDL perspective. - MDL is extremely sensitive to the correct calculation of code length: model code and data-to-model code. These results show why the applications of MDL to grammar induction so far have been disappointing. We show how the theoretical results can be deployed to create an effective algorithm for DFA induction. However, we believe that, since MDL is a global optimization criterion, MDL based solutions will in many cases be less effective in problem domains where local optimization criteria can be easily calculated. The algorithms were tested on the Abbadingo problems ([10]). The code was in Java, using the Satin ([17]) divide-and-conquer system that runs on top of the Ibis ([18]) Grid programming environment.", "paper_title": "Using MDL for grammar induction", "paper_id": "WOS:000242124200024"}