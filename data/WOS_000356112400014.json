{"auto_keywords": [{"score": 0.049017891771026986, "phrase": "multiple_views"}, {"score": 0.014754450064259779, "phrase": "shared_information"}, {"score": 0.012669727909466447, "phrase": "large_pose_variation"}, {"score": 0.012195716298598405, "phrase": "proposed_method"}, {"score": 0.011335633696502454, "phrase": "mixed_norm"}, {"score": 0.00481495049065317, "phrase": "multi_view"}, {"score": 0.0046632033374901715, "phrase": "challenging_research_problem"}, {"score": 0.004589124394375718, "phrase": "existing_works"}, {"score": 0.004359853990466236, "phrase": "pose_variation"}, {"score": 0.0041023644174418205, "phrase": "poor_recognition_results"}, {"score": 0.003985738225654119, "phrase": "novel_method"}, {"score": 0.003922378980031565, "phrase": "multiple_view_images"}, {"score": 0.00376230106601654, "phrase": "novel_mixed_norm"}, {"score": 0.0035741900278634616, "phrase": "highly_correlated_face_images"}, {"score": 0.003494866798828308, "phrase": "classification_accuracy"}, {"score": 0.00339545228483945, "phrase": "sparse_representation"}, {"score": 0.0033845816848753073, "phrase": "based_classification"}, {"score": 0.003330746760940307, "phrase": "joint_sparse_representation"}, {"score": 0.0032256239062596944, "phrase": "jsrc"}, {"score": 0.003025197043767572, "phrase": "face_image"}, {"score": 0.002948547333717581, "phrase": "recognition_process"}, {"score": 0.0028463059289874637, "phrase": "unseen_pose_variation"}, {"score": 0.0027741761880779535, "phrase": "optimal_representation"}, {"score": 0.002747599993498257, "phrase": "query_images"}, {"score": 0.0026184796288543878, "phrase": "open_problem"}, {"score": 0.002601727192945944, "phrase": "robust_sparse_representation"}, {"score": 0.002511481545937323, "phrase": "loss_function"}, {"score": 0.00247944491239733, "phrase": "robust_solution"}, {"score": 0.002370493290982407, "phrase": "powerful_alternative_directions_method"}, {"score": 0.0022956075241520064, "phrase": "extensive_comparisons"}, {"score": 0.0021876820913902207, "phrase": "cmu-pie"}, {"score": 0.002173679145840769, "phrase": "yale_b_and"}, {"score": 0.0021667117312863427, "phrase": "multi-pie"}, {"score": 0.002145942273032774, "phrase": "multi-view_face_recognition"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Multi-pose face recognition", " Sparse representation classification", " ADMM", " Group sparse representation", " Multi-task learning", " Joint dynamic sparse representation classification", " Unsupervised learning", " Convex optimization", " Robust face recognition"], "paper_abstract": "Face recognition with multiple views is a challenging research problem. Most of the existing works have focused on extracting shared information among multiple views to improve recognition. However, when the pose variation is too large or missing, 'shared information' may not be properly extracted, leading to poor recognition results. In this paper, we propose a novel method for face recognition with multiple view images to overcome the large pose variation and missing pose issue. By introducing a novel mixed norm, the proposed method automatically selects candidates from the gallery to best represent a group of highly correlated face images in a query set to improve classification accuracy. This mixed norm combines the advantages of both sparse representation based classification (SRC) and joint sparse representation based classification (JSRC). A trade off between the l(1) norm from SRC and l(2,1) norm from JSRC is introduced to achieve this goal. Due to this property, the proposed method decreases the influence when a face image is unseen and has large pose variation in the recognition process. And when some face images with a certain degree of unseen pose variation appear, this mixed norm will find an optimal representation for these query images based on the shared information induced from multiple views. Moreover, we also address an open problem in robust sparse representation and classification which is using l(1) norm on the loss function to achieve a robust solution. To solve this formulation, we derive a simple, yet provably convergent algorithm based on the powerful alternative directions method of multipliers (ADMM) framework. We provide extensive comparisons which demonstrate that our method outperforms other state-of-the-arts algorithms on CMU-PIE, Yale B and Multi-PIE databases for multi-view face recognition. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Mixed-norm sparse representation for multi view face recognition", "paper_id": "WOS:000356112400014"}