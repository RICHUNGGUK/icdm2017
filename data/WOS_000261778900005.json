{"auto_keywords": [{"score": 0.03548110837704283, "phrase": "image_structures"}, {"score": 0.00481495049065317, "phrase": "modeling_and_change_detection"}, {"score": 0.0045817497454044565, "phrase": "core_components"}, {"score": 0.004549366134876482, "phrase": "video_processing"}, {"score": 0.004192937957960497, "phrase": "current_input"}, {"score": 0.004075596668736259, "phrase": "existing_methods"}, {"score": 0.003933508945770709, "phrase": "background_perturbation"}, {"score": 0.003905689096176873, "phrase": "statistical_modeling"}, {"score": 0.0038234758985278275, "phrase": "gaussians"}, {"score": 0.0037561467438280175, "phrase": "satisfactory_performance"}, {"score": 0.0035867530188337933, "phrase": "nearby_pixels"}, {"score": 0.003224336566887827, "phrase": "natural_scenes"}, {"score": 0.0027972697690729453, "phrase": "appearance_characteristics"}, {"score": 0.002699627613420169, "phrase": "appropriate_subspace"}, {"score": 0.002623967178291655, "phrase": "dynamical_characteristics"}, {"score": 0.0025504217985882725, "phrase": "prediction_mechanism"}, {"score": 0.0024613749081680474, "phrase": "long-term_changes"}, {"score": 0.0024094425220967273, "phrase": "incremental_method"}, {"score": 0.002392375784707278, "phrase": "fast_online_adaptation"}, {"score": 0.0023670015392684885, "phrase": "model_parameters"}, {"score": 0.002308834230545883, "phrase": "robust_and_meaningful_measures"}, {"score": 0.002260112998123604, "phrase": "structural_and_motion_changes"}, {"score": 0.002220296517089146, "phrase": "experimental_results"}, {"score": 0.0021967433763351884, "phrase": "qualitative_and_quantitative_comparisons"}, {"score": 0.002135146725817984, "phrase": "proposed_framework"}, {"score": 0.0021049977753042253, "phrase": "complex_backgrounds"}], "paper_keywords": ["Scene analysis", " Background subtraction", " Time series", " Principal component analysis"], "paper_abstract": "Background modeling and subtraction are core components in video Processing. To this end one arms to, recover and continuously update a representation of the scene that is compared with the current input to perform subtraction. Most of the existing methods treat each pixel independently and attempt to model the background perturbation through statistical modeling such as a mixture of Gaussians. While Such methods have satisfactory performance in many scenarios, they do not model the relationships and correlation amongst nearby pixels. Such correlation between pixels exists both in space and across time especially when the scene consists of image structures moving across space. Waving trees, beach, escalators and natural scenes with rain or snow are examples of such scenes. In this paper, we propose a method for differentiating between image Structures and motion that are persistent and repeated from those that are \"new\". Towards capturing the appearance characteristics of such scenes, we propose the use of an appropriate subspace created from image structures. Furthermore, the dynamical characteristics are captured by the use of a prediction mechanism in such subspace. Since the model must adapt to long-term changes in the background, an incremental method for fast online adaptation of the model parameters is proposed. Given Such adaptive models, robust and meaningful measures for detection that consider both structural and motion changes are considered. Promising experimental results that include qualitative and quantitative comparisons with existing background modeling/subtraction techniques demonstrate the very promising performance of the proposed framework when dealing with complex backgrounds. (C) 2008 Elsevier Inc. All rights reserved.", "paper_title": "Scene modeling and change detection in dynamic scenes: A subspace approach", "paper_id": "WOS:000261778900005"}