{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "scalable_active_learning_for_multiclass_image_classification"}, {"score": 0.004701556483912018, "phrase": "computer_vision_applications"}, {"score": 0.004664352260912174, "phrase": "object_recognition"}, {"score": 0.004627441072541506, "phrase": "scene_classification"}, {"score": 0.00450052670755585, "phrase": "large_number"}, {"score": 0.00446490613141384, "phrase": "training_samples"}, {"score": 0.004429566229017728, "phrase": "satisfactory_performance"}, {"score": 0.004042635935882651, "phrase": "new_ideas"}, {"score": 0.004010624853427534, "phrase": "multiclass_active_learning"}, {"score": 0.003931697356115479, "phrase": "training_bottleneck"}, {"score": 0.003823791479971016, "phrase": "large_multiclass_image_classification_systems"}, {"score": 0.0037188360359702182, "phrase": "new_interaction_modality"}, {"score": 0.003248483521309273, "phrase": "proposed_modality"}, {"score": 0.0030847461428168614, "phrase": "user_annotation_cost"}, {"score": 0.0030000149283621255, "phrase": "active_selection_measure"}, {"score": 0.0027815466400771768, "phrase": "fast_seed_search"}, {"score": 0.0027485371422461408, "phrase": "voi"}, {"score": 0.0026412824985309323, "phrase": "dataset_size"}, {"score": 0.002578946584040053, "phrase": "locality_sensitive_hashing"}, {"score": 0.0025180781216911246, "phrase": "active_learning"}, {"score": 0.002478297391121455, "phrase": "sublinear_time"}, {"score": 0.0023346234464901978, "phrase": "magnitude_speedups"}, {"score": 0.002279508335630797, "phrase": "thorough_empirical_evaluation"}, {"score": 0.0022614266476954467, "phrase": "classification_accuracy"}, {"score": 0.0022434880661725493, "phrase": "noise_sensitivity"}, {"score": 0.002225691463551672, "phrase": "imbalanced_data"}, {"score": 0.0021992603252793995, "phrase": "computational_performance"}, {"score": 0.0021731423856364003, "phrase": "diverse_set"}, {"score": 0.0021559025985688255, "phrase": "image_datasets"}, {"score": 0.0021049977753042253, "phrase": "proposed_algorithms"}], "paper_keywords": ["Active learning", " scalable machine learning", " multiclass classification", " object recognition"], "paper_abstract": "Machine learning techniques for computer vision applications like object recognition, scene classification, etc., require a large number of training samples for satisfactory performance. Especially when classification is to be performed over many categories, providing enough training samples for each category is infeasible. This paper describes new ideas in multiclass active learning to deal with the training bottleneck, making it easier to train large multiclass image classification systems. First, we propose a new interaction modality for training which requires only yes-no type binary feedback instead of a precise category label. The modality is especially powerful in the presence of hundreds of categories. For the proposed modality, we develop a Value-of-Information (VOI) algorithm that chooses informative queries while also considering user annotation cost. Second, we propose an active selection measure that works with many categories and is extremely fast to compute. This measure is employed to perform a fast seed search before computing VOI, resulting in an algorithm that scales linearly with dataset size. Third, we use locality sensitive hashing to provide a very fast approximation to active learning, which gives sublinear time scaling, allowing application to very large datasets. The approximation provides up to two orders of magnitude speedups with little loss in accuracy. Thorough empirical evaluation of classification accuracy, noise sensitivity, imbalanced data, and computational performance on a diverse set of image datasets demonstrates the strengths of the proposed algorithms.", "paper_title": "Scalable Active Learning for Multiclass Image Classification", "paper_id": "WOS:000308755000016"}