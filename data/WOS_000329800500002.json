{"auto_keywords": [{"score": 0.05007800426347441, "phrase": "facial_gender_classification"}, {"score": 0.047751940127596725, "phrase": "gender_classification"}, {"score": 0.03776654602337569, "phrase": "svm."}, {"score": 0.024532713187083333, "phrase": "feret"}, {"score": 0.004743594110762319, "phrase": "research_paper"}, {"score": 0.004513255056769647, "phrase": "first_approach"}, {"score": 0.004402295697276237, "phrase": "discrete_cosine_transform"}, {"score": 0.004358732559588519, "phrase": "dct"}, {"score": 0.004188459638572375, "phrase": "features_values"}, {"score": 0.004126349202545883, "phrase": "second_approach"}, {"score": 0.003984968827278219, "phrase": "texture_features"}, {"score": 0.00392586404888927, "phrase": "gray-level_cooccurrence_matrix"}, {"score": 0.0038102613924627647, "phrase": "third_approach"}, {"score": 0.00367967106192446, "phrase": "extracted_features"}, {"score": 0.003553540530701019, "phrase": "precise_evaluation"}, {"score": 0.003448863509392547, "phrase": "gender_evaluation"}, {"score": 0.0032975859014983586, "phrase": "k-fold"}, {"score": 0.0025827837420330816, "phrase": "glcm_texture"}, {"score": 0.0023375389239461745, "phrase": "umist"}], "paper_keywords": ["Faces gender classification", " Discrete cosine transform", " Grey-level cooccurrence matrix (GLCM)", " SVM"], "paper_abstract": "This research paper introduces three robust approaches for features extraction for gender classification. The first approach is based on using Discrete Cosine Transform (DCT) and consists of two different methods for calculating features values. The second approach is based on the extraction of texture features using the gray-level cooccurrence matrix (GLCM). The third approach is based on 2D-wavelet transform. The extracted features vectors are classified using SVM. For precise evaluation, the databases used for gender evaluation are based on images from the AT@T, Faces94, UMIST, and color FERET databases. K-fold cross validation is used in training the SVM. The accuracies of gender classification when using one of the two proposed DCT methods for features extraction are 98.6 %, 99.97 %, 99.90 %, and 93.3 % with 2-fold cross validation, and 98.93 %, 100 %, 99.9 %, and 92.18 % with 5-fold cross validation. The accuracies of GLCM texture features approach for facial gender classification are 98.8 %, 99.6 %, 100 %, and 93.11 %, for AT@T, Faces94, UMIST, and FERET, databases. The accuracies for all databases when using 2D-WT are ranging between 96.18 % and 99.6 % except FERET and its accuracy is 92 %.", "paper_title": "Three robust features extraction approaches for facial gender classification", "paper_id": "WOS:000329800500002"}