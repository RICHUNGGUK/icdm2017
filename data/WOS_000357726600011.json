{"auto_keywords": [{"score": 0.03672998173300791, "phrase": "nsa"}, {"score": 0.00481495049065317, "phrase": "neumann_series"}, {"score": 0.004471978831302331, "phrase": "gbssl"}, {"score": 0.004209539728590977, "phrase": "expensive_computational_burden"}, {"score": 0.004125513927068713, "phrase": "main_bottleneck"}, {"score": 0.0038314621564116192, "phrase": "huge_matrix"}, {"score": 0.0035344448639851827, "phrase": "neumann_series_approximation"}, {"score": 0.0033492947290751996, "phrase": "inversion_process"}, {"score": 0.003282383509542342, "phrase": "conventional_gbssl_methodologies"}, {"score": 0.003110396267535254, "phrase": "relatively_large_datasets"}, {"score": 0.002869115451202179, "phrase": "direct_inversion"}, {"score": 0.0027741761880779535, "phrase": "real-world_datasets"}, {"score": 0.0027187231747900814, "phrase": "handwritten_digit_recognition"}, {"score": 0.0026823700218343506, "phrase": "speech_recognition"}, {"score": 0.002646501671714952, "phrase": "text_classification"}, {"score": 0.0025935941070969575, "phrase": "experimental_results"}, {"score": 0.0022365262201954643, "phrase": "nystrom_method"}, {"score": 0.002206606452557159, "phrase": "takahashi_equation"}, {"score": 0.0021771097375650524, "phrase": "lanczos"}, {"score": 0.0021335796129250224, "phrase": "svd"}, {"score": 0.0021049977753042253, "phrase": "anchorgraph_regularization"}], "paper_keywords": ["Semi-supervised learning", " Scalability", " Neumann series", " Error bound"], "paper_abstract": "Traditional graph-based semi-supervised learning (GBSSL) algorithms usually scale badly due to the expensive computational burden. The main bottleneck is that they need to compute the inversion of a huge matrix. In order to alleviate this problem, this paper proposes Neumann series approximation (NSA) to explicitly approximate the inversion process required by conventional GBSSL methodologies, which makes them computationally tractable for relatively large datasets. It is proved that the deviation between the approximation and direct inversion is bounded. Using real-world datasets related to handwritten digit recognition, speech recognition and text classification, the experimental results reveal that NSA accelerates the speed significantly without decreasing too much precision. We also empirically show that NSA outperforms other scalable approaches such as Nystrom method, Takahashi equation, Lanczos process based SVD and AnchorGraph regularization, in terms of both efficiency and accuracy.", "paper_title": "Scalable Semi-Supervised Classification via Neumann Series", "paper_id": "WOS:000357726600011"}