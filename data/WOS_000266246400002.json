{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "dynamic_coordination"}, {"score": 0.0495648351427175, "phrase": "multiple_competing_goals"}, {"score": 0.03517083259120442, "phrase": "dynamic_weighting"}, {"score": 0.004686688155058031, "phrase": "general_framework"}, {"score": 0.004464326432401002, "phrase": "dynamic_environments"}, {"score": 0.00441635700580562, "phrase": "physical_agents"}, {"score": 0.004252469672259375, "phrase": "goal_coordination"}, {"score": 0.0041840994704406866, "phrase": "novel_tool"}, {"score": 0.004094639048362357, "phrase": "deep_coordination_ability"}, {"score": 0.004028796143006953, "phrase": "reactive_agents"}, {"score": 0.003796267885124202, "phrase": "multi-objective_optimisation"}, {"score": 0.0035771121569391916, "phrase": "aggregating_functions'_formulation"}, {"score": 0.0028502479839354637, "phrase": "unitary_vector"}, {"score": 0.0025031188149336257, "phrase": "agent's_environment"}, {"score": 0.0023079225317714815, "phrase": "machine-learning_tool"}, {"score": 0.0021745003291048356, "phrase": "reinforcement_learning"}, {"score": 0.0021394674440767124, "phrase": "first_approach"}], "paper_keywords": ["goal coordination", " conflicting goals", " multi-objective optimisation", " reinforcement learning"], "paper_abstract": "A general framework for the problem of coordination of multiple competing goals in dynamic environments for physical agents is presented. This approach to goal coordination is a novel tool to incorporate a deep coordination ability to pure reactive agents. The framework presented is based on the notion of multi-objective optimisation. In this article we propose a kind of 'aggregating functions' formulation with the particularity that the aggregation is weighted by means of a dynamic weighting unitary vector [image omitted], which is dependent from the system dynamic state allowing the agent to dynamically coordinate the priorities of its single goals. This dynamic weighting unitary vector is represented as a (n - 1) set of angles. The dynamic coordination must be established by means of a mapping between the state of the agent's environment S to the set of angles i(S) by means of any sort of machine-learning tool. In this work, we investigate the use of Reinforcement Learning as a first approach to learn that mapping.", "paper_title": "A model for the dynamic coordination of multiple competing goals", "paper_id": "WOS:000266246400002"}