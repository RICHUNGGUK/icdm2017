{"auto_keywords": [{"score": 0.04586846484671967, "phrase": "action_domain"}, {"score": 0.00481495049065317, "phrase": "optimistic_plan_execution"}, {"score": 0.004674952036988355, "phrase": "nondeterministic_actions"}, {"score": 0.004614038128321949, "phrase": "dynamic_environment"}, {"score": 0.004033464035028803, "phrase": "possible_execution"}, {"score": 0.0037402558657576124, "phrase": "current_state"}, {"score": 0.0032372213689015844, "phrase": "different_purposes"}, {"score": 0.0031740669025323606, "phrase": "execution_monitoring"}, {"score": 0.0028857130140890787, "phrase": "plan_failures"}, {"score": 0.0028480459059007468, "phrase": "modeling_level"}, {"score": 0.0027833043858224078, "phrase": "useful_insight"}, {"score": 0.0027289810731258865, "phrase": "better_understanding"}, {"score": 0.002538687900036229, "phrase": "general_logic-based_knowledge_representation_framework"}, {"score": 0.002330790244117364, "phrase": "computational_complexity"}, {"score": 0.002218668420806254, "phrase": "computing_explanations"}, {"score": 0.0021398811716327273, "phrase": "dlvk"}, {"score": 0.0021049977753042253, "phrase": "logic-programming_based_system"}], "paper_keywords": ["knowledge representation", " reasoning about actions", " logic-based planning", " explanations", " execution monitoring", " computational complexity"], "paper_abstract": "Consider an agent executing a plan with nondeterministic actions, in a dynamic environment, which might fail. Suppose that she is given a description of this action domain, including specifications of effects of actions, and a set of trajectories for the execution of this plan, where each trajectory specifies a possible execution of the plan in this domain. After executing some part of the plan, suppose that she obtains information about the current state of the world, and notices that she is not at a correct state relative to the given trajectories. How can she find an explanation ( a point of failure) for such a discrepancy? An answer to this question can be useful for different purposes. In the context of execution monitoring, points of failure can determine some checkpoints that specify when to check for discrepancies, and they can sometimes be used for recovering from discrepancies that cause plan failures. At the modeling level, points of failure may provide useful insight into the action domain for a better understanding of the domain, or reveal errors in the formalization of the domain. We study the question above in a general logic-based knowledge representation framework, which can accommodate nondeterminism and concurrency. In this framework, we define a discrepancy and an explanation for it, and analyze the computational complexity of detecting discrepancies and finding explanations for them. We introduce a method for computing explanations, and report about a realization of this method using DLVK, which is a logic-programming based system for reasoning about actions and change.", "paper_title": "A logic-based approach to finding explanations for discrepancies in optimistic plan execution", "paper_id": "WOS:000250383000004"}