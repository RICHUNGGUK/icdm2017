{"auto_keywords": [{"score": 0.03803948985551093, "phrase": "network_congestion"}, {"score": 0.03183543607122102, "phrase": "glb_method"}, {"score": 0.030204949035849533, "phrase": "global_congestion_information"}, {"score": 0.00481495049065317, "phrase": "on-chip_networks"}, {"score": 0.00476323161560059, "phrase": "efficient_congestion-aware_method"}, {"score": 0.004661446705304497, "phrase": "order_delivery"}, {"score": 0.004586531354697466, "phrase": "critical_issue"}, {"score": 0.004537254814246843, "phrase": "memory_parallelism"}, {"score": 0.004488505301335364, "phrase": "network-based_mpsocs"}, {"score": 0.0041840994704406866, "phrase": "in-order_delivery"}, {"score": 0.004050625770007516, "phrase": "subtle_point"}, {"score": 0.0037554497046697432, "phrase": "congestion-aware_method"}, {"score": 0.0033163269450817716, "phrase": "streamlined_method"}, {"score": 0.0032629585038738856, "phrase": "global_load_balancing"}, {"score": 0.002928399649340438, "phrase": "first_idea"}, {"score": 0.002685558057339722, "phrase": "congestion_level"}, {"score": 0.002656650588033728, "phrase": "highly_congested_areas"}, {"score": 0.002613870237087035, "phrase": "second_idea"}, {"score": 0.0025440911575156755, "phrase": "adaptive_scheduler"}, {"score": 0.0025167026017217926, "phrase": "network_interfaces"}, {"score": 0.0024231382864800173, "phrase": "additional_traffic"}, {"score": 0.0023970487263732737, "phrase": "congested_areas"}, {"score": 0.0023712394008737958, "phrase": "experimental_results"}, {"score": 0.002345707314211983, "phrase": "synthetic_test_cases"}, {"score": 0.002295463032589125, "phrase": "on-chip_network"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Network-on-Chip", " Congestion-aware scheduler", " Adaptive arbitration"], "paper_abstract": "In-order delivery is a critical issue of memory parallelism in network-based MPSoCs where multiple memories can be accessed simultaneously. In addition to the in-order delivery, network congestion is another subtle point that required to be taken into account for such architectures. Therefore, a congestion-aware method is necessitated to deal with the network congestion while coping with the ordering of transactions. In this paper, we present a streamlined method, named Global Load Balancing (GLB), in order to reduce the network congestion. The ideas behind the GLB method are twofold. The first idea is to use the global congestion information as a metric for arbitration in routers to reduce the congestion level of highly congested areas. The second idea is to use an adaptive scheduler in network interfaces based on the global congestion information to avoid additional traffic to congested areas. Experimental results with synthetic test cases demonstrate that the on-chip network utilizing the GLB method considerably outperforms a conventional on-chip network. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "A systematic reordering mechanism for on-chip networks using efficient congestion-aware method", "paper_id": "WOS:000320293900003"}