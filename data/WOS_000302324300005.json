{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "complementary_corrective_demonstration"}, {"score": 0.0045879792359519375, "phrase": "skill_execution_performance"}, {"score": 0.00441883624011048, "phrase": "existing_algorithmic_solution"}, {"score": 0.004371660146981191, "phrase": "corrective_human_demonstration"}, {"score": 0.004255902303152008, "phrase": "proposed_method"}, {"score": 0.004187917910692495, "phrase": "biped_walking_problem"}, {"score": 0.004077005481951783, "phrase": "good_example"}, {"score": 0.004011867299107537, "phrase": "complex_low_level_skill"}, {"score": 0.003926626018798576, "phrase": "complicated_dynamics"}, {"score": 0.0038638811223100184, "phrase": "walk_process"}, {"score": 0.003802135020791801, "phrase": "high_dimensional_state"}, {"score": 0.0037615180375561805, "phrase": "action_space"}, {"score": 0.00366185681714204, "phrase": "incremental_learning_approach"}, {"score": 0.003584025547693836, "phrase": "nao_humanoid_robot's_stability"}, {"score": 0.0033243718810317254, "phrase": "complete_walk_cycle"}, {"score": 0.0030834712590249863, "phrase": "black_box"}, {"score": 0.002985631781749091, "phrase": "offline_advice_operators"}, {"score": 0.002875391177926809, "phrase": "learned_open-loop_walk_cycle"}, {"score": 0.002695768552609587, "phrase": "recorded_walk_cycle"}, {"score": 0.00266693888510356, "phrase": "real_time_corrective_human_demonstration"}, {"score": 0.0025822818714499795, "phrase": "corrective_feedback"}, {"score": 0.0025409639091476363, "phrase": "commercially_available_wireless_game_controller"}, {"score": 0.0024339783012484032, "phrase": "proposed_algorithm"}, {"score": 0.0023566987138026285, "phrase": "closed-loop_correction_policy"}, {"score": 0.0023189818169615135, "phrase": "open-loop_walk"}, {"score": 0.0022696277881969896, "phrase": "corrective_demonstrations"}, {"score": 0.0022333012657436307, "phrase": "sensory_readings"}, {"score": 0.002174041708084857, "phrase": "experiment_results"}, {"score": 0.0021392418081444798, "phrase": "significant_improvement"}, {"score": 0.0021049977753042253, "phrase": "walk_stability"}], "paper_keywords": ["Learning from demonstration", " Complex motor skill acquisition", " Motion and sensor model learning"], "paper_abstract": "We contribute a method for improving the skill execution performance of a robot by complementing an existing algorithmic solution with corrective human demonstration. We apply the proposed method to the biped walking problem, which is a good example of a complex low level skill due to the complicated dynamics of the walk process in a high dimensional state and action space. We introduce an incremental learning approach to improve the Nao humanoid robot's stability during walking. First, we identify, extract, and record a complete walk cycle from the motion of the robot as it executes a given walk algorithm as a black box. Second, we apply offline advice operators for improving the stability of the learned open-loop walk cycle. Finally, we present an algorithm to directly modify the recorded walk cycle using real time corrective human demonstration. The demonstrator delivers the corrective feedback using a commercially available wireless game controller without touching the robot. Through the proposed algorithm, the robot learns a closed-loop correction policy for the open-loop walk by mapping the corrective demonstrations to the sensory readings received while walking. Experiment results demonstrate a significant improvement in the walk stability.", "paper_title": "Improving biped walk stability with complementary corrective demonstration", "paper_id": "WOS:000302324300005"}