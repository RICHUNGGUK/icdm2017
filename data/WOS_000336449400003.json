{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "autonomous_landing_of"}, {"score": 0.004687305496643216, "phrase": "arbitrarily_textured_landing_site"}, {"score": 0.004624751696958501, "phrase": "onboard_monocular_vision"}, {"score": 0.004442032546224076, "phrase": "novel_solution"}, {"score": 0.004382737590042589, "phrase": "micro_aerial_vehicles"}, {"score": 0.004043158538239064, "phrase": "arbitrary_landing_site"}, {"score": 0.00398916666053909, "phrase": "real-time_monocular_vision"}, {"score": 0.0036064757492752703, "phrase": "unknown_size"}, {"score": 0.0033946556965877873, "phrase": "well-known_monocular_visual_slam_algorithm"}, {"score": 0.003195236629209403, "phrase": "unknown_environments"}, {"score": 0.0029473940028924748, "phrase": "multi-scale_orb_feature_based_method"}, {"score": 0.002811770047652563, "phrase": "slam_framework"}, {"score": 0.0027741761880779535, "phrase": "landing_site_detection"}, {"score": 0.0026823700218343506, "phrase": "ransac-based_method"}, {"score": 0.0026111116934081284, "phrase": "landing_site"}, {"score": 0.002507748938616919, "phrase": "slam_system"}, {"score": 0.0024084679931209514, "phrase": "map_points"}, {"score": 0.002344468886431959, "phrase": "detected_landing_site"}, {"score": 0.0022215160785078797, "phrase": "presented_vision_system"}, {"score": 0.0021917966722180132, "phrase": "autonomous_flights"}, {"score": 0.0021049977753042253, "phrase": "challenging_outdoor_environment"}], "paper_keywords": ["Micro aerial vehicles", " Autonomous navigation", " Autonomous landing", " SLAM", " Monocular vision"], "paper_abstract": "This paper presents a novel solution for micro aerial vehicles (MAVs) to autonomously search for and land on an arbitrary landing site using real-time monocular vision. The autonomous MAV is provided with only one single reference image of the landing site with an unknown size before initiating this task. We extend a well-known monocular visual SLAM algorithm that enables autonomous navigation of the MAV in unknown environments, in order to search for such landing sites. Furthermore, a multi-scale ORB feature based method is implemented and integrated into the SLAM framework for landing site detection. We use a RANSAC-based method to locate the landing site within the map of the SLAM system, taking advantage of those map points associated with the detected landing site. We demonstrate the efficiency of the presented vision system in autonomous flights, both indoor and in challenging outdoor environment.", "paper_title": "Autonomous Landing of MAVs on an Arbitrarily Textured Landing Site Using Onboard Monocular Vision", "paper_id": "WOS:000336449400003"}