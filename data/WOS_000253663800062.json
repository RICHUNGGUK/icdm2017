{"auto_keywords": [{"score": 0.04397146767907389, "phrase": "pso"}, {"score": 0.00481495049065317, "phrase": "artificial_neural_networks"}, {"score": 0.004654210559456924, "phrase": "improved_pso"}, {"score": 0.004299621153829837, "phrase": "improved_particle_swarm_optimization"}, {"score": 0.0037532257703888315, "phrase": "enhancement_operation"}, {"score": 0.0035869274480340727, "phrase": "self-adaptive_evolution_strategies"}, {"score": 0.0032026066791743866, "phrase": "joint_optimization"}, {"score": 0.0031308163228919773, "phrase": "three-layer_feedforward_artificial_neural_network"}, {"score": 0.0025239898026543964, "phrase": "experimental_results"}, {"score": 0.0023848164282879885, "phrase": "espnet"}, {"score": 0.002305014991156598, "phrase": "compact_anns"}, {"score": 0.002253299769886694, "phrase": "good_generalization_ability"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["artificial neural network", " particle swarm optimization", " evolution strategies"], "paper_abstract": "This paper presents an improved particle swarm optimization (PSO) and discrete PSO (DPSO) with an enhancement operation by using a self-adaptive evolution strategies (ES). This improved PSO/DPSO is proposed for joint optimization of three-layer feedforward artificial neural network (ANN) structure and parameters (weights and bias), which is named ESPNet. The experimental results on two real-world problems show that ESPNet can produce compact ANNs with good generalization ability. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Evolving artificial neural networks using an improved PSO and DPSO", "paper_id": "WOS:000253663800062"}