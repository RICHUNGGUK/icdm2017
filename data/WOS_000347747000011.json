{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "distinctive_features"}, {"score": 0.004771196027464407, "phrase": "pore-scale_facial_keypoints"}, {"score": 0.004600100053651545, "phrase": "different_viewpoints"}, {"score": 0.004516856326107826, "phrase": "important_role"}, {"score": 0.004354841111644036, "phrase": "face_images"}, {"score": 0.004256533389293113, "phrase": "sufficient_distinctive_features"}, {"score": 0.004179480763003705, "phrase": "large_number"}, {"score": 0.004103817210338686, "phrase": "uncalibrated_images"}, {"score": 0.003956558420993431, "phrase": "pore-scale_facial_features"}, {"score": 0.003814563533445401, "phrase": "fine_wrinkles"}, {"score": 0.003561865840737996, "phrase": "facial_images"}, {"score": 0.0035294580355761506, "phrase": "different_variations"}, {"score": 0.003465521267039616, "phrase": "biological_observation"}, {"score": 0.003433987036569199, "phrase": "computervision_consideration"}, {"score": 0.0033872210664940817, "phrase": "new_framework"}, {"score": 0.003325852346387272, "phrase": "pore-scale_facial-feature_extraction"}, {"score": 0.003177235604998673, "phrase": "different_subjects"}, {"score": 0.0031483163191080425, "phrase": "imaging_distortion"}, {"score": 0.003021392767766593, "phrase": "matching_performance"}, {"score": 0.0029396242707327986, "phrase": "varying_illuminations"}, {"score": 0.0029128614098881253, "phrase": "unfocused_blurring"}, {"score": 0.0028082176224611542, "phrase": "correspondences_dataset"}, {"score": 0.0026461080202599694, "phrase": "face_database"}, {"score": 0.002527788827701828, "phrase": "pore-scale_features"}, {"score": 0.0024258208033731154, "phrase": "minimum_resolution"}, {"score": 0.002327956449278255, "phrase": "reliable_matching"}, {"score": 0.0023067494372458427, "phrase": "different_poses"}, {"score": 0.0021834945657804193, "phrase": "uncalibrated_face_images"}, {"score": 0.0021049977753042253, "phrase": "proposed_methods"}], "paper_keywords": ["Pore-scale facial feature", " Feature extraction", " Face matching", " Face reconstruction", " Face recognition"], "paper_abstract": "Establishing correct correspondences between two faces with different viewpoints has played an important role in 3D face reconstruction and other computer-vision applications. Usually, face images are considered to lack sufficient distinctive features to establish a large number of correspondences on uncalibrated images. In this paper, we investigate pore-scale facial features, which are formed from pores, fine wrinkles, and hair. These features have many characteristics that make them suitable for matching facial images under different variations. Using both biological observation and computervision consideration, a new framework is devised for pore-scale facial-feature extraction and matching. The matching difficulty under various skin appearances of different subjects and imaging distortion is also analyzed. For further improving the matching performance and tackling distortions such as varying illuminations and unfocused blurring, a pore-to-pore correspondences dataset is established for training a more distinctive and compact descriptor. Experiments are conducted on a face database containing 105 subjects, and the results prove that the pore-scale features are highly distinctive; face images with a minimum resolution of 600 x 700 (0.4 mega) pixels contain sufficient details to perform a reliable matching in different poses. Generally, our algorithm can establish between 500 and 2000 correct correspondences on a pair of uncalibrated face images of the same person. Furthermore, the proposed methods can be applied to face recognition, 3D reconstruction, etc. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Design and learn distinctive features from pore-scale facial keypoints", "paper_id": "WOS:000347747000011"}