{"auto_keywords": [{"score": 0.048580384941031354, "phrase": "model-based_performance_evaluation_methods"}, {"score": 0.046359721876742796, "phrase": "component-based_performance_modelling"}, {"score": 0.03941864421624202, "phrase": "pcm"}, {"score": 0.03594687035500543, "phrase": "monolithic_methods"}, {"score": 0.03379834948552901, "phrase": "component-based_method"}, {"score": 0.00481495049065317, "phrase": "component-based_performance_evaluation"}, {"score": 0.004562847483469705, "phrase": "design_alternatives"}, {"score": 0.004507409180942999, "phrase": "late_life-cycle_performance_fixes"}, {"score": 0.004377077848734575, "phrase": "reusable_performance_models"}, {"score": 0.004219427915728969, "phrase": "needed_effort"}, {"score": 0.00414780558977049, "phrase": "human_factors"}, {"score": 0.004037694641919865, "phrase": "component-based_methods"}, {"score": 0.003998380230709541, "phrase": "performance_predictions"}, {"score": 0.003969144836240849, "phrase": "comparable_accuracy_while_saving_effort"}, {"score": 0.0036434002236454305, "phrase": "method_users"}, {"score": 0.0035553221885904467, "phrase": "different_levels"}, {"score": 0.003477867589973215, "phrase": "first_experiment"}, {"score": 0.003303617297414837, "phrase": "second_experiment"}, {"score": 0.0031767199435197243, "phrase": "model_creation_case"}, {"score": 0.003107487675471985, "phrase": "effort_reduction"}, {"score": 0.0030847461428168614, "phrase": "component-based_models"}, {"score": 0.003024909947609294, "phrase": "resulting_artefacts"}, {"score": 0.002995427206425849, "phrase": "screen_recording"}, {"score": 0.002951739421935396, "phrase": "hypothesis_testing"}, {"score": 0.002937318465594425, "phrase": "linear_models"}, {"score": 0.002831391861183493, "phrase": "spe"}, {"score": 0.0028192696160800252, "phrase": "cp"}, {"score": 0.0027969169552386, "phrase": "accurate_predictions"}, {"score": 0.0026762874092443197, "phrase": "reusable_models"}, {"score": 0.002579736401984506, "phrase": "accurate_models"}, {"score": 0.002511147699138714, "phrase": "pcm_models"}, {"score": 0.002391067964886602, "phrase": "inner_complexity"}, {"score": 0.0023104373174118458, "phrase": "actual_activities"}, {"score": 0.0022379971185402833, "phrase": "sufficient_prediction_accuracy"}, {"score": 0.00220533188459562, "phrase": "monolithic_and_component-based_methods"}, {"score": 0.0021784745589727246, "phrase": "higher_effort"}, {"score": 0.0021309511768862637, "phrase": "component_models"}, {"score": 0.0021049977753042253, "phrase": "sufficient_amount"}], "paper_keywords": ["Empirical study", " Software architecture", " Performance evaluation", " Performance modelling", " Performance prediction"], "paper_abstract": "Model-based performance evaluation methods for software architectures can help architects to assess design alternatives and save costs for late life-cycle performance fixes. A recent trend is component-based performance modelling, which aims at creating reusable performance models; a number of such methods have been proposed during the last decade. Their accuracy and the needed effort for modelling are heavily influenced by human factors, which are so far hardly understood empirically. Do component-based methods allow to make performance predictions with a comparable accuracy while saving effort in a reuse scenario? We examined three monolithic methods (SPE, umlPSI, Capacity Planning (CP)) and one component-based performance evaluation method (PCM) with regard to their accuracy and effort from the viewpoint of method users. We conducted a series of three experiments (with different levels of control) involving 47 computer science students. In the first experiment, we compared the applicability of the monolithic methods in order to choose one of them for comparison. In the second experiment, we compared the accuracy and effort of this monolithic and the component-based method for the model creation case. In the third, we studied the effort reduction from reusing component-based models. Data were collected based on the resulting artefacts, questionnaires and screen recording. They were analysed using hypothesis testing, linear models, and analysis of variance. For the monolithic methods, we found that using SPE and CP resulted in accurate predictions, while umlPSI produced over-estimates. Comparing the component-based method PCM with SPE, we found that creating reusable models using PCM takes more (but not drastically more) time than using SPE and that participants can create accurate models with both techniques. Finally, we found that reusing PCM models can save time, because effort to reuse can be explained by a model that is independent of the inner complexity of a component. The tasks performed in our experiments reflect only a subset of the actual activities when applying model-based performance evaluation methods in a software development process. Our results indicate that sufficient prediction accuracy can be achieved with both monolithic and component-based methods, and that the higher effort for component-based performance modelling will indeed pay off when the component models incorporate and hide a sufficient amount of complexity.", "paper_title": "From monolithic to component-based performance evaluation of software architectures A series of experiments analysing accuracy and effort", "paper_id": "WOS:000293978900003"}