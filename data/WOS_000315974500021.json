{"auto_keywords": [{"score": 0.04916104605092019, "phrase": "grid"}, {"score": 0.0064629459489930026, "phrase": "grid_infrastructure"}, {"score": 0.006001305167083654, "phrase": "soil"}, {"score": 0.004815023550552162, "phrase": "distributed"}, {"score": 0.004768559572292452, "phrase": "large_scale_swat_models"}, {"score": 0.004677108044285109, "phrase": "increasing_interest"}, {"score": 0.004647013794908825, "phrase": "larger_spatial_and_temporal_scale_models"}, {"score": 0.004617112284856892, "phrase": "high_resolution_input_data_processing"}, {"score": 0.004528551999851654, "phrase": "higher_computational_demand"}, {"score": 0.004398872331144531, "phrase": "common_modeling_routines"}, {"score": 0.004328432545135587, "phrase": "uncertainty_analysis"}, {"score": 0.0041773934798743405, "phrase": "computation_time"}, {"score": 0.00415050117148714, "phrase": "large_scale_socio-environmental_modeling_software"}, {"score": 0.004057728601458481, "phrase": "distributed_computing"}, {"score": 0.003853359519337239, "phrase": "computational_efficiency"}, {"score": 0.0038038900382901864, "phrase": "generic_tools"}, {"score": 0.003635676878573833, "phrase": "model_application"}, {"score": 0.0035774147651746395, "phrase": "egee"}, {"score": 0.003520082172409082, "phrase": "e-science_projects"}, {"score": 0.00349744840682586, "phrase": "europe"}, {"score": 0.0033861930947608207, "phrase": "large_scale_hydrological_model"}, {"score": 0.0032259472087775138, "phrase": "split_models"}, {"score": 0.0031032109441552287, "phrase": "single_output_format"}, {"score": 0.0030732613046470314, "phrase": "three-step_procedure"}, {"score": 0.0029467742734417255, "phrase": "python_script"}, {"score": 0.0028715299874549245, "phrase": "swat_model"}, {"score": 0.00281635677605879, "phrase": "individual_sub-models"}, {"score": 0.002622947550220266, "phrase": "reach_routing_process"}, {"score": 0.002555950807368337, "phrase": "modified_swat_program"}, {"score": 0.0025230952890994236, "phrase": "experimental_simulations"}, {"score": 0.00250682585023182, "phrase": "multiple_temporal_and_spatial_scale"}, {"score": 0.0023958326775913165, "phrase": "computing_overheads"}, {"score": 0.002380381895973937, "phrase": "parallel_computation"}, {"score": 0.0023650305205893353, "phrase": "socio-environmental_models"}, {"score": 0.0023120743774800176, "phrase": "model_applications"}, {"score": 0.0022897425998475362, "phrase": "large_spatial_and_temporal_scales"}, {"score": 0.0021883400011393564, "phrase": "computational_overheads"}, {"score": 0.0021672007484097575, "phrase": "large_scale_model_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Distributed computing", " Grid computing", " Hydrological models", " SWAT", " Gridification"], "paper_abstract": "The increasing interest in larger spatial and temporal scale models and high resolution input data processing comes at a price of higher computational demand. This price is evidently even higher when common modeling routines such as calibration and uncertainty analysis are involved. Likewise, methods and techniques for reducing computation time in large scale socio-environmental modeling software is growing. Recent advancements in distributed computing such as Grid infrastructure have provided further opportunity to this effort. In the interest of gaining computational efficiency, we developed generic tools and techniques for enabling the Soil and Water Assessment Tool (SWAT) model application to run on the EGEE (Enabling Grids for E-science projects in Europe) Grid. Various program components/scripts were written to split a large scale hydrological model of the Soil and Water Assessment Tool (SWAT), to submit the split models to the Grid, and to collect and merge results into single output format. A three-step procedure was applied to take advantage of the Grid. Firstly, a python script was run in order to split the SWAT model into several sub-models. Then, individual sub-models were submitted in parallel for execution on the Grid. Finally, the outputs of the sub-basins were collected and the reach routing process was performed with another script executing a modified SWAT program. We conducted experimental simulations with multiple temporal and spatial scale hydrological models on the Grid infrastructure. Results showed that, in spite of computing overheads, parallel computation of socio-environmental models on the Grid is beneficial for model applications especially with large spatial and temporal scales. In the end, we conclude by recommending methods for further reducing computational overheads while running large scale model applications on the Grid. (c) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Distributed computation of large scale SWAT models on the Grid", "paper_id": "WOS:000315974500021"}