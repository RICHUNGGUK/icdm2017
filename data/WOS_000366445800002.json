{"auto_keywords": [{"score": 0.04544828952511045, "phrase": "tm"}, {"score": 0.00481495049065317, "phrase": "intel_restricted_transactional_memory"}, {"score": 0.004637478829869904, "phrase": "concurrent_applications"}, {"score": 0.004551199992546761, "phrase": "familiar_abstraction"}, {"score": 0.004517137548648729, "phrase": "atomic_transaction"}, {"score": 0.00443308765153716, "phrase": "intense_research"}, {"score": 0.00440951156726707, "phrase": "rtm"}, {"score": 0.004237666411136617, "phrase": "mainstream_computing"}, {"score": 0.00419016653753787, "phrase": "intel's_decision"}, {"score": 0.004143196873246147, "phrase": "tm_support"}, {"score": 0.003800093834008562, "phrase": "relevant_issue"}, {"score": 0.003771631577951067, "phrase": "great_impact"}, {"score": 0.003701401653850141, "phrase": "intel's_rtm"}, {"score": 0.003659890662429693, "phrase": "correct_tuning"}, {"score": 0.0035248419365839856, "phrase": "failed_hardware_transactions"}, {"score": 0.003446208270665051, "phrase": "optimal_tuning"}, {"score": 0.0032941471167321408, "phrase": "relative_difference"}, {"score": 0.002987236799291296, "phrase": "simple_and_effective_approach"}, {"score": 0.002920561105784389, "phrase": "optimal_rtm_configuration"}, {"score": 0.0028769371032728733, "phrase": "lightweight_reinforcement_learning_techniques"}, {"score": 0.002863670035844551, "phrase": "gcc"}, {"score": 0.0028446460307503343, "phrase": "proposed_technique"}, {"score": 0.0028127163745564777, "phrase": "off-line_sampling"}, {"score": 0.0026583500966092044, "phrase": "single_global_lock"}, {"score": 0.002628506002255396, "phrase": "software_tm_implementation"}, {"score": 0.0025892330566358503, "phrase": "fall-back_synchronization_mechanism"}, {"score": 0.002531418327080538, "phrase": "different_designs"}, {"score": 0.002502995662011305, "phrase": "proposed_self-tuning_mechanisms"}, {"score": 0.0024014759148123736, "phrase": "full_transparency"}, {"score": 0.0023214774334744713, "phrase": "standard_tm_benchmarks"}, {"score": 0.002295406551990453, "phrase": "average_gains"}, {"score": 0.002252602622785975, "phrase": "static_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Hardware Transactional Memory", " Performance", " Self-tuning"], "paper_abstract": "The Transactional Memory (TM) paradigm aims at simplifying the development of concurrent applications by means of the familiar abstraction of atomic transaction. After a decade of intense research, hardware implementations of TM have recently entered the domain of mainstream computing thanks to Intel's decision to integrate TM support, codenamed RTM (Reduced Transactional Memory), in their last generation of processors. In this work we shed light on a relevant issue with great impact on the performance of Intel's RTM: the correct tuning of the logic that regulates how to cope with failed hardware transactions. We show that the optimal tuning of this policy is strongly workload dependent, and that the relative difference in performance among the various possible configurations can be remarkable (up to 10 x slow-downs). We address this issue by introducing a simple and effective approach that aims to identify the optimal RTM configuration at run-time via lightweight reinforcement learning techniques. The proposed technique requires no off-line sampling of the application, and can be applied to optimize both the cases in which a single global lock or a software TM implementation is used as fall-back synchronization mechanism. We propose and evaluate different designs for the proposed self-tuning mechanisms, which we integrated with GCC in order to achieve full transparency for the programmers. Our experimental study, based on standard TM benchmarks, demonstrates average gains of 60% over any static approach while remaining within 5% from the performance of manually identified optimal configurations. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Self-tuning Intel Restricted Transactional Memory", "paper_id": "WOS:000366445800002"}