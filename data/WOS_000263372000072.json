{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "face_recognition"}, {"score": 0.013270240512411453, "phrase": "face_images"}, {"score": 0.010530280876081212, "phrase": "lrr"}, {"score": 0.004780030485538593, "phrase": "ridge_regression"}, {"score": 0.004642852977065663, "phrase": "regularized_least_square_method"}, {"score": 0.004575740812937594, "phrase": "linear_dependency"}, {"score": 0.00454254773622547, "phrase": "covariate_variables"}, {"score": 0.00444439983637316, "phrase": "appropriate_techniques"}, {"score": 0.004380143676997257, "phrase": "multivariate_labels"}, {"score": 0.004254393078576148, "phrase": "regular_simplex"}, {"score": 0.004162445117081609, "phrase": "highest_degree"}, {"score": 0.0040135756033094225, "phrase": "face_subspace"}, {"score": 0.003786337629480068, "phrase": "holistic_method"}, {"score": 0.0037590396171830434, "phrase": "rr"}, {"score": 0.0036909954181293405, "phrase": "whole_face_region"}, {"score": 0.00350742771604554, "phrase": "illumination_variations"}, {"score": 0.003481957226813911, "phrase": "partial_occlusions"}, {"score": 0.0033696019683761274, "phrase": "novel_algorithm"}, {"score": 0.003320833167729157, "phrase": "local_ridge_regression"}, {"score": 0.0031671412657333364, "phrase": "local_face_region"}, {"score": 0.0029444248503861167, "phrase": "local_variations"}, {"score": 0.002901791790730922, "phrase": "spatial_and_geometrical_information"}, {"score": 0.002808104467715375, "phrase": "dimensionality_reduction"}, {"score": 0.0027775505385261553, "phrase": "holistic_rr"}, {"score": 0.0026976845075643314, "phrase": "efficient_cross-validation_algorithm"}, {"score": 0.0026392916936302355, "phrase": "regularization_parameters"}, {"score": 0.0026105697442146357, "phrase": "local_region"}, {"score": 0.002535492891830764, "phrase": "proposed_algorithm"}, {"score": 0.0023229408675543147, "phrase": "proposed_line"}, {"score": 0.0021515951441422082, "phrase": "better_recognition_accuracies"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Ridge regression (RR)", " Local information", " Local ridge regression (LRR)", " Face recognition"], "paper_abstract": "Ridge regression (RR) for classification is a regularized least square method to model the linear dependency between covariate variables and labels. By applying appropriate techniques to encode the multivariate labels in face recognition as the vertices of the regular simplex which can separate points with highest degree of symmetry, RR maps the face images into a face subspace where the images from each individual will locate near their individual targets. However, as a holistic method, RR operates directly on a whole face region represented as a vector and thus cannot effectively recognize the faces with illumination variations and partial occlusions. in this paper, we present a novel algorithm, termed as local ridge regression (LRR). Different from RR, LRR emphasizes on each local face region matching rather than the whole. As a result, LRR can not only enhance the robustness to the local variations by utilizing the spatial and geometrical information of facial components, but also avoid the dimensionality reduction in the holistic RR as a preprocessing. Furthermore, an efficient cross-validation algorithm is adopted to select the regularization parameters in each local region. Experiments on two standard face databases demonstrate that the proposed algorithm significantly outperforms RR and the two popular linear face recognition techniques (Eigenface and Fisherface). Although we concentrate on RR in this paper, following the proposed line of the research, many current multi-category classifiers can also be applied in face recognition through combining the characteristics of face images and may obtain better recognition accuracies. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Local ridge regression for face recognition", "paper_id": "WOS:000263372000072"}