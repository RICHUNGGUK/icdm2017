{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multimodal_video_genre_classification"}, {"score": 0.004717723626157272, "phrase": "digital_technology"}, {"score": 0.004506048850130758, "phrase": "huge_quantities"}, {"score": 0.004460309246062286, "phrase": "digital_multimedia_data"}, {"score": 0.00437021209960886, "phrase": "high-level_multimedia_documentation"}, {"score": 0.004260134699483774, "phrase": "efficiently_access"}, {"score": 0.004195418010131832, "phrase": "desired_content"}, {"score": 0.004027586827290042, "phrase": "automatic_genre_classification"}, {"score": 0.003966388754366831, "phrase": "simple_and_effective_solution"}, {"score": 0.003906116922372891, "phrase": "multimedia_contents"}, {"score": 0.0038467574225322086, "phrase": "structured_and_well_understandable_way"}, {"score": 0.003581412258960711, "phrase": "television_programmes"}, {"score": 0.003403122817578447, "phrase": "visual-perceptual_information"}, {"score": 0.003250238918180901, "phrase": "structural_information"}, {"score": 0.0030569913145731408, "phrase": "clusters_duration"}, {"score": 0.0027600360731762997, "phrase": "aural_information"}, {"score": 0.0025433263646920364, "phrase": "parallel_neural_network_system"}, {"score": 0.002479150189700726, "phrase": "seven_video_genres"}, {"score": 0.0023798115577749225, "phrase": "weather_forecast"}, {"score": 0.002331641523873951, "phrase": "talk_show"}, {"score": 0.0022267859286766553, "phrase": "audiovisual_material"}, {"score": 0.0021595094738887767, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "classification_accuracy_rate"}], "paper_keywords": ["Video annotation", " Genre recognition", " Neural network", " Feature extraction", " Multimedia semantics"], "paper_abstract": "Improvements in digital technology have made possible the production and distribution of huge quantities of digital multimedia data. Tools for high-level multimedia documentation are becoming indispensable to efficiently access and retrieve desired content from such data. In this context, automatic genre classification provides a simple and effective solution to describe multimedia contents in a structured and well understandable way. We propose in this article a methodology for classifying the genre of television programmes. Features are extracted from four informative sources, which include visual-perceptual information (colour, texture and motion), structural information (shot length, shot distribution, shot rhythm, shot clusters duration and saturation), cognitive information (face properties, such as number, positions and dimensions) and aural information (transcribed text, sound characteristics). These features are used for training a parallel neural network system able to distinguish between seven video genres: football, cartoons, music, weather forecast, newscast, talk show and commercials. Experiments conducted on more than 100 h of audiovisual material confirm the effectiveness of the proposed method, which reaches a classification accuracy rate of 95%.", "paper_title": "Parallel neural networks for multimodal video genre classification", "paper_id": "WOS:000261953400006"}