{"auto_keywords": [{"score": 0.04131289278612189, "phrase": "automatic_summarization"}, {"score": 0.00481495049065317, "phrase": "older_versions"}, {"score": 0.004647442352794694, "phrase": "rougeeval_summarization_evaluation_system"}, {"score": 0.0040334640350288, "phrase": "rouge_evaluation_method"}, {"score": 0.003459191419478298, "phrase": "markov_model"}, {"score": 0.003338690782620756, "phrase": "source_text"}, {"score": 0.0031845067058084583, "phrase": "simple_greedy_word_selection_strategy"}, {"score": 0.0030374213037172803, "phrase": "high_rouge-scores"}, {"score": 0.0026045914281028473, "phrase": "human_readers"}, {"score": 0.0023415390666563177, "phrase": "different_settings"}, {"score": 0.002259883463607508, "phrase": "rougeeval_package"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["automatic summarization", " automatic evaluation", " Markov models"], "paper_abstract": "We show some limitations of the ROUGE evaluation method for automatic summarization. We present a method for automatic summarization based on a Markov model of the source text. By a simple greedy word selection strategy, summaries with high ROUGE-scores are generated. These summaries would however not be considered good by human readers. The method can be adapted to trick different settings of the ROUGEeval package. (C) 2007 Elsevier Ltd. All rights reserved.", "paper_title": "Older versions of the ROUGEeval summarization evaluation system were easier to fool", "paper_id": "WOS:000249742500006"}