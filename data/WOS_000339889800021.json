{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "motion_statistics"}, {"score": 0.004747141873785, "phrase": "reliable_people"}, {"score": 0.004680283709974884, "phrase": "crucial_task"}, {"score": 0.004647206916983993, "phrase": "video_surveillances"}, {"score": 0.0045817497454044565, "phrase": "available_techniques"}, {"score": 0.004549366134876482, "phrase": "map-based_approaches"}, {"score": 0.0044852808671980325, "phrase": "good_performance"}, {"score": 0.004046775982578706, "phrase": "foreground_area"}, {"score": 0.004018158280364063, "phrase": "texture_features"}, {"score": 0.003989742144066683, "phrase": "edge_count"}, {"score": 0.0039195744361570075, "phrase": "complex_scenes"}, {"score": 0.0038234000205958547, "phrase": "erroneous_image_features"}, {"score": 0.00376950244909, "phrase": "large_amount"}, {"score": 0.0037428381813152532, "phrase": "training_data"}, {"score": 0.0036900720643677034, "phrase": "wide_variations"}, {"score": 0.0036639675955591065, "phrase": "crowd_distribution"}, {"score": 0.0033886832371468954, "phrase": "simple_feature-points"}, {"score": 0.003201516237269705, "phrase": "separate_groups"}, {"score": 0.0030679359570782595, "phrase": "related_feature-points"}, {"score": 0.0029399127512711493, "phrase": "rough_estimate"}, {"score": 0.0029190995437264377, "phrase": "group_size"}, {"score": 0.002877912855903293, "phrase": "motion_trajectories"}, {"score": 0.0026900523406547827, "phrase": "extracted_data"}, {"score": 0.0025413743933379185, "phrase": "total_crowd_size"}, {"score": 0.0024877583128884457, "phrase": "group_estimates"}, {"score": 0.0024613749081680474, "phrase": "experimental_results"}, {"score": 0.002426630714074822, "phrase": "proposed_method"}, {"score": 0.0023754296478100865, "phrase": "art_approaches"}, {"score": 0.002260112998123604, "phrase": "benchmark_video_clip"}, {"score": 0.0022124176057373365, "phrase": "proposed_approach"}, {"score": 0.002135146725817984, "phrase": "public_places"}, {"score": 0.0021049977753042253, "phrase": "pedestrian_walkways"}], "paper_keywords": ["People counting", " Crowd counting", " Feature point", " Feature tracking", " Occlusion", " Video surveillance"], "paper_abstract": "Reliable people counting is a crucial task in video surveillances. Among the available techniques, map-based approaches have shown a good performance in estimating the number of people in crowds. These approaches generally subtract the background, and then map the number of people to some features such as foreground area, texture features or edge count. However, in complex scenes, they suffer from inaccurate foreground/background segmentations, erroneous image features, and require large amount of training data to capture the wide variations in crowd distribution. This paper proposes a method using motion statistics of feature-points to estimate the number of moving people in a crowd. Simple feature-points are tracked within the scene. Then moving feature-points are partitioned into clusters corresponding to separate groups of people. For each group, three statistical features are calculated from related feature-points. The amount of moving feature-points is used to provide a rough estimate of group size. Furthermore, motion trajectories of feature-points are utilized to extract two other features related with the amount of occlusions present in groups. The extracted data are used to estimate the number of people in each group, so that the total crowd size is the sum of all group estimates. The experimental results show that the proposed method outperforms the state of the art approaches, e.g., with MSE of 2.357 and MAE of 1.093 for the benchmark video clip \"Peds1\". The proposed approach is good for estimating the number of people in public places, such as pedestrian walkways and parks, where people are moving and partial occlusions present in the scene.", "paper_title": "Counting moving people in crowds using motion statistics of feature-points", "paper_id": "WOS:000339889800021"}