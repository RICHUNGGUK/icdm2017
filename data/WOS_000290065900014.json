{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "modulation_spectral_features"}, {"score": 0.004438250823243621, "phrase": "automatic_recognition"}, {"score": 0.004386887374401584, "phrase": "human_affective_information"}, {"score": 0.004138813595009761, "phrase": "auditory-inspired_long-term_spectro-temporal_representation"}, {"score": 0.003927516959113487, "phrase": "modulation_filterbank"}, {"score": 0.0038820411362656803, "phrase": "speech_analysis"}, {"score": 0.003726967166630926, "phrase": "temporal_modulation_frequency_components"}, {"score": 0.0035366216368204182, "phrase": "human_speech_perception"}, {"score": 0.0034551632687788857, "phrase": "conventional_short-term_spectral_features"}, {"score": 0.0032978134802348433, "phrase": "discrete_emotion_categories"}, {"score": 0.0032031180198375283, "phrase": "promising_performance"}, {"score": 0.003039445153076014, "phrase": "mel-frequency_cepstral_coefficients"}, {"score": 0.0030042210975126616, "phrase": "perceptual_linear_prediction_coefficients"}, {"score": 0.002850682396853918, "phrase": "substantial_improvement"}, {"score": 0.002817639725689939, "phrase": "recognition_performance"}, {"score": 0.002736694413701639, "phrase": "prosodic_features"}, {"score": 0.0026119782818898193, "phrase": "emotion_recognition"}, {"score": 0.0024784363584530976, "phrase": "overall_recognition_rate"}, {"score": 0.0023792975669318615, "phrase": "seven_emotion_categories"}, {"score": 0.0021799789348982516, "phrase": "human_evaluation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Emotion recognition", " Speech modulation", " Spectro-temporal representation", " Affective computing", " Speech analysis"], "paper_abstract": "In this study, modulation spectral features (MSFs) are proposed for the automatic recognition of human affective information from speech. The features are extracted from an auditory-inspired long-term spectro-temporal representation. Obtained using an auditory filterbank and a modulation filterbank for speech analysis, the representation captures both acoustic frequency and temporal modulation frequency components, thereby conveying information that is important for human speech perception but missing from conventional short-term spectral features. On an experiment assessing classification of discrete emotion categories, the MSFs show promising performance in comparison with features that are based on mel-frequency cepstral coefficients and perceptual linear prediction coefficients, two commonly used short-term spectral representations. The MSFs further render a substantial improvement in recognition performance when used to augment prosodic features, which have been extensively used for emotion recognition. Using both types of features, an overall recognition rate of 91.6% is obtained for classifying seven emotion categories. Moreover, in an experiment assessing recognition of continuous emotions, the proposed features in combination with prosodic features attain estimation performance comparable to human evaluation. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Automatic speech emotion recognition using modulation spectral features", "paper_id": "WOS:000290065900014"}