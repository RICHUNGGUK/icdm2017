{"auto_keywords": [{"score": 0.0490076197066283, "phrase": "structured_output_prediction"}, {"score": 0.00481495049065317, "phrase": "magic_moments"}, {"score": 0.004299621153829837, "phrase": "hypothesis_space"}, {"score": 0.004203343568960231, "phrase": "prediction_functions"}, {"score": 0.003882970272082245, "phrase": "linear_scoring_function"}, {"score": 0.003467040410632942, "phrase": "hypothesis_class"}, {"score": 0.0028919522313933525, "phrase": "first_two_moments"}, {"score": 0.002795228413298423, "phrase": "scoring_function"}, {"score": 0.0027017308406240563, "phrase": "output_space"}, {"score": 0.002495521662819317, "phrase": "convex_objective_functions"}, {"score": 0.0023313149689465386, "phrase": "extensive_experimental_results"}, {"score": 0.002279011030331704, "phrase": "sequence_alignment"}, {"score": 0.0021051143798310194, "phrase": "rna"}], "paper_keywords": ["structured output prediction", " discriminative learning", " Z-score", " discriminant analysis", " PAC bound"], "paper_abstract": "Most approaches to structured output prediction rely on a hypothesis space of prediction functions that compute their output by maximizing a linear scoring function. In this paper we present two novel learning algorithms for this hypothesis class, and a statistical analysis of their performance. The methods rely on efficiently computing the first two moments of the scoring function over the output space, and using them to create convex objective functions for training. We report extensive experimental results for sequence alignment, named entity recognition, and RNA secondary structure prediction.", "paper_title": "Magic Moments for Structured Output Prediction", "paper_id": "WOS:000263240700007"}