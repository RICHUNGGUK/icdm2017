{"auto_keywords": [{"score": 0.030507086791631846, "phrase": "independent_components"}, {"score": 0.00481495049065317, "phrase": "near-synonym_choice"}, {"score": 0.004645959941491617, "phrase": "different_usages"}, {"score": 0.0046046429665581555, "phrase": "different_contexts"}, {"score": 0.004173603566828364, "phrase": "increasing_concern"}, {"score": 0.004045068727683462, "phrase": "query_expansion"}, {"score": 0.004009074013302036, "phrase": "information_retrieval"}, {"score": 0.003920476803132283, "phrase": "alternative_word_selection"}, {"score": 0.003868257410961701, "phrase": "support_systems"}, {"score": 0.0037827603118271757, "phrase": "text_summarization"}, {"score": 0.0035851703423654432, "phrase": "latent_semantic_analysis"}, {"score": 0.0035532597369137033, "phrase": "isa"}, {"score": 0.003234762750570416, "phrase": "lsa"}, {"score": 0.003163212007747804, "phrase": "useful_latent_features"}, {"score": 0.0029845364184358544, "phrase": "ica"}, {"score": 0.0027659126653647712, "phrase": "svm_classifier"}, {"score": 0.0026686444508167875, "phrase": "best_near-synonym_prediction"}, {"score": 0.002574788013427524, "phrase": "proposed_method"}, {"score": 0.002418393046947528, "phrase": "experimental_results"}, {"score": 0.002322895056238477, "phrase": "useful_contextual_features"}, {"score": 0.0023021895404322767, "phrase": "minimized_term_dependence"}, {"score": 0.0022613292987262177, "phrase": "classifiers'_ability"}, {"score": 0.002162316557411786, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Near-synonym choice", " Independent component analysis", " Information retrieval", " Natural language processing"], "paper_abstract": "Despite their similar meanings, near-synonyms may have different usages in different contexts, and the development of algorithms that can verify whether near-synonyms do match their given contexts has been the focus of increasing concern. Such algorithms have many applications such as query expansion for information retrieval (IR), alternative word selection for writing support systems, and (near-)duplicate detection for text summarization. In this paper, we propose a framework that incorporates latent semantic analysis (ISA) and independent component analysis (ICA) to automatically select suitable near-synonyms according to the given context. LSA is used to discover useful latent features that do not frequently occur in the contexts of near-synonyms, and ICA is used to estimate a set of independent components by minimizing the dependence between features. An SVM classifier is then trained with the independent components for best near-synonym prediction. In experiments, we evaluate the proposed method on both Chinese and English sentences, and compare its performance to state-of-the-art supervised and unsupervised methods. Experimental results show that training on the independent components that contain useful contextual features with minimized term dependence can improve the classifiers' ability to discriminate among near-synonyms, thus yielding better performance. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Independent component analysis for near-synonym choice", "paper_id": "WOS:000320493400014"}