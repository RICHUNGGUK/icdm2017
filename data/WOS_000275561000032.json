{"auto_keywords": [{"score": 0.04714352860016274, "phrase": "lossy_transmission"}, {"score": 0.00481495049065317, "phrase": "linear_encoding_approach"}, {"score": 0.004768378525561471, "phrase": "index_assignment"}, {"score": 0.004722254884093624, "phrase": "lossy_source-channel"}, {"score": 0.004586531354697466, "phrase": "general_scheme"}, {"score": 0.004411588377842043, "phrase": "arbitrary_statistics"}, {"score": 0.0043477114072437316, "phrase": "noisy_channel"}, {"score": 0.004284755353695709, "phrase": "mean-square_error_fidelity_criterion"}, {"score": 0.004141365648080381, "phrase": "transform_coding"}, {"score": 0.0040222701316738295, "phrase": "transform_coefficients"}, {"score": 0.003983334573043943, "phrase": "linear_encoding"}, {"score": 0.003925633992809873, "phrase": "quantization_indices"}, {"score": 0.0038876302202924644, "phrase": "entropy_coding"}, {"score": 0.0038499929374478125, "phrase": "channel_coding"}, {"score": 0.003757480190200645, "phrase": "single_linear_encoding_function"}, {"score": 0.0036671822784770463, "phrase": "\"catastrophic\"_behavior"}, {"score": 0.003631671435460452, "phrase": "conventional_entropy_coding"}, {"score": 0.0035443861412929006, "phrase": "full_power"}, {"score": 0.0035100601949451028, "phrase": "modern_coding_techniques"}, {"score": 0.003459191419478298, "phrase": "\"belief-propagation\"_decoding"}, {"score": 0.0031845067058084583, "phrase": "large_block_length"}, {"score": 0.0031383410838018953, "phrase": "arbitrary_source_statistics"}, {"score": 0.003107935254560724, "phrase": "binary-input_output-symmetric_channel"}, {"score": 0.003003809128328864, "phrase": "finite_block_length"}, {"score": 0.0029747028229638625, "phrase": "low_decoding_complexity"}, {"score": 0.002875027551180213, "phrase": "explicit_construction"}, {"score": 0.002778682854371595, "phrase": "digital_images"}, {"score": 0.0027383842769094354, "phrase": "binary_symmetric_channel"}, {"score": 0.002672511078070529, "phrase": "significant_improvements"}, {"score": 0.0026209522797963447, "phrase": "previously_proposed_channel-optimized_quantization_schemes"}, {"score": 0.0025331002386232014, "phrase": "conventional_concatenation"}, {"score": 0.0023431692392929353, "phrase": "art_channel_coding"}, {"score": 0.002264607102799332, "phrase": "special_case"}, {"score": 0.0021049977753042253, "phrase": "practical_interest"}], "paper_keywords": ["Channel-optimized quantization", " iterative decoding", " source-channel coding"], "paper_abstract": "We present a general scheme for the lossy transmission of a source with arbitrary statistics through a noisy channel under the mean-square error fidelity criterion. Our approach is based on transform coding, scalar quantization of the transform coefficients and linear encoding of the quantization indices. Entropy coding and channel coding are merged into a single linear encoding function, such that the \"catastrophic\" behavior of conventional entropy coding is avoided and the full power of modern coding techniques and iterative \"Belief-Propagation\" decoding can be exploited. We show that this approach is asymptotically optimal in the limit of large block length, for arbitrary source statistics and binary-input output-symmetric channel. In the practical regime of finite block length and low decoding complexity, we show, through the explicit construction of codes for the lossy transmission of digital images over a binary symmetric channel, that our approach yields significant improvements with respect to previously proposed channel-optimized quantization schemes and also with respect to the conventional concatenation of state-of-the art image coding with state-of-the art channel coding. Although our constructive example focuses on a special case, the approach is general and can be applied to other classes of sources of practical interest.", "paper_title": "A Linear Encoding Approach to Index Assignment in Lossy Source-Channel Coding", "paper_id": "WOS:000275561000032"}