{"auto_keywords": [{"score": 0.04835978765719222, "phrase": "entire_database"}, {"score": 0.021773614690715693, "phrase": "association_rules"}, {"score": 0.005817020060308081, "phrase": "threshold_condition"}, {"score": 0.00481495049065317, "phrase": "efficient_sample"}, {"score": 0.004779876533667754, "phrase": "market_basket_data"}, {"score": 0.004745056850725867, "phrase": "classical_data"}, {"score": 0.0047277417909824745, "phrase": "mining_algorithms"}, {"score": 0.004693300099911199, "phrase": "expensive_passes"}, {"score": 0.004591466267316524, "phrase": "frequent_items"}, {"score": 0.004221072004655573, "phrase": "large_amount"}, {"score": 0.003646399625591736, "phrase": "complete_database"}, {"score": 0.0035802796531956413, "phrase": "correct_sample"}, {"score": 0.003476963781647026, "phrase": "easy_task"}, {"score": 0.0032433414042726356, "phrase": "better_accuracy"}, {"score": 0.0027405092973494293, "phrase": "average_number"}, {"score": 0.002690771424958613, "phrase": "database_and_average_weight"}, {"score": 0.002401875938287542, "phrase": "proposed_algorithm"}, {"score": 0.0023154527779996213, "phrase": "ibm_synthetic_data_generator"}, {"score": 0.002290135975651888, "phrase": "vivid_comparative_performance_evaluation"}, {"score": 0.002265095354846931, "phrase": "proposed_technique"}, {"score": 0.00224032791638295, "phrase": "existing_sampling_techniques"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Sampling", " Synopsis", " Threshold", " Scalability"], "paper_abstract": "Classical data mining algorithms require expensive passes over the entire database to generate frequent items and hence to generate association rules. With the increase in the size of database, it is becoming very difficult to handle large amount of data for computation. One of the solutions to this problem is to generate sample from the database that acts as representative of the entire database for finding association rules in such a way that the distance of the sample from the complete database is minimal. Choosing correct sample that could represent data is not an easy task. Many algorithms have been proposed in the past. Some of them are computationally fast while others give better accuracy. In this paper, we present an algorithm for generating a sample from the database that can replace the entire database for generating association rules and is aimed at keeping a balance between accuracy and speed. The algorithm that is proposed takes into account the average number of small, medium and large 1-itemset in the database and average weight of the transactions to define threshold condition for the transactions. Set of transactions that satisfy the threshold condition is chosen as the representative for the entire database. The effectiveness of the proposed algorithm has been tested over several runs of database generated by IBM synthetic data generator. A vivid comparative performance evaluation of the proposed technique with the existing sampling techniques for comparing the accuracy and speed has also been carried out. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "A new approach for generating efficient sample from market basket data", "paper_id": "WOS:000284863200007"}