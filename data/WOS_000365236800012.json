{"auto_keywords": [{"score": 0.03165799083170358, "phrase": "sldp"}, {"score": 0.010511512028390058, "phrase": "heterogeneous_hadoop_clusters"}, {"score": 0.010165904756395581, "phrase": "hdfs"}, {"score": 0.008276417967487761, "phrase": "mapreduce_performance"}, {"score": 0.00481495049065317, "phrase": "data_placement"}, {"score": 0.004723322467153553, "phrase": "data_placement_decision"}, {"score": 0.004678184269060857, "phrase": "hadoop"}, {"score": 0.004655742198075387, "phrase": "distributed_file_system"}, {"score": 0.004458722048888919, "phrase": "data_locality"}, {"score": 0.0043738432231020885, "phrase": "primary_criterion"}, {"score": 0.00433200902751133, "phrase": "task_scheduling"}, {"score": 0.00429057323623293, "phrase": "mapreduce_model"}, {"score": 0.004188702178897384, "phrase": "application_performance"}, {"score": 0.0041287394089001405, "phrase": "existing_hdfs's_rack-aware_data_placement_strategy"}, {"score": 0.0039729853486821995, "phrase": "mapreduce_framework"}, {"score": 0.003934970057482768, "phrase": "homogeneous_hadoop_clusters"}, {"score": 0.0036788184374592706, "phrase": "increasingly_energy_dissipation"}, {"score": 0.003643607569483598, "phrase": "heterogeneous_environments"}, {"score": 0.0035060903664150115, "phrase": "inflexible_replica_factor"}, {"score": 0.0034392837410790293, "phrase": "data_block"}, {"score": 0.003325410433297401, "phrase": "unnecessary_waste"}, {"score": 0.003293570937654716, "phrase": "storage_space"}, {"score": 0.0031845067058084583, "phrase": "inactive_data"}, {"score": 0.003154012038613403, "phrase": "hadoop_system"}, {"score": 0.0030203487665054806, "phrase": "novel_data_placement_strategy"}, {"score": 0.0028784478769295204, "phrase": "heterogeneity_aware_algorithm"}, {"score": 0.002690886043654469, "phrase": "data_blocks"}, {"score": 0.0026269009701853055, "phrase": "vst"}, {"score": 0.0024556852466581527, "phrase": "hotness_proportional_replication"}, {"score": 0.00242047093248845, "phrase": "disk_space"}, {"score": 0.00236289633510808, "phrase": "effective_power_control_function"}, {"score": 0.0021049977753042253, "phrase": "heterogeneous_hadoop_cluster"}], "paper_keywords": ["Hadoop cluster", " HDFS", " Data placement", " Heterogeneous", " Replica"], "paper_abstract": "Data placement decision of Hadoop distributed file system (HDFS) is very important for the data locality which is a primary criterion for task scheduling of MapReduce model and eventually affects the application performance. The existing HDFS's rack-aware data placement strategy and replication scheme are work well with MapReduce framework in homogeneous Hadoop clusters, but in practice, such data placement policy can noticeably reduce MapReduce performance and may cause increasingly energy dissipation in heterogeneous environments. Besides that, HDFS employs an inflexible replica factor acquiescently for each data block, which will give rise to unnecessary waste of storage space when there is a lot of inactive data in Hadoop system. In this paper, we propose a novel data placement strategy (SLDP) for heterogeneous Hadoop clusters. SLDP adopts a heterogeneity aware algorithm to divide various nodes into several virtual storage tiers (VSTs) firstly, and then places data blocks across nodes in each VST circuitously according to the hotness of data. Furthermore, SLDP uses a hotness proportional replication to save disk space and also has an effective power control function. Experimental results on two real data-intensive applications show that SLDP is energy-efficient, space-saving and able to improve MapReduce performance in a heterogeneous Hadoop cluster significantly.", "paper_title": "Optimizing data placement in heterogeneous Hadoop clusters", "paper_id": "WOS:000365236800012"}