{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "streaming_applications"}, {"score": 0.02809562715313692, "phrase": "streaming_program"}, {"score": 0.004503422625191897, "phrase": "embedded_domain"}, {"score": 0.004450568197899267, "phrase": "simd-enabled_architectures"}, {"score": 0.0042452552248398445, "phrase": "data-level_parallelism"}, {"score": 0.0038624981944755813, "phrase": "particular_simd_engine"}, {"score": 0.003640938643675543, "phrase": "growing_application_domain"}, {"score": 0.003541923233726252, "phrase": "ideal_solution"}, {"score": 0.003500313767208306, "phrase": "multi-core_architectures"}, {"score": 0.0034185505275141077, "phrase": "tiled_architectures"}, {"score": 0.003378385493203297, "phrase": "single-core_systems"}, {"score": 0.003247868216333148, "phrase": "simd_acceleration_units"}, {"score": 0.0031223774204093713, "phrase": "simd_code"}, {"score": 0.00290855128461017, "phrase": "high-level_streaming_graphs"}, {"score": 0.0028405715222684183, "phrase": "high-level_information"}, {"score": 0.002807178116892454, "phrase": "execution_rates"}, {"score": 0.002763261749602258, "phrase": "communication_patterns"}, {"score": 0.0026986685585382347, "phrase": "graph_structure"}, {"score": 0.0026774738852854427, "phrase": "vectorize_actors"}, {"score": 0.0026045914281028473, "phrase": "intermediate_code"}, {"score": 0.0025537472239953807, "phrase": "low-overhead_architectural_modifications"}, {"score": 0.0025038930574283174, "phrase": "data_elements"}, {"score": 0.002474447780553576, "phrase": "scalar_and_vectorized_parts"}, {"score": 0.002286781334850213, "phrase": "scalar_code"}, {"score": 0.0022509878391826867, "phrase": "current_state-of-art_autovectorizing_compilers"}, {"score": 0.0021983430142660373, "phrase": "low-overhead_data"}], "paper_keywords": ["Design", " Languages", " Performance", " Streaming", " Compiler", " SIMD Architecture", " Optimization"], "paper_abstract": "SIMD (Single Instruction, Multiple Data) engines are an essential part of the processors in various computing markets, from servers to the embedded domain. Although SIMD-enabled architectures have the capability of boosting the performance of many application domains by exploiting data-level parallelism, it is very challenging for compilers and also programmers to identify and transform parts of a program that will benefit from a particular SIMD engine. The focus of this paper is on the problem of SIMDization for the growing application domain of streaming. Streaming applications are an ideal solution for targeting multi-core architectures, such as shared/distributed memory systems, tiled architectures, and single-core systems. Since these architectures, in most cases, provide SIMD acceleration units as well, it is highly beneficial to generate SIMD code from streaming programs. Specifically, we introduce MacroSS, which is capable of performing macro-SIMDization on high-level streaming graphs. Macro-SIMDization uses high-level information such as execution rates of actors and communication patterns between them to transform the graph structure, vectorize actors of a streaming program, and generate intermediate code. We also propose low-overhead architectural modifications that accelerate shuffling of data elements between the scalar and vectorized parts of a streaming program. Our experiments show that MacroSS is capable of generating code that, on average, outperforms scalar code compiled with the current state-of-art autovectorizing compilers by 54%. Using the low-overhead data shuffling hardware, performance is improved by an additional 8% with less than 1% area overhead.", "paper_title": "MacroSS: Macro-SIMDization of Streaming Applications", "paper_id": "WOS:000275926700024"}