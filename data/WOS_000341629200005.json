{"auto_keywords": [{"score": 0.03370894964701269, "phrase": "nmsnn"}, {"score": 0.028059855130987493, "phrase": "virtual_images"}, {"score": 0.00481495049065317, "phrase": "nonlinear_manifolds"}, {"score": 0.004712988631183401, "phrase": "manifold_learning_methods"}, {"score": 0.004672808182229058, "phrase": "important_techniques"}, {"score": 0.004632968695963776, "phrase": "nonlinear_extraction"}, {"score": 0.004593467306126913, "phrase": "high-dimensional_data_structures"}, {"score": 0.00445783412174435, "phrase": "global_manifold"}, {"score": 0.00418046991987597, "phrase": "additional_information"}, {"score": 0.004039639718055365, "phrase": "large_number"}, {"score": 0.0038702288460744274, "phrase": "data_reconstruction"}, {"score": 0.0037719988989298983, "phrase": "data_manifolds"}, {"score": 0.0036762529165489644, "phrase": "nonlinear_method"}, {"score": 0.0036137713873827374, "phrase": "deep_neural_network"}, {"score": 0.0035833690509814073, "phrase": "nn"}, {"score": 0.0034033029171804106, "phrase": "unsupervised_learning"}, {"score": 0.003374250301861101, "phrase": "bottleneck_nn"}, {"score": 0.0033454448643854525, "phrase": "data_labels"}, {"score": 0.003288567185099276, "phrase": "simultaneous_manifold_learning"}, {"score": 0.0030705342386533083, "phrase": "facial_images"}, {"score": 0.002929056388593134, "phrase": "different_metrics"}, {"score": 0.0028916124463906983, "phrase": "identity_manifold"}, {"score": 0.0028302635493019867, "phrase": "image_identity"}, {"score": 0.0027702126237754625, "phrase": "identity_recognition"}, {"score": 0.002746549549029177, "phrase": "k-nearest_neighbor_classifier"}, {"score": 0.0027114323601885666, "phrase": "virtual_identities"}, {"score": 0.0026199603775129516, "phrase": "different_expressions"}, {"score": 0.002597577409911978, "phrase": "test_subjects"}, {"score": 0.002553382046204689, "phrase": "expression_manifold"}, {"score": 0.0025207284405252914, "phrase": "facial_expression_recognition_rate"}, {"score": 0.0024566655761509276, "phrase": "virtual_expressions"}, {"score": 0.0024356742694508662, "phrase": "test_persons"}, {"score": 0.002178529882942255, "phrase": "face_recognition_task"}, {"score": 0.002150659690967412, "phrase": "single_image"}], "paper_keywords": ["Neural network", " Manifold learning", " Multitask learning", " Virtual pattern", " Deep structure", " Manifold separation"], "paper_abstract": "Manifold learning methods are important techniques for nonlinear extraction of high-dimensional data structures. These methods usually extract a global manifold for data. However, in many real-world problems, there is not only one global manifold, but also additional information about the objects is shared by a large number of manifolds. These manifolds can share information for data reconstruction. To simultaneously extract these data manifolds, this paper proposes a nonlinear method based on the deep neural network (NN) named nonlinear manifold separator NN (NMSNN). Unlike unsupervised learning of bottleneck NN, data labels were used for simultaneous manifold learning. This paper makes use of NMSNN for extracting both expression and identity manifolds for facial images of the CK+ database. These manifolds have been evaluated by different metrics. The identity manifold is used for changing image identity. The result of identity recognition by K-nearest neighbor classifier shows that virtual identities are exactly sanitized. The virtual images for different expressions of test subjects are generated by expression manifold. The facial expression recognition rate of 92.86 % is achieved for virtual expressions of test persons. It is shown that NMSNN can be used to enrich datasets by sanitizing virtual images. As a result, 8 and 19 % improvements are gained in the face recognition task by a single image of each person on CK+ and Bosphorus databases, respectively.", "paper_title": "Simultaneous Learning of Nonlinear Manifolds Based on the Bottleneck Neural Network", "paper_id": "WOS:000341629200005"}