{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "resource_utilization"}, {"score": 0.049250789168149026, "phrase": "smt_processors"}, {"score": 0.03270162401837859, "phrase": "rucount"}, {"score": 0.013729609996806589, "phrase": "long-latency_operations"}, {"score": 0.012555163826694908, "phrase": "shared_resources"}, {"score": 0.007811160940580919, "phrase": "icount"}, {"score": 0.0045959609346817535, "phrase": "chip_parallelism"}, {"score": 0.004503297824977738, "phrase": "performance_improvement"}, {"score": 0.0044771659114402045, "phrase": "modern_processors"}, {"score": 0.004451231251215905, "phrase": "smt"}, {"score": 0.004374139251810056, "phrase": "single_thread"}, {"score": 0.004236321075918639, "phrase": "shared_fashion"}, {"score": 0.00398510860837973, "phrase": "lower-level_memory_hierarchy"}, {"score": 0.003770633265791941, "phrase": "extended_number"}, {"score": 0.0037487368769596814, "phrase": "clock_cycles"}, {"score": 0.003705323407433896, "phrase": "undesired_inter-thread_interference"}, {"score": 0.003609465839614284, "phrase": "negative_impacts"}, {"score": 0.0035885019925285394, "phrase": "overall_system_throughput"}, {"score": 0.0035676594679040488, "phrase": "average_thread_performance"}, {"score": 0.003516079377293321, "phrase": "instruction_fetch_policies"}, {"score": 0.0034551632687788857, "phrase": "thread_priority"}, {"score": 0.0034251007650845534, "phrase": "fetch_stage"}, {"score": 0.003175241510860455, "phrase": "better_performance"}, {"score": 0.00310208083392418, "phrase": "instruction_fetch_policy"}, {"score": 0.003039445153076014, "phrase": "individual_thread"}, {"score": 0.00301298877185846, "phrase": "prioritization_process"}, {"score": 0.0029867619862229853, "phrase": "proposed_policy"}, {"score": 0.0029435555176530732, "phrase": "front-end_stages"}, {"score": 0.00280126189041041, "phrase": "thread_management"}, {"score": 0.00278497898719426, "phrase": "higher_priority"}, {"score": 0.0026892447164623247, "phrase": "overall_resources"}, {"score": 0.002507511169156787, "phrase": "hardware_resource"}, {"score": 0.0024496978447849835, "phrase": "limited_resource_entries"}, {"score": 0.002264218639227785, "phrase": "averaged_performance"}, {"score": 0.0022184630090454132, "phrase": "similar_level"}, {"score": 0.002142161017595363, "phrase": "studied_policies"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Instruction fetch policy", " Simultaneous multithreading", " Memory accessing resource", " Computation resource", " Thread management"], "paper_abstract": "Simultaneous Multithreading (SMT) architectures are proposed to better explore on-chip parallelism, which capture the essence of performance improvement in modern processors. SMT overcomes the limits in a single thread by fetching and executing from multiple of them in a shared fashion. The long-latency operations, however, still cause inefficiency in SMT processors. When instructions have to wait for data from lower-level memory hierarchy, the dependent instructions cannot proceed, hence continue occupying the shared resources on the chip for an extended number of clock cycles. This introduces undesired inter-thread interference in SMT processors, which further leads to negative impacts on overall system throughput and average thread performance. In practice, instruction fetch policies take the responsibility of assigning thread priority at the fetch stage, in an effort to better distribute the shared resources among threads in the same core to cope with the long-latency operations and other runtime behavior from the thread for better performance. In this paper we propose an instruction fetch policy RUCOUNT, which considers resource utilization of individual thread in the prioritization process. The proposed policy observes instructions in the front-end stages of the pipeline as well as low-level data misses to summarize the resource utilization for thread management. Higher priority is granted to the thread(s) with less utilized resources, such that overall resources are distributed more efficiently in SMT processors. As a result, it has two unique features compared to other policies: one is to observe the hardware resource comprehensively and the other is to monitor limited resource entries. Our experimental results demonstrate that RUCOUNT is 20% better than ICOUNT, 10% than Stall, 8% than DG and 3% than DWarn, in terms of averaged performance. Considering its hardware overhead is at the similar level as ICOUNT and DWarn, our proposed instruction fetch policy RUCOUNT is superior among the studied policies. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A resource utilization based instruction fetch policy for SMT processors", "paper_id": "WOS:000348557400001"}