{"auto_keywords": [{"score": 0.03374883864749991, "phrase": "tracking_hji_equation"}, {"score": 0.00481495049065317, "phrase": "completely_unknown_continuous-time_systems"}, {"score": 0.00475070135279933, "phrase": "off-policy_reinforcement_learning"}, {"score": 0.004442032546224076, "phrase": "h-infinity_tracking_controller"}, {"score": 0.004382737590042589, "phrase": "nonlinear_continuous-time_systems"}, {"score": 0.004043158538239064, "phrase": "discounted_performance_function"}, {"score": 0.003909522412849035, "phrase": "h-infinity_tracking"}, {"score": 0.0036553070575015344, "phrase": "nash_equilibrium_solution"}, {"score": 0.0035823043879169153, "phrase": "associated_min-max_optimization_problem"}, {"score": 0.0033045378860812403, "phrase": "control_solution"}, {"score": 0.0029473940028924748, "phrase": "discount_factor"}, {"score": 0.002888488567436329, "phrase": "local_asymptotic_stability"}, {"score": 0.002830757050018908, "phrase": "tracking_error_dynamics"}, {"score": 0.0027741761880779535, "phrase": "off-policy_reinforcement_learning_algorithm"}, {"score": 0.0024742098091226203, "phrase": "system_dynamics"}, {"score": 0.0023923066544220277, "phrase": "proposed_algorithm"}, {"score": 0.0022365262201954643, "phrase": "simulation_examples"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Bounded L-2-gain", " H-infinity tracking controller", " reinforcement learning (RL)", " tracking Hamilton-Jacobi-Isaac (HJI) equation"], "paper_abstract": "This paper deals with the design of an H-infinity tracking controller for nonlinear continuous-time systems with completely unknown dynamics. A general bounded L2-gain tracking problem with a discounted performance function is introduced for the H-infinity tracking. A tracking Hamilton-Jacobi-Isaac (HJI) equation is then developed that gives a Nash equilibrium solution to the associated min-max optimization problem. A rigorous analysis of bounded L-2-gain and stability of the control solution obtained by solving the tracking HJI equation is provided. An upper-bound is found for the discount factor to assure local asymptotic stability of the tracking error dynamics. An off-policy reinforcement learning algorithm is used to learn the solution to the tracking HJI equation online without requiring any knowledge of the system dynamics. Convergence of the proposed algorithm to the solution to the tracking HJI equation is shown. Simulation examples are provided to verify the effectiveness of the proposed method.", "paper_title": "H-infinity Tracking Control of Completely Unknown Continuous-Time Systems via Off-Policy Reinforcement Learning", "paper_id": "WOS:000362358800026"}