{"auto_keywords": [{"score": 0.0432739673557945, "phrase": "class_imbalance_problem"}, {"score": 0.015719716506582538, "phrase": "imbalanced_data"}, {"score": 0.011619848158326404, "phrase": "adaboost_algorithm"}, {"score": 0.004674952036988355, "phrase": "imbalanced_class_distribution"}, {"score": 0.004583878086896926, "phrase": "significant_drawback"}, {"score": 0.004342430078306461, "phrase": "relatively_balanced_class_distribution"}, {"score": 0.004299910946753963, "phrase": "equal_misclassification_costs"}, {"score": 0.004236908273106904, "phrase": "significant_difficulty"}, {"score": 0.004195418010131832, "phrase": "frequent_occurrence"}, {"score": 0.0040334640350288, "phrase": "extra_research_efforts"}, {"score": 0.003462599815177726, "phrase": "successful_meta-technique"}, {"score": 0.0034118234596993836, "phrase": "classification_accuracy"}, {"score": 0.003296212583539166, "phrase": "comprehensive_analysis"}, {"score": 0.002899965889623787, "phrase": "cost_items"}, {"score": 0.0028574164693918433, "phrase": "learning_framework"}, {"score": 0.0028294132377182134, "phrase": "adaboost"}, {"score": 0.0027200305495826797, "phrase": "proposed_algorithms_tallies"}, {"score": 0.002680114113899346, "phrase": "stagewise_additive"}, {"score": 0.0025892330566358503, "phrase": "cost_exponential_loss"}, {"score": 0.002551231163230566, "phrase": "boosting_algorithms"}, {"score": 0.0024405312482831646, "phrase": "different_types"}, {"score": 0.0023346234464901978, "phrase": "rare_cases"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["classification", " class imbalance problem", " AdaBoost", " cost-sensitive learning"], "paper_abstract": "Classification of data with imbalanced class distribution has posed a significant drawback of the performance attainable by most standard classifier learning algorithms, which assume a relatively balanced class distribution and equal misclassification costs. The significant difficulty and frequent occurrence of the class imbalance problem indicate the need for extra research efforts. The objective of this paper is to investigate meta-techniques applicable to most classifier learning algorithms, with the aim to advance the classification of imbalanced data. The AdaBoost algorithm is reported as a successful meta-technique for improving classification accuracy. The insight gained from a comprehensive analysis of the AdaBoost algorithm in terms of its advantages and shortcomings in tacking the class imbalance problem leads to the exploration of three cost-sensitive boosting algorithms, which are developed by introducing cost items into the learning framework of AdaBoost. Further analysis shows that one of the proposed algorithms tallies with the stagewise additive modelling in statistics to minimize the cost exponential loss. These boosting algorithms are also studied with respect to their weighting strategies towards different types of samples, and their effectiveness in identifying rare cases through experiments on several real world medical data sets, where the class imbalance problem prevails. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "Cost-sensitive boosting for classification of imbalanced data", "paper_id": "WOS:000249678400004"}