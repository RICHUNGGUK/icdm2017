{"auto_keywords": [{"score": 0.04001538688662844, "phrase": "approximation_functions"}, {"score": 0.010612387000973441, "phrase": "function_approximation"}, {"score": 0.010318872356626227, "phrase": "ise"}, {"score": 0.009677750641152411, "phrase": "approximate_hessian_matrix"}, {"score": 0.005189779879015529, "phrase": "popular_approximating_functions"}, {"score": 0.004718897469501381, "phrase": "incomplete_series_expansion"}, {"score": 0.003951800212882157, "phrase": "off-diagonal_terms"}, {"score": 0.00363080961099728, "phrase": "arbitrary_number"}, {"score": 0.003601628511550962, "phrase": "previously_sampled_points"}, {"score": 0.0032428780373184207, "phrase": "storage_requirements"}, {"score": 0.003040050100579337, "phrase": "sparse_diagonal_matrix"}, {"score": 0.0029672941061574375, "phrase": "resultant_approximations"}, {"score": 0.002884603537502399, "phrase": "proposed_approximation_functions"}, {"score": 0.0027816546451972725, "phrase": "gradient-based_sequential_approximate_optimization"}, {"score": 0.0027041233221381756, "phrase": "typical_example"}, {"score": 0.002682370021834353, "phrase": "structural_design_problems"}, {"score": 0.0025866199378466754, "phrase": "wide_selection"}, {"score": 0.002395530243993313, "phrase": "reciprocal_and_exponential_intervening_variables"}, {"score": 0.002254672021120091, "phrase": "new_family"}, {"score": 0.0021306709646058295, "phrase": "structural_optimization_applications"}], "paper_keywords": ["nonlinear function approximation", " sequential approximate optimization (SAO)", " incomplete series expansion (ISE)"], "paper_abstract": "We present an incomplete series expansion (ISE) as a basis for function approximation. The ISE is expressed in terms of an approximate Hessian matrix, which may contain second, third, and even higher order \"main\" or diagonal terms, but which excludes \"interaction\" or off-diagonal terms. From the ISE, a family of approximation functions may be derived. The approximation functions may be based on an arbitrary number of previously sampled points, and any of the function and gradient values at suitable previously sampled points may be enforced when deriving the approximation functions. When function values only are enforced, the storage requirements are minimal. However, irrespective of the conditions enforced, the approximate Hessian matrix is a sparse diagonal matrix. In addition, the resultant approximations are separable. Hence, the proposed approximation functions are very well-suited for use in gradient-based sequential approximate optimization requiring computationally expensive simulations; a typical example is structural design problems with many design variables and constraints. We derived a wide selection of approximations from the family of ISE approximating functions; these include approximations based on the substitution of reciprocal and exponential intervening variables. A comparison with popular approximating functions previously proposed illustrates the accuracy and flexibility of the new family of approximation functions. In fact, a number of popular approximating functions previously proposed for structural optimization applications derive from our ISE.", "paper_title": "Incomplete series expansion for function approximation", "paper_id": "WOS:000246770400002"}