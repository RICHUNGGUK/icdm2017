{"auto_keywords": [{"score": 0.029183625978501333, "phrase": "irls"}, {"score": 0.00481495049065317, "phrase": "smoothed_low_rank"}, {"score": 0.0047555023078686386, "phrase": "sparse_matrix_recovery"}, {"score": 0.00469678464293492, "phrase": "iteratively_reweighted_least_squares_minimization"}, {"score": 0.0045249263666466005, "phrase": "general_framework"}, {"score": 0.004096635798793164, "phrase": "least_squares"}, {"score": 0.0039221899471111, "phrase": "fast_solver"}, {"score": 0.003802135020791801, "phrase": "objective_function"}, {"score": 0.0034634973175137486, "phrase": "traditional_irls"}, {"score": 0.003357435261066107, "phrase": "sparse_only_or_low_rank_only_minimization_problem"}, {"score": 0.0031549249117721946, "phrase": "paper_generalizes_irls"}, {"score": 0.0030582832134483685, "phrase": "sparse_minimization_problems"}, {"score": 0.0029830992938695007, "phrase": "essential_formulations"}, {"score": 0.0028737647829311587, "phrase": "concrete_example"}, {"score": 0.0025691622090542304, "phrase": "stationary_point"}, {"score": 0.0022967713922705, "phrase": "previous_one"}, {"score": 0.002226357953581725, "phrase": "special_properties"}, {"score": 0.002131383155056741, "phrase": "extensive_experiments"}], "paper_keywords": ["Low-rank and sparse minimization", " iteratively reweighted least squares"], "paper_abstract": "This paper presents a general framework for solving the low-rank and/or sparse matrix minimization problems, which may involve multiple nonsmooth terms. The iteratively reweighted least squares (IRLSs) method is a fast solver, which smooths the objective function and minimizes it by alternately updating the variables and their weights. However, the traditional IRLS can only solve a sparse only or low rank only minimization problem with squared loss or an affine constraint. This paper generalizes IRLS to solve joint/mixed low-rank and sparse minimization problems, which are essential formulations for many tasks. As a concrete example, we solve the Schatten-p norm and l(2,q)-norm regularized low-rank representation problem by IRLS, and theoretically prove that the derived solution is a stationary point (globally optimal if p, q >= 1). Our convergence proof of IRLS is more general than previous one that depends on the special properties of the Schatten-p norm and l(2,q)-norm. Extensive experiments on both synthetic and real data sets demonstrate that our IRLS is much more efficient.", "paper_title": "Smoothed Low Rank and Sparse Matrix Recovery by Iteratively Reweighted Least Squares Minimization", "paper_id": "WOS:000354550200012"}