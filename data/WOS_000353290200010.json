{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "otoacoustic_emission"}, {"score": 0.004707949417676074, "phrase": "biometrics"}, {"score": 0.00462919213721188, "phrase": "increasing_attention"}, {"score": 0.004500891637057374, "phrase": "concerned_issues"}, {"score": 0.004400804926266097, "phrase": "access_control"}, {"score": 0.004351595642056769, "phrase": "remote_financial_transaction"}, {"score": 0.004254814649568355, "phrase": "advanced_forgery"}, {"score": 0.004044822781630218, "phrase": "conventional_biometric_modalities"}, {"score": 0.00378080526397273, "phrase": "modality_transient"}, {"score": 0.00357395617690842, "phrase": "acoustic_response"}, {"score": 0.00345530020388352, "phrase": "click_stimulus"}, {"score": 0.0033974527047473044, "phrase": "conventional_modalities"}, {"score": 0.003247868216333148, "phrase": "teoae"}, {"score": 0.00305285084207725, "phrase": "physiological_outcome"}, {"score": 0.003018668521745676, "phrase": "human_auditory_system"}, {"score": 0.0028695095228791724, "phrase": "wavelet_analysis"}, {"score": 0.002805597755796506, "phrase": "time-frequency_representation"}, {"score": 0.0027123819773059127, "phrase": "individual_uniqueness"}, {"score": 0.0026820015810254004, "phrase": "long-term_reproducibility"}, {"score": 0.0026370661343466354, "phrase": "machine_learning_technique_linear_discriminant_analysis"}, {"score": 0.0025494354909453847, "phrase": "intrasubject_variability"}, {"score": 0.0024926348205500715, "phrase": "intersubject_differentiation_features"}, {"score": 0.002450864311898833, "phrase": "practical_application"}, {"score": 0.0023694065215394593, "phrase": "complete_framework"}, {"score": 0.0023296961971785357, "phrase": "biometric_system"}, {"score": 0.002264982416465872, "phrase": "identification_modes"}, {"score": 0.0022396019251440724, "phrase": "comparative_experiments"}, {"score": 0.0022020622730208514, "phrase": "teoae_data_set"}, {"score": 0.0021773853011112882, "phrase": "biometric_setting"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Robust biometric modality", " transient evoked otoacoustic emission", " time-frequency analysis", " linear discriminant analysis", " biometric fusion"], "paper_abstract": "Biometrics is attracting increasing attention in privacy and security concerned issues, such as access control and remote financial transaction. However, advanced forgery and spoofing techniques are threatening the reliability of conventional biometric modalities. This has been motivating our investigation of a novel yet promising modality transient evoked otoacoustic emission (TEOAE), which is an acoustic response generated from cochlea after a click stimulus. Unlike conventional modalities that are easily accessible or captured, TEOAE is naturally immune to replay and falsification attacks as a physiological outcome from human auditory system. In this paper, we resort to wavelet analysis to derive the time-frequency representation of such nonstationary signal, which reveals individual uniqueness and long-term reproducibility. A machine learning technique linear discriminant analysis is subsequently utilized to reduce intrasubject variability and further capture intersubject differentiation features. Considering practical application, we also introduce a complete framework of the biometric system in both verification and identification modes. Comparative experiments on a TEOAE data set of biometric setting show the merits of the proposed method. Performance is further improved with fusion of information from both ears.", "paper_title": "Earprint: Transient Evoked Otoacoustic Emission for Biometrics", "paper_id": "WOS:000353290200010"}