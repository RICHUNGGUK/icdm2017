{"auto_keywords": [{"score": 0.04547624598453918, "phrase": "visual_features"}, {"score": 0.013946562485163948, "phrase": "semantic_annotations"}, {"score": 0.00481495049065317, "phrase": "multimodal_fusion"}, {"score": 0.004624751696958501, "phrase": "histology_image_indexing_strategy"}, {"score": 0.0045324756541157574, "phrase": "multimodal_representations"}, {"score": 0.00418134346679498, "phrase": "data_modalities"}, {"score": 0.004125513927068713, "phrase": "complementary_information_sources"}, {"score": 0.004043158538239064, "phrase": "image_retrieval_system"}, {"score": 0.003909522412849035, "phrase": "explicit_semantic_information"}, {"score": 0.0038573081851680656, "phrase": "semantic_terms"}, {"score": 0.003704797078215222, "phrase": "visual_appearance"}, {"score": 0.003510754567808717, "phrase": "novel_strategy"}, {"score": 0.003417565253539315, "phrase": "fused_image_representation"}, {"score": 0.0033718991936259038, "phrase": "matrix_factorization_algorithms"}, {"score": 0.0033268412940032103, "phrase": "data_reconstruction_principles"}, {"score": 0.003195236629209403, "phrase": "multimodal_features"}, {"score": 0.0030278017562213265, "phrase": "multimodal_representation"}, {"score": 0.002830757050018908, "phrase": "new_images"}, {"score": 0.0026823700218343506, "phrase": "single_example_images"}, {"score": 0.0026111116934081284, "phrase": "experimental_evaluations"}, {"score": 0.0023603078194781965, "phrase": "histology_image_search"}, {"score": 0.0022365262201954643, "phrase": "popular_late_fusion_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Histology", " Digital pathology", " Image search", " Multimodal fusion", " Visual representation", " Semantic spaces"], "paper_abstract": "This work proposes a histology image indexing strategy based on multimodal representations obtained from the combination of visual features and associated semantic annotations. Both data modalities are complementary information sources for an image retrieval system, since visual features lack explicit semantic information and semantic terms do not usually describe the visual appearance of images. The paper proposes a novel strategy to build a fused image representation using matrix factorization algorithms and data reconstruction principles to generate a set of multimodal features. The methodology can seamlessly recover the multimodal representation of images without semantic annotations, allowing us to index new images using visual features only, and also accepting single example images as queries. Experimental evaluations on three different histology image data sets show that our strategy is a simple, yet effective approach to building multimodal representations for histology image search, and outperforms the response of the popular late fusion approach to combine information. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Histology image search using multimodal fusion", "paper_id": "WOS:000343362800014"}