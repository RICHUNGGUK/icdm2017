{"auto_keywords": [{"score": 0.03886698645129167, "phrase": "active_threads"}, {"score": 0.03314280676724776, "phrase": "hierarchical_register_file"}, {"score": 0.02730312360622678, "phrase": "register_file_hierarchy"}, {"score": 0.00481495049065317, "phrase": "hierarchical_thread_scheduler"}, {"score": 0.004723742646716804, "phrase": "energy-efficient_throughput_processors"}, {"score": 0.004687742829233727, "phrase": "modern_graphics_processing_units"}, {"score": 0.004581373625744533, "phrase": "large_number"}, {"score": 0.0045464538515249085, "phrase": "hardware_threads"}, {"score": 0.004477407179841716, "phrase": "function_unit"}, {"score": 0.004443276312972159, "phrase": "memory_access_latency"}, {"score": 0.004409404470207072, "phrase": "extreme_multithreading"}, {"score": 0.004359078118356132, "phrase": "complex_thread_scheduler"}, {"score": 0.004276468590041119, "phrase": "large_register_file"}, {"score": 0.003931118518507637, "phrase": "massively-threaded_processors"}, {"score": 0.0037834649508375544, "phrase": "two-level_thread_scheduler"}, {"score": 0.0037259623657693794, "phrase": "small_set"}, {"score": 0.0036274201504044685, "phrase": "local_memory_access_latency"}, {"score": 0.003585986761045987, "phrase": "larger_set"}, {"score": 0.0035179764329354877, "phrase": "main_memory_latency"}, {"score": 0.003308862957060602, "phrase": "scheduler's_energy_efficiency"}, {"score": 0.003208999546225013, "phrase": "monolithic_register_file"}, {"score": 0.0031723302551782324, "phrase": "modern_designs"}, {"score": 0.002599177223533834, "phrase": "data_movement"}, {"score": 0.0023798115577749225, "phrase": "upper_levels"}, {"score": 0.002272794656458419, "phrase": "real_world_graphics"}, {"score": 0.0022211005680689666, "phrase": "active_thread_count"}, {"score": 0.0021375377706211686, "phrase": "minimal_impact"}], "paper_keywords": ["Experimentation", " Measurement", " Energy efficiency", " multithreading", " register file organization", " throughput computing"], "paper_abstract": "Modern graphics processing units (GPUs) employ a large number of hardware threads to hide both function unit and memory access latency. Extreme multithreading requires a complex thread scheduler as well as a large register file, which is expensive to access both in terms of energy and latency. We present two complementary techniques for reducing energy on massively-threaded processors such as GPUs. First, we investigate a two-level thread scheduler that maintains a small set of active threads to hide ALU and local memory access latency and a larger set of pending threads to hide main memory latency. Reducing the number of threads that the scheduler must consider each cycle improves the scheduler's energy efficiency. Second, we propose replacing the monolithic register file found on modern designs with a hierarchical register file. We explore various trade-offs for the hierarchy including the number of levels in the hierarchy and the number of entries at each level. We consider both a hardware-managed caching scheme and a software-managed scheme, where the compiler is responsible for orchestrating all data movement within the register file hierarchy. Combined with a hierarchical register file, our two-level thread scheduler provides a further reduction in energy by only allocating entries in the upper levels of the register file hierarchy for active threads. Averaging across a variety of real world graphics and compute workloads, the active thread count can be reduced by a factor of 4 with minimal impact on performance and our most efficient three-level software-managed register file hierarchy reduces register file energy by 54%.", "paper_title": "A Hierarchical Thread Scheduler and Register File for Energy-Efficient Throughput Processors", "paper_id": "WOS:000303436700003"}