{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "primary_motor_cortex"}, {"score": 0.049750469707859776, "phrase": "audiovisual_speech_perception"}, {"score": 0.014338218928936665, "phrase": "speech_perception"}, {"score": 0.011642569864543257, "phrase": "left_tongue"}, {"score": 0.004749106104067268, "phrase": "recent_neurophysiological_studies"}, {"score": 0.0047003115977448905, "phrase": "cortical_brain_regions"}, {"score": 0.0045726187330434025, "phrase": "speech_gestures"}, {"score": 0.004494570360108983, "phrase": "processing_speech"}, {"score": 0.004253618550301311, "phrase": "motor_actions"}, {"score": 0.004195418010131832, "phrase": "speech_signal"}, {"score": 0.004123781267600542, "phrase": "auditory_and_visual_modalities"}, {"score": 0.004039423410198574, "phrase": "face-to-face_communication"}, {"score": 0.0039841418890102925, "phrase": "single-pulse_transcranial_magnetic_stimulation"}, {"score": 0.0038492126993451337, "phrase": "excitability_changes"}, {"score": 0.003809628721278519, "phrase": "left_tongue-related_primary_motor_cortex"}, {"score": 0.0037704502704526996, "phrase": "acoustic_and_visual_speech_inputs"}, {"score": 0.0037188360359702182, "phrase": "motor_excitability"}, {"score": 0.0036427316134070007, "phrase": "motor-evoked_potentials"}, {"score": 0.0036052633308076933, "phrase": "focal_tms"}, {"score": 0.0034951469511975346, "phrase": "participants'_tongue_muscles"}, {"score": 0.0034000828197314264, "phrase": "audiovisual_syllables"}, {"score": 0.003353521531649663, "phrase": "lip-related_phonemes"}, {"score": 0.0030554300179552415, "phrase": "lip_movements"}, {"score": 0.0029518598926717332, "phrase": "acoustic_tongue-related_phonemes"}, {"score": 0.0027837615811247963, "phrase": "consonantal_onset"}, {"score": 0.002755104031926742, "phrase": "acoustically_presented_syllable"}, {"score": 0.002680114113899346, "phrase": "visual_and_auditory_modalities"}, {"score": 0.0026252106881752067, "phrase": "tongue_primary_motor_cortex"}, {"score": 0.0025981810951165836, "phrase": "early_stage"}, {"score": 0.002424942315592064, "phrase": "sensory_channel"}, {"score": 0.0021864526544323163, "phrase": "human_speech_processing_system"}, {"score": 0.0021490449563443025, "phrase": "audiovisual_interaction"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Audiovisual speech perception", " Transcranial magnetic stimulation", " Motor system", " Mirror-neuron system", " Motor theory of speech perception", " McGurk effect"], "paper_abstract": "Recent neurophysiological studies show that cortical brain regions involved in the planning and execution of speech gestures are also activated in processing speech sounds. These findings suggest that speech perception is in part mediated by reference to the motor actions afforded in the speech signal. Since interactions between auditory and visual modalities are beneficial in speech perception and face-to-face communication, we used single-pulse transcranial magnetic stimulation (TMS) to investigate whether audiovisual speech perception might induce excitability changes in the left tongue-related primary motor cortex and whether acoustic and visual speech inputs might differentially modulate motor excitability. To this aim, motor-evoked potentials obtained with focal TMS applied over the left tongue primary motor cortex were recorded from participants' tongue muscles during the perception of matching and conflicting audiovisual syllables incorporating tongue- and/or lip-related phonemes (i.e. visual and acoustic /ba/, /ga/ and /da/, visual /ba/ and acoustic /ga/, visual /ga/ and acoustic /ba/). Compared to the presentation of congruent /ba/ syllable, which primarily involves lip movements when pronounced, exposure to syllables incorporating visual and/or acoustic tongue-related phonemes induced a greater excitability of the left tongue primary motor cortex as early as 100-200 ms after the consonantal onset of the acoustically presented syllable. These results provide evidence that both visual and auditory modalities specifically modulate activity in the tongue primary motor cortex at an early stage during audiovisual speech perception. Because no interaction between the two modalities was observed, these results suggest that information from each sensory channel is recoded separately in the primary motor cortex at that point of time. These findings are discussed in relation to theories assuming a link between perception and action in the human speech processing system and theoretical models of audiovisual interaction. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "On the tip of the tongue: Modulation of the primary motor cortex during audiovisual speech perception", "paper_id": "WOS:000278282000007"}