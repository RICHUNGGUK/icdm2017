{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "core_working_sets"}, {"score": 0.0046781613377273774, "phrase": "random_sampling"}, {"score": 0.004523455475492876, "phrase": "working_sets"}, {"score": 0.004437349839203418, "phrase": "denning"}, {"score": 0.00433200902751133, "phrase": "distinct_addresses"}, {"score": 0.004050116768809519, "phrase": "dramatic_differences"}, {"score": 0.0039729853486821995, "phrase": "usage_patterns"}, {"score": 0.003934970057482768, "phrase": "frequently_used_data"}, {"score": 0.0038973170902076707, "phrase": "transient_data"}, {"score": 0.0037683358267785435, "phrase": "denning's_definition"}, {"score": 0.0034725269588525534, "phrase": "longest_time"}, {"score": 0.003293570937654716, "phrase": "dual-cache_structures"}, {"score": 0.003246380517062771, "phrase": "special_treatment"}, {"score": 0.0030790429005600898, "phrase": "probabilistic_locality_predictor"}, {"score": 0.0029914213495838998, "phrase": "skewed_popularity"}, {"score": 0.0029203055813347874, "phrase": "transient_cache_insertions"}, {"score": 0.0025398521156505425, "phrase": "prohibitive_cost"}, {"score": 0.0024556852466581527, "phrase": "content_addressable_memory_design"}, {"score": 0.0023857603808363527, "phrase": "costly_lookups"}, {"score": 0.0023515464194592195, "phrase": "small_auxiliary_lookup_table"}, {"score": 0.0023178219772486868, "phrase": "proposed_design"}], "paper_keywords": ["Core working sets", " random insertion policy", " mass-count disparity", " L1 cache", " cache insertion policy", " dual-cache design", " cache filtering"], "paper_abstract": "Locality is often characterized by working sets, defined by Denning as the set of distinct addresses referenced within a certain window of time. This definition ignores the fact that dramatic differences exist between the usage patterns of frequently used data and transient data. We therefore propose to extend Denning's definition with that of core working sets, which identify blocks that are used most frequently and for the longest time. The concept of a core motivates the design of dual-cache structures that provide special treatment for the core. In particular, we present a probabilistic locality predictor for L1 caches that leverages the skewed popularity of blocks to distinguish transient cache insertions from more persistent ones. We further present a dual L1 design that inserts only frequently used blocks into a low-latency, low-power, direct-mapped main cache, while serving others from a small fully associative filter. To reduce the prohibitive cost of such a filter, we present a content addressable memory design that eliminates most of the costly lookups using a small auxiliary lookup table. The proposed design enables a 16K direct-mapped L1 cache, augmented with a small 2K filter, to outperform a 32K 4-way cache, while at the same time consumes 70-80 percent less dynamic power and 40 percent less static power.", "paper_title": "Exploiting Core Working Sets to Filter the L1 Cache with Random Sampling", "paper_id": "WOS:000309113200002"}