{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "hand_gestures"}, {"score": 0.004741845603430361, "phrase": "mobile_spoken_dialogue_systems"}, {"score": 0.004529093447865156, "phrase": "everyday_human-to-human_interaction"}, {"score": 0.0044150318724093226, "phrase": "diverse_spoken_dialogue_applications"}, {"score": 0.004260134699483774, "phrase": "consumer_electronics"}, {"score": 0.004152818376630929, "phrase": "new_interaction_paradigms"}, {"score": 0.003788296551609616, "phrase": "spoken_dialogue_systems"}, {"score": 0.003749869279784845, "phrase": "sds"}, {"score": 0.0036553070575015344, "phrase": "situation-induced_disabilities"}, {"score": 0.003563172322934695, "phrase": "determinant_factors"}, {"score": 0.003351381374975648, "phrase": "six_concise_and_intuitively_meaningful_gestures"}, {"score": 0.0031360809992645074, "phrase": "sds."}, {"score": 0.0031042018721479385, "phrase": "different_machine"}, {"score": 0.003025915966640355, "phrase": "classification_error"}, {"score": 0.0029798924689472014, "phrase": "gesture_patterns"}, {"score": 0.002860546817196148, "phrase": "proposed_set"}, {"score": 0.002676692093594358, "phrase": "social_acceptability"}, {"score": 0.0026359661683151006, "phrase": "specific_interaction_scheme"}, {"score": 0.0026091594819333654, "phrase": "high_levels"}, {"score": 0.002556359086441866, "phrase": "public_use"}, {"score": 0.002126635713519053, "phrase": "male_subject"}, {"score": 0.0021049977753042253, "phrase": "spastic_cerebral_palsy"}], "paper_keywords": ["Gestured-controlled mobile applications", " Gesture and speech interfaces", " Gesture classification", " Mobile accessibility"], "paper_abstract": "Speech and hand gestures offer the most natural modalities for everyday human-to-human interaction. The availability of diverse spoken dialogue applications and the proliferation of accelerometers on consumer electronics allow the introduction of new interaction paradigms based on speech and gestures. Little attention has been paid, however, to the manipulation of spoken dialogue systems (SDS) through gestures. Situation-induced disabilities or real disabilities are determinant factors that motivate this type of interaction. In this paper, six concise and intuitively meaningful gestures are proposed that can be used to trigger the commands in any SDS. Using different machine learning techniques, a classification error for the gesture patterns of less than 5 % is achieved, and the proposed set of gestures is compared to ones proposed by users. Examining the social acceptability of the specific interaction scheme, high levels of acceptance for public use are encountered. An experiment was conducted comparing a button-enabled and a gesture-enabled interface, which showed that the latter imposes little additional mental and physical effort. Finally, results are provided after recruiting a male subject with spastic cerebral palsy, a blind female user, and an elderly female person.", "paper_title": "Using hand gestures to control mobile spoken dialogue systems", "paper_id": "WOS:000339891000002"}