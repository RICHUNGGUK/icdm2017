{"auto_keywords": [{"score": 0.0433312844265797, "phrase": "word_repetition"}, {"score": 0.02581590435353387, "phrase": "speaker_information"}, {"score": 0.00481495049065317, "phrase": "words_benefits"}, {"score": 0.004792273556106929, "phrase": "subsequent_auditory_recognition"}, {"score": 0.0044435677598780796, "phrase": "subsequent_phonological_processing"}, {"score": 0.004401794742140806, "phrase": "visual_speech"}, {"score": 0.004258644418211771, "phrase": "speaker_repetition"}, {"score": 0.004043003243656031, "phrase": "long-term_cross-modal_repetition"}, {"score": 0.0038930368103015467, "phrase": "underlying_lexical_representations"}, {"score": 0.003626626504149897, "phrase": "auditory-only_words"}, {"score": 0.0035587046945919788, "phrase": "visual-only_words"}, {"score": 0.0033150974333333244, "phrase": "exposure_speaker"}, {"score": 0.00326840809777013, "phrase": "novel_speaker"}, {"score": 0.0031920445513574907, "phrase": "significant_effect"}, {"score": 0.0030017207229983385, "phrase": "speaker_changes"}, {"score": 0.002917736974519881, "phrase": "explicit_recognition_task"}, {"score": 0.0028630535573013686, "phrase": "listeners'_lipreading_performance"}, {"score": 0.0027961342030212353, "phrase": "prior_exposure"}, {"score": 0.002769805263310232, "phrase": "auditory_words"}, {"score": 0.0027437235598539904, "phrase": "explicit_recognition_memory"}, {"score": 0.0025436978068459565, "phrase": "cross-modal_repetition"}, {"score": 0.00247249708860822, "phrase": "explicit_memory"}, {"score": 0.0023694065215394593, "phrase": "phonological_representations"}, {"score": 0.002292199117499287, "phrase": "auditory_and_visual_processing"}, {"score": 0.0021656385587456952, "phrase": "lexical_level"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Speech perception", " Audiovisual speech", " Word repetition priming", " Cross-modal priming"], "paper_abstract": "Watching a speaker say words benefits subsequent auditory recognition of the same words. In this study, we tested whether hearing words also facilitates subsequent phonological processing from visual speech, and if so, whether speaker repetition influences the magnitude of this word repetition priming. We used long-term cross-modal repetition priming as a means to investigate the underlying lexical representations involved in listening to and seeing speech. In Experiment 1, listeners identified auditory-only words during exposure and visual-only words at test. Words at test were repeated or new and produced by the exposure speaker or a novel speaker. Results showed a significant effect of cross-modal word repetition priming but this was unaffected by speaker changes. Experiment 2 added an explicit recognition task at test. Listeners' lipreading performance was again improved by prior exposure to auditory words. Explicit recognition memory was poor, and neither word repetition nor speaker repetition improved it. This suggests that cross-modal repetition priming is neither mediated by explicit memory nor improved by speaker information. Our results suggest that phonological representations in the lexicon are shared across auditory and visual processing, and that speaker information is not transferred across modalities at the lexical level. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Hearing words helps seeing words: A cross-modal word repetition effect", "paper_id": "WOS:000333496300004"}