{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "automatic_usability_evaluation_method"}, {"score": 0.004628101576367193, "phrase": "software_application"}, {"score": 0.004254671386496732, "phrase": "crucial_aspect"}, {"score": 0.004212759658511567, "phrase": "software_engineering"}, {"score": 0.004089475312474684, "phrase": "automatic_tools"}, {"score": 0.0040491842732233154, "phrase": "graphical_user_interface_evaluation"}, {"score": 0.003911253966141701, "phrase": "traditional_activities"}, {"score": 0.003853583126988071, "phrase": "expert_evaluation"}, {"score": 0.003815607281455725, "phrase": "user_testing"}, {"score": 0.0037039021744127783, "phrase": "success_probability"}, {"score": 0.003577691211998842, "phrase": "automatic_methods"}, {"score": 0.00308357048262018, "phrase": "usability_evaluation_method"}, {"score": 0.003023047748772801, "phrase": "consistency_aspects"}, {"score": 0.0026973310437053573, "phrase": "comparative_experimental_study"}, {"score": 0.002618278365749875, "phrase": "stand-alone_interactive_application"}, {"score": 0.0024793019587009035, "phrase": "human-based_usability_evaluation"}, {"score": 0.0023710856920150574, "phrase": "statistical_correlation"}, {"score": 0.002336071138145897, "phrase": "tool's_rating"}, {"score": 0.0023130151703068444, "phrase": "humans'_average_ratings"}, {"score": 0.0022675820982741347, "phrase": "proposed_methodology"}, {"score": 0.0022120408738490437, "phrase": "useful_complement"}, {"score": 0.0021902063413831545, "phrase": "standard_techniques"}, {"score": 0.002168586864007222, "phrase": "usability_evaluation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Interactive systems evaluation", " Usability engineering", " Summative usability evaluation"], "paper_abstract": "Today, the success of a software application strongly depends on the usability of its interface, so the evaluation of interfaces has become a crucial aspect of software engineering. It is recognized that automatic tools for graphical user interface evaluation may greatly reduce the costs of traditional activities performed during expert evaluation or user testing in order to estimate the success probability of an application. However, automatic methods need to be empirically validated in order to prove their effectiveness with respect to the attributes they are supposed to evaluate. In this work, we empirically validate a usability evaluation method conceived to assess consistency aspects of a GUI with no need to analyze the back-end. We demonstrate the validity of the approach by means of a comparative experimental study, where four web sites and a stand-alone interactive application are analyzed and the results compared to those of a human-based usability evaluation. The analysis of the results and the statistical correlation between the tool's rating and humans' average ratings show that the proposed methodology can indeed be a useful complement to standard techniques of usability evaluation. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Empirical validation of an automatic usability evaluation method", "paper_id": "WOS:000353312200001"}