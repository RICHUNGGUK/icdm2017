{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "high-dimensional_probabilistic_models"}, {"score": 0.003950453462399077, "phrase": "coding_theories"}, {"score": 0.0032786537599187125, "phrase": "expected_values"}, {"score": 0.003129317057177867, "phrase": "underlying_probability_distributions"}, {"score": 0.0030572112793962004, "phrase": "direct_computations"}, {"score": 0.00278497898719426, "phrase": "high_numerical_precision"}, {"score": 0.0025967927629150715, "phrase": "numerical_trick"}, {"score": 0.0023654615987859402, "phrase": "numerical_precision"}, {"score": 0.002231441081806766, "phrase": "simple_alternative"}, {"score": 0.0021799789348982534, "phrase": "indirect_methods"}, {"score": 0.0021049977753042253, "phrase": "stochastic_sampling"}], "paper_keywords": [""], "paper_abstract": "Sensory stimuli are generally encoded by the activity of thousands of neurons in parallel. Coding theories dealing with such high-dimensional representations face hard numerical problems. One of them is the computation of expected values according to the underlying probability distributions. Direct computations are generally avoided also because of the high numerical precision required. Here, a numerical trick is described that overcomes the problem of numerical precision, thereby providing a simple alternative to indirect methods based on stochastic sampling (Monte-Carlo methods).", "paper_title": "A Trick for Computing Expected Values in High-Dimensional Probabilistic Models", "paper_id": "WOS:000297757300006"}