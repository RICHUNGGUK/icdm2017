{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "gray_and_pseudo-color_images"}, {"score": 0.004644451060812007, "phrase": "biological_tissues"}, {"score": 0.004602773636967002, "phrase": "single_image"}, {"score": 0.0044934449515131, "phrase": "medical_practice"}, {"score": 0.004439753960631346, "phrase": "fused_results"}, {"score": 0.004347327095048136, "phrase": "blurred_details"}, {"score": 0.004308304400698582, "phrase": "color_and_artifact_contours"}, {"score": 0.004093673695008595, "phrase": "color_perception"}, {"score": 0.0040569185796103845, "phrase": "color_appearance_model"}, {"score": 0.004032597946578543, "phrase": "international_commission"}, {"score": 0.0038780151896468194, "phrase": "rainbow_palette"}, {"score": 0.003820144626025562, "phrase": "color_attributes"}, {"score": 0.0036958398682001015, "phrase": "pseudo-color_image"}, {"score": 0.003586336325832857, "phrase": "fusion_process"}, {"score": 0.0035010659378711816, "phrase": "gray_image"}, {"score": 0.0034281134042005654, "phrase": "predicted_hue"}, {"score": 0.003387108469185429, "phrase": "pseudocolor_image"}, {"score": 0.0033365390352128065, "phrase": "predicted_lightness"}, {"score": 0.0032085525502105836, "phrase": "achromatic_and_chromatic_properties"}, {"score": 0.0031797191359738356, "phrase": "resulting_image"}, {"score": 0.003141675970409644, "phrase": "different_color_spaces"}, {"score": 0.0031229354453258863, "phrase": "css"}, {"score": 0.0030947594580569854, "phrase": "color_appearance_models"}, {"score": 0.0030393807371663934, "phrase": "color_aggregations"}, {"score": 0.0030030115662983956, "phrase": "fused_images"}, {"score": 0.0028106004823927723, "phrase": "simulated_lesion"}, {"score": 0.002793730385549585, "phrase": "breast_phantom"}, {"score": 0.0026384167183586015, "phrase": "quantitative_experiment"}, {"score": 0.0026068329296254087, "phrase": "simulated_ultrasound_and_strain_images"}, {"score": 0.002583392808974657, "phrase": "visual_information_fidelity"}, {"score": 0.0024178026341680693, "phrase": "proposed_method"}, {"score": 0.0023960581528720934, "phrase": "traditional_ones"}, {"score": 0.0023816703250113883, "phrase": "css-based_methods"}, {"score": 0.0023460767171603054, "phrase": "alternating_display_technique"}, {"score": 0.00233198831578686, "phrase": "frequency_encoding_methods"}, {"score": 0.00223570488212345, "phrase": "medical_applications"}, {"score": 0.0021433882705962034, "phrase": "simulated_mri_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Biomedical image fusion", " Rainbow palette", " Color appearance model (CAM)", " CIECAM02", " Ultrasound", " Magnetic resonance imaging (MRI)"], "paper_abstract": "Fusion of gray and pseudo-color images presents more information of biological tissues in a single image and facilitates the interpretation of multimodalities in medical practice. However, fused results are hampered by the problems of blurred details, faded color and artifact contours. This paper reports a method to solve the problems by precisely predicting the attributes of color perception using the color appearance model of International Commission on Illumination published in 2002 (CIECAM02). First, a rainbow palette is generated from the color attributes. It is uniform in lightness, and thus the valuable information of pseudo-color image can be totally sealed in its chromatic properties. Then the fusion process is carried out with the adjustment of gray image in lightness. Here, the predicted hue and saturation of pseudocolor image is merged with the predicted lightness of gray one. Therefore, information of two original images exists separately in achromatic and chromatic properties of the resulting image. Based on different color spaces (CSs) and color appearance models (CAMs), the color aggregations available for displaying fused images are presented and compared. The aggregation based on the CIECAM02 exhibited more uniform variation in lightness and hue. Fused results of simulated lesion and breast phantom manifested the compromise between the scope of gray and the perception of color. Furthermore, in the quantitative experiment on 49 sets of simulated ultrasound and strain images, the visual information fidelity (VIF) was applied to assess the similarity between the result and its sources. It revealed the superiority of the proposed method over the traditional ones including CSs-based methods, transparency technique, alternating display technique, frequency encoding methods, and maximum-selection-rule based rules. The results of two clinical cases demonstrated its practicality in medical applications. Besides, its feasibility in fusing two high-resolution structural images was preliminarily approved based on the simulated MRI data. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Color-appearance-model based fusion of gray and pseudo-color images for medical applications", "paper_id": "WOS:000334133100012"}