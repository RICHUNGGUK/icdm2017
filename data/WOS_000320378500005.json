{"auto_keywords": [{"score": 0.049146612112995945, "phrase": "normal_regression_models"}, {"score": 0.00481495049065317, "phrase": "intrinsic_variable_selection"}, {"score": 0.004073359218158693, "phrase": "variable_selection_problem"}, {"score": 0.003877737556673229, "phrase": "expected-posterior_prior_methodology"}, {"score": 0.0036914757355166966, "phrase": "straightforward_mcmc_scheme"}, {"score": 0.003479692058963528, "phrase": "posterior_distribution"}, {"score": 0.003312486229143855, "phrase": "monte_carlo"}, {"score": 0.003091767402370757, "phrase": "marginal_likelihood"}, {"score": 0.0030314419455512013, "phrase": "posterior_model_probabilities"}, {"score": 0.0028857130140890787, "phrase": "large_spaces"}, {"score": 0.0025638362414466278, "phrase": "proposed_methodology"}, {"score": 0.002323142666222693, "phrase": "relevant_literature"}, {"score": 0.0022777800735119405, "phrase": "objective_variable_selection"}, {"score": 0.0021049977753042253, "phrase": "different_training_samples"}], "paper_keywords": ["Bayesian variable selection", " Expected-posterior priors", " Imaginary data", " Intrinsic priors", " Jeffreys prior", " Objective model selection methods", " Normal regression models"], "paper_abstract": "In this paper, we focus on the variable selection problem in normal regression models using the expected-posterior prior methodology. We provide a straightforward MCMC scheme for the derivation of the posterior distribution, as well as Monte Carlo estimates for the computation of the marginal likelihood and posterior model probabilities. Additionally, for large spaces, a model search algorithm based on is constructed. The proposed methodology is applied in two real life examples, already used in the relevant literature of objective variable selection. In both examples, uncertainty over different training samples is taken into consideration.", "paper_title": "Computation for intrinsic variable selection in normal regression models via expected-posterior prior", "paper_id": "WOS:000320378500005"}