{"auto_keywords": [{"score": 0.03599292157590238, "phrase": "lda"}, {"score": 0.01733927335299669, "phrase": "hybrid_model"}, {"score": 0.00926991097344267, "phrase": "strother"}, {"score": 0.005851153329842714, "phrase": "gnb"}, {"score": 0.00481495049065317, "phrase": "fmri_data_classification"}, {"score": 0.004746558955503364, "phrase": "linear_predictive_models"}, {"score": 0.004579780586951551, "phrase": "experimental_task_states"}, {"score": 0.0044346739635814135, "phrase": "statistical_parametric_maps"}, {"score": 0.004294145092032327, "phrase": "high_spatial_reproducibility"}, {"score": 0.0038986150699604504, "phrase": "interpretable_spms"}, {"score": 0.0037480753312398754, "phrase": "flexible_hybrid_model"}, {"score": 0.0036422425344358037, "phrase": "prediction_power"}, {"score": 0.0035141291835319682, "phrase": "weighted_summation"}, {"score": 0.00347657813672945, "phrase": "optimization_functions"}, {"score": 0.0034394269654205094, "phrase": "linear_discriminate_analysis"}, {"score": 0.0033303306367699816, "phrase": "afshin-pour"}, {"score": 0.0032016639006812826, "phrase": "model's_ability"}, {"score": 0.0031561148083611647, "phrase": "fmri_scans"}, {"score": 0.0031335830806256777, "phrase": "multiple_brain_states"}, {"score": 0.003111212015024308, "phrase": "gcca"}, {"score": 0.0030779528295407925, "phrase": "linear_combination"}, {"score": 0.0030450484042676023, "phrase": "subject's_scans"}, {"score": 0.0030017207229983385, "phrase": "estimated_boundary_map"}, {"score": 0.002896071795090179, "phrase": "split-half_resampling_framework"}, {"score": 0.002676514445417281, "phrase": "gaussian_naive"}, {"score": 0.002610198789888055, "phrase": "simulated_fmri_data"}, {"score": 0.0024122616475793206, "phrase": "real_fmri_data"}, {"score": 0.0022133711375320244, "phrase": "large_increases"}, {"score": 0.002181851408180827, "phrase": "small_reductions"}, {"score": 0.0021049977753042253, "phrase": "ideal_performance_point"}], "paper_keywords": ["Classification", " functional magnetic resonance imaging (fMRI)", " generalized canonical correlation analysis", " linear discriminate analysis", " multivariate analysis", " visualization"], "paper_abstract": "Linear predictive models are applied to functional MRI (fMRI) data to estimate boundaries that predict experimental task states for scans. These boundaries are visualized as statistical parametric maps (SPMs) and range from low to high spatial reproducibility across subjects (e.g., Strother et al., 2004; LaConte et al., 2003). Such inter-subject pattern reproducibility is an essential characteristic of interpretable SPMs that generalize across subjects. Therefore, we introduce a flexible hybrid model that optimizes reproducibility by simultaneously enhancing the prediction power and reproducibility. This hybrid model is formed by a weighted summation of the optimization functions of a linear discriminate analysis (LDA) model and a generalized canonical correlation (gCCA) model (Afshin-Pour et al., 2012). LDA preserves the model's ability to discriminate the fMRI scans of multiple brain states while gCCA finds a linear combination for each subject's scans such that the estimated boundary map is reproducible. The hybrid model is implemented in a split-half resampling framework (Strother et al., 2010) which provides reproducibility (r) and prediction (p) quality metrics. Then the model was compared with LDA, and Gaussian Naive Bayes (GNB). For simulated fMRI data, the hybrid model outperforms the other two techniques in terms of receiver operating characteristic (ROC) curves, particularly for detecting less predictable but spatially reproducible networks. These techniques were applied to real fMRI data to estimate the maps for two task contrasts. Our results indicate that compared to LDA and GNB, the hybrid model can provide maps with large increases in reproducibility for small reductions in prediction, which are jointly closer to the ideal performance point of (p=1, r=1).", "paper_title": "A Hybrid LDA plus gCCA Model for fMRI Data Classification and Visualization", "paper_id": "WOS:000353899600003"}