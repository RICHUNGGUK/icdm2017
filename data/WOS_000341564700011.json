{"auto_keywords": [{"score": 0.04858132305104682, "phrase": "smo-based_training_accelerator"}, {"score": 0.024039117451172657, "phrase": "proposed_architecture"}, {"score": 0.00481495049065317, "phrase": "rec-sta"}, {"score": 0.004714023408114857, "phrase": "efficient_chip_design"}, {"score": 0.004518455021159186, "phrase": "smo"}, {"score": 0.004447201233380302, "phrase": "karush-kuhn-tucker_condition"}, {"score": 0.0043080553835735825, "phrase": "learning_problems"}, {"score": 0.004262643556463569, "phrase": "support_vector_machines"}, {"score": 0.004151188559520802, "phrase": "hardware_implementation"}, {"score": 0.004085713541752114, "phrase": "smo_algorithm"}, {"score": 0.004021267064832957, "phrase": "chip_performance"}, {"score": 0.003978866233891427, "phrase": "excessively_increasing_chip_area"}, {"score": 0.0038953958723049287, "phrase": "crucial_issue"}, {"score": 0.0036942726653704213, "phrase": "novel_reconfigurable_and_efficient_chip_design"}, {"score": 0.0034482025128821548, "phrase": "proposed_rec-sta"}, {"score": 0.0034118234596993836, "phrase": "trimode_coarse-grained_reconfigurable_architecture"}, {"score": 0.003375827412956124, "phrase": "tcra"}, {"score": 0.003322540556404882, "phrase": "triple_finite-state-machine"}, {"score": 0.0032355864829403413, "phrase": "first_method"}, {"score": 0.0031845067058084583, "phrase": "baseline_smo_design"}, {"score": 0.0031342307827666675, "phrase": "trimode_reconfigurable_architectures"}, {"score": 0.003101153870424188, "phrase": "parallel_and_pipeline_computing_capabilities"}, {"score": 0.0029565620771207003, "phrase": "efficient_reconfiguration"}, {"score": 0.0029098743621130004, "phrase": "tcra._use"}, {"score": 0.002818692837561076, "phrase": "kernel_cache_design"}, {"score": 0.0027741761880779535, "phrase": "chip_manufacturing"}, {"score": 0.002429451930463481, "phrase": "power_consumption"}, {"score": 0.0023408288327263316, "phrase": "baseline_design"}, {"score": 0.0023038418282549274, "phrase": "fpga_simulation_results"}, {"score": 0.0021387992835532367, "phrase": "training_performance"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": ["Reconfigurable computing", " sequential minimal optimization (SMO)", " speaker recognition", " support vector machine (SVM)", " trimode coarse-grained reconfigurable architecture (TCRA)", " triple finite-state-machine with dynamic scheduling (TFDS)", " VLSI"], "paper_abstract": "Sequential minimal optimization (SMO) and Karush-Kuhn-Tucker condition are often used to solve learning problems in support vector machines. However, during hardware implementation of the SMO algorithm, enhancing chip performance without excessively increasing chip area is often a crucial issue. The solution proposed in this paper is a novel reconfigurable and efficient chip design with SMO-based training accelerator (REC-STA). Two novel methods used in the proposed REC-STA are trimode coarse-grained reconfigurable architecture (TCRA) and triple finite-state-machine with dynamic scheduling The first method modifies the baseline SMO design by developing trimode reconfigurable architectures with parallel and pipeline computing capabilities. The second method provides a schedule for efficient reconfiguration of the TCRA. Use of these methods can remove kernel cache design. For chip manufacturing, the implementation of the REC-STA is synthesized, placed, and routed using the TSMC 0.18-mu m technology library. The core size is 2.94 mm x 2.94 mm and the power consumption is 77.3 mW. Compared with the baseline design, the FPGA simulation results show that the proposed architecture requires 50% less memory and 31% fewer gate counts but provides a 16-fold improvement in training performance. The experimental results confirm the efficacy of the proposed architecture and methods.", "paper_title": "REC-STA: Reconfigurable and Efficient Chip Design With SMO-Based Training Accelerator", "paper_id": "WOS:000341564700011"}