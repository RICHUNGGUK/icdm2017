{"auto_keywords": [{"score": 0.03970543330650032, "phrase": "multiple_users"}, {"score": 0.015719716506582538, "phrase": "semantics-aware_photo_cropping"}, {"score": 0.01300485584269887, "phrase": "semantically_important_regions"}, {"score": 0.009925450478084947, "phrase": "training_photos"}, {"score": 0.004718897469501381, "phrase": "widely_used_tool"}, {"score": 0.004687305496643216, "phrase": "printing_industry"}, {"score": 0.004578382275810468, "phrase": "conventional_cropping_models"}, {"score": 0.004397487039229447, "phrase": "semantic_contents"}, {"score": 0.004280861452668641, "phrase": "low-level_features"}, {"score": 0.004125513927068713, "phrase": "sequential_ordering"}, {"score": 0.004084129504819342, "phrase": "existing_models"}, {"score": 0.0036430378180975667, "phrase": "photo_assessment"}, {"score": 0.0036186222999811802, "phrase": "quite_a_subjective_task"}, {"score": 0.003238517900104576, "phrase": "local_features"}, {"score": 0.0031419449938286663, "phrase": "semantic_space"}, {"score": 0.003058515297281172, "phrase": "category_information"}, {"score": 0.0029973957125353306, "phrase": "efficient_learning_algorithm"}, {"score": 0.002927626967420519, "phrase": "semantically_representative_graphlets"}, {"score": 0.0028594775336675897, "phrase": "selecting_process"}, {"score": 0.002646501671714952, "phrase": "prior_distribution"}, {"score": 0.002507748938616919, "phrase": "learned_priors"}, {"score": 0.002482552408222559, "phrase": "corresponding_active_graphlet_path"}, {"score": 0.0024576084154573396, "phrase": "test_photo"}, {"score": 0.0023682672729645714, "phrase": "experimental_results"}, {"score": 0.0023131084326717755, "phrase": "active_graphlet_path"}, {"score": 0.002214048743052355, "phrase": "photo_aesthetics"}, {"score": 0.002199189123395672, "phrase": "conventional_saliency_maps"}, {"score": 0.0021624739899833868, "phrase": "cropped_photos"}, {"score": 0.0021049977753042253, "phrase": "qualitative_and_quantitative_comparisons"}], "paper_keywords": ["Photo cropping", " semantics", " active graphlet path", " aesthetics"], "paper_abstract": "Photo cropping is a widely used tool in printing industry, photography, and cinematography. Conventional cropping models suffer from the following three challenges. First, the deemphasized role of semantic contents that are many times more important than low-level features in photo aesthetics. Second, the absence of a sequential ordering in the existing models. In contrast, humans look at semantically important regions sequentially when viewing a photo. Third, the difficulty of leveraging inputs from multiple users. Experience from multiple users is particularly critical in cropping as photo assessment is quite a subjective task. To address these challenges, this paper proposes semantics-aware photo cropping, which crops a photo by simulating the process of humans sequentially perceiving semantically important regions of a photo. We first project the local features (graphlets in this paper) onto the semantic space, which is constructed based on the category information of the training photos. An efficient learning algorithm is then derived to sequentially select semantically representative graphlets of a photo, and the selecting process can be interpreted by a path, which simulates humans actively perceiving semantics in a photo. Furthermore, we learn a prior distribution of such active graphlet paths from training photos that are marked as aesthetically pleasing by multiple users. The learned priors enforce the corresponding active graphlet path of a test photo to be maximally similar to those from the training photos. Experimental results show that: 1) the active graphlet path accurately predicts human gaze shifting, and thus is more indicative for photo aesthetics than conventional saliency maps and 2) the cropped photos produced by our approach outperform its competitors in both qualitative and quantitative comparisons.", "paper_title": "Actively Learning Human Gaze Shifting Paths for Semantics-Aware Photo Cropping", "paper_id": "WOS:000334677900003"}