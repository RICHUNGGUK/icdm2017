{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "spatial_and_non-spatial_data"}, {"score": 0.04759132288543124, "phrase": "face_detection"}, {"score": 0.04318562459045211, "phrase": "robust_skin_segmentation"}, {"score": 0.041025976343579976, "phrase": "local_skin_information"}, {"score": 0.040606626433812944, "phrase": "detected_faces"}, {"score": 0.004468684611798047, "phrase": "body_parts"}, {"score": 0.004421284843189731, "phrase": "hand_gesture_analysis"}, {"score": 0.0042820680211904235, "phrase": "objectionable_content"}, {"score": 0.004169394481182493, "phrase": "systematic_approach"}, {"score": 0.004081385289516914, "phrase": "graph_cuts"}, {"score": 0.004016594765266821, "phrase": "skin_segmentation_process"}, {"score": 0.003727527379253624, "phrase": "foreground_seeds"}, {"score": 0.0036488111139918135, "phrase": "foreground_weights"}, {"score": 0.0033680968918579717, "phrase": "universal_seed"}, {"score": 0.0032272929113113203, "phrase": "decision_tree"}, {"score": 0.0030923570058383355, "phrase": "universal_seed_weights"}, {"score": 0.00304321897427383, "phrase": "local_information"}, {"score": 0.002794001681064862, "phrase": "off-line_trained_classifiers"}, {"score": 0.0026914710445743693, "phrase": "generic_skin_detection_system"}, {"score": 0.0026486862281576086, "phrase": "positive_training_data"}, {"score": 0.002497531381123025, "phrase": "contextual_information_present"}, {"score": 0.002405853977978678, "phrase": "weight_augmentation"}, {"score": 0.002220551141101661, "phrase": "annotated_pixel-level_ground_truth"}, {"score": 0.0021735890994119757, "phrase": "systematic_skin_segmentation_approach"}, {"score": 0.0021049977753042253, "phrase": "robust_skin_detection"}], "paper_keywords": ["Skin detection", " Skin segmentation", " Classification", " Graph cuts for skin detection", " Neighborhood relationship", " Systematic skin detection approach", " Classifiers integration"], "paper_abstract": "Skin detection is used in applications ranging from face detection, tracking of body parts, hand gesture analysis, to retrieval and blocking objectionable content. We present a systematic approach for robust skin segmentation using graph cuts. The skin segmentation process starts by exploiting the local skin information of detected faces. The detected faces are used as foreground seeds for calculating the foreground weights of the graph. If local skin information is not available, we opt for the universal seed. To increase the robustness, the decision tree based classifier is used to augment the universal seed weights when no local information is available in the image. With this setup, we achieve robust skin segmentation, outperforming off-line trained classifiers. The setup also provides a generic skin detection system, using positive training data only. With face detection, we take advantage of the contextual information present in the scene. With the weight augmentation, we provide a setup for merging spatial and non-spatial data. Experiments on two datasets with annotated pixel-level ground truth show that the systematic skin segmentation approach outperforms other approaches and provides robust skin detection.", "paper_title": "Systematic skin segmentation: merging spatial and non-spatial data", "paper_id": "WOS:000333209300008"}