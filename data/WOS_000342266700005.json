{"auto_keywords": [{"score": 0.049483572884790016, "phrase": "monocular_camera"}, {"score": 0.00481495049065317, "phrase": "low-cost_quadrocopter"}, {"score": 0.004656871909510407, "phrase": "complete_solution"}, {"score": 0.004598933498016774, "phrase": "visual_navigation"}, {"score": 0.004283913685201902, "phrase": "main_sensor"}, {"score": 0.004160531596936783, "phrase": "external_tracking_aids"}, {"score": 0.004109029267306102, "phrase": "gps"}, {"score": 0.004074574278425223, "phrase": "visual_markers"}, {"score": 0.004040688646993605, "phrase": "costly_computations"}, {"score": 0.003940706575253453, "phrase": "external_laptop"}, {"score": 0.003875424718379985, "phrase": "wireless_lan"}, {"score": 0.0036099019581975963, "phrase": "kalman"}, {"score": 0.0035648266669315943, "phrase": "data_fusion"}, {"score": 0.003265365666305185, "phrase": "large_delays"}, {"score": 0.0032246835734680377, "phrase": "control_loop"}, {"score": 0.0031845067058084583, "phrase": "accurate_model"}, {"score": 0.0031448288291084, "phrase": "quadrocopter's_flight_dynamics"}, {"score": 0.0028926147550022607, "phrase": "monocular_slam_system"}, {"score": 0.0028685304140180137, "phrase": "additional_metric_sensors"}, {"score": 0.002751075263422475, "phrase": "estimation_accuracy"}, {"score": 0.002728166176898539, "phrase": "flight_accuracy"}, {"score": 0.0026941587813581252, "phrase": "flight_agility"}, {"score": 0.002660574167091781, "phrase": "external_motion_capture_system"}, {"score": 0.002509284173541882, "phrase": "ultrasound_altimeter"}, {"score": 0.002477998427152547, "phrase": "air_pressure_sensor"}, {"score": 0.0024573577356299765, "phrase": "filtering-based_approaches"}, {"score": 0.002426717832834137, "phrase": "complete_system"}, {"score": 0.002158505888557746, "phrase": "research_projects"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Quadrocopter", " Visual navigation", " Visual SLAM", " Monocular SLAM", " Scale estimation", " AR.Drone"], "paper_abstract": "We present a complete solution for the visual navigation of a small-scale, low-cost quadrocopter in unknown environments. Our approach relies solely on a monocular camera as the main sensor, and therefore does not need external tracking aids such as GPS or visual markers. Costly computations are carried out on an external laptop that communicates over wireless LAN with the quadrocopter. Our approach consists of three components: a monocular SLAM system, an extended Kalman filter for data fusion, and a PID controller. In this paper, we (1) propose a simple, yet effective method to compensate for large delays in the control loop using an accurate model of the quadrocopter's flight dynamics, and (2) present a novel, closed-form method to estimate the scale of a monocular SLAM system from additional metric sensors. We extensively evaluated our system in terms of pose estimation accuracy, flight accuracy, and flight agility using an external motion capture system. Furthermore, we compared the convergence and accuracy of our scale estimation method for an ultrasound altimeter and an air pressure sensor with filtering-based approaches. The complete system is available as open-source in ROS. This software can be used directly with a low-cost, off-the-shelf Parrot AR.Drone quadrocopter, and hence serves as an ideal basis for follow-up research projects. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Scale-aware navigation of a low-cost quadrocopter with a monocular camera", "paper_id": "WOS:000342266700005"}