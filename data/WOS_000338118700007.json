{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "visual_computing"}, {"score": 0.04923607408107278, "phrase": "facewarehouse"}, {"score": 0.03698114486737466, "phrase": "color_image"}, {"score": 0.004585332915477379, "phrase": "visual_computing_applications"}, {"score": 0.004504585524419396, "phrase": "kinect"}, {"score": 0.004366621944520248, "phrase": "rgbd"}, {"score": 0.0040309035566691645, "phrase": "rgbd_data"}, {"score": 0.0039248128268720645, "phrase": "neutral_expression"}, {"score": 0.0036390887584943723, "phrase": "rgbd_raw_data_record"}, {"score": 0.0035590664550919854, "phrase": "facial_feature_points"}, {"score": 0.003465350958971198, "phrase": "eye_corners"}, {"score": 0.003434662174045939, "phrase": "mouth_contour"}, {"score": 0.003374094774912924, "phrase": "nose_tip"}, {"score": 0.0032416819339366712, "phrase": "better_accuracy"}, {"score": 0.003128336741911927, "phrase": "template_facial_mesh"}, {"score": 0.003073154478201771, "phrase": "depth_data"}, {"score": 0.002965684305115369, "phrase": "feature_points"}, {"score": 0.0027989800906333784, "phrase": "fitted_face"}, {"score": 0.0027010719929751, "phrase": "individual-specific_expression_blendshapes"}, {"score": 0.00260657976055413, "phrase": "consistent_topology"}, {"score": 0.0025042115651986332, "phrase": "bilinear_face_model"}], "paper_keywords": ["Face modeling", " facial animation", " face database", " mesh deformation", " RGBD camera"], "paper_abstract": "We present FaceWarehouse, a database of 3D facial expressions for visual computing applications. We use Kinect, an off-the-shelf RGBD camera, to capture 150 individuals aged 7-80 from various ethnic backgrounds. For each person, we captured the RGBD data of her different expressions, including the neutral expression and 19 other expressions such as mouth-opening, smile, kiss, etc. For every RGBD raw data record, a set of facial feature points on the color image such as eye corners, mouth contour, and the nose tip are automatically localized, and manually adjusted if better accuracy is required. We then deform a template facial mesh to fit the depth data as closely as possible while matching the feature points on the color image to their corresponding points on the mesh. Starting from these fitted face meshes, we construct a set of individual-specific expression blendshapes for each person. These meshes with consistent topology are assembled as a rank-3 tensor to build a bilinear face model with two attributes: identity and expression. Compared with previous 3D facial databases, for every person in our database, there is a much richer matching collection of expressions, enabling depiction of most human facial actions. We demonstrate the potential of FaceWarehouse for visual computing with four applications: facial image manipulation, face component transfer, real-time performance-based facial image animation, and facial animation retargeting from video to image.", "paper_title": "FaceWarehouse: A 3D Facial Expression Database for Visual Computing", "paper_id": "WOS:000338118700007"}