{"auto_keywords": [{"score": 0.049698358871674404, "phrase": "multi-core_processors"}, {"score": 0.010612387000973441, "phrase": "thread_communications"}, {"score": 0.007103040924185965, "phrase": "multithreaded_applications"}, {"score": 0.005960889689154575, "phrase": "destination's_cache"}, {"score": 0.004701015188740582, "phrase": "ongoing_quest"}, {"score": 0.004663636232080366, "phrase": "greater_computational_power"}, {"score": 0.004535124351828787, "phrase": "paramount_importance"}, {"score": 0.0044990584725586764, "phrase": "architectural_trends"}, {"score": 0.0044101380740283825, "phrase": "single-threaded_application_performance"}, {"score": 0.004322967486451877, "phrase": "instruction_level_parallelism"}, {"score": 0.004203803478570494, "phrase": "multithreaded_application_performance"}, {"score": 0.004153739859461064, "phrase": "thread_level_parallelism"}, {"score": 0.003959353513286997, "phrase": "single_die"}, {"score": 0.003850173884725567, "phrase": "concurrent_execution"}, {"score": 0.003526186748088922, "phrase": "parallel_programming"}, {"score": 0.0033077610063168093, "phrase": "processor_cores"}, {"score": 0.0032814236411444022, "phrase": "current_multi-core_processors"}, {"score": 0.0032423089921154503, "phrase": "explicit_communications_support"}, {"score": 0.003065830998810144, "phrase": "inter-core_communications"}, {"score": 0.0030292784088033838, "phrase": "cache_coherence"}, {"score": 0.002981216610222911, "phrase": "demand-based_cache_line_transfers"}, {"score": 0.0028302049070944944, "phrase": "communications_support"}, {"score": 0.002752075650871066, "phrase": "software_controlled_data_forwarding_technique"}, {"score": 0.002623111480310373, "phrase": "cache_misses"}, {"score": 0.002530359917257626, "phrase": "coherence_traffic"}, {"score": 0.0024802523752944536, "phrase": "software_controlled_eviction"}, {"score": 0.00240213106042981, "phrase": "shared_data"}, {"score": 0.002382987346529592, "phrase": "shared_caches"}, {"score": 0.0022803854904010347, "phrase": "remote_caches"}, {"score": 0.002262209824105154, "phrase": "main_memory"}, {"score": 0.002244178699939059, "phrase": "simulation_results"}, {"score": 0.0022262909736042212, "phrase": "significant_performance_improvement"}, {"score": 0.0021734768728417977, "phrase": "architecture_optimizations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multi-core processors", " Parallelism and concurrency", " Shared memory"], "paper_abstract": "In the ongoing quest for greater computational power, efficiently exploiting parallelism is of paramount importance. Architectural trends have shifted from improving single-threaded application performance, often achieved through instruction level parallelism (ILP), to improving multithreaded application performance by supporting thread level parallelism (TLP). Thus, multi-core processors incorporating two or more cores on a single die have become ubiquitous. To achieve concurrent execution on multi-core processors, applications must be explicitly restructured to exploit parallelism, either by programmers or compilers. However, multithreaded parallel programming may introduce overhead due to communications among threads. Though some resources are shared among processor cores, current multi-core processors provide no explicit communications support for multithreaded applications that takes advantage of the proximity between cores. Currently, inter-core communications depend on cache coherence, resulting in demand-based cache line transfers with their inherent latency and overhead. In this paper, we explore two approaches to improve communications support for multithreaded applications. Prepushing is a software controlled data forwarding technique that sends data to destination's cache before it is needed, eliminating cache misses in the destination's cache as well as reducing the coherence traffic on the bus. Software Controlled Eviction (SCE) improves thread communications by placing shared data in shared caches so that it can be found in a much closer location than remote caches or main memory. Simulation results show significant performance improvement with the addition of these architecture optimizations to multi-core processors. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Architectural support for thread communications in multi-core processors", "paper_id": "WOS:000287350600003"}