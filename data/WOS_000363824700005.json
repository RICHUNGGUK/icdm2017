{"auto_keywords": [{"score": 0.04942981937458461, "phrase": "physiological_signals"}, {"score": 0.01454449125800608, "phrase": "emotion_recognition_system"}, {"score": 0.009140644557911885, "phrase": "classification_units"}, {"score": 0.00481495049065317, "phrase": "dynamic_adaptive_fusion"}, {"score": 0.00478218760286811, "phrase": "forehead_biopotentials"}, {"score": 0.004605917942709477, "phrase": "new_adaptive_method"}, {"score": 0.004558977045730675, "phrase": "multiple_emotional_modalities"}, {"score": 0.004316552692395911, "phrase": "peripheral_physiological_measurements"}, {"score": 0.004287166497171827, "phrase": "blood_volume_pressure"}, {"score": 0.0041149859710361125, "phrase": "emotional_modalities"}, {"score": 0.0040869663676860535, "phrase": "six_basic_emotions"}, {"score": 0.0038170129089059013, "phrase": "preselected_video_clips"}, {"score": 0.003352088714126572, "phrase": "adaptive_weighted_linear_model"}, {"score": 0.003306559295382181, "phrase": "final_result"}, {"score": 0.0032728171827367068, "phrase": "classification_unit"}, {"score": 0.003077451642616653, "phrase": "testing_phase"}, {"score": 0.0030460403366412126, "phrase": "training_phase_results"}, {"score": 0.003014948673771347, "phrase": "dynamic_weighting_scheme"}, {"score": 0.0029235593748707495, "phrase": "new_user"}, {"score": 0.002854392852477005, "phrase": "suggested_method"}, {"score": 0.0028349323966217386, "phrase": "conventional_fusion"}, {"score": 0.0027584046728703297, "phrase": "majority_voting_method"}, {"score": 0.002702363975375762, "phrase": "considerable_improvement"}, {"score": 0.002620424858132324, "phrase": "static_weighting_schemes"}, {"score": 0.002532284627202572, "phrase": "support_vector_machine"}, {"score": 0.0024893297856666808, "phrase": "k-nearest_neighbors"}, {"score": 0.002430411367515404, "phrase": "overall_classification_accuracies"}, {"score": 0.002238767763626708, "phrase": "proposed_scheme"}, {"score": 0.0022007808283071133, "phrase": "reliable_emotion_recognition_system"}, {"score": 0.002148677187261496, "phrase": "additional_emotional_modalities"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ireland_ltd."}], "paper_keywords": ["Emotion recognition system", " Dynamic adaptive fusion of classification units", " Forehead bioelectric signals", " Physiological signals", " Human computer interactions"], "paper_abstract": "In this study, we proposed a new adaptive method for fusing multiple emotional modalities to improve the performance of the emotion recognition system. Three-channel forehead biosignals along with peripheral physiological measurements (blood volume pressure, skin conductance, and interbeat intervals) were utilized as emotional modalities. Six basic emotions, i.e., anger, sadness, fear, disgust, happiness, and surprise were elicited by displaying preselected video clips for each of the 25 participants in the experiment; the physiological signals were collected simultaneously. In our multimodal emotion recognition system, recorded signals with the formation of several classification units identified the emotions independently. Then the results were fused using the adaptive weighted linear model to produce the final result. Each classification unit is assigned a weight that is determined dynamically by considering the performance of the units during the testing phase and the training phase results. This dynamic weighting scheme enables the emotion recognition system to adapt itself to each new user. The results showed that the suggested method outperformed conventional fusion of the features and classification units using the majority voting method. In addition, a considerable improvement, compared to the systems that used the static weighting schemes for fusing classification units, was also shown. Using support vector machine (SVM) and k-nearest neighbors (KNN) classifiers, the overall classification accuracies of 84.7% and 80% were obtained in identifying the emotions, respectively. In addition, applying the forehead or physiological signals in the proposed scheme indicates that designing a reliable emotion recognition system is feasible without the need for additional emotional modalities. (C) 2015 Elsevier Ireland Ltd. All rights reserved.", "paper_title": "Reliable emotion recognition system based on dynamic adaptive fusion of forehead biopotentials and physiological signals", "paper_id": "WOS:000363824700005"}