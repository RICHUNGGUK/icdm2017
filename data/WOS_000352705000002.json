{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "hidden_markov_models"}, {"score": 0.040490368143968045, "phrase": "proposed_method"}, {"score": 0.004645057834614705, "phrase": "general_class"}, {"score": 0.004481132747216135, "phrase": "time-varying_covariates"}, {"score": 0.004271490815763164, "phrase": "observed_information_matrix"}, {"score": 0.00407161650109722, "phrase": "standard_errors"}, {"score": 0.003999089046152065, "phrase": "parameter_estimates"}, {"score": 0.003927848423072668, "phrase": "model_identifiability"}, {"score": 0.00374399358035391, "phrase": "oakes'_identity"}, {"score": 0.003526186748088922, "phrase": "exact_computation"}, {"score": 0.0034633412134999425, "phrase": "information_matrix"}, {"score": 0.0031654684543975077, "phrase": "maximum_likelihood_estimation"}, {"score": 0.002945669860541221, "phrase": "first_derivative"}, {"score": 0.0028931405607654495, "phrase": "posterior_probabilities"}, {"score": 0.0028245516301681713, "phrase": "forward-backward_recursions"}, {"score": 0.0027742026116710466, "phrase": "baum"}, {"score": 0.0027411064072367327, "phrase": "welch"}, {"score": 0.002708399936381754, "phrase": "alternative_methods"}, {"score": 0.0026600905156986317, "phrase": "exactly_the_observed_information_matrix_require"}, {"score": 0.0025660347613972573, "phrase": "twice_the_forward_recursion"}, {"score": 0.0024901940672239784, "phrase": "model_likelihood"}, {"score": 0.0024311346712789553, "phrase": "greater_additional_effort"}, {"score": 0.0023592715993204796, "phrase": "em_algorithm"}, {"score": 0.0021304214257321, "phrase": "longitudinal_dataset"}, {"score": 0.0021049977753042253, "phrase": "health_economics"}], "paper_keywords": ["EM algorithm", " Forward-backward recursions", " Oakes' identity", " Standard errors"], "paper_abstract": "For a general class of hidden Markov models that may include time-varying covariates, we illustrate how to compute the observed information matrix, which may be used to obtain standard errors for the parameter estimates and check model identifiability. The proposed method is based on the Oakes' identity and, as such, it allows for the exact computation of the information matrix on the basis of the output of the expectation-maximization (EM) algorithm for maximum likelihood estimation. In addition to this output, the method requires the first derivative of the posterior probabilities computed by the forward-backward recursions introduced by Baum and Welch. Alternative methods for computing exactly the observed information matrix require, instead, to differentiate twice the forward recursion used to compute the model likelihood, with a greater additional effort with respect to the EM algorithm. The proposed method is illustrated by a series of simulations and an application based on a longitudinal dataset in Health Economics.", "paper_title": "Information matrix for hidden Markov models with covariates", "paper_id": "WOS:000352705000002"}