{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "local_visual_and_semantic_concept-based_feature_spaces"}, {"score": 0.004646258518859209, "phrase": "learning-based_unified_image_retrieval_framework"}, {"score": 0.004326321719714357, "phrase": "visual_concept_vocabulary"}, {"score": 0.003910278811774747, "phrase": "probabilistic_multi-class_support_vector_machine"}, {"score": 0.0035341028694769036, "phrase": "spatial_relationship-enhanced_concept_feature_spaces"}, {"score": 0.0034101316738399203, "phrase": "local_neighborhood_structure"}, {"score": 0.0033101397746161843, "phrase": "local_concept_correlation_statistics"}, {"score": 0.003251552926963083, "phrase": "spatial_relationships"}, {"score": 0.0032130703855586685, "phrase": "individual_encoded_images"}, {"score": 0.0030273620861817055, "phrase": "dynamically_weighted_linear_combination"}, {"score": 0.002991524908432975, "phrase": "similarity_matching_scheme"}, {"score": 0.002921114512115261, "phrase": "relevance_feedback_information"}, {"score": 0.0028693932802982417, "phrase": "feature_weights"}, {"score": 0.0027358910467781155, "phrase": "rank_order_information"}, {"score": 0.002655616553414394, "phrase": "relevant_images"}, {"score": 0.0025169965861573185, "phrase": "individual_searches"}, {"score": 0.002472412920623605, "phrase": "effective_results"}, {"score": 0.002428617044669043, "phrase": "experimental_results"}, {"score": 0.002385595105638277, "phrase": "photographic_database"}, {"score": 0.002357337046408753, "phrase": "natural_scenes"}, {"score": 0.002315574871863272, "phrase": "bio-medical_database"}, {"score": 0.0022881443200668886, "phrase": "different_imaging_modalities"}, {"score": 0.0022610379771517966, "phrase": "body_parts"}, {"score": 0.002181626277903721, "phrase": "proposed_framework"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Content-based image retrieval", " Learning methods", " Classification", " Self-organizing map", " Support vector machine", " Relevance feedback", " Similarity fusion"], "paper_abstract": "This paper presents a learning-based unified image retrieval framework to represent images in local visual and semantic concept-based feature spaces. In this framework, a visual concept vocabulary (codebook) is automatically constructed by utilizing self-organizing map (SOM) and statistical models are built for local semantic concepts using probabilistic multi-class support vector machine (SVM). Based on these constructions, the images are represented in correlation and spatial relationship-enhanced concept feature spaces by exploiting the topology preserving local neighborhood structure of the codebook, local concept correlation statistics, and spatial relationships in individual encoded images. Finally, the features are unified by a dynamically weighted linear combination of similarity matching scheme based on the relevance feedback information. The feature weights are calculated by considering both the precision and the rank order information of the top retrieved relevant images of each representation, which adapts itself to individual searches to produce effective results. The experimental results on a photographic database of natural scenes and a bio-medical database of different imaging modalities and body parts demonstrate the effectiveness of the proposed framework. (C) 2009 Elsevier Inc. All rights reserved.", "paper_title": "A unified image retrieval framework on local visual and semantic concept-based feature spaces", "paper_id": "WOS:000274800800002"}