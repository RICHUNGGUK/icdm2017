{"auto_keywords": [{"score": 0.04041253813268456, "phrase": "local_site"}, {"score": 0.032296702618043426, "phrase": "upper_bound"}, {"score": 0.03192280240290009, "phrase": "server_capacity"}, {"score": 0.00481495049065317, "phrase": "data-sharing_tasks"}, {"score": 0.0047386923107107645, "phrase": "almost_every_computation_task"}, {"score": 0.0044101380740283825, "phrase": "centralized_system"}, {"score": 0.003959353513286997, "phrase": "remote_sites"}, {"score": 0.003669941438286456, "phrase": "interleaved_sequence"}, {"score": 0.003640730820018083, "phrase": "data_transfer"}, {"score": 0.003611751858608048, "phrase": "job_execution"}, {"score": 0.0035687137873965684, "phrase": "significant_impact"}, {"score": 0.003526186748088922, "phrase": "overall_computational_efficiency"}, {"score": 0.0034016119212097826, "phrase": "computational_complexity"}, {"score": 0.003361069456060196, "phrase": "shared-data_job"}, {"score": 0.0032036590920314725, "phrase": "storage_capacity_constraint"}, {"score": 0.0029586775075482125, "phrase": "np"}, {"score": 0.002623111480310373, "phrase": "efficient_algorithm"}, {"score": 0.002571171956724731, "phrase": "optimal_job_schedule"}, {"score": 0.0024506642262508735, "phrase": "efficient_heuristic_algorithm"}, {"score": 0.0024117603727471654, "phrase": "good_schedules"}, {"score": 0.0022352169832099153, "phrase": "reported_experiment_results"}, {"score": 0.002199725773957207, "phrase": "heuristic_algorithm"}, {"score": 0.0021304214257321, "phrase": "optimal_solutions"}], "paper_keywords": ["Data-sharing tasks", " Scheduling"], "paper_abstract": "Almost every computation task requires input data in order to find a solution. This is not a problem for a centralized system because data is usually available locally. However, in a parallel and distributed system, e.g., Computation grids, the data may be in remote sites and must be transferred to the local site before the computation can proceed. As a result, the interleaved sequence of data transfer and job execution has a significant impact on the overall computational efficiency. In this paper, we analyze the computational complexity of the shared-data job scheduling problem on uniprocessor, with and without consideration of the storage capacity constraint on the local site. We show that if there is an upper bound on the server capacity, the problem is NP-complete, even when each job depends on at most two data items. For the case where there is no upper bound on the server capacity, we show that there exists an efficient algorithm that can provide an optimal job schedule when each job depends on at most two data items. We also propose an efficient heuristic algorithm that can determine good schedules for cases where there is no limit on the amount of data a job may access. The reported experiment results demonstrate that this heuristic algorithm performs very well, and derives near optimal solutions. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Computation and communication schedule optimization for data-sharing tasks on uniprocessor", "paper_id": "WOS:000271358800002"}