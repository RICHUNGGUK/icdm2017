{"auto_keywords": [{"score": 0.03896650159418718, "phrase": "opportunity_cost"}, {"score": 0.00481495049065317, "phrase": "dark_silicon_era"}, {"score": 0.004582722012454012, "phrase": "general-purpose_cpus"}, {"score": 0.004330941610682453, "phrase": "significant_performance"}, {"score": 0.004270178957872099, "phrase": "power_improvements"}, {"score": 0.003603989174919527, "phrase": "real_estate"}, {"score": 0.0033817999428800457, "phrase": "general-purpose_architectures"}, {"score": 0.003195787852087248, "phrase": "novel_technique"}, {"score": 0.0030199761431186434, "phrase": "gp-cpu_cores"}, {"score": 0.0029565620771207003, "phrase": "accelerator_memory"}, {"score": 0.0028944757265206332, "phrase": "non-uniform_cache_architecture"}, {"score": 0.002275477757478827, "phrase": "nuca_slices"}, {"score": 0.0021049977753042253, "phrase": "equally-sized_ad_hoc_cache_slices"}], "paper_keywords": ["Cache memory", " accelerator architectures"], "paper_abstract": "Accelerators integrated on-die with General-Purpose CPUs (GP-CPUs) can yield significant performance and power improvements. Their extensive use, however, is ultimately limited by their area overhead; due to their high degree of specialization, the opportunity cost of investing die real estate on accelerators can become prohibitive, especially for general-purpose architectures. In this paper we present a novel technique aimed at mitigating this opportunity cost by allowing GP-CPU cores to reuse accelerator memory as a non-uniform cache architecture (NUCA) substrate. On a system with a last level-2 cache of 128kB, our technique achieves on average a 25% performance improvement when reusing four 512 kB accelerator memory blocks to form a level-3 cache. Making these blocks reusable as NUCA slices incurs on average in a 1.89% area overhead with respect to equally-sized ad hoc cache slices.", "paper_title": "Accelerator Memory Reuse in the Dark Silicon Era", "paper_id": "WOS:000344987900003"}