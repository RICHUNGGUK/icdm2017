{"auto_keywords": [{"score": 0.049722360725641276, "phrase": "token_coherence"}, {"score": 0.008976791610680851, "phrase": "unordered_requests"}, {"score": 0.005226613962511806, "phrase": "priority_requests"}, {"score": 0.00481495049065317, "phrase": "scalable_starvation_prevention_mechanism"}, {"score": 0.004690583510896564, "phrase": "cache_coherence_protocol"}, {"score": 0.0046037124365759215, "phrase": "best_attributes"}, {"score": 0.004552360432689039, "phrase": "traditional_approximations"}, {"score": 0.004385270183517169, "phrase": "snooping-based_protocols"}, {"score": 0.004287961675700099, "phrase": "bus-like_interconnects"}, {"score": 0.004240116703465252, "phrase": "directory-based_protocols"}, {"score": 0.003775803846431323, "phrase": "protocol_races"}, {"score": 0.003516635512391528, "phrase": "unresolved_misses"}, {"score": 0.0034385353123700885, "phrase": "starvation_prevention_mechanism"}, {"score": 0.003154836091281154, "phrase": "storage_structures"}, {"score": 0.0030275252142439213, "phrase": "system_size"}, {"score": 0.002949189427671915, "phrase": "increasingly_number"}, {"score": 0.00286213454317036, "phrase": "cache_coherence_protocols"}, {"score": 0.0028090313440881937, "phrase": "key_aspects"}, {"score": 0.0027159094186967247, "phrase": "alternative_starvation_prevention_mechanism"}, {"score": 0.002625866440129899, "phrase": "persistent_request"}, {"score": 0.00252930673503721, "phrase": "application_runtime"}, {"score": 0.002251911996999611, "phrase": "whole_scalability"}, {"score": 0.0021448202319775634, "phrase": "slight_performance_degradation"}, {"score": 0.0021049977753042253, "phrase": "persistent_requests"}], "paper_keywords": ["Cache coherence", " token coherence", " starvation prevention", " scalability"], "paper_abstract": "Token Coherence is a cache coherence protocol that simultaneously captures the best attributes of the traditional approximations to coherence: direct communication between processors (like snooping-based protocols) and no reliance on bus-like interconnects (like directory-based protocols). This is possible thanks to a class of unordered requests that usually succeed in resolving the cache misses. The problem of the unordered requests is that they can cause protocol races, which prevent some misses from being resolved. To eliminate races and ensure the completion of the unresolved misses, Token Coherence uses a starvation prevention mechanism named persistent requests. This mechanism is extremely inefficient and, besides, it endangers the scalability of Token Coherence since it requires storage structures (at each node) whose size grows proportionally to the system size. While multiprocessors continue including an increasingly number of nodes, both the performance and scalability of cache coherence protocols will continue to be key aspects. In this work, we propose an alternative starvation prevention mechanism, named priority requests, that outperforms the persistent request one. This mechanism is able to reduce the application runtime more than 20 percent (on average) in a 64-processor system. Furthermore, thanks to the flexibility shown by priority requests, it is possible to drastically minimize its storage requirements, thereby improving the whole scalability of Token Coherence. Although this is achieved at the expense of a slight performance degradation, priority requests still outperform persistent requests significantly.", "paper_title": "Efficient and Scalable Starvation Prevention Mechanism for Token Coherence", "paper_id": "WOS:000294162500002"}