{"auto_keywords": [{"score": 0.03261638306028882, "phrase": "input_image"}, {"score": 0.015164996513205235, "phrase": "real-world_images"}, {"score": 0.00481495049065317, "phrase": "image_classification"}, {"score": 0.004749824776508639, "phrase": "pixel-wise_matching"}, {"score": 0.0045804107341714, "phrase": "typical_problem"}, {"score": 0.004477595431209663, "phrase": "computer_vision"}, {"score": 0.004126123386192962, "phrase": "similarity_recognition_model"}, {"score": 0.004015182362035361, "phrase": "difficult_issue"}, {"score": 0.003960831041259951, "phrase": "numerous_approaches"}, {"score": 0.0038368442918503072, "phrase": "tough_issue"}, {"score": 0.003716724243777879, "phrase": "pixel-wise_techniques"}, {"score": 0.003503497128638099, "phrase": "innovative_method"}, {"score": 0.0034092396400930446, "phrase": "pixel_matching"}, {"score": 0.00330246222643051, "phrase": "two-dimensional_continuous_dynamic_programming"}, {"score": 0.0031556799865964974, "phrase": "corresponding_pixels"}, {"score": 0.0031271133933467575, "phrase": "nonlinearly_matched_areas"}, {"score": 0.0029610472910087176, "phrase": "advance_segmentation_procedure"}, {"score": 0.002934237411711622, "phrase": "direction_pattern"}, {"score": 0.0028682668647074397, "phrase": "scalar_patterns"}, {"score": 0.0028037753646260937, "phrase": "vector_angles"}, {"score": 0.0027159094186967247, "phrase": "vector_field"}, {"score": 0.00266693888510356, "phrase": "matching_pixels"}, {"score": 0.0026307897899760383, "phrase": "reference_image"}, {"score": 0.002502374576203785, "phrase": "test_image"}, {"score": 0.002401972657236926, "phrase": "strongest_correlation"}, {"score": 0.0023694065215394593, "phrase": "orientation_patterns"}, {"score": 0.0022951216874671516, "phrase": "experimental_results"}, {"score": 0.0022537212268979507, "phrase": "proposed_method"}, {"score": 0.0022231606165229235, "phrase": "competitive_and_robust_performance"}, {"score": 0.0021731423856364003, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Categorical classification", " Full pixel matching", " Direction pattern", " Segmentation-free"], "paper_abstract": "Categorical classification for real-world images is a typical problem in the field of computer vision. This task is extremely easy for a human due to our visual cortex systems. However, developing a similarity recognition model for computer is still a difficult issue. Although numerous approaches have been proposed for solving the tough issue, little attention is given to the pixel-wise techniques for recognition and classification. In this paper, we present an innovative method for recognizing real-world images based on pixel matching between images. A method called two-dimensional continuous dynamic programming (2DCDP) is adopted to optimally capture the corresponding pixels within nonlinearly matched areas in an input image and a reference image representing an object without advance segmentation procedure. Direction pattern (a set of scalar patterns based on quantization of vector angles) is made by using a vector field constructed by the matching pixels between a reference image and an input image. Finally, the category of the test image is deemed to be that which has the strongest correlation with the orientation patterns of the input image and its reference image. Experimental results show that the proposed method achieves a competitive and robust performance on the Caltech 101 image dataset. Crown Copyright (C) 2012 Published by Elsevier Inc. All rights reserved.", "paper_title": "A segmentation-free method for image classification based on pixel-wise matching", "paper_id": "WOS:000312354000008"}