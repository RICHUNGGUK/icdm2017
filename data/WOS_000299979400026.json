{"auto_keywords": [{"score": 0.04440921591961226, "phrase": "tan"}, {"score": 0.015557567873129763, "phrase": "naive_bayes"}, {"score": 0.01331909488531533, "phrase": "classification_accuracy"}, {"score": 0.013181706026698827, "phrase": "error_rate"}, {"score": 0.00481495049065317, "phrase": "improving_tree"}, {"score": 0.0047152877145889656, "phrase": "class_probability_estimation"}, {"score": 0.004666228956744244, "phrase": "numerous_algorithms"}, {"score": 0.004291617358806677, "phrase": "tree_augmented_naive_bayes"}, {"score": 0.0041589926969138585, "phrase": "remarkable_classification_performance"}, {"score": 0.003554661425339528, "phrase": "direct_marketing"}, {"score": 0.0034267429854665035, "phrase": "different_promotion_strategies"}, {"score": 0.003355717283753749, "phrase": "different_likelihood"}, {"score": 0.0031513240597392843, "phrase": "accurate_class_probability_estimation"}, {"score": 0.0030538300202383106, "phrase": "optimal_decisions"}, {"score": 0.0029131986574478046, "phrase": "class_probability_estimation_performance"}, {"score": 0.002823050755743821, "phrase": "conditional_log_likelihood"}, {"score": 0.0027936253901331503, "phrase": "cll"}, {"score": 0.002721388234661538, "phrase": "new_algorithm"}, {"score": 0.002637160140011997, "phrase": "spanning_tan_classifiers"}, {"score": 0.00256895975568914, "phrase": "averaged_tree"}, {"score": 0.002450602177683066, "phrase": "experimental_results"}, {"score": 0.002412371116984224, "phrase": "large_number"}, {"score": 0.002387214876538434, "phrase": "uci_datasets"}, {"score": 0.002337684811187166, "phrase": "main_web_site"}, {"score": 0.0023133055945761235, "phrase": "weka_platform_show"}, {"score": 0.0022891802106682793, "phrase": "atan"}, {"score": 0.0021496085300726207, "phrase": "cll."}], "paper_keywords": ["Naive Bayes", " Tree Augmented Naive Bayes", " Class probability estimation", " Conditional log likelihood", " Ensemble learning"], "paper_abstract": "Numerous algorithms have been proposed to improve Naive Bayes (NB) by weakening its conditional attribute independence assumption, among which Tree Augmented Naive Bayes (TAN) has demonstrated remarkable classification performance in terms of classification accuracy or error rate, while maintaining efficiency and simplicity. In many real-world applications, however, classification accuracy or error rate is not enough. For example, in direct marketing, we often need to deploy different promotion strategies to customers with different likelihood (class probability) of buying some products. Thus, accurate class probability estimation is often required to make optimal decisions. In this paper, we investigate the class probability estimation performance of TAN in terms of conditional log likelihood (CLL) and present a new algorithm to improve its class probability estimation performance by the spanning TAN classifiers. We call our improved algorithm Averaged Tree Augmented Naive Bayes (ATAN). The experimental results on a large number of UCI datasets published on the main web site of Weka platform show that ATAN significantly outperforms TAN and all the other algorithms used to compare in terms of CLL. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Improving Tree augmented Naive Bayes for class probability estimation", "paper_id": "WOS:000299979400026"}