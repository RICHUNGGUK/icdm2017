{"auto_keywords": [{"score": 0.03128898671324496, "phrase": "rl"}, {"score": 0.00481495049065317, "phrase": "parameter-less_self-organising_map"}, {"score": 0.004439097815805505, "phrase": "novel_method"}, {"score": 0.0038242899532391914, "phrase": "sound_source"}, {"score": 0.002511349409241358, "phrase": "directional_filtering"}, {"score": 0.0024111277643627154, "phrase": "plsom."}, {"score": 0.0023465400668244386, "phrase": "presented_system"}, {"score": 0.0021925226977381244, "phrase": "similar_system"}], "paper_keywords": ["active audition", " self-organisation"], "paper_abstract": "This paper presents a novel method for enabling a robot to determine the position of a sound source in three dimensions using just two microphones and interaction with its environment. The method uses the Parameter-Less Self-Organising Map (PLSOM) algorithm and Reinforcement Learning (RL) to achieve rapid, accurate response. We also introduce a method for directional filtering using the PLSOM. The presented system is compared to a similar system to evaluate its performance.", "paper_title": "Active audition using the parameter-less self-organising map", "paper_id": "WOS:000253695300005"}