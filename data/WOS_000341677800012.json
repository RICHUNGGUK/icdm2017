{"auto_keywords": [{"score": 0.042456351563769784, "phrase": "video_clustering"}, {"score": 0.012455600793695632, "phrase": "low-level_visual-audio_features"}, {"score": 0.00863831121252414, "phrase": "fmri-derived_features"}, {"score": 0.00481495049065317, "phrase": "video_shots"}, {"score": 0.0047587234712024775, "phrase": "natural_stimulus_fmri._functional_magnetic_resonance_imaging"}, {"score": 0.004648222388468414, "phrase": "powerful_tool"}, {"score": 0.004575977644865379, "phrase": "human_brain's_perception"}, {"score": 0.0044002186469797476, "phrase": "clinical_applications"}, {"score": 0.004365881789903319, "phrase": "fmri_technique"}, {"score": 0.004281202319048493, "phrase": "human's_ordinary_life"}, {"score": 0.0041328796505374155, "phrase": "novel_application"}, {"score": 0.004084584884062157, "phrase": "fmri_techniques"}, {"score": 0.003958529104387973, "phrase": "proposed_work"}, {"score": 0.0038817197332605647, "phrase": "semantic_human-centric_features"}, {"score": 0.0038363485899400285, "phrase": "natural_stimulus_fmri_data"}, {"score": 0.0036457672198249333, "phrase": "significant_innovation"}, {"score": 0.003589046900483573, "phrase": "previous_works"}, {"score": 0.0033314049082500794, "phrase": "video_shot_samples"}, {"score": 0.0032539388572032563, "phrase": "newly_developed_brain_networks_localization_system"}, {"score": 0.0031782684007251403, "phrase": "cortical_regions"}, {"score": 0.0030800962618484844, "phrase": "individual_subject"}, {"score": 0.0030440661915657175, "phrase": "functional_interactions"}, {"score": 0.0030084563186769764, "phrase": "wavelet_transform_coherence"}, {"score": 0.002926973459215349, "phrase": "human-centric_features"}, {"score": 0.002847691227421257, "phrase": "gaussian_process_regression_model"}, {"score": 0.002825435048559866, "phrase": "visual-audio_feature_space"}, {"score": 0.002792375587031108, "phrase": "fmri-derived_feature_space"}, {"score": 0.002727409429089543, "phrase": "training_samples"}, {"score": 0.0026954938318408464, "phrase": "trained_model"}, {"score": 0.0025816239578784067, "phrase": "fmri_data"}, {"score": 0.002531463482341473, "phrase": "multi-modal_spectral_clustering"}, {"score": 0.0024822751900485758, "phrase": "ranking_algorithm"}, {"score": 0.002312960805824996, "phrase": "trecvid_database"}, {"score": 0.0021721582450016, "phrase": "visual-audio_features"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Video clustering", " Video retrieval", " Functional magnetic resonance imaging", " Feature integration"], "paper_abstract": "Functional magnetic resonance imaging (fMRI) is a powerful tool to probe the human brain's perception and cognition. Besides being extensively exploited in the clinical applications, fMRI technique is also useful to human's ordinary life. In this paper, we investigate a novel application of leveraging fMRI techniques to video clustering and retrieval. In the proposed work, we successfully integrate semantic human-centric features derived from natural stimulus fMRI data and low-level visual-audio features to facilitate video clustering and retrieval, which is a significant innovation compared to the previous works relying on either fMRI-derived features or low-level visual-audio features. Our system consists of several algorithmic modules. First, fMRI data when the subjects are watching video shot samples are acquired. Then a newly developed brain networks localization system is employed to locate the cortical regions of interests (ROIs) for each individual subject. The functional interactions computed by wavelet transform coherence are quantified, from which the human-centric features are derived. Afterwards, the Gaussian process regression model mapping visual-audio feature space to an fMRI-derived feature space is trained, given the training samples. The trained model is then adopted to predict fMRI-derived features for videos without the fMRI data. Finally, the multi-modal spectral clustering and multi-modal ranking algorithm are adopted and proposed to integrate these two heterogeneous features for video clustering and retrieval, respectively. Our experiment on TRECVID database has demonstrated the precision of video clustering and retrieval can be substantially improved by integration of visual-audio features and fMRI-derived features. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Clustering and retrieval of video shots based on natural stimulus fMRI", "paper_id": "WOS:000341677800012"}