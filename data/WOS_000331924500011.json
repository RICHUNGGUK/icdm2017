{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "projective_geometry"}, {"score": 0.04973919369807266, "phrase": "view-invariant_monocular_human_motion_analysis"}, {"score": 0.004663074596384574, "phrase": "example-based_approaches"}, {"score": 0.00456448259718331, "phrase": "human_motion_analysis"}, {"score": 0.004342430078306461, "phrase": "training_images"}, {"score": 0.004265760046406154, "phrase": "roof-top_cameras"}, {"score": 0.004190438004831167, "phrase": "video_surveillance"}, {"score": 0.004087207102190335, "phrase": "significant_angle"}, {"score": 0.003958194802333944, "phrase": "typical_training_viewpoints"}, {"score": 0.003544088803300751, "phrase": "straight_lines"}, {"score": 0.0034077704063304208, "phrase": "known_ground_plane"}, {"score": 0.0033119237381809617, "phrase": "reduced_set"}, {"score": 0.0032883848851259123, "phrase": "training_views"}, {"score": 0.003218764138744059, "phrase": "online_stage"}, {"score": 0.0031393948330209224, "phrase": "selected_training_plane"}, {"score": 0.003105979498529766, "phrase": "input_image_points"}, {"score": 0.002954669496511141, "phrase": "ground_plane"}, {"score": 0.002923214590192792, "phrase": "camera_view"}, {"score": 0.0028715299874549245, "phrase": "testing_images"}, {"score": 0.0028409576481842457, "phrase": "homographic_transformation"}, {"score": 0.0027121844541913367, "phrase": "novel_viewpoint"}, {"score": 0.0025800088089364737, "phrase": "bottom-up_manner"}, {"score": 0.0025434384320561403, "phrase": "input_image"}, {"score": 0.002516350372379076, "phrase": "training_plane"}, {"score": 0.0024630345285372958, "phrase": "corresponding_view-based_silhouette_model"}, {"score": 0.002385166298265828, "phrase": "candidate_silhouette"}, {"score": 0.0023015232625177755, "phrase": "qualitative_and_quantitative_results"}, {"score": 0.0022770057597574734, "phrase": "caviar_dataset"}, {"score": 0.0022447206386952126, "phrase": "top-down_types"}, {"score": 0.0021971473452127126, "phrase": "significant_improvements"}, {"score": 0.002173739308244513, "phrase": "proposed_homographic_alignment"}, {"score": 0.002150580119047236, "phrase": "commonly_used_similarity_transform"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Human motion analysis", " Projective geometry", " View-invariance", " Video-surveillance"], "paper_abstract": "Example-based approaches have been very successful for human motion analysis but their accuracy strongly depends on the similarity of the viewpoint in testing and training images. In practice, roof-top cameras are widely used for video surveillance and are usually placed at a significant angle from the floor, which is different from typical training viewpoints. We present a methodology for view-invariant monocular human motion analysis in man-made environments in which we exploit some properties of projective geometry and the presence of numerous easy-to-detect straight lines. We also assume that observed people move on a known ground plane. First, we model body poses and silhouettes using a reduced set of training views. Then, during the online stage, the homography that relates the selected training plane to the input image points is calculated using the dominant 3D directions of the scene, the location on the ground plane and the camera view in both training and testing images. This homographic transformation is used to compensate for the changes in silhouette due to the novel viewpoint. In our experiments, we show that it can be employed in a bottom-up manner to align the input image to the training plane and process it with the corresponding view-based silhouette model, or top-down to project a candidate silhouette and match it in the image. We present qualitative and quantitative results on the CAVIAR dataset using both bottom-up and top-down types of framework and demonstrate the significant improvements of the proposed homographic alignment over a commonly used similarity transform. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Exploiting projective geometry for view-invariant monocular human motion analysis in man-made environments", "paper_id": "WOS:000331924500011"}