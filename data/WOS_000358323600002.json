{"auto_keywords": [{"score": 0.038715848928693446, "phrase": "textured_motion"}, {"score": 0.029207532255041347, "phrase": "vps"}, {"score": 0.012433892754970036, "phrase": "feature_statistics"}, {"score": 0.012269674418163588, "phrase": "input_video"}, {"score": 0.00481495049065317, "phrase": "video_primal_sketch"}, {"score": 0.004645959941491617, "phrase": "middle-level_video_representation"}, {"score": 0.004081385289516914, "phrase": "moving_corners"}, {"score": 0.004009074013302036, "phrase": "feature_points"}, {"score": 0.003474694300991964, "phrase": "spatio-temporal_filters"}, {"score": 0.003177392642813126, "phrase": "video_primitives"}, {"score": 0.003149094460617212, "phrase": "parametric_generative_models"}, {"score": 0.0030520148188164084, "phrase": "spatio-temporal_frame"}, {"score": 0.0030248298759040695, "phrase": "motion-appearance_frame_models"}, {"score": 0.0028539179130824786, "phrase": "parsimonious_hybrid_model"}, {"score": 0.0028284924551705516, "phrase": "generic_video_representation"}, {"score": 0.002716844480081738, "phrase": "proper_models"}, {"score": 0.0026806139086152365, "phrase": "different_motion_patterns"}, {"score": 0.002621297299343551, "phrase": "high-level_action_representations"}, {"score": 0.0024620842899061614, "phrase": "real_videos"}, {"score": 0.002364865100579589, "phrase": "human_perception_experiments"}, {"score": 0.0023021895404322767, "phrase": "reconstructed_videos"}, {"score": 0.0022112700457629494, "phrase": "scale_transition"}, {"score": 0.0021430393104977788, "phrase": "close_connection"}, {"score": 0.0021049977753042253, "phrase": "high-level_action_models"}], "paper_keywords": ["Middle-level vision", " Video representation", " Textured motion", " Dynamic texture synthesis", " Primal sketch"], "paper_abstract": "This paper presents a middle-level video representation named video primal sketch (VPS), which integrates two regimes of models: (i) sparse coding model using static or moving primitives to explicitly represent moving corners, lines, feature points, etc., (ii) FRAME /MRF model reproducing feature statistics extracted from input video to implicitly represent textured motion, such as water and fire. The feature statistics include histograms of spatio-temporal filters and velocity distributions. This paper makes three contributions to the literature: (i) Learning a dictionary of video primitives using parametric generative models; (ii) Proposing the spatio-temporal FRAME and motion-appearance FRAME models for modeling and synthesizing textured motion; and (iii) Developing a parsimonious hybrid model for generic video representation. Given an input video, VPS selects the proper models automatically for different motion patterns and is compatible with high-level action representations. In the experiments, we synthesize a number of textured motion; reconstruct real videos using the VPS; report a series of human perception experiments to verify the quality of reconstructed videos; demonstrate how the VPS changes over the scale transition in videos; and present the close connection between VPS and high-level action models.", "paper_title": "Video Primal Sketch: A Unified Middle-Level Representation for Video", "paper_id": "WOS:000358323600002"}