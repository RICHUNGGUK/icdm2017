{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "sparse_integration"}, {"score": 0.004751216062917875, "phrase": "multiple_manifolds"}, {"score": 0.004688321299229397, "phrase": "data_representation"}, {"score": 0.004626255242038005, "phrase": "manifold_regularized_techniques"}, {"score": 0.004444921827311577, "phrase": "unsupervised_learning"}, {"score": 0.004386063799793622, "phrase": "matrix_factorization"}, {"score": 0.004186105377259855, "phrase": "underlying_graph_regularization"}, {"score": 0.003995226376780718, "phrase": "principled_ways"}, {"score": 0.003916098498242888, "phrase": "reasonable_graphs"}, {"score": 0.0038385317554884713, "phrase": "matrix_decomposition"}, {"score": 0.003712640297460159, "phrase": "multiple_heterogeneous_graph_sources"}, {"score": 0.003359119985242403, "phrase": "optimal_linear_combination_space"}, {"score": 0.0032272929113113203, "phrase": "low_rank_matrix_approximation_model"}, {"score": 0.00312138530097218, "phrase": "probabilistic_simplex"}, {"score": 0.0029988599391845517, "phrase": "coefficient_vector"}, {"score": 0.002861961643289598, "phrase": "sparse_pattern"}, {"score": 0.0027680095380207756, "phrase": "attractive_property"}, {"score": 0.002405853977978678, "phrase": "noisy_or_irrelevant_graphs"}, {"score": 0.002295964130868963, "phrase": "low_rank_decomposition_performance"}, {"score": 0.002220551141101661, "phrase": "diverse_popular_image"}, {"score": 0.0021910825909008946, "phrase": "web_document"}], "paper_keywords": ["Dimensionality reduction", " Low rank matrix approximation", " Manifold learning", " Multiple graph integration", " Sparsity", " Clustering"], "paper_abstract": "Manifold regularized techniques have been extensively exploited in unsupervised learning like matrix factorization whose performance is heavily affected by the underlying graph regularization. However, there exist no principled ways to select reasonable graphs under the matrix decomposition setting, particularly in multiple heterogeneous graph sources. In this paper, we deal with the issue of searching for the optimal linear combination space of multiple graphs under the low rank matrix approximation model. Specifically, efficient projection onto the probabilistic simplex is utilized to optimize the coefficient vector of graphs, resulting in the sparse pattern of coefficients. This attractive property of sparsity can be interpreted as a criterion for selecting graphs, i.e., identifying the most discriminative graphs and removing the noisy or irrelevant graphs, so as to boost the low rank decomposition performance. Experimental results over diverse popular image and web document corpora corroborate the effectiveness of our new model in terms of clusterings.", "paper_title": "Low rank approximation with sparse integration of multiple manifolds for data representation", "paper_id": "WOS:000351110600003"}