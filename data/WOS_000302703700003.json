{"auto_keywords": [{"score": 0.029237135610446486, "phrase": "mean_square_convergence"}, {"score": 0.00481495049065317, "phrase": "quantized_kernel_least_mean_square_algorithm"}, {"score": 0.004545240514015278, "phrase": "quantization_approach"}, {"score": 0.004155283263388382, "phrase": "radial_basis_function_structure"}, {"score": 0.004076157223660074, "phrase": "adaptive_filtering"}, {"score": 0.003998531873723384, "phrase": "basic_idea"}, {"score": 0.003450329424861292, "phrase": "new_approach"}, {"score": 0.0033845816848753073, "phrase": "\"redundant\"_data"}, {"score": 0.0032359856233193504, "phrase": "closest_center"}, {"score": 0.003113804826864362, "phrase": "quantized_kernel"}, {"score": 0.0028830690329478465, "phrase": "simple_online_vector_quantization_method"}, {"score": 0.002635339648135844, "phrase": "energy_conservation_relation"}, {"score": 0.002601727192945944, "phrase": "qklms"}, {"score": 0.0024088451312725924, "phrase": "sufficient_condition"}, {"score": 0.0022302306304023602, "phrase": "theoretical_value"}, {"score": 0.0021876814398268775, "phrase": "steady-state_excess_mean_square_error"}, {"score": 0.0021049977753042253, "phrase": "short-term_chaotic_time-series_prediction_examples"}], "paper_keywords": ["Kernel methods", " mean square convergence", " quantized kernel least mean square", " vector quantization"], "paper_abstract": "In this paper, we propose a quantization approach, as an alternative of sparsification, to curb the growth of the radial basis function structure in kernel adaptive filtering. The basic idea behind this method is to quantize and hence compress the input (or feature) space. Different from sparsification, the new approach uses the \"redundant\" data to update the coefficient of the closest center. In particular, a quantized kernel least mean square (QKLMS) algorithm is developed, which is based on a simple online vector quantization method. The analytical study of the mean square convergence has been carried out. The energy conservation relation for QKLMS is established, and on this basis we arrive at a sufficient condition for mean square convergence, and a lower and upper bound on the theoretical value of the steady-state excess mean square error. Static function estimation and short-term chaotic time-series prediction examples are presented to demonstrate the excellent performance.", "paper_title": "Quantized Kernel Least Mean Square Algorithm", "paper_id": "WOS:000302703700003"}