{"auto_keywords": [{"score": 0.04012762854715395, "phrase": "optimal_solution"}, {"score": 0.00481495049065317, "phrase": "optimal_convergence_probability"}, {"score": 0.0046993598473345395, "phrase": "univariate_estimation"}, {"score": 0.004586531354697466, "phrase": "distribution_algorithms"}, {"score": 0.003685067218455088, "phrase": "compact_genetic_algorithm"}, {"score": 0.0029244418026475832, "phrase": "sufficient_condition"}, {"score": 0.002466139325703204, "phrase": "possible_values"}, {"score": 0.002406799309495983, "phrase": "algorithm_parameters"}, {"score": 0.0021049977753042253, "phrase": "predefined_confidence_level"}], "paper_keywords": ["EDA", " PBIL", " cGA", " Markov process", " submartingale", " subregular functions", " optimal convergence probability"], "paper_abstract": "In this paper we obtain bounds on the probability of convergence to the optimal solution for the compact genetic algorithm (cGA) and the population based incremental learning (PBIL). Moreover, we give a sufficient condition for convergence of these algorithms to the optimal solution and compute a range of possible values for algorithm parameters at which there is convergence to the optimal solution with a predefined confidence level.", "paper_title": "On the Optimal Convergence Probability of Univariate Estimation of Distribution Algorithms", "paper_id": "WOS:000290634000003"}