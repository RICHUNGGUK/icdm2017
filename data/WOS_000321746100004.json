{"auto_keywords": [{"score": 0.04203400118778606, "phrase": "multiple_time_points"}, {"score": 0.00481495049065317, "phrase": "gene_expression_image_sequences"}, {"score": 0.00477513738640734, "phrase": "non-parametric_factor_analysis"}, {"score": 0.00446820572467064, "phrase": "image_data"}, {"score": 0.004412881870378388, "phrase": "promising_results"}, {"score": 0.004304271837157217, "phrase": "rich_and_valuable_information"}, {"score": 0.004250969091124481, "phrase": "gene_function"}, {"score": 0.004061088450663783, "phrase": "high_spatial_resolution"}, {"score": 0.003863568356785813, "phrase": "individual_time"}, {"score": 0.003690927840780375, "phrase": "developmental_gene_expression_patterns"}, {"score": 0.003439117493141663, "phrase": "spatial_and_temporal_dependencies"}, {"score": 0.0032990689963715157, "phrase": "discriminative_undirected_graphical_model"}, {"score": 0.0032581736321024373, "phrase": "gene-expression_time-series_image_data"}, {"score": 0.0031647054743284947, "phrase": "decoding_method"}, {"score": 0.0031125001790084936, "phrase": "junction_tree_algorithm"}, {"score": 0.003010651173285521, "phrase": "effective_feature_selection_technique"}, {"score": 0.002948689937518561, "phrase": "non-parametric_sparse_bayesian_factor_analysis_model"}, {"score": 0.002805121439110729, "phrase": "large-scale_data"}, {"score": 0.0027818804382539444, "phrase": "noisy_incomplete_samples"}, {"score": 0.0026796495639791426, "phrase": "individual_time_points"}, {"score": 0.002591927716261631, "phrase": "gene_expression_patterns"}, {"score": 0.002549146857303602, "phrase": "drosophila_embryonic_development"}, {"score": 0.0024452510143564057, "phrase": "superior_accuracy"}, {"score": 0.0023849523850778807, "phrase": "phenotype_sequences"}, {"score": 0.002335838283092986, "phrase": "previous_models"}, {"score": 0.002249961956629804, "phrase": "experimental_results"}, {"score": 0.002231310272815607, "phrase": "missing_data"}, {"score": 0.0021403407314754637, "phrase": "expression_data"}], "paper_keywords": [""], "paper_abstract": "Motivation: Computational approaches for the annotation of phenotypes from image data have shown promising results across many applications, and provide rich and valuable information for studying gene function and interactions. While data are often available both at high spatial resolution and across multiple time points, phenotypes are frequently annotated independently, for individual time points only. In particular, for the analysis of developmental gene expression patterns, it is biologically sensible when images across multiple time points are jointly accounted for, such that spatial and temporal dependencies are captured simultaneously. Methods: We describe a discriminative undirected graphical model to label gene-expression time-series image data, with an efficient training and decoding method based on the junction tree algorithm. The approach is based on an effective feature selection technique, consisting of a non-parametric sparse Bayesian factor analysis model. The result is a flexible framework, which can handle large-scale data with noisy incomplete samples, i.e. it can tolerate data missing from individual time points. Results: Using the annotation of gene expression patterns across stages of Drosophila embryonic development as an example, we demonstrate that our method achieves superior accuracy, gained by jointly annotating phenotype sequences, when compared with previous models that annotate each stage in isolation. The experimental results on missing data indicate that our joint learning method successfully annotates genes for which no expression data are available for one or more stages.", "paper_title": "Automated annotation of gene expression image sequences via non-parametric factor analysis and conditional random fields", "paper_id": "WOS:000321746100004"}