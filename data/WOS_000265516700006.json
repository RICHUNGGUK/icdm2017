{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "automated_naming"}, {"score": 0.0047057084749407485, "phrase": "tv_video"}, {"score": 0.00436742595270452, "phrase": "tv_or_film_material"}, {"score": 0.0040767015025213625, "phrase": "huge_variation"}, {"score": 0.004030157055463817, "phrase": "imaged_appearance"}, {"score": 0.0038052556098065694, "phrase": "available_annotation"}, {"score": 0.0036553070575015344, "phrase": "high_precision"}, {"score": 0.003531474887552889, "phrase": "multiple_sources"}, {"score": 0.003334309053314909, "phrase": "principal_novelties"}, {"score": 0.003166259444961177, "phrase": "automatic_generation"}, {"score": 0.003094306770612843, "phrase": "character_annotation"}, {"score": 0.0028880836335117297, "phrase": "supervisory_information"}, {"score": 0.002680114113899346, "phrase": "complementary_cues"}, {"score": 0.0025449518236394103, "phrase": "common_annotations"}, {"score": 0.0025158514649823724, "phrase": "face_tracks"}, {"score": 0.0023079225317714815, "phrase": "automatic_extraction"}, {"score": 0.0022815262950738814, "phrase": "training_data"}, {"score": 0.0022424956516376073, "phrase": "weak_textual_annotation"}, {"score": 0.002129356014992349, "phrase": "tv_series"}, {"score": 0.0021049977753042253, "phrase": "buffy_the_vampire_slayer"}], "paper_keywords": ["Video indexing", " Automatic annotation", " Face recognition"], "paper_abstract": "We investigate the problem of automatically labelling appearances of characters in TV or film material with their names. This is tremendously challenging due to the huge variation in imaged appearance of each character and the weakness and ambiguity of available annotation. However, we demonstrate that high precision can be achieved by combining multiple sources of information, both visual and textual. The principal novelties that we introduce are: (i) automatic generation of time stamped character annotation by aligning subtitles and transcripts; (ii) strengthening the supervisory information by identifying when characters are speaking. In addition, we incorporate complementary cues of face matching and clothing matching to propose common annotations for face tracks, and consider choices of classifier which can potentially correct errors made in the automatic extraction of training data from the weak textual annotation. Results are presented on episodes of the TV series \"Buffy the Vampire Slayer\". (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Taking the bite out of automated naming of characters in TV video", "paper_id": "WOS:000265516700006"}