{"auto_keywords": [{"score": 0.048857116898692106, "phrase": "adaptive_integral_method"}, {"score": 0.04521527025313504, "phrase": "aim"}, {"score": 0.00481495049065317, "phrase": "hybrid_message"}, {"score": 0.004770461993586338, "phrase": "memory_parallelization"}, {"score": 0.00466102244911872, "phrase": "multi-core_clusters"}, {"score": 0.004596561972944185, "phrase": "hybrid_message_passing"}, {"score": 0.004554082077300675, "phrase": "shared_memory_parallelization_technique"}, {"score": 0.004247696749118451, "phrase": "fft_based_algorithm"}, {"score": 0.00415019999222481, "phrase": "identical_multi-core_processors"}, {"score": 0.00383508177668219, "phrase": "associated_aim_calculations"}, {"score": 0.0035273744062641636, "phrase": "regular_grid"}, {"score": 0.0034624082435775676, "phrase": "mt_sub-slabs"}, {"score": 0.0033051623473192814, "phrase": "associated_operations"}, {"score": 0.003140509815319442, "phrase": "mpi"}, {"score": 0.0031113369425402287, "phrase": "inter-processor_data_communication"}, {"score": 0.003054009753601139, "phrase": "intra-processor_data_exchange"}, {"score": 0.0028882701690741467, "phrase": "combined-field_integral_equation"}, {"score": 0.0028087949095629955, "phrase": "time-harmonic_electromagnetic_scattering"}, {"score": 0.0025832180231667853, "phrase": "state-of-the-art_multi-core_cluster"}, {"score": 0.0023427844897844093, "phrase": "better_strong_scalability"}, {"score": 0.0022571810910697013, "phrase": "pure_mpi_parallelization"}, {"score": 0.0022155569675462333, "phrase": "multiple_cores"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Adaptive integral method", " Hybrid MPI/OpenMP parallelization", " Multi-core cluster", " Nested one-dimensional slab decomposition", " Latency/grid limited"], "paper_abstract": "A hybrid message passing and shared memory parallelization technique is presented for improving the scalability of the adaptive integral method (AIM), an FFT based algorithm, on clusters of identical multi-core processors. The proposed hybrid MPI/OpenMP parallelization scheme is based on a nested one-dimensional (1-D) slab decomposition of the 3-D auxiliary regular grid and the associated AIM calculations: If there are M processors and T cores per processor, the scheme (i) divides the regular grid into M slabs and MT sub-slabs, (ii) assigns each slab/sub-slab and the associated operations to one of the processors/cores, and (iii) uses MPI for inter-processor data communication and OpenMP for intra-processor data exchange. The MPI/OpenMP parallel AIM is used to accelerate the solution of the combined-field integral equation pertinent to the analysis of time-harmonic electromagnetic scattering from perfectly conducting surfaces. The scalability of the scheme is investigated theoretically and verified on a state-of-the-art multi-core cluster for benchmark scattering problems. Timing and speedup results on up to 1024 quad-core processors show that the hybrid MPI/OpenMP parallelization of AIM exhibits better strong scalability (fixed problem size speedup) than pure MPI parallelization of it when multiple cores are used on each processor. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "A hybrid message passing/shared memory parallelization of the adaptive integral method for multi-core clusters", "paper_id": "WOS:000293323600002"}