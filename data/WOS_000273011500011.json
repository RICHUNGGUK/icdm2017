{"auto_keywords": [{"score": 0.026106522905837096, "phrase": "computed_solution"}, {"score": 0.015658814908887347, "phrase": "mixed_precision_algorithms"}, {"score": 0.015567897632576893, "phrase": "modern_architectures"}, {"score": 0.014348324161023317, "phrase": "resulting_solution"}, {"score": 0.012304096347437727, "phrase": "distributed_program"}, {"score": 0.012232414984934391, "phrase": "test_data"}, {"score": 0.00481495049065317, "phrase": "scientific_computations"}, {"score": 0.0042968467346293105, "phrase": "conventional_processors"}, {"score": 0.004238195927297947, "phrase": "field_programmable_gate_arrays"}, {"score": 0.004196791208444218, "phrase": "graphical_processing_units"}, {"score": 0.004139500454411233, "phrase": "sti_cell_be_processor"}, {"score": 0.0041071132561341876, "phrase": "modern_processor_architectures"}, {"score": 0.00402047071022415, "phrase": "program"}, {"score": 0.003995732624296808, "phrase": "iter-ref_catalogue"}, {"score": 0.0038950035305437, "phrase": "cpc_program_library"}, {"score": 0.0038797328654691233, "phrase": "queen's_university"}, {"score": 0.0038645221252169453, "phrase": "belfast"}, {"score": 0.0038493702169119137, "phrase": "n._ireland"}, {"score": 0.0038192442742880986, "phrase": "standard_cpc"}, {"score": 0.0035724756599249965, "phrase": "tar.gz_programming_language"}, {"score": 0.003441584945933715, "phrase": "external"}, {"score": 0.002999192764694792, "phrase": "single_precision_solution"}, {"score": 0.0029350299322633455, "phrase": "double_precision_accuracy"}, {"score": 0.002906319231856731, "phrase": "common_approach"}, {"score": 0.0028778885712104256, "phrase": "linear_systems"}, {"score": 0.0028163135133300603, "phrase": "lu_factorization"}, {"score": 0.0027997495165900683, "phrase": "coefficient_matrix"}, {"score": 0.002788760858440817, "phrase": "gaussian_elimination"}, {"score": 0.0027614770111595386, "phrase": "coefficient_matrix_a"}, {"score": 0.002718375475165936, "phrase": "lower_triangular_matrix_l"}, {"score": 0.0027023859347223836, "phrase": "upper_triangular_matrix"}, {"score": 0.0026970769588761188, "phrase": "u._partial_row_pivoting"}, {"score": 0.002660204240563, "phrase": "numerical_stability"}, {"score": 0.0026083993945640086, "phrase": "permutation_matrix"}, {"score": 0.0024686373007083676, "phrase": "round-off_errors"}, {"score": 0.002425319963839934, "phrase": "numerical_error"}, {"score": 0.0024063120020918487, "phrase": "condition_number"}, {"score": 0.0023921536224946567, "phrase": "coefficient_matrix_a."}, {"score": 0.0023501751877366764, "phrase": "iterative_process"}, {"score": 0.0022285985654725226, "phrase": "iterative_refinement_algorithm"}, {"score": 0.0021383946795073107, "phrase": "working_precision"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Numerical linear algebra", " Mixed precision", " Iterative refinement"], "paper_abstract": "On modern architectures, the performance of 32-bit operations is often at least twice as fast as the performance of 64-bit operations. By using a combination of 32-bit and 64-bit floating point arithmetic, the performance of many dense and sparse linear algebra algorithms can be significantly enhanced while maintaining the 64-bit accuracy of the resulting solution. The approach presented here can apply not only to conventional processors but also to other technologies such as Field Programmable Gate Arrays (FPGA), Graphical Processing Units (CPU), and the STI Cell BE processor. Results on modern processor architectures and the STI Cell BE are presented. Program summary Program title: ITER-REF Catalogue identifier: AECO_v1_0 Program summary URL: http://cpc.cs.qub.ac.Lik/summaries/AECO-vl-O.html Program obtainable from: CPC Program Library, Queen's University. Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. oflines in distributed program, including test data, etc.: 7211 No. of bytes in distributed program, including test data, etc.: 41862 Distribution format: tar.gz Programming language: FORTRAN 77 Computer: desktop, server Operating system: Unix/Linux RAM: 512 Mbytes Classification: 4.8 External routines: BIAS (optional) Nature of problem: On modern architectures, the performance of 32-bit operations is often at least twice as fast as the performance of 64-bit operations. By using a combination of 32-bit and 64-bit floating point arithmetic, the performance of many dense and sparse linear algebra algorithms can be significantly enhanced while maintaining the 64-bit accuracy of the resulting solution. Solution method: Mixed precision algorithms stem from the observation that, in many cases, a single precision solution of a problem can be refined to the point where double precision accuracy is achieved. A common approach to the solution of linear systems, either dense or sparse, is to perform the LU factorization of the coefficient matrix using Gaussian elimination. First, the coefficient matrix A is factored into the product of a lower triangular matrix L and an upper triangular matrix U. Partial row pivoting is in general used to improve numerical stability resulting in a factorization PA = LU, where P is a permutation matrix. The solution for the system is achieved by first solving Ly = Pb (forward substitution) and then solving Ux = y (backward substitution). Due to round-off errors, the computed solution, x, carries a numerical error magnified by the condition number of the coefficient matrix A. In order to improve the computed solution, an iterative process can be applied, which produces a correction to the computed solution at each iteration. which then yields the method that is commonly known as the iterative refinement algorithm. Provided that the system is not too ill-conditioned, the algorithm produces a solution correct to the working precision. Running time: seconds/minutes Published by Elsevier B.V.", "paper_title": "Accelerating scientific computations with mixed precision algorithms", "paper_id": "WOS:000273011500011"}