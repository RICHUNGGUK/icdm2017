{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "hybrid_image_templates"}, {"score": 0.004738177185041523, "phrase": "information_projection"}, {"score": 0.004647655812642494, "phrase": "novel_framework"}, {"score": 0.004588266612786895, "phrase": "generative_image_representation"}, {"score": 0.00454422099327167, "phrase": "hybrid_image_template"}, {"score": 0.004457388497044933, "phrase": "small_number"}, {"score": 0.004316323233538678, "phrase": "image_examples"}, {"score": 0.0042748769561032325, "phrase": "learned_template"}, {"score": 0.003970013879881066, "phrase": "local_neighborhood"}, {"score": 0.003616303279958699, "phrase": "flatness_regions"}, {"score": 0.0035471385647914775, "phrase": "heterogeneous_patches"}, {"score": 0.003456965170485635, "phrase": "large_pool"}, {"score": 0.00339083755411773, "phrase": "information_projection_framework"}, {"score": 0.003304624380309877, "phrase": "higher_information_gain"}, {"score": 0.0032102434609532888, "phrase": "training_examples"}, {"score": 0.0031286075376993103, "phrase": "negative_examples"}, {"score": 0.002933458667525067, "phrase": "learning_process"}, {"score": 0.002858841145587906, "phrase": "generative_or_discriminative_purpose"}, {"score": 0.0027593227272966186, "phrase": "information_gain"}, {"score": 0.0027327860743648165, "phrase": "statistical_fluctuation"}, {"score": 0.0026632593674563855, "phrase": "well-normalized_probability_model"}, {"score": 0.002629160426591144, "phrase": "heterogeneous_feature_statistics"}, {"score": 0.00260387228762141, "phrase": "automated_feature_selection_procedure"}, {"score": 0.002529454236169383, "phrase": "wide_range"}, {"score": 0.0025132071574192672, "phrase": "image_categories"}, {"score": 0.0024730434312323296, "phrase": "regular_shapes"}, {"score": 0.0024413739512778136, "phrase": "stochastic_texture"}, {"score": 0.002417887626368368, "phrase": "learned_representation"}, {"score": 0.0023946267004932736, "phrase": "intrinsic_characteristics"}, {"score": 0.002371589020876307, "phrase": "object_or_scene_categories"}, {"score": 0.0022742871983734737, "phrase": "classification_performances"}, {"score": 0.0021599821402426013, "phrase": "small_training_sample_sizes"}, {"score": 0.0021254512976941644, "phrase": "proposed_system"}, {"score": 0.0021049977753042253, "phrase": "clear_advantage"}], "paper_keywords": ["Image representation", " deformable templates", " information projection", " visual learning", " statistical modeling"], "paper_abstract": "This paper presents a novel framework for learning a generative image representation-the hybrid image template (HIT) from a small number (i.e., 3 similar to 20) of image examples. Each learned template is composed of, typically, 50 similar to 500 image patches whose geometric attributes (location, scale, orientation) may adapt in a local neighborhood for deformation, and whose appearances are characterized, respectively, by four types of descriptors: local sketch (edge or bar), texture gradients with orientations, flatness regions, and colors. These heterogeneous patches are automatically ranked and selected from a large pool according to their information gains using an information projection framework. Intuitively, a patch has a higher information gain if 1) its feature statistics are consistent within the training examples and are distinctive from the statistics of negative examples (i.e., generic images or examples from other categories); and 2) its feature statistics have less intraclass variations. The learning process pursues the most informative (for either generative or discriminative purpose) patches one at a time and stops when the information gain is within statistical fluctuation. The template is associated with a well-normalized probability model that integrates the heterogeneous feature statistics. This automated feature selection procedure allows our algorithm to scale up to a wide range of image categories, from those with regular shapes to those with stochastic texture. The learned representation captures the intrinsic characteristics of the object or scene categories. We evaluate the hybrid image templates on several public benchmarks, and demonstrate classification performances on par with state-of-the-art methods like HoG+SVM, and when small training sample sizes are used, the proposed system shows a clear advantage.", "paper_title": "Learning Hybrid Image Templates (HIT) by Information Projection", "paper_id": "WOS:000304138300008"}