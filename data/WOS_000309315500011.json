{"auto_keywords": [{"score": 0.04881990207677593, "phrase": "missing_data"}, {"score": 0.03843856552198325, "phrase": "gknn"}, {"score": 0.014977894092235797, "phrase": "minkowski_distance"}, {"score": 0.011100776750824411, "phrase": "gray_distance"}, {"score": 0.00481495049065317, "phrase": "iteratively_knn_imputation"}, {"score": 0.004772367030970874, "phrase": "existing_knn_imputation_methods"}, {"score": 0.004327981760540394, "phrase": "numerical_variables"}, {"score": 0.0038900709793274484, "phrase": "novel_knn"}, {"score": 0.0035118972210075633, "phrase": "k_nearest_neighbors"}, {"score": 0.0033442114331500407, "phrase": "missing_datum"}, {"score": 0.0032561349010603734, "phrase": "distance_metric_methods"}, {"score": 0.003198705576491802, "phrase": "euclidean_distance"}, {"score": 0.0031006232333900055, "phrase": "numerical_and_categorical_attributes"}, {"score": 0.003032405563826263, "phrase": "better_effectiveness"}, {"score": 0.002811464848641341, "phrase": "complete_instances"}, {"score": 0.00260657976055413, "phrase": "proposed_approach"}, {"score": 0.00241658945942583, "phrase": "proximity_relationship"}, {"score": 0.0023113506171584157, "phrase": "mixed_attributes"}, {"score": 0.0022705467477443417, "phrase": "experimental_results"}, {"score": 0.002220551141101661, "phrase": "gknn_algorithm"}, {"score": 0.0021620042653528846, "phrase": "existent_knn_imputation_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Missing data", " k nearest neighbors", " kNN imputation"], "paper_abstract": "Existing kNN imputation methods for dealing with missing data are designed according to Minkowski distance or its variants, and have been shown to be generally efficient for numerical variables (features, or attributes). To deal with heterogeneous (i.e., mixed-attributes) data, we propose a novel kNN (k nearest neighbor) imputation method to iteratively imputing missing data, named GkNN (gray kNN) imputation. GkNN selects k nearest neighbors for each missing datum via calculating the gray distance between the missing datum and all the training data rather than traditional distance metric methods, such as Euclidean distance. Such a distance metric can deal with both numerical and categorical attributes. For achieving the better effectiveness, GkNN regards all the imputed instances (i.e., the missing data been imputed) as observed data, which with complete instances (instances without missing values) together to iteratively impute other missing data. We experimentally evaluate the proposed approach, and demonstrate that the gray distance is much better than the Minkowski distance at both capturing the proximity relationship (or nearness) of two instances and dealing with mixed attributes. Moreover, experimental results also show that the GkNN algorithm is much more efficient than existent kNN imputation methods. (c) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Nearest neighbor selection for iteratively kNN imputation", "paper_id": "WOS:000309315500011"}