{"auto_keywords": [{"score": 0.028158187282501485, "phrase": "np"}, {"score": 0.00481495049065317, "phrase": "one-dimensional_interval_data"}, {"score": 0.004610058444728656, "phrase": "upper_and_lower_limits"}, {"score": 0.0045108906244892165, "phrase": "possible_values"}, {"score": 0.004244375827831527, "phrase": "well-known_statistics"}, {"score": 0.0032546105164772995, "phrase": "polynomial_time"}, {"score": 0.00321236577162671, "phrase": "new_efficient_algorithm"}, {"score": 0.0030888830649190282, "phrase": "complementary_np-hardness_results"}, {"score": 0.002843519597398796, "phrase": "np-hardness_results"}, {"score": 0.0027104531025934865, "phrase": "even_an_approximate_evaluation"}, {"score": 0.002675252546913683, "phrase": "arbitrary_absolute_error"}, {"score": 0.0023886641270884973, "phrase": "new_pseudopolynomial_algorithm"}, {"score": 0.0023068049914566975, "phrase": "practical_importance"}, {"score": 0.0021607883988873492, "phrase": "\"excessively\"_large_numbers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Interval data", " t-ratio", " Computational complexity", " NP-hardness", " Inapproximability", " Pseudopolynomial algorithms"], "paper_abstract": "The main question is how to compute the upper and lower limits of the range of possible values of a given statistic, when the data range over given intervals. Initially some well-known statistics, such as sample mean, sample variance or F-ratio, are considered in order to illustrate that in some cases the limits can be computed efficiently, while in some cases their computation is NP-hard. Subsequently, the t-ratio (variation coefficient) is considered. It is investigated when the limits for t-ratio are computable in polynomial time and a new efficient algorithm is designed for this case. Conversely, complementary NP-hardness results are proved, demonstrating the cases when the computation cannot be done efficiently. Subsequently, the NP-hardness results are strengthened: it is shown that under certain assumptions, even an approximate evaluation with an arbitrary absolute error is NP-hard. Finally, it is shown that the situation can also be (in some sense) regarded positively: a new pseudopolynomial algorithm is developed. The algorithm is of practical importance, especially when the dataset to be processed is large and does not contain \"excessively\" large numbers. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "The complexity of computation and approximation of the t-ratio over one-dimensional interval data", "paper_id": "WOS:000341346300003"}