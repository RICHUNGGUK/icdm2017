{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "unlabeled_data"}, {"score": 0.04336705121455173, "phrase": "multi-class_cases"}, {"score": 0.004749646583168342, "phrase": "semi-supervised_learning"}, {"score": 0.004590217765551337, "phrase": "pattern_recognition"}, {"score": 0.004527947981009528, "phrase": "machine_learning"}, {"score": 0.003613899384402803, "phrase": "semi-supervised_learning_method"}, {"score": 0.003516417950483685, "phrase": "multi-class_boosting"}, {"score": 0.003352088714126572, "phrase": "multi-class_data"}, {"score": 0.003284026247389735, "phrase": "high_classification_accuracy"}, {"score": 0.002825251837733693, "phrase": "multiple_two-class_problems"}, {"score": 0.002285216591220303, "phrase": "experimental_results"}, {"score": 0.0022234951091677085, "phrase": "proposed_method"}], "paper_keywords": ["Semi-supervised learning", " J48 Decision Tree", " Naive Bayes classifier", " Unlabeled data"], "paper_abstract": "Semi-supervised learning has attracted much attention in pattern recognition and machine learning. Most semi-supervised learning algorithms are proposed for binary classification, and then extended to multi-class cases by using approaches such as one-against-the-rest. In this work, we propose a semi-supervised learning method by using the multi-class boosting, which can directly classify the multi-class data and achieve high classification accuracy by exploiting the unlabeled data. There are two distinct features in our proposed semi-supervised learning approach: (1) handling multi-class cases directly without reducing them to multiple two-class problems, and (2) the classification accuracy of each base classifier requiring only at least 1/K or better than 1/K (K is the number of classes). Experimental results show that the proposed method is effective based on the testing of 21 UCI benchmark data sets. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Semi-supervised multi-class Adaboost by exploiting unlabeled data", "paper_id": "WOS:000288343900038"}