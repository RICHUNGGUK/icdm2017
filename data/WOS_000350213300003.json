{"auto_keywords": [{"score": 0.044623380435940996, "phrase": "multiple_features"}, {"score": 0.015026270193234905, "phrase": "gaussian_process"}, {"score": 0.006200194264429483, "phrase": "large-margin_principle"}, {"score": 0.004816142792542206, "phrase": "gaussian"}, {"score": 0.0047057084749407485, "phrase": "image_classification"}, {"score": 0.003916098498242888, "phrase": "classification_accuracy"}, {"score": 0.0037188360359702182, "phrase": "new_problems"}, {"score": 0.0034512514926836667, "phrase": "high-dimensional_features"}, {"score": 0.003334309053314909, "phrase": "small_training"}, {"score": 0.0031481164109237636, "phrase": "large-margin_idea"}, {"score": 0.0030239842475439814, "phrase": "latent_subspace"}, {"score": 0.002758273619951683, "phrase": "probabilistic_explanation"}, {"score": 0.0026041635822373265, "phrase": "shared_low-dimensional_subspace"}, {"score": 0.002530359917257626, "phrase": "strong_discriminative_ability"}, {"score": 0.002402731767209114, "phrase": "subsequent_classification_task"}, {"score": 0.0022168460543913787, "phrase": "proposed_algorithm"}, {"score": 0.002191489192077851, "phrase": "real-world_image_datasets"}, {"score": 0.0021539955106204354, "phrase": "discriminative_latent_subspace"}, {"score": 0.0021049977753042253, "phrase": "classification_performance"}], "paper_keywords": ["Multi-view learning", " Large margin", " Gaussian process"], "paper_abstract": "In image classification, the goal was to decide whether an image belongs to a certain category or not. Multiple features are usually employed to comprehend the contents of images substantially for the improvement of classification accuracy. However, it also brings in some new problems that how to effectively combine multiple features together and how to handle the high-dimensional features from multiple views given the small training set. In this paper, we integrate the large-margin idea into the Gaussian process to discover the latent subspace shared by multiple features. Therefore, our approach inherits all the advantages of Gaussian process and large-margin principle. A probabilistic explanation is provided by Gaussian process to embed multiple features into the shared low-dimensional subspace, which derives a strong discriminative ability from the large-margin principle, and thus, the subsequent classification task can be effectively accomplished. Finally, we demonstrate the advantages of the proposed algorithm on real-world image datasets for discovering discriminative latent subspace and improving the classification performance.", "paper_title": "Large-margin multi-view Gaussian process", "paper_id": "WOS:000350213300003"}