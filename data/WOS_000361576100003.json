{"auto_keywords": [{"score": 0.037897220781069975, "phrase": "rrmcc"}, {"score": 0.0187521249267669, "phrase": "rmvdr_spectrum_estimator"}, {"score": 0.01675735249678729, "phrase": "nrmcc"}, {"score": 0.00481495049065317, "phrase": "robust_continuous_speech_recognition"}, {"score": 0.004716215351463082, "phrase": "robust_feature_extractors"}, {"score": 0.004667606070383657, "phrase": "regularized_minimum_variance_distortionless_response"}, {"score": 0.004548921891850394, "phrase": "fourier"}, {"score": 0.004397625983080243, "phrase": "conventional_mfcc"}, {"score": 0.004341023905716924, "phrase": "speech_power_spectrum"}, {"score": 0.004318586703426523, "phrase": "direct_spectrum_estimators"}, {"score": 0.004219039749566144, "phrase": "high_variance"}, {"score": 0.004153947871210216, "phrase": "noisy_and_adverse_conditions"}, {"score": 0.0041004692702610365, "phrase": "performance_drop"}, {"score": 0.004016326119656517, "phrase": "speech_recognition_systems"}, {"score": 0.0039034303042299327, "phrase": "regularized_mvdr_technique"}, {"score": 0.0038531644281313056, "phrase": "low_spectral_variance"}, {"score": 0.003725470458263889, "phrase": "robust_acoustic_front-ends"}, {"score": 0.0036679653799542114, "phrase": "mvdr-based_cepstral_coefficients"}, {"score": 0.0036207206487324506, "phrase": "robust_rmvdr_cepstral_coefficients"}, {"score": 0.0035740822639305767, "phrase": "normalized_rmvdr_cepstral_coefficients"}, {"score": 0.003428824706964939, "phrase": "auditory_domain_spectrum_enhancement_methods"}, {"score": 0.0033758909010472744, "phrase": "ase"}, {"score": 0.0031969216992345974, "phrase": "feature_extraction_method"}, {"score": 0.0031803790636361273, "phrase": "experimental_speech_recognition_results"}, {"score": 0.0030828999299145365, "phrase": "mel_frequency_cepstral_coefficients"}, {"score": 0.003011753695038325, "phrase": "plp"}, {"score": 0.002949887119720528, "phrase": "mfcc"}, {"score": 0.0029270106140058825, "phrase": "mvdr"}, {"score": 0.002679824306876977, "phrase": "robust_feature_extractor"}, {"score": 0.0026659517169968527, "phrase": "rfe"}, {"score": 0.0026452734009203764, "phrase": "alam_et_al"}, {"score": 0.0026043982852389227, "phrase": "experimental_results"}, {"score": 0.00257749879848061, "phrase": "proposed_robust_feature_extractors"}, {"score": 0.0025049455849056965, "phrase": "percentage_word_error_rate"}, {"score": 0.002447101794397243, "phrase": "clean_and_multi-condition_training_conditions"}, {"score": 0.0023536415128806655, "phrase": "significant_reductions"}, {"score": 0.0023414522240150287, "phrase": "word_error_rate"}, {"score": 0.0022873751378897364, "phrase": "multi-condition_training"}, {"score": 0.0022696277881969896, "phrase": "rmcc"}, {"score": 0.002194296665270526, "phrase": "average_word_error_rate"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Speech recognition", " Robust feature extraction", " Regularized MVDR", " ASE", " Feature normalization", " Multi-condition training"], "paper_abstract": "In this paper, we present robust feature extractors that incorporate a regularized minimum variance distortionless response (RMVDR) spectrum estimator instead of the discrete Fourier transform-based direct spectrum estimator, used in many front-ends including the conventional MFCC, to estimate the speech power spectrum. Direct spectrum estimators, e.g., single tapered periodogram, have high variance and they perform poorly under noisy and adverse conditions. To reduce this performance drop we propose to increase the robustness of speech recognition systems by extracting features that are more robust based on the regularized MVDR technique. The RMVDR spectrum estimator has low spectral variance and is robust to mismatch conditions. Based on the RMVDR spectrum estimator, robust acoustic front-ends, namely, are regularized MVDR-based cepstral coefficients (RMCC), robust RMVDR cepstral coefficients (RRMCC) and normalized RMVDR cepstral coefficients (NRMCC). In addition to the RMVDR spectrum estimator, RRMCC and NRMCC also utilize auditory domain spectrum enhancement methods, auditory spectrum enhancement (ASE) and medium duration power bias subtraction (MDPBS) techniques, respectively, to improve the robustness of the feature extraction method. Experimental speech recognition results are conducted on the AURORA-4 large vocabulary continuous speech recognition corpus and performances are compared with the Mel frequency cepstral coefficients (MFCC), perceptual linear prediction (PLP), MVDR spectrum estimator-based MFCC, perceptual MVDR (PMVDR), cochlear filterbank cepstral coefficients (CFCC), power normalized cepstral coefficients (PNCC), ETSI advancement front-end (ETSI-AFE), and the robust feature extractor (RFE) of Alam et al. (2012). Experimental results demonstrate that the proposed robust feature extractors outperformed the other robust front-ends in terms of percentage word error rate on the AURORA-4 large vocabulary continuous speech recognition (LVCSR) task under clean and multi-condition training conditions. In clean training conditions, on average, the RRMCC and NRMCC provide significant reductions in word error rate over the rest of the front-ends. In multi-condition training, the RMCC, RRMCC, and NRMCC perform slightly better in terms of the average word error rate than the rest of the front-ends used in this work. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Regularized minimum variance distortionless response-based cepstral features for robust continuous speech recognition", "paper_id": "WOS:000361576100003"}