{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "recurrent_neural_networks"}, {"score": 0.004674952036988355, "phrase": "multiple_discrete_delays"}, {"score": 0.003378385493203297, "phrase": "discrete_time-varying_delays"}, {"score": 0.0032319109979344184, "phrase": "time-varying_delays"}, {"score": 0.003091767402370757, "phrase": "sufficient_conditions"}, {"score": 0.0028293966058473476, "phrase": "global_asymptotical_stability"}, {"score": 0.00266693888510356, "phrase": "mixed_time-varying_delay"}, {"score": 0.002551231163230566, "phrase": "proposed_lmi_result"}, {"score": 0.0021682027434117095, "phrase": "standard_commercial_software"}], "paper_keywords": ["discrete delays", " distributed delays", " global asymptotical stability", " linear matrix inequality (LMI)", " recurrent neural networks (RNNs)", " time-varying delays"], "paper_abstract": "By employing the Lyapunov-Krasovskii functional and linear matrix inequality (LMI) approach, the problem of global asymptotical stability is studied for recurrent neural networks with both discrete time-varying delays and distributed time-varying delays. Some sufficient conditions are given for checking the global asymptotical stability of recurrent neural networks with mixed time-varying delay. The proposed LMI result is computationally efficient as it can be solved numerically using standard commercial software. Two examples are given to show the usefulness of the results.", "paper_title": "Global asymptotical stability of recurrent neural networks with multiple discrete delays and distributed delays", "paper_id": "WOS:000241933100028"}