{"auto_keywords": [{"score": 0.03417212975519707, "phrase": "boolean"}, {"score": 0.005849641217795986, "phrase": "theoreticians"}, {"score": 0.00481495049065317, "phrase": "evolutionary_program_induction"}, {"score": 0.004737579882204798, "phrase": "evolutionary_computation_techniques"}, {"score": 0.004661446705304497, "phrase": "considerable_popularity"}, {"score": 0.0043512358455892, "phrase": "exact_and_approximate_models"}, {"score": 0.0043161190928529755, "phrase": "evolutionary_program_induction_algorithms"}, {"score": 0.004078078530972285, "phrase": "simplistic_problems"}, {"score": 0.004012500850311087, "phrase": "unrealistic_parameters"}, {"score": 0.0036553070575015344, "phrase": "program_induction_systems"}, {"score": 0.0035100601949451028, "phrase": "simple_and_practical_model"}, {"score": 0.003439608110599787, "phrase": "program-induction_algorithms"}, {"score": 0.0031459887611258765, "phrase": "different_versions"}, {"score": 0.003120568497402472, "phrase": "genetic_programming"}, {"score": 0.0030953529970646626, "phrase": "gene_expression_programming"}, {"score": 0.003070340620983981, "phrase": "stochastic_iterated_hill"}, {"score": 0.00303319936111073, "phrase": "program_space"}, {"score": 0.0028425481299483254, "phrase": "training_algorithm"}, {"score": 0.0028195727965553367, "phrase": "artificial_neural_networks"}, {"score": 0.002762941385784905, "phrase": "off-line_bin_packing_problem"}, {"score": 0.0026638482306228575, "phrase": "accurate_predictions"}, {"score": 0.0025578967205807843, "phrase": "different_algorithms"}, {"score": 0.0025167026017217926, "phrase": "different_parameters"}, {"score": 0.002436289099444074, "phrase": "automatic_construction"}, {"score": 0.0023776656246300063, "phrase": "stochastic_program-induction_algorithms"}, {"score": 0.0022923586577645143, "phrase": "important_features"}, {"score": 0.0022371907579775796, "phrase": "performance_point"}, {"score": 0.0021569129153653777, "phrase": "ordinary_experimentation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Evolution algorithms", " Program induction", " Performance prediction", " Algorithm taxonomies", " Algorithm selection problem"], "paper_abstract": "Evolutionary computation techniques have seen a considerable popularity as problem solving and optimisation tools in recent years. Theoreticians have developed a variety of both exact and approximate models for evolutionary program induction algorithms. However, these models are often criticised for being only applicable to simplistic problems or algorithms with unrealistic parameters. In this paper, we start rectifying this situation in relation to what matters the most to practitioners and users of program induction systems: performance. That is, we introduce a simple and practical model for the performance of program-induction algorithms. To test our approach, we consider two important classes of problems - symbolic regression and Boolean function induction - and we model different versions of genetic programming, gene expression programming and stochastic iterated hill climbing in program space. We illustrate the generality of our technique by also accurately modelling the performance of a training algorithm for artificial neural networks and two heuristics for the off-line bin packing problem. We show that our models, besides performing accurate predictions, can help in the analysis and comparison of different algorithms and/or algorithms with different parameters setting. We illustrate this via the automatic construction of a taxonomy for the stochastic program-induction algorithms considered in this study. The taxonomy reveals important features of these algorithms from the performance point of view, which are not detected by ordinary experimentation. (c) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Practical performance models of algorithms in evolutionary program induction and other domains", "paper_id": "WOS:000281987600006"}