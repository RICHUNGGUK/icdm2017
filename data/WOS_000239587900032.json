{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "novel_framework"}, {"score": 0.004508661664944657, "phrase": "online_learning_algorithms"}, {"score": 0.004182301599359094, "phrase": "constrained_optimization"}, {"score": 0.003916098498242888, "phrase": "universal_online_bounds"}, {"score": 0.003807242767474929, "phrase": "optimization_problem"}, {"score": 0.0036667768092524576, "phrase": "weak_duality_theorem"}, {"score": 0.0034657012607680203, "phrase": "online_learning"}, {"score": 0.0032145922365231093, "phrase": "dual_objective_function"}, {"score": 0.0030097975788892896, "phrase": "dual_increases"}, {"score": 0.0028986672783671147, "phrase": "new_and_natural_notion"}, {"score": 0.002613709503583786, "phrase": "primal_objective_value"}, {"score": 0.002493592357827492, "phrase": "prediction_mistakes"}, {"score": 0.0022696277881969896, "phrase": "end_result"}, {"score": 0.0022064376000055764, "phrase": "general_framework"}, {"score": 0.0021049977753042253, "phrase": "old_and_new_online_learning_algorithms"}], "paper_keywords": [""], "paper_abstract": "We describe a novel framework for the design and analysis of online learning algorithms based on the notion of duality in constrained optimization. We cast a sub-family of universal online bounds as an optimization problem. Using the weak duality theorem we reduce the process of online learning to the task of incrementally increasing the dual objective function. The amount by which the dual increases serves as a new and natural notion of progress. We are thus able to tie the primal objective value and the number of prediction mistakes using and the increase in the dual. The end result is a general framework for designing and analyzing old and new online learning algorithms in the mistake bound model.", "paper_title": "Online learning meets optimization in the dual", "paper_id": "WOS:000239587900032"}