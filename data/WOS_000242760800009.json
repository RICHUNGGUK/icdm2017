{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "context-dependent_visemes"}, {"score": 0.004661446705304497, "phrase": "novel_approach"}, {"score": 0.004537254814246843, "phrase": "realistic_speech"}, {"score": 0.004392565073466714, "phrase": "anticipatory_and_perseveratory_coarticulation"}, {"score": 0.004116823963855969, "phrase": "fiduciary_points"}, {"score": 0.003964007795174772, "phrase": "real_speaker"}, {"score": 0.003900257249255497, "phrase": "speech_production"}, {"score": 0.00385832528624328, "phrase": "cvcv_non-sense_words"}, {"score": 0.0037150687722055727, "phrase": "standard_video_sequences"}, {"score": 0.003675120438902734, "phrase": "stereo_vision_photogrammetric_techniques"}, {"score": 0.0036159990127332315, "phrase": "first_stationary_point"}, {"score": 0.0034817084307034955, "phrase": "phonetic_segment"}, {"score": 0.003298441494378465, "phrase": "geometric_similarity"}, {"score": 0.0032629585038738856, "phrase": "articulatory_targets"}, {"score": 0.0031759067385562553, "phrase": "different_phonetic_contexts"}, {"score": 0.0030911702059432224, "phrase": "phonetic_context-dependent_visemes"}, {"score": 0.002685558057339722, "phrase": "temporomandibular_joint"}, {"score": 0.0024231382864800173, "phrase": "opening_width"}, {"score": 0.00235843888868088, "phrase": "natural_articulation"}, {"score": 0.002234165013865669, "phrase": "synchronized_animation"}, {"score": 0.002198173002125909, "phrase": "natural_and_synthetic_speech"}, {"score": 0.0021049977753042253, "phrase": "speech_synthesizer"}], "paper_keywords": ["facial animation", " speech synchronized facial animation", " visual speech synthesis", " visemes", " coarticulation"], "paper_abstract": "This paper presents a novel approach for the generation of realistic speech synchronized 3D facial animation that copes with anticipatory and perseveratory coarticulation. The methodology is based on the measurement of 3D trajectories of fiduciary points marked on the face of a real speaker during the speech production of CVCV non-sense words. The trajectories are measured from standard video sequences using stereo vision photogrammetric techniques. The first stationary point of each trajectory associated with a phonetic segment is selected as its articulatory target. By clustering according to geometric similarity all articulatory targets of a same segment in different phonetic contexts, a set of phonetic context-dependent visemes accounting for coarticulation is identified. These visemes are then used to drive a set of geometric transformation/deformation models that reproduce the rotation and translation of the temporomandibular joint on the 3D virtual face, as well as the behavior of the lips, such as protrusion, and opening width and height of the natural articulation. This approach is being used to generate 3D speech synchronized animation from both natural and synthetic speech generated by a text-to-speech synthesizer. (c) 2006 Elsevier Ltd. All rights reserved.", "paper_title": "Facial animation based on context-dependent visemes", "paper_id": "WOS:000242760800009"}