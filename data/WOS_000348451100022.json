{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "prosodic_features"}, {"score": 0.004762202897268383, "phrase": "voice-based_biometric_security_systems"}, {"score": 0.0045820747375409435, "phrase": "promising_performance"}, {"score": 0.004218602458288531, "phrase": "test_data_exhibit"}, {"score": 0.0039269071382230444, "phrase": "emotional_states"}, {"score": 0.003841263262252044, "phrase": "testing_speech"}, {"score": 0.003757480190200645, "phrase": "different_modeling_strategies"}, {"score": 0.003516898780234098, "phrase": "training_stage"}, {"score": 0.003459191419478298, "phrase": "mandarin-based_speaker_recognition_system"}, {"score": 0.0032021226849872054, "phrase": "limited_affective_speech"}, {"score": 0.0031495640320537283, "phrase": "training_speeches"}, {"score": 0.0029805015010906013, "phrase": "prosodic_variations"}, {"score": 0.002947790697936243, "phrase": "multiple_models"}, {"score": 0.002851790448644913, "phrase": "clustered_speech"}, {"score": 0.002758907973783665, "phrase": "prosodic_differences"}, {"score": 0.0025537472239953807, "phrase": "fundamental_frequencies"}, {"score": 0.0025257081555100556, "phrase": "energy_contours"}, {"score": 0.0023900527169254744, "phrase": "mandarin_affective_speech_corpus"}, {"score": 0.0022994427535192514, "phrase": "recognition_rate"}, {"score": 0.0022368274529152342, "phrase": "traditional_speaker_verification_tasks"}, {"score": 0.0021049977753042253, "phrase": "structural_training-based_systems"}], "paper_keywords": ["Speaker recognition", " Emotional speech clustering", " Prosodic features"], "paper_abstract": "Voice-based biometric security systems involving only neutral speech have achieved promising performance. However, the speakers are very likely to fail the recognition when the test data exhibit multiple emotions. This paper aimed to address the mismatch of the emotional states between training and testing speech. We discuss different modeling strategies that incorporate the emotions (affects) of speakers into the training stage of a Mandarin-based speaker recognition system and propose an alternative approach, which could optimize the utilization of the limited affective speech. The training speeches are partitioned and clustered by the trends of the prosodic variations. Multiple models are built based on the clustered speech for a given speaker. The prosodic differences are characterized by a combination of features that describe the changes of the fundamental frequencies and energy contours. The experiments were carried out based on the Mandarin Affective Speech Corpus. The result shows 73.37 % improvement in recognition rate over that of the traditional speaker verification tasks relatively and also achieves 63.53 % higher in performance over the structural training-based systems relatively.", "paper_title": "Affect-insensitive speaker recognition systems via emotional speech clustering using prosodic features", "paper_id": "WOS:000348451100022"}