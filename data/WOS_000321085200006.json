{"auto_keywords": [{"score": 0.04504506847018902, "phrase": "proposed_estimation_method"}, {"score": 0.03515585983779111, "phrase": "sample_size"}, {"score": 0.03306276254513539, "phrase": "adaptive_lasso"}, {"score": 0.00481495049065317, "phrase": "high-dimensional_partially_linear_additive_models"}, {"score": 0.004683540676363745, "phrase": "new_estimation_procedure"}, {"score": 0.004610058444728656, "phrase": "composite_quantile_regression"}, {"score": 0.0045198174374297285, "phrase": "semiparametric_additive_partial_linear_models"}, {"score": 0.00443133501650381, "phrase": "nonparametric_components"}, {"score": 0.004361792415184563, "phrase": "polynomial_splines"}, {"score": 0.004078157608867258, "phrase": "error_distributions"}, {"score": 0.0038584250641318057, "phrase": "popular_least-squares-based_estimation_method"}, {"score": 0.0037087324991876727, "phrase": "cauchy_error"}, {"score": 0.003607404191062938, "phrase": "normal_random_errors"}, {"score": 0.003522749900725601, "phrase": "high-dimensional_and_sparse_additive_partial_linear_models"}, {"score": 0.0032804824152243106, "phrase": "significant_covariates"}, {"score": 0.00316565009987584, "phrase": "variable_selection_procedure"}, {"score": 0.003042752533935891, "phrase": "variable_selection"}, {"score": 0.0029246121262946384, "phrase": "oracle_property"}, {"score": 0.0028110458014332187, "phrase": "least-squares-based_method"}, {"score": 0.0027668603377225564, "phrase": "random_error_distributions"}, {"score": 0.0025462137546846154, "phrase": "lasso"}, {"score": 0.0025259082947443343, "phrase": "composite_quantile_regression_estimates"}, {"score": 0.0023334673218688437, "phrase": "significant_variables"}, {"score": 0.0023058910418682676, "phrase": "simulation_results"}, {"score": 0.0022606512324475584, "phrase": "theoretical_properties"}, {"score": 0.0022339335462778437, "phrase": "real_data_example"}, {"score": 0.002155656133617155, "phrase": "proposed_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Adaptive Lasso", " Composite quantile regression", " High-dimension", " Semiparametric additive partial linear model", " Spline approximation", " Variable selection"], "paper_abstract": "A new estimation procedure based on the composite quantile regression is proposed for the semiparametric additive partial linear models, of which the nonparametric components are approximated by polynomial splines. The proposed estimation method can simultaneously estimate both the parametric regression coefficients and nonparametric components without any specification of the error distributions. The proposed estimation method is empirically shown to be much more efficient than the popular least-squares-based estimation method for non-normal random errors, especially for Cauchy error, and almost as efficient for normal random errors. To achieve sparsity in high-dimensional and sparse additive partial linear models, of which the number of linear covariates is much larger than the sample size but that of significant covariates is small relative to the sample size, a variable selection procedure based on adaptive Lasso is proposed to conduct estimation and variable selection simultaneously. The procedure is shown to possess the oracle property, and is much superior to the adaptive Lasso penalized least-squares-based method regardless of the random error distributions. In particular, two kinds of weights in the penalty are considered, namely the composite quantile regression estimates and Lasso penalized composite quantile regression estimates. Both types of weights perform very well with the latter performing especially well in terms of precisely selecting significant variables. The simulation results are consistent with the theoretical properties. A real data example is used to illustrate the application of the proposed methods. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Variable selection in high-dimensional partially linear additive models for composite quantile regression", "paper_id": "WOS:000321085200006"}