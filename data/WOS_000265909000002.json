{"auto_keywords": [{"score": 0.045889715318462816, "phrase": "bpn"}, {"score": 0.02137589479454487, "phrase": "high_order_connections"}, {"score": 0.02039331627153816, "phrase": "hhonn"}, {"score": 0.00481495049065317, "phrase": "neural_networks"}, {"score": 0.004690952711665194, "phrase": "familiar_artificial_intelligence_approach"}, {"score": 0.004530552828603269, "phrase": "wide_range"}, {"score": 0.00443308765153716, "phrase": "back_propagation_network"}, {"score": 0.004099183062034004, "phrase": "error_back_propagation_learning_algorithm"}, {"score": 0.004010960493946656, "phrase": "associate_multiplicative_weightings"}, {"score": 0.003976203286249396, "phrase": "layer_connections"}, {"score": 0.003924629168434799, "phrase": "single_connections"}, {"score": 0.0038568987435766014, "phrase": "neuron_inputs"}, {"score": 0.003806866174028117, "phrase": "neuron_outputs"}, {"score": 0.0035199625749545616, "phrase": "bpn."}, {"score": 0.0034894451015047875, "phrase": "resultant_proposed_hybrid_high_order_neural_network"}, {"score": 0.0032263862712733934, "phrase": "additional_connection_type"}, {"score": 0.0030888830649190282, "phrase": "different_scenarios"}, {"score": 0.002843519597398796, "phrase": "feedforward_neural_network"}, {"score": 0.002663620639539737, "phrase": "improved_performance"}, {"score": 0.002640507929183363, "phrase": "developed_hhonn_models"}, {"score": 0.0026175952455594277, "phrase": "case_studies"}, {"score": 0.0025062312601757944, "phrase": "tc"}, {"score": 0.002462664392109308, "phrase": "squat_wall_strength_learning"}, {"score": 0.0023990982005125763, "phrase": "hhonn_performance"}, {"score": 0.0023168823213024856, "phrase": "high_order_connection"}, {"score": 0.002257070536352418, "phrase": "eventual_connection"}, {"score": 0.002218054404179068, "phrase": "better_results"}, {"score": 0.0021797112385590913, "phrase": "traditional_bpn._such_results"}], "paper_keywords": ["Artificial intelligence", " High order", " Back propagation networks", " Exponent multiplier", " Neural networks"], "paper_abstract": "Neural networks (NNs) represent a familiar artificial intelligence approach widely applied in many fields and to a wide range of issues. The back propagation network (BPN) is one of the most well-known NNs, comprising multilayer perceptrons (MLPs) with an error back propagation learning algorithm. BPN typically employs associate multiplicative weightings for layer connections. For single connections, BPN combines neuron inputs linearly to neuron outputs. In this study, the author develops and embeds high order connections (exponent multipliers) into the BPN. The resultant proposed hybrid high order neural network (HHONN) is intended to be applicable to both linear and high order connections. HHONN allows an additional connection type for BPN, which permits BPN to adapt to different scenarios. In this paper, learning equations for both weighting and high order connections are introduced in their general forms. A feedforward neural network with a topology of two hidden layers and one high order connection was developed and studied to confirm the improved performance of developed HHONN models. Case studies, including two basic tests (a function approximation and the TC problem) and squat wall strength learning, were used to verify HHONN performance. Results showed that, when the high order connection was employed anywhere except the eventual connection, HHONN delivered better results than achievable using traditional BPN. Such results show that HHONN successfully introduces high order connections into BPN. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Hybrid high order neural networks", "paper_id": "WOS:000265909000002"}