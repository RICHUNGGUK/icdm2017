{"auto_keywords": [{"score": 0.03876199044309078, "phrase": "renyi"}, {"score": 0.00481495049065317, "phrase": "high-dimensional_patterns"}, {"score": 0.00466085208934021, "phrase": "novel_feature_selection_filter"}, {"score": 0.004395742407834023, "phrase": "efficient_estimation"}, {"score": 0.004310752197635499, "phrase": "mutual_information"}, {"score": 0.004227398267369744, "phrase": "high-dimensional_set"}, {"score": 0.0038843558517333327, "phrase": "probability_density_function"}, {"score": 0.003735522846193052, "phrase": "entropic-graphs_approximation"}, {"score": 0.003477264432055326, "phrase": "shannon_entropy"}, {"score": 0.002543224008253855, "phrase": "greedy_algorithm"}, {"score": 0.002477753633057247, "phrase": "maximal_relevance"}, {"score": 0.0024456516553345966, "phrase": "minimal_redundancy_criterion"}, {"score": 0.0022763657774198184, "phrase": "image_classification"}, {"score": 0.0022468671200629024, "phrase": "microarray_data_classification"}, {"score": 0.002160640052461594, "phrase": "tested_data_sets"}, {"score": 0.0021049977753042253, "phrase": "better_classification_results"}], "paper_keywords": ["filter feature selection", " mutual information", " entropic spanning graphs", " microarray"], "paper_abstract": "We propose a novel feature selection filter for supervised learning, which relies on the efficient estimation of the mutual information between a high-dimensional set of features and the classes. We bypass the estimation of the probability density function with the aid of the entropic-graphs approximation of Renyi entropy, and the subsequent approximation of the Shannon entropy. Thus, the complexity does not depend on the number of dimensions but on the number of patterns/samples, and the curse of dimensionality is circumvented. We show that it is then possible to outperform algorithms which individually rank features, as well as a greedy algorithm based on the maximal relevance and minimal redundancy criterion. We successfully test our method both in the contexts of image classification and microarray data classification. For most of the tested data sets, we obtain better classification results than those reported in the literature.", "paper_title": "Feature selection, mutual information, and the classification of high-dimensional patterns", "paper_id": "WOS:000258579900008"}