{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "mei"}, {"score": 0.022806837159791912, "phrase": "text-augmented_social_networks"}, {"score": 0.00477924690801092, "phrase": "mutual_enhanced_infinite_community-topic_model"}, {"score": 0.0041642891310893, "phrase": "inherent_difference"}, {"score": 0.0035744997458371335, "phrase": "community-topic_distribution"}, {"score": 0.00353476609156032, "phrase": "mutual_enhancement_effect"}, {"score": 0.002977835845437357, "phrase": "hierarchical_dirichlet_process_mixture"}, {"score": 0.0026330549554033876, "phrase": "community_inference"}, {"score": 0.0025844090835070986, "phrase": "co-author_network"}, {"score": 0.0025272158996086378, "phrase": "dblp_data"}, {"score": 0.00247128526955136, "phrase": "baseline_models"}, {"score": 0.0024256208351516027, "phrase": "generalization_performance"}, {"score": 0.0024075916292945715, "phrase": "parameter_study"}, {"score": 0.002217880187104576, "phrase": "low_weight"}, {"score": 0.0021049977753042253, "phrase": "appropriate_numbers"}], "paper_keywords": ["mutual enhanced infinite community-topic model", " community", " topic", " Dirichlet process", " Gibbs sampling"], "paper_abstract": "The community and the topic can help summarize the text-augmented social networks. Existing works mixed up the community and the topic by regarding them as the same. However, there is an inherent difference between the community and the topic such that considering them as the same is not so flexible. We propose a mutual enhanced infinite (MEI) community-topic model to detect communities and topics simultaneously in text-augmented social networks. The community and the topic are correlated via a community-topic distribution. The mutual enhancement effect between the community and the topic is validated by introducing two novel measures perplexity with community (perplexity(c)) and mean of the rank (MRK) with topic (MRKt). To determine the numbers of communities and topics automatically, the Dirichlet Process Mixture (DPM) model and the Hierarchical Dirichlet Process mixture (HDP) model are used to model the community and the topic, respectively. We further introduce parameters to model the weight of the community and the topic responsible for community inference. Experiments on the co-author network built from a subset of DBLP data show that MEI outperforms the baseline models in terms of the generalization performance. Parameter study shows that MEI is averagely improved by 3.7 and 15.5% in perplexity(c) and MRKt, respectively, by setting a low weight for the topic. We also experimentally validate that MEI can determine the appropriate numbers of communities and topics.", "paper_title": "MEI: Mutual Enhanced Infinite Community-Topic Model for Analyzing Text-Augmented Social Networks", "paper_id": "WOS:000315631100006"}