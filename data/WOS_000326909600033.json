{"auto_keywords": [{"score": 0.049483572884790016, "phrase": "difference_images"}, {"score": 0.00481495049065317, "phrase": "action_patterns"}, {"score": 0.004695900553353526, "phrase": "efficient_action_recognition"}, {"score": 0.004608539830653038, "phrase": "new_framework"}, {"score": 0.004494570360108983, "phrase": "single-person_oriented_action_recognition"}, {"score": 0.004248294537944227, "phrase": "bounding_boxes"}, {"score": 0.004195418010131832, "phrase": "human_body"}, {"score": 0.003916098498242888, "phrase": "action_representation"}, {"score": 0.003819187440994939, "phrase": "local_temporal_self-similarities"}, {"score": 0.0034984340449789745, "phrase": "words_framework"}, {"score": 0.0033905067962602515, "phrase": "action_classification"}, {"score": 0.003028729738789638, "phrase": "weizmann"}, {"score": 0.0029537236840150734, "phrase": "kth"}, {"score": 0.0028805474861014722, "phrase": "weizmann_dataset"}, {"score": 0.0028268629720802772, "phrase": "proposed_framework"}, {"score": 0.002688532127821979, "phrase": "recognition_rate"}, {"score": 0.0025730425700096365, "phrase": "kth_dataset"}, {"score": 0.0022413233627905696, "phrase": "high_potential"}, {"score": 0.0021857667493036786, "phrase": "faster_execution_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Action patterns", " Efficient action recognition", " Temporal self-similarities", " Bag-of-words"], "paper_abstract": "A new framework is presented for single-person oriented action recognition. This framework does not require detection/location of bounding boxes of human body nor motion estimation in each frame. The novel descriptor/pattern for action representation is learned with local temporal self-similarities (LTSSs) derived directly from difference images. The bag-of-words framework is then employed for action classification taking advantages of these descriptors. We investigated the effectiveness of the framework on two public human action datasets: the Weizmann dataset and the KTH dataset In the Weizmann dataset, the proposed framework achieves a performance of 95.6% in the recognition rate and that of 91.1% in the KTH dataset, both of which are competitive with those of state-of-the-art approaches, but it has a high potential to achieve a faster execution performance. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Learning action patterns in difference images for efficient action recognition", "paper_id": "WOS:000326909600033"}