{"auto_keywords": [{"score": 0.047277809523201465, "phrase": "osktd"}, {"score": 0.02111582939890176, "phrase": "selective_kernel-based_value_function"}, {"score": 0.008490830050496426, "phrase": "sparsified_dictionary"}, {"score": 0.00481495049065317, "phrase": "online_selective_kernel-based_temporal_difference_learning"}, {"score": 0.004797041537515165, "phrase": "up-to-date_algorithms"}, {"score": 0.004564021871465994, "phrase": "continuous_reinforcement_learning_problems"}, {"score": 0.004059585951426263, "phrase": "selective_ensemble_learning"}, {"score": 0.0038867116254051363, "phrase": "proposed_sparsification_method"}, {"score": 0.0035507457285983268, "phrase": "local_validity"}, {"score": 0.003445316481824611, "phrase": "best_samples"}, {"score": 0.003410871299189454, "phrase": "sample_dictionary"}, {"score": 0.003376769321692139, "phrase": "selective_kernel-based_value_function_approximator"}, {"score": 0.0032328778271536454, "phrase": "temporal_difference"}, {"score": 0.003136857047565403, "phrase": "gradient_descent_technique"}, {"score": 0.0030744279865523036, "phrase": "online_sparsification_procedure"}, {"score": 0.003043679504527297, "phrase": "osktd_algorithm"}, {"score": 0.0026887414772050707, "phrase": "tdc"}, {"score": 0.0026618355977665745, "phrase": "kernel-based_value_function"}, {"score": 0.002539802613867161, "phrase": "maze_problem"}, {"score": 0.0024892263318773704, "phrase": "optimal_policy"}, {"score": 0.0023513172266105982, "phrase": "mountain_car_problem"}, {"score": 0.0022510237833271, "phrase": "better_local_optima"}, {"score": 0.0022284920601703595, "phrase": "traditional_algorithms"}, {"score": 0.0021049977753042253, "phrase": "competitive_ultimate_optima"}], "paper_keywords": ["Function approximation", " online sparsification", " reinforcement learning (RL)", " selective ensemble learning", " selective kernel-based value function"], "paper_abstract": "In this paper, an online selective kernel-based temporal difference (OSKTD) learning algorithm is proposed to deal with large scale and/or continuous reinforcement learning problems. OSKTD includes two online procedures: online sparsification and parameter updating for the selective kernel-based value function. A new sparsification method (i.e., a kernel distance-based online sparsification method) is proposed based on selective ensemble learning, which is computationally less complex compared with other sparsification methods. With the proposed sparsification method, the sparsified dictionary of samples is constructed online by checking if a sample needs to be added to the sparsified dictionary. In addition, based on local validity, a selective kernel-based value function is proposed to select the best samples from the sample dictionary for the selective kernel-based value function approximator. The parameters of the selective kernel-based value function are iteratively updated by using the temporal difference (TD) learning algorithm combined with the gradient descent technique. The complexity of the online sparsification procedure in the OSKTD algorithm is O(n). In addition, two typical experiments (Maze and Mountain Car) are used to compare with both traditional and up-to-date O(n) algorithms (GTD, GTD2, and TDC using the kernel-based value function), and the results demonstrate the effectiveness of our proposed algorithm. In the Maze problem, OSKTD converges to an optimal policy and converges faster than both traditional and up-to-date algorithms. In the Mountain Car problem, OSKTD converges, requires less computation time compared with other sparsification methods, gets a better local optima than the traditional algorithms, and converges much faster than the up-to-date algorithms. In addition, OSKTD can reach a competitive ultimate optima compared with the up-to-date algorithms.", "paper_title": "Online Selective Kernel-Based Temporal Difference Learning", "paper_id": "WOS:000326940600004"}