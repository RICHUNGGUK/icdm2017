{"auto_keywords": [{"score": 0.04377352312035198, "phrase": "block_subspace_methods"}, {"score": 0.008616749750618338, "phrase": "undersampled_problems"}, {"score": 0.00481495049065317, "phrase": "blockwise_data"}, {"score": 0.004551781491498328, "phrase": "linear_subspace_methods"}, {"score": 0.004351595642056769, "phrase": "pattern_recognition"}, {"score": 0.0043029342321223825, "phrase": "machine_learning"}, {"score": 0.004022137057452406, "phrase": "computational_complexity"}, {"score": 0.003823584649521733, "phrase": "thorough_analysis"}, {"score": 0.0036966717141736355, "phrase": "theoretical_framework"}, {"score": 0.00345530020388352, "phrase": "classical_subspace_methods"}, {"score": 0.0033405704229694656, "phrase": "blockwise_pca"}, {"score": 0.003303177222901723, "phrase": "larger_reconstruction_errors"}, {"score": 0.003266201217790818, "phrase": "classical_pca"}, {"score": 0.003175556211659149, "phrase": "stronger_discriminant_power"}, {"score": 0.003140004304719746, "phrase": "blockwise_lda"}, {"score": 0.0030017207229983385, "phrase": "reduced_features"}, {"score": 0.0028695095228791724, "phrase": "fisher_criterion"}, {"score": 0.0027123819773059127, "phrase": "approximate_block_size"}, {"score": 0.0026820015810254004, "phrase": "classification_problems"}, {"score": 0.0026370661343466354, "phrase": "comprehensive_experiments"}, {"score": 0.002607527117561699, "phrase": "face_images"}, {"score": 0.00257831812581194, "phrase": "gene_expression_data"}, {"score": 0.002464709648714996, "phrase": "comparative_analysis"}, {"score": 0.0023827927890399357, "phrase": "experimental_results"}, {"score": 0.0022396019251440724, "phrase": "subspace_distance"}, {"score": 0.0022020622730208514, "phrase": "undesirable_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["LDA", " PCA", " Blockwise PCA", " Blockwise LDA", " 2DPCA", " 2DLDA", " Face recognition", " Gene expression data"], "paper_abstract": "Linear subspace methods are extensively used in many areas such as pattern recognition and machine learning. Among them, block subspace methods are efficient in terms of the computational complexity. In this paper, we perform a thorough analysis on block subspace methods and give a theoretical framework for understanding block subspace methods. It reveals the relationship between block subspace methods and classical subspace methods. We theoretically show that blockwise PCA has larger reconstruction errors than classical PCA and classical LDA has stronger discriminant power than blockwise LDA in the case of the same number of reduced features. In addition, based on the Fisher criterion, we also give a strategy for selecting an approximate block size for classification problems. The comprehensive experiments on face images and gene expression data are used to evaluate our results and a comparative analysis for various methods is made. Experimental results demonstrate that overly combining subspaces of block subspace methods without considering the subspace distance may yield undesirable performance on undersampled problems. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Blockwise projection matrix versus blockwise data on undersampled problems: Analysis, comparison and applications", "paper_id": "WOS:000292849000046"}