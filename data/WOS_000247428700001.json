{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "parallel_layer"}, {"score": 0.004771435352180973, "phrase": "perceptron_complexity"}, {"score": 0.0046432244185370605, "phrase": "multiobjective_learning_algorithm"}, {"score": 0.004240130566108756, "phrase": "plp"}, {"score": 0.003503497128638099, "phrase": "training_process"}, {"score": 0.00334780964309978, "phrase": "bi-objective_problem"}, {"score": 0.003141364320497748, "phrase": "training_error"}, {"score": 0.0030017207229983385, "phrase": "weight_vector"}, {"score": 0.0027910516355928983, "phrase": "network_complexity"}, {"score": 0.002548331088496964, "phrase": "classification_problems"}, {"score": 0.0022640009579466924, "phrase": "plp_mobj_training_algorithm"}, {"score": 0.0022231606165229235, "phrase": "good_generalization_results"}, {"score": 0.0021632743048552536, "phrase": "traditional_methods"}, {"score": 0.0021049977753042253, "phrase": "tested_examples"}], "paper_keywords": ["parallel layer perceptron", " neural networks", " learning algorithms", " machine learning", " multiobjective training algorithm"], "paper_abstract": "This paper deals with the parallel layer perceptron (PLP) complexity control, bias and variance dilemma, using a multiobjective (MOBJ) training algorithm. To control the bias and variance the training process is rewritten as a bi-objective problem, considering the minimization of both training error and norm of the weight vector, which is a measure of the network complexity. This method is, applied to regression and classification problems and compared with several other training procedures and topologies. The results show that the PLP MOBJ training algorithm presents good generalization results, outperforming traditional methods in the tested examples.", "paper_title": "Controlling the parallel layer perceptron complexity using a multiobjective learning algorithm", "paper_id": "WOS:000247428700001"}