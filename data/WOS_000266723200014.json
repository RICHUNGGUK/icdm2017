{"auto_keywords": [{"score": 0.04837093451796987, "phrase": "feedforward_neural_networks"}, {"score": 0.04472882712454684, "phrase": "online_gradient_method"}, {"score": 0.00481495049065317, "phrase": "boundedness_and_convergence_of_online_gradient_method"}, {"score": 0.0030291453183733897, "phrase": "generalization_performance"}, {"score": 0.0026427848602443267, "phrase": "network_training"}, {"score": 0.0022231606165229235, "phrase": "numerical_example"}, {"score": 0.0021049977753042253, "phrase": "theoretical_analysis"}], "paper_keywords": ["Boundedness", " convergence", " feedforward neural networks", " online gradient method", " penalty"], "paper_abstract": "In this brief, we consider an online gradient method with penalty for training feedforward neural networks. Specifically, the penalty is a term proportional to the norm of the weights. Its roles in the method are to control the magnitude of the weights and to improve the generalization performance of the network. By proving that the weights are automatically bounded in the network training with penalty, we simplify the conditions that are required for convergence of online gradient method in literature. A numerical example is given to support the theoretical analysis.", "paper_title": "Boundedness and Convergence of Online Gradient Method With Penalty for Feedforward Neural Networks", "paper_id": "WOS:000266723200014"}