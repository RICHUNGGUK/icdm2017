{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "single_image_matting"}, {"score": 0.03689565391010681, "phrase": "input_images"}, {"score": 0.004664352260912174, "phrase": "accurate_foreground_opacity"}, {"score": 0.004494570360108983, "phrase": "severely_ill-posed_and_challenging_problem"}, {"score": 0.004330941610682453, "phrase": "image_co-segmentation"}, {"score": 0.004129248271757936, "phrase": "novel_framework"}, {"score": 0.004064117897000019, "phrase": "new_task"}, {"score": 0.0038339398365449507, "phrase": "alpha_mattes"}, {"score": 0.0037935066882208235, "phrase": "multiple_images"}, {"score": 0.0037336520904376687, "phrase": "slightly_deformed_instances"}, {"score": 0.0036359780843400625, "phrase": "different_backgrounds"}, {"score": 0.0032184697893776052, "phrase": "alpha_matte"}, {"score": 0.002988101395789399, "phrase": "training_dataset"}, {"score": 0.0029253546782349875, "phrase": "co-matting_step"}, {"score": 0.002833689453299307, "phrase": "foreground_object_instances"}, {"score": 0.0027741761880779535, "phrase": "geometric_features"}, {"score": 0.0027015344365793016, "phrase": "global_optimization"}, {"score": 0.002548331088496964, "phrase": "high_confidence_local_regions"}, {"score": 0.002378408229095287, "phrase": "experimental_results"}, {"score": 0.002328434471939886, "phrase": "co-matting_framework"}, {"score": 0.0022916428586256723, "phrase": "noticeably_higher_quality_results"}, {"score": 0.002255431275670053, "phrase": "image_stack"}, {"score": 0.002219790619936024, "phrase": "state-of-the-art_single_image_matting_techniques"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Image matting", " Image co-segmentation"], "paper_abstract": "Single image matting, the task of estimating accurate foreground opacity from a given image, is a severely ill-posed and challenging problem. Inspired by recent advances in image co-segmentation, in this paper, we present a novel framework for a new task called co-matting, which aims to simultaneously extract alpha mattes in multiple images that contain slightly deformed instances of the same foreground object against different backgrounds. Our system first generates trimaps for input images using co-segmentation, and an initial alpha matte for each image using single image matting. Each alpha matte is then locally evaluated using a novel matting confidence metric learned from a training dataset. In the co-matting step, we first align the foreground object instances using appearance and geometric features, then apply a global optimization on all input images to jointly improve their alpha mattes, which allows high confidence local regions to guide their corresponding low confidence ones in other images to achieve more accurate mattes all together. Experimental results show that this co-matting framework can achieve noticeably higher quality results on an image stack than applying state-of-the-art single image matting techniques individually on each image. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Confidence-driven image co-matting", "paper_id": "WOS:000331596300017"}