{"auto_keywords": [{"score": 0.04394516098812625, "phrase": "environmental_variations"}, {"score": 0.013128219881548763, "phrase": "facial_features"}, {"score": 0.012883817040104925, "phrase": "feature_dimensions"}, {"score": 0.01095919136928511, "phrase": "statistical_analysis"}, {"score": 0.009750839492489992, "phrase": "extracted_triangular_facial_features"}, {"score": 0.008906798262738392, "phrase": "triangular_facial_feature_sets"}, {"score": 0.00481495049065317, "phrase": "emotion_recognition"}, {"score": 0.004618342952383313, "phrase": "human_emotions"}, {"score": 0.004583464412234181, "phrase": "facial_expressions"}, {"score": 0.004429727701202369, "phrase": "referred_features"}, {"score": 0.004363058588000252, "phrase": "conventional_methods"}, {"score": 0.004090682761004765, "phrase": "new_triangular_facial_feature_extraction_method"}, {"score": 0.0037918465913284478, "phrase": "noisy_facial_features"}, {"score": 0.003748937184382714, "phrase": "proposed_method"}, {"score": 0.0036924762294207633, "phrase": "face_shape_model"}, {"score": 0.0036645642553325215, "phrase": "target_image"}, {"score": 0.00362308996613223, "phrase": "modified_active_shape_model"}, {"score": 0.0035415392642831616, "phrase": "traditional_asm"}, {"score": 0.003501452436803395, "phrase": "landmark_searching"}, {"score": 0.0034749796618436567, "phrase": "masm"}, {"score": 0.0034226302212225206, "phrase": "gray-level_training"}, {"score": 0.00330770035909988, "phrase": "genetic_algorithm"}, {"score": 0.0032087739900195232, "phrase": "optimal_set"}, {"score": 0.0031845067058084583, "phrase": "triangular_facial_features"}, {"score": 0.0031484483754909026, "phrase": "feature_points"}, {"score": 0.0031246358910995316, "phrase": "constructed_face_shape_model"}, {"score": 0.0030658872249549893, "phrase": "neural_network_classifier"}, {"score": 0.002951689799589969, "phrase": "jaffe"}, {"score": 0.002896167001212006, "phrase": "performance_evaluation"}, {"score": 0.0028525124381208705, "phrase": "experimental_results"}, {"score": 0.0025357050267224715, "phrase": "manually_selected_features"}, {"score": 0.0023771343615901185, "phrase": "best_case"}, {"score": 0.002350196395175188, "phrase": "proposed_approach"}, {"score": 0.002288519595829552, "phrase": "computational_complexity"}, {"score": 0.0022284577808744316, "phrase": "average_recognition_rate"}, {"score": 0.002153540857619362, "phrase": "proposed_genetic_algorithm"}, {"score": 0.0021049977753042253, "phrase": "legacy_approaches"}], "paper_keywords": ["Human-computer interaction", " Emotion recognition", " Facial expression", " Active shape model", " Neural network", " Genetic algorithm"], "paper_abstract": "Recognition of human emotions from facial expressions is highly dependent on the quality of the referred features. However, conventional methods usually were time-consuming and less robust to environmental variations. In this paper, a new triangular facial feature extraction method considering the interactions among facial features is proposed to reduce feature dimensions and avoid the effect of environmental variations as well as noisy facial features. The proposed method first constructs the face shape model of target image using a Modified Active Shape Model (MASM). Unlike traditional ASM, the landmark searching of MASM need not perform gray-level training as a pre-process. A statistical analysis and a genetic algorithm are then respectively employed to extract an optimal set of triangular facial features from the feature points of constructed face shape model. Finally, a neural network classifier is adopted to recognize emotions from the extracted triangular facial features. JAFFE database is used for performance evaluation. According to experimental results, the extracted triangular facial features are really robust to environmental variations. Besides, the triangular facial feature sets extracted by statistical analysis achieved a 65.1% recognition rate on average, which is close to the results conducted by manually selected features. However, the feature dimensions are greatly reduced from several hundreds of facial features to 21 features in the best case by the proposed approach. This reduction much benefits the computational complexity. We can further improve the average recognition rate to 73.9% with the triangular facial feature sets extracted by the proposed genetic algorithm, which is better than legacy approaches.", "paper_title": "EMOTION RECOGNITION BY A NOVEL TRIANGULAR FACIAL FEATURE EXTRACTION METHOD", "paper_id": "WOS:000311584500013"}