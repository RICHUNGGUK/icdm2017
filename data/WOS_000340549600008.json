{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "motion_perception_technique"}, {"score": 0.0047515546458205046, "phrase": "autonomous_robot_system"}, {"score": 0.00470975295439431, "phrase": "visual_motion_perception"}, {"score": 0.0046477357199085035, "phrase": "moving_observer"}, {"score": 0.004546174820239776, "phrase": "real_life_situations"}, {"score": 0.004198510172614725, "phrase": "new_applications"}, {"score": 0.0040886093072615, "phrase": "innovative_and_autonomous_robotic_system"}, {"score": 0.003964007795174772, "phrase": "dense_optical_flow_technique"}, {"score": 0.0038431888954930083, "phrase": "motion_perception"}, {"score": 0.003660700128133065, "phrase": "autonomous_mobile_systems"}, {"score": 0.0036124465071873998, "phrase": "proposed_hybridtree_method"}, {"score": 0.0035178323426661626, "phrase": "intrinsic_nature"}, {"score": 0.003335948601271999, "phrase": "descriptive_properties"}, {"score": 0.0032199307816384577, "phrase": "tree-based_scheme"}, {"score": 0.003163439005885435, "phrase": "expectation_phase"}, {"score": 0.003107935254560724, "phrase": "sensing_operation"}, {"score": 0.0030399188412691914, "phrase": "image_regions"}, {"score": 0.0029471818883482688, "phrase": "hierarchical_optical_flow_structure"}, {"score": 0.00289546142998427, "phrase": "flow_field"}, {"score": 0.002807118943000936, "phrase": "proposed_method"}, {"score": 0.00278237555651743, "phrase": "reliable_visual_motion_information"}, {"score": 0.0027456676902333304, "phrase": "short_period"}, {"score": 0.002592100731070259, "phrase": "specialized_computer_devices"}, {"score": 0.002535344521369057, "phrase": "hybridtree"}, {"score": 0.002447101794397243, "phrase": "new_perspective"}, {"score": 0.0024148064819862337, "phrase": "motion_perception_computation"}, {"score": 0.002341094670523097, "phrase": "image_sequence"}, {"score": 0.0022595974985992664, "phrase": "optical_flow"}, {"score": 0.0021049977753042253, "phrase": "resulting_flow_field"}], "paper_keywords": ["Optical flow", " Autonomous robot", " Surveillance", " Motion perception"], "paper_abstract": "Visual motion perception from a moving observer is the most often encountered case in real life situations. It is a complex and challenging problem, although, it can promote the arising of new applications. This article presents an innovative and autonomous robotic system designed for active surveillance and a dense optical flow technique. Several optical flow techniques have been proposed for motion perception however, most of them are too computationally demanding for autonomous mobile systems. The proposed HybridTree method is able to identify the intrinsic nature of the motion by performing two consecutive operations: expectation and sensing. Descriptive properties of the image are retrieved using a tree-based scheme and during the expectation phase. In the sensing operation, the properties of image regions are used by a hybrid and hierarchical optical flow structure to estimate the flow field. The experiments prove that the proposed method extracts reliable visual motion information in a short period of time and is more suitable for applications that do not have specialized computer devices. Therefore, the HybridTree differs from other techniques since it introduces a new perspective for the motion perception computation: high level information about the image sequence is integrated into the estimation of the optical flow. In addition, it meets most of the robotic or surveillance demands and the resulting flow field is less computationally demanding comparatively to other state-of-the-art methods.", "paper_title": "A Flow-based Motion Perception Technique for an Autonomous Robot System", "paper_id": "WOS:000340549600008"}