{"auto_keywords": [{"score": 0.039712716961339774, "phrase": "local_fusion_agent"}, {"score": 0.00481495049065317, "phrase": "trajectory_tracking"}, {"score": 0.004758987153057194, "phrase": "cooperative_surveillance_multi-agent_architecture"}, {"score": 0.004436545340717729, "phrase": "specific_coalition_formation"}, {"score": 0.004402088928254543, "phrase": "fusion_skills"}, {"score": 0.004283576270012874, "phrase": "fusion_process"}, {"score": 0.004055998173160551, "phrase": "fusion_center"}, {"score": 0.0036505565334886227, "phrase": "autonomous_agent"}, {"score": 0.0036221822903900725, "phrase": "surveillance-sensor_agents"}, {"score": 0.00331125524068286, "phrase": "autonomous_agents"}, {"score": 0.0032094634756436595, "phrase": "specific_surveillance_task"}, {"score": 0.0031721009574803127, "phrase": "surveillance-sensor_agent"}, {"score": 0.0031229578623834394, "phrase": "individual_sensors"}, {"score": 0.003015143226706584, "phrase": "different_capabilities"}, {"score": 0.0029224275921964724, "phrase": "sensor-specific_aspects"}, {"score": 0.002810520668490478, "phrase": "new_autonomous_agent"}, {"score": 0.002702887319160534, "phrase": "cs-mas_architecture"}, {"score": 0.002671406231520296, "phrase": "specific_problems"}, {"score": 0.0026506222660465104, "phrase": "on-line_sensor_alignment"}, {"score": 0.0026095369186867707, "phrase": "bias_removal"}, {"score": 0.002490053106007765, "phrase": "fusion_center_agent"}, {"score": 0.0023391880766516285, "phrase": "new_dynamic_local_fusion_agent"}, {"score": 0.00228499525153, "phrase": "video-surveillance_system"}, {"score": 0.002197443382039439, "phrase": "whole_area"}, {"score": 0.002154930852763048, "phrase": "seamless_transitions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Software agents", " Data fusion", " Coordination", " Sensor network architecture", " Distributed vision", " Surveillance application"], "paper_abstract": "In this paper we present a Cooperative Surveillance Multi-Agent System (CS-MAS) architecture extended to incorporate dynamic coalition formation. We illustrate specific coalition formation using fusion skills. In this case, the fusion process is divided into two layers: (i) a global layer in the fusion center, which initializes the coalitions and (ii) a local layer within coalitions, where a local fusion agent is dynamically instantiated. There are several types of autonomous agent: surveillance-sensor agents, a fusion center agent, a local fusion agent, interface agents, record agents, planning agents, etc. Autonomous agents differ in their ability to carry out a specific surveillance task. A surveillance-sensor agent controls and manages individual sensors (usually video cameras). It has different capabilities depending on its functional complexity and limitations related to sensor-specific aspects. In the work presented here we add a new autonomous agent, called the local fusion agent, to the CS-MAS architecture, addressing specific problems of on-line sensor alignment, registration, bias removal and data fusion. The local fusion agent is dynamically created by the fusion center agent and involves several surveillance-sensor agents working in a coalition. We show how the inclusion of this new dynamic local fusion agent guarantees that, in a video-surveillance system, objects of interest are successfully tracked across the whole area, assuring continuity and seamless transitions. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Data fusion to improve trajectory tracking in a Cooperative Surveillance Multi-Agent Architecture", "paper_id": "WOS:000277754900005"}