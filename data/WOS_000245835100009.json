{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "hypertree_width"}, {"score": 0.0347352604800049, "phrase": "weighted_hypertree_decompositions"}, {"score": 0.0045820747375409435, "phrase": "relevant_problems"}, {"score": 0.004551883842967241, "phrase": "different_areas"}, {"score": 0.004447766706144458, "phrase": "conjunctive_queries"}, {"score": 0.004418456827500267, "phrase": "database_theory"}, {"score": 0.004374852170791322, "phrase": "constraint_satisfaction"}, {"score": 0.00435454567416127, "phrase": "al"}, {"score": 0.004163172790791119, "phrase": "practical_contexts"}, {"score": 0.00409490456027741, "phrase": "database_queries"}, {"score": 0.0036472537997966938, "phrase": "commercial_query-optimizers"}, {"score": 0.0035993041437026225, "phrase": "quantitative_methods"}, {"score": 0.0035285548582081627, "phrase": "structural_properties"}, {"score": 0.003413705707789296, "phrase": "structural_decomposition_methods"}, {"score": 0.0033911868693238894, "phrase": "quantitative_approaches"}, {"score": 0.0033355353594739707, "phrase": "weighted_hyper-tree_decomposition"}, {"score": 0.0032483801419536675, "phrase": "cost_functions"}, {"score": 0.0030003014343035965, "phrase": "hypertree_decompositions"}, {"score": 0.0029706504420983896, "phrase": "smallest_weights"}, {"score": 0.002663156413861478, "phrase": "-not_very_severe-restrictions"}, {"score": 0.0024924663319500326, "phrase": "polynomial_time"}, {"score": 0.002459660938061167, "phrase": "easier_hypertree_weighting_functions"}, {"score": 0.002363806685815014, "phrase": "cost_function_modeling_query_evaluation_costs"}, {"score": 0.0021903801614787423, "phrase": "preliminary_results"}, {"score": 0.002168715943767454, "phrase": "experimental_comparison"}, {"score": 0.002147265537489893, "phrase": "query_optimization_technique"}, {"score": 0.0021260268415459805, "phrase": "query_optimizer"}, {"score": 0.0021049977753042253, "phrase": "commercial_dbms"}], "paper_keywords": ["query processing", " computational complexity", " decomposition methods", " hypergraphs", " relational databases"], "paper_abstract": "Hypertree width is a measure of the degree of cyclicity of hypergraphs. A number of relevant problems from different areas, e.g., the evaluation of conjunctive queries in database theory or the constraint satisfaction in Al, are tractable when their underlying hypergraphs have bounded hypertree width. However, in practical contexts like the evaluation of database queries, we have more information besides the structure of queries. For instance, we know the number of tuples in relations, the selectivity of attributes and so on. In fact, all commercial query-optimizers are based on quantitative methods and do not care on structural properties. In this paper, in order to combine structural decomposition methods with quantitative approaches, the notion of weighted hyper-tree decomposition is defined. Weighted hypertree decompositions are equipped with cost functions, that can he used for modeling many situations where there is further information on the given problem, besides its hypergraph representation. The complexity of computing hypertree decompositions having the smallest weights, called minimal hypertree decompositions, is analyzed. It is shown that in many cases tractability is lost if weights are added. However, it is proven that, under some-not very severe-restrictions on the allowed cost functions and on the target hypertrees, optimal weighted hypertree decompositions can be computed in polynomial time. For some easier hypertree weighting functions, this problem is also highly parallelizable. Then, a cost function modeling query evaluation costs is provided, and it is shown how to exploit weighted hypertree decompositions for determining (logical) query plans for answering conjunctive queries. Finally, some preliminary results of an experimental comparison of this query optimization technique with the query optimizer of a commercial DBMS are presented. (c) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Weighted hypertree decompositions and optimal query plans", "paper_id": "WOS:000245835100009"}