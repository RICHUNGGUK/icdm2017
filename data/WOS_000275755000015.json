{"auto_keywords": [{"score": 0.04571345706034808, "phrase": "svm"}, {"score": 0.00481495049065317, "phrase": "empirical_kernel_map"}, {"score": 0.00475413908468027, "phrase": "row_kernel_space"}, {"score": 0.004605434064238641, "phrase": "machine-learning_technologies"}, {"score": 0.004518442937844318, "phrase": "support_vector_machine"}, {"score": 0.004267163206961948, "phrase": "brilliant_invention"}, {"score": 0.004055511503825102, "phrase": "local_minima"}, {"score": 0.0038789122930433305, "phrase": "different_clusters"}, {"score": 0.003503497128638102, "phrase": "linear_separability_relationships"}, {"score": 0.003437248394635138, "phrase": "high-dimensional_feature_space_h"}, {"score": 0.0031044458412608084, "phrase": "kernel_outputs"}, {"score": 0.0030847461428168614, "phrase": "k._second"}, {"score": 0.0026815368507715, "phrase": "upper_bound"}, {"score": 0.0026307897899760383, "phrase": "margin_width"}, {"score": 0.0025974916908139472, "phrase": "k._third"}, {"score": 0.002421726275597666, "phrase": "separating_hyperplane"}, {"score": 0.0022292394795878643, "phrase": "existing_svm_training"}, {"score": 0.0021049977753042253, "phrase": "considerable_success"}], "paper_keywords": ["Separating hyperplane", " Linear separability", " High-dimensional feature space", " Support vector machine"], "paper_abstract": "In machine-learning technologies, the support vector machine (SV machine, SVM) is a brilliant invention with many merits, such as freedom from local minima, the widest possible margins separating different clusters, and a solid theoretical foundation. In this paper, we first explore the linear separability relationships between the high-dimensional feature space H and the empirical kernel map U as well as between H and the space of kernel outputs K. Second, we investigate the relations of the distances between separating hyperplanes and SVs in H and U, and derive an upper bound for the margin width in K. Third, as an application, we show experimentally that the separating hyperplane in H can be slightly adjusted through U. The experiments reveal that existing SVM training can linearly separate the data in H with considerable success. The results in this paper allow us to visualize the geometry of H by studying U and K.", "paper_title": "Feature space versus empirical kernel map and row kernel space in SVMs", "paper_id": "WOS:000275755000015"}