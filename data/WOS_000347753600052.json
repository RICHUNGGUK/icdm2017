{"auto_keywords": [{"score": 0.03737634241271661, "phrase": "proposed_method"}, {"score": 0.01446779966423264, "phrase": "src_model"}, {"score": 0.00481495049065317, "phrase": "hierarchical_multi-scale_lbp"}, {"score": 0.004372895175179516, "phrase": "strict_one_compare"}, {"score": 0.004345804626592329, "phrase": "sparse_representation_model"}, {"score": 0.004278807087784626, "phrase": "strict_and_standard_dictionary"}, {"score": 0.004239103253656808, "phrase": "sparser_coefficient"}, {"score": 0.0041478818670853115, "phrase": "better_classification_accuracy"}, {"score": 0.004046020290832207, "phrase": "rational_and_optimal_dictionary"}, {"score": 0.004020974379839629, "phrase": "src"}, {"score": 0.003971262520692664, "phrase": "challenging_task"}, {"score": 0.0038978806337961565, "phrase": "good_performance"}, {"score": 0.003849711329589429, "phrase": "new_algorithmic_and_analytical_techniques"}, {"score": 0.0037434875065980415, "phrase": "novel_src_fusion_method"}, {"score": 0.0037202816351450995, "phrase": "hierarchical_multi-scale_local_binary_patterns"}, {"score": 0.003697234200630287, "phrase": "lbp"}, {"score": 0.003662892058072211, "phrase": "greedy_search_strategy"}, {"score": 0.003584025547693836, "phrase": "face_recognition"}, {"score": 0.0032749212355657215, "phrase": "optimized_dictionary"}, {"score": 0.00316475494774005, "phrase": "original_training_samples"}, {"score": 0.0031159081999910694, "phrase": "training_variables"}, {"score": 0.003086961663712383, "phrase": "classification_strategy"}, {"score": 0.003039311963787733, "phrase": "query_sample"}, {"score": 0.0030110748510795175, "phrase": "linear_combination"}, {"score": 0.0029370480686919075, "phrase": "optimal_representation"}, {"score": 0.002918826667294298, "phrase": "training_samples"}, {"score": 0.0028737647829311587, "phrase": "major_relevant_contributions"}, {"score": 0.0026421521830403377, "phrase": "final_remaining_training_samples"}, {"score": 0.0025932659540059875, "phrase": "best_representation"}, {"score": 0.0025691622090542304, "phrase": "test_sample"}, {"score": 0.0024595996811420566, "phrase": "important_goal"}, {"score": 0.002340081450249521, "phrase": "descriptive_representation"}, {"score": 0.002325554982412043, "phrase": "sparse_category_knowledge_structure"}, {"score": 0.002289631204915149, "phrase": "heuristic_learning_strategy"}, {"score": 0.0022472527731744974, "phrase": "experimental_results"}, {"score": 0.002219440641801526, "phrase": "orl"}, {"score": 0.0022056599393300872, "phrase": "feret"}, {"score": 0.0021851480717840484, "phrase": "face_databases"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Sparse representation", " Greedy search", " Hierarchical multi-scale", " Image classification"], "paper_abstract": "As is well known, most of the sparse representation based classification (SRC) schemes are not the standard form of SR model, that is, the dictionary in SRC model is not a strict one compare to sparse representation model. Actually, a strict and standard dictionary will create sparser coefficient, but it might not achieve better classification accuracy in SRC model. Therefore, constructing a rational and optimal dictionary for SRC model is a challenging task for us. Understanding the good performance of such unconventional dictionaries demands new algorithmic and analytical techniques. In this paper, we propose a novel SRC fusion method using hierarchical multi-scale local binary patterns (LBP) and greedy search strategy (SRC-GSLBP) for face recognition. The proposed method involves three aspects: dictionary optimization, training variables selection and classification strategy, sparse coding coefficient decomposing. First of all, we get an optimized dictionary through extracting hierarchical multi-scale LBP features from the original training samples. Second, the training variables selection and classification strategy aim to represent a query sample as a linear combination of the most informative training samples, and exploits an optimal representation of training samples from the classes with major relevant contributions. Instead of eliminating several classes at one time, we choose eliminating classes one by one with greedy search (GS) sparse coding process until the predefined termination condition is satisfied. The final remaining training samples are used to produce a best representation of the test sample and to perform classification. In the context of the proposed method, an important goal is to select a subset of variables that accomplishes one objective: the provision of a descriptive representation for sparse category knowledge structure. We develop a heuristic learning strategy to achieve this goal. Experimental results conducted on the ORL, FERET and AR face databases demonstrate the effectiveness of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A novel SRC fusion method using hierarchical multi-scale LBP and greedy search strategy", "paper_id": "WOS:000347753600052"}