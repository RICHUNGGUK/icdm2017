{"auto_keywords": [{"score": 0.049460287006492736, "phrase": "data_augmentation"}, {"score": 0.00481495049065317, "phrase": "bayesian_inference"}, {"score": 0.004600596158672458, "phrase": "common_tool"}, {"score": 0.0045411156682300695, "phrase": "bayesian_statistics"}, {"score": 0.004338898899247236, "phrase": "mcmc._data_augmentation"}, {"score": 0.004227398267369744, "phrase": "direct_computation"}, {"score": 0.004145649381700967, "phrase": "posterior_density"}, {"score": 0.0024939618994290016, "phrase": "exact_computation"}, {"score": 0.002398274973378986, "phrase": "mixture_distribution"}, {"score": 0.0022763657774198184, "phrase": "mcmc._useful_byproducts"}, {"score": 0.002232261129770455, "phrase": "exact_posterior_distribution"}, {"score": 0.002189009136006588, "phrase": "marginal_likelihood"}, {"score": 0.0021049977753042253, "phrase": "exact_predictive_distribution"}], "paper_keywords": ["Bayesian statistics", " Data augmentation", " Multinomial distribution", " Reed-Frost epidemic", " Integer valued autoregressive process"], "paper_abstract": "Data augmentation is a common tool in Bayesian statistics, especially in the application of MCMC. Data augmentation is used where direct computation of the posterior density, pi(theta|x), of the parameters theta, given the observed data x, is not possible. We show that for a range of problems, it is possible to augment the data by y, such that, pi(theta|x,y) is known, and pi(y|x) can easily be computed. In particular, pi(y|x) is obtained by collapsing pi(y,theta|x) through integrating out theta. This allows the exact computation of pi(theta|x) as a mixture distribution without recourse to approximating methods such as MCMC. Useful byproducts of the exact posterior distribution are the marginal likelihood of the model and the exact predictive distribution.", "paper_title": "Exact Bayesian inference via data augmentation", "paper_id": "WOS:000349551100012"}