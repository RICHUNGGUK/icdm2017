{"auto_keywords": [{"score": 0.03902727831247399, "phrase": "sla"}, {"score": 0.009471970119183182, "phrase": "weighted_speedup"}, {"score": 0.007134137817411, "phrase": "multithreaded_processors"}, {"score": 0.0059609058848697875, "phrase": "sla_enforcement"}, {"score": 0.00481495049065317, "phrase": "service_level_agreement_for_multithreaded_processors"}, {"score": 0.0047026237903774895, "phrase": "processor_throughput"}, {"score": 0.004625554249508983, "phrase": "unbalanced_threads"}, {"score": 0.0045122922461952805, "phrase": "predicted_performance"}, {"score": 0.00447251540886613, "phrase": "major_problem"}, {"score": 0.00438105507792004, "phrase": "previous_work"}, {"score": 0.004316868627944404, "phrase": "different_fairness_mechanisms"}, {"score": 0.00420368356873615, "phrase": "new_approach"}, {"score": 0.004154332348800334, "phrase": "resource_allocation"}, {"score": 0.004093453936415085, "phrase": "service_level_agreement"}, {"score": 0.0039045506947164225, "phrase": "minimal_level"}, {"score": 0.00384731849108269, "phrase": "running_threads"}, {"score": 0.0037909219941547373, "phrase": "new_metric"}, {"score": 0.003768594674768144, "phrase": "c-sla"}, {"score": 0.0036481158025940047, "phrase": "controlling_resources"}, {"score": 0.003584025547693836, "phrase": "higher_gains"}, {"score": 0.003531474887552889, "phrase": "previously_suggested_fairness_techniques"}, {"score": 0.003165739628969694, "phrase": "execution_parameters"}, {"score": 0.0030826428662461083, "phrase": "fairness_based_algorithms"}, {"score": 0.0030374213037172803, "phrase": "acceptable_execution_points"}, {"score": 0.002821044196775531, "phrase": "individual_threads"}, {"score": 0.002722712628307598, "phrase": "new_sla_approach"}, {"score": 0.0024842242921857705, "phrase": "performance_losses"}, {"score": 0.0024405312482831646, "phrase": "fairness_enforcement_methods"}, {"score": 0.002404706573379854, "phrase": "power_reduction"}, {"score": 0.002181069180139225, "phrase": "differentiated_sla"}, {"score": 0.0021049977753042253, "phrase": "different_throughput_constraint"}], "paper_keywords": ["Design", " Performance", " Service level agreement", " fairness", " performance", " throughput", " power"], "paper_abstract": "Multithreading is widely used to increase processor throughput. As the number of shared resources increase, managing them while guaranteeing predicted performance becomes a major problem. Attempts have been made in previous work to ease this via different fairness mechanisms. In this article, we present a new approach to control the resource allocation and sharing via a service level agreement (SLA)-based mechanism; that is, via an agreement in which multithreaded processors guarantee a minimal level of service to the running threads. We introduce a new metric, C-SLA, for conformance to SLA in multithreaded processors and show that controlling resources using with SLA allows for higher gains than are achievable by previously suggested fairness techniques. It also permits improving one metric ( e. g., power) while maintaining SLA in another ( e. g., performance). We compare SLA enforcement to schemes based on other fairness metrics, which are mostly targeted at equalizing execution parameters. We show that using SLA rather than fairness based algorithms provides a range of acceptable execution points from which we can select the point that best fits our optimization target, such as maximizing the weighted speedup ( sum of the speedups of the individual threads) or reducing power. We demonstrate the effectiveness of the new SLA approach using switch-on-event (coarse-grained) multithreading. Our weighted speedup improvement scheme successfully enforces SLA while improving the weighted speedup by an average of 10% for unbalanced threads. This result is significant when compared with performance losses that may be incurred by fairness enforcement methods. When optimizing for power reduction in unbalanced threads SLA enforcement reduces the power by an average of 15%. SLA may be complemented by other power reduction methods to achieve further power savings and maintain the same service level for the threads. We also demonstrate differentiated SLA, where weighted speedup is maximized while each thread may have a different throughput constraint.", "paper_title": "Service Level Agreement for Multithreaded Processors", "paper_id": "WOS:000269267000002"}