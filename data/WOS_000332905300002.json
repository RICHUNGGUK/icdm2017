{"auto_keywords": [{"score": 0.015719716506582538, "phrase": "television_broadcasts"}, {"score": 0.015371729967760941, "phrase": "fer"}, {"score": 0.014480199250072661, "phrase": "lab-based_data"}, {"score": 0.00474283953918251, "phrase": "facial_expression_recognition"}, {"score": 0.004584495834677719, "phrase": "real_data"}, {"score": 0.004550029253278477, "phrase": "uncontrolled_environments"}, {"score": 0.004348580182733617, "phrase": "facial_expressions"}, {"score": 0.004299621153829837, "phrase": "pre-set_laboratory_environments"}, {"score": 0.004140354220982935, "phrase": "real-world_situations"}, {"score": 0.004062937864702115, "phrase": "unauthorized_capture"}, {"score": 0.003897659323896113, "phrase": "birthday_parties"}, {"score": 0.003415047118340286, "phrase": "'acted'_emotions"}, {"score": 0.003049086085585051, "phrase": "feature_distributions"}, {"score": 0.0028058141911641225, "phrase": "environmental_and_facial_variations"}, {"score": 0.0027741761880779535, "phrase": "real_conditions"}, {"score": 0.002671263324230699, "phrase": "fully_automatic_system"}, {"score": 0.0025335509856200433, "phrase": "performance_evaluation"}, {"score": 0.002514464610980629, "phrase": "performance_improvements"}, {"score": 0.002458061764297103, "phrase": "point-based_texture"}, {"score": 0.0023758152068732025, "phrase": "image_scale_variations"}, {"score": 0.002305014991156598, "phrase": "video_dataset"}, {"score": 0.00227040825063645, "phrase": "fer_performance"}, {"score": 0.002253299769886694, "phrase": "lab-based_and_realistic_data"}, {"score": 0.0021778895748464045, "phrase": "different_train-test_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Facial expression recognition", " Realistic", " Texture", " Geometry", " Experiment"], "paper_abstract": "Facial expression recognition (FER) systems must ultimately work on real data in uncontrolled environments although most research studies have been conducted on lab-based data with posed or evoked facial expressions obtained in pre-set laboratory environments. It is very difficult to obtain data in real-world situations because privacy laws prevent unauthorized capture and use of video from events such as funerals, birthday parties, marriages etc. It is a challenge to acquire such data on a scale large enough for benchmarking algorithms. Although video obtained from TV or movies or postings on the World Wide Web may also contain 'acted' emotions and facial expressions, they may be more 'realistic' than lab-based data currently used by most researchers. Or is it? One way of testing this is to compare feature distributions and FER performance. This paper describes a database that has been collected from television broadcasts and the World Wide Web containing a range of environmental and facial variations expected in real conditions and uses it to answer this question. A fully automatic system that uses a fusion based approach for FER on such data is introduced for performance evaluation. Performance improvements arising from the fusion of point-based texture and geometry features, and the robustness to image scale variations are experimentally evaluated on this image and video dataset. Differences in FER performance between lab-based and realistic data, between different feature sets, and between different train-test data splits are investigated. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Facial expression recognition experiments with data from television broadcasts and the World Wide Web", "paper_id": "WOS:000332905300002"}