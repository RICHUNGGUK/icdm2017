{"auto_keywords": [{"score": 0.050077081405102225, "phrase": "multi-class_problems"}, {"score": 0.03231550833923174, "phrase": "dsa"}, {"score": 0.025371533898339085, "phrase": "proposed_method"}, {"score": 0.004758457292840376, "phrase": "fukunaga-koontz"}, {"score": 0.004565876339189493, "phrase": "famous_feature_extraction_method"}, {"score": 0.0045122922461952805, "phrase": "statistical_pattern_recognition"}, {"score": 0.004178935413340453, "phrase": "best_representative_power"}, {"score": 0.00405735420159564, "phrase": "poorest_representative_power"}, {"score": 0.0039401180097238956, "phrase": "li"}, {"score": 0.0038930368103015467, "phrase": "savvides"}, {"score": 0.003757480190200645, "phrase": "one-against-all_strategy"}, {"score": 0.003562912424153324, "phrase": "two-class_fkt_method"}, {"score": 0.0033984088755183287, "phrase": "presentative_vectors"}, {"score": 0.0032414759269196493, "phrase": "fkt_method"}, {"score": 0.003091767402370757, "phrase": "new_discriminant_subspace_analysis"}, {"score": 0.002966438503447793, "phrase": "multi-class_feature_extraction_problems"}, {"score": 0.0028127163745564777, "phrase": "iterative_algorithm"}, {"score": 0.002763261749602258, "phrase": "joint_diagonalization"}, {"score": 0.0025892330566358503, "phrase": "linear_dsa_method"}, {"score": 0.0025436978068459565, "phrase": "nonlinear_feature_extraction_problems"}, {"score": 0.002498961351132696, "phrase": "kernel_trick"}, {"score": 0.0023554316787703137, "phrase": "pattern_recognition_problems"}, {"score": 0.0023003498123420237, "phrase": "extensive_experiments"}, {"score": 0.002273292707863821, "phrase": "real_data_sets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Fukunaga-Koontz Transform", " Common principal component analysis", " Feature extraction"], "paper_abstract": "Fukunaga-Koontz Transform (FIG) is a famous feature extraction method in statistical pattern recognition, which aims to find a set of vectors that have the best representative power for one class while the poorest representative power for the other class. Li and Savvides [1] propose a one-against-all strategy to deal with multi-class problems, in which the two-class FKT method can be directly applied to find the presentative vectors of each class. Motivated by the FKT method, in this paper we propose a new discriminant subspace analysis (DSA) method for the multi-class feature extraction problems. To solve DSA, we propose an iterative algorithm for the joint diagonalization (JD) problem. Finally, we generalize the linear DSA method to handle nonlinear feature extraction problems via the kernel trick. To demonstrate the effectiveness of the proposed method for pattern recognition problems, we conduct extensive experiments on real data sets and show that the proposed method outperforms most commonly used feature extraction methods. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "A new discriminant subspace analysis approach for multi-class problems", "paper_id": "WOS:000300459000017"}