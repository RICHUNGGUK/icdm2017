{"auto_keywords": [{"score": 0.04940067796826836, "phrase": "self-organization_feature_map"}, {"score": 0.041361508715379594, "phrase": "som"}, {"score": 0.004613516457919661, "phrase": "local_features"}, {"score": 0.004452078350485375, "phrase": "vision-based_human_action_recognition"}, {"score": 0.004326987090971404, "phrase": "\"wild\"_or_unconstrained_videos"}, {"score": 0.004145882022189891, "phrase": "novel_framework"}, {"score": 0.0038332390893263844, "phrase": "action_recognition"}, {"score": 0.0037789720824759503, "phrase": "unconstrained_videos"}, {"score": 0.0036727235025069828, "phrase": "demanding_preprocessing"}, {"score": 0.0035949949979695063, "phrase": "human_detection"}, {"score": 0.002881793492919646, "phrase": "realistic_action_recognition_task"}, {"score": 0.002664221051021009, "phrase": "ucf-youtube_dataset"}, {"score": 0.002570817338292482, "phrase": "promising_results"}, {"score": 0.002516350372379076, "phrase": "local_feature-based_support_vector_machine"}, {"score": 0.002244729997687728, "phrase": "kth"}, {"score": 0.002212892265364764, "phrase": "ut-interaction"}], "paper_keywords": ["Spatio-temporal interest points (STIPs)", " HOG3D/Fast HOG3D", " Self-organization feature map (SOM)", " Support vector machine (SVM)", " Bag-of-words (BoW)"], "paper_abstract": "Nowadays, local features are very popular in vision-based human action recognition, especially in \"wild\" or unconstrained videos. This paper proposes a novel framework that combines Fast HOG3D and self-organization feature map (SOM) network for action recognition from unconstrained videos, bypassing the demanding preprocessing such as human detection, tracking or contour extraction. The contributions of our work not only lie in creating a more compact and computational effective local feature descriptor than original HOG3D, but also lie in first successfully applying SOM to realistic action recognition task and studying its training parameters' influence. We mainly test our approach on the UCF-YouTube dataset with 11 realistic sport actions, achieving promising results that outperform local feature-based support vector machine and are comparable with bag-of-words. Experiments are also carried out on KTH and UT-Interaction datasets for comparison. Results on all the three datasets confirm that our work has comparable, if not better, performance comparing with state-of-the-art.", "paper_title": "Realistic human action recognition by Fast HOG3D and self-organization feature map", "paper_id": "WOS:000342435800014"}