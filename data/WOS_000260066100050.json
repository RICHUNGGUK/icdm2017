{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "input_space"}, {"score": 0.004741167616693272, "phrase": "conventional_neural_networks"}, {"score": 0.0033228699494959172, "phrase": "separated_attributes"}, {"score": 0.0032718761046588835, "phrase": "different_batches"}, {"score": 0.0028687545730861665, "phrase": "ilnnt"}, {"score": 0.0027386335451725762, "phrase": "benchmark_binary_and_multi-class_classification_problems"}, {"score": 0.0026347074232350503, "phrase": "k-fold_cross_validation_show"}, {"score": 0.002554406040896888, "phrase": "varying_degrees"}, {"score": 0.0023278569001363263, "phrase": "classification_accuracy"}, {"score": 0.0022744346997235444, "phrase": "nns"}, {"score": 0.0022394839933089074, "phrase": "reduced_interference"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Classification", " Input space partitioning", " Attribute interference", " Neural networks"], "paper_abstract": "The lack of segregation of input space for conventional neural networks (NNs) training often causes interference within the network. The interference-less neural network training (ILNNT) method employed in this paper reduces interference among input attributes by identifying those attributes that interfere with one another and separating them, while attributes that are mutually beneficial are grouped together. Separated attributes in different batches do not share the same hidden neurons while attributes within a batch are connected to the same hidden neurons. ILNNT is applied to widely used benchmark binary and multi-class classification problems and experimental results from K-fold cross validation show that there exist varying degrees of interference among the attributes for the datasets used and the classification accuracy produced by NNs with reduced interference is high. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Interference-less neural network training", "paper_id": "WOS:000260066100050"}