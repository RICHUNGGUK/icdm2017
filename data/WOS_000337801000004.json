{"auto_keywords": [{"score": 0.04081002585718696, "phrase": "gpp"}, {"score": 0.009806204313792767, "phrase": "intrinsic_target_appearance_variation"}, {"score": 0.009394272587747561, "phrase": "novel_framework"}, {"score": 0.009142984797174276, "phrase": "robot_navigation"}, {"score": 0.006906408744576476, "phrase": "gray_gpp."}, {"score": 0.00481495049065317, "phrase": "online_multiple_targets_detection_and_tracking_from_mobile_robot_in_cluttered_indoor_environments_with_depth_camera._indoor_environment"}, {"score": 0.004664352260912174, "phrase": "multiple_targets"}, {"score": 0.00460125407969429, "phrase": "key_component"}, {"score": 0.004467441124159974, "phrase": "limited_space"}, {"score": 0.004427052632328442, "phrase": "e._g._full_or_partial_occlusion"}, {"score": 0.0043080553835735825, "phrase": "proposed_approach"}, {"score": 0.004201774694043468, "phrase": "indoor_environments"}, {"score": 0.0040981051812938865, "phrase": "key_components"}, {"score": 0.004051828608343507, "phrase": "virtual_top_view"}, {"score": 0.004015182362035361, "phrase": "rgb-d_camera"}, {"score": 0.003969838436551289, "phrase": "ground_plane_projection"}, {"score": 0.003916098498242888, "phrase": "key_advantage"}, {"score": 0.003708289015692081, "phrase": "regular_side-view_image"}, {"score": 0.003624978714700943, "phrase": "free_space"}, {"score": 0.0035435334033073695, "phrase": "moving_camera"}, {"score": 0.0034717929086014636, "phrase": "top-view_image"}, {"score": 0.003386072841722016, "phrase": "object_detection"}, {"score": 0.0033554276520303935, "phrase": "gpp."}, {"score": 0.0033326252993345685, "phrase": "gpp_images"}, {"score": 0.003257727050827128, "phrase": "maximal_height"}, {"score": 0.003091767402370757, "phrase": "simple_connected_component_labeling"}, {"score": 0.002934237411711622, "phrase": "consecutive_frames"}, {"score": 0.0029010651676100365, "phrase": "optical_flow"}, {"score": 0.0028879012092511867, "phrase": "gray_gpp"}, {"score": 0.002612967100145869, "phrase": "rgb"}, {"score": 0.0025425407999349306, "phrase": "multiple_moving_targets"}, {"score": 0.0025309995627197444, "phrase": "real_time"}, {"score": 0.0025137856138000014, "phrase": "detection_process"}, {"score": 0.0024797072773840704, "phrase": "target_model"}, {"score": 0.002429451930463481, "phrase": "training_process"}, {"score": 0.0023802126605244438, "phrase": "manual_initialization"}, {"score": 0.002233301265743633, "phrase": "prefect_detection"}, {"score": 0.002203016940021265, "phrase": "performance_gain"}, {"score": 0.0021049977753042253, "phrase": "background_clutter"}], "paper_keywords": ["Online tracking", " robot navigation", " depth camera"], "paper_abstract": "Indoor environment is a common scene in our everyday life, and detecting and tracking multiple targets in this environment is a key component for many applications. However, this task still remains challenging due to limited space, intrinsic target appearance variation, e. g. full or partial occlusion, large pose deformation, and scale change. In the proposed approach, we give a novel framework for detection and tracking in indoor environments, and extend it to robot navigation. One of the key components of our approach is a virtual top view created from an RGB-D camera, which is named ground plane projection (GPP). The key advantage of using GPP is the fact that the intrinsic target appearance variation and extrinsic noise is far less likely to appear in GPP than in a regular side-view image. Moreover, it is a very simple task to determine free space in GPP without any appearance learning even from a moving camera. Hence GPP is very different from the top-view image obtained from a ceiling mounted camera. We perform both object detection and tracking in GPP. Two kinds of GPP images are utilized: gray GPP, which represents the maximal height of 3D points projecting to each pixel, and binary GPP, which is obtained by thresholding the gray GPP. For detection, a simple connected component labeling is used to detect footprints of targets in binary GPP. For tracking, a novel Pixel Level Association (PLA) strategy is proposed to link the same target in consecutive frames in gray GPP. It utilizes optical flow in gray GPP, which to our best knowledge has never been done before. Then we \"back project\" the detected and tracked objects in GPP to original, sideview (RGB) images. Hence we are able to detect and track objects in the side-view (RGB) images. Our system is able to robustly detect and track multiple moving targets in real time. The detection process does not rely on any target model, which means we do not need any training process. Moreover, tracking does not require any manual initialization, since all entering objects are robustly detected. We also extend the novel framework to robot navigation by tracking. As our experimental results demonstrate, our approach can achieve near prefect detection and tracking results. The performance gain in comparison to state-of-the-art trackers is most significant in the presence of occlusion and background clutter.", "paper_title": "ONLINE MULTIPLE TARGETS DETECTION AND TRACKING FROM MOBILE ROBOT IN CLUTTERED INDOOR ENVIRONMENTS WITH DEPTH CAMERA", "paper_id": "WOS:000337801000004"}