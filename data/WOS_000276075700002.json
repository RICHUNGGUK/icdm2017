{"auto_keywords": [{"score": 0.04660802533264657, "phrase": "twin_boosting"}, {"score": 0.0048149882108785465, "phrase": "twin"}, {"score": 0.004031495920060339, "phrase": "false_positives"}, {"score": 0.0034924598001567944, "phrase": "predictive_accuracy"}, {"score": 0.002984173420996039, "phrase": "general_weak_learners"}, {"score": 0.002903628734069691, "phrase": "wide_variety"}, {"score": 0.002805989498127897, "phrase": "generalized_regression"}, {"score": 0.002549672862868133, "phrase": "large_problems"}, {"score": 0.002515014676664348, "phrase": "potentially_many_more_features"}, {"score": 0.002364777610365689, "phrase": "special_case"}, {"score": 0.002332626862738603, "phrase": "orthonormal_linear_models"}, {"score": 0.0021932609696277937, "phrase": "adaptive_lasso"}, {"score": 0.0021340178074057245, "phrase": "theoretical_aspects"}, {"score": 0.0021049977753042253, "phrase": "feature_selection"}], "paper_keywords": ["Classification", " Gradient descent", " High-dimensional data", " Regression", " Regularization"], "paper_abstract": "We propose Twin Boosting which has much better feature selection behavior than boosting, particularly with respect to reducing the number of false positives (falsely selected features). In addition, for cases with a few important effective and many noise features, Twin Boosting also substantially improves the predictive accuracy of boosting. Twin Boosting is as general and generic as (gradient-based) boosting. It can be used with general weak learners and in a wide variety of situations, including generalized regression, classification or survival modeling. Furthermore, it is computationally feasible for large problems with potentially many more features than observed samples. Finally, for the special case of orthonormal linear models, we prove equivalence of Twin Boosting to the adaptive Lasso which provides some theoretical aspects on feature selection with Twin Boosting.", "paper_title": "Twin Boosting: improved feature selection and prediction", "paper_id": "WOS:000276075700002"}