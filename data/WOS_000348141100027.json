{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "unsupervised_dimension_reduction"}, {"score": 0.004748556604045108, "phrase": "least-squares_quadratic_mutual_information"}, {"score": 0.004586531354697466, "phrase": "dimension_reduction"}, {"score": 0.0044608829094248985, "phrase": "high-dimensional_data"}, {"score": 0.00436890075128947, "phrase": "lower-dimensional_subspace"}, {"score": 0.004278807087784626, "phrase": "intrinsic_properties"}, {"score": 0.004190563478825626, "phrase": "original_data"}, {"score": 0.003936560022538905, "phrase": "important_challenge"}, {"score": 0.003621588555525458, "phrase": "supervised_information"}, {"score": 0.0034978813769575233, "phrase": "parameter_selection"}, {"score": 0.0031514627590375354, "phrase": "information-theoretic_approach"}, {"score": 0.0030437652050982643, "phrase": "objective_tuning_parameter_selection"}, {"score": 0.0029602552900111407, "phrase": "quadratic_mutual_information"}, {"score": 0.002630085891013006, "phrase": "ordinary_mutual_information"}, {"score": 0.0025757568391827235, "phrase": "qmi"}, {"score": 0.0024704333220467393, "phrase": "least-squares_method"}, {"score": 0.002419393934835993, "phrase": "computationally_efficient_way"}, {"score": 0.0023043558058824572, "phrase": "eigenvector-based_efficient_implementation"}, {"score": 0.0021947755130109696, "phrase": "qmi_estimator"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["unsupervised dimension reduction", " quadratic mutual information", " least-squares density difference", " Epanechnikov kernel", " hyperparameter tuning"], "paper_abstract": "The goal of dimension reduction is to represent high-dimensional data in a lower-dimensional subspace, while intrinsic properties of the original data are kept as much as possible. An important challenge in unsupervised dimension reduction is the choice of tuning parameters, because no supervised information is available and thus parameter selection tends to be subjective and heuristic. In this paper, we propose an information-theoretic approach to unsupervised dimension reduction that allows objective tuning parameter selection. We employ quadratic mutual information (QMI) as our information measure, which is known to be less sensitive to outliers than ordinary mutual information, and QMI is estimated analytically by a least-squares method in a computationally efficient way. Then, we provide an eigenvector-based efficient implementation for performing unsupervised dimension reduction based on the QMI estimator. The usefulness of the proposed method is demonstrated through experiments.", "paper_title": "Unsupervised Dimension Reduction via Least-Squares Quadratic Mutual Information", "paper_id": "WOS:000348141100027"}