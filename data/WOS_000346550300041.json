{"auto_keywords": [{"score": 0.04928833151703452, "phrase": "bayesian_framework"}, {"score": 0.048975574052803, "phrase": "heavy-tailed_distribution"}, {"score": 0.04081578574791827, "phrase": "model_output"}, {"score": 0.04003671841917816, "phrase": "likelihood_function"}, {"score": 0.03611681085383697, "phrase": "corresponding_model"}, {"score": 0.031734443947036915, "phrase": "student's_t-distribution"}, {"score": 0.030921851836227438, "phrase": "rbelm-t"}, {"score": 0.004815008415160623, "phrase": "elm"}, {"score": 0.004672727518631859, "phrase": "weighted_likelihood_function"}, {"score": 0.004626255242038005, "phrase": "actual_industrial_processes"}, {"score": 0.004371470939474398, "phrase": "corrupted_approximation_function"}, {"score": 0.004242291530697285, "phrase": "new_robust_extreme_learning_machine_method"}, {"score": 0.004103212598803194, "phrase": "main_idea"}, {"score": 0.004075946554498088, "phrase": "rbelm"}, {"score": 0.004008568312912331, "phrase": "gaussian_distribution"}, {"score": 0.003929177231678094, "phrase": "probability_density_function"}, {"score": 0.0034730657554172405, "phrase": "laplace_distribution"}, {"score": 0.003381607100127276, "phrase": "rbelm-l"}, {"score": 0.003314591878914152, "phrase": "posterior_distribution"}, {"score": 0.0032597581672236453, "phrase": "approximate_surrogate_function"}, {"score": 0.0031109870010753663, "phrase": "maximum_likelihood-type_ii"}, {"score": 0.0027680095380207756, "phrase": "infinitely_many_normal_distributions"}, {"score": 0.0027404283412788997, "phrase": "gamma_distribution"}, {"score": 0.0026950674053179404, "phrase": "variational_inference_method"}, {"score": 0.002641621667026613, "phrase": "approximate_solution"}, {"score": 0.0024627509513027923, "phrase": "robust_statistic"}, {"score": 0.002421975107313603, "phrase": "robust_error_measure"}, {"score": 0.0023190823948528953, "phrase": "testing_data"}, {"score": 0.002288309252254464, "phrase": "numerical_comparison"}, {"score": 0.0021764949731965656, "phrase": "proposed_rbelm-l"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Extreme learning machine", " Bayesian regression", " Heavy-tailed distributions", " Weighted likelihood", " Variational inference", " Robust model"], "paper_abstract": "In actual industrial processes, the data used for modeling usually contains some outliers, which may lead to a corrupted approximation function. In this paper, we propose a new Robust Extreme Learning Machine method based on a Bayesian framework (RBELM). The main idea of RBELM is to replace the Gaussian distribution with a heavy-tailed distribution as the probability density function of the model output and give weights to the likelihood function based on the error of the model output, which makes the model more robust to outliers. Two different heavy-tailed distributions are used in this paper. One is the Laplace distribution, and the corresponding model is denoted as RBELM-l. In RBELM-l, the posterior distribution is replaced by an approximate surrogate function, and then the parameters learning problem can be solved by means of Maximum Likelihood-type II (ML-H). The other is the Student's t-distribution, and the corresponding model is denoted as RBELM-t. In order to solve RBELM-t, the Student's t-distribution is written as a scale-mixture of infinitely many Normal distributions and a Gamma distribution. Then, the variational inference method is used to obtain an approximate solution for the parameters. Also, we propose two methods for giving weights to the likelihood function based on the concepts of robust statistic. Finally, a robust error measure is proposed for evaluating the performance of models with outliers in the testing data. Results of numerical comparison based on one synthesis data set, four real benchmark regression problems, and two actual industrial modeling problems show the usefulness of the proposed RBELM-l and RBELM-t. (C) 2014 Published by Elsevier B.V.", "paper_title": "A new robust ELM method based on a Bayesian framework with heavy-tailed distribution and weighted likelihood function", "paper_id": "WOS:000346550300041"}