{"auto_keywords": [{"score": 0.03235740424067532, "phrase": "intel"}, {"score": 0.004958331648755645, "phrase": "dgemm"}, {"score": 0.004405596416783185, "phrase": "parallelized_mathematical_libraries"}, {"score": 0.004289686492089576, "phrase": "common_way"}, {"score": 0.004176813329075736, "phrase": "numerical_applications"}, {"score": 0.004103212598803194, "phrase": "computer_architectures"}, {"score": 0.0040309035566691645, "phrase": "shared_memory_characteristics"}, {"score": 0.003959863717046575, "phrase": "different_approaches"}, {"score": 0.003687960013746783, "phrase": "openmp_or_mpi._this_paper's_content"}, {"score": 0.003434662174045939, "phrase": "dgemm_calls"}, {"score": 0.0033442114331500407, "phrase": "point_matrix_multiplication"}, {"score": 0.0031703706626348507, "phrase": "different_openmp"}, {"score": 0.0031422859551159506, "phrase": "parallelized_numerical_libraries"}, {"score": 0.002952516738708181, "phrase": "scsl"}, {"score": 0.002537880772794665, "phrase": "memory_placement_policy"}, {"score": 0.002427372728532664, "phrase": "initializing_data"}], "paper_keywords": [""], "paper_abstract": "Using functions of parallelized mathematical libraries is a common way to accelerate numerical applications. Computer architectures with shared memory characteristics support different approaches for the implementation of such libraries, usually OpenMP or MPI. This paper's content is based on the performance comparison of DGEMM calls (floating point matrix multiplication, double precision) with different OpenMP parallelized numerical libraries, namely Intel MKL and SGI SCSL, and how they can be optimized. Additionally, we have a look at the memory placement policy and give hints for initializing data. Our attention has been focused on a SGI Altix 3700 Bx2 system using BenchIT [1] as a very convenient performance measurement suite for the examinations.", "paper_title": "Optimizing OpenMP parallelized DGEMM calls on SGI Altix 3700", "paper_id": "WOS:000241469500013"}