{"auto_keywords": [{"score": 0.027643733067438878, "phrase": "achlioptas"}, {"score": 0.00481495049065317, "phrase": "sparser_johnson-lindenstrauss"}, {"score": 0.004223708778943785, "phrase": "linear_mappings"}, {"score": 0.003417565253539315, "phrase": "high_probability"}, {"score": 0.003216804708106142, "phrase": "asymptotically_optimal_number"}, {"score": 0.0029973957125353306, "phrase": "first_constructions"}, {"score": 0.002907992115184249, "phrase": "subconstant_sparsity"}, {"score": 0.0026554236621262515, "phrase": "previous_works"}], "paper_keywords": ["Algorithms", " Theory", " Dimensionality reduction", " Johnson-Lindenstrauss", " numerical linear algebra", " streaming algorithms"], "paper_abstract": "We give two different and simple constructions for dimensionality reduction in l(2) via linear mappings that are sparse: only an O(epsilon)- fraction of entries in each column of our embedding matrices are non-zero to achieve distortion 1+epsilon with high probability, while still achieving the asymptotically optimal number of rows. These are the first constructions to provide subconstant sparsity for all values of parameters, improving upon previous works of Achlioptas [2003] and Dasgupta et al. [2010]. Such distributions can be used to speed up applications where l(2) dimensionality reduction is used.", "paper_title": "Sparser Johnson-Lindenstrauss Transforms", "paper_id": "WOS:000331466500004"}