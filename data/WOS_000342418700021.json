{"auto_keywords": [{"score": 0.0357198079604387, "phrase": "mcsvm"}, {"score": 0.014859725905966752, "phrase": "face_system"}, {"score": 0.011171745218161264, "phrase": "hmm"}, {"score": 0.00481495049065317, "phrase": "embedded_confusable_system"}, {"score": 0.004782848614014638, "phrase": "real_time"}, {"score": 0.004503350877279651, "phrase": "low_computational_complexity"}, {"score": 0.0043697607816770775, "phrase": "confusable_system"}, {"score": 0.004282900153232246, "phrase": "efficient_phoneme-viseme_mapping_table"}, {"score": 0.004211831095629, "phrase": "phoneme_grouping"}, {"score": 0.0041837333868790134, "phrase": "houtgast_similarity_approach"}, {"score": 0.004100555318595827, "phrase": "viseme_similarity_estimation"}, {"score": 0.004073196909500369, "phrase": "histogram_distance"}, {"score": 0.003912822391390783, "phrase": "generated_mapping_table"}, {"score": 0.003860774424566198, "phrase": "mapping_problem"}, {"score": 0.003822191555851545, "phrase": "viseme_classification_accuracy"}, {"score": 0.003622811707147052, "phrase": "snr-aware_speech_enhancement"}, {"score": 0.003480108299476168, "phrase": "robust_acoustic_feature_vectors"}, {"score": 0.003433796409346569, "phrase": "recognition_network_processing"}, {"score": 0.003331828027460222, "phrase": "recognition_network_approach"}, {"score": 0.0033095814296125532, "phrase": "phoneme_recognition"}, {"score": 0.003287482882222731, "phrase": "viseme_classification"}, {"score": 0.00318984544993994, "phrase": "sequential_inputs"}, {"score": 0.003136857047565403, "phrase": "superior_performance"}, {"score": 0.0030950988205648605, "phrase": "good_generalization_properties"}, {"score": 0.003053894781246847, "phrase": "limited_samples"}, {"score": 0.0030233510365494406, "phrase": "phoneme-viseme_mapping_table"}, {"score": 0.002943381865409788, "phrase": "observation_sequence"}, {"score": 0.0029237213120317227, "phrase": "hmm_results"}, {"score": 0.002884792163423083, "phrase": "viseme_class"}, {"score": 0.002808477620731167, "phrase": "lip_shape_image"}, {"score": 0.0027710786693798534, "phrase": "time_sequence"}, {"score": 0.0027068216332674895, "phrase": "dynamic_alpha"}, {"score": 0.0026797398345997114, "phrase": "different_alpha_value_settings"}, {"score": 0.0026088355715432523, "phrase": "used_speech_signal_processing"}, {"score": 0.0025568881277209725, "phrase": "clean_speech"}, {"score": 0.0024892298523153107, "phrase": "wer"}, {"score": 0.0023044856709624494, "phrase": "gsm_communication"}, {"score": 0.0022890828779208016, "phrase": "mobile_phone"}, {"score": 0.0022585847551229274, "phrase": "visual_quality_rating"}, {"score": 0.0022359775196858765, "phrase": "driven_feeling"}, {"score": 0.00222103160420506, "phrase": "mean_opinion_score"}, {"score": 0.002140593237903078, "phrase": "lip_shape_images"}, {"score": 0.0021262835396323623, "phrase": "confusable_sets"}, {"score": 0.0021049977753042253, "phrase": "real-time_operation"}], "paper_keywords": ["Real-time speech driven", " Lip-synch", " Talking face", " Hidden markov model (HMM)", " Multiclass support vector machine (MCSVM)", " Viseme histogram similarity", " Confusion matrix"], "paper_abstract": "This paper presents a real-time speech-driven talking face system which provides low computational complexity and smoothly visual sense. A novel embedded confusable system is proposed to generate an efficient phoneme-viseme mapping table which is constructed by phoneme grouping using Houtgast similarity approach based on the results of viseme similarity estimation using histogram distance, according to the concept of viseme visually ambiguous. The generated mapping table can simplify the mapping problem and promote viseme classification accuracy. The implemented real time speech-driven talking face system includes: 1) speech signal processing, including SNR-aware speech enhancement for noise reduction and ICA-based feature set extractions for robust acoustic feature vectors; 2) recognition network processing, HMM and MCSVM are combined as a recognition network approach for phoneme recognition and viseme classification, which HMM is good at dealing with sequential inputs, while MCSVM shows superior performance in classifying with good generalization properties, especially for limited samples. The phoneme-viseme mapping table is used for MCSVM to classify the observation sequence of HMM results, which the viseme class is belong to; 3) visual processing, arranges lip shape image of visemes in time sequence, and presents more authenticity using a dynamic alpha blending with different alpha value settings. Presented by the experiments, the used speech signal processing with noise speech comparing with clean speech, could gain 1.1 % (16.7 % to 15.6 %) and 4.8 % (30.4 % to 35.2 %) accuracy rate improvements in PER and WER, respectively. For viseme classification, the error rate is decreased from 19.22 % to 9.37 %. Last, we simulated a GSM communication between mobile phone and PC for visual quality rating and speech driven feeling using mean opinion score. Therefore, our method reduces the number of visemes and lip shape images by confusable sets and enables real-time operation.", "paper_title": "Speech-driven talking face using embedded confusable system for real time mobile multimedia", "paper_id": "WOS:000342418700021"}