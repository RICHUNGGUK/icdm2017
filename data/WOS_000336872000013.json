{"auto_keywords": [{"score": 0.04418518864132593, "phrase": "complex_scenes"}, {"score": 0.00481495049065317, "phrase": "adaptive_fusing_model"}, {"score": 0.004729856080441582, "phrase": "hybrid_feature_space"}, {"score": 0.0046739596755881185, "phrase": "accurate_extraction"}, {"score": 0.004618720776729413, "phrase": "foreground_objects"}, {"score": 0.004275173711009189, "phrase": "challenging_problem"}, {"score": 0.004174677062711731, "phrase": "illumination_variations"}, {"score": 0.004125314447335291, "phrase": "dynamic_backgrounds"}, {"score": 0.003910278811774747, "phrase": "foreground_object_detection_approach"}, {"score": 0.0036625643243684827, "phrase": "temporal_persistence"}, {"score": 0.003619235073669304, "phrase": "texture_sequences"}, {"score": 0.0035341028694769036, "phrase": "liao's_method"}, {"score": 0.0034101316738399203, "phrase": "spatiotemporal_domain"}, {"score": 0.003329901594166227, "phrase": "modified_local_image"}, {"score": 0.003118838635447237, "phrase": "adaptive_fusion_approach"}, {"score": 0.002903771635043968, "phrase": "existing_fusion_methods"}, {"score": 0.0026874405408023956, "phrase": "actual_situations"}, {"score": 0.002371424085814217, "phrase": "lateral_inhibition_filter_model"}, {"score": 0.002315574871863272, "phrase": "neighborhood_information"}, {"score": 0.0022610379771517966, "phrase": "pixel's_confidence_score"}, {"score": 0.0022209780222461587, "phrase": "comprehensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Foreground detection", " ST-SILTP", " Adaptive fusion model", " Lateral inhibition filter"], "paper_abstract": "Accurate extraction of foreground objects is crucial for tracking and recognition, and it is still a challenging problem in complex scenes with illumination variations and dynamic backgrounds. In this paper, we propose a foreground object detection approach with three aspects of contributions. First, considering the temporal persistence of texture sequences, we extend Liao's method [1] to the spatiotemporal domain and propose a modified local image descriptor called ST-SILTP. Second, we present an adaptive fusion approach of color and texture to compensate for their respective defects. Unlike those existing fusion methods, we do not need to adjust the parameters manually to adapt actual situations. Third, since a pixel of foreground or not depends on not only itself but also its neighborhood, we utilize the lateral inhibition filter model to incorporate the neighborhood information into calculating the pixel's confidence score. The comprehensive experiments on the dataset containing complex scenes demonstrate that the proposed approach is superior to the existing state-of-the-art algorithms. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Detect foreground objects via adaptive fusing model in a hybrid feature space", "paper_id": "WOS:000336872000013"}