{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "context"}, {"score": 0.004671588539217021, "phrase": "visual_data"}, {"score": 0.004624751696958501, "phrase": "smart_homes"}, {"score": 0.004555371402128666, "phrase": "information_fusion"}, {"score": 0.0044870272550540415, "phrase": "ambient_intelligence"}, {"score": 0.004471014782259966, "phrase": "ami"}, {"score": 0.004288059466938456, "phrase": "computational_systems"}, {"score": 0.003975781274672803, "phrase": "everyday_tasks"}, {"score": 0.003935892934907777, "phrase": "visual_sensors"}, {"score": 0.003558294449586273, "phrase": "scene_objects"}, {"score": 0.003233075944817365, "phrase": "cognitive_framework"}, {"score": 0.003152531962718477, "phrase": "ami_applications"}, {"score": 0.003105168935158648, "phrase": "visual_sensor_networks"}, {"score": 0.002922705896608178, "phrase": "priori_context_knowledge"}, {"score": 0.0028498718992429825, "phrase": "real_time_single_camera_data"}, {"score": 0.0028070431733705735, "phrase": "logic-based_high-level_local_interpretation"}, {"score": 0.0025892330566358503, "phrase": "feedback_recommendations"}, {"score": 0.0025503112711036994, "phrase": "data_acquisition_procedures"}, {"score": 0.0024993218789131437, "phrase": "recognized_situations"}, {"score": 0.0024247382451294255, "phrase": "central_node"}, {"score": 0.0023762535034673017, "phrase": "overall_description"}, {"score": 0.0022937210378944457, "phrase": "ami_services"}, {"score": 0.002137137933768807, "phrase": "prototype_system"}, {"score": 0.0021049977753042253, "phrase": "smart_home_scenario"}], "paper_keywords": ["Ambient intelligence", " Computer vision", " Data and information fusion", " Context", " Ontologies"], "paper_abstract": "Ambient Intelligence (AmI) aims at the development of computational systems that process data acquired by sensors embedded in the environment to support users in everyday tasks. Visual sensors, however, have been scarcely used in this kind of applications, even though they provide very valuable information about scene objects: position, speed, color, texture, etc. In this paper, we propose a cognitive framework for the implementation of AmI applications based on visual sensor networks. The framework, inspired by the Information Fusion paradigm, combines a priori context knowledge represented with ontologies with real time single camera data to support logic-based high-level local interpretation of the current situation. In addition, the system is able to automatically generate feedback recommendations to adjust data acquisition procedures. Information about recognized situations is eventually collected by a central node to obtain an overall description of the scene and consequently trigger AmI services. We show the extensible and adaptable nature of the approach with a prototype system in a smart home scenario.", "paper_title": "Context-based scene recognition from visual data in smart homes: an Information Fusion approach", "paper_id": "WOS:000309242900005"}