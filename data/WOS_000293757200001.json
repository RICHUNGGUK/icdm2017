{"auto_keywords": [{"score": 0.04511750041358268, "phrase": "aggregation_procedure"}, {"score": 0.040179907029343674, "phrase": "optimal_aggregation_procedures"}, {"score": 0.00481495049065317, "phrase": "hyper-sparse"}, {"score": 0.0044688500725247726, "phrase": "learning_sample"}, {"score": 0.0039841418890102925, "phrase": "best_function"}, {"score": 0.0037834649508375544, "phrase": "convex_combinations"}, {"score": 0.0036768994925991012, "phrase": "f."}, {"score": 0.0033152062780180073, "phrase": "particular_interest"}, {"score": 0.0030239842475439814, "phrase": "suboptimal_aggregation_procedures"}, {"score": 0.0028880836335117297, "phrase": "minimal_number"}, {"score": 0.002711109302199029, "phrase": "optimal_aggregation_procedure"}, {"score": 0.0025596276616952516, "phrase": "numerical_study"}, {"score": 0.002444544487772349, "phrase": "regularization_parameters"}, {"score": 0.0024029313400826457, "phrase": "lasso"}, {"score": 0.002361632539339945, "phrase": "elastic-net_estimators"}, {"score": 0.002294686545883412, "phrase": "simulated_examples"}, {"score": 0.0022296340517805125, "phrase": "exponential_weights"}, {"score": 0.0021049977753042253, "phrase": "selection_procedures"}], "paper_keywords": ["aggregation", " exact oracle inequality", " empirical risk minimization", " empirical process theory", " sparsity", " Lasso", " Lars"], "paper_abstract": "Given a finite set F of functions and a learning sample, the aim of an aggregation procedure is to have a risk as close as possible to risk of the best function in F. Up to now, optimal aggregation procedures are convex combinations of every elements of F. In this paper, we prove that optimal aggregation procedures combining only two functions in F exist. Such algorithms are of particular interest when F contains many irrelevant functions that should not appear in the aggregation procedure. Since selectors are suboptimal aggregation procedures, this proves that two is the minimal number of elements of F required for the construction of an optimal aggregation procedure in every situations. Then, we perform a numerical study for the problem of selection of the regularization parameters of the Lasso and the Elastic-net estimators. We compare on simulated examples our aggregation algorithms to aggregation with exponential weights, to Mallow's C(p) and to cross-validation selection procedures.", "paper_title": "Hyper-Sparse Optimal Aggregation", "paper_id": "WOS:000293757200001"}