{"auto_keywords": [{"score": 0.0448143060594691, "phrase": "temporal_model_propagation"}, {"score": 0.042478821150660054, "phrase": "likelihood_maps"}, {"score": 0.038323814569956004, "phrase": "temporal_step"}, {"score": 0.00481495049065317, "phrase": "floating_foreground"}, {"score": 0.004617949594931096, "phrase": "on-line_algorithm"}, {"score": 0.004388035083357706, "phrase": "moving_camera"}, {"score": 0.004247696749118451, "phrase": "spatial_model_composition"}, {"score": 0.00411182818527434, "phrase": "background_models"}, {"score": 0.00383508177668219, "phrase": "energy_minimization_technique"}, {"score": 0.003610292749660581, "phrase": "block-wise_models"}, {"score": 0.0035273744062641636, "phrase": "previous_frame"}, {"score": 0.0034947408949397127, "phrase": "motion_information"}, {"score": 0.003367188029221534, "phrase": "current_frame"}, {"score": 0.0032292292848296617, "phrase": "spatial_step"}, {"score": 0.0028350413546400703, "phrase": "graph-cut_algorithm"}, {"score": 0.0027062100658653485, "phrase": "segmentation_result"}, {"score": 0.002488851299416018, "phrase": "spatial_model_composition_step"}, {"score": 0.002397923568994474, "phrase": "updated_motions"}, {"score": 0.0023427844897844093, "phrase": "iterative_procedure"}, {"score": 0.002236272403824371, "phrase": "large_camera"}, {"score": 0.0021848422732893926, "phrase": "significant_background_changes"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Foreground/background segmentation", " Motion estimation", " Kernel density estimation", " Graph-cut"], "paper_abstract": "We propose an on-line algorithm to segment foreground from background in videos captured by a moving camera. In our algorithm, temporal model propagation and spatial model composition are combined to generate foreground and background models, and likelihood maps are computed based on the models. After that, an energy minimization technique is applied to the likelihood maps for segmentation. In the temporal step, block-wise models are transferred from the previous frame using motion information, and pixel-wise foreground/background likelihoods and labels in the current frame are estimated using the models. In the spatial step, another block-wise foreground/background models are constructed based on the models and labels given by the temporal step, and the corresponding per-pixel likelihoods are also generated. A graph-cut algorithm performs segmentation based on the foreground/background likelihood maps, and the segmentation result is employed to update the motion of each segment in a block; the temporal model propagation and the spatial model composition step are re-evaluated based on the updated motions, by which the iterative procedure is implemented. We tested our framework with various challenging videos involving large camera and object motions, significant background changes and clutters. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Modeling and segmentation of floating foreground and background in videos", "paper_id": "WOS:000300459000038"}