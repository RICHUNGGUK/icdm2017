{"auto_keywords": [{"score": 0.029960777002537447, "phrase": "proposed_framework"}, {"score": 0.00481495049065317, "phrase": "pipeline-architecture_based"}, {"score": 0.004781357546476652, "phrase": "real-time_active-vision"}, {"score": 0.004426882270402403, "phrase": "generic_framework"}, {"score": 0.00436530211426514, "phrase": "on-line_reconfiguration"}, {"score": 0.004274527415193801, "phrase": "multi-camera_active-vision_system"}, {"score": 0.004041546659145336, "phrase": "customizable_pipeline_architecture"}, {"score": 0.003848088904418221, "phrase": "real_time"}, {"score": 0.00379452936798156, "phrase": "subject_visibility"}, {"score": 0.003663857375787215, "phrase": "depth-limited_search_algorithm"}, {"score": 0.0034884152484429207, "phrase": "real-time_operation"}, {"score": 0.003415812499773905, "phrase": "central_focus"}, {"score": 0.0033447157263095223, "phrase": "human_action-sensing_implementation_example"}, {"score": 0.0031182092708983184, "phrase": "human_analogue"}, {"score": 0.0029688173975648173, "phrase": "real_human"}, {"score": 0.002767696345005216, "phrase": "tangible_increase"}, {"score": 0.002729133029776093, "phrase": "action-recognition_success_rate"}, {"score": 0.0025801648787263662, "phrase": "static_cameras"}, {"score": 0.0021049977753042253, "phrase": "-system_mobility"}], "paper_keywords": ["Surveillance", " Sensing-system reconfiguration", " Active vision", " Form recognition"], "paper_abstract": "This paper presents a generic framework for on-line reconfiguration of a multi-camera active-vision system for time-varying-geometry object/subject action recognition. The proposed methodology utilizes customizable pipeline architecture to select optimal camera poses in real time. Subject visibility is optimized via a depth-limited search algorithm. All stages are developed with real-time operation as the central focus. A human action-sensing implementation example demonstrates viability. Controlled experiments, first with a human analogue and, subsequently, with a real human, illustrate the workings of the proposed framework. A tangible increase in action-recognition success rate over other strategies, particularly those with static cameras, is noteworthy. The proposed framework is also shown to operate in real-time. Further experiments examine the effect of scaling the number of obstacles and cameras, sensing-system mobility, and library actions on real-time performance.", "paper_title": "Pipeline-Architecture Based Real-Time Active-Vision for Human-Action Recognition", "paper_id": "WOS:000326192300008"}