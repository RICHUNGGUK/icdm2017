{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "dvfs"}, {"score": 0.015486809958002438, "phrase": "many-core_architectures"}, {"score": 0.0047787596516662, "phrase": "efficient_power_state_transitions"}, {"score": 0.0046018264570209765, "phrase": "first-class_design_constraint"}, {"score": 0.004567230180529598, "phrase": "high-performance_computing"}, {"score": 0.004348580182733617, "phrase": "carbon_footprint"}, {"score": 0.004315879542755464, "phrase": "hpc_systems"}, {"score": 0.004283423748543866, "phrase": "dynamic_voltage"}, {"score": 0.004140354220982935, "phrase": "commonly_used_power_management_technique"}, {"score": 0.004047628461126961, "phrase": "power_consumption"}, {"score": 0.003942059405218598, "phrase": "time-varying_program_behavior"}, {"score": 0.003882970272082245, "phrase": "prior_work"}, {"score": 0.0036005006349430586, "phrase": "crucial_factor"}, {"score": 0.0035198224928307854, "phrase": "power_management_scheme"}, {"score": 0.0034933321145368336, "phrase": "frequent_power_state_transitions"}, {"score": 0.00340217066797559, "phrase": "real_impact"}, {"score": 0.003363830908814182, "phrase": "execution_performance"}, {"score": 0.0032760377953971248, "phrase": "multiple_voltage_domains"}, {"score": 0.0031665087019813244, "phrase": "dvfs_latencies"}, {"score": 0.003026127736667187, "phrase": "new_latency-aware_dvfs_scheme"}, {"score": 0.0029807267909921628, "phrase": "optimal_power_state"}, {"score": 0.0028810424107858436, "phrase": "latency_characteristics"}, {"score": 0.0028164399450837465, "phrase": "novel_profile-guided_dvfs_solution"}, {"score": 0.0027741761880779535, "phrase": "varying_execution_patterns"}, {"score": 0.0027428939498108746, "phrase": "parallel_program"}, {"score": 0.0027119634978446895, "phrase": "excessive_power_state_transitions"}, {"score": 0.002631172352670227, "phrase": "power_management_library"}, {"score": 0.002591681512611419, "phrase": "shared-memory_parallel_applications"}, {"score": 0.0025335509856200433, "phrase": "intel_scc_many-core_platform"}, {"score": 0.002486103638234488, "phrase": "power_efficiency"}, {"score": 0.0024120247307686084, "phrase": "latency-unaware_approach"}, {"score": 0.002313748594795675, "phrase": "energy-delay_product"}, {"score": 0.0022618378709785172, "phrase": "execution_time"}, {"score": 0.0022363199197710385, "phrase": "average_case"}, {"score": 0.0021451873499061633, "phrase": "prior_dvfs_approach"}, {"score": 0.0021049977753042253, "phrase": "latency_effects"}], "paper_keywords": ["Power management", " Dynamic voltage and frequency scaling", " Profiling", " Shared virtual memory", " Many-core processors", " The single-chip cloud computer"], "paper_abstract": "Energy efficiency is quickly becoming a first-class design constraint in high-performance computing (HPC). We need more efficient power management solutions to save energy costs and carbon footprint of HPC systems. Dynamic voltage and frequency scaling (DVFS) is a commonly used power management technique for making a trade-off between power consumption and system performance according to the time-varying program behavior. However, prior work on DVFS seldom takes into account the voltage and frequency scaling latencies, which we found to be a crucial factor determining the efficiency of the power management scheme. Frequent power state transitions without latency awareness can make a real impact on the execution performance of applications. The design of multiple voltage domains in some many-core architectures has made the effect of DVFS latencies even more significant. These concerns lead us to propose a new latency-aware DVFS scheme to adjust the optimal power state more accurately. Our main idea is to analyze the latency characteristics in depth and design a novel profile-guided DVFS solution which exploits the varying execution patterns of the parallel program to avoid excessive power state transitions. We implement the solution into a power management library for use by shared-memory parallel applications. Experimental evaluation on the Intel SCC many-core platform shows significant improvement in power efficiency after using our scheme. Compared with a latency-unaware approach, we achieve 24.0 % extra energy saving, 31.3 % more reduction in the energy-delay product and 15.2 % less overhead in execution time in the average case for various benchmarks. Our algorithm is also proved to outperform a prior DVFS approach attempted to mitigate the latency effects.", "paper_title": "Latency-aware DVFS for efficient power state transitions on many-core architectures", "paper_id": "WOS:000357345600018"}