{"auto_keywords": [{"score": 0.037085211414711, "phrase": "quadratic_program"}, {"score": 0.015719716506582538, "phrase": "support_vector_clustering"}, {"score": 0.004518442937844318, "phrase": "intra-cluster_similarity"}, {"score": 0.0044237033788643715, "phrase": "inter-cluster_similarity"}, {"score": 0.004285293395708244, "phrase": "svc"}, {"score": 0.004195418010131832, "phrase": "clustering_approach"}, {"score": 0.0041074234667687875, "phrase": "arbitrarily_shaped_cluster_boundaries"}, {"score": 0.004042635935882651, "phrase": "execution_time"}, {"score": 0.003753498345597498, "phrase": "kernel_function"}, {"score": 0.003674738405118697, "phrase": "nonlinear_transformation"}, {"score": 0.0036167509502276294, "phrase": "input_data"}, {"score": 0.0029253546782349875, "phrase": "kernel_width_value"}, {"score": 0.002658863179011018, "phrase": "starting_point"}, {"score": 0.0026307897899760383, "phrase": "efficient_exploration"}, {"score": 0.002561892963059385, "phrase": "kernel_width_values"}, {"score": 0.002231607958228148, "phrase": "novel_way"}, {"score": 0.0021847119298612264, "phrase": "important_deficiency_present"}, {"score": 0.0021616339773325704, "phrase": "previous_methods"}, {"score": 0.0021049977753042253, "phrase": "two-dimensional_and_high-dimensional_data_sets"}], "paper_keywords": ["Cluster analysis", " Support vector clustering"], "paper_abstract": "The process of clustering groups together data points so that intra-cluster similarity is maximized while inter-cluster similarity is minimized. Support vector clustering (SVC) is a clustering approach that can identify arbitrarily shaped cluster boundaries. The execution time of SVC depends heavily on several factors: choice of the width of a kernel function that determines a nonlinear transformation of the input data, solution of a quadratic program, and the way that the output of the quadratic program is used to produce clusters. This paper builds on our prior SVC research in two ways. First, we propose a method for identifying a kernel width value in a region where our experiments suggest that clustering structure is changing significantly. This can form the starting point for efficient exploration of the space of kernel width values. Second, we offer a technique, called cone cluster labeling, that uses the output of the quadratic program to build clusters in a novel way that avoids an important deficiency present in previous methods. Our experimental results use both two-dimensional and high-dimensional data sets.", "paper_title": "Gaussian kernel width exploration and cone cluster labeling for support vector clustering", "paper_id": "WOS:000306121400009"}