{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "budgeted_learning"}, {"score": 0.004635187610736025, "phrase": "budgeted_machine_learning"}, {"score": 0.0045108906244892165, "phrase": "learning_algorithm"}, {"score": 0.004462105963334103, "phrase": "free_access"}, {"score": 0.004389912080394437, "phrase": "training_examples'_class_labels"}, {"score": 0.004090274535243564, "phrase": "learning_model"}, {"score": 0.003937459891461576, "phrase": "medical_applications"}, {"score": 0.0038527044625533574, "phrase": "new_algorithms"}, {"score": 0.0035507457285983268, "phrase": "multi-armed_bandit_problem"}, {"score": 0.003219368413618912, "phrase": "second-order_statistics"}, {"score": 0.0030157628075954588, "phrase": "current_state"}, {"score": 0.0026175952455594277, "phrase": "new_heuristics"}, {"score": 0.0022472527731744974, "phrase": "experimental_results"}, {"score": 0.002210814150677161, "phrase": "performance_improvements"}, {"score": 0.0021631447601689444, "phrase": "new_instance_selectors"}, {"score": 0.0021049977753042253, "phrase": "consistent_winner"}], "paper_keywords": ["Budgeted learning", " Multi-armed bandit"], "paper_abstract": "We explore the problem of budgeted machine learning, in which the learning algorithm has free access to the training examples' class labels but has to pay for each attribute that is specified. This learning model is appropriate in many areas, including medical applications. We present new algorithms for choosing which attributes to purchase of which examples, based on algorithms for the multi-armed bandit problem. In addition, we also evaluate a group of algorithms based on the idea of incorporating second-order statistics into decision making. Most of our algorithms are competitive with the current state of art and performed better when the budget was highly limited (in particular, our new algorithm AbsoluteBR2). Finally, we present new heuristics for selecting an instance to purchase after the attribute is selected, instead of selecting an instance uniformly at random, which is typically done. While experimental results showed some performance improvements when using the new instance selectors, there was no consistent winner among these methods.", "paper_title": "New algorithms for budgeted learning", "paper_id": "WOS:000314715400003"}