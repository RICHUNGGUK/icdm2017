{"auto_keywords": [{"score": 0.04569647441539398, "phrase": "image_retrieval"}, {"score": 0.00481495049065317, "phrase": "weakly_supervised_deep_metric_learning_for_community-contributed_image_retrieval"}, {"score": 0.004766683200410046, "phrase": "recent_years"}, {"score": 0.004671588539217021, "phrase": "explosive_growth"}, {"score": 0.004624751696958501, "phrase": "community-contributed_images"}, {"score": 0.004578382275810468, "phrase": "rich_context_information"}, {"score": 0.00418134346679498, "phrase": "suitable_metric"}, {"score": 0.0040978781692373005, "phrase": "semantic_gap"}, {"score": 0.003916098498242888, "phrase": "new_distance_metric_learning_algorithm"}, {"score": 0.003799397093447221, "phrase": "deep_metric_learning"}, {"score": 0.0036676174658755683, "phrase": "deep_learning_framework"}, {"score": 0.003576286811853861, "phrase": "progressive_learning_manner"}, {"score": 0.0034348484776384643, "phrase": "heterogeneous_data_structures"}, {"score": 0.0034003686971964707, "phrase": "visual_contents"}, {"score": 0.003366233863411861, "phrase": "user-provided_tags"}, {"score": 0.0032658649336454923, "phrase": "semantic_structure"}, {"score": 0.003216804708106142, "phrase": "textual_space"}, {"score": 0.0029374939071038146, "phrase": "visual_structure"}, {"score": 0.0028933521924166287, "phrase": "original_visual_space"}, {"score": 0.0028070431733705735, "phrase": "mixed_norm"}, {"score": 0.0027370835853738626, "phrase": "transformation_matrix"}, {"score": 0.0026959452932289797, "phrase": "first_layer"}, {"score": 0.0026554236621262515, "phrase": "deep_architecture"}, {"score": 0.0026023381988430666, "phrase": "noisy_or_redundant_visual_features"}, {"score": 0.002486734224234698, "phrase": "optimization_problem"}, {"score": 0.0024493494346360415, "phrase": "well-defined_objective_function"}, {"score": 0.0024125253170522816, "phrase": "simple_yet_efficient_iterative_algorithm"}, {"score": 0.0023287359930308864, "phrase": "extensive_experiments"}, {"score": 0.0023053339328456234, "phrase": "real-world_social_image_datasets"}, {"score": 0.002202894673025544, "phrase": "proposed_method"}, {"score": 0.002158836285985314, "phrase": "encouraging_experimental_results"}], "paper_keywords": ["Deep", " image retrieval", " metric learning", " weakly supervised"], "paper_abstract": "Recent years have witnessed the explosive growth of community-contributed images with rich context information, which is beneficial to the task of image retrieval. It can help us to learn a suitable metric to alleviate the semantic gap. In this paper, we propose a new distance metric learning algorithm, namely weakly-supervised deep metric learning (WDML), under the deep learning framework. It utilizes a progressive learning manner to discover knowledge by jointly exploiting the heterogeneous data structures from visual contents and user-provided tags of social images. The semantic structure in the textual space is expected to be well preserved while the problem of the noisy, incomplete or subjective tags is addressed by leveraging the visual structure in the original visual space. Besides, a sparse model with the mixed norm is imposed on the transformation matrix of the first layer in the deep architecture to compress the noisy or redundant visual features. The proposed problem is formulated as an optimization problem with a well-defined objective function and a simple yet efficient iterative algorithm is proposed to solve it. Extensive experiments on real-world social image datasets are conducted to verify the effectiveness of the proposed method for image retrieval. Encouraging experimental results are achieved compared with several representative metric learning methods.", "paper_title": "Weakly Supervised Deep Metric Learning for Community-Contributed Image Retrieval", "paper_id": "WOS:000364102400012"}