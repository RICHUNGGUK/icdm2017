{"auto_keywords": [{"score": 0.029781621838727648, "phrase": "gpu"}, {"score": 0.007355890869748643, "phrase": "fpga"}, {"score": 0.00481495049065317, "phrase": "high_performance_computing_applications"}, {"score": 0.004274981117736524, "phrase": "hardware_accelerators"}, {"score": 0.004117329555194574, "phrase": "significant_programming"}, {"score": 0.004066076430818046, "phrase": "porting_effort"}, {"score": 0.003965468669507077, "phrase": "performance_benefit"}, {"score": 0.0036745112202989567, "phrase": "milc"}, {"score": 0.003587235362628753, "phrase": "predicted_performance_benefit"}, {"score": 0.0032858981413454802, "phrase": "performance-modeling_framework"}, {"score": 0.00320453237792, "phrase": "application_performance"}, {"score": 0.0031056437850836326, "phrase": "hybrid-core_systems"}, {"score": 0.0025409639091476363, "phrase": "overall_compute_time"}, {"score": 0.002477998427152547, "phrase": "hycom"}, {"score": 0.0021049977753042253, "phrase": "data_transfer_time"}], "paper_keywords": ["accelerators", " benchmarking", " FPGA", " GPU", " HPC", " idioms", " performance modeling", " performance prediction"], "paper_abstract": "Hybrid-core systems speedup applications by offloading certain compute operations that can run faster on hardware accelerators. However, such systems require significant programming and porting effort to gain a performance benefit from the accelerators. Therefore, prior to porting it is prudent to investigate the predicted performance benefit of accelerators for a given workload. To address this problem we present a performance-modeling framework that predicts the application performance rapidly and accurately for hybrid-core systems. We present predictions for two full-scale HPC applications-HYCOM and Milc. Our results for two accelerators (GPU and FPGA) show that gather/scatter and stream operations can speedup by as much as a factor of 15 and overall compute time of Milc and HYCOM improve by 3.4% and 20%, respectively. We also show that in order to benefit from the accelerators, 70% of the latency of data transfer time between the CPU and the accelerators needs to be overcome.", "paper_title": "Modeling and predicting performance of high performance computing applications on hardware accelerators", "paper_id": "WOS:000318356600002"}