{"auto_keywords": [{"score": 0.04818691642695348, "phrase": "human-robot_collision_avoidance"}, {"score": 0.00481495049065317, "phrase": "evaluating_distance"}, {"score": 0.004471978831302331, "phrase": "novel_approach"}, {"score": 0.004266501496765747, "phrase": "generic_point"}, {"score": 0.00418134346679498, "phrase": "cartesian_space"}, {"score": 0.004016072233242585, "phrase": "depth_sensor"}, {"score": 0.003704797078215222, "phrase": "collision_avoidance"}, {"score": 0.0036553070575015344, "phrase": "contact_point_identification"}, {"score": 0.0035823043879169153, "phrase": "augmented_reality"}, {"score": 0.003510754567808717, "phrase": "key_idea"}, {"score": 0.0033946556965877873, "phrase": "distance_evaluations"}, {"score": 0.0033045378860812403, "phrase": "depth_space"}, {"score": 0.003216804708106142, "phrase": "distance_estimation"}, {"score": 0.0029672941061574375, "phrase": "depth_image"}, {"score": 0.0027929100418926725, "phrase": "occluded_points"}, {"score": 0.002755567647101251, "phrase": "different_techniques"}, {"score": 0.002700485592691974, "phrase": "distance_data"}, {"score": 0.002646501671714952, "phrase": "multiple_object_points"}, {"score": 0.002524688179363081, "phrase": "depth_space_approach"}, {"score": 0.0024742098091226203, "phrase": "commonly_used_cartesian_space"}, {"score": 0.0023287359930308864, "phrase": "presented_method"}, {"score": 0.002297585503415527, "phrase": "better_results"}, {"score": 0.0022668507535947976, "phrase": "faster_execution_times"}, {"score": 0.0021479597698614355, "phrase": "kuka_lwr_iv_robot"}, {"score": 0.0021049977753042253, "phrase": "microsoft_kinect_sensor"}], "paper_keywords": ["Depth space", " Depth sensor", " Kinect", " Distance", " Collision avoidance"], "paper_abstract": "We present a novel approach to estimate the distance between a generic point in the Cartesian space and objects detected with a depth sensor. This information is crucial in many robotic applications, e.g., for collision avoidance, contact point identification, and augmented reality. The key idea is to perform all distance evaluations directly in the depth space. This allows distance estimation by considering also the frustum generated by the pixel on the depth image, which takes into account both the pixel size and the occluded points. Different techniques to aggregate distance data coming from multiple object points are proposed. We compare the Depth space approach with the commonly used Cartesian space or Configuration space approaches, showing that the presented method provides better results and faster execution times. An application to human-robot collision avoidance using a KUKA LWR IV robot and a Microsoft Kinect sensor illustrates the effectiveness of the approach.", "paper_title": "A Depth Space Approach for Evaluating Distance to Objects with Application to Human-Robot Collision Avoidance", "paper_id": "WOS:000368189000003"}