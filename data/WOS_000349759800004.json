{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "differentially-private_check-in_data"}, {"score": 0.00468627326602559, "phrase": "location-based_services"}, {"score": 0.004654642380553263, "phrase": "geo-social_networks"}, {"score": 0.004454158739805578, "phrase": "explicit_spatio-temporal_data"}, {"score": 0.004262273304740847, "phrase": "specific_venues"}, {"score": 0.004051074327962139, "phrase": "location_data"}, {"score": 0.004010102190292041, "phrase": "mobile_services"}, {"score": 0.0039028497942174777, "phrase": "explicit_check-ins"}, {"score": 0.003811350661783412, "phrase": "social_network"}, {"score": 0.0037346256869699975, "phrase": "implicit_check-ins"}, {"score": 0.003671865026158296, "phrase": "service_provider"}, {"score": 0.0036101552409969037, "phrase": "unauthorized_users"}, {"score": 0.00357362651129581, "phrase": "privacy_threat"}, {"score": 0.0035494788628319903, "phrase": "recurring_presence"}, {"score": 0.0034898187091432806, "phrase": "political_opinions"}, {"score": 0.0034662353953537773, "phrase": "religious_beliefs"}, {"score": 0.0034311578789991363, "phrase": "sexual_orientation"}, {"score": 0.0030992666061123533, "phrase": "possibly_untrusted_third_parties"}, {"score": 0.0030163012350270025, "phrase": "serious_privacy_issues"}, {"score": 0.0028569549040495163, "phrase": "formal_privacy_guarantees"}, {"score": 0.002660482980203146, "phrase": "differential_privacy_methods"}, {"score": 0.002624616889866485, "phrase": "pre-filtering_process"}, {"score": 0.0025630077791393125, "phrase": "untrusted_third_party"}, {"score": 0.0024193249334041557, "phrase": "sensitive_locations"}, {"score": 0.0022992346264367374, "phrase": "incremental_releases"}, {"score": 0.0022452462028184654, "phrase": "extensive_experiments"}, {"score": 0.00222249726328354, "phrase": "large_dataset"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Privacy", " Check-ins", " Incremental release", " Differential privacy", " Spatio-temporal"], "paper_abstract": "Due to the growing popularity of location-based services and geo-social networks, users communicate more and more private location traces to service providers, as well as explicit spatio-temporal data, often called \"check-ins'', about their presence in specific venues at given times. Further check-in data may be implicitly derived by analyzing location data collected by mobile services. In general, the visibility of explicit check-ins is limited to friends in the social network, while the visibility of implicit check-ins is limited to the service provider. Exposing check-ins to unauthorized users is a privacy threat since recurring presence in given locations may reveal political opinions, religious beliefs, or sexual orientation, as well as absence from other locations where the user is supposed to be. Hence, on one side mobile app providers host valuable information that they would like to sell to possibly untrusted third parties, and on the other we recognize serious privacy issues in releasing that information. In this paper, we solve this dilemma by providing formal privacy guarantees to users, while preserving the utility of check-in data. Our technique is based on the use of differential privacy methods integrated with a pre-filtering process, and protects both against an untrusted third party receiving check-in statistics, and against its users, willing to infer the venues and sensitive locations visited by other users. We show how the technique can be extended to support incremental releases of check-in data. Extensive experiments with a large dataset of real users' check-ins show the effectiveness of our methods. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Incremental release of differentially-private check-in data", "paper_id": "WOS:000349759800004"}