{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "text_classification"}, {"score": 0.004546970518808189, "phrase": "comprehensive_analysis"}, {"score": 0.004436716583179764, "phrase": "lexical_dependency"}, {"score": 0.004224130367280183, "phrase": "text_classification_problem"}, {"score": 0.003924121879214595, "phrase": "feature_vector"}, {"score": 0.003736004578001584, "phrase": "standard_bag-of-words_approach"}, {"score": 0.0034990853199511982, "phrase": "low_frequencies"}, {"score": 0.003304097742490624, "phrase": "solution_vector"}, {"score": 0.003223883109446599, "phrase": "pruning_levels"}, {"score": 0.0030441844088874366, "phrase": "dependency_combinations"}, {"score": 0.002994701080666466, "phrase": "different_datasets"}, {"score": 0.002827740707723551, "phrase": "main_motivation"}, {"score": 0.00219311232069446, "phrase": "statistically_significant_improvements"}, {"score": 0.0021049977753042253, "phrase": "proposed_approaches"}], "paper_keywords": ["Text classification", " Lexical dependency", " Pruning analysis", " Stanford parser"], "paper_abstract": "In this study, a comprehensive analysis of the lexical dependency and pruning concepts for the text classification problem is presented. Dependencies are included in the feature vector as an extension to the standard bag-of-words approach. The pruning process filters features with low frequencies so that fewer but more informative features remain in the solution vector. The pruning levels for words, dependencies, and dependency combinations for different datasets are analyzed in detail. The main motivation in this work is to make use of dependencies and pruning efficiently in text classification and to achieve more successful results using much smaller feature vector sizes. Three different datasets were used in the experiments and statistically significant improvements for most of the proposed approaches were obtained.", "paper_title": "Optimization of dependency and pruning usage in text classification", "paper_id": "WOS:000299505000004"}