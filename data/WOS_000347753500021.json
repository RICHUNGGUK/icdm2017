{"auto_keywords": [{"score": 0.004762202897268383, "phrase": "robust_visual_tracking"}, {"score": 0.0045318666714939905, "phrase": "challenging_problem"}, {"score": 0.004457579615095599, "phrase": "single_object"}, {"score": 0.004384504920139083, "phrase": "complex_dynamic_scene"}, {"score": 0.004081385289516914, "phrase": "appearance_model"}, {"score": 0.004014452814186653, "phrase": "tracked_object"}, {"score": 0.003883850058095871, "phrase": "different_approach"}, {"score": 0.003778253716938922, "phrase": "increased_popularity"}, {"score": 0.00373682045166829, "phrase": "depth_sensors"}, {"score": 0.003536346954940084, "phrase": "model_drift"}, {"score": 0.0031669873302916, "phrase": "spatial-temporal_co-occurrence_correlations"}, {"score": 0.0030470127429039497, "phrase": "collaborative_tracking"}, {"score": 0.0030135741897058844, "phrase": "binocular_video_data"}, {"score": 0.002883439044844259, "phrase": "spatial-temporal_constrain"}, {"score": 0.0025678829712650437, "phrase": "probability_voting"}, {"score": 0.0024569466759289055, "phrase": "depth_information"}, {"score": 0.00241658945942583, "phrase": "simple_yet_effective_occlusion_handling_scheme"}, {"score": 0.0022994427535192492, "phrase": "qualitative_and_quantitative_experimental_results"}, {"score": 0.002175913488493802, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual tracking", " 3D context", " Depth information"], "paper_abstract": "In this paper, we study the challenging problem of tracking single object in a complex dynamic scene. In contrast to most existing trackers which only exploit 2D color or gray images to learn the appearance model of the tracked object online, we take a different approach, inspired by the increased popularity of depth sensors, by putting more emphasis on the 3D Context to prevent model drift and handle occlusion. Specifically, we propose a 3D context-based object tracking method that learns a set of 3D context key-points, which have spatial-temporal co-occurrence correlations with the tracked object, for collaborative tracking in binocular video data. We first learn 3D context key-points via the spatial-temporal constrain in their spatial and depth coordinates. Then, the position of the object of interest is determined by a probability voting from the learnt 3D context key-points. Moreover, with depth information, a simple yet effective occlusion handling scheme is proposed to detect occlusion and recovery. Qualitative and quantitative experimental results on challenging video sequences demonstrate the robustness of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Online learning 3D context for robust visual tracking", "paper_id": "WOS:000347753500021"}