{"auto_keywords": [{"score": 0.03503242712598695, "phrase": "hidden_nodes"}, {"score": 0.014321692293290054, "phrase": "elm"}, {"score": 0.00916269408841909, "phrase": "candidate_reservoir"}, {"score": 0.00481495049065317, "phrase": "neural_network_model"}, {"score": 0.004690694501758065, "phrase": "unknown_datasets"}, {"score": 0.004522080178250592, "phrase": "important_method"}, {"score": 0.004475022550508119, "phrase": "global_regression"}, {"score": 0.004428452434981208, "phrase": "extreme_learning_machine"}, {"score": 0.004291617358806677, "phrase": "typical_learning_method"}, {"score": 0.004246947739596565, "phrase": "single-hidden_layer_feedforward_network"}, {"score": 0.004137288854115515, "phrase": "better_generalization_performance"}, {"score": 0.004072851768196397, "phrase": "faster_implementation"}, {"score": 0.0040094142308666975, "phrase": "\"randomness\"_property"}, {"score": 0.0038854765143440965, "phrase": "nonlinear_combination"}, {"score": 0.0038450179181069833, "phrase": "arbitrary_function_approximation"}, {"score": 0.003629882559085245, "phrase": "alternative_mechanism"}, {"score": 0.0035920758080335655, "phrase": "input_connections"}, {"score": 0.003444732262403694, "phrase": "evolutionary_algorithm"}, {"score": 0.003355717283753749, "phrase": "number_l"}, {"score": 0.003251920460276645, "phrase": "original_elm_models"}, {"score": 0.0032012284065895537, "phrase": "hidden_node"}, {"score": 0.0029905104479072482, "phrase": "larger_weight_nodes"}, {"score": 0.002897978407284774, "phrase": "elm."}, {"score": 0.0028378798711397235, "phrase": "trivial_hidden_nodes"}, {"score": 0.0026649432435828842, "phrase": "l_hidden_nodes"}, {"score": 0.0024634797027967203, "phrase": "fitness-proportional_selection"}, {"score": 0.002387214876538434, "phrase": "evolutionary_selection_elm."}, {"score": 0.002362320344521919, "phrase": "entire_algorithm"}, {"score": 0.002301211274459965, "phrase": "large-scale_dataset_regression"}, {"score": 0.002218299213266519, "phrase": "regression_performance"}, {"score": 0.0021609076467365247, "phrase": "traditional_elm"}, {"score": 0.002138660813267558, "phrase": "bayesian"}], "paper_keywords": ["Extreme learning machine", " Evolutionary algorithm", " Hidden nodes evaluation", " Gene crossover"], "paper_abstract": "Neural network model of aggression can approximate unknown datasets with the less error. As an important method of global regression, extreme learning machine (ELM) represents a typical learning method in single-hidden layer feedforward network, because of the better generalization performance and the faster implementation. The \"randomness\" property of input weights makes the nonlinear combination reach arbitrary function approximation. In this paper, we attempt to seek the alternative mechanism to input connections. The idea is derived from the evolutionary algorithm. After predefining the number L of hidden nodes, we generate original ELM models. Each hidden node is seemed as a gene. To rank these hidden nodes, the larger weight nodes are reassigned for the updated ELM. We put L/2 trivial hidden nodes in a candidate reservoir. Then, we generate L/2 new hidden nodes to combine L hidden nodes from this candidate reservoir. Another ranking is used to choose these hidden nodes. The fitness-proportional selection may select L/2 hidden nodes and recombine evolutionary selection ELM. The entire algorithm can be applied for large-scale dataset regression. The verification shows that the regression performance is better than the traditional ELM and Bayesian ELM under less cost gain.", "paper_title": "Evolutionary selection extreme learning machine optimization for regression", "paper_id": "WOS:000307535400004"}