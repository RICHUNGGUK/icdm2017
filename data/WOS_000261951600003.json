{"auto_keywords": [{"score": 0.049613254104042076, "phrase": "background_knowledge"}, {"score": 0.044549273217110816, "phrase": "graphical_model"}, {"score": 0.00481495049065317, "phrase": "bayesian_networks"}, {"score": 0.004652963867892925, "phrase": "discovery_framework"}, {"score": 0.004430920292612374, "phrase": "discourse_area"}, {"score": 0.0038448988429199086, "phrase": "central_step"}, {"score": 0.0033524956061690868, "phrase": "attribute_sets"}, {"score": 0.003024909947609294, "phrase": "current_model"}, {"score": 0.002951739421935396, "phrase": "exact_algorithm"}, {"score": 0.002663208600887875, "phrase": "exact_inference"}, {"score": 0.0023677483882740317, "phrase": "confidence_probability"}, {"score": 0.002299142268368128, "phrase": "infinite_streams"}, {"score": 0.0021891781017389783, "phrase": "controlled_experiments"}, {"score": 0.0021049977753042253, "phrase": "practical_usefulness"}], "paper_keywords": ["Association rule", " Background knowledge", " Interestingness", " Bayesian network", " Data stream"], "paper_abstract": "We study a discovery framework in which background knowledge on variables and their relations within a discourse area is available in the form of a graphical model. Starting from an initial, hand-crafted or possibly empty graphical model, the network evolves in an interactive process of discovery. We focus on the central step of this process: given a graphical model and a database, we address the problem of finding the most interesting attribute sets. We formalize the concept of interestingness of attribute sets as the divergence between their behavior as observed in the data, and the behavior that can be explained given the current model. We derive an exact algorithm that finds all attribute sets whose interestingness exceeds a given threshold. We then consider the case of a very large network that renders exact inference unfeasible, and a very large database or data stream. We devise an algorithm that efficiently finds the most interesting attribute sets with prescribed approximation bound and confidence probability, even for very large networks and infinite streams. We study the scalability of the methods in controlled experiments; a case-study sheds light on the practical usefulness of the approach.", "paper_title": "Scalable pattern mining with Bayesian networks as background knowledge", "paper_id": "WOS:000261951600003"}