{"auto_keywords": [{"score": 0.033172228999680184, "phrase": "candidate_annotations"}, {"score": 0.02661104179666677, "phrase": "proposed_algorithm"}, {"score": 0.00481495049065317, "phrase": "digital_cameras"}, {"score": 0.00471700544744796, "phrase": "considerable_digital_images"}, {"score": 0.004416713079266374, "phrase": "personal_images"}, {"score": 0.004380540407926982, "phrase": "automatic_image_annotation"}, {"score": 0.004238775572746022, "phrase": "annotated_keywords"}, {"score": 0.0041696157492057, "phrase": "search_processes"}, {"score": 0.003968806706727518, "phrase": "arbitrary_personal_images"}, {"score": 0.0036104596826132965, "phrase": "search-based_image_annotation_algorithm"}, {"score": 0.0035369291417564606, "phrase": "information_retrieval"}, {"score": 0.003479180627368156, "phrase": "content-based_image_retrieval_technology"}, {"score": 0.0033664873319204027, "phrase": "visually_similar_images"}, {"score": 0.0033251716926666437, "phrase": "large-scale_web_image"}, {"score": 0.003244050414264445, "phrase": "text-based_keyword_search_technique"}, {"score": 0.0031649018957020337, "phrase": "ranked_list"}, {"score": 0.0031004173389196387, "phrase": "retrieved_image"}, {"score": 0.0030372426452745073, "phrase": "fusion_algorithm"}, {"score": 0.0029631248341951064, "phrase": "ranked_lists"}, {"score": 0.00292674497467906, "phrase": "final_candidate_annotation_list"}, {"score": 0.0027176309244222, "phrase": "top_ones"}, {"score": 0.0026622351303038885, "phrase": "final_annotations"}, {"score": 0.0025972447844047515, "phrase": "efficient_search_techniques"}, {"score": 0.002575934917174136, "phrase": "web-scale_image"}, {"score": 0.002431570196486513, "phrase": "annotation_rejection_scheme"}, {"score": 0.002304754792740636, "phrase": "experimental_results"}, {"score": 0.002285839246740627, "phrase": "u._washington"}, {"score": 0.002157697367447098, "phrase": "image_retrieval"}, {"score": 0.002139986159978777, "phrase": "annotation_results"}, {"score": 0.0021049977753042253, "phrase": "visual_features"}], "paper_keywords": [""], "paper_abstract": "With the popularity of digital cameras, more and more people have accumulated considerable digital images on their personal devices. As a result, there are increasing needs to effectively search these personal images. Automatic image annotation may serve the goal, for the annotated keywords could facilitate the search processes. Although many image annotation methods have been proposed in recent years, their effectiveness on arbitrary personal images is constrained by their limited scalability, i.e. limited lexicon of small-scale training set. To be scalable, we propose a search-based image annotation algorithm that is analogous to information retrieval. First, content-based image retrieval technology is used to retrieve a set of visually similar images from a large-scale Web image set. Second, a text-based keyword search technique is used to obtain a ranked list of candidate annotations for each retrieved image. Third, a fusion algorithm is used to combine the ranked lists into a final candidate annotation list. Finally, the candidate annotations are re-ranked using Random Walk with Restarts and only the top ones are reserved as the final annotations. The application of both efficient search techniques and Web-scale image set guarantees the scalability of the proposed algorithm. Moreover, we provide an annotation rejection scheme to point out the images that our annotation system cannot handle well. Experimental results on U. Washington dataset show not only the effectiveness and efficiency of the proposed algorithm but also the advantage of image retrieval using annotation results over that using visual features.", "paper_title": "Scalable search-based image annotation", "paper_id": "WOS:000258886000003"}