{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "structural_learning"}, {"score": 0.008596042884850592, "phrase": "directed_acyclic_graphs"}, {"score": 0.007201808019222167, "phrase": "large_dag"}, {"score": 0.004466519142879166, "phrase": "recursive_method"}, {"score": 0.0034450303951025704, "phrase": "smaller_subsets"}, {"score": 0.002903628734069691, "phrase": "small_subsets"}, {"score": 0.002602555367635598, "phrase": "statistical_tests"}, {"score": 0.002463906556781983, "phrase": "recent_advances"}, {"score": 0.0023810183846557486, "phrase": "undirected_graphical_models"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Bayesian network", " conditional independence", " decomposition", " directed acyclic graph", " structural learning"], "paper_abstract": "In this paper, we propose a recursive method for structural learning of directed acyclic graphs (DAGs), in which a problem of structural learning for a large DAG is first decomposed into two problems of structural learning for two small vertex subsets, each of which is then decomposed recursively into two problems of smaller subsets until none subset can be decomposed further. In our approach, search for separators of a pair of variables in a large DAG is localized to small subsets, and thus the approach can improve the efficiency of searches and the power of statistical tests for structural learning. We show how the recent advances in the learning of undirected graphical models can be employed to facilitate the decomposition. Simulations are given to demonstrate the performance of the proposed method.", "paper_title": "A recursive method for structural learning of directed acyclic graphs", "paper_id": "WOS:000256642000004"}