{"auto_keywords": [{"score": 0.04016157518902184, "phrase": "unlabeled_samples"}, {"score": 0.004815440238983995, "phrase": "fisher"}, {"score": 0.004653667500876187, "phrase": "dimensionality_reduction"}, {"score": 0.0042373381286051354, "phrase": "dimensionality_reduction_methods"}, {"score": 0.0033374705499418377, "phrase": "semi-supervised_dimensionality_reduction_method"}, {"score": 0.0030127172247606812, "phrase": "labeled_samples"}, {"score": 0.0029617414861784525, "phrase": "different_classes"}, {"score": 0.0028139168128067343, "phrase": "proposed_method"}, {"score": 0.0026963662375234124, "phrase": "semi-supervised_local_fisher_discriminant_analysis"}, {"score": 0.002539978170928796, "phrase": "analytic_form"}, {"score": 0.002475755804232436, "phrase": "globally_optimal_solution"}, {"score": 0.0021827740589480003, "phrase": "self"}, {"score": 0.0021049977753042253, "phrase": "benchmark_and_real-world_document_classification_datasets"}], "paper_keywords": ["Semi-supervised learning", " Dimensionality reduction", " Cluster assumption", " Local Fisher discriminant analysis", " Principal component analysis"], "paper_abstract": "When only a small number of labeled samples are available, supervised dimensionality reduction methods tend to perform poorly because of overfitting. In such cases, unlabeled samples could be useful in improving the performance. In this paper, we propose a semi-supervised dimensionality reduction method which preserves the global structure of unlabeled samples in addition to separating labeled samples in different classes from each other. The proposed method, which we call SEmi-supervised Local Fisher discriminant analysis (SELF), has an analytic form of the globally optimal solution and it can be computed based on eigen-decomposition. We show the usefulness of SELF through experiments with benchmark and real-world document classification datasets.", "paper_title": "Semi-supervised local Fisher discriminant analysis for dimensionality reduction", "paper_id": "WOS:000272849400002"}