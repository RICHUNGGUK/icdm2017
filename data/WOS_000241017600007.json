{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "application_systems"}, {"score": 0.004707810093520679, "phrase": "recognition_technologies"}, {"score": 0.004588266612786895, "phrase": "color_recognition"}, {"score": 0.004558855900816642, "phrase": "human-machine_interfacing"}, {"score": 0.004412973361459218, "phrase": "interfacing_framework"}, {"score": 0.004372207937638619, "phrase": "traditional_input_devices"}, {"score": 0.0042748769561032325, "phrase": "current_solutions"}, {"score": 0.0041262692428189985, "phrase": "ad_hoc_approach"}, {"score": 0.004060432002446197, "phrase": "generic_and_systematic_way"}, {"score": 0.004021432924450511, "phrase": "common_approach"}, {"score": 0.0039192497049015135, "phrase": "low-level_programmed_wrappers"}, {"score": 0.003558573794178866, "phrase": "generic_and_systematic_approach"}, {"score": 0.00339083755411773, "phrase": "research_work"}, {"score": 0.0033366952764030946, "phrase": "generic_and_visual_interfacing_framework"}, {"score": 0.003220596121589591, "phrase": "application_system's_front_end"}, {"score": 0.0031793840887737687, "phrase": "visual_level"}, {"score": 0.0031286075376993103, "phrase": "detailed_system_design"}, {"score": 0.0031085239972726106, "phrase": "programming_knowledge"}, {"score": 0.003039238375314774, "phrase": "interfacing_environment"}, {"score": 0.002895910285227502, "phrase": "p_party_applications"}, {"score": 0.002840484388249037, "phrase": "application's_source_code"}, {"score": 0.002654693503799094, "phrase": "transparent_grid_layout_mechanism"}, {"score": 0.0026207039474589, "phrase": "graphic_user_interface_icons"}, {"score": 0.0025871484499191736, "phrase": "interfaced_application_system"}, {"score": 0.002562263358004784, "phrase": "proposed_interfacing_framework"}, {"score": 0.0025051226957195634, "phrase": "visual_interface_commands"}, {"score": 0.00242569125010088, "phrase": "speech_recognizers"}, {"score": 0.0024023554314227067, "phrase": "proposed_system"}, {"score": 0.002356353539621074, "phrase": "based_commercial_software"}, {"score": 0.0022307321581833918, "phrase": "interaction_overhead"}, {"score": 0.0021669551936989886, "phrase": "proposed_interfacing_mechanisms"}, {"score": 0.0021049977753042253, "phrase": "proposed_visual_interfacing_approach"}], "paper_keywords": ["interfacing environment", " recognizer interfacing", " see-through interface", " generic interfacing framework", " application interfacing", " customized interfacing"], "paper_abstract": "Application systems that utilize recognition technologies such as speech, gesture, and color recognition provide human-machine interfacing to those users that are physically unable to interact with computers through traditional input devices such as mouse or keyboard. Current solutions to interface application systems with recognizers, however, use an ad hoc approach and lack of a generic and systematic way. The common approach used is to interface with recognizers through low-level programmed wrappers that are application dependent and require the details of system design and programming knowledge to perform the interfacing and to make any modifications to it. Thus, a generic and systematic approach to bridge the interface between recognizers and application systems must be quested. In this research work, we provide a generic and visual interfacing framework for bridging the interface between application systems and recognizers through the application system's front end, applying a visual level interfacing without requiring the detailed system design and programming knowledge, allowing for modifications to an interfacing environment to be made on the fly and more importantly allowing the interfacing with the P party applications without requiring access to the application's source code. Specifically, an interfacing script language for building the interfacing framework is designed and implemented. The interfacing framework uses a transparent grid layout mechanism to position the graphic user interface icons defined in the interfaced application system. The proposed interfacing framework is then used to bridge the visual interface commands defined in application systems to the voice commands trained in speech recognizers. The proposed system can be applied to GUI based commercial software without the need of accessing their internal code, and also allowing the composition of macros to reduce interaction overhead to users. Examples are applied using the proposed interfacing mechanisms to demonstrate the applicability and feasibility of the proposed visual interfacing approach.", "paper_title": "A generic and visual interfacing framework for bridging the interface between application systems and recognizers", "paper_id": "WOS:000241017600007"}