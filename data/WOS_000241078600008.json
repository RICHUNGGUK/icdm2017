{"auto_keywords": [{"score": 0.04843603269514023, "phrase": "hexapod_robot"}, {"score": 0.00481495049065317, "phrase": "distributed_control"}, {"score": 0.003996727479807572, "phrase": "neurobiological_evidence"}, {"score": 0.0038148090091532933, "phrase": "real_hexapod_insects"}, {"score": 0.0033170847930578473, "phrase": "distributed_controllers"}, {"score": 0.002884111441153185, "phrase": "reinforcement_learning"}, {"score": 0.00278497898719426, "phrase": "new_learning_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["hexapod robot", " distributed control", " reinforcement learning", " genetic algorithm", " coevolution"], "paper_abstract": "This paper reports on experiments involving a hexapod robot. Motivated by neurobiological evidence that control in real hexapod insects is distributed leg-wise, we investigated two approaches to learning distributed controllers: genetic algorithms and reinforcement learning. In the case of reinforcement learning, a new learning algorithm was developed to encourage cooperation between legs. Results from both approaches are presented and compared. (c) 2006 Published by Elsevier B.V.", "paper_title": "Experiments in learning distributed control for a hexapod robot", "paper_id": "WOS:000241078600008"}