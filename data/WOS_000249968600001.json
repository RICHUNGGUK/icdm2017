{"auto_keywords": [{"score": 0.049178471674397164, "phrase": "gestural_information"}, {"score": 0.00481495049065317, "phrase": "music_scores"}, {"score": 0.00459165923324494, "phrase": "physical_gestures"}, {"score": 0.004462663711734448, "phrase": "music_instruments"}, {"score": 0.0035864603175592854, "phrase": "music_performance"}, {"score": 0.003355515315708125, "phrase": "sound_synthesis"}, {"score": 0.0031096747349602344, "phrase": "highly_constrained_nature"}, {"score": 0.0027479040199262393, "phrase": "constraint-based_approach"}, {"score": 0.0024984517279573906, "phrase": "gestural_comfort"}, {"score": 0.002337403139264533, "phrase": "problem_representation"}, {"score": 0.0022715929119140194, "phrase": "search_strategy"}, {"score": 0.0021049977753042253, "phrase": "human_performance"}], "paper_keywords": ["constraint-based approach", " computational modeling", " gestural control", " music performance"], "paper_abstract": "The physical gestures that operate music instruments are responsible for the qualities of the sound being produced in a performance. Gestural information is thereby crucial for a model of music performance, paired with a model of sound synthesis where this information is applied. The highly constrained nature of performers gestures makes this task suitable to be modeled via a constraint-based approach, coupled with a strategy aimed at maximizing the gestural comfort of performers. We illustrate the problem representation, the search strategy and a validation of the model against human performance.", "paper_title": "A constraint-based approach for annotating music scores with gestural information", "paper_id": "WOS:000249968600001"}