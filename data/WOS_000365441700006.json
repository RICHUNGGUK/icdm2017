{"auto_keywords": [{"score": 0.03799635259867219, "phrase": "optical_flow"}, {"score": 0.00481495049065317, "phrase": "modern_wearables"}, {"score": 0.004776669953449352, "phrase": "visual_feature_tracking"}, {"score": 0.004589763483242731, "phrase": "robust_method"}, {"score": 0.004553265070135597, "phrase": "orientation_estimation"}, {"score": 0.004463278123628969, "phrase": "google_glass"}, {"score": 0.0044101380740283825, "phrase": "bias_compensation"}, {"score": 0.004288581530198804, "phrase": "raw_angular_rates"}, {"score": 0.004237512575106522, "phrase": "resulting_orientation_estimate"}, {"score": 0.004120694410890683, "phrase": "non-zero_bias"}, {"score": 0.00407161650109722, "phrase": "measured_gyroscope"}, {"score": 0.003975200317233532, "phrase": "simple_error_model"}, {"score": 0.0038965930422333035, "phrase": "measurement_capabilities"}, {"score": 0.0037740295668681014, "phrase": "inertial_sensing"}, {"score": 0.0036553070575015344, "phrase": "feature_point_displacements"}, {"score": 0.0034702685641070283, "phrase": "sensor_fusion_algorithm"}, {"score": 0.0033077610063168093, "phrase": "introduced_orientation_estimator"}, {"score": 0.0032814236411444022, "phrase": "bias_removal_method"}, {"score": 0.003229374325577207, "phrase": "adaptive_reliability_filter"}, {"score": 0.003190878119415192, "phrase": "optical_flow_feature_points"}, {"score": 0.0031277316566463978, "phrase": "remaining_feature_point"}, {"score": 0.002981216610222911, "phrase": "maximum_a-posteriori_estimator"}, {"score": 0.0026547761341670505, "phrase": "bias_estimate"}, {"score": 0.002530359917257626, "phrase": "asynchronous_work-flow"}, {"score": 0.0024408799645640323, "phrase": "real_time"}, {"score": 0.0023451553255837317, "phrase": "real_world_measurements"}, {"score": 0.0023079225317714815, "phrase": "industrial_robots"}, {"score": 0.002262209824105154, "phrase": "adaptive_filter"}, {"score": 0.0021561514733516676, "phrase": "integrated_output"}, {"score": 0.0021049977753042253, "phrase": "significant_drift"}], "paper_keywords": ["Orientation estimation", " Gyroscope", " Optical flow", " Wearable", " Sensor fusion", " Modality-oriented CogInfoCom", " Augmented sensing"], "paper_abstract": "In this paper we propose and examine a robust method for orientation estimation of wearables (like Google Glass) through bias compensation of gyroscope. Through integration of raw angular rates, the resulting orientation estimate will drift, due to the non-zero bias of the measured gyroscope was also accumulated. A simple error model was constructed for the measurement capabilities of the device, in terms of inertial sensing of rotation. Using the benefits of feature point displacements (as optical flow) from the camera of the device, a sensor fusion algorithm was developed to lower, and compensate the bias. The introduced orientation estimator and bias removal method is based on adaptive reliability filter for the optical flow feature points. To fuse the remaining feature point displacements into one single value, various aggregation methods have been tested, and a maximum a-posteriori estimator was applied on the dataset. To further lower the bias from the gyroscope, the output of the system was used as a feedback to calculate a bias estimate. To measure the performance and investigate the benefits of the asynchronous work-flow, the optical flow was performed on various devices in real time. To validate the results of the simulations, real world measurements were performed with industrial robots. Our reliable, adaptive filter matched our expectations, could compensate the bias well, and the integrated output of the system had no significant drift.", "paper_title": "Orientation estimation in modern wearables with visual feature tracking", "paper_id": "WOS:000365441700006"}