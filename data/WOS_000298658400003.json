{"auto_keywords": [{"score": 0.047446295972823384, "phrase": "dependency_networks"}, {"score": 0.00481495049065317, "phrase": "statistical_relational_learning"}, {"score": 0.004455061431809975, "phrase": "joint_probability_distribution"}, {"score": 0.004392565073466714, "phrase": "multiple_random_variables"}, {"score": 0.004240116703465252, "phrase": "conditional_distributions"}, {"score": 0.004180622964109706, "phrase": "relational_dependency_networks"}, {"score": 0.004035500442527029, "phrase": "graphical_models"}, {"score": 0.0038953958723049287, "phrase": "relational_domains"}, {"score": 0.003813669883040509, "phrase": "higher_expressivity"}, {"score": 0.0034057975804778293, "phrase": "relational_abstraction_levels"}, {"score": 0.0032184697893776052, "phrase": "current_learning_approaches"}, {"score": 0.00310664242361199, "phrase": "single_probability_tree"}, {"score": 0.0030630037175103032, "phrase": "random_variable"}, {"score": 0.00281371157349156, "phrase": "relational_function-approximation_problems"}, {"score": 0.0027741761880779535, "phrase": "gradient-based_boosting"}, {"score": 0.002196342933346204, "phrase": "efficient_learning"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_statistical_relational_learning_approaches"}], "paper_keywords": ["Statistical relational learning", " Graphical models", " Ensemble methods"], "paper_abstract": "Dependency networks approximate a joint probability distribution over multiple random variables as a product of conditional distributions. Relational Dependency Networks (RDNs) are graphical models that extend dependency networks to relational domains. This higher expressivity, however, comes at the expense of a more complex model-selection problem: an unbounded number of relational abstraction levels might need to be explored. Whereas current learning approaches for RDNs learn a single probability tree per random variable, we propose to turn the problem into a series of relational function-approximation problems using gradient-based boosting. In doing so, one can easily induce highly complex features over several iterations and in turn estimate quickly a very expressive model. Our experimental results in several different data sets show that this boosting method results in efficient learning of RDNs when compared to state-of-the-art statistical relational learning approaches.", "paper_title": "Gradient-based boosting for statistical relational learning: The relational dependency network case", "paper_id": "WOS:000298658400003"}