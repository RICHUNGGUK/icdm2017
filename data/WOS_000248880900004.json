{"auto_keywords": [{"score": 0.04007839710766617, "phrase": "spme_technique"}, {"score": 0.02682891927173452, "phrase": "explicit_water"}, {"score": 0.00481495049065317, "phrase": "fine_grained_parallel_smooth_particle"}, {"score": 0.004777243771520779, "phrase": "ewald"}, {"score": 0.004721162131188487, "phrase": "biophysical_simulation_studies"}, {"score": 0.004521179256835894, "phrase": "complex_heterogeneous_biophysical_macrostructures"}, {"score": 0.004485735417293941, "phrase": "non-trivial_charge_distributions"}, {"score": 0.004261998281333649, "phrase": "long_range_forces"}, {"score": 0.00409748471133883, "phrase": "smooth_particle_mesh_ewald_summation_technique"}, {"score": 0.003939296259436904, "phrase": "long_range_part"}, {"score": 0.003908396188878932, "phrase": "electrostatic_energy"}, {"score": 0.003877737556673229, "phrase": "large_scale_molecular_simulations"}, {"score": 0.0037133478610481994, "phrase": "performance_bottleneck"}, {"score": 0.0036697319652557363, "phrase": "single_processor"}, {"score": 0.003640938643675543, "phrase": "current_implementations"}, {"score": 0.0036123709573116372, "phrase": "spme"}, {"score": 0.003584025547693833, "phrase": "massively_parallel_supercomputers"}, {"score": 0.003527998934981411, "phrase": "large_processor_numbers"}, {"score": 0.003312486229143855, "phrase": "synergis_investigation"}, {"score": 0.003286486670483032, "phrase": "method_improvement"}, {"score": 0.003260690513595527, "phrase": "parallel_programming"}, {"score": 0.0032350961776525075, "phrase": "novel_architectures"}, {"score": 0.0031223774204093713, "phrase": "relatively_simple_modification"}, {"score": 0.0029899137403982027, "phrase": "improved_accuracy"}, {"score": 0.002931569771634119, "phrase": "massively_parallel_and_scalar_computing_platforms"}, {"score": 0.0028743610212291727, "phrase": "modified_spme_method"}, {"score": 0.0028405715222684183, "phrase": "novel_qcdoc_supercomputer"}, {"score": 0.002763261749602258, "phrase": "numerical_tests"}, {"score": 0.0027415611720084006, "phrase": "algorithm_performance_oil"}, {"score": 0.0026774738852854427, "phrase": "qcdoc_machine"}, {"score": 0.002656530231407055, "phrase": "bnl"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Particle Mesh Ewald", " 3D-FFT", " biomolecular simulations"], "paper_abstract": "In order to model complex heterogeneous biophysical macrostructures with non-trivial charge distributions such as globular proteins in water it is important to evaluate the long range forces present in these systems accurately and efficiently. The Smooth Particle Mesh Ewald summation technique (SPME) is commonly used to determine the long range part of electrostatic energy in large scale molecular simulations. While the SPME technique does not give rise to a performance bottleneck on a single processor, current implementations of SPME on massively parallel supercomputers become problematic at large processor numbers, limiting the time and length scales that can be reached. Here, a synergis investigation involving method improvement, parallel programming and novel architectures is employed to address this difficulty. A relatively simple modification of the SPME technique is described which gives rise to both improved accuracy and efficiency on both massively parallel and scalar computing platforms. Our fine grained parallel implementation of the modified SPME method for the novel QCDOC supercomputer with its 6D-torus architecture is then given. Numerical tests of algorithm performance oil up to 1024 processors of the QCDOC machine at BNL a presented for two systems of interest, beta-hairpin solvated in explicit water, a system which consists of 1142 water molecules and a 20 resid protein for a total of 3579 atoms, and the HIV-I protease solvated in explicit water, a system which consists of 9331 water molecules and a I residue protein for a total of 29508 atoms. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "A fine grained parallel smooth particle mesh Ewald algorithm for biophysical simulation studies: Application to the 6-D torus QCDOC supercomputer", "paper_id": "WOS:000248880900004"}