{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "product_rating"}, {"score": 0.049764804068700534, "phrase": "partial_information"}, {"score": 0.03938679329249631, "phrase": "minimum_number"}, {"score": 0.015415790839628542, "phrase": "amazon"}, {"score": 0.014537637004634537, "phrase": "product_ratings"}, {"score": 0.011567961494714988, "phrase": "users'_misbehavior"}, {"score": 0.0046898195764117035, "phrase": "epinions"}, {"score": 0.004643729733199096, "phrase": "tripadvisor"}, {"score": 0.004613254605667248, "phrase": "historical_product_ratings"}, {"score": 0.00390000531646629, "phrase": "partial_information_setting"}, {"score": 0.0038110933504990683, "phrase": "fundamental_questions"}, {"score": 0.0036034816680872877, "phrase": "reliable_evaluation"}, {"score": 0.0034183895670057717, "phrase": "evaluation_result"}, {"score": 0.0033075503163659055, "phrase": "probabilistic_model"}, {"score": 0.003221463787552773, "phrase": "aggregation_rules"}, {"score": 0.0031272833420309685, "phrase": "product_quality_assessment"}, {"score": 0.002966578246443101, "phrase": "reliable_indicator"}, {"score": 0.002777227714581881, "phrase": "maximum_fraction"}, {"score": 0.0027228088474257426, "phrase": "rating_aggregation_rule"}, {"score": 0.00242590924077914, "phrase": "\"average_rating_rule"}, {"score": 0.002324055400492893, "phrase": "\"median_rating_rule"}, {"score": 0.002211822660522734, "phrase": "flixster"}, {"score": 0.0021972795583288037, "phrase": "netflix"}, {"score": 0.0021049977753042253, "phrase": "recommender_systems"}], "paper_keywords": ["Reliability", " Human Factors", " Experimentation", " Product rating", " minimum number of ratings", " misbehavior", " bias", " true quality", " rating aggregation rule"], "paper_abstract": "Many Web services like Amazon, Epinions, and TripAdvisor provide historical product ratings so that users can evaluate the quality of products. Product ratings are important because they affect how well a product will be adopted by the market. The challenge is that we only have partial information on these ratings: each user assigns ratings to only a small subset of products. Under this partial information setting, we explore a number of fundamental questions. What is the minimum number of ratings a product needs so that one can make a reliable evaluation of its quality? How may users' misbehavior, such as cheating in product rating, affect the evaluation result? To answer these questions, we present a probabilistic model to capture various important factors (e.g., rating aggregation rules, rating behavior) that may influence the product quality assessment under the partial information setting. We derive the minimum number of ratings needed to produce a reliable indicator on the quality of a product. We extend our model to accommodate users' misbehavior in product rating. We derive the maximum fraction of misbehaving users that a rating aggregation rule can tolerate and the minimum number of ratings needed to compensate. We carry out experiments using both synthetic and real-world data (from Amazon and TripAdvisor). We not only validate our model but also show that the \"average rating rule\" produces more reliable and robust product quality assessments than the \"majority rating rule\" and the \"median rating rule\" in aggregating product ratings. Last, we perform experiments on two movie rating datasets (from Flixster and Netflix) to demonstrate how to apply our framework to improve the applications of recommender systems.", "paper_title": "Mathematical Modeling and Analysis of Product Rating with Partial Information", "paper_id": "WOS:000355675000001"}