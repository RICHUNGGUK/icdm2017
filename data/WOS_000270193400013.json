{"auto_keywords": [{"score": 0.048730390959229944, "phrase": "online_algorithm"}, {"score": 0.011955898026897402, "phrase": "best_fixed_s"}, {"score": 0.009731256162067133, "phrase": "offline_algorithm"}, {"score": 0.009662338117450693, "phrase": "approximation_algorithm"}, {"score": 0.00481495049065317, "phrase": "playing_games_with"}, {"score": 0.004757971766446564, "phrase": "online_linear_optimization_problem"}, {"score": 0.004712872344739, "phrase": "period_t"}, {"score": 0.004510621257178412, "phrase": "nature"}, {"score": 0.004163886956866897, "phrase": "fixed_cost_function"}, {"score": 0.004104789653560503, "phrase": "weight_vector"}, {"score": 0.004065856260542744, "phrase": "full-information_setting"}, {"score": 0.00403689776357084, "phrase": "vector_wt"}, {"score": 0.003441095739912004, "phrase": "online_shortest-path"}, {"score": 0.003424726997441264, "phrase": "online_traveling_salesman_problem"}, {"score": 0.0033841438302493914, "phrase": "online_clustering"}, {"score": 0.0033600243545849917, "phrase": "online_weighted_set"}, {"score": 0.0032652476949345866, "phrase": "efficient_exact_offline_optimization_algorithm"}, {"score": 0.0032111967830711413, "phrase": "efficient_online_algorithm"}, {"score": 0.003143011234621232, "phrase": "average_cost"}, {"score": 0.002905117389508774, "phrase": "previous_approach"}, {"score": 0.0028775298534120747, "phrase": "special_types"}, {"score": 0.0028638341999370344, "phrase": "approximation_algorithms"}, {"score": 0.002809698509866494, "phrase": "offline_approximation_algorithm"}, {"score": 0.002789661761685155, "phrase": "linear_optimization_problem"}, {"score": 0.00276976750429457, "phrase": "corresponding_online_approximation_algorithm"}, {"score": 0.002743461739463753, "phrase": "polynomial_blowup"}, {"score": 0.002685181176249374, "phrase": "alpha-approximation_guarantee"}, {"score": 0.0026596766243524765, "phrase": "expected_cost"}, {"score": 0.002553950356953297, "phrase": "best_s"}, {"score": 0.0024291174605753987, "phrase": "zinkevich's_algorithm"}, {"score": 0.00241755085920605, "phrase": "convex_optimization"}, {"score": 0.0024003038945183907, "phrase": "geometric_transformation"}, {"score": 0.0023492960110523325, "phrase": "standard_techniques"}, {"score": 0.002282963795800102, "phrase": "\"barycentric_spanner"}, {"score": 0.0021558531139163396, "phrase": "large_repeated_games"}, {"score": 0.0021049977753042253, "phrase": "best_responses"}], "paper_keywords": ["online linear optimization", " regret minimization", " approximation algorithms", " online algorithms"], "paper_abstract": "In an online linear optimization problem, on each period t, an online algorithm chooses s(t) is an element of S from a fixed (possibly infinite) set S of feasible decisions. Nature (who may be adversarial) chooses a weight vector w(t) is an element of R(n), and the algorithm incurs cost c(s(t), w(t)), where c is a fixed cost function that is linear in the weight vector. In the full-information setting, the vector wt is then revealed to the algorithm, and in the bandit setting, only the cost experienced, c(s(t), w(t)), is revealed. The goal of the online algorithm is to perform nearly as well as the best fixed s is an element of S in hindsight. Many repeated decision-making problems with weights fit naturally into this framework, such as online shortest-path, online traveling salesman problem (TSP), online clustering, and online weighted set cover. Previously, it was shown how to convert any efficient exact offline optimization algorithm for such a problem into an efficient online algorithm in both the full-information and the bandit settings, with average cost nearly as good as that of the best fixed s is an element of S in hindsight. However, in the case where the offline algorithm is an approximation algorithm with ratio alpha > 1, the previous approach worked only for special types of approximation algorithms. We show how to convert any offline approximation algorithm for a linear optimization problem into a corresponding online approximation algorithm, with a polynomial blowup in runtime. If the offline algorithm has an alpha-approximation guarantee, then the expected cost of the online algorithm on any sequence is not much larger than a times that of the best s is an element of S, where the best is chosen with the benefit of hindsight. Our main innovation is combining Zinkevich's algorithm for convex optimization with a geometric transformation that can be applied to any approximation algorithm. Standard techniques generalize the above result to the bandit setting, except that a \"barycentric spanner\" for the problem is also (provably) necessary as input. Our algorithm can also be viewed as a method for playing large repeated games, where one can compute only approximate best responses, rather than best responses.", "paper_title": "PLAYING GAMES WITH APPROXIMATION ALGORITHMS", "paper_id": "WOS:000270193400013"}