{"auto_keywords": [{"score": 0.03347071801557563, "phrase": "problem_classes"}, {"score": 0.00481495049065317, "phrase": "wavefront_applications"}, {"score": 0.004765482708043842, "phrase": "distributed_many-core_architectures"}, {"score": 0.004525629293824217, "phrase": "distributed_graphics_processing_unit"}, {"score": 0.0043875257506180865, "phrase": "pipelined_wavefront_applications"}, {"score": 0.004253618550301311, "phrase": "parallel_algorithms"}, {"score": 0.004060350364088702, "phrase": "scientific_and_engineering_applications"}, {"score": 0.003916098498242888, "phrase": "recently_developed_port"}, {"score": 0.0038558497470953306, "phrase": "lu_solver"}, {"score": 0.0037769520261285872, "phrase": "nas_parallel_benchmark_suite"}, {"score": 0.0035866734383189396, "phrase": "high-performance_computing_solutions"}, {"score": 0.0035498082086900195, "phrase": "nvidia"}, {"score": 0.003370907075333389, "phrase": "traditional_clusters"}, {"score": 0.00330195428282534, "phrase": "ibm"}, {"score": 0.003234299589505403, "phrase": "benchmark_results"}, {"score": 0.0030712749385664686, "phrase": "recently_developed_performance_model"}, {"score": 0.0027982016314450717, "phrase": "billion-cell_problem"}, {"score": 0.002684740763324991, "phrase": "theoretical_performance"}, {"score": 0.0026570998719084153, "phrase": "gpu_solutions"}, {"score": 0.0025361866386341796, "phrase": "sustained_application_performance"}, {"score": 0.002471400498582011, "phrase": "scientific_wavefront_applications"}, {"score": 0.0023711591828229736, "phrase": "gpu_solution"}, {"score": 0.002310578855290687, "phrase": "pcie_overheads"}, {"score": 0.002286781334850213, "phrase": "decomposition_constraints"}, {"score": 0.002251542790734307, "phrase": "new_k-blocking_strategy"}, {"score": 0.0021826828321952615, "phrase": "future_performance"}, {"score": 0.0021049977753042253, "phrase": "gpu-based_architectures"}], "paper_keywords": ["wavefront", " GPU", " many-core computing", " CUDA", " optimization", " performance modelling"], "paper_abstract": "In this paper we investigate the use of distributed graphics processing unit (GPU)-based architectures to accelerate pipelined wavefront applications-a ubiquitous class of parallel algorithms used for the solution of a number of scientific and engineering applications. Specifically, we employ a recently developed port of the LU solver (from the NAS Parallel Benchmark suite) to investigate the performance of these algorithms on high-performance computing solutions from NVIDIA (Tesla C1060 and C2050) as well as on traditional clusters (AMD/InfiniBand and IBM BlueGene/P). Benchmark results are presented for problem classes A to C and a recently developed performance model is used to provide projections for problem classes D and E, the latter of which represents a billion-cell problem. Our results demonstrate that while the theoretical performance of GPU solutions will far exceed those of many traditional technologies, the sustained application performance is currently comparable for scientific wavefront applications. Finally, a breakdown of the GPU solution is conducted, exposing PCIe overheads and decomposition constraints. A new k-blocking strategy is proposed to improve the future performance of this class of algorithm on GPU-based architectures.", "paper_title": "On the Acceleration of Wavefront Applications using Distributed Many-Core Architectures", "paper_id": "WOS:000300042300002"}