{"auto_keywords": [{"score": 0.042332068480846564, "phrase": "nbi"}, {"score": 0.012802920494291407, "phrase": "wli"}, {"score": 0.005969498164987213, "phrase": "image_stream"}, {"score": 0.005867743285512599, "phrase": "teleoperated_flexible_endoscopes"}, {"score": 0.005404273660314702, "phrase": "clinical_setting"}, {"score": 0.005084108064228205, "phrase": "commercial_gastrointestinal_endoscopes"}, {"score": 0.00481495049065317, "phrase": "image-based_pose_detection"}, {"score": 0.004764058719939481, "phrase": "colorectal_cancer"}, {"score": 0.004732523578222246, "phrase": "leading_causes"}, {"score": 0.004719967769672781, "phrase": "cancer-related_deaths"}, {"score": 0.004608447069728477, "phrase": "emerging_technology"}, {"score": 0.0045901169723656194, "phrase": "patient_apprehension"}, {"score": 0.004505531506839144, "phrase": "robust_feedback"}, {"score": 0.004329466192376432, "phrase": "novel_image-based_tracking_system"}, {"score": 0.00424401959643256, "phrase": "proposed_approach"}, {"score": 0.004232754320736792, "phrase": "artificial_neural_networks"}, {"score": 0.00417132545659814, "phrase": "optical_flow"}, {"score": 0.00406190229765448, "phrase": "first_time"}, {"score": 0.004051118465276454, "phrase": "narrow_band_illumination"}, {"score": 0.004002724181294861, "phrase": "commercial_endoscope"}, {"score": 0.003971143445938496, "phrase": "feature_extraction"}, {"score": 0.003923915284959959, "phrase": "white_light_illumination"}, {"score": 0.003831130857788212, "phrase": "endoscopic_camera_stream"}, {"score": 0.0037755085509719737, "phrase": "best_features"}, {"score": 0.003760478950217445, "phrase": "neural_networks"}, {"score": 0.0036373291753692546, "phrase": "lumen-centered_partitioning"}, {"score": 0.0034859784191419306, "phrase": "root_mean_square_error"}, {"score": 0.0034628739472520307, "phrase": "ground_truth"}, {"score": 0.0034445002926891725, "phrase": "robotic_arm"}, {"score": 0.0034171218142220396, "phrase": "commercial_state-of-the-art_magnetic_tracker"}, {"score": 0.0033362808262068794, "phrase": "magnetic_tracker"}, {"score": 0.0032790837847071945, "phrase": "expert_endoscopist"}, {"score": 0.0032573460929536326, "phrase": "colonoscopy_training_model"}, {"score": 0.0032486912871662697, "phrase": "porcine_blood"}, {"score": 0.003218579575714347, "phrase": "ann_output"}, {"score": 0.0031887460730482832, "phrase": "magnetic_tracker_readings"}, {"score": 0.0030967664671042445, "phrase": "first_experiment"}, {"score": 0.003084430447410567, "phrase": "best_anns"}, {"score": 0.0028175869111208697, "phrase": "illumination_modality"}, {"score": 0.002573769226959822, "phrase": "feature_strengths"}, {"score": 0.0025566952106314484, "phrase": "grayscale_version"}, {"score": 0.0024273379788341118, "phrase": "valid_mechanisms"}, {"score": 0.0024208831577692486, "phrase": "endoscopic_camera"}, {"score": 0.0023730146921498337, "phrase": "similar_performance"}, {"score": 0.0023478721466464888, "phrase": "state-of-the-art_magnetic_tracker"}, {"score": 0.002292268882940364, "phrase": "better_performance"}, {"score": 0.0022439477248503343, "phrase": "best_approach"}, {"score": 0.0022350013061445484, "phrase": "different_variations"}, {"score": 0.0022260904764292372, "phrase": "vision-based_pose_estimation"}, {"score": 0.002182065249115692, "phrase": "accurate_feedback"}, {"score": 0.0021332193737802585, "phrase": "enabling_technology"}, {"score": 0.002127545010174509, "phrase": "closed-loop_control"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Artificial neural networks", " Pose estimation", " Localization", " Optical flow", " Visual odometry", " Closed-loop control", " Teleoperation", " Narrow band imaging", " Flexible endoscopes", " Colonoscopes", " Gastrointestinal endoscopy"], "paper_abstract": "Objective: Colorectal cancer is one of the leading causes of cancer-related deaths in the world, although it can be effectively treated if detected early. Teleoperated flexible endoscopes are an emerging technology to ease patient apprehension about the procedure, and subsequently increase compliance. Essential to teleoperation is robust feedback reflecting the change in pose (i.e., position and orientation) of the tip of the endoscope. The goal of this study is to first describe a novel image-based tracking system for teleoperated flexible endoscopes, and subsequently determine its viability in a clinical setting. The proposed approach leverages artificial neural networks (ANNs) to learn the mapping that links the optical flow between two sequential images to the change in the pose of the camera. Secondly, the study investigates for the first time how narrow band illumination (NBI) - today available in commercial gastrointestinal endoscopes - can be applied to enhance feature extraction, and quantify the effect of NBI and white light illumination (WLI), as well as their color information, on the strength of features extracted from the endoscopic camera stream. Methods and materials: In order to provide the best features for the neural networks to learn the change in pose based on the image stream, we investigated two different imaging modalities - WLI and NBI - and we applied two different spatial partitions - lumen-centered and grid-based - to create descriptors used as input to the ANNs. An experiment was performed to compare the error of these four variations, measured in root mean square error (RMSE) from ground truth given by a robotic arm, to that of a commercial state-of-the-art magnetic tracker. The viability of this technique for a clinical setting was then tested using the four ANN variations, a magnetic tracker, and a commercial colonoscope. The trial was performed by an expert endoscopist (>2000 lifetime procedures) on a colonoscopy training model with porcine blood, and the RMSE of the ANN output was calculated with respect to the magnetic tracker readings. Using the image stream obtained from the commercial endoscope, the strength of features extracted was evaluated. Results: In the first experiment, the best ANNs resulted from grid-based partitioning under WLI (2.42 mm RMSE) for position, and from lumen-centered partitioning under NBI (1.69 degrees RMSE) for rotation. By comparison, the performance of the tracker was 2.49 mm RMSE in position and 0.89 degrees RMSE in rotation. The trial with the commercial endoscope indicated that lumen-centered partitioning was the best overall, while NBI outperformed WLI in terms of illumination modality. The performance of lumen-centered partitioning with NBI was 1.03 +/- 0.8 mm RMSE in positional degrees of freedom (DOF), and 1.26 +/- 0.98 degrees RMSE in rotational DOF, while with WLI, the performance was 1.56 +/- 1.15 mm RMSE in positional DOF and 2.45 +/- 1.90 degrees RMSE in rotational DOF. Finally, the features extracted under NBI were found to be twice as strong as those extracted under WLI, but no significance in feature strengths was observed between a grayscale version of the image, and the red, blue, and green color channels. Conclusions: This work demonstrates that both WLI and NBI, combined with feature partitioning based on the anatomy of the colon, provide valid mechanisms for endoscopic camera pose estimation via image stream. Illumination provided by WLI and NBI produce ANNs with similar performance which are comparable to that of a state-of-the-art magnetic tracker. However, NBI produces features that are stronger than WLI, which enables more robust feature tracking, and better performance of the ANN in terms of accuracy. Thus, NBI with lumen-centered partitioning resulted the best approach among the different variations tested for vision-based pose estimation. The proposed approach takes advantage of components already available in commercial gastrointestinal endoscopes to provide accurate feedback about the motion of the tip of the endoscope. This solution may serve as an enabling technology for closed-loop control of teleoperated flexible endoscopes. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Image partitioning and illumination in image-based pose detection for teleoperated flexible endoscopes", "paper_id": "WOS:000328300700005"}