{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "route_planning_system"}, {"score": 0.009370557987065535, "phrase": "case_studies"}, {"score": 0.004744437370338926, "phrase": "q_value-based_dynamic_programming"}, {"score": 0.004428728205625129, "phrase": "new_model"}, {"score": 0.004299910946753963, "phrase": "multi-agent_reinforcement_learning"}, {"score": 0.0041136473765874815, "phrase": "combined_q-value"}, {"score": 0.003954837422946628, "phrase": "boltzmann_distribution"}, {"score": 0.003858697684681798, "phrase": "vehicle_delay's_problems"}, {"score": 0.003709693561373117, "phrase": "road_network_environments"}, {"score": 0.003584025547693836, "phrase": "road_safety"}, {"score": 0.003531474887552889, "phrase": "fuel_capacity"}, {"score": 0.003462599815177726, "phrase": "priority_route_plan"}, {"score": 0.003378385493203297, "phrase": "important_part"}, {"score": 0.003247868216333148, "phrase": "multi-agent_system"}, {"score": 0.0032161507921411895, "phrase": "mas"}, {"score": 0.003168859801438632, "phrase": "learning_abilities"}, {"score": 0.0030017207229983385, "phrase": "malaysia's_cities"}, {"score": 0.0028016507334576216, "phrase": "road_networks"}, {"score": 0.0027741823811768527, "phrase": "malaysia"}, {"score": 0.002640781900605126, "phrase": "travel_durations"}, {"score": 0.0025638362414466278, "phrase": "existing_approaches"}, {"score": 0.0024525907271610104, "phrase": "actual_travel_times"}, {"score": 0.00241658945942583, "phrase": "proposed_method"}, {"score": 0.0022890371899188466, "phrase": "proposed_approach"}, {"score": 0.002255431275670053, "phrase": "unique_contribution"}, {"score": 0.0022005118194652704, "phrase": "computational_intelligence"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Route planning system (RPS)", " Multi-agent system (MAS)", " Multi-agent reinforcement learning (MARL)", " Q-learning", " Traffic congestion"], "paper_abstract": "In this paper, a new model for a route planning system based on multi-agent reinforcement learning (MARL) algorithms is proposed. The combined Q-value based dynamic programming (QVDP) with Boltzmann distribution was used to solve vehicle delay's problems by studying the weights of various components in road network environments such as weather, traffic, road safety, and fuel capacity to create a priority route plan for vehicles. The important part of the study was to use a multi-agent system (MAS) with learning abilities which in order to make decisions about routing vehicles between Malaysia's cities. The evaluation was done using a number of case studies that focused on road networks in Malaysia. The results of these experiments indicated that the travel durations for the case studies predicted by existing approaches were between 0.00 and 12.33% off from the actual travel times by the proposed method. From the experiments, the results illustrate that the proposed approach is a unique contribution to the field of computational intelligence in the route planning system. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Modeling of route planning system based on Q value-based dynamic programming with multi-agent reinforcement learning algorithms", "paper_id": "WOS:000332811300014"}