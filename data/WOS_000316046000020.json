{"auto_keywords": [{"score": 0.039282223508626896, "phrase": "hard_sciences"}, {"score": 0.00481495049065317, "phrase": "national_peer-review_research_assessment_exercises"}, {"score": 0.004500891637057374, "phrase": "complete_waste"}, {"score": 0.0043151088251388815, "phrase": "italian"}, {"score": 0.004102096151528319, "phrase": "ample_demonstration"}, {"score": 0.0038343546245999285, "phrase": "national_research_assessment_exercises"}, {"score": 0.0034944094552943, "phrase": "italian_case"}, {"score": 0.0030017207229983385, "phrase": "first_national_evaluation_exercise"}, {"score": 0.002735392281320413, "phrase": "zero_cost"}, {"score": 0.0021408862709571615, "phrase": "italian_evaluation"}, {"score": 0.0021049977753042253, "phrase": "research_institutions"}], "paper_keywords": ["Research evaluation", " Bibliometrics", " VTR", " Ranking", " Productivity", " Universities"], "paper_abstract": "There has been ample demonstration that bibliometrics is superior to peer-review for national research assessment exercises in the hard sciences. In this paper we examine the Italian case, taking the 2001-2003 university performance rankings list based on bibliometrics as benchmark. We compare the accuracy of the first national evaluation exercise, conducted entirely by peer-review, to other rankings lists prepared at zero cost, based on indicators indirectly linked to performance or available on the Internet. The results show that, for the hard sciences, the costs of conducting the Italian evaluation of research institutions could have been completely avoided.", "paper_title": "National peer-review research assessment exercises for the hard sciences can be a complete waste of money: the Italian case", "paper_id": "WOS:000316046000020"}