{"auto_keywords": [{"score": 0.048231156244864744, "phrase": "non-convex_loss_function"}, {"score": 0.03992659287798476, "phrase": "tsvr"}, {"score": 0.004278807087784626, "phrase": "robust_truncated_support_vector_regression"}, {"score": 0.0036914757355166966, "phrase": "concave_convex_procedure"}, {"score": 0.0033452741392850523, "phrase": "non-convex_problem"}, {"score": 0.0031845067058084613, "phrase": "convex_ones"}, {"score": 0.0030314419455512013, "phrase": "better_robustness"}, {"score": 0.0028857130140890787, "phrase": "classical_support_vector_regression"}, {"score": 0.0027469703311742647, "phrase": "tsvr_gain_advantages"}, {"score": 0.00266693888510356, "phrase": "generalization_ability"}, {"score": 0.002538687900036229, "phrase": "support_vector"}, {"score": 0.002346160830406661, "phrase": "synthetic_and_real-world_benchmark_data_sets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Non-convex loss function", " Support vector regression", " Robustness"], "paper_abstract": "In this paper, we utilize two epsilon-insensitive loss functions to construct a non-convex loss function. Based on this non-convex loss function, a robust truncated support vector regression (TSVR) is proposed. In order to solve the TSVR, the concave convex procedure is used to circumvent this problem though transforming the non-convex problem to a sequence of convex ones. The TSVR owns better robustness to outliers than the classical support vector regression, which makes the TSVR gain advantages in the generalization ability and the number of support vector. Finally, the experiments on the synthetic and real-world benchmark data sets further confirm the effectiveness of our proposed TSVR. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Robust truncated support vector regression", "paper_id": "WOS:000277726300047"}