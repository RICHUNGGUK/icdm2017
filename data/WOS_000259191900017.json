{"auto_keywords": [{"score": 0.04522176534199055, "phrase": "fixed_level"}, {"score": 0.03778413671149982, "phrase": "smoothing_parameters"}, {"score": 0.00481495049065317, "phrase": "discriminant_analysis"}, {"score": 0.004730158389701481, "phrase": "case-specific_smoothing_parameters"}, {"score": 0.004605748839642513, "phrase": "kernel_discriminant_analysis"}, {"score": 0.004103212598803194, "phrase": "training_data"}, {"score": 0.0039248128268720645, "phrase": "unlabeled_observations"}, {"score": 0.0036553070575015344, "phrase": "good_choice"}, {"score": 0.0029789104204803137, "phrase": "entire_measurement_space"}, {"score": 0.002629889135655667, "phrase": "specific_observation"}, {"score": 0.002470987929071079, "phrase": "simple_method"}, {"score": 0.0022806798371116698, "phrase": "benchmark_data_sets"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["bandwidth", " Bayes risk", " bootstrap", " cross validation", " kernel smoothing", " misclassification rate", " nearest neighbor", " p-value"], "paper_abstract": "In kernel discriminant analysis, one common practice is to use a fixed level of smoothing (estimated from training data) for classifying all unlabeled observations. But, in classification, a good choice of smoothing parameters also depends on the observation to be classified. Therefore, instead of using a fixed level of smoothing over the entire measurement space, it may be more useful to estimate the smoothing parameters depending on that specific observation. Here, we propose a simple method for this case-specific smoothing. Some benchmark data sets are analyzed to illustrate the performance of the proposed method.", "paper_title": "Kernel discriminant analysis using case-specific smoothing parameters", "paper_id": "WOS:000259191900017"}