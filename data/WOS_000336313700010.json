{"auto_keywords": [{"score": 0.04635074898147141, "phrase": "mcelm"}, {"score": 0.020557947353237592, "phrase": "cognitive_component"}, {"score": 0.015023287206334323, "phrase": "output_weights"}, {"score": 0.008480547452218693, "phrase": "meta-cognitive_component"}, {"score": 0.005535394368165321, "phrase": "hinge-loss_error_function"}, {"score": 0.00481495049065317, "phrase": "meta-cognitive_learning_algorithm"}, {"score": 0.004773404795430319, "phrase": "extreme_learning_machine_classifier"}, {"score": 0.004691380685111258, "phrase": "efficient_fast_learning_classifier"}, {"score": 0.004637478829869904, "phrase": "nelson_and_narens_model"}, {"score": 0.00461075951152053, "phrase": "human_meta-cognition"}, {"score": 0.004518442937844318, "phrase": "extreme_learning_machine"}, {"score": 0.004191377834552202, "phrase": "three-layered_extreme_learning_machine"}, {"score": 0.004071957673937727, "phrase": "hidden_layer"}, {"score": 0.004001938457469328, "phrase": "q-gaussian_activation_function"}, {"score": 0.003899151860479525, "phrase": "output_layers"}, {"score": 0.0037880260900233064, "phrase": "self-regulatory_learning_mechanism"}, {"score": 0.0035442655396704724, "phrase": "meta-cognitive_framework"}, {"score": 0.0033741997276290356, "phrase": "monitory_signals"}, {"score": 0.0033161388347360786, "phrase": "suitable_learning_strategies"}, {"score": 0.003138768436081888, "phrase": "new_neuron"}, {"score": 0.002996761094541162, "phrase": "future_use"}, {"score": 0.002945175711537758, "phrase": "conventional_elm"}, {"score": 0.0027795345823932406, "phrase": "training_process"}, {"score": 0.0026156018381676407, "phrase": "gaussian_function"}, {"score": 0.0025336179740814905, "phrase": "least_square_estimate"}, {"score": 0.0024541975028954497, "phrase": "posterior_probabilities"}, {"score": 0.002425937226012825, "phrase": "mean-square_error"}, {"score": 0.002370386872018425, "phrase": "mcelm_classifier"}, {"score": 0.0023363141951290526, "phrase": "network_parameters"}, {"score": 0.0022828113789751694, "phrase": "recursive_least_square_estimate"}, {"score": 0.0022048406330100697, "phrase": "benchmark_classification_problems"}, {"score": 0.0021857667493036786, "phrase": "uci_machine"}, {"score": 0.0021794454466797382, "phrase": "learning_repository"}, {"score": 0.00212336833618933, "phrase": "elm_framework"}, {"score": 0.0021049977753042253, "phrase": "decision-making_ability"}], "paper_keywords": ["Extreme learning machine", " Meta-cognition", " Classification", " Self-regulatory learning mechanism", " Hinge-loss error function"], "paper_abstract": "This paper presents an efficient fast learning classifier based on the Nelson and Narens model of human meta-cognition, namely 'Meta-cognitive Extreme Learning Machine (McELM).' McELM has two components: a cognitive component and a meta-cognitive component. The cognitive component of McELM is a three-layered extreme learning machine (ELM) classifier. The neurons in the hidden layer of the cognitive component employ the q-Gaussian activation function, while the neurons in the input and output layers are linear. The meta-cognitive component of McELM has a self-regulatory learning mechanism that decides what-to-learn, when-to-learn, and how-to-learn in a meta-cognitive framework. As the samples in the training set are presented one-by-one, the meta-cognitive component receives the monitory signals from the cognitive component and chooses suitable learning strategies for the sample. Thus, it either deletes the sample, uses the sample to add a new neuron, or updates the output weights based on the sample, or reserves the sample for future use. Therefore, unlike the conventional ELM, the architecture of McELM is not fixed a priori, instead, the network is built during the training process. While adding a neuron, McELM chooses the centers based on the sample, and the width of the Gaussian function is chosen randomly. The output weights are estimated using the least square estimate based on the hinge-loss error function. The hinge-loss error function facilitates prediction of posterior probabilities better than the mean-square error and is hence preferred to develop the McELM classifier. While updating the network parameters, the output weights are updated using a recursive least square estimate. The performance of McELM is evaluated on a set of benchmark classification problems from the UCI machine learning repository. Performance study results highlight that meta-cognition in ELM framework enhances the decision-making ability of ELM significantly.", "paper_title": "A Meta-Cognitive Learning Algorithm for an Extreme Learning Machine Classifier", "paper_id": "WOS:000336313700010"}