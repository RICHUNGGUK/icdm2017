{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "common_framework"}, {"score": 0.004734448316824488, "phrase": "multimodal_generation"}, {"score": 0.0043150485532080065, "phrase": "international_effort"}, {"score": 0.004171891198117434, "phrase": "multimodal_behavior_generation_framework"}, {"score": 0.004102096151528319, "phrase": "embodied_conversational_agents"}, {"score": 0.003584025547693836, "phrase": "intent_planning"}, {"score": 0.0035240305920962796, "phrase": "behavior_planning"}, {"score": 0.003349984456443527, "phrase": "function_markup_language"}, {"score": 0.0030787405733989615, "phrase": "physical_behavior"}, {"score": 0.002951444412262927, "phrase": "first_two_stages"}, {"score": 0.0027123819773059127, "phrase": "desired_physical_realization"}, {"score": 0.002600194073758015, "phrase": "last_two_stages"}, {"score": 0.002195866991284673, "phrase": "eca_researchers"}], "paper_keywords": [""], "paper_abstract": "This paper describes an international effort to unify a multimodal behavior generation framework for Embodied Conversational Agents (ECAs). We propose a three stage model we call SAIBA where the stages represent intent planning, behavior planning and behavior realization. A Function Markup Language (FML), describing intent without referring to physical behavior, mediates between the first two stages and a Behavior Markup Language (BML) describing desired physical realization, mediates between the last two stages. In this paper we will focus on BML. The hope is that this abstraction and modularization will help ECA researchers pool their resources to build more sophisticated virtual humans.", "paper_title": "Towards a common framework for multimodal generation: The behavior markup language", "paper_id": "WOS:000240268400017"}