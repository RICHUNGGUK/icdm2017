{"auto_keywords": [{"score": 0.045290403341537215, "phrase": "distributed_data_aggregation_algorithms"}, {"score": 0.00481495049065317, "phrase": "tolerant_orthogonalization"}, {"score": 0.004714869813251479, "phrase": "randomized_distributed_data_aggregation"}, {"score": 0.004552648949390462, "phrase": "distributed_algorithms"}, {"score": 0.004489327204473076, "phrase": "matrix_computations"}, {"score": 0.004274527415193801, "phrase": "randomized_communication_schedules"}, {"score": 0.0040133278382101885, "phrase": "new_aggregation_algorithm"}, {"score": 0.0038751504050385183, "phrase": "distributed_values"}, {"score": 0.0035376693476114733, "phrase": "superior_resilience_properties"}, {"score": 0.0033682492486884364, "phrase": "existing_aggregation_methods"}, {"score": 0.0031845067058084583, "phrase": "hypercube_topology"}, {"score": 0.0029688173975648173, "phrase": "optimal_all-to-all_reduction_operation"}, {"score": 0.0027291488710723152, "phrase": "orthogonalization"}, {"score": 0.00263505298504827, "phrase": "prototypical_matrix_computation_task"}, {"score": 0.0025801648787263662, "phrase": "new_fault"}, {"score": 0.002405309378904663, "phrase": "accurate_results"}, {"score": 0.002306123367679187, "phrase": "node_failures"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Distributed reduction operation", " Push-flow algorithm", " Distributed orthogonalization", " Distributed matrix computations", " Fault tolerant matrix computations"], "paper_abstract": "The construction of distributed algorithms for matrix computations built on top of distributed data aggregation algorithms with randomized communication schedules is investigated. For this purpose, a new aggregation algorithm for summing or averaging distributed values, the push-flow algorithm, is developed, which achieves superior resilience properties with respect to failures compared to existing aggregation methods. It is illustrated that on a hypercube topology it asymptotically requires the same number of iterations as the optimal all-to-all reduction operation and that it scales well with the number of nodes. Orthogonalization is studied as a prototypical matrix computation task. A new fault tolerant distributed orthogonalization method rdmGS, which can produce accurate results even in the presence of node failures, is built on top of distributed data aggregation algorithms. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Scalable and fault tolerant orthogonalization based on randomized distributed data aggregation", "paper_id": "WOS:000328184300008"}