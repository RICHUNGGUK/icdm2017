{"auto_keywords": [{"score": 0.03908291158054249, "phrase": "rmcv"}, {"score": 0.01560544606717282, "phrase": "risk_minimization"}, {"score": 0.011147241535340907, "phrase": "restricted_bncs"}, {"score": 0.009626251854940874, "phrase": "nbc"}, {"score": 0.008653817231514684, "phrase": "neural_network"}, {"score": 0.008099903777071127, "phrase": "unrestricted_bncs"}, {"score": 0.00481495049065317, "phrase": "bayesian_network_classifiers"}, {"score": 0.004744437370338926, "phrase": "bayesian_networks"}, {"score": 0.004640590144749795, "phrase": "powerful_graphical_model"}, {"score": 0.0045726187330434025, "phrase": "probabilistic_relationships"}, {"score": 0.004279391641065566, "phrase": "bayesian"}, {"score": 0.004139028737420222, "phrase": "common_way"}, {"score": 0.004108589735101849, "phrase": "likelihood_scores"}, {"score": 0.003830312347175889, "phrase": "general_inference_problem"}, {"score": 0.0037463983616303786, "phrase": "cross_validation"}, {"score": 0.003597284507308585, "phrase": "classification-oriented_score"}, {"score": 0.003466865016432561, "phrase": "classification-oriented_scores"}, {"score": 0.003378385493203297, "phrase": "non-bn_classifiers"}, {"score": 0.0033411580268394732, "phrase": "small_real_and_synthetic_problems"}, {"score": 0.003267925215811654, "phrase": "possible_graphs"}, {"score": 0.0032081215771180664, "phrase": "rmcv_superiority"}, {"score": 0.0031845067058084583, "phrase": "marginal_and_class-conditional_likelihood-based_scores"}, {"score": 0.003080365929916083, "phrase": "twenty-two_real-world_datasets"}, {"score": 0.0030017207229983385, "phrase": "rmcv-based_algorithm"}, {"score": 0.0029576827451501956, "phrase": "naive_bayesian_classifier"}, {"score": 0.0028609864568829605, "phrase": "tan"}, {"score": 0.0027878797103973313, "phrase": "marginal_or_conditional_likelihood_scores"}, {"score": 0.002726740692380339, "phrase": "non-bn_state"}, {"score": 0.0026966744704447275, "phrase": "art_classifiers"}, {"score": 0.0026570998719084153, "phrase": "support_vector_machine"}, {"score": 0.0026084451971464867, "phrase": "classification_tree"}, {"score": 0.0025324393547676623, "phrase": "optimized_version"}, {"score": 0.0023606625824479956, "phrase": "main_conclusion"}, {"score": 0.0022415745160585146, "phrase": "good_alternative"}, {"score": 0.002208663870368384, "phrase": "traditional_machine-learning_classifiers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Bayesian networks", " Classification", " Probabilistic graphical models", " Structure learning"], "paper_abstract": "Bayesian networks (BNs) provide a powerful graphical model for encoding the probabilistic relationships among a set of variables, and hence can naturally be used for classification. However, Bayesian network classifiers (BNCs) learned in the common way using likelihood scores usually tend to achieve only mediocre classification accuracy because these scores are less specific to classification, but rather suit a general inference problem. We propose risk minimization by cross validation (RMCV) using the 0/1 loss function, which is a classification-oriented score for unrestricted BNCs. RMCV is an extension of classification-oriented scores commonly used in learning restricted BNCs and non-BN classifiers. Using small real and synthetic problems, allowing for learning all possible graphs, we empirically demonstrate RMCV superiority to marginal and class-conditional likelihood-based scores with respect to classification accuracy. Experiments using twenty-two real-world datasets show that BNCs learned using an RMCV-based algorithm significantly outperform the naive Bayesian classifier (NBC), tree augmented NBC (TAN), and other BNCs learned using marginal or conditional likelihood scores and are on par with non-BN state of the art classifiers, such as support vector machine, neural network, and classification tree. These experiments also show that an optimized version of RMCV is faster than all unrestricted BNCs and comparable with the neural network with respect to run-time. The main conclusion from our experiments is that unrestricted BNCs, when learned properly, can be a good alternative to restricted BNCs and traditional machine-learning classifiers with respect to both accuracy and efficiency. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "Learning Bayesian network classifiers by risk minimization", "paper_id": "WOS:000305104100010"}