{"auto_keywords": [{"score": 0.03596176205294266, "phrase": "expectation-maximization_algorithm"}, {"score": 0.0038492126993451337, "phrase": "clustering_noise_benefit"}, {"score": 0.003592859432554987, "phrase": "general_noise_benefit"}, {"score": 0.0031845067058084613, "phrase": "special_cases"}, {"score": 0.0025014259919355453, "phrase": "stochastic_unsupervised_competitive_learning"}, {"score": 0.0023346234464901978, "phrase": "differential_competitive_learning"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Noise injection", " Stochastic resonance", " Clustering", " EM algorithm", " Competitive learning", " k-means clustering"], "paper_abstract": "Noise can provably speed up convergence in many centroid-based clustering algorithms. This includes the popular k-means clustering algorithm. The clustering noise benefit follows from the general noise benefit for the expectation-maximization algorithm because many clustering algorithms are special cases of the expectation-maximization algorithm. Simulations show that noise also speeds up convergence in stochastic unsupervised competitive learning, supervised competitive learning, and differential competitive learning. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Noise-enhanced clustering and competitive learning algorithms", "paper_id": "WOS:000313141800009"}