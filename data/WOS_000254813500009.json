{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "intelligent"}, {"score": 0.0047273577269638725, "phrase": "overlapped_execution"}, {"score": 0.004684157900507474, "phrase": "grid_applications"}, {"score": 0.004641351004344458, "phrase": "existing_data_grid_scheduling_systems"}, {"score": 0.004515252649226697, "phrase": "replica_location_services"}, {"score": 0.004453488286477661, "phrase": "simple_staging"}, {"score": 0.004332471656145115, "phrase": "computing_tasks"}, {"score": 0.004119049028319832, "phrase": "considerable_degradations"}, {"score": 0.0039522429946090174, "phrase": "tightly-coupled_cluster"}, {"score": 0.0038447943243941685, "phrase": "numerous_nodes"}, {"score": 0.0037060428445111694, "phrase": "extreme_performance_degradation"}, {"score": 0.0033651019362620866, "phrase": "expensive_solutions"}, {"score": 0.0033190180867511605, "phrase": "parallel_file_systems"}, {"score": 0.0031991799574455555, "phrase": "data_transfer"}, {"score": 0.002799810685137358, "phrase": "multiple_nodes"}, {"score": 0.0027614468443073028, "phrase": "multireplication_framework"}, {"score": 0.0025537472239953807, "phrase": "staging_time"}, {"score": 0.002461472107682778, "phrase": "data_staging"}, {"score": 0.002427732996314194, "phrase": "bound_tasks"}, {"score": 0.002405496949144104, "phrase": "early_benchmark_results"}, {"score": 0.002214297250267208, "phrase": "data_transfers"}, {"score": 0.002163930783583212, "phrase": "cpu_utilization"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["grid computing", " job scheduling", " data grid", " data-intensive application"], "paper_abstract": "Existing data grid scheduling systems handle huge data I/O via replica location services coupled with simple staging and decoupled from scheduling of computing tasks. However, when the application/workflow scales, we observe considerable degradations in performance, compared to processing within a tightly-coupled cluster. For example, when numerous nodes access the same set of files simultaneously, extreme performance degradation occurs even if replicas are used, due to bottlenecks that show in the infrastructure. Instead of resorting to expensive solutions such as parallel file systems, we propose tightly coupling replica and data transfer management with computation scheduling for alleviating such situations. In particular, we propose three techniques: (1) data-staging requests aggregation and O(1) replication across multiple nodes using a multireplication framework, (2) replica-centric scheduling, which reuses previously used data for minimizing staging time and (3) overlapped execution of data staging and compute bound tasks. Early benchmark results implemented in our prototype Condor-like grid scheduling system demonstrate that the techniques are quite effective in eliminating much of the overhead in data transfers and achieving 100% of CPU utilization. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Intelligent data staging with overlapped execution of grid applications", "paper_id": "WOS:000254813500009"}