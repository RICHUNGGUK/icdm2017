{"auto_keywords": [{"score": 0.007651503322878484, "phrase": "dai_et_al"}, {"score": 0.005313498094823171, "phrase": "nocedal"}, {"score": 0.00481495049065317, "phrase": "unconstrained_minimization"}, {"score": 0.0047113960612140335, "phrase": "modified_secant_equation"}, {"score": 0.004650572834645031, "phrase": "li"}, {"score": 0.004610062382565798, "phrase": "fukushima"}, {"score": 0.0044524122425287005, "phrase": "barzilai-borwein_gradient_method"}, {"score": 0.004337710093279712, "phrase": "newly_proposed_stepsize"}, {"score": 0.00428146713705618, "phrase": "effective_stepsize"}, {"score": 0.004153041453795458, "phrase": "adaptive_scheme"}, {"score": 0.004046020290832207, "phrase": "objective_function_convexity"}, {"score": 0.003958937342925219, "phrase": "modified_two-point_stepsize_gradient_algorithm"}, {"score": 0.0038401488612789963, "phrase": "limit_point"}, {"score": 0.003504670673093149, "phrase": "unconstrained_optimization_test_problems"}, {"score": 0.003459191419478298, "phrase": "cuter_collection"}, {"score": 0.0031431690368229443, "phrase": "raydan"}, {"score": 0.0030888830649190282, "phrase": "numerical_comparisons"}, {"score": 0.0029572449603376635, "phrase": "gilbert"}, {"score": 0.002893508389351546, "phrase": "hestenes"}, {"score": 0.0028684092002834107, "phrase": "stiefel"}, {"score": 0.0027822459052173113, "phrase": "memoryless_bfgs_algorithm"}, {"score": 0.0027461472175772045, "phrase": "liu"}, {"score": 0.0026062133750675894, "phrase": "numerical_support"}, {"score": 0.0022472527731744974, "phrase": "numerical_results"}, {"score": 0.0021327110530034088, "phrase": "performance_profile"}, {"score": 0.002105000361603945, "phrase": "dolan"}], "paper_keywords": ["unconstrained optimization", " two-point stepsize gradient algorithm", " modified secant equation", " convexity", " nonmonotone line search", " 90C52", " 65K05", " 49M37", " 26B25"], "paper_abstract": "Based on a modified secant equation proposed by Li and Fukushima, we derive a stepsize for the Barzilai-Borwein gradient method. Then, using the newly proposed stepsize and another effective stepsize proposed by Dai et al. in an adaptive scheme that is based on the objective function convexity, we suggest a modified two-point stepsize gradient algorithm. We also show that the limit point of the sequence generated by our algorithm is first-order critical. Finally, our numerical comparisons done on a set of unconstrained optimization test problems from the CUTEr collection are presented. At first, we compare the performance of our algorithm with two other two-point stepsize gradient algorithms proposed by Dai et al. and Raydan. Then, numerical comparisons between the implementations of our algorithm and two conjugate gradient methods proposed by Gilbert and Nocedal, and Hestenes and Stiefel, and also, with the memoryless BFGS algorithm proposed by Liu and Nocedal, are made. Furthermore, to provide a numerical support for our adaptive approach, we compare two other two-point stepsize gradient algorithms, one of which applies the stepsize proposed by Dai et al. and the other applies our newly proposed stepsize, with our algorithm which applies both of these stepsizes together. Numerical results demonstrating the efficiency of our algorithm, in the sense of the performance profile introduced by Dolan and More, are reported.", "paper_title": "A modified two-point stepsize gradient algorithm for unconstrained minimization", "paper_id": "WOS:000322823700005"}