{"auto_keywords": [{"score": 0.03918658648346325, "phrase": "visual_words"}, {"score": 0.00481495049065317, "phrase": "difference_maximization"}, {"score": 0.004776669953449352, "phrase": "image_classification"}, {"score": 0.004719816332271661, "phrase": "important_topic"}, {"score": 0.004682288586254123, "phrase": "computer_vision"}, {"score": 0.004481132747216135, "phrase": "rapid_increase"}, {"score": 0.004254467919664946, "phrase": "different_geometric_deformations"}, {"score": 0.004220624516321415, "phrase": "illumination_variations"}, {"score": 0.0041703614123283165, "phrase": "image_objects"}, {"score": 0.003943569631183138, "phrase": "bag-of-words\"_model"}, {"score": 0.0038810583785936505, "phrase": "fundamental_and_crucial_role"}, {"score": 0.0038348235692738783, "phrase": "efficient_and_discriminative_image_content_representations"}, {"score": 0.003611751858608048, "phrase": "image_classification_problems"}, {"score": 0.003512123587588346, "phrase": "weak_discriminative_power"}, {"score": 0.0034841647157189985, "phrase": "strong_ambiguity"}, {"score": 0.0034426417353349567, "phrase": "low-level_visual_features"}, {"score": 0.0031028232755683674, "phrase": "image_semantics"}, {"score": 0.002981216610222911, "phrase": "novel_visual_word_coding_algorithm"}, {"score": 0.002910545717767559, "phrase": "difference_maximization_technique"}, {"score": 0.0028643622911111942, "phrase": "generated_codebook_model"}, {"score": 0.0027964537059186893, "phrase": "image_feature_vector"}, {"score": 0.0026336242881032645, "phrase": "farthest_visual_words"}, {"score": 0.0025918235228843444, "phrase": "coding_process"}, {"score": 0.0025405019456703325, "phrase": "representative_variations"}, {"score": 0.0025202582748972122, "phrase": "different_image_features"}, {"score": 0.00240213106042981, "phrase": "discriminative_power"}, {"score": 0.002373472641477602, "phrase": "visual_word"}, {"score": 0.002199725773957207, "phrase": "semantic_content"}, {"score": 0.0021561514733516676, "phrase": "superior_classification_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Bag of words", " Visual words", " Codebook", " Difference maximization", " Image classification"], "paper_abstract": "Image classification is an important topic in computer vision, which becomes more and more challenging due to the rapid increase of the amounts and categories of images, as well as the different geometric deformations and illumination variations existing in image objects. \"Bag-of-Features\" model, also known as \"Bag-of-Words\" model, plays a fundamental and crucial role in generating efficient and discriminative image content representations by using local descriptors such as visual words, making it widely used in solving image classification problems. However, because of the weak discriminative power and strong ambiguity of the low-level visual features, the visual codebook, i.e., a set of visual words, generated in this model is usually over-completed and inconsistent for capturing image semantics. To address this issue, we propose a novel visual word coding algorithm in this paper based on difference maximization technique to improve the generated codebook model. Instead of mapping an image feature vector to one or multiple nearest visual words, the proposed approach utilizes a group of the nearest and the farthest visual words together in the coding process. Consequently, the representative variations of different image features are well kept and strengthened, which can then improve the discriminative power of the visual word descriptor significantly. We examine the performance of our visual word coding model extensively on four standard real-world image datasets, demonstrating that it captures image semantic content more accurately and achieves superior classification performance. (c) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Visual word coding based on difference maximization", "paper_id": "WOS:000324847100030"}