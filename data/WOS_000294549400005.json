{"auto_keywords": [{"score": 0.027286797735952908, "phrase": "spectral_transforms"}, {"score": 0.00481495049065317, "phrase": "label_propagation"}, {"score": 0.004680473391946691, "phrase": "available_information"}, {"score": 0.004592905436175987, "phrase": "graph_structures"}, {"score": 0.004485735417293941, "phrase": "common_problem"}, {"score": 0.0044435677598780796, "phrase": "biological_networks"}, {"score": 0.004401794742140806, "phrase": "social_networks"}, {"score": 0.004360412703519539, "phrase": "web_communities"}, {"score": 0.0043194180167921165, "phrase": "document_citations"}, {"score": 0.004159241394996858, "phrase": "nodes'_labels"}, {"score": 0.004100712177044264, "phrase": "similarity_graph"}, {"score": 0.003967314311312148, "phrase": "conventional_machine_learning_methods"}, {"score": 0.003820144626025562, "phrase": "euclidean_spaces"}, {"score": 0.0037309384824565695, "phrase": "kernel_representation"}, {"score": 0.0031920445513574907, "phrase": "different_learning_objectives"}, {"score": 0.0031174595932694036, "phrase": "large_scale_applications"}, {"score": 0.0029454679553901613, "phrase": "feature_space"}, {"score": 0.0029039692582303904, "phrase": "discriminative_purpose"}, {"score": 0.002822712709335093, "phrase": "label_information"}, {"score": 0.002782938683493689, "phrase": "embedding_process"}, {"score": 0.0027307746993761035, "phrase": "space_representation"}, {"score": 0.0026293540353514075, "phrase": "embedding_objective_functions"}, {"score": 0.00247249708860822, "phrase": "multiple_kernel_learning_problems"}, {"score": 0.002358220053411644, "phrase": "discriminative_tasks"}, {"score": 0.0022706045233150795, "phrase": "massive_data_sets"}, {"score": 0.002196609505859369, "phrase": "discriminative_embedding"}, {"score": 0.002125020720324262, "phrase": "biological_network_problems"}], "paper_keywords": ["Graph embedding", " label propagation", " multiple kernel learning"], "paper_abstract": "In many applications, the available information is encoded in graph structures. This is a common problem in biological networks, social networks, web communities and document citations. We investigate the problem of classifying nodes' labels on a similarity graph given only a graph structure on the nodes. Conventional machine learning methods usually require data to reside in some Euclidean spaces or to have a kernel representation. Applying these methods to nodes on graphs would require embedding the graphs into these spaces. By embedding and then learning the nodes on graphs, most methods are either flexible with different learning objectives or efficient enough for large scale applications. We propose a method to embed a graph into a feature space for a discriminative purpose. Our idea is to include label information into the embedding process, making the space representation tailored to the task. We design embedding objective functions that the following learning formulations become spectral transforms. We then reformulate these spectral transforms into multiple kernel learning problems. Our method, while being tailored to the discriminative tasks, is efficient and can scale to massive data sets. We show the need of discriminative embedding on some simulations. Applying to biological network problems, our method is shown to outperform baselines.", "paper_title": "Discriminative Graph Embedding for Label Propagation", "paper_id": "WOS:000294549400005"}