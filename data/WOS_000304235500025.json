{"auto_keywords": [{"score": 0.042853440575760134, "phrase": "local_self-similarities"}, {"score": 0.039976303937712954, "phrase": "lss"}, {"score": 0.015719103545831094, "phrase": "interest_regions"}, {"score": 0.01201859828416345, "phrase": "flss"}, {"score": 0.004707479285061122, "phrase": "distinctive_invariant_features"}, {"score": 0.004339979174946844, "phrase": "measuring_similarity"}, {"score": 0.004300951511110487, "phrase": "visual_entities"}, {"score": 0.004129607015893271, "phrase": "internal_layout"}, {"score": 0.0040373708328770306, "phrase": "main_contributions"}, {"score": 0.00357362651129581, "phrase": "cartesian_location_grid"}, {"score": 0.0034467039994594065, "phrase": "modified_versions"}, {"score": 0.003400274964240732, "phrase": "well-known_local_self-similarities"}, {"score": 0.00326469463991041, "phrase": "log-polar_location_grid"}, {"score": 0.003148726949372571, "phrase": "sift"}, {"score": 0.00298238929037041, "phrase": "local_features"}, {"score": 0.002942196368747418, "phrase": "sift_algorithm"}, {"score": 0.0028376361457661415, "phrase": "maximal_correlation_value"}, {"score": 0.0027616550517346066, "phrase": "photometric_translations_invariance"}, {"score": 0.002724428781940696, "phrase": "proposed_lss"}, {"score": 0.002627587221594597, "phrase": "distribution-based_representation"}, {"score": 0.002522738549524317, "phrase": "image_matching"}, {"score": 0.0025000115574335693, "phrase": "object_category_classification_experiments"}, {"score": 0.002367875199095903, "phrase": "original_lss"}, {"score": 0.0022940375532231145, "phrase": "favorably_comparable_performance"}, {"score": 0.002263101331353505, "phrase": "sift."}, {"score": 0.002202469129781332, "phrase": "low_computational_complexity"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Local Self-Similarity", " Fast Local Self-Similarity", " SIFT", " Region description", " Image matching", " Object classification"], "paper_abstract": "Two novel methods for extracting distinctive invariant features from interest regions are presented in this paper. The idea of these methods are associated with that measuring similarity between visual entities from images can be based on matching the internal layout of Local Self-Similarities. The main contributions are two-folds: firstly, two new texture features called Local Self-Similarities (LSS,C) and Fast Local Self-Similarities (FLSS,C) based on Cartesian location grid, are extracted, which are the modified versions of the well-known Local Self-Similarities (LSS,LP) feature based on Log-Polar location grid. To combine the powers of the SIFT and LSS (LP), LSS and FLSS are used as the local features in the SIFT algorithm. Secondly, different from the natural LSS (LP) descriptor that chooses the maximal correlation value in each bucket to get photometric translations invariance, the proposed LSS (C) and FLSS (C) adopt distribution-based representation to achieve more robust geometric translations invariance. In the contexts of image matching and object category classification experiments, the LSS (C) and FLSS (C) both outperform the original LSS (LP), and achieve favorably comparable performance to the SIFT. Furthermore, these descriptors are low computational complexity and simpler than the SIFT. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Fast Local Self-Similarity for describing interest regions", "paper_id": "WOS:000304235500025"}