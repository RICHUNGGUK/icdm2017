{"auto_keywords": [{"score": 0.03283075453743216, "phrase": "animated_talker"}, {"score": 0.0324337131484804, "phrase": "real_talker"}, {"score": 0.00481495049065317, "phrase": "adverse_conditions"}, {"score": 0.004541712637353326, "phrase": "diverse_conditions"}, {"score": 0.004319830179921363, "phrase": "face_animation"}, {"score": 0.0036400696415545813, "phrase": "similar_shape"}, {"score": 0.0035648266669315943, "phrase": "original_talker"}, {"score": 0.003505749731180509, "phrase": "error_minimization_procedure"}, {"score": 0.0034476484413811987, "phrase": "animated_version"}, {"score": 0.003306559295382181, "phrase": "original_performance"}, {"score": 0.003197843245296877, "phrase": "perceptual_intelligibility_study"}, {"score": 0.0031712256091350316, "phrase": "degraded_audio"}, {"score": 0.002953711377604328, "phrase": "audio-visual_word_recognition_rate"}, {"score": 0.0028446460307503343, "phrase": "visual_intelligibility"}, {"score": 0.0027054473441439422, "phrase": "lombard_and_whisper_conditions"}, {"score": 0.0026164433143193015, "phrase": "normal_speech_audio"}, {"score": 0.0025730425700096365, "phrase": "animated_lombard_speech"}, {"score": 0.0024883835349005863, "phrase": "congruent_normal_speech_condition"}, {"score": 0.002426717832834137, "phrase": "significant_increase"}, {"score": 0.002327310963701377, "phrase": "separate_evaluation"}, {"score": 0.0022886952510350416, "phrase": "subjective_opinions"}, {"score": 0.0022601535748259785, "phrase": "different_animations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Lombard effect", " Motion capture", " Speech-reading", " Lip-reading", " Facial animation", " Audio-visual intelligibility"], "paper_abstract": "In this paper we study the production and perception of speech in diverse conditions for the purposes of accurate, flexible and highly intelligible talking face animation. We recorded audio, video and facial motion capture data of a talker uttering a,set of 180 short sentences, under three conditions: normal speech (in quiet), Lombard speech (in noise), and whispering. We then produced an animated 3D avatar with similar shape and appearance as the original talker and used an error minimization procedure to drive the animated version of the talker in a way that matched the original performance as closely as possible. In a perceptual intelligibility study with degraded audio we then compared the animated talker against the real talker and the audio alone, in terms of audio-visual word recognition rate across the three different production conditions. We found that the visual intelligibility of the animated talker was on par with the real talker for the Lombard and whisper conditions. In addition we created two incongruent conditions where normal speech audio was paired with animated Lombard speech or whispering. When compared to the congruent normal speech condition, Lombard animation yields a significant increase in intelligibility, despite the AV-incongruence. In a separate evaluation, we gathered subjective opinions on the different animations, and found that some degree of incongruence was generally accepted. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Animated Lombard speech: Motion capture, facial animation and visual intelligibility of speech produced in adverse conditions", "paper_id": "WOS:000329415400017"}