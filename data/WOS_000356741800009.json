{"auto_keywords": [{"score": 0.04553575671949213, "phrase": "mapreduce"}, {"score": 0.00481495049065317, "phrase": "big_geospatial_data"}, {"score": 0.004653220443592979, "phrase": "software_architecture"}, {"score": 0.004567294967643222, "phrase": "large_geospatial_data_sets"}, {"score": 0.004400153852462583, "phrase": "multiple_algorithm_design_paradigms"}, {"score": 0.004160792819919432, "phrase": "web-based_user_interface"}, {"score": 0.00398362591640497, "phrase": "high-level_processing_workflows"}, {"score": 0.003946650265907885, "phrase": "domain-specific_language"}, {"score": 0.0035951877427580006, "phrase": "declarative_and_procedural_knowledge"}, {"score": 0.003517773841528639, "phrase": "processing_chain"}, {"score": 0.003305624430427938, "phrase": "job_manager"}, {"score": 0.0032445022888094636, "phrase": "processing_services"}, {"score": 0.003086961663712383, "phrase": "distributed_file_system"}, {"score": 0.0029830992938695007, "phrase": "previous_work"}, {"score": 0.0029645930408561086, "phrase": "cloud_infrastructures"}, {"score": 0.00288272132056405, "phrase": "big_heterogeneous_geospatial_data"}, {"score": 0.002633941112839883, "phrase": "dsl-based_workflows"}, {"score": 0.002444333100610621, "phrase": "large_data_sets"}, {"score": 0.0023767948946074547, "phrase": "processing_power"}, {"score": 0.002362041061180632, "phrase": "distributed_computing_environments"}, {"score": 0.002347378595930709, "phrase": "large-volume_geospatial_data_sets"}, {"score": 0.0022683432490549064, "phrase": "iqmulus_research_project"}, {"score": 0.0021987994275190314, "phrase": "evaluation_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Cloud computing", " Big Data", " Geoprocessing", " Distributed systems", " Software architectures", " Domain-specific languages"], "paper_abstract": "In this paper we propose a software architecture that allows for processing of large geospatial data sets in the cloud. Our system is modular and flexible and supports multiple algorithm design paradigms such as MapReduce, in-memory computing or agent-based programming. It contains a web-based user interface where domain experts (e.g. GIS analysts or urban planners) can define high-level processing workflows using a domain-specific language (DSL). The workflows are passed through a number of components including a parser, interpreter, and a service called job manager. These components use declarative and procedural knowledge encoded in rules to generate a processing chain specifying the execution of the workflows on a given cloud infrastructure according to the constraints defined by the user. The job manager evaluates this chain, spawns processing services in the cloud and monitors them. The services communicate with each other through a distributed file system that is scalable and fault-tolerant. Compared to previous work describing cloud infrastructures and architectures we focus on the processing of big heterogeneous geospatial data. In addition to that, we do not rely on only one specific programming model or a certain cloud infrastructure but support several ones. Combined with the possibility to control the processing through DSL-based workflows, this makes our architecture very flexible and configurable. We do not only see the cloud as a means to store and distribute large data sets but also as a way to harness the processing power of distributed computing environments for large-volume geospatial data sets. The proposed architecture design has been developed for the IQmulus research project funded by the European Commission. The paper concludes with the evaluation results from applying our solution to two example workflows from this project. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "A modular software architecture for processing of big geospatial data in the cloud", "paper_id": "WOS:000356741800009"}