{"auto_keywords": [{"score": 0.03667383794334986, "phrase": "actor-critic_algorithms"}, {"score": 0.00481495049065317, "phrase": "actor-critic_reinforcement_learning"}, {"score": 0.004611369021812453, "phrase": "policy-gradient-based_actor-critic_algorithms"}, {"score": 0.004392565073466714, "phrase": "reinforcement_learning_framework"}, {"score": 0.0041840994704406866, "phrase": "optimal_policies"}, {"score": 0.004139128578531134, "phrase": "low-variance_gradient_estimates"}, {"score": 0.003879234831701853, "phrase": "power_control"}, {"score": 0.0037554497046697432, "phrase": "general_surveys"}, {"score": 0.002992456421856034, "phrase": "online_setting"}, {"score": 0.002944284514509205, "phrase": "function_approximation"}, {"score": 0.0028502479839354637, "phrase": "continuous_state_and_action_spaces"}, {"score": 0.002685558057339722, "phrase": "reinforcement_learning"}, {"score": 0.002489608163017922, "phrase": "natural_gradient"}, {"score": 0.0021627595586364724, "phrase": "application_areas"}, {"score": 0.0021049977753042253, "phrase": "open_issues"}], "paper_keywords": ["Actor-critic", " natural gradient", " policy gradient", " reinforcement learning (RL)"], "paper_abstract": "Policy-gradient-based actor-critic algorithms are amongst the most popular algorithms in the reinforcement learning framework. Their advantage of being able to search for optimal policies using low-variance gradient estimates has made them useful in several real-life applications, such as robotics, power control, and finance. Although general surveys on reinforcement learning techniques already exist, no survey is specifically dedicated to actor-critic algorithms in particular. This paper, therefore, describes the state of the art of actor-critic algorithms, with a focus on methods that can work in an online setting and use function approximation in order to deal with continuous state and action spaces. After starting with a discussion on the concepts of reinforcement learning and the origins of actor-critic algorithms, this paper describes the workings of the natural gradient, which has made its way into many actor-critic algorithms over the past few years. A review of several standard and natural actor-critic algorithms is given, and the paper concludes with an overview of application areas and a discussion on open issues.", "paper_title": "A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients", "paper_id": "WOS:000312885400013"}