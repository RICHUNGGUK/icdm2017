{"auto_keywords": [{"score": 0.04968510255692421, "phrase": "edit_propagation"}, {"score": 0.03793044352294926, "phrase": "convex_combinations"}, {"score": 0.030793720179465855, "phrase": "image_colors"}, {"score": 0.029938294659738327, "phrase": "affine_combinations"}, {"score": 0.028988855203249318, "phrase": "sparse_pixel_sampling"}, {"score": 0.024365862148154532, "phrase": "proposed_model"}, {"score": 0.00481495049065317, "phrase": "appearance_edit_propagation"}, {"score": 0.004716520738331953, "phrase": "appearance-editing_method"}, {"score": 0.004677711903652145, "phrase": "sparsely_provided_edit_strokes"}, {"score": 0.004525629293824217, "phrase": "wide_variety"}, {"score": 0.004253618550301311, "phrase": "large_linear_systems"}, {"score": 0.0041666157975446564, "phrase": "computational_cost"}, {"score": 0.004132312946154097, "phrase": "interpolation-based_approaches"}, {"score": 0.0039323225960857956, "phrase": "interpolation-based_edit-propagation_method"}, {"score": 0.003473529187092258, "phrase": "clustering_algorithm"}, {"score": 0.0033053159828082095, "phrase": "feature_space"}, {"score": 0.0031582637043009562, "phrase": "exact_reconstruction"}, {"score": 0.0030808211830129304, "phrase": "convex_hull"}, {"score": 0.0029437270961011077, "phrase": "novel_approximation_model"}, {"score": 0.0026107601878587816, "phrase": "weight_coefficients"}, {"score": 0.002494531100339247, "phrase": "candidate_pixels"}, {"score": 0.002473959963690124, "phrase": "unnecessary_pixels"}, {"score": 0.0024333239726872604, "phrase": "compressive_sensing"}, {"score": 0.00240328454980006, "phrase": "new_candidate_pixels"}, {"score": 0.0022679195103377124, "phrase": "better_approximation"}], "paper_keywords": ["Image and video editing", " Interactive editing", " Edit propagation", " Compressive sensing"], "paper_abstract": "Edit propagation is an appearance-editing method using sparsely provided edit strokes from users. Although edit propagation has a wide variety of applications, it is computationally complex, owing to the need to solve large linear systems. To reduce the computational cost, interpolation-based approaches have been studied intensely. This study is inspired by an interpolation-based edit-propagation method that uses a clustering algorithm to determine samples. The method uses an interpolant, which approximates edit parameters with convex combinations of the samples. However, because the clustering algorithm generates samples that lie inside the set of pixels in a feature space, an interpolant with convex combinations does not allow for an exact reconstruction of the pixels outside the convex hull. To address this issue, this paper proposes a novel approximation model for interpolating image colors as well as edit parameters using affine combinations. In addition, this paper introduces sparse pixel sampling to determine the quantity and positions of samples and the weight coefficients of the affine combinations simultaneously. Sparse pixel sampling is performed by updating candidate pixels. Unnecessary pixels are discarded with compressive sensing, and new candidate pixels are greedily resampled following their approximation errors. This paper demonstrates that the proposed model achieves better approximation in terms of both image colors and edit parameters, and discusses the properties of the proposed model with various experiments.", "paper_title": "Sparse pixel sampling for appearance edit propagation", "paper_id": "WOS:000357487500034"}