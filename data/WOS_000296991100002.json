{"auto_keywords": [{"score": 0.043322976460317734, "phrase": "sparse_representation"}, {"score": 0.03519288113111451, "phrase": "image_fusion"}, {"score": 0.02591269594445234, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "simultaneous_orthogonal_matching_pursuit"}, {"score": 0.00475924837336259, "phrase": "pixel-level_image_fusion"}, {"score": 0.004622783000449884, "phrase": "multiple_images"}, {"score": 0.004464156619275582, "phrase": "informative_image"}, {"score": 0.004310949776826717, "phrase": "human_visual_perception"}, {"score": 0.004067152645111547, "phrase": "new_signal_representation_theory"}, {"score": 0.003927516959113487, "phrase": "natural_signals"}, {"score": 0.0038148090091532933, "phrase": "traditional_multiscale_transform_coefficients"}, {"score": 0.0037487368769596814, "phrase": "sparse_representation_coefficients"}, {"score": 0.003619993477999133, "phrase": "image_information"}, {"score": 0.0034551632687788857, "phrase": "novel_image_fusion_scheme"}, {"score": 0.0033952989364738353, "phrase": "signal_sparse_representation_theory"}, {"score": 0.0032786537599187125, "phrase": "local_information"}, {"score": 0.0032406665327678616, "phrase": "source_images"}, {"score": 0.003111133215976132, "phrase": "overlapping_patches"}, {"score": 0.003039445153076014, "phrase": "whole_image"}, {"score": 0.0029694040368299624, "phrase": "small_size"}, {"score": 0.00280126189041041, "phrase": "simultaneous_orthogonal_matching_pursuit_technique"}, {"score": 0.0027049694095434905, "phrase": "different_source_images"}, {"score": 0.0025816953009851072, "phrase": "dictionary_bases"}, {"score": 0.0022841153001549193, "phrase": "popular_image_fusion_methods"}, {"score": 0.002244494905883452, "phrase": "experimental_results"}, {"score": 0.002154693685426657, "phrase": "superior_fused_image"}], "paper_keywords": ["Multi-sensor fusion", " Image fusion", " Simultaneous orthogonal matching pursuit", " Sparse representation", " Multiscale transform"], "paper_abstract": "Pixel-level image fusion integrates the information from multiple images of one scene to get an informative image which is more suitable for human visual perception or further image-processing. Sparse representation is a new signal representation theory which explores the sparseness of natural signals. Comparing to the traditional multiscale transform coefficients, the sparse representation coefficients can more accurately represent the image information. Thus, this paper proposes a novel image fusion scheme using the signal sparse representation theory. Because image fusion depends on local information of source images, we conduct the sparse representation on overlapping patches instead of the whole image, where a small size of dictionary is needed. In addition, the simultaneous orthogonal matching pursuit technique is introduced to guarantee that different source images are sparsely decomposed into the same subset of dictionary bases, which is the key to image fusion. The proposed method is tested on several categories of images and compared with some popular image fusion methods. The experimental results show that the proposed method can provide superior fused image in terms of several quantitative fusion evaluation indexes. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Pixel-level image fusion with simultaneous orthogonal matching pursuit", "paper_id": "WOS:000296991100002"}