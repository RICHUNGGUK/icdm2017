{"auto_keywords": [{"score": 0.03455018268948868, "phrase": "elpso"}, {"score": 0.015719716506582538, "phrase": "particle_swarm_optimization"}, {"score": 0.011472359439069825, "phrase": "convergence_speed"}, {"score": 0.004774324145784758, "phrase": "continuous_optimization"}, {"score": 0.004615202066192795, "phrase": "heuristic_optimization_technique"}, {"score": 0.004556901872357751, "phrase": "swarm_intelligence"}, {"score": 0.004404994123834589, "phrase": "bird_flocking"}, {"score": 0.004349337717774093, "phrase": "canonical_pso"}, {"score": 0.004258128672571261, "phrase": "premature_convergence"}, {"score": 0.004012751049253625, "phrase": "searching_process"}, {"score": 0.0038953958723049287, "phrase": "rapid_convergence"}, {"score": 0.003533347967582184, "phrase": "swarm_diversity"}, {"score": 0.0034299649219748513, "phrase": "social_phenomenon"}, {"score": 0.003400984514637656, "phrase": "multiple_good_examples"}, {"score": 0.0031912706211861324, "phrase": "multiple_global_best_particles"}, {"score": 0.0028944757265206332, "phrase": "best_particles"}, {"score": 0.002833689453299307, "phrase": "better_particles"}, {"score": 0.0027978304423349246, "phrase": "first-in-first-out_order"}, {"score": 0.0025919830205975215, "phrase": "high_quality"}, {"score": 0.0025375331660958665, "phrase": "target_optimization_function"}, {"score": 0.0024947959375982614, "phrase": "better_diversity"}, {"score": 0.0024527767211457046, "phrase": "single-gbest_and_non-gbest_pso_algorithms"}, {"score": 0.002391067964886602, "phrase": "mathematical_and_numerical_results"}, {"score": 0.0023507916951658455, "phrase": "computational_experiments"}, {"score": 0.0023309080951251335, "phrase": "benchmark_problems"}, {"score": 0.0022530375696567136, "phrase": "tested_pso_algorithms"}, {"score": 0.002205692205167157, "phrase": "solution_quality"}, {"score": 0.0021870332034407817, "phrase": "convergence_time"}, {"score": 0.002168531704054597, "phrase": "crown_copyright"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Swarm intelligence", " Particle swarm optimization", " Example-based learning", " Continuous optimization"], "paper_abstract": "Particle swarm optimization (PSO) is a heuristic optimization technique based on swarm intelligence that is inspired by the behavior of bird flocking. The canonical PSO has the disadvantage of premature convergence. Several improved PSO versions do well in keeping the diversity of the particles during the searching process, but at the expense of rapid convergence. This paper proposes an example-based learning PSO (ELPSO) to overcome these shortcomings by keeping a balance between swarm diversity and convergence speed. Inspired by a social phenomenon that multiple good examples can guide a crowd towards making progress, ELPSO uses an example set of multiple global best particles to update the positions of the particles. In this study, the particles of the example set were selected from the best particles and updated by the better particles in the first-in-first-out order in each iteration. The particles in the example set are different, and are usually of high quality in terms of the target optimization function. ELPSO has better diversity and convergence speed than single-gbest and non-gbest PSO algorithms, which is proved by mathematical and numerical results. Finally, computational experiments on benchmark problems show that ELPSO outperforms all of the tested PSO algorithms in terms of both solution quality and convergence time. Crown Copyright (C) 2010 Published by Elsevier Inc. All rights reserved.", "paper_title": "Example-based learning particle swarm optimization for continuous optimization", "paper_id": "WOS:000297403300010"}