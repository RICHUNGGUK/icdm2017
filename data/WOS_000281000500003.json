{"auto_keywords": [{"score": 0.03597562753410283, "phrase": "dominant_subspaces"}, {"score": 0.00481495049065317, "phrase": "adaptive_subspace_symbolization_for_content-based_video_detection"}, {"score": 0.004678940805063634, "phrase": "similar_videos"}, {"score": 0.004612376827433774, "phrase": "important_and_nontrivial_problem"}, {"score": 0.004568525347438891, "phrase": "content-based_video_retrieval"}, {"score": 0.004439445472040688, "phrase": "subspace_symbolization_approach"}, {"score": 0.004376273644295806, "phrase": "suds"}, {"score": 0.004313996835376177, "phrase": "content-based_retrieval"}, {"score": 0.004054169947971483, "phrase": "data_distribution"}, {"score": 0.003939565240409143, "phrase": "visual_dictionary"}, {"score": 0.0037556843869894566, "phrase": "string_matching_techniques"}, {"score": 0.0037199473428123175, "phrase": "two-step_data_simplification"}, {"score": 0.003580355398511932, "phrase": "adaptive_approach"}, {"score": 0.003529366898009729, "phrase": "vlp"}, {"score": 0.0033806943112103397, "phrase": "variable_lengths"}, {"score": 0.003332537728389913, "phrase": "whole_visual_feature_space"}, {"score": 0.003253791343615811, "phrase": "dimension_consecutiveness"}, {"score": 0.0032074366230426727, "phrase": "stable_visual_dictionary"}, {"score": 0.00305762327908599, "phrase": "dominant_subspace"}, {"score": 0.0030140547908298404, "phrase": "compact_video_representation_model"}, {"score": 0.002549269480908849, "phrase": "innovative_similarity_measure"}, {"score": 0.002524985183240859, "phrase": "cve"}, {"score": 0.0024652715040303416, "phrase": "complementary_information_compensation_scheme"}, {"score": 0.0024185182010749273, "phrase": "visual_features"}, {"score": 0.0023954743066925714, "phrase": "sequence_context"}, {"score": 0.002316532084420729, "phrase": "efficient_two-layered_index_strategy"}, {"score": 0.0022617389804167943, "phrase": "query_optimizations"}, {"score": 0.00220823903315848, "phrase": "video_retrieval"}, {"score": 0.002176747110119268, "phrase": "experimental_results"}, {"score": 0.002145703330831668, "phrase": "high_effectiveness"}, {"score": 0.0021049977753042253, "phrase": "suds."}], "paper_keywords": ["Video detection", " subspace symbolization", " variable length partition", " query optimization"], "paper_abstract": "Efficiently and effectively identifying similar videos is an important and nontrivial problem in content-based video retrieval. This paper proposes a subspace symbolization approach, namely SUDS, for content-based retrieval on very large video databases. The novelty of SUDS is that it explores the data distribution in subspaces to build a visual dictionary with which the videos are processed by deriving the string matching techniques with two-step data simplification. Specifically, we first propose an adaptive approach, called VLP, to extract a series of dominant subspaces of variable lengths from the whole visual feature space without the constraint of dimension consecutiveness. A stable visual dictionary is built by clustering the video keyframes over each dominant subspace. A compact video representation model is developed by transforming each keyframe into a word that is a series of symbols in the dominant subspaces, and further each video into a series of words. Then, we present an innovative similarity measure called CVE, which adopts a complementary information compensation scheme based on the visual features and sequence context of videos. Finally, an efficient two-layered index strategy with a number of query optimizations is proposed to facilitate video retrieval. The experimental results demonstrate the high effectiveness and efficiency of SUDS.", "paper_title": "Adaptive Subspace Symbolization for Content-Based Video Detection", "paper_id": "WOS:000281000500003"}