{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "dynamic-bayesian_network"}, {"score": 0.004089991141220082, "phrase": "complex_tasks"}, {"score": 0.00388016972840459, "phrase": "human_actor"}, {"score": 0.0037397086147485897, "phrase": "significant_amount"}, {"score": 0.003492155652400838, "phrase": "unified_terminology"}, {"score": 0.0034555479218891638, "phrase": "evaluation_procedure"}, {"score": 0.0032954888655173666, "phrase": "theoretical_framework"}, {"score": 0.0032437952431945724, "phrase": "dynamic-bayesian_networks"}, {"score": 0.0031428202743657057, "phrase": "quantitative_modeling"}, {"score": 0.0030772505522663612, "phrase": "lfo_tasks"}, {"score": 0.002769304577201566, "phrase": "agent_behaviors"}, {"score": 0.0026689487424251907, "phrase": "stochastic_process"}, {"score": 0.002518525107994039, "phrase": "state-to-action_map"}, {"score": 0.0024017638230939514, "phrase": "dynamic_bayesian_models"}, {"score": 0.002376559242152662, "phrase": "hidden_states"}, {"score": 0.002326938965568362, "phrase": "learning_and_model_evaluation_tasks"}, {"score": 0.002207363758847308, "phrase": "stochastic_similarity_measures"}, {"score": 0.002172701452347454, "phrase": "crossed_entropy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Learning from observation", " Dynamic Bayesian Networks"], "paper_abstract": "Learning from observation (LfO), also known as learning from demonstration, studies how computers can learn to perform complex tasks by observing and thereafter imitating the performance of a human actor. Although there has been a significant amount of research in this area, there is no agreement on a unified terminology or evaluation procedure. In this paper, we present a theoretical framework based on Dynamic-Bayesian Networks (DBNs) for the quantitative modeling and evaluation of LfO tasks. Additionally, we provide evidence showing that: (1) the information captured through the observation of agent behaviors occurs as the realization of a stochastic process (and often not just as a sample of a state-to-action map); (2) learning can be simplified by introducing dynamic Bayesian models with hidden states for which the learning and model evaluation tasks can be reduced to minimization and estimation of some stochastic similarity measures such as crossed entropy. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "A Dynamic-Bayesian Network framework for modeling and evaluating learning from observation", "paper_id": "WOS:000336191800019"}