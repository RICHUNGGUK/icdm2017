{"auto_keywords": [{"score": 0.004297795905522757, "phrase": "gaussian_kernel_function"}, {"score": 0.0035681790580031998, "phrase": "class_separability_criterion_ill_feature_space"}, {"score": 0.003459191419478298, "phrase": "between-class_separation"}, {"score": 0.003353521531649663, "phrase": "within-class_data_distribution"}, {"score": 0.0026986685585382347, "phrase": "kernel_parameters"}, {"score": 0.002643386043540555, "phrase": "support_vector_machine"}, {"score": 0.0023834640793589435, "phrase": "feature_space"}, {"score": 0.0023346234464901978, "phrase": "experimental_results"}, {"score": 0.00226322835801988, "phrase": "real-world_data"}, {"score": 0.0021714122348552747, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "corresponding_hyperparameters"}], "paper_keywords": ["kernel parameter", " data classification", " class separability", " support vector machine"], "paper_abstract": "With a Gaussian kernel function, we find that the distance between two classes, (DBTC) can be used as a class separability criterion ill feature space since the between-class separation and the within-class data distribution are taken into account impliedly. To test the validity of DBTC, we develop a method Of tuning the kernel parameters in support vector machine (SVM) algorithm by maximizing the DBTC in feature space. Experimental results on the real-world data show that the proposed method consistently outperforms corresponding hyperparameters tuning methods.", "paper_title": "Distance between Two Classes: A Novel Kernel Class Separability Criterion", "paper_id": "WOS:000268506200008"}