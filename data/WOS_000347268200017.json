{"auto_keywords": [{"score": 0.04878455414226702, "phrase": "steerable_filters"}, {"score": 0.010578567276832979, "phrase": "eigenspace_filters"}, {"score": 0.004721602309430702, "phrase": "oblique_hough_forests"}, {"score": 0.004558091785667046, "phrase": "novel_framework"}, {"score": 0.004348813532606792, "phrase": "multivariate_hough_voting"}, {"score": 0.0043148760739240575, "phrase": "oblique_random_forests"}, {"score": 0.004181743040532619, "phrase": "noisy_annotations"}, {"score": 0.004052701031142039, "phrase": "efficient_computation"}, {"score": 0.003958529104387973, "phrase": "different_scales"}, {"score": 0.0037915057447460133, "phrase": "centerline_accuracy"}, {"score": 0.003717925116469845, "phrase": "synthetic_vascular_data"}, {"score": 0.0036457672198249333, "phrase": "rat_visual_cortex"}, {"score": 0.0034107088717109857, "phrase": "orthogonal_subspace"}, {"score": 0.0031907572162427978, "phrase": "local_image_patches"}, {"score": 0.0030321497870310077, "phrase": "overall_approach"}, {"score": 0.0028701222153940283, "phrase": "optimally_oriented_flux"}, {"score": 0.002847691227421257, "phrase": "oof"}, {"score": 0.0027706329821710804, "phrase": "hessian"}, {"score": 0.0026639507068734907, "phrase": "homotopic_skeletonization"}, {"score": 0.0026431267487109543, "phrase": "geodesic_path_tracing"}, {"score": 0.002462867872567125, "phrase": "oblique_split_directions"}, {"score": 0.0024436119167523156, "phrase": "univariate_orthogonal_splits"}, {"score": 0.0023773911659018825, "phrase": "learning-based_approach"}, {"score": 0.002358801930248239, "phrase": "different_state-of-the-art_methods"}, {"score": 0.002259123228671651, "phrase": "vessel_segmentation"}, {"score": 0.0022414566728770745, "phrase": "centerline_extraction"}, {"score": 0.002197891020396052, "phrase": "high_level"}, {"score": 0.002180702259644951, "phrase": "label_noise"}, {"score": 0.0021551702945512494, "phrase": "training_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Vessel segmentation", " Centerline extraction", " Steerable filters", " Oblique random forest", " Multivariate Hough voting"], "paper_abstract": "Contributions: We propose a novel framework for joint 3-D vessel segmentation and centerline extraction. The approach is based on multivariate Hough voting and oblique random forests (RFs) that we learn from noisy annotations. It relies on steerable filters for the efficient computation of local image features at different scales and orientations. Experiments: We validate both the segmentation performance and the centerline accuracy of our approach both on synthetic vascular data and four 3-D imaging datasets of the rat visual cortex at 700 nm resolution. First, we evaluate the most important structural components of our approach: (1) Orthogonal subspace filtering in comparison to steerable filters that show, qualitatively, similarities to the eigenspace filters learned from local image patches. (2) Standard RF against oblique RF. Second, we compare the overall approach to different state-of-the-art methods for (I) vessel segmentation based on optimally oriented flux (OOF) and the eigenstructure of the Hessian, and (2) centerline extraction based on homotopic skeletonization and geodesic path tracing. Results: Our experiments reveal the benefit of steerable over eigenspace filters as well as the advantage of oblique split directions over univariate orthogonal splits. We further show that the learning-based approach outperforms different state-of-the-art methods and proves highly accurate and robust with regard to both vessel segmentation and centerline extraction in spite of the high level of label noise in the training data. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Joint 3-D vessel segmentation and centerline extraction using oblique Hough forests with steerable filters", "paper_id": "WOS:000347268200017"}