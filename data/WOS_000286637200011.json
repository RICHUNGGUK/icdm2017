{"auto_keywords": [{"score": 0.049226991195811136, "phrase": "pac-bayesian_generalization_bounds"}, {"score": 0.04364011428330573, "phrase": "data_matrices"}, {"score": 0.03843856552198327, "phrase": "regularization_terms"}, {"score": 0.03544401896528498, "phrase": "mutual_information"}, {"score": 0.02907873267247575, "phrase": "tree-shaped_graphical_models"}, {"score": 0.00481495049065317, "phrase": "pac-bayesian_analysis_of_co-clustering"}, {"score": 0.004701015188740582, "phrase": "supervised_and_unsupervised_learning_models"}, {"score": 0.004233284262727897, "phrase": "widely_used_approach"}, {"score": 0.00408383113155665, "phrase": "matrix_data_analysis"}, {"score": 0.004011086974442549, "phrase": "missing_entries"}, {"score": 0.003927848423072668, "phrase": "joint_probability_distribution"}, {"score": 0.0038810583785936505, "phrase": "column_variables"}, {"score": 0.003857871979942733, "phrase": "co-occurrence_matrices"}, {"score": 0.0037778009042360758, "phrase": "expected_out-of-sample_performance"}, {"score": 0.003755229065596736, "phrase": "co-clustering-based_solutions"}, {"score": 0.0035901685646972585, "phrase": "previous_formulations"}, {"score": 0.0034946232062615813, "phrase": "expected_performance"}, {"score": 0.003321008590273796, "phrase": "cluster_variables"}, {"score": 0.0032814236411444022, "phrase": "column_ids"}, {"score": 0.0032326031622964477, "phrase": "iterative_projection_algorithm"}, {"score": 0.0031940685896742356, "phrase": "local_optimum"}, {"score": 0.0031465436619697385, "phrase": "discriminative_prediction_tasks"}, {"score": 0.0030171910207671205, "phrase": "movielens_collaborative_filtering_task"}, {"score": 0.002945669860541221, "phrase": "matrix_tri-factorization"}, {"score": 0.0029018301277718415, "phrase": "generalization_bounds"}, {"score": 0.0028586409810976367, "phrase": "new_algorithms"}, {"score": 0.002816092821027267, "phrase": "matrix_factorization"}, {"score": 0.0026760974046034854, "phrase": "high_dimensional_tensors"}, {"score": 0.002612640527241776, "phrase": "generalization_abilities"}, {"score": 0.002467880918630221, "phrase": "tree_levels"}, {"score": 0.0024311346712789553, "phrase": "weighted_graph_clustering"}, {"score": 0.0024093494406195386, "phrase": "prediction_problem"}, {"score": 0.002366361492754389, "phrase": "edge_weights"}, {"score": 0.0022895278869126848, "phrase": "remaining_edge_weights"}, {"score": 0.0021496900363962602, "phrase": "empirical_data_fit"}, {"score": 0.0021049977753042253, "phrase": "graph_nodes"}], "paper_keywords": ["matrix tri-factorization", " graphical models", " graph clustering", " pairwise clustering", " combinatorial priors", " density estimation"], "paper_abstract": "We derive PAC-Bayesian generalization bounds for supervised and unsupervised learning models based on clustering, such as co-clustering, matrix tri-factorization, graphical models, graph clustering, and pairwise clustering.(1) We begin with the analysis of co-clustering, which is a widely used approach to the analysis of data matrices. We distinguish among two tasks in matrix data analysis: discriminative prediction of the missing entries in data matrices and estimation of the joint probability distribution of row and column variables in co-occurrence matrices. We derive PAC-Bayesian generalization bounds for the expected out-of-sample performance of co-clustering-based solutions for these two tasks. The analysis yields regularization terms that were absent in the previous formulations of co-clustering. The bounds suggest that the expected performance of co-clustering is governed by a trade-off between its empirical performance and the mutual information preserved by the cluster variables on row and column IDs. We derive an iterative projection algorithm for finding a local optimum of this trade-off for discriminative prediction tasks. This algorithm achieved state-of-the-art performance in the MovieLens collaborative filtering task. Our co-clustering model can also be seen as matrix tri-factorization and the results provide generalization bounds, regularization terms, and new algorithms for this form of matrix factorization. The analysis of co-clustering is extended to tree-shaped graphical models, which can be used to analyze high dimensional tensors. According to the bounds, the generalization abilities of tree-shaped graphical models depend on a trade-off between their empirical data fit and the mutual information that is propagated up the tree levels. We also formulate weighted graph clustering as a prediction problem: given a subset of edge weights we analyze the ability of graph clustering to predict the remaining edge weights. The analysis of co-clustering easily extends to this problem and suggests that graph clustering should optimize the trade-off between empirical data fit and the mutual information that clusters preserve on graph nodes.", "paper_title": "PAC-Bayesian Analysis of Co-clustering and Beyond", "paper_id": "WOS:000286637200011"}