{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "test_cost_constraint"}, {"score": 0.049558064870310475, "phrase": "feature_selection"}, {"score": 0.035945882758951095, "phrase": "new_problem"}, {"score": 0.028901550427837396, "phrase": "heuristic_algorithm"}, {"score": 0.004685012337701536, "phrase": "important_preprocessing_step"}, {"score": 0.0046340196745259694, "phrase": "machine_learning"}, {"score": 0.004583579470330216, "phrase": "data_mining"}, {"score": 0.004508942069742167, "phrase": "real-world_applications"}, {"score": 0.003868142906199082, "phrase": "limited_resources"}, {"score": 0.0037226570791514184, "phrase": "informative_and_cheap_feature_subset"}, {"score": 0.003524227590204673, "phrase": "test_cost_constraint_problem"}, {"score": 0.0033546701239540555, "phrase": "simple_form"}, {"score": 0.003264010423431402, "phrase": "constraint_satisfaction_problem"}, {"score": 0.0031758298380401527, "phrase": "backtracking"}, {"score": 0.0031240075437664314, "phrase": "general_algorithm"}, {"score": 0.0030900503546963764, "phrase": "csp"}, {"score": 0.0029091587159002503, "phrase": "medium-sized_data"}, {"score": 0.0028460640294160383, "phrase": "backtracking_algorithm"}, {"score": 0.0027691111795848183, "phrase": "large_datasets"}, {"score": 0.002650279521276126, "phrase": "experimental_results"}, {"score": 0.002536534348967786, "phrase": "optimal_solution"}, {"score": 0.0024276590297034064, "phrase": "existing_feature_selection_problems"}, {"score": 0.0023362245884046176, "phrase": "decision-theoretic_rough_sets"}, {"score": 0.002260603348058606, "phrase": "csp."}, {"score": 0.0022359278646792153, "phrase": "new_definitions"}, {"score": 0.002175436093794315, "phrase": "new_research_directions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Feature selection", " Cost-sensitive learning", " Constraint satisfaction problem", " Backtracking algorithm", " Heuristic algorithm", " Decision-theoretic rough sets"], "paper_abstract": "Feature selection is an important preprocessing step in machine learning and data mining. In real-world applications, costs, including money, time and other resources, are required to acquire the features. In some cases, there is a test cost constraint due to limited resources. We shall deliberately select an informative and cheap feature subset for classification. This paper proposes the feature selection with test cost constraint problem for this issue. The new problem has a simple form while described as a constraint satisfaction problem (CSP). Backtracking is a general algorithm for CSP, and it is efficient in solving the new problem on medium-sized data. As the backtracking algorithm is not scalable to large datasets, a heuristic algorithm is also developed. Experimental results show that the heuristic algorithm can find the optimal solution in most cases. We also redefine some existing feature selection problems in rough sets, especially in decision-theoretic rough sets, from the viewpoint of CSP. These new definitions provide insight to some new research directions. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Feature selection with test cost constraint", "paper_id": "WOS:000329256700007"}