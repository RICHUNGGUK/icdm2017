{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "unsupervised_training_of_multi-class_regularized_least-squares_classifiers"}, {"score": 0.004529093447865156, "phrase": "first_efficient_algorithm"}, {"score": 0.004460309246062286, "phrase": "unsupervised_training"}, {"score": 0.004392565073466714, "phrase": "multi-class_regularized_least-squares_classifiers"}, {"score": 0.0041001740903338834, "phrase": "unsupervised_extension"}, {"score": 0.004007083686875716, "phrase": "support_vector_machine"}, {"score": 0.0038862297330905836, "phrase": "maximum_margin_clustering"}, {"score": 0.003711723285313348, "phrase": "considerable_attention"}, {"score": 0.003545024951402821, "phrase": "binary_classification_case"}, {"score": 0.0034118234596993836, "phrase": "combinatorial_search_scheme"}, {"score": 0.003334309053314909, "phrase": "steepest_descent_strategies"}, {"score": 0.0032836104153151973, "phrase": "powerful_meta-heuristics"}, {"score": 0.003208999546225013, "phrase": "bad_local_optima"}, {"score": 0.0031360786664165093, "phrase": "regularized_least-squares"}, {"score": 0.00290473242917264, "phrase": "matrix_algebraic_optimization"}, {"score": 0.002860546817196148, "phrase": "constant_time_checks"}, {"score": 0.0027955219242123013, "phrase": "intermediate_candidate_solutions"}, {"score": 0.0025694584194998356, "phrase": "novel_method"}, {"score": 0.002416589459425828, "phrase": "competing_methods"}, {"score": 0.002290291401956985, "phrase": "time_complexity_analysis"}, {"score": 0.002255431275670053, "phrase": "experimental_comparisons"}, {"score": 0.0021049977753042253, "phrase": "practical_sized_problems"}], "paper_keywords": ["unsupervised learning", " multi-class regularized least-squares classification", " maximum margin clustering", " combinatorial optimization"], "paper_abstract": "In this work we present the first efficient algorithm for unsupervised training of multi-class regularized least-squares classifiers. The approach is closely related to the unsupervised extension of the support vector machine classifier known as maximum margin clustering, which recently has received considerable attention, though mostly considering the binary classification case. We present a combinatorial search scheme that combines steepest descent strategies with powerful meta-heuristics for avoiding bad local optima. The regularized least-squares based formulation of the problem allows us to use matrix algebraic optimization enabling constant time checks for the intermediate candidate solutions during the search. Our experimental evaluation indicates the potential of the novel method and demonstrates its superior clustering performance over a variety of competing methods on real world datasets. Both time complexity analysis and experimental comparisons show that the method can scale well to practical sized problems.", "paper_title": "On Unsupervised Training of Multi-Class Regularized Least-Squares Classifiers", "paper_id": "WOS:000330317300008"}