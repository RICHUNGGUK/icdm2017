{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "oja's_pca_learning_algorithm"}, {"score": 0.04928938422006422, "phrase": "non-zero-approaching_adaptive_learning_rate"}, {"score": 0.04179789452876998, "phrase": "learning_step_increases"}, {"score": 0.004430629452265786, "phrase": "oja's_principal_component_analysis"}, {"score": 0.004382229828888339, "phrase": "pca"}, {"score": 0.004333406378146173, "phrase": "learning_algorithm"}, {"score": 0.0042148594491580324, "phrase": "existing_adaptive_learning_rates"}, {"score": 0.00370981613076245, "phrase": "computational_round-off_limitations"}, {"score": 0.003588291565092195, "phrase": "proposed_adaptive_leaming_rate"}, {"score": 0.0034707339811048403, "phrase": "learning_rate"}, {"score": 0.003265090934183249, "phrase": "evolution_rate"}, {"score": 0.002857605453835429, "phrase": "rigorous_mathematical_proofs"}, {"score": 0.0028260302580927856, "phrase": "global_convergence"}, {"score": 0.002794802975530612, "phrase": "oja's_algorithm"}, {"score": 0.0027486060614330043, "phrase": "proposed_learning_rate"}, {"score": 0.002585638506308606, "phrase": "equivalent_deterministic_discrete_time"}, {"score": 0.0023656467839555458, "phrase": "simulation_results"}, {"score": 0.0023136311468961125, "phrase": "adaptive_learning_rate"}, {"score": 0.0022502133699402018, "phrase": "oja's_pca_algorithm"}, {"score": 0.0021763973978248005, "phrase": "online_leaming_situation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["principal component analysis (PCA)", " Oja's PCA learning algorithm", " global convergence", " deterministic discrete time system"], "paper_abstract": "A non-zero-approaching adaptive learning rate is proposed to guarantee the global convergence of Oja's principal component analysis (PCA) learning algorithm. Most of the existing adaptive learning rates for Oja's PCA learning algorithm are required to approach zero as the learning step increases. However, this is not practical in many applications due to the computational round-off limitations and tracking requirements, The proposed adaptive leaming rate overcomes this shortcoming. The learning rate converges to a positive constant, thus it increases the evolution rate as the learning step increases. This is different from learning rates which approach zero which slow the convergence considerably and increasingly with time. Rigorous mathematical proofs for global convergence of Oja's algorithm with the proposed learning rate are given in detail via studying the convergence of an equivalent deterministic discrete time (DDT) system. Extensive simulations are carried out to illustrate and verify the theory derived. Simulation results show that this adaptive learning rate is more suitable for Oja's PCA algorithm to be used in an online leaming situation. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Global convergence of Oja's PCA learning algorithm with a non-zero-approaching adaptive learning rate", "paper_id": "WOS:000242685300003"}