{"auto_keywords": [{"score": 0.04901721310106573, "phrase": "automatic_speech_recognition"}, {"score": 0.03406896969421786, "phrase": "word-based_model"}, {"score": 0.004815042024119956, "phrase": "lexicon"}, {"score": 0.00474348728309194, "phrase": "discriminative_learning"}, {"score": 0.004673079747693193, "phrase": "agglutinative_language"}, {"score": 0.004586571554601154, "phrase": "asr"}, {"score": 0.00453537012358554, "phrase": "agglutinative_languages"}, {"score": 0.004451360793577698, "phrase": "lexical_unit"}, {"score": 0.004352592156102578, "phrase": "morpheme_unit"}, {"score": 0.004256005669252138, "phrase": "sufficient_coverage"}, {"score": 0.0041151131903594445, "phrase": "weak_constraints"}, {"score": 0.004084440052083978, "phrase": "possible_confusion"}, {"score": 0.004008749730113699, "phrase": "discriminative_approach"}, {"score": 0.003978866233891427, "phrase": "lexicon_optimization"}, {"score": 0.003905124669323623, "phrase": "asr_error_reduction"}, {"score": 0.00366443843576107, "phrase": "evaluation_function"}, {"score": 0.0034001358540125303, "phrase": "word_error_rates"}, {"score": 0.0033370841436001597, "phrase": "asr_hypotheses"}, {"score": 0.003287482882222731, "phrase": "morpheme-based_model"}, {"score": 0.003178550413662537, "phrase": "word_or_sub-word_entries"}, {"score": 0.00286213454317036, "phrase": "support_vector_machines"}, {"score": 0.0025965187247488876, "phrase": "uyghur_large-vocabulary_continuous_speech_recognition_system"}, {"score": 0.002519854876593324, "phrase": "wer"}, {"score": 0.0024916819803100635, "phrase": "modest_lexicon_size"}, {"score": 0.002463830258460528, "phrase": "small_out-of-vocabulary_rate"}, {"score": 0.002418250700367664, "phrase": "svm"}, {"score": 0.002391067964886602, "phrase": "sub-word_lexicon_results"}, {"score": 0.0022859244876449396, "phrase": "conventional_statistical_concatenation_approaches"}, {"score": 0.002260367486652148, "phrase": "proposed_learning_approach"}, {"score": 0.002218404456227325, "phrase": "unsupervised_manner"}, {"score": 0.00216907363015155, "phrase": "correct_transcription"}, {"score": 0.002152874480615438, "phrase": "training_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Speech recognition", " Language model", " Lexicon", " Morpheme", " Discriminative learning", " Uyghur"], "paper_abstract": "For automatic speech recognition (ASR) of agglutinative languages, selection of a lexical unit is not obvious. The morpheme unit is usually adopted to ensure sufficient coverage, but many morphemes are short, resulting in weak constraints and possible confusion. We propose a discriminative approach for lexicon optimization that directly contributes to ASR error reduction by taking into account not only linguistic constraints but also acoustic phonetic confusability. It is based on an evaluation function for each word defined by a set of features and their weights, which are optimized by the difference in word error rates (WERs) between ASR hypotheses obtained by the morpheme-based model and those by the word-based model. Then, word or sub-word entries with higher evaluation scores are selected to be added to the lexicon. We investigate several discriminative models to realize this approach. Specifically, we implement it with support vector machines (SVM), logistic regression (LR) model as well as the simple perceptron algorithm. This approach was successfully applied to an Uyghur large-vocabulary continuous speech recognition system, resulting in a significant reduction of WER with a modest lexicon size and a small out-of-vocabulary rate. The use of SVM for a sub-word lexicon results in the best performance, outperforming the word-based model as well as conventional statistical concatenation approaches. The proposed learning approach is realized in an unsupervised manner because it does not require correct transcription for training data. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Lexicon optimization based on discriminative learning for automatic speech recognition of agglutinative language", "paper_id": "WOS:000335804800006"}