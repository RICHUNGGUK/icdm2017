{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "recent_years"}, {"score": 0.004720606036240263, "phrase": "great_explosion"}, {"score": 0.0046741260449047976, "phrase": "user-generated_videos"}, {"score": 0.004448471107649881, "phrase": "effective_and_efficient_video_search"}, {"score": 0.0043183186953102805, "phrase": "modern_video_search_engines"}, {"score": 0.004212759658511567, "phrase": "semantic_keywords"}, {"score": 0.004089475312474684, "phrase": "existing_video_tagging_methods"}, {"score": 0.004009288598277725, "phrase": "reliable_performance"}, {"score": 0.003911253966141701, "phrase": "training_data"}, {"score": 0.0037967593942595233, "phrase": "abundant_well-tagged_data"}, {"score": 0.003421697038352743, "phrase": "novel_video_tagging_framework"}, {"score": 0.0033545600622020464, "phrase": "cross-media_tag_transfer"}, {"score": 0.003192406091820197, "phrase": "well-tagged_images"}, {"score": 0.0031453010852936334, "phrase": "video_tagging"}, {"score": 0.003038066486989815, "phrase": "\"cross-media_tunnel"}, {"score": 0.0028203950416405563, "phrase": "optimal_kernel_space"}, {"score": 0.0027650234530228923, "phrase": "distribution_distance"}, {"score": 0.0025924443774713473, "phrase": "domain-shift_problem"}, {"score": 0.0025541693207036167, "phrase": "novel_cross-media_video_tagging_model"}, {"score": 0.002442693254693416, "phrase": "intrinsic_local_structures"}, {"score": 0.0023245146355917626, "phrase": "reliable_video_classifiers"}, {"score": 0.0022901862321082407, "phrase": "efficient_algorithm"}, {"score": 0.002223039450439376, "phrase": "proposed_model"}, {"score": 0.0021902063413831545, "phrase": "iterative_and_alternative_way"}], "paper_keywords": ["Algorithms", " Design", " Experimentation", " Video tagging", " cross media", " transfer learning", " semi-supervised learning"], "paper_abstract": "Recent years have witnessed a great explosion of user-generated videos on the Web. In order to achieve an effective and efficient video search, it is critical for modern video search engines to associate videos with semantic keywords automatically. Most of the existing video tagging methods can hardly achieve reliable performance due to deficiency of training data. It is noticed that abundant well-tagged data are available in other relevant types of media (e. g., images). In this article, we propose a novel video tagging framework, termed as Cross-Media Tag Transfer (CMTT), which utilizes the abundance of well-tagged images to facilitate video tagging. Specifically, we build a \"cross-media tunnel\" to transfer knowledge from images to videos. To this end, an optimal kernel space, in which distribution distance between images and video is minimized, is found to tackle the domain-shift problem. A novel cross-media video tagging model is proposed to infer tags by exploring the intrinsic local structures of both labeled and unlabeled data, and learn reliable video classifiers. An efficient algorithm is designed to optimize the proposed model in an iterative and alternative way. Extensive experiments illustrate the superiority of our proposal compared to the state-of-the-art algorithms.", "paper_title": "Effective Transfer Tagging from Image to Video", "paper_id": "WOS:000318944400006"}