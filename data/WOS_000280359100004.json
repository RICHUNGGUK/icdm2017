{"auto_keywords": [{"score": 0.03190812938259865, "phrase": "fars"}, {"score": 0.02870122825143339, "phrase": "relevant_features"}, {"score": 0.00481495049065317, "phrase": "effective_features_and_relations"}, {"score": 0.004762893197005439, "phrase": "efficient_multi-relational_classification._feature_selection"}, {"score": 0.004535481695403089, "phrase": "irrelevant_and_redundant_attributes"}, {"score": 0.004486432283770142, "phrase": "shorter_learning_time"}, {"score": 0.004437910956996051, "phrase": "better_accuracy"}, {"score": 0.004366106816225457, "phrase": "better_comprehensibility"}, {"score": 0.004112582094962078, "phrase": "data_mining"}, {"score": 0.004068087482412997, "phrase": "machine_learning_areas"}, {"score": 0.0038737214010638745, "phrase": "single_table_environment"}, {"score": 0.003531474887552889, "phrase": "multi-relational_environment"}, {"score": 0.003399466007862412, "phrase": "multiple_tables"}, {"score": 0.003290237137651949, "phrase": "semantic_relationships"}, {"score": 0.0030487828775502563, "phrase": "novel_approach"}, {"score": 0.00295078850927459, "phrase": "feature_and_relation_selection"}, {"score": 0.002918826667294298, "phrase": "efficient_multi-relational_classification"}, {"score": 0.0027491084541806823, "phrase": "traditional_feature_selection_method"}, {"score": 0.0025892330566358503, "phrase": "new_method"}, {"score": 0.0025334249463305875, "phrase": "multi-relational_database_schema"}, {"score": 0.0024386325347607674, "phrase": "classification_performance"}, {"score": 0.0022967713922705, "phrase": "real_and_synthetic_databases"}, {"score": 0.0021987994275190314, "phrase": "small_set"}, {"score": 0.002128067018576581, "phrase": "classification_efficiency"}, {"score": 0.0021049977753042253, "phrase": "prediction_accuracy"}], "paper_keywords": ["feature selection", " classification", " multi-relational classification"], "paper_abstract": "Feature selection is an essential data processing step to remove irrelevant and redundant attributes for shorter learning time, better accuracy, and better comprehensibility. A number of algorithms have been proposed in both data mining and machine learning areas. These algorithms are usually used in a single table environment, where data are stored in one relational table or one flat file. They are not suitable for a multi-relational environment, where data are stored in multiple tables joined to one another by semantic relationships. To address this problem, in this article, we propose a novel approach called FARS to conduct both Feature And Relation Selection for efficient multi-relational classification. Through this approach, we not only extend the traditional feature selection method to select relevant features from multi-relations, but also develop a new method to reconstruct the multi-relational database schema and eliminate irrelevant tables to improve classification performance further. The results of the experiments conducted on both real and synthetic databases show that FARS can effectively choose a small set of relevant features, thereby enhancing classification efficiency and prediction accuracy significantly.", "paper_title": "SELECTING EFFECTIVE FEATURES AND RELATIONS FOR EFFICIENT MULTI-RELATIONAL CLASSIFICATION", "paper_id": "WOS:000280359100004"}