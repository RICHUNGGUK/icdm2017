{"auto_keywords": [{"score": 0.04939815249833027, "phrase": "undecimated_wavelet_transform"}, {"score": 0.04850460722985758, "phrase": "nonorthogonal_filter_banks"}, {"score": 0.00481495049065317, "phrase": "multiscale_image_fusion"}, {"score": 0.0047013405841819025, "phrase": "spectral_factorization"}, {"score": 0.004612376827433774, "phrase": "multiscale_transforms"}, {"score": 0.004418287966422041, "phrase": "pixel-level_image_fusion"}, {"score": 0.004313996835376177, "phrase": "fusion_performance"}, {"score": 0.004112711391952791, "phrase": "different_sensor_modalities"}, {"score": 0.003597514862052876, "phrase": "image_decomposition_process"}, {"score": 0.0034625012596827334, "phrase": "analysis_filters"}, {"score": 0.003413183361838603, "phrase": "actual_fusion"}, {"score": 0.003300813776412652, "phrase": "first_filter_pair"}, {"score": 0.003161740194257218, "phrase": "unwanted_spreading"}, {"score": 0.003131637033429892, "phrase": "coefficient_values"}, {"score": 0.0031018195951638882, "phrase": "overlapping_image_singularities"}, {"score": 0.0030140547908298404, "phrase": "feature_selection_process"}, {"score": 0.00290087451159631, "phrase": "reconstruction_errors"}, {"score": 0.002859533151305368, "phrase": "fused_image"}, {"score": 0.002739001004969201, "phrase": "nonsubsampled_nature"}, {"score": 0.002699960714852968, "phrase": "uwt"}, {"score": 0.0024534993283766332, "phrase": "obtained_results"}, {"score": 0.0023388183537341213, "phrase": "fusion_framework"}, {"score": 0.0022944576894161485, "phrase": "clear_advantages"}, {"score": 0.0022725931637071852, "phrase": "traditional_multiscale_fusion_approaches"}, {"score": 0.0022188370388602813, "phrase": "underlying_fusion_rule"}, {"score": 0.002176747110119268, "phrase": "unwanted_side_effects"}, {"score": 0.0021049977753042253, "phrase": "fused_reconstruction"}], "paper_keywords": ["Image fusion", " nonorthogonal filter banks", " spectral factorization", " undecimated wavelet transform (UWT)"], "paper_abstract": "Multiscale transforms are among the most popular techniques in the field of pixel-level image fusion. However, the fusion performance of these methods often deteriorates for images derived from different sensor modalities. In this paper, we demonstrate that for such images, results can be improved using a novel undecimated wavelet transform (UWT)-based fusion scheme, which splits the image decomposition process into two successive filtering operations using spectral factorization of the analysis filters. The actual fusion takes place after convolution with the first filter pair. Its significantly smaller support size leads to the minimization of the unwanted spreading of coefficient values around overlapping image singularities. This usually complicates the feature selection process and may lead to the introduction of reconstruction errors in the fused image. Moreover, we will show that the nonsubsampled nature of the UWT allows the design of nonorthogonal filter banks, which are more robust to artifacts introduced during fusion, additionally improving the obtained results. The combination of these techniques leads to a fusion framework, which provides clear advantages over traditional multiscale fusion approaches, independent of the underlying fusion rule, and reduces unwanted side effects such as ringing artifacts in the fused reconstruction.", "paper_title": "Multiscale Image Fusion Using the Undecimated Wavelet Transform With Spectral Factorization and Nonorthogonal Filter Banks", "paper_id": "WOS:000318014300013"}