{"auto_keywords": [{"score": 0.04885877600670675, "phrase": "discriminative_classification"}, {"score": 0.00481495049065317, "phrase": "sparse_mixture_models"}, {"score": 0.0045139612588801035, "phrase": "saul"}, {"score": 0.004399221293406681, "phrase": "lee"}, {"score": 0.004231699728933577, "phrase": "mixture_model"}, {"score": 0.0040186038781533946, "phrase": "non-negative_data"}, {"score": 0.003916098498242888, "phrase": "non-negative_matrix_factorization"}, {"score": 0.0031845067058084583, "phrase": "sparse_version"}, {"score": 0.0029467742734417255, "phrase": "basic_idea"}, {"score": 0.0025892330566358503, "phrase": "un-normalized_mixture_models"}, {"score": 0.0023958326775913165, "phrase": "regularization_method"}, {"score": 0.002304606411453748, "phrase": "oil_cbcl_face_database_and_usps_digit_data"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["discriminative classification", " mixture model", " sparseness", " nonnegative matrix factorization", " regularization method"], "paper_abstract": "Recently Saul and Lee proposed a mixture model for discriminative classification of non-negative data via non-negative matrix factorization for feature extraction. In order to improve the generalization, this paper considers a sparse version of the model. The basic idea is to minimize the sum of the weights of un-normalized mixture models for posterior distributions according to regularization method. Experiments oil CBCL face database and USPS digit data set assess the validity of the proposed approach.", "paper_title": "Learning sparse mixture models for discriminative classification", "paper_id": "WOS:000238266100007"}