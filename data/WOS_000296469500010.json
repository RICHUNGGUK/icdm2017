{"auto_keywords": [{"score": 0.04755154299589266, "phrase": "sc_methods"}, {"score": 0.04175402074753411, "phrase": "high-dimensional_data"}, {"score": 0.004439097815805505, "phrase": "manifold_assumption"}, {"score": 0.004281568920264999, "phrase": "high-density_region"}, {"score": 0.004223941453664225, "phrase": "low-dimensional_data_manifold"}, {"score": 0.0038242899532391914, "phrase": "clear_low-dimensional_manifold_structure"}, {"score": 0.0035898158129721003, "phrase": "clustering_performance"}, {"score": 0.0034157624093743635, "phrase": "k-means"}, {"score": 0.003220709449062307, "phrase": "true_cluster_assignment_matrix"}, {"score": 0.0030922667860233603, "phrase": "linear_space"}, {"score": 0.002812080283780621, "phrase": "objective_function"}, {"score": 0.002712131567923321, "phrase": "proposed_sec_framework"}, {"score": 0.0026514708899935333, "phrase": "out-of-sample_data"}, {"score": 0.0025804616931593897, "phrase": "new_laplacian_matrix"}, {"score": 0.0025341792091114184, "phrase": "local_regression"}, {"score": 0.002400241288973103, "phrase": "local_and_global_discriminative_information"}, {"score": 0.0023571835517819124, "phrase": "comprehensive_experiments"}, {"score": 0.00233594452829104, "phrase": "eight_real-world_high-dimensional_datasets"}, {"score": 0.0022427071130840647, "phrase": "existing_sc_methods"}, {"score": 0.00222249726328354, "phrase": "k-means-based_clustering_methods"}, {"score": 0.002192621290439543, "phrase": "sec"}, {"score": 0.0021241414408077895, "phrase": "nystrom_algorithm"}, {"score": 0.0021049977753042253, "phrase": "unseen_data"}], "paper_keywords": ["Linearity regularization", " out-of-sample clustering", " spectral clustering", " spectral embedded clustering"], "paper_abstract": "Spectral clustering (SC) methods have been successfully applied to many real-world applications. The success of these SC methods is largely based on the manifold assumption, namely, that two nearby data points in the high-density region of a low-dimensional data manifold have the same cluster label. However, such an assumption might not always hold on high-dimensional data. When the data do not exhibit a clear low-dimensional manifold structure (e. g., high-dimensional and sparse data), the clustering performance of SC will be degraded and become even worse than K-means clustering. In this paper, motivated by the observation that the true cluster assignment matrix for high-dimensional data can be always embedded in a linear space spanned by the data, we propose the spectral embedded clustering (SEC) framework, in which a linearity regularization is explicitly added into the objective function of SC methods. More importantly, the proposed SEC framework can naturally deal with out-of-sample data. We also present a new Laplacian matrix constructed from a local regression of each pattern and incorporate it into our SEC framework to capture both local and global discriminative information for clustering. Comprehensive experiments on eight real-world high-dimensional datasets demonstrate the effectiveness and advantages of our SEC framework over existing SC methods and K-means-based clustering methods. Our SEC framework significantly outperforms SC using the Nystrom algorithm on unseen data.", "paper_title": "Spectral Embedded Clustering: A Framework for In-Sample and Out-of-Sample Spectral Clustering", "paper_id": "WOS:000296469500010"}