{"auto_keywords": [{"score": 0.04934325842114906, "phrase": "hyper-heuristic_evolutionary_algorithm"}, {"score": 0.03812022871741234, "phrase": "decision-tree_induction_algorithm"}, {"score": 0.00481495049065317, "phrase": "fitness_functions"}, {"score": 0.004620093797504386, "phrase": "balanced_and_imbalanced_data_classification"}, {"score": 0.004320055598195391, "phrase": "different_strategies"}, {"score": 0.004209893377338457, "phrase": "fitness_function"}, {"score": 0.004145143433523008, "phrase": "evolutionary_cycle"}, {"score": 0.003997891221012094, "phrase": "decision-tree_induction_algorithms"}, {"score": 0.0037965243835456214, "phrase": "experimental_scheme"}, {"score": 0.0035866734383189366, "phrase": "multiple_balanced_data_sets"}, {"score": 0.003405948098114941, "phrase": "multiple_imbalanced_data_sets"}, {"score": 0.003151736708029235, "phrase": "well-known_classification_performance_measures"}, {"score": 0.0030712886471866417, "phrase": "f-measure"}, {"score": 0.003039700964756449, "phrase": "auc"}, {"score": 0.0029620573986902416, "phrase": "also_a_lesser-known_criterion"}, {"score": 0.002931569771634119, "phrase": "namely_the_relative_accuracy_improvement"}, {"score": 0.0028273061946184645, "phrase": "different_schemes"}, {"score": 0.002740885774408238, "phrase": "simple_average"}, {"score": 0.0025493457404304446, "phrase": "best-performing_fitness_functions"}, {"score": 0.002408265305704217, "phrase": "traditional_decision-tree_induction_algorithms"}, {"score": 0.0023589299540736405, "phrase": "cart"}, {"score": 0.002322571491379753, "phrase": "reptree"}, {"score": 0.002298649369775623, "phrase": "experimental_results"}, {"score": 0.0022283519468680475, "phrase": "good_option"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_decision-tree_induction_algorithms"}], "paper_keywords": ["Hyper-heuristics", " Decision trees", " Fitness function", " Imbalanced data"], "paper_abstract": "In this paper, we analyse in detail the impact of different strategies to be used as fitness function during the evolutionary cycle of a hyper-heuristic evolutionary algorithm that automatically designs decision-tree induction algorithms (HEAD-DT). We divide the experimental scheme into two distinct scenarios: (1) evolving a decision-tree induction algorithm from multiple balanced data sets; and (2) evolving a decision-tree induction algorithm from multiple imbalanced data sets. In each of these scenarios, we analyse the difference in performance of well-known classification performance measures such as accuracy, F-Measure, AUC, recall, and also a lesser-known criterion, namely the relative accuracy improvement. In addition, we analyse different schemes of aggregation, such as simple average, median, and harmonic mean. Finally, we verify whether the best-performing fitness functions are capable of providing HEAD-DT with algorithms more effective than traditional decision-tree induction algorithms like C4.5, CART, and REPTree. Experimental results indicate that HEAD-DT is a good option for generating algorithms tailored to (im)balanced data, since it outperforms state-of-the-art decision-tree induction algorithms with statistical significance.", "paper_title": "Investigating fitness functions for a hyper-heuristic evolutionary algorithm in the context of balanced and imbalanced data classification", "paper_id": "WOS:000360081400001"}