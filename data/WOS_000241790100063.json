{"auto_keywords": [{"score": 0.044340662163821175, "phrase": "feedforward_neural_networks"}, {"score": 0.00481495049065317, "phrase": "fnn_training"}, {"score": 0.004714023408114857, "phrase": "penalty_methods"}, {"score": 0.004330941610682453, "phrase": "generalization_performance"}, {"score": 0.0038953958723049287, "phrase": "network_weights"}, {"score": 0.003813669883040509, "phrase": "weight_boundedness_and_convergence_results"}, {"score": 0.0036167509502276294, "phrase": "batch_bp_algorithm"}, {"score": 0.003322540556404882, "phrase": "hidden_layer"}, {"score": 0.0032184697893776052, "phrase": "key_point"}, {"score": 0.0029253546782349875, "phrase": "error_function"}, {"score": 0.002833689453299307, "phrase": "penalty_term"}, {"score": 0.002744888626958772, "phrase": "training_iteration"}, {"score": 0.002575526825728026, "phrase": "learning_rate_parameter"}, {"score": 0.0024947959375982614, "phrase": "penalty_parameter"}], "paper_keywords": [""], "paper_abstract": "Penalty methods have been commonly used to improve the generalization performance of feedforward neural networks and to control the magnitude of the network weights. Weight boundedness and convergence results are presented for the batch BP algorithm with penalty for training feedforward neural networks with a hidden layer. A key point of the proofs is the monotonicity of the error function with the penalty term during the training iteration. A relationship between the learning rate parameter and the penalty parameter is proposed to guarantee the convergence. The algorithm is applied to two classification problems to support our theoretical findings.", "paper_title": "Convergence of batch BP algorithm with penalty for FNN training", "paper_id": "WOS:000241790100063"}