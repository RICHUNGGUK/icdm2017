{"auto_keywords": [{"score": 0.02632647964669402, "phrase": "average_memory_access_time"}, {"score": 0.00481495049065317, "phrase": "packet_forwarding_engines"}, {"score": 0.0047804843375940835, "phrase": "packet_forwarding"}, {"score": 0.0047292449487169345, "phrase": "memory-intensive_application"}, {"score": 0.004628400269774981, "phrase": "trie_structure"}, {"score": 0.004481132747216135, "phrase": "line_rates"}, {"score": 0.004449045430179066, "phrase": "high-performance_routers"}, {"score": 0.004215571179806372, "phrase": "seven_memory_accesses"}, {"score": 0.004185377431624781, "phrase": "earlier_work"}, {"score": 0.004125634486868786, "phrase": "single_cache"}, {"score": 0.003951453722517865, "phrase": "external_memory_accesses"}, {"score": 0.003853251284913932, "phrase": "locality_characteristics"}, {"score": 0.0038119123317396954, "phrase": "level-one_nodes"}, {"score": 0.003677280504320636, "phrase": "lower_level_nodes"}, {"score": 0.0035858673522839407, "phrase": "heterogeneously_segmented_cache_architecture"}, {"score": 0.003509317669345521, "phrase": "separate_caches"}, {"score": 0.0034841647157189985, "phrase": "level-one_and_lower_level_nodes"}, {"score": 0.0031277316566463978, "phrase": "nonuniform_distribution"}, {"score": 0.0030830390264125923, "phrase": "cache_sets"}, {"score": 0.0030499378654797143, "phrase": "level-one_nodes_cache"}, {"score": 0.003006353490112719, "phrase": "high_conflict_misses"}, {"score": 0.002963390095037466, "phrase": "conflict_misses"}, {"score": 0.0029210388852074208, "phrase": "novel_two-level_mapping-based_cache_placement_framework"}, {"score": 0.0028076592725295646, "phrase": "modified_placement_function"}, {"score": 0.0027775064989253575, "phrase": "cache_organization"}, {"score": 0.0027575842698911173, "phrase": "minimal_increase"}, {"score": 0.0027378045447760705, "phrase": "access_time"}, {"score": 0.0026505322540093783, "phrase": "trace_generation_methodology"}, {"score": 0.0026220625042810706, "phrase": "real_traces"}, {"score": 0.0025660347613972573, "phrase": "varying_locality"}, {"score": 0.0025476254812544135, "phrase": "performance_results"}, {"score": 0.002448704249007665, "phrase": "unified_nodes_cache"}, {"score": 0.0024136912104995977, "phrase": "hsca"}, {"score": 0.002396371892825691, "phrase": "iharc"}, {"score": 0.0023536149458842992, "phrase": "lookup_results"}, {"score": 0.002143247921132179, "phrase": "overall_improvement"}, {"score": 0.0021049977753042253, "phrase": "unified_scheme"}], "paper_keywords": ["Special-purpose and application-based systems", " design", " performance", " experimentation", " cache architectures", " network processors", " synthetic trace generation", " trace driven simulation"], "paper_abstract": "Packet forwarding is a memory-intensive application requiring multiple accesses through a trie structure. With the requirement to process packets at line rates, high-performance routers need to forward millions of packets every second with each packet needing up to seven memory accesses. Earlier work shows that a single cache for the nodes of a trie can reduce the number of external memory accesses. It is observed that the locality characteristics of the level-one nodes of a trie are significantly different from those of lower level nodes. Hence, we propose a heterogeneously segmented cache architecture (HSCA) which uses separate caches for level-one and lower level nodes, each with carefully chosen sizes. Besides reducing misses, segmenting the cache allows us to focus on optimizing the more frequently accessed level-one node segment. We find that due to the nonuniform distribution of nodes among cache sets, the level-one nodes cache is susceptible to high conflict misses. We reduce conflict misses by introducing a novel two-level mapping-based cache placement framework. We also propose an elegant way to fit the modified placement function into the cache organization with minimal increase in access time. Further, we propose an attribute preserving trace generation methodology which emulates real traces and can generate traces with varying locality. Performance results reveal that our HSCA scheme results in a 32 percent speedup in average memory access time over a unified nodes cache. Also, HSCA outperforms IHARC, a cache for lookup results, with as high as a 10-fold speedup in average memory access time. Two-level mapping further enhances the performance of the base HSCA by up to 13 percent leading to an overall improvement of up to 40 percent over the unified scheme.", "paper_title": "A Novel Cache Architecture and Placement Framework for Packet Forwarding Engines", "paper_id": "WOS:000267941900001"}