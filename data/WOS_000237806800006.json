{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "listeners'_emotional_engagement"}, {"score": 0.004556901872357751, "phrase": "possible_approach"}, {"score": 0.004273196830970426, "phrase": "particular_musical_performances"}, {"score": 0.004081385289516914, "phrase": "audio_parameters"}, {"score": 0.0038271712887391015, "phrase": "recorded_audio_files"}, {"score": 0.003689053436223376, "phrase": "bach's_solo_violin_sonatas"}, {"score": 0.0036218682585355895, "phrase": "partitas"}, {"score": 0.0034911335714333507, "phrase": "listeners'_responses"}, {"score": 0.0030135741897058844, "phrase": "highest_correlations"}, {"score": 0.002851790448644913, "phrase": "decision_trees"}, {"score": 0.002530359917257626, "phrase": "emotional_engagement"}, {"score": 0.0024844539065497708, "phrase": "em"}, {"score": 0.0023944552329463035, "phrase": "potential_listeners"}, {"score": 0.0023507916951658455, "phrase": "similar_pieces"}], "paper_keywords": [""], "paper_abstract": "This paper introduces a possible approach for evaluating and predicting listeners' emotional engagement during particular musical performances. A set of audio parameters (cues) is extracted from recorded audio files of two contrasting movements from Bach's Solo Violin Sonatas and Partitas and compared to listeners' responses, obtained by moving a slider while listening to music. The cues showing the highest correlations are then used for generating decision trees and a set of rules which will be useful for predicting the emotional engagement (EM) experienced by potential listeners in similar pieces. The model is tested on two different movements of the Solos showing very promising results.", "paper_title": "A possible model for predicting listeners' emotional engagement", "paper_id": "WOS:000237806800006"}