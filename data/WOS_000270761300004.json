{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "local_spatiotemporal_descriptors"}, {"score": 0.004745056850725867, "phrase": "visual_speech_information"}, {"score": 0.004642105253191792, "phrase": "important_role"}, {"score": 0.004508286991825192, "phrase": "noisy_conditions"}, {"score": 0.0043147264956783565, "phrase": "hearing_impairment"}, {"score": 0.003923269062268688, "phrase": "spoken_isolated_phrases"}, {"score": 0.003810093416457147, "phrase": "visual_input"}, {"score": 0.003754731210715724, "phrase": "spatiotemporal_local_binary_patterns"}, {"score": 0.0036731870109004993, "phrase": "mouth_regions"}, {"score": 0.003541182515693916, "phrase": "isolated_phrase_sequences"}, {"score": 0.00336428077531883, "phrase": "ten_phrases"}, {"score": 0.0032671775301001513, "phrase": "promising_accuracies"}, {"score": 0.003081272473508291, "phrase": "speaker-independent_and_speaker-dependent_recognition"}, {"score": 0.0028847066125323893, "phrase": "avletters_database"}, {"score": 0.0025468951021098717, "phrase": "confusion_matrix"}, {"score": 0.002455266773537278, "phrase": "good_clustering_characteristics"}, {"score": 0.0023669270875629205, "phrase": "proposed_descriptors"}, {"score": 0.002248553559414903, "phrase": "local_processing"}, {"score": 0.0021835829960683666, "phrase": "monotonic_gray-scale_changes"}, {"score": 0.0021049977753042253, "phrase": "error_prone_segmentation"}], "paper_keywords": ["Lipreading", " local binary patterns", " spatiotemporal descriptors", " visual speech recognition"], "paper_abstract": "Visual speech information plays an important role in lipreading under noisy conditions or for listeners with a hearing impairment. In this paper, we present local spatiotemporal descriptors to represent and recognize spoken isolated phrases based solely on visual input. Spatiotemporal local binary patterns extracted from mouth regions are used for describing isolated phrase sequences. In our experiments with 817 sequences from ten phrases and 20 speakers, promising accuracies of 62% and 70% were obtained in speaker-independent and speaker-dependent recognition, respectively. In comparison with other methods on AVLetters database, the accuracy, 62.8%, of our method clearly outperforms the others. Analysis of the confusion matrix for 26 English letters shows the good clustering characteristics of visemes for the proposed descriptors. The advantages of our approach include local processing and robustness to monotonic gray-scale changes. Moreover, no error prone segmentation of moving lips is needed.", "paper_title": "Lipreading With Local Spatiotemporal Descriptors", "paper_id": "WOS:000270761300004"}