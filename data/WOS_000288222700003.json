{"auto_keywords": [{"score": 0.04619063797532855, "phrase": "decision_trees"}, {"score": 0.00481495049065317, "phrase": "heuristic_for_incremental_decision_tree_learning_through_asymptotic_analysis."}, {"score": 0.004508661664944657, "phrase": "incremental_induction"}, {"score": 0.004342430078306461, "phrase": "stability_problems"}, {"score": 0.004182301599359094, "phrase": "induction_algorithm"}, {"score": 0.004028054020045027, "phrase": "decision_tree"}, {"score": 0.003807242767474929, "phrase": "similar_concepts"}, {"score": 0.0032756158688245, "phrase": "asymptotic_analysis"}, {"score": 0.003154701855951328, "phrase": "basic_parameters"}, {"score": 0.0029816229984366374, "phrase": "computational_effort"}, {"score": 0.0029260602766930065, "phrase": "incremental_learning"}, {"score": 0.0021049977753042253, "phrase": "experimental_evidence"}], "paper_keywords": ["Decision trees", " incremental induction", " approximation", " asymptotic analysis", " heuristic"], "paper_abstract": "This paper addresses stability issues in incremental induction of decision trees. Stability problems arise when an induction algorithm must revise a decision tree very often and oscillations between similar concepts decrease learning speed. We review a heuristic that solves this problem and subsequently employ asymptotic analysis to approximate the basic parameters related to the estimation of computational effort in incremental learning of decision trees. We then use these approximations to simplify the heuristic, we deliver insight into its amortizing behavior and argue how they can also speed-up its execution and enhance its applicability, also providing experimental evidence to support these claims.", "paper_title": "CONSOLIDATING A HEURISTIC FOR INCREMENTAL DECISION TREE LEARNING THROUGH ASYMPTOTIC ANALYSIS", "paper_id": "WOS:000288222700003"}