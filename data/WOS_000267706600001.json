{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "transductive_rademacher_complexity"}, {"score": 0.004278807087784626, "phrase": "data-dependent_error_bounds"}, {"score": 0.0036815763368083197, "phrase": "novel_general_error"}, {"score": 0.00323625520042892, "phrase": "novel_bounding_technique"}, {"score": 0.003167441161387607, "phrase": "rademacher_averages"}, {"score": 0.003100085797251317, "phrase": "particular_algorithms"}, {"score": 0.0025003054002226965, "phrase": "error_bounds"}, {"score": 0.0022696277881969896, "phrase": "new_pac-bayesian_bound"}, {"score": 0.002174041708084857, "phrase": "transductive_algorithms"}], "paper_keywords": [""], "paper_abstract": "We develop a technique for deriving data-dependent error bounds for transductive learning algorithms based on transductive Rademacher complexity. Our technique is based on a novel general error bound for transduction in terms of transductive Rademacher complexity, together with a novel bounding technique for Rademacher averages for particular algorithms, in terms of their \"unlabeled-labeled\" representation. This technique is relevant to many advanced graph-based transductive algorithms and we demonstrate its effectiveness by deriving error bounds to three well known algorithms. Finally, we present a new PAC-Bayesian bound for mixtures of transductive algorithms based on our Rademacher bounds.", "paper_title": "Transductive Rademacher Complexity and its Applications", "paper_id": "WOS:000267706600001"}