{"auto_keywords": [{"score": 0.0487522732954503, "phrase": "low-rank_matrix_factorization"}, {"score": 0.00481495049065317, "phrase": "low-rank_matrix_factorizations"}, {"score": 0.004500891637057374, "phrase": "effective_methodology"}, {"score": 0.004450568197899267, "phrase": "collaborative_filtering_applications"}, {"score": 0.004327196832280818, "phrase": "high_quality_rating_predictions"}, {"score": 0.00413684709497912, "phrase": "low-rank_factorization"}, {"score": 0.003932654396285872, "phrase": "low-rank_model"}, {"score": 0.0037595947142663997, "phrase": "over-fitting_problem"}, {"score": 0.0036966717141736355, "phrase": "observed_data"}, {"score": 0.003474799999519295, "phrase": "novel_regularization_technique"}, {"score": 0.003303177222901723, "phrase": "pre-estimated_ratings"}, {"score": 0.003247868216333148, "phrase": "pre-specified_subset"}, {"score": 0.002951444412262927, "phrase": "new_regularized_problem"}, {"score": 0.0029020077365708966, "phrase": "least_squares_iterations"}, {"score": 0.0028695095228791724, "phrase": "stochastic_gradient_descent"}, {"score": 0.0027741761880779535, "phrase": "fast_implementation"}, {"score": 0.002727700630869639, "phrase": "alternating_least_squares_algorithm"}, {"score": 0.002651960559564796, "phrase": "parallel_computing"}, {"score": 0.0026222551419772867, "phrase": "numerical_experiments"}, {"score": 0.0025783250341880385, "phrase": "movielens"}, {"score": 0.0025494356807031857, "phrase": "jester"}, {"score": 0.0025067157194874094, "phrase": "eachmovie"}, {"score": 0.0024234059612683032, "phrase": "proposed_algorithms"}, {"score": 0.0023962545023307937, "phrase": "existing_algorithms"}, {"score": 0.0022020622730208514, "phrase": "superior_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Regularization", " Matrix factorization", " Collaborative filtering", " Missing data", " Over-fitting"], "paper_abstract": "Low-rank matrix factorization with missing data has become an effective methodology for collaborative filtering applications since it can generate high quality rating predictions for recommendation systems. The performance of low-rank factorization, however, critically depends on how the low-rank model is regularized in order to mitigate the over-fitting problem to the observed data. The objective of this paper is to propose a novel regularization technique which we call inducible regularization. It utilizes pre-estimated ratings on a pre-specified subset of the ratings to regularize the solutions of low-rank matrix factorization. We develop two algorithms for solving the new regularized problem via alternating least squares iterations and stochastic gradient descent. We also devise a fast implementation of the alternating least squares algorithm which is suitable for parallel computing. Numerical experiments on three real-world data sets MovieLens, Jester, and EachMovie are given for comparing the proposed algorithms with existing algorithms ALS, SGD, and SVD++ that solve low-rank matrix factorization with classical regularizations, illustrating superior performance of our proposed algorithms. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Inducible regularization for low-rank matrix factorizations for collaborative filtering", "paper_id": "WOS:000309318200007"}