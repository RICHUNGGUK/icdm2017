{"auto_keywords": [{"score": 0.03430889850360744, "phrase": "bilattice_framework"}, {"score": 0.00481495049065317, "phrase": "predicate_logic_based_image_grammars"}, {"score": 0.004782455247247007, "phrase": "complex_pattern_recognition"}, {"score": 0.004750178261675602, "phrase": "predicate_logic"}, {"score": 0.0047341211614980085, "phrase": "based_reasoning_approaches"}, {"score": 0.004623224002010226, "phrase": "domain_knowledge"}, {"score": 0.004576491793324233, "phrase": "symbolic_information"}, {"score": 0.004499647408293102, "phrase": "different_concepts"}, {"score": 0.004409127897028587, "phrase": "traditional_binary_predicate_logics"}, {"score": 0.004364550313102054, "phrase": "bilattice_formalism"}, {"score": 0.004176509019758331, "phrase": "computer_vision_problems"}, {"score": 0.004051074327962139, "phrase": "first_order_predicate_logics"}, {"score": 0.003983016985197904, "phrase": "bilattice_based_uncertainty_handling_formalism"}, {"score": 0.0039028497942174777, "phrase": "formally_encoding_pattern_grammars"}, {"score": 0.0038113506617834087, "phrase": "image_features"}, {"score": 0.0037219886365287085, "phrase": "different_patterns"}, {"score": 0.0036470559917231218, "phrase": "low_level_feature_detectors"}, {"score": 0.0035979378467361762, "phrase": "logical_facts"}, {"score": 0.003525493807130663, "phrase": "logical_rules"}, {"score": 0.0034311578789991363, "phrase": "positive_and_negative_information"}, {"score": 0.003057503388220776, "phrase": "parse_trees"}, {"score": 0.0029655761366079877, "phrase": "direct_analysis"}, {"score": 0.0029355502535757696, "phrase": "final_solution"}, {"score": 0.002915701586760994, "phrase": "linguistic_form"}, {"score": 0.002895986736522535, "phrase": "automated_logical_rule_weight_learning"}, {"score": 0.0027804579695873827, "phrase": "computer_vision_domain"}, {"score": 0.0027336881691956186, "phrase": "rule_weight_optimization_method"}, {"score": 0.002696837864985637, "phrase": "instantiated_inference_tree"}, {"score": 0.002669525619637691, "phrase": "knowledge-based_neural_network"}, {"score": 0.0026157259734105, "phrase": "link_weights"}, {"score": 0.002485911017095097, "phrase": "rule_weights"}, {"score": 0.0024607296642187846, "phrase": "optimal_performance"}, {"score": 0.00237861522566195, "phrase": "proposed_predicate_logic_based_pattern_grammar_formulation"}, {"score": 0.002252880693912436, "phrase": "partial_occlusions"}, {"score": 0.0022074592164608134, "phrase": "large_complex_man"}, {"score": 0.002162951519368368, "phrase": "satellite_imagery"}, {"score": 0.002119339298633587, "phrase": "optimization_approach"}, {"score": 0.0021049977753042253, "phrase": "real_as_well_as_simulated_data"}], "paper_keywords": ["Stochastic image grammars", " Logical reasoning", " Human detection", " Object detection and classification", " Bilattice", " Back propagation", " Aerial image analysis"], "paper_abstract": "Predicate logic based reasoning approaches provide a means of formally specifying domain knowledge and manipulating symbolic information to explicitly reason about different concepts of interest. Extension of traditional binary predicate logics with the bilattice formalism permits the handling of uncertainty in reasoning, thereby facilitating their application to computer vision problems. In this paper, we propose using first order predicate logics, extended with a bilattice based uncertainty handling formalism, as a means of formally encoding pattern grammars, to parse a set of image features, and detect the presence of different patterns of interest. Detections from low level feature detectors are treated as logical facts and, in conjunction with logical rules, used to drive the reasoning. Positive and negative information from different sources, as well as uncertainties from detections, are integrated within the bilattice framework. We show that this approach can also generate proofs or justifications (in the form of parse trees) for each hypothesis it proposes thus permitting direct analysis of the final solution in linguistic form. Automated logical rule weight learning is an important aspect of the application of such systems in the computer vision domain. We propose a rule weight optimization method which casts the instantiated inference tree as a knowledge-based neural network, interprets rule uncertainties as link weights in the network, and applies a constrained, back-propagation algorithm to converge upon a set of rule weights that give optimal performance within the bilattice framework. Finally, we evaluate the proposed predicate logic based pattern grammar formulation via application to the problems of (a) detecting the presence of humans under partial occlusions and (b) detecting large complex man made structures as viewed in satellite imagery. We also evaluate the optimization approach on real as well as simulated data and show favorable results.", "paper_title": "Predicate Logic Based Image Grammars for Complex Pattern Recognition", "paper_id": "WOS:000288806000003"}