{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "decision_tables"}, {"score": 0.049655608595442394, "phrase": "attribute_value_taxonomies"}, {"score": 0.0492360740810728, "phrase": "attribute_reduction"}, {"score": 0.04881990207677593, "phrase": "attribute_generalization"}, {"score": 0.0363505910819361, "phrase": "knowledge_reduction"}, {"score": 0.004605748839642513, "phrase": "simple_representations"}, {"score": 0.004232875294230749, "phrase": "hierarchical_domains"}, {"score": 0.004139850082354509, "phrase": "raw_attribute_domains"}, {"score": 0.00408501512749186, "phrase": "coarser_granularity"}, {"score": 0.0032852337992126564, "phrase": "generalization_process"}, {"score": 0.0032129675521135616, "phrase": "reduced_data"}, {"score": 0.0031422859551159506, "phrase": "smaller_attribute_domains"}, {"score": 0.003032405563826263, "phrase": "shannon's_conditional_entropy"}, {"score": 0.002992195343569767, "phrase": "classification_capability"}, {"score": 0.0029133627624098064, "phrase": "novel_concept"}, {"score": 0.0027010719929751, "phrase": "high_levels"}, {"score": 0.0026182085765020548, "phrase": "raw_data"}, {"score": 0.002572001496778222, "phrase": "major_relationships"}, {"score": 0.0025492038831408715, "phrase": "attribute_reduct"}, {"score": 0.0024490834773668153, "phrase": "minimal_attribute-generalization_reduct"}, {"score": 0.00241658945942583, "phrase": "np-hard_problem"}, {"score": 0.0023739321566540682, "phrase": "heuristic_algorithm"}, {"score": 0.002352886041381761, "phrase": "attribute-generalization_reduction"}, {"score": 0.0022705467477443417, "phrase": "better_classification_performance"}, {"score": 0.002220551141101661, "phrase": "smaller_rule_sets"}, {"score": 0.002200861826643147, "phrase": "better_generalized_knowledge"}, {"score": 0.0021620042653528846, "phrase": "attribute_reduction_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Knowledge reduction", " Attribute value taxonomy", " Attribute generalization", " Classification", " Rough set theory"], "paper_abstract": "Attribute reduction and attribute generalization are two basic methods for simple representations of knowledge. Attribute reduction can only reduce the number of attributes and is thus unsuitable for attributes with hierarchical domains. Attribute generalization can transform raw attribute domains into a coarser granularity by exploiting attribute value taxonomies (AVTs). As the control of how high an attribute should be generalized is typically quite subjective, it can easily result in over-generalization or under-generalization. This paper investigates knowledge reduction for decision tables with AVTs, which can objectively control the generalization process, and construct a reduced data set with fewer attributes and smaller attribute domains. Specifically, we make use of Shannon's conditional entropy for measuring classification capability for generalization and propose a novel concept for knowledge reduction, designated attribute-generalization reduct, which can objectively generalize attributes to maximize high levels while keep the same classification capability as the raw data. We analyze major relationships between attribute reduct and attribute-generalization reduct and prove that finding a minimal attribute-generalization reduct is an NP-hard problem and develop a heuristic algorithm for attribute-generalization reduction, namely, AGR-SCE. Empirical studies demonstrate that our algorithm accomplishes better classification performance and assists in computing smaller rule sets with better generalized knowledge compared with the attribute reduction method. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Knowledge reduction for decision tables with attribute value taxonomies", "paper_id": "WOS:000331160200006"}