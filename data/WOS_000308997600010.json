{"auto_keywords": [{"score": 0.030025708036724715, "phrase": "rmi"}, {"score": 0.00481495049065317, "phrase": "rank_entropy-based"}, {"score": 0.004706453355638515, "phrase": "monotonic_classification"}, {"score": 0.004247560712327667, "phrase": "monotonic_constraint"}, {"score": 0.004128192012388041, "phrase": "better_feature_values"}, {"score": 0.003966667994579941, "phrase": "worse_decision_class"}, {"score": 0.003789763907758991, "phrase": "monotonicity_constraint"}, {"score": 0.003725470458263889, "phrase": "learning_algorithms"}, {"score": 0.003267342521938321, "phrase": "noisy_samples"}, {"score": 0.0031393948330209224, "phrase": "real-world_applications"}, {"score": 0.002982203248352076, "phrase": "new_measure"}, {"score": 0.0029483516334882862, "phrase": "feature_quality"}, {"score": 0.002675654549462983, "phrase": "shannon's_entropy"}, {"score": 0.002585539416877115, "phrase": "rough_sets"}, {"score": 0.0025416235470290286, "phrase": "ordinal_structures"}, {"score": 0.0025127604406208668, "phrase": "monotonic_data_sets"}, {"score": 0.002414290278501595, "phrase": "decision_tree_algorithm"}, {"score": 0.002386869729952315, "phrase": "remt"}, {"score": 0.0023329572140896237, "phrase": "rank_mutual_information"}, {"score": 0.0022933216359142736, "phrase": "theoretic_and_experimental_analysis"}, {"score": 0.00224151735457093, "phrase": "proposed_algorithm"}, {"score": 0.0022034318550547866, "phrase": "monotonically_consistent_decision_trees"}, {"score": 0.0021659920594094407, "phrase": "training_samples"}], "paper_keywords": ["Monotonic classification", " rank entropy", " rank mutual information", " decision tree"], "paper_abstract": "In many decision making tasks, values of features and decision are ordinal. Moreover, there is a monotonic constraint that the objects with better feature values should not be assigned to a worse decision class. Such problems are called ordinal classification with monotonicity constraint. Some learning algorithms have been developed to handle this kind of tasks in recent years. However, experiments show that these algorithms are sensitive to noisy samples and do not work well in real-world applications. In this work, we introduce a new measure of feature quality, called rank mutual information (RMI), which combines the advantage of robustness of Shannon's entropy with the ability of dominance rough sets in extracting ordinal structures from monotonic data sets. Then, we design a decision tree algorithm (REMT) based on rank mutual information. The theoretic and experimental analysis shows that the proposed algorithm can get monotonically consistent decision trees, if training samples are monotonically consistent. Its performance is still good when data are contaminated with noise.", "paper_title": "Rank Entropy-Based Decision Trees for Monotonic Classification", "paper_id": "WOS:000308997600010"}