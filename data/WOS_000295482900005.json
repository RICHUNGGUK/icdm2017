{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "uncertain_data"}, {"score": 0.04954033184026155, "phrase": "data_uncertainty"}, {"score": 0.03712948918190359, "phrase": "urule"}, {"score": 0.03272696524242419, "phrase": "uncertain_numerical_data"}, {"score": 0.029637584382245584, "phrase": "uncertain_categorical_data"}, {"score": 0.026831747073449014, "phrase": "urule_algorithm"}, {"score": 0.004654210559456924, "phrase": "real-world_applications"}, {"score": 0.004398094237005956, "phrase": "imprecise_measurements"}, {"score": 0.0038392331564122387, "phrase": "unreliable_or_even_wrong_mining_results"}, {"score": 0.0035869274480340727, "phrase": "rule_induction_algorithm"}, {"score": 0.0033511469200347907, "phrase": "key_problem"}, {"score": 0.0031845067058084583, "phrase": "optimal_cut_points"}, {"score": 0.003148612096891635, "phrase": "training_data"}, {"score": 0.003009022147559257, "phrase": "optimization_mechanism"}, {"score": 0.002958281631770322, "phrase": "adjacent_bins"}, {"score": 0.0029083942467546305, "phrase": "equal_classifying_class_distribution"}, {"score": 0.0027017308406240563, "phrase": "new_method"}, {"score": 0.002656158309155626, "phrase": "cut_points"}, {"score": 0.0026113524778702624, "phrase": "possible_world_semantics"}, {"score": 0.002318127769195112, "phrase": "potentially_higher_accuracies"}, {"score": 0.0022661190184053628, "phrase": "proposed_optimization_method"}, {"score": 0.002202742267484358, "phrase": "cut_point_selection"}, {"score": 0.0021049977753042253, "phrase": "quite_stable_performance"}], "paper_keywords": ["Rule", " Uncertain data", " Data classification", " Possible world semantics"], "paper_abstract": "Data uncertainty are common in real-world applications and it can be caused by many factors such as imprecise measurements, network latency, outdated sources and sampling errors. When mining knowledge from these applications, data uncertainty need to be handled with caution. Otherwise, unreliable or even wrong mining results would be obtained. In this paper, we propose a rule induction algorithm, called uRule, to learn rules from uncertain data. The key problem in learning rules is to efficiently identify the optimal cut points from training data. For uncertain numerical data, we propose an optimization mechanism which merges adjacent bins that have equal classifying class distribution and prove its soundness. For the uncertain categorical data, we also propose a new method to select cut points based on possible world semantics. We then present the uRule algorithm in detail. Our experimental results show that the uRule algorithm can generate rules from uncertain numerical data with potentially higher accuracies, and the proposed optimization method is effective in the cut point selection for both certain and uncertain numerical data. Furthermore, uRule has quite stable performance when mining uncertain categorical data.", "paper_title": "Rule induction for uncertain data", "paper_id": "WOS:000295482900005"}