{"auto_keywords": [{"score": 0.027532906467297294, "phrase": "resource_allocation"}, {"score": 0.00481495049065317, "phrase": "indoor_camera_networks"}, {"score": 0.004761732436126133, "phrase": "event_detection"}, {"score": 0.0047090997998449095, "phrase": "distributed_camera_network"}, {"score": 0.004605565335682916, "phrase": "large-scale_tracking"}, {"score": 0.004000486064911652, "phrase": "network_bandwidth_restrictions"}, {"score": 0.003897989308486044, "phrase": "writing_images"}, {"score": 0.0038548668648948044, "phrase": "cpu_usage"}, {"score": 0.0036598289615980837, "phrase": "resource_constraints"}, {"score": 0.0033981387193790353, "phrase": "\"best\"_subset"}, {"score": 0.0033110234463504125, "phrase": "user-specified_objective-e.g"}, {"score": 0.002929394386754424, "phrase": "non-active_camera"}, {"score": 0.0028969560940141233, "phrase": "main_idea"}, {"score": 0.002822652835367827, "phrase": "sensor_semantics"}, {"score": 0.0027097117582440687, "phrase": "dynamic_probabilistic_model"}, {"score": 0.002689666606553487, "phrase": "motion_correlations"}, {"score": 0.002543967677678384, "phrase": "previous_work"}, {"score": 0.0025157865918985704, "phrase": "probabilistic_models"}, {"score": 0.002353120949568249, "phrase": "camera_network"}, {"score": 0.0022927343007881846, "phrase": "sensor_network"}, {"score": 0.002267329954548889, "phrase": "dozen_cameras"}, {"score": 0.0022338938462817867, "phrase": "university_building"}, {"score": 0.0021927897271015657, "phrase": "unscripted_human_activity"}, {"score": 0.002120694858618692, "phrase": "semantic_model"}, {"score": 0.0021049977753042253, "phrase": "typical_behaviors"}], "paper_keywords": ["Video surveillance", " Algorithms", " Sensor network", " Real-time"], "paper_abstract": "A distributed camera network allows for many compelling applications such as large-scale tracking or event detection. In most practical systems, resources are constrained. Although one would like to probe every camera at every time instant and store every frame, this is simply not feasible. Constraints arise from network bandwidth restrictions, I/O and disk usage from writing images, and CPU usage needed to extract features from the images. Assume that, due to resource constraints, only a subset of sensors can be probed at any given time unit. This paper examines the problem of selecting the \"best\" subset of sensors to probe under some user-specified objective-e.g., detecting as much motion as possible. With this objective, we would like to probe a camera when we expect motion, but would not like to waste resources on a non-active camera. The main idea behind our approach is the use of sensor semantics to guide the scheduling of resources. We learn a dynamic probabilistic model of motion correlations between cameras, and use the model to guide resource allocation for our sensor network. Although previous work has leveraged probabilistic models for sensor-scheduling, our work is distinct in its focus on real-time building-monitoring using a camera network. We validate our approach on a sensor network of a dozen cameras spread throughout a university building, recording measurements of unscripted human activity over a two week period. We automatically learnt a semantic model of typical behaviors, and show that one can significantly improve efficiency of resource allocation by exploiting this model.", "paper_title": "SEMARTCam scheduler: semantics driven real-time data collection from indoor camera networks to maximize event detection", "paper_id": "WOS:000284330400002"}