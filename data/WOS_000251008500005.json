{"auto_keywords": [{"score": 0.045492676640370204, "phrase": "population_metaheuristics"}, {"score": 0.00481495049065317, "phrase": "comprehending_metaheuristics"}, {"score": 0.00445712058827745, "phrase": "hard_optimization_problems"}, {"score": 0.00406250784433007, "phrase": "purely_algorithmic_angle"}, {"score": 0.0033486631403337555, "phrase": "probabilistic_sampling"}, {"score": 0.0032718761046588835, "phrase": "objective_function"}, {"score": 0.002476546030310661, "phrase": "adaptive_learning_search"}, {"score": 0.0021049977753042253, "phrase": "concrete_examples"}], "paper_keywords": ["metaheuristics", " hard optimization", " evolutionary algorithm", " ant colony algorithm", " simulated annealing", " estimation of distribution", " optimization framework", " software", " performance assessment"], "paper_abstract": "The majority of the algorithms used to solve hard optimization problems today are population metaheuristics. These methods are often presented under a purely algorithmic angle, while insisting on the metaphors which led to their design. We propose in this article to regard population metaheuristics as methods making evolution a probabilistic sampling of the objective function, either explicitly, implicitly, or directly, via processes of learning, diversification, and intensification. We present a synthesis of some metaheuristics and their functioning seen under this angle,called Adaptive Learning Search. We discuss how to design metaheuristics following this approach, and propose an implementation with our Open Metaheuristics framework, along with concrete examples.", "paper_title": "Adaptive learning search, a new tool to help comprehending metaheuristics", "paper_id": "WOS:000251008500005"}