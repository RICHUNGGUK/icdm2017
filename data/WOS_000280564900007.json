{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "top-k_frequent_itemsets"}, {"score": 0.017435529359566344, "phrase": "upper_bound"}, {"score": 0.007344451873424977, "phrase": "actual_top-k_frequent_itemsets"}, {"score": 0.006589501510134992, "phrase": "progressive_sampling_approach"}, {"score": 0.0037249113156851013, "phrase": "itemsets'_frequencies"}, {"score": 0.00367658459781873, "phrase": "bounded_error"}, {"score": 0.0035507457285983268, "phrase": "sample_size"}, {"score": 0.0034143003168921114, "phrase": "random_sample"}, {"score": 0.0032263862712733934, "phrase": "specified_value"}, {"score": 0.002931569771634119, "phrase": "suitable_stopping_conditions"}, {"score": 0.002880927789104712, "phrase": "appropriate_inputs"}, {"score": 0.002818850283787242, "phrase": "approximate_top-k_frequent_itemsets"}, {"score": 0.0027104531025934865, "phrase": "general_upper"}, {"score": 0.0026175952455594277, "phrase": "stopping_conditions"}, {"score": 0.0024306740161601625, "phrase": "small_w."}, {"score": 0.00226693109377084, "phrase": "bloom_filters"}, {"score": 0.0021049977753042253, "phrase": "original_dataset"}], "paper_keywords": ["Sampling", " Top-K frequent itemsets", " Frequent itemsets mining", " Bloom filters", " Progressive sampling"], "paper_abstract": "We study the use of sampling for efficiently mining the top-K frequent itemsets of cardinality at most w. To this purpose, we define an approximation to the top-K frequent itemsets to be a family of itemsets which includes (resp., excludes) all very frequent (resp., very infrequent) itemsets, together with an estimate of these itemsets' frequencies with a bounded error. Our first result is an upper bound on the sample size which guarantees that the top-K frequent itemsets mined from a random sample of that size approximate the actual top-K frequent itemsets, with probability larger than a specified value. We show that the upper bound is asymptotically tight when w is constant. Our main algorithmic contribution is a progressive sampling approach, combined with suitable stopping conditions, which on appropriate inputs is able to extract approximate top-K frequent itemsets from samples whose sizes are smaller than the general upper bound. In order to test the stopping conditions, this approach maintains the frequency of all itemsets encountered, which is practical only for small w. However, we show how this problem can be mitigated by using a variation of Bloom filters. A number of experiments conducted on both synthetic and real benchmark datasets show that using samples substantially smaller than the original dataset (i.e., of size defined by the upper bound or reached through the progressive sampling approach) enable to approximate the actual top-K frequent itemsets with accuracy much higher than what analytically proved.", "paper_title": "Mining top-K frequent itemsets through progressive sampling", "paper_id": "WOS:000280564900007"}