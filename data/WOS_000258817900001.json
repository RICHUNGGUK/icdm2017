{"auto_keywords": [{"score": 0.041207822243040246, "phrase": "proposed_method"}, {"score": 0.021788778796328102, "phrase": "svm"}, {"score": 0.010612387000973441, "phrase": "iris_recognition_systems"}, {"score": 0.009322116731981207, "phrase": "wavelet-based_method"}, {"score": 0.004703324236051336, "phrase": "new_focus_assessment_method"}, {"score": 0.004429627234967641, "phrase": "vapnik"}, {"score": 0.0043608674815879345, "phrase": "statistical_learning_theory"}, {"score": 0.004338186326760738, "phrase": "john_wiley"}, {"score": 0.004128489013513603, "phrase": "high_and_low-frequency_sub-band_averages"}, {"score": 0.004032712685822676, "phrase": "focused_and_defocused_image"}, {"score": 0.003980463173701481, "phrase": "focus_value"}, {"score": 0.003959752657656169, "phrase": "input_values"}, {"score": 0.0038982628940954405, "phrase": "distinctive_advantages"}, {"score": 0.003778122295696292, "phrase": "proposed_wavelet-based_method"}, {"score": 0.0037389008316269716, "phrase": "omni-directional_high-frequency"}, {"score": 0.003680827933437776, "phrase": "iris_patterns"}, {"score": 0.0036142111184389266, "phrase": "slight_defocusing"}, {"score": 0.0035395474074405935, "phrase": "high_and_low-frequency_sub-bands"}, {"score": 0.0034573864329600413, "phrase": "error_rate"}, {"score": 0.003394799755533929, "phrase": "optimum_threshold"}, {"score": 0.0033595442220352633, "phrase": "processing_time"}, {"score": 0.0032644618237574765, "phrase": "maximum_speeds"}, {"score": 0.0032389990161618178, "phrase": "previous_spatial_domain_methods"}, {"score": 0.003222141717761441, "phrase": "kang"}, {"score": 0.0031146241114474427, "phrase": "fast_iris_restoration"}, {"score": 0.003090326414654403, "phrase": "focus_checking"}, {"score": 0.0030582251537586837, "phrase": "lncs"}, {"score": 0.0029407695867562536, "phrase": "daugman"}, {"score": 0.0028875076263279917, "phrase": "iris_recognition"}, {"score": 0.0028426209019228694, "phrase": "circuits_systems_video_technol"}, {"score": 0.0027838622573550355, "phrase": "wei"}, {"score": 0.002697966531825203, "phrase": "cui"}, {"score": 0.0026215563658729757, "phrase": "iris_image_quality"}, {"score": 0.0025340345255790517, "phrase": "reference_criteria"}, {"score": 0.0024881209169317236, "phrase": "focus_measures"}, {"score": 0.0024558344356654413, "phrase": "schematic_model"}, {"score": 0.002430306426446819, "phrase": "pixel_size"}, {"score": 0.0023369118494234484, "phrase": "performance_rate"}, {"score": 0.0023247328402019743, "phrase": "daugman's_kernel"}, {"score": 0.002312617155763442, "phrase": "kang's_kernel"}, {"score": 0.002300564468380128, "phrase": "wei's_kernel"}, {"score": 0.0022885744520045105, "phrase": "kautsky's_method"}, {"score": 0.002247098260686729, "phrase": "five_different_types"}, {"score": 0.0022006144972018526, "phrase": "best_performance"}, {"score": 0.002127116019185069, "phrase": "yonsei_database"}, {"score": 0.0021050260912150354, "phrase": "er"}], "paper_keywords": ["focus assessment method", " iris recognition", " wavelet", " SVM (support vector machine)"], "paper_abstract": "In this paper, we propose a new focus assessment method (focus method) for iris recognition systems, which combines the wavelet transform method and the SVM (support vector machine) [Vapnik, V., 1998. Statistical Learning Theory. John Wiley & Sons, NY, USA]. The wavelet-based method estimates focus values by using the ratio of high and low-frequency sub-band averages. The SVM find optimal decision boundary between focused and defocused image with image brightness and focus value as input values. The proposed method has shown distinctive advantages in terms of the following four points. First, by using the proposed wavelet-based method, it detects omni-directional high-frequency which is the characteristic of iris patterns. Second, proposed method can detect slight defocusing of images by using the average of high and low-frequency sub-bands simultaneously. Third, the SVM reduces the error rate of the wavelet-based method by finding the optimum threshold. Fourth, processing time is reduced. It is 213 times faster than the maximum speeds compared with previous spatial domain methods [Kang, B., Park, K., 2006. A study on fast iris restoration based on focus checking. In: LNCS (AMDO 2006), vol. 4069, pp. 19-28; Daugman, J.G., 2004. How iris recognition works. IEEE Trans. Circuits Systems Video Technol. 14, 21-30: Wei, Z., Tan, T., Sun, Z., Cui, J., 2005. Robust and Face Assessment of Iris Image Quality. ICB. pp. 464-471]. For making the reference criteria to compare with the result of focus measures, we propose a schematic model for evaluating the pixel size of SR (specular reflection) in the cornea. To compare with the performance rate, Daugman's kernel, Kang's kernel, Wei's kernel and Kautsky's method are tested with the proposed method using five different types of data. The proposed method showed the best performance and has shown 3.03% of ER (error rate) using the Yonsei database and 2.62% of ER using the UBIRIS. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "New focus assessment method for iris recognition systems", "paper_id": "WOS:000258817900001"}