{"auto_keywords": [{"score": 0.05007347285230457, "phrase": "scala"}, {"score": 0.040043316347254894, "phrase": "gpu"}, {"score": 0.00801665445736467, "phrase": "code_trees"}, {"score": 0.004774324145784758, "phrase": "recent_advances"}, {"score": 0.004615202066192795, "phrase": "general-purpose_parallel_processors"}, {"score": 0.004186534737631288, "phrase": "programming_model"}, {"score": 0.0037495207047193034, "phrase": "dynamic_memory_allocation"}, {"score": 0.0034738975998176323, "phrase": "good_performance"}, {"score": 0.0034445472801689046, "phrase": "gpu_programmers"}, {"score": 0.003259702394241964, "phrase": "gpu_memory"}, {"score": 0.003204841443605308, "phrase": "different_levels"}, {"score": 0.0031643005824589917, "phrase": "gpu_memory_hierarchy"}, {"score": 0.0031110402375026016, "phrase": "firepile"}, {"score": 0.0030457198309616694, "phrase": "gpu_programming"}, {"score": 0.0028457440091791252, "phrase": "gpu._code_trees"}, {"score": 0.002785978280998868, "phrase": "run-time_function_values"}, {"score": 0.002658863179011018, "phrase": "gpu_code"}, {"score": 0.0026252106881752067, "phrase": "key_property"}, {"score": 0.0023708445073819277, "phrase": "library_interface"}, {"score": 0.00227225841515826, "phrase": "library_writers"}, {"score": 0.002215081186105616, "phrase": "firepile_users"}, {"score": 0.0021593396036472777, "phrase": "c_code"}], "paper_keywords": ["Languages", " GPU", " Scala", " OpenCL", " run-time code generation"], "paper_abstract": "Recent advances have enabled GPUs to be used as general-purpose parallel processors on commodity hardware for little cost. However, the ability to program these devices has not kept up with their performance. The programming model for GPUs has a number of restrictions that make it difficult to program. For example, software running on the GPU cannot perform dynamic memory allocation, requiring the programmer to pre-allocate all memory the GPU might use. To achieve good performance, GPU programmers must also be aware of how data is moved between host and GPU memory and between the different levels of the GPU memory hierarchy. We describe Firepile, a library for GPU programming in Scala. The library enables a subset of Scala to be executed on the GPU. Code trees can be created from run-time function values, which can then be analyzed and transformed to generate GPU code. A key property of this mechanism is that it is modular: unlike with other meta-programming constructs, the use of code trees need not be exposed in the library interface. Code trees are general and can be used by library writers in other application domains. Our experiments show Firepile users can achieve performance comparable to C code targeted to the GPU with shorter, simpler, and easier-to-understand code.", "paper_title": "Firepile: Run-time Compilation for GPUs in Scala", "paper_id": "WOS:000303558100015"}