{"auto_keywords": [{"score": 0.049445419527232116, "phrase": "cache_configurations"}, {"score": 0.04850996534936056, "phrase": "cache_performance"}, {"score": 0.00481495049065317, "phrase": "program_inputs"}, {"score": 0.004595529592539951, "phrase": "understanding_cache_behavior"}, {"score": 0.00421410521089045, "phrase": "cache_behavior"}, {"score": 0.004103212598803194, "phrase": "data_input_sets"}, {"score": 0.0038900709793274484, "phrase": "locality_analysis"}, {"score": 0.00378767277402891, "phrase": "parameterized_model"}, {"score": 0.003737485125097945, "phrase": "program_cache_behavior"}, {"score": 0.0036390887584943723, "phrase": "cache_size"}, {"score": 0.003449972561293443, "phrase": "miss_rate"}, {"score": 0.003404244237372396, "phrase": "arbitrary_data_input_set_sizes"}, {"score": 0.0032706520949775065, "phrase": "critical_data_input_sizes"}, {"score": 0.003163326114997034, "phrase": "marked_changes"}, {"score": 0.0029394074636168435, "phrase": "hit_rate"}, {"score": 0.002881130228859848, "phrase": "associative_caches"}, {"score": 0.0027865506182608263, "phrase": "floating-point_and_integer_programs"}, {"score": 0.0027131212233443137, "phrase": "pointer-based_data_structures"}, {"score": 0.0026240423738883704, "phrase": "new_model"}, {"score": 0.002520990102833368, "phrase": "interactive_visualization_tool"}, {"score": 0.0024545413637350765, "phrase": "three-dimensional_plot"}, {"score": 0.002389839896897424, "phrase": "rate_changes"}, {"score": 0.00235813005446246, "phrase": "program_data_sizes"}, {"score": 0.0023268399760599336, "phrase": "cache_sizes"}, {"score": 0.002250415129116109, "phrase": "compiler_transformations"}, {"score": 0.0021764949731965656, "phrase": "visualization_tool"}, {"score": 0.0021049977753042253, "phrase": "benchmark-set_design"}], "paper_keywords": ["cache memories", " modeling techniques", " performance analysis and design aids", " compilers", " optimization"], "paper_abstract": "Improving cache performance requires understanding cache behavior. However, measuring cache performance for one or two data input sets provides little insight into how cache behavior varies across all data input sets and all cache configurations. This paper uses locality analysis to generate a parameterized model of program cache behavior. Given a cache size and associativity, this model predicts the miss rate for arbitrary data input set sizes. This model also identifies critical data input sizes where cache behavior exhibits marked changes. Experiments show this technique is within 2 percent of the hit rate for set associative caches on a set of floating-point and integer programs using array and pointer-based data structures. Building on the new model, this paper presents an interactive visualization tool that uses a three-dimensional plot to show miss rate changes across program data sizes and cache sizes and its use in evaluating compiler transformations. Other uses of this visualization tool include assisting machine and benchmark-set design. The tool can be accessed on the Web at http://www.cs.rochester.edu/research/locality.", "paper_title": "Miss rate prediction across program inputs and cache configurations", "paper_id": "WOS:000243558500004"}