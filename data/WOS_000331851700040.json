{"auto_keywords": [{"score": 0.04573228268553137, "phrase": "sparse_representation_structure"}, {"score": 0.041300200338926535, "phrase": "srda"}, {"score": 0.00481495049065317, "phrase": "regularization_discriminant_analysis"}, {"score": 0.004761494044422926, "phrase": "face_recognition"}, {"score": 0.00465634671242413, "phrase": "underlying_sparse_representation_structure"}, {"score": 0.0046046429665581555, "phrase": "high_dimensional_data"}, {"score": 0.004528156929805637, "phrase": "considerable_interests"}, {"score": 0.004477870190590885, "phrase": "pattern_recognition"}, {"score": 0.004428139418750855, "phrase": "computer_vision"}, {"score": 0.004306205029641728, "phrase": "sparse_reconstructive_relationship"}, {"score": 0.004027031316965272, "phrase": "novel_dimensionality_reduction_method"}, {"score": 0.0039822874870125095, "phrase": "sparse_regularization_discriminant_analysis"}, {"score": 0.0036214184763804034, "phrase": "efficient_discriminating_subspace"}, {"score": 0.0034437574674180365, "phrase": "concatenated_dictionary"}, {"score": 0.003405472159599442, "phrase": "class-wise_pca_decompositions"}, {"score": 0.003349021846840345, "phrase": "pca"}, {"score": 0.0030967107893195246, "phrase": "constructed_dictionary"}, {"score": 0.0030451958332949735, "phrase": "matrix-vector_multiplications"}, {"score": 0.002800158709933889, "phrase": "learned_sparse_representation_structure"}, {"score": 0.0027535633837592597, "phrase": "regularization_term"}, {"score": 0.002618366076489732, "phrase": "optimal_embedding"}, {"score": 0.0024897902536499005, "phrase": "generalized_eigenvalue_problem"}, {"score": 0.00244834685428352, "phrase": "extensive_and_promising_experimental_results"}, {"score": 0.0023941628577473606, "phrase": "yale"}, {"score": 0.002354302193867031, "phrase": "yale_b"}, {"score": 0.00232810507911235, "phrase": "orl"}, {"score": 0.0023021915971924967, "phrase": "cmu"}, {"score": 0.002176887956041267, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Subspace learning", " Sparse representation", " Class-wise PCA decompositions", " Linear discriminant analysis", " Face recognition"], "paper_abstract": "Recently the underlying sparse representation structure in high dimensional data has attracted considerable interests in pattern recognition and computer vision. Sparse representation structure means the sparse reconstructive relationship of the data. In this paper, we propose a novel dimensionality reduction method called Sparse Regularization Discriminant Analysis (SRDA), which aims to preserve the sparse representation structure of the data when learning an efficient discriminating subspace. More specifically, SRDA first constructs a concatenated dictionary through class-wise PCA decompositions which conduct PCA on data from each class separately, and learns the sparse representation structure under the constructed dictionary quickly through matrix-vector multiplications. Then SRDA takes into account both the sparse representation structure and the discriminating efficiency by using the learned sparse representation structure as a regularization term of linear discriminant analysis. Finally, the optimal embedding of the data is learned via solving a generalized eigenvalue problem. The extensive and promising experimental results on four publicly available face data sets (Yale, Extended Yale B, ORL and CMU PIE) validate the feasibility and effectiveness of the proposed method. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Sparse regularization discriminant analysis for face recognition", "paper_id": "WOS:000331851700040"}