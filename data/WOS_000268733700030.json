{"auto_keywords": [{"score": 0.049418985040378574, "phrase": "selective_reduction"}, {"score": 0.04876768085416924, "phrase": "target_levels"}, {"score": 0.03307663719414094, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "neural_classifiers"}, {"score": 0.00436890075128947, "phrase": "training_samples"}, {"score": 0.004278807087784626, "phrase": "machine_classifier"}, {"score": 0.004104132253183181, "phrase": "auxiliary_classifier"}, {"score": 0.0038822311096089307, "phrase": "expressive_power"}, {"score": 0.0037236852537136547, "phrase": "output_level"}, {"score": 0.0036722834182246933, "phrase": "well-classified_samples"}, {"score": 0.0034736499231079083, "phrase": "iterative_form"}, {"score": 0.003285725064532174, "phrase": "simple_linear_reduction_schedule"}, {"score": 0.0029602552900111433, "phrase": "conventional_training"}, {"score": 0.002899125545529459, "phrase": "static_versions"}, {"score": 0.002685558057339722, "phrase": "vector_machines"}, {"score": 0.002575756583567029, "phrase": "potential_advantage"}, {"score": 0.0024876840172100567, "phrase": "smaller_size"}, {"score": 0.002436289099444074, "phrase": "design_effort"}, {"score": 0.002336655334451466, "phrase": "corresponding_svm"}, {"score": 0.0021947755130109696, "phrase": "practical_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Artificial neural networks", " Classification", " Learning algorithm", " Reduced target level", " Sample selection"], "paper_abstract": "Reducing the level of the targets corresponding to training samples for a machine classifier using the outputs of an auxiliary classifier is interesting because it allows to save expressive power unnecessarily dedicated to increase the output level of well-classified samples. In this paper we propose an iterative form of this selective reduction of target levels with a simple linear reduction schedule. Extensive simulations show that the proposed method has not only a performance better than or equal to conventional training or using static versions of the reduction, but also with respect to support vector machines (SVM). This potential advantage is accompanied by a smaller size and a design effort not much higher than the corresponding SVM, thus making the proposed method very attractive for practical applications. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Improving performance of neural classifiers via selective reduction of target levels", "paper_id": "WOS:000268733700030"}