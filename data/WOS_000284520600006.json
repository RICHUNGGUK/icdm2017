{"auto_keywords": [{"score": 0.04313137598710988, "phrase": "intensity_image"}, {"score": 0.030328139665828313, "phrase": "motion_context"}, {"score": 0.024502760290459967, "phrase": "recognition_rate"}, {"score": 0.004765173195920904, "phrase": "harmonic_motion_context"}, {"score": 0.004571133708117502, "phrase": "view-invariant_gesture_recognition"}, {"score": 0.0036363418376496484, "phrase": "data_fusion"}, {"score": 0.0035245918797629804, "phrase": "motion_detection"}, {"score": 0.003434085751246066, "phrase": "better_recognition"}, {"score": 0.00339853518227171, "phrase": "gesture_recognition"}, {"score": 0.00331125524068286, "phrase": "motion_primitives"}, {"score": 0.0030625949549620475, "phrase": "optical_flow"}, {"score": 0.002983916676307492, "phrase": "annotated_point_clouds"}, {"score": 0.002759769970554556, "phrase": "view-invariant_representation"}, {"score": 0.0027311809666295565, "phrase": "spherical_harmonic_basis_functions"}, {"score": 0.0026888503045081505, "phrase": "harmonic_motion_context_representation"}, {"score": 0.0026609940110902666, "phrase": "probabilistic_edit_distance_classifier"}], "paper_keywords": ["Time of Flight camera", " Action recognition", " View invariant", " Motion primitives", " Optical flow", " Spherical harmonics"], "paper_abstract": "This paper presents an approach for view-invariant gesture recognition The approach is based on 3D data captured by a SwissRanger SR4000 camera This camera produces both a depth map as well as an intensity Image of a scene Since the two information types are aligned we can use the intensity Image to define a region of interest for the relevant 3D data This data fusion improves the quality of the motion detection and hence results in better recognition The gesture recognition is based on finding motion primitives (temporal instances) in the 3D data Motion is detected by a 3D version of optical flow and results in velocity annotated point clouds The 3D motion primitives are represented efficiently by introducing motion context The motion context is transformed into a view-invariant representation using spherical harmonic basis functions yielding a harmonic motion context representation A probabilistic Edit Distance classifier is applied to identify which gesture best describes a string of primitives The approach is trained on data from one viewpoint and tested on data from a very different viewpoint The recognition rate is 94 4% which is similar to the recognition rate when training and testing on gestures from the same viewpoint hence the approach is indeed view-invariant (C) 2010 Elsevier Inc All rights reserved", "paper_title": "View-invariant gesture recognition using 3D optical flow and harmonic motion context", "paper_id": "WOS:000284520600006"}