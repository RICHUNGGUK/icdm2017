{"auto_keywords": [{"score": 0.03665878723559446, "phrase": "starpu"}, {"score": 0.00481495049065317, "phrase": "heterogeneous_multicore_architectures"}, {"score": 0.004691659072594037, "phrase": "hpc"}, {"score": 0.004631099806015235, "phrase": "current_hardware_trend"}, {"score": 0.004551647527068771, "phrase": "multiprocessor_architectures"}, {"score": 0.0045124316982387315, "phrase": "heterogeneous_technologies"}, {"score": 0.004454237726525018, "phrase": "specialized_coprocessors"}, {"score": 0.004138309011478741, "phrase": "theoretical_performance"}, {"score": 0.00403221710768334, "phrase": "complex_issue"}, {"score": 0.003962998498942108, "phrase": "substantial_efforts"}, {"score": 0.0038447018470115146, "phrase": "offload_parts"}, {"score": 0.003697760799674494, "phrase": "execution_model"}, {"score": 0.003634262647873338, "phrase": "computing_units"}, {"score": 0.003602922164562919, "phrase": "associated_embedded_memory"}, {"score": 0.0035564156572789473, "phrase": "main_challenge"}, {"score": 0.0032896745636186824, "phrase": "expressive_data_management_library"}, {"score": 0.0032471982781283374, "phrase": "main_goal"}, {"score": 0.003163878786694538, "phrase": "numerical_kernel_designers"}, {"score": 0.0031230216871739776, "phrase": "convenient_way"}, {"score": 0.00308269056870936, "phrase": "parallel_tasks"}, {"score": 0.0030560920414081645, "phrase": "heterogeneous_hardware"}, {"score": 0.0029264925857346497, "phrase": "powerful_scheduling_algorithms"}, {"score": 0.0026033013834547507, "phrase": "multiple_cores"}, {"score": 0.002525489173110693, "phrase": "substantial_improvements"}, {"score": 0.0025036862991477437, "phrase": "execution_times"}, {"score": 0.002449997042686432, "phrase": "consistent_superlinear_parallelism"}, {"score": 0.0023974563359295043, "phrase": "heterogeneous_nature"}, {"score": 0.002266051712795851, "phrase": "highly_optimized_magma_library"}, {"score": 0.0021982976170703884, "phrase": "corresponding_static_scheduling"}, {"score": 0.002169882514603539, "phrase": "portable_way"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["GPU", " multicore", " accelerator", " scheduling", " runtime system"], "paper_abstract": "In the field of HPC, the current hardware trend is to design multiprocessor architectures featuring heterogeneous technologies such as specialized coprocessors (e.g. Cell/BE) or data-parallel accelerators (e.g. GPUs). Approaching the theoretical performance of these architectures is a complex issue. Indeed, substantial efforts have already been devoted to efficiently offload parts of the computations. However, designing an execution model that unifies all computing units and associated embedded memory remains a main challenge. We therefore designed StarPU, an original runtime system providing a high-level, unified execution model tightly coupled with an expressive data management library. The main goal of StarPU is to provide numerical kernel designers with a convenient way to generate parallel tasks over heterogeneous hardware on the one hand, and easily develop and tune powerful scheduling algorithms on the other hand. We have developed several strategies that can be selected seamlessly at run-time, and we have analyzed their efficiency on several algorithms running simultaneously over multiple cores and a GPU. In addition to substantial improvements regarding execution times, we have obtained consistent superlinear parallelism by actually exploiting the heterogeneous nature of the machine. We eventually show that our dynamic approach competes with the highly optimized MAGMA library and overcomes the limitations of the corresponding static scheduling in a portable way. Copyright (C) 2010 John Wiley & Sons, Ltd.", "paper_title": "StarPU: a unified platform for task scheduling on heterogeneous multicore architectures", "paper_id": "WOS:000285979600005"}