{"auto_keywords": [{"score": 0.03895000187878607, "phrase": "proposed_neural_network"}, {"score": 0.008713768692145006, "phrase": "recurrent_neural_network"}, {"score": 0.00832193467288963, "phrase": "genetic_regulatory_networks"}, {"score": 0.007947579078299969, "phrase": "non-smooth_convex_optimization_problem"}, {"score": 0.00755119575489577, "phrase": "objective_function"}, {"score": 0.007474305596954145, "phrase": "inequality_constraints"}, {"score": 0.004765788394931875, "phrase": "non-smooth_convex_optimization_problems"}, {"score": 0.004256895619944631, "phrase": "linear_equality_constraints"}, {"score": 0.003982011128052839, "phrase": "clarke's_generalized_gradients"}, {"score": 0.003574830654211291, "phrase": "equilibrium_point"}, {"score": 0.003413284742632989, "phrase": "optimal_solution"}, {"score": 0.003361069456060196, "phrase": "original_optimization_problem"}, {"score": 0.003292685392413911, "phrase": "lagrangian_saddle-point_theorem"}, {"score": 0.002986329509791943, "phrase": "neural_network"}, {"score": 0.0028221322455573624, "phrase": "existing_neural_network_models"}, {"score": 0.002793260314529583, "phrase": "non-smooth_optimization_problems"}, {"score": 0.0026806884201358515, "phrase": "larger_class"}, {"score": 0.002559444836360178, "phrase": "penalty_method"}, {"score": 0.0024186620196958867, "phrase": "identification_problem"}, {"score": 0.0022161333611134806, "phrase": "satisfactory_identification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "proposed_approach"}], "paper_keywords": ["Convex", " genetic regulatory network", " identification", " non-smooth optimization problem", " recurrent neural network"], "paper_abstract": "A recurrent neural network is proposed for solving the non-smooth convex optimization problem with the convex inequality and linear equality constraints. Since the objective function and inequality constraints may not be smooth, the Clarke's generalized gradients of the objective function and inequality constraints are employed to describe the dynamics of the proposed neural network. It is proved that the equilibrium point set of the proposed neural network is equivalent to the optimal solution of the original optimization problem by using the Lagrangian saddle-point theorem. Under weak conditions, the proposed neural network is proved to be stable, and the state of the neural network is convergent to one of its equilibrium points. Compared with the existing neural network models for non-smooth optimization problems, the proposed neural network can deal with a larger class of constraints and is not based on the penalty method. Finally, the proposed neural network is used to solve the identification problem of genetic regulatory networks, which can be transformed into a non-smooth convex optimization problem. The simulation results show the satisfactory identification accuracy, which demonstrates the effectiveness and efficiency of the proposed approach.", "paper_title": "Recurrent Neural Network for Non-Smooth Convex Optimization Problems With Application to the Identification of Genetic Regulatory Networks", "paper_id": "WOS:000290414400004"}