{"auto_keywords": [{"score": 0.04812305996521059, "phrase": "noise_reduction"}, {"score": 0.00481495049065317, "phrase": "instance-based_learning"}, {"score": 0.004760518730536645, "phrase": "local_maximal_margin_approach"}, {"score": 0.004583464412234181, "phrase": "machine_learning"}, {"score": 0.0041374874583908535, "phrase": "noise_tolerant_and_noise_reduction"}, {"score": 0.004075198669927074, "phrase": "important_role"}, {"score": 0.0040444053843446326, "phrase": "k-nearest_neighbour_classification"}, {"score": 0.0037774893672602506, "phrase": "simpler_models"}, {"score": 0.003748937184382714, "phrase": "data_cleansing"}, {"score": 0.0035550029054401016, "phrase": "novel_approach"}, {"score": 0.0034881908940439213, "phrase": "local_support_vector_machines"}, {"score": 0.003371066990851953, "phrase": "maximal_margin_classifiers"}, {"score": 0.0032209766681045365, "phrase": "majority_rule"}, {"score": 0.0031845067058084583, "phrase": "almost_all_the_existing_noise_reduction_techniques"}, {"score": 0.0030775481952377017, "phrase": "training_example"}, {"score": 0.0030543340648308812, "phrase": "svm"}, {"score": 0.0029629009627331355, "phrase": "svm_classification"}, {"score": 0.002929344511491418, "phrase": "central_example"}, {"score": 0.0027776899345132193, "phrase": "training_set"}, {"score": 0.0027254466299651936, "phrase": "empirical_evaluation"}, {"score": 0.0026843584448921565, "phrase": "improved_classification_accuracy"}, {"score": 0.00265394824073552, "phrase": "training_data"}, {"score": 0.0025843206540392184, "phrase": "specific_experiments"}, {"score": 0.002555040841339798, "phrase": "spam_filtering_application_domain"}, {"score": 0.002314752262613559, "phrase": "different_class_densities"}, {"score": 0.0022625835448873495, "phrase": "lsvm_noise_reduction"}, {"score": 0.0021948455916770233, "phrase": "real_datasets"}, {"score": 0.002169968849836984, "phrase": "artificial_datasets"}, {"score": 0.0021453734588569823, "phrase": "gaussian_noise"}, {"score": 0.0021049977753042253, "phrase": "uneven_class_densities"}], "paper_keywords": ["Noise reduction", " Editing techniques", " k-NN", " SVM", " Locality"], "paper_abstract": "To some extent the problem of noise reduction in machine learning has been finessed by the development of learning techniques that are noise-tolerant. However, it is difficult to make instance-based learning noise tolerant and noise reduction still plays an important role in k-nearest neighbour classification. There are also other motivations for noise reduction, for instance the elimination of noise may result in simpler models or data cleansing may be an end in itself. In this paper we present a novel approach to noise reduction based on local Support Vector Machines (LSVM) which brings the benefits of maximal margin classifiers to bear on noise reduction. This provides a more robust alternative to the majority rule on which almost all the existing noise reduction techniques are based. Roughly speaking, for each training example an SVM is trained on its neighbourhood and if the SVM classification for the central example disagrees with its actual class there is evidence in favour of removing it from the training set. We provide an empirical evaluation on 15 real datasets showing improved classification accuracy when using training data edited with our method as well as specific experiments regarding the spam filtering application domain. We present a further evaluation on two artificial datasets where we analyse two different types of noise (Gaussian feature noise and mislabelling noise) and the influence of different class densities. The conclusion is that LSVM noise reduction is significantly better than the other analysed algorithms for real datasets and for artificial datasets perturbed by Gaussian noise and in presence of uneven class densities.", "paper_title": "Noise reduction for instance-based learning with a local maximal margin approach", "paper_id": "WOS:000281166100005"}