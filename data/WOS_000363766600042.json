{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "mapreduce"}, {"score": 0.004524624065803229, "phrase": "research_community"}, {"score": 0.004484596684703308, "phrase": "computer_science"}, {"score": 0.004444921827311577, "phrase": "business_executives"}, {"score": 0.004386063799793622, "phrase": "decision_makers"}, {"score": 0.004289686492089576, "phrase": "big_data"}, {"score": 0.004066898031169739, "phrase": "performance-oriented_data-intensive_processing_frameworks"}, {"score": 0.0038900709793274484, "phrase": "large_commodity_clusters"}, {"score": 0.0038556354709511818, "phrase": "hadoop_mapreduce"}, {"score": 0.00378767277402891, "phrase": "hadoop_distributed_file_system"}, {"score": 0.003687960013746783, "phrase": "yarn_fair_scheduler"}, {"score": 0.0036553070575015344, "phrase": "capacity_scheduler"}, {"score": 0.003543273649210823, "phrase": "dynamic_changes"}, {"score": 0.0034807976670686628, "phrase": "operating_environments"}, {"score": 0.003073154478201771, "phrase": "virtual_machines"}, {"score": 0.0030189426536422577, "phrase": "different_hardware"}, {"score": 0.00258347644721642, "phrase": "hadoop_mapreduce_scheduling"}, {"score": 0.0022705467477443417, "phrase": "open_issues"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["scheduling", " task scheduling", " job scheduling", " data-intensive computing", " big data", " cloud"], "paper_abstract": "It is a fact that the attention of research community in computer science, business executives, and decision makers is drastically drawn by big data. As the volume of data becomes bigger, it needs performance-oriented data-intensive processing frameworks such as MapReduce, which can scale computation on large commodity clusters. Hadoop MapReduce processes data in Hadoop Distributed File System as jobs scheduled according to YARN fair scheduler and capacity scheduler. However, with advancement and dynamic changes in hardware and operating environments, the performance of clusters is greatly affected. Various efforts in literature have been made to address the issues of heterogeneity (i.e., clusters consisting of virtual machines and machines with different hardware), network communication, data locality, better resource utilization, and run-time scheduling. In this paper, we present a survey to discuss various research efforts made so far to improve Hadoop MapReduce scheduling. We classify scheduling algorithms and techniques proposed in the literature so far based on their addressing areas and present a taxonomy. Furthermore, we also discuss various aspects of open issues and challenges in the scheduling of MapReduce to improve its performance. Copyright (c) 2015 John Wiley & Sons, Ltd.", "paper_title": "Context-aware scheduling in MapReduce: a compact review", "paper_id": "WOS:000363766600042"}