{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "sufficient_descent_property"}, {"score": 0.004747429622531595, "phrase": "large-scale_unconstrained_optimization"}, {"score": 0.004582722012454012, "phrase": "new_spectral_conjugate_gradient_methods"}, {"score": 0.0042102651938187114, "phrase": "spectral_perry's_conjugate_gradient_method"}, {"score": 0.004064117897000019, "phrase": "best_spectral_conjugate_gradient_algorithm_scg"}, {"score": 0.003950863141407859, "phrase": "martinez"}, {"score": 0.0038953958723049287, "phrase": "e.g._birgin"}, {"score": 0.0038407203087210775, "phrase": "j.m._martinez"}, {"score": 0.003629557750546267, "phrase": "unconstrained_optimization"}, {"score": 0.0035789724961719296, "phrase": "appl"}, {"score": 0.002853808773854451, "phrase": "strongly_convex_functions"}, {"score": 0.002735194789581153, "phrase": "global_convergent"}, {"score": 0.002640114583897493, "phrase": "global_convergence_result"}, {"score": 0.002603012037901889, "phrase": "nonconvex_minimization"}, {"score": 0.0025125151618810523, "phrase": "line_search"}, {"score": 0.0024597305738431226, "phrase": "wolfe_line_search_conditions"}, {"score": 0.002275477757478827, "phrase": "numerical_comparisons"}, {"score": 0.002196342933346204, "phrase": "scg_and_cg_descent_methods"}, {"score": 0.0021501863832966966, "phrase": "unconstrained_optimization_problems"}, {"score": 0.0021049977753042253, "phrase": "cute_library"}], "paper_keywords": ["unconstrained optimization", " spectral conjugate gradient method", " large-scale optimization", " global convergence"], "paper_abstract": "A class of new spectral conjugate gradient methods are proposed in this paper. First, we modify the spectral Perry's conjugate gradient method, which is the best spectral conjugate gradient algorithm SCG by Birgin and Martinez [E.G. Birgin and J.M. Martinez, A spectral conjugate gradient method for unconstrained optimization, Appl. Math. Optim. 43 (2001), 117-128.], such that it possesses sufficient descent property for any (inexact) line search. It is shown that, for strongly convex functions, the method is a global convergent. Further, a global convergence result for nonconvex minimization is established when the line search fulfils the Wolfe line search conditions. Some other spectral conjugate gradient methods with guaranteed descent are presented here. Numerical comparisons are given with both SCG and CG_DESCENT methods using the unconstrained optimization problems in the CUTE library.", "paper_title": "Spectral conjugate gradient methods with sufficient descent property for large-scale unconstrained optimization", "paper_id": "WOS:000253659400009"}