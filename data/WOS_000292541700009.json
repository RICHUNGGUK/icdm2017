{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "learning_objects"}, {"score": 0.015307431265596982, "phrase": "different_quality_indicators"}, {"score": 0.0038573081851680656, "phrase": "existing_approaches"}, {"score": 0.0037549546301384336, "phrase": "quality_indicators"}, {"score": 0.0029473940028924748, "phrase": "explicit_evaluations"}, {"score": 0.0026823700218343506, "phrase": "usage_data"}, {"score": 0.0023131084326717755, "phrase": "merlot_repository"}, {"score": 0.0021049977753042253, "phrase": "overall_quality_indicator"}], "paper_keywords": ["Learning object", " Merlot", " ranking", " quality"], "paper_abstract": "The solutions used to-date for recommending learning objects have proved unsatisfactory. In an attempt to improve the situation, this document highlights the insufficiencies of the existing approaches, and identifies quality indicators that might be used to provide information on which materials to recommend to users. Next, a synthesized quality indicator that can facilitate the ranking of learning objects, according to their overall quality, is proposed. In this way, explicit evaluations carried out by users or experts will be used, along with the usage data; thus, completing the information on which the recommendation is based. Taking a set of learning objects from the Merlot repository, we analyzed the relationships that exist between the different quality indicators to form an overall quality indicator that can be calculated automatically, guaranteeing that all resources will be rated.", "paper_title": "Ranking Learning Objects through Integration of Different Quality Indicators", "paper_id": "WOS:000292541700009"}