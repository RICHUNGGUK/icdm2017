{"auto_keywords": [{"score": 0.04916809664432026, "phrase": "ppsvm"}, {"score": 0.00481495049065317, "phrase": "posterior_probability_support_vector_machine"}, {"score": 0.004545240514015278, "phrase": "soft_labels"}, {"score": 0.004416079619543104, "phrase": "estimated_posterior_probabilities"}, {"score": 0.003714368305523811, "phrase": "window-based_density_estimator"}, {"score": 0.0035741900278634616, "phrase": "posterior_probabilities"}, {"score": 0.0034392837410790293, "phrase": "binary_classifier"}, {"score": 0.0032777653153451265, "phrase": "neighbor-based_density_estimator"}, {"score": 0.003034916887102753, "phrase": "multiclass_case"}, {"score": 0.002340250894008014, "phrase": "accuracy_results"}, {"score": 0.002145942273032774, "phrase": "canonical_svm"}, {"score": 0.0021049977753042253, "phrase": "significantly_fewer_support_vectors"}], "paper_keywords": ["density estimation", " kernel machines", " multiclass classification", " support vector machines (SVMs)"], "paper_abstract": "Tao et al. have recently proposed the posterior probability support vector machine (PPSVM) which uses soft labels derived from estimated posterior probabilities to be more robust to noise and outliers. Tao et al.'s model uses a window-based density estimator to calculate the posterior probabilities and is a binary classifier. We propose a neighbor-based density estimator and also extend the model to the multiclass case. Our bias-variance analysis shows that the decrease in error by PPSVM is due to a decrease in bias. On 20 benchmark data sets, we observe that PPSVM obtains accuracy results that are higher or comparable to those of canonical SVM using significantly fewer support vectors.", "paper_title": "Multiclass posterior probability support vector machines", "paper_id": "WOS:000252516700011"}