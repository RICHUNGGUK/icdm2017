{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "count_queries"}, {"score": 0.004777569299319633, "phrase": "study_design"}, {"score": 0.004740476936977635, "phrase": "objective_today's_clinical_research_institutions"}, {"score": 0.004471270242168067, "phrase": "patient_privacy"}, {"score": 0.004266907250334316, "phrase": "increased_privacy"}, {"score": 0.004103728794623367, "phrase": "current_query_answer_systems"}, {"score": 0.004040211152784802, "phrase": "quantifiable_level"}, {"score": 0.0037516215763875225, "phrase": "perturbation_mechanism"}, {"score": 0.0034296217420566304, "phrase": "true_count"}, {"score": 0.0034029588672379926, "phrase": "user_preferences"}, {"score": 0.0033502512757488433, "phrase": "privacy_level"}, {"score": 0.003324203391715804, "phrase": "administrator-specified_bounds"}, {"score": 0.0032855095476183372, "phrase": "probability_distribution"}, {"score": 0.003234615195382533, "phrase": "perturbed_count"}, {"score": 0.0031845067058084613, "phrase": "results_users"}, {"score": 0.0030625949549620475, "phrase": "count_perturbation"}, {"score": 0.0029916929549256297, "phrase": "strong_and_semantically_meaningful_differential_privacy"}, {"score": 0.0029110398328258194, "phrase": "unified_privacy_accounting_system"}, {"score": 0.002865929543375884, "phrase": "role-based_trust_levels"}, {"score": 0.0027995677499976406, "phrase": "open_source_web-enabled_tool"}, {"score": 0.002702887319160534, "phrase": "system_parameters"}, {"score": 0.002671406231520296, "phrase": "required_privacy_level"}, {"score": 0.0026506222660465126, "phrase": "user_preference_settings"}, {"score": 0.0025892330566358503, "phrase": "system_administrators"}, {"score": 0.0025292620341476283, "phrase": "privacy_budget"}, {"score": 0.002422890839801611, "phrase": "inevitable_loss"}, {"score": 0.002376027109070317, "phrase": "current_measures"}, {"score": 0.0022672107906933714, "phrase": "future_advances"}, {"score": 0.0022495644368875686, "phrase": "privacy_measurement"}, {"score": 0.002206045784326466, "phrase": "new_ways"}, {"score": 0.0021049977753042253, "phrase": "current_study_design_systems"}], "paper_keywords": [""], "paper_abstract": "Objective Today's clinical research institutions provide tools for researchers to query their data warehouses for counts of patients. To protect patient privacy, counts are perturbed before reporting; this compromises their utility for increased privacy. The goal of this study is to extend current query answer systems to guarantee a quantifiable level of privacy and allow users to tailor perturbations to maximize the usefulness according to their needs. Methods A perturbation mechanism was designed in which users are given options with respect to scale and direction of the perturbation. The mechanism translates the true count, user preferences, and a privacy level within administrator-specified bounds into a probability distribution from which the perturbed count is drawn. Results Users can significantly impact the scale and direction of the count perturbation and can receive more accurate final cohort estimates. Strong and semantically meaningful differential privacy is guaranteed, providing for a unified privacy accounting system that can support role-based trust levels. This study provides an open source web-enabled tool to investigate visually and numerically the interaction between system parameters, including required privacy level and user preference settings. Conclusions Quantifying privacy allows system administrators to provide users with a privacy budget and to monitor its expenditure, enabling users to control the inevitable loss of utility. While current measures of privacy are conservative, this system can take advantage of future advances in privacy measurement. The system provides new ways of trading off privacy and utility that are not provided in current study design systems.", "paper_title": "Protecting count queries in study design", "paper_id": "WOS:000307934600010"}