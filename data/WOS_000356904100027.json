{"auto_keywords": [{"score": 0.04972867160744286, "phrase": "pso"}, {"score": 0.00481495049065317, "phrase": "particle_swarm_optimization"}, {"score": 0.0047273577269638725, "phrase": "social_behavior"}, {"score": 0.0046073860169839305, "phrase": "fish_schooling"}, {"score": 0.004523552067565685, "phrase": "emerging_population-based_meta-heuristic"}, {"score": 0.004473982381245469, "phrase": "population-based_evolutionary_algorithm"}, {"score": 0.0043764594918057915, "phrase": "precise_objectives"}, {"score": 0.004328494656899359, "phrase": "multidimensional_space"}, {"score": 0.0038342108263454628, "phrase": "best_experience"}, {"score": 0.003536346954940087, "phrase": "pso_algorithm"}, {"score": 0.0031553611552558986, "phrase": "local_optima"}, {"score": 0.0031207372860045427, "phrase": "convergence_rate"}, {"score": 0.0030526216870671325, "phrase": "evolutionary_processing"}, {"score": 0.002953217535105884, "phrase": "local_optimum"}, {"score": 0.0028993944292191433, "phrase": "random_value"}, {"score": 0.0027036380093304747, "phrase": "prescribed_probability"}, {"score": 0.002521064923851732, "phrase": "convergence_speed"}, {"score": 0.002502576987281976, "phrase": "search_performance"}, {"score": 0.0024359343539733657, "phrase": "rosenbrock"}, {"score": 0.00240328454980006, "phrase": "standard_pso_algorithm"}, {"score": 0.0023768935613577985, "phrase": "eight_standard_testing_benchmark_functions"}, {"score": 0.0023606162738483267, "phrase": "rastrigin"}, {"score": 0.0022825763382627443, "phrase": "accurate_solution"}, {"score": 0.0021721779757835217, "phrase": "griewank"}, {"score": 0.0021520139248317333, "phrase": "ackley"}, {"score": 0.002148319353505513, "phrase": "salomon"}], "paper_keywords": ["Particle swarm optimization", " Conditional random"], "paper_abstract": "Particle swarm optimization (PSO) simulates social behavior, such as birds flocking or fish schooling. It is an emerging population-based meta-heuristic and a population-based evolutionary algorithm that is used to achieve precise objectives in a multidimensional space. A population (called a swarm) is made up of individuals (called particles) that are updated by iteration. Each particle uses its own best previous experience (pBest) and the best experience (gBest) of all other members to correctly search for a direction. The two important factors are pBest and gBest. A PSO algorithm has four advantages: fewer parameters must be adjusted, it is easy to understand, easy to implement and it is computationally efficient. But it also easily becomes trapped in local optima and the convergence rate is significantly decreased in the latter period of evolutionary processing. The algorithm can easily fall into a local optimum early, because a random value is used to influence the weights of pBest and gBest. This study proposes that, given a prescribed probability that is adjusted randomly, the algorithm is prevented from falling into the local optimum early and the convergence speed and search performance are both improved. This method is compared with a standard PSO algorithm that uses eight standard testing benchmark functions, thirty times. The results show that convergence to an accurate solution is faster for 6 functions (the Sphere, the Rosenbrock, the Rastrigin, the Ackley, the Griewank and the Salomon function). (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "A cautious PSO with conditional random", "paper_id": "WOS:000356904100027"}