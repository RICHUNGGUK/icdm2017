{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "repeated_binary_data"}, {"score": 0.015570484684779675, "phrase": "ibf_sampler"}, {"score": 0.012538536280153488, "phrase": "bayesian_perspective"}, {"score": 0.011651245731599313, "phrase": "mcmc_methods"}, {"score": 0.004738177185041523, "phrase": "hierarchical_models"}, {"score": 0.004662622277282557, "phrase": "promising_tool"}, {"score": 0.004515091332353969, "phrase": "computational_complexity"}, {"score": 0.004233826962599848, "phrase": "computational_difficulties"}, {"score": 0.004206678601411097, "phrase": "maximum_likelihood_estimation"}, {"score": 0.004166280750248375, "phrase": "frequentist_perspective"}, {"score": 0.004113017293557937, "phrase": "j._amer"}, {"score": 0.0039192497049015135, "phrase": "markov_chain_monte_carlo"}, {"score": 0.0036986954643952203, "phrase": "marcel_dekker"}, {"score": 0.0036749658368075027, "phrase": "new_york"}, {"score": 0.003524377837382856, "phrase": "whole_posterior"}, {"score": 0.003379939505148497, "phrase": "markov_chain"}, {"score": 0.0031185531305483703, "phrase": "sinica"}, {"score": 0.003010017873923648, "phrase": "noniterative_sampling_approach"}, {"score": 0.0029810774705309536, "phrase": "inverse_bayes_formulae"}, {"score": 0.002961939701866045, "phrase": "ibf"}, {"score": 0.0028588411455879037, "phrase": "em_algorithm"}, {"score": 0.0027593227272966186, "phrase": "monte_carlo_em"}, {"score": 0.0027416046537446985, "phrase": "mcem"}, {"score": 0.0027065039341671103, "phrase": "hierarchical_model"}, {"score": 0.0026632593674563855, "phrase": "current_methods"}, {"score": 0.0026207039474589, "phrase": "efficient_ibf_sampler"}, {"score": 0.002570531747243578, "phrase": "estimated_posterior_modes"}, {"score": 0.0025458060790109647, "phrase": "mcem_algorithm"}, {"score": 0.002521317643120762, "phrase": "proposed_method"}, {"score": 0.002417887626368368, "phrase": "observed_posterior_distribution"}, {"score": 0.002379243574322898, "phrase": "convergence_problem"}, {"score": 0.0023037942361136205, "phrase": "slow_convergence_problem"}, {"score": 0.0022889932805175406, "phrase": "gibbs_sampler"}, {"score": 0.0022451572368358476, "phrase": "noniterative_ibf_sampler"}, {"score": 0.0022163995544178215, "phrase": "fast_em-type_algorithm"}, {"score": 0.0021809687586808522, "phrase": "six_cities"}, {"score": 0.002139197034966045, "phrase": "children's_ear"}, {"score": 0.0021049977753042253, "phrase": "proposed_methods"}], "paper_keywords": ["Bayesian computation", " Gibbs sampler", " inverse Bayes formulae", " MCMC", " Monte Carlo EM algorithm"], "paper_abstract": "Hierarchical models have emerged as a promising tool for the analysis of repeated binary data. However, the computational complexity in these models have limited their applications in practice. Several approaches have been proposed in the literature to overcome the computational difficulties including maximum likelihood estimation from a frequentist perspective (e.g., J. Amer. Statist. Assoc. 89 (1994) 330-335) and Markov chain Monte Carlo (MCMC) methods from a Bayesian perspective (e.g., Generalized Linear Models: A Bayesian Perspective, Marcel Dekker, New York, pp. 113-131). Although MCMC methods provide the whole posterior of the parameter of interest, the convergence diagnostics problem of the Markov chain and the slow convergence problem owing to the introduction of too many Gaussian latent variables are still unresolved. Recently, Tan et al. (Statist. Sinica 13 (2003) 625-639) proposed a noniterative sampling approach, the inverse Bayes formulae (IBF) sampler, for computing posteriors in the structure of EM algorithm. This article develops the IBF sampler in the structure of Monte Carlo EM (MCEM) for the hierarchical model with repeated binary data for which current methods encounter difficulty. An efficient IBF sampler is implemented by utilizing the estimated posterior modes obtained via MCEM algorithm. The proposed method generates independent and identically distributed (iid) samples approximately from the observed posterior distribution and thus alleviates the convergence problem associated with the MCMC methods. In addition, the slow convergence problem in Gibbs sampler can be bypassed in the noniterative IBF sampler via running some fast EM-type algorithm. Real datasets from six cities children's wheeze study and children's ear fluid study illustrate the proposed methods. (C) 2004 Elsevier B.V. All rights reserved.", "paper_title": "Hierarchical models for repeated binary data using the IBF sampler", "paper_id": "WOS:000234940200007"}