{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "defocused_images"}, {"score": 0.01863618965267845, "phrase": "proposed_method"}, {"score": 0.009826851487925574, "phrase": "imaging_noise"}, {"score": 0.008188678472603938, "phrase": "stable_bits"}, {"score": 0.004775918707955445, "phrase": "mobile_phones."}, {"score": 0.00462291551375938, "phrase": "novel_iris_recognition_approach"}, {"score": 0.0044025116437190785, "phrase": "image_capture"}, {"score": 0.004175533280178052, "phrase": "existing_approaches"}, {"score": 0.004108066884382925, "phrase": "special_hardware"}, {"score": 0.004008897491380646, "phrase": "computationally_expensive_algorithms"}, {"score": 0.0036652492107503956, "phrase": "iris_code_representation"}, {"score": 0.00335095982979018, "phrase": "iris_features"}, {"score": 0.00332375606483146, "phrase": "varying_degree"}, {"score": 0.0032967724149749853, "phrase": "image_defocus"}, {"score": 0.0029652292779277782, "phrase": "enrolled_image"}, {"score": 0.0029053904956617043, "phrase": "iris_recognition"}, {"score": 0.0028236336891860592, "phrase": "entire_code_representation"}, {"score": 0.00278930116312699, "phrase": "proposed_recognition_method"}, {"score": 0.002755384932325921, "phrase": "inter-class_variability"}, {"score": 0.0027108021939930014, "phrase": "intra-class_variability"}, {"score": 0.002613103872300205, "phrase": "smaller_intersections"}, {"score": 0.002560352786969071, "phrase": "inter-class_distance"}, {"score": 0.0024984517279573906, "phrase": "higher_recognition_performance"}, {"score": 0.0024781515864648242, "phrase": "experimental_results"}, {"score": 0.002379092507901856, "phrase": "average_recognition_performance_gain"}, {"score": 0.0022196745041124888, "phrase": "multi-biometric_system"}, {"score": 0.0021049977753042253, "phrase": "power_sensitive_solutions"}], "paper_keywords": ["Iris recognition", " defocused iris image", " depth of field"], "paper_abstract": "In this paper, we introduce a novel iris recognition approach for mobile phones, which takes into account imaging noise arising from image capture outside the depth of field (DOF) of cameras. Unlike existing approaches that rely on special hardware to extend the DOF or computationally expensive algorithms to restore the defocused images prior to recognition, the proposed method performs recognition on the defocused images based on the stable bits in the iris code representation that are robust to imaging noise. To the best of our knowledge, our work is the first to investigate the characteristics of iris features for varying degree of image defocus when the images are captured outside the DOF of cameras. Based on our findings, we present a method to determine the stable bits of an enrolled image. When compared to iris recognition of defocused images that relies on the entire code representation, the proposed recognition method increases the inter-class variability while reducing the intra-class variability of the samples considered. This leads to smaller intersections between the intra-class and inter-class distance distributions, which results in higher recognition performance. Experimental results based on over 15,000 images show that the proposed method achieves an average recognition performance gain of about two times. It is envisioned that the proposed method can be incorporated as part of a multi-biometric system for mobile phones due to its lightweight computational requirements, which is well suited for power sensitive solutions.", "paper_title": "IRIS RECOGNITION OF DEFOCUSED IMAGES FOR MOBILE PHONES", "paper_id": "WOS:000315523100008"}