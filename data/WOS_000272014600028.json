{"auto_keywords": [{"score": 0.049954102555453066, "phrase": "mpi_applications"}, {"score": 0.006789974287216047, "phrase": "deterministic_replay"}, {"score": 0.0061668329870276616, "phrase": "srr"}, {"score": 0.00481495049065317, "phrase": "subgroup_reproducible_replay_of"}, {"score": 0.004777634277114317, "phrase": "mpiwiz"}, {"score": 0.004678870311639579, "phrase": "widely_used_standard"}, {"score": 0.0046424265003082, "phrase": "coarse-grained_concurrency"}, {"score": 0.004570384351035464, "phrase": "parallel_mpi_applications"}, {"score": 0.004476056395659678, "phrase": "particularly_challenging_task"}, {"score": 0.004418088217921573, "phrase": "concurrent_execution"}, {"score": 0.004395110768083201, "phrase": "non-deterministic_behavior"}, {"score": 0.004326889832663823, "phrase": "potentially_powerful_technique"}, {"score": 0.004248630241580105, "phrase": "existing_mpi_replay_tools"}, {"score": 0.004075003660456217, "phrase": "substantial_log_sizes"}, {"score": 0.004032712685822676, "phrase": "communication_message"}, {"score": 0.003990858854249981, "phrase": "small_logs"}, {"score": 0.0038078071331183435, "phrase": "primary_reasons"}, {"score": 0.0037682786703039264, "phrase": "wide_adoption"}, {"score": 0.003719442481033911, "phrase": "critical_enabler"}, {"score": 0.003700085021374714, "phrase": "cyclic_debugging"}, {"score": 0.0033595442220352633, "phrase": "disjoint_groups"}, {"score": 0.0032815477724070534, "phrase": "group_boundaries"}, {"score": 0.0030742330223615974, "phrase": "communication_locality"}, {"score": 0.0030582231820028057, "phrase": "traffic_patterns"}, {"score": 0.0028875076263279917, "phrase": "intra-group_communication"}, {"score": 0.0027984299898350697, "phrase": "replay_group"}, {"score": 0.0027334248520330803, "phrase": "necessary_control"}, {"score": 0.0025943101835888896, "phrase": "srr._mpiwiz"}, {"score": 0.0025740610607310017, "phrase": "replay_framework"}, {"score": 0.002553969581727289, "phrase": "transparent_binary_instrumentation"}, {"score": 0.0024430371692379807, "phrase": "source_code_modification"}, {"score": 0.002373832128444394, "phrase": "os_system"}, {"score": 0.0022295531401315787, "phrase": "entire_application"}, {"score": 0.0021720506477686105, "phrase": "execution_time"}], "paper_keywords": ["Reliability", " Design", " Performance", " non-determinism", " Message Passing Interface", " record and replay", " distributed debugging"], "paper_abstract": "Message Passing Interface (MPI) is a widely used standard for managing coarse-grained concurrency on distributed computers. Debugging parallel MPI applications, however, has always been a particularly challenging task due to their high degree of concurrent execution and non-deterministic behavior. Deterministic replay is a potentially powerful technique for addressing these challenges, with existing MPI replay tools adopting either data-replay or order-replay approaches. Unfortunately, each approach has its tradeoffs. Data-replay generates substantial log sizes by recording every communication message. Order-replay generates small logs, but requires all processes to be replayed together. We believe that these drawbacks are the primary reasons that inhibit the wide adoption of deterministic replay as the critical enabler of cyclic debugging of MPI applications. This paper describes subgroup reproducible replay (SRR), a hybrid deterministic replay method that provides the benefits of both data-replay and order-replay while balancing their trade-offs. SRR divides all processes into disjoint groups. It records the contents of messages crossing group boundaries as in data-replay, but records just message orderings for communication within a group as in order-replay. In this way, SRR can exploit the communication locality of traffic patterns in MPI applications. During replay, developers can then replay each group individually. SRR reduces recording overhead by not recording intra-group communication, and reduces replay overhead by limiting the size of each replay group. Exposing these tradeoffs gives the user the necessary control for making deterministic replay practical for MPI applications. We have implemented a prototype, MPIWIZ, to demonstrate and evaluate SRR. MPIWIZ employs a replay framework that allows transparent binary instrumentation of both library and system calls. As a result, MPIWIZ replays MPI applications with no source code modification and relinking, and handles non-determinism in both MPI and OS system calls. Our preliminary results show that MPIWIZ can reduce recording overhead by over a factor of four relative to data-replay, yet without requiring the entire application to be replayed as in order-replay. Recording increases execution time by 27% while the application can be replayed in just 53% of its base execution time.", "paper_title": "MPIWIZ: Subgroup Reproducible Replay of MPI Applications", "paper_id": "WOS:000272014600028"}