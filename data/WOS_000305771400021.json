{"auto_keywords": [{"score": 0.03843856552198327, "phrase": "sefr"}, {"score": 0.00481495049065317, "phrase": "large_amount"}, {"score": 0.004730158389701481, "phrase": "unlabeled_data"}, {"score": 0.004484596684703308, "phrase": "feature_selection"}, {"score": 0.003959863717046575, "phrase": "new_method"}, {"score": 0.0037209035703970705, "phrase": "guided_feature_ranking_method"}, {"score": 0.003404244237372396, "phrase": "bagged_ensemble"}, {"score": 0.0033442114331500407, "phrase": "standard_semi-supervised_approaches"}, {"score": 0.0030595112110658675, "phrase": "bag_feature_importance_measure"}, {"score": 0.0027252240573281163, "phrase": "empirical_results"}, {"score": 0.002515384834484012, "phrase": "significant_improvement"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Semi-supervised learning", " Feature selection", " Ensemble learning"], "paper_abstract": "We consider the problem of using a large amount of unlabeled data to improve the efficiency of feature selection in high-dimension when only a small amount of labeled examples is available. We propose a new method called semi-supervised ensemble learning guided feature ranking method (SEFR for short), that combines a bagged ensemble of standard semi-supervised approaches with a permutation-based out-of-bag feature importance measure that takes into account both labeled and unlabeled data. We provide empirical results on several benchmark data sets indicating that SEFR can lead to significant improvement over state-of-the-art supervised and semi-supervised algorithms. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "A semi-supervised feature ranking method with ensemble learning", "paper_id": "WOS:000305771400021"}