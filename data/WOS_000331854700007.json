{"auto_keywords": [{"score": 0.048745558625529165, "phrase": "visual_data"}, {"score": 0.03250463365971379, "phrase": "classifier_selection"}, {"score": 0.00481495049065317, "phrase": "pattern_classifiers"}, {"score": 0.0047810714349158165, "phrase": "multimedia_recognition"}, {"score": 0.004615202066192795, "phrase": "countless_monitoring_video_cameras"}, {"score": 0.004486640769041646, "phrase": "mobile_devices"}, {"score": 0.00422516469733364, "phrase": "so-called_\"big-data_revolution"}, {"score": 0.004049783994776266, "phrase": "pandora_box"}, {"score": 0.004021267064832957, "phrase": "new_visual_classification_problems"}, {"score": 0.003950846696972114, "phrase": "image_and_video_classification_tasks"}, {"score": 0.00388165472334023, "phrase": "different_and_complex_applications"}, {"score": 0.003813669883040509, "phrase": "machine_learning-based_solutions"}, {"score": 0.0036424097335610492, "phrase": "silver_bullet"}, {"score": 0.0034421126037849, "phrase": "different_domains"}, {"score": 0.003275879115801376, "phrase": "good_results"}, {"score": 0.002988101395789399, "phrase": "image_characterization"}, {"score": 0.0029670381308395505, "phrase": "learning_methods"}, {"score": 0.0029150253706493852, "phrase": "meta-learning_approach"}, {"score": 0.0025938179480905783, "phrase": "diversity_measures_analysis"}, {"score": 0.002530359917257626, "phrase": "proposed_approach"}, {"score": 0.0025125151618810523, "phrase": "comparable_results"}, {"score": 0.0024947959375982614, "phrase": "well-known_algorithms"}, {"score": 0.0022434880661725493, "phrase": "proposed_method"}, {"score": 0.0022041312401435346, "phrase": "continuous_learning"}, {"score": 0.0021501863832966966, "phrase": "highly-parallel_architectures"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Meta-learning", " Ensemble of classifiers", " Diversity measures"], "paper_abstract": "The frequent growth of visual data, either by countless monitoring video cameras wherever we go or the popularization of mobile devices that allow each person to create and edit their own images and videos have contributed enormously to the so-called \"big-data revolution\". This shear amount of visual data gives rise to a Pandora box of new visual classification problems never imagined before. Image and video classification tasks have been inserted in different and complex applications and the use of machine learning-based solutions has become the most popular approach for several applications. Notwithstanding, there is no silver bullet that solves all the problems, i.e., it is not possible to characterize all images of different domains with the same description method nor is it possible to use the same learning method to achieve good results in any kind of application. In this work, we aim at proposing a framework for classifier selection and fusion. Our method seeks to combine image characterization and learning methods by means of a meta-learning approach responsible for assessing which methods contribute more towards the solution of a given problem. The framework uses a strategy of classifier selection which pinpoints the less correlated, yet effective, classifiers through a series of diversity measures analysis. The experiments show that the proposed approach achieves comparable results to well-known algorithms from the literature on four different applications but using less learning and description methods as well as not incurring in the curse of dimensionality and normalization problems common to some fusion techniques. Furthermore, our approach is able to achieve effective classification results using very reduced training sets. The proposed method is also amenable to continuous learning and flexible enough for implementation in highly-parallel architectures. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A framework for selection and fusion of pattern classifiers in multimedia recognition", "paper_id": "WOS:000331854700007"}