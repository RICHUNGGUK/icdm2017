{"auto_keywords": [{"score": 0.04464053001280883, "phrase": "clinical_editors"}, {"score": 0.015423788060513935, "phrase": "clinical_guidelines"}, {"score": 0.00481495049065317, "phrase": "collaborative_specification"}, {"score": 0.004311241567238011, "phrase": "expert_physicians"}, {"score": 0.004208881856146758, "phrase": "knowledge_engineers"}, {"score": 0.004148631410346188, "phrase": "quantitative_evaluation"}, {"score": 0.004089239912167375, "phrase": "specification's_quality"}, {"score": 0.003934970057482768, "phrase": "particular_framework"}, {"score": 0.0038973170902076707, "phrase": "incremental_gl"}, {"score": 0.0036788184374592706, "phrase": "gold-standard_mark-up"}, {"score": 0.0034558655164987134, "phrase": "ontological_knowledge_roles"}, {"score": 0.0033575566897536906, "phrase": "completeness_measure"}, {"score": 0.0033094525227603012, "phrase": "acquired_knowledge"}, {"score": 0.003138874040786261, "phrase": "kr_instances"}, {"score": 0.002977061391551628, "phrase": "correctness_measure"}, {"score": 0.0029343925814926787, "phrase": "high_variability"}, {"score": 0.0029062860108533374, "phrase": "clinical_editor_pairs"}, {"score": 0.0027431953780099826, "phrase": "specification_quality"}, {"score": 0.0025892330566358503, "phrase": "procedural_krs"}, {"score": 0.00247944491239733, "phrase": "declarative_krs"}, {"score": 0.0023972750359328235, "phrase": "ontology-specific_consensus"}, {"score": 0.002340250894008014, "phrase": "mark-up_training"}, {"score": 0.0023066880707738736, "phrase": "cl_knowledge"}, {"score": 0.0022845800828325555, "phrase": "high_completeness"}, {"score": 0.0022409963215568565, "phrase": "main_demand"}, {"score": 0.002219516542316085, "phrase": "correct_structuring"}, {"score": 0.002166711569953301, "phrase": "ontology's_semantics"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Clinical decision support systems", " Clinical guidelines", " Ontologies", " Knowledge acquisition", " Knowledge bases", " Evaluation", " Mark-up", " Structuring", " Completeness", " Correctness"], "paper_abstract": "We introduce a three-phase, nine-step methodology for specification of clinical guidelines (GLs) by expert physicians, clinical editors, and knowledge engineers and for quantitative evaluation of the specification's quality. We applied this methodology to a particular framework for incremental GL structuring (mark-up) and to GLs in three clinical domains. A gold-standard mark-up was created, including 196 plans and subplans, and 326 instances of ontological knowledge roles (KRs). A completeness measure of the acquired knowledge revealed that 97% of the plans and 91% of the KR instances of the GLs were recreated by the clinical editors. A correctness measure often revealed high variability within clinical editor pairs structuring each GL, but for all GLs and clinical editors the specification quality was significantly higher than random (p < 0.01). Procedural KRs were more difficult to mark-up than declarative KRs. We conclude that given an ontology-specific consensus. clinical editors with mark-up training can structure CL knowledge with high completeness, whereas the main demand for correct structuring is training in the ontology's semantics. (c) 2008 Elsevier Inc. All rights reserved.", "paper_title": "A quantitative assessment of a methodology for collaborative specification and evaluation of clinical guidelines", "paper_id": "WOS:000261220500004"}