{"auto_keywords": [{"score": 0.038317712805750026, "phrase": "svmr_training_time"}, {"score": 0.035862556853898, "phrase": "grid_search"}, {"score": 0.00481495049065317, "phrase": "support_vector_regression_algorithms"}, {"score": 0.004675768396728975, "phrase": "essential_process"}, {"score": 0.004540591176992658, "phrase": "learning_machines"}, {"score": 0.004366387782457736, "phrase": "exact_method"}, {"score": 0.00428179779071721, "phrase": "optimal_values"}, {"score": 0.004017989546119125, "phrase": "search_algorithm"}, {"score": 0.0038074544783102226, "phrase": "best_combination"}, {"score": 0.0035553221885904467, "phrase": "large_training_databases"}, {"score": 0.003520687960750365, "phrase": "standard_search_algorithms"}, {"score": 0.003368948014436942, "phrase": "k-fold_cross_validation"}, {"score": 0.003024909947609294, "phrase": "final_machine"}, {"score": 0.002951739421935396, "phrase": "good_performance"}, {"score": 0.0028662606272282926, "phrase": "standard_svmr"}, {"score": 0.002783250284824728, "phrase": "hyper-parameters_search"}, {"score": 0.0025608471909800076, "phrase": "multi-parametric_kernels"}, {"score": 0.002523481637809674, "phrase": "meta-heuristic_approaches"}, {"score": 0.002486659929589854, "phrase": "evolutionary_algorithms"}, {"score": 0.002391067964886602, "phrase": "best_set"}, {"score": 0.0023677483882740317, "phrase": "svmr_hyper-parameters"}, {"score": 0.00229914226836813, "phrase": "new_validation_methods"}, {"score": 0.0022216045996270974, "phrase": "training_time"}, {"score": 0.0021678232353129472, "phrase": "final_svmr_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Support vector regression algorithms", " SVMr hyper-parameters", " Training time", " Validation methods"], "paper_abstract": "The selection of hyper-parameters in support vector regression algorithms (SVMr) is an essential process in the training of these learning machines. Unfortunately, there is not an exact method to obtain the optimal values of SVMr hyper-parameters. Therefore, it is necessary to use a search algorithm and sometimes a validation method in order to find the best combination of hyper-parameters. The problem is that the SVMr training time can be huge in large training databases if standard search algorithms and validation methods (such as grid search and K-fold cross validation), are used. In this paper we propose two novel validation methods which reduce the SVMr training time, maintaining the accuracy of the final machine. We show the good performance of both methods in the standard SVMr with 3 hyper-parameters (where the hyper-parameters search is usually carried out by means of a grid search) and also in the extension to multi-parametric kernels, where meta-heuristic approaches such as evolutionary algorithms must be used to look for the best set of SVMr hyper-parameters. In all cases the new validation methods have provided very good results in terms of training time, without affecting the final SVMr accuracy. (c) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "New validation methods for improving standard and multi-parametric support vector regression training time", "paper_id": "WOS:000303281600063"}