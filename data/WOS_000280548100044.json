{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "loop_vectorization"}, {"score": 0.0047517225918491226, "phrase": "multithreaded_data_parallel_architectures"}, {"score": 0.004447766706144458, "phrase": "high_performance"}, {"score": 0.004389339243427964, "phrase": "single_instruction_multiple_data"}, {"score": 0.004081385289516914, "phrase": "irregular_memory_access_patterns"}, {"score": 0.00400119808662365, "phrase": "data_stream"}, {"score": 0.003871024872459116, "phrase": "data_transformations"}, {"score": 0.0036714667610391535, "phrase": "massively_multithreaded_data"}, {"score": 0.0035052810710060893, "phrase": "mathematical_model"}, {"score": 0.0034363735647539267, "phrase": "loop-based_memory_access_patterns"}, {"score": 0.0031115683920520773, "phrase": "proposed_data_transformations"}, {"score": 0.0028173769301594745, "phrase": "data-level_parallelism"}, {"score": 0.0024353398669404334, "phrase": "input_data"}, {"score": 0.0024192592458651204, "phrase": "set_increases"}, {"score": 0.0023249757987087055, "phrase": "high_performance_benchmark_kernels"}, {"score": 0.0022492129111567824, "phrase": "consistent_and_significant_performance_improvements"}], "paper_keywords": ["Algorithms", " Performance", " Experimentation", " Loop Vectorization", " Data Transformation", " GPGPU"], "paper_abstract": "Loop vectorization, a key feature exploited to obtain high performance on Single Instruction Multiple Data (SIMD) vector architectures, is significantly hindered by irregular memory access patterns in the data stream. This paper describes data transformations that allow us to vectorize loops targeting massively multithreaded data parallel architectures. We present a mathematical model that captures loop-based memory access patterns and computes the most appropriate data transformations in order to enable vectorization. Our experimental results show that the proposed data transformations can significantly increase the number of loops that can be vectorized and enhance the data-level parallelism of applications. Our results also show that the overhead associated with our data transformations can be easily amortized as the size of the input data set increases. For the set of high performance benchmark kernels studied, we achieve consistent and significant performance improvements (up to 11.4X) by applying vectorization using our data transformation approach.", "paper_title": "Data Transformations Enabling Loop Vectorization on Multithreaded Data Parallel Architectures", "paper_id": "WOS:000280548100044"}