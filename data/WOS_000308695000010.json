{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multiple_virtual_planes"}, {"score": 0.0047602693158272655, "phrase": "fusion-based_camera_network"}, {"score": 0.0044111930537670705, "phrase": "camera_network"}, {"score": 0.004118874671285618, "phrase": "inertial_sensor"}, {"score": 0.004025787455454387, "phrase": "virtual_camera"}, {"score": 0.00394981748347167, "phrase": "is-camera_couple"}, {"score": 0.0038752755502006442, "phrase": "infinite_homography"}, {"score": 0.003802135020791801, "phrase": "inertial_and_visual_information"}, {"score": 0.0037446140218109895, "phrase": "inertial_data"}, {"score": 0.0037020429480068653, "phrase": "planar_ground_assumption"}, {"score": 0.0036321600255449613, "phrase": "virtual_horizontal_planes"}, {"score": 0.0035230711775515854, "phrase": "inertial-based_virtual_planes"}, {"score": 0.003391290302481397, "phrase": "planar_homography"}, {"score": 0.0032894118890753805, "phrase": "translation_vectors"}, {"score": 0.003264422557779248, "phrase": "virtual_cameras"}, {"score": 0.0031663432942179853, "phrase": "relative_heights"}, {"score": 0.0029675701595142656, "phrase": "image_planes"}, {"score": 0.0029450186031370245, "phrase": "different_experimental_results"}, {"score": 0.0028025415122856973, "phrase": "first_type"}, {"score": 0.0027495914857929584, "phrase": "-camera_couple"}, {"score": 0.002687366778212309, "phrase": "different_locations"}, {"score": 0.002616544154458438, "phrase": "second_type"}, {"score": 0.002557322657104706, "phrase": "walking_person"}, {"score": 0.0024522007854499554, "phrase": "installed_cameras"}, {"score": 0.0023784664152543718, "phrase": "data_acquisition"}, {"score": 0.0022375675189464715, "phrase": "translation_estimation_method"}, {"score": 0.0022120914337992034, "phrase": "experimental_results"}, {"score": 0.0021455612994325424, "phrase": "proposed_framework"}, {"score": 0.0021049977753042253, "phrase": "multi-layer_data_registration"}], "paper_keywords": [""], "paper_abstract": "A novel approach for three-dimensional (3D) volumetric reconstruction of an object inside a scene is proposed. A camera network is used to observe the scene. Each camera within the network is rigidly coupled with an Inertial Sensor (IS). A virtual camera is defined for each IS-camera couple using the concept of infinite homography, by fusion of inertial and visual information. Using the inertial data and without planar ground assumption, a set of virtual horizontal planes are defined. The intersections of these inertial-based virtual planes with the object are registered using the concept of planar homography. Moreover a method to estimate the translation vectors among virtual cameras is proposed, which just needs the relative heights of two 3D points in the scene with respect to one of the cameras and their correspondences on the image planes. Different experimental results for the proposed 3D reconstruction method are provided on two different types of scenarios. In the first type, a single IS-camera couple is used and placed in different locations around the object. In the second type, the 3D reconstruction of a walking person (dynamic case) is performed where a set of installed cameras in a smart-room is used for the data acquisition. Moreover, a set of experiments are simulated to analyse the accuracy of the translation estimation method. The experimental results show the feasibility and effectiveness of the proposed framework for the purpose of multi-layer data registration and volumetric reconstruction.", "paper_title": "Three-dimensional reconstruction based on multiple virtual planes by using fusion-based camera network", "paper_id": "WOS:000308695000010"}