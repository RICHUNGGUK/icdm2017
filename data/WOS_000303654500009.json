{"auto_keywords": [{"score": 0.032299082504174376, "phrase": "analyzer"}, {"score": 0.00481495049065317, "phrase": "data_analysis"}, {"score": 0.004740009255053372, "phrase": "extensible_markup_language"}, {"score": 0.004569630374630379, "phrase": "leading_role"}, {"score": 0.004475022550508119, "phrase": "data_representation"}, {"score": 0.0042692243768616455, "phrase": "massive_boom"}, {"score": 0.004224786847720058, "phrase": "corresponding_techniques"}, {"score": 0.0041589926969138585, "phrase": "xml_data"}, {"score": 0.004051595625804513, "phrase": "processing_techniques"}, {"score": 0.0038450179181069833, "phrase": "space_efficiency"}, {"score": 0.0037261429556468217, "phrase": "main_reason"}, {"score": 0.0036489343475053187, "phrase": "xml_collections"}, {"score": 0.0034992667091713813, "phrase": "real-world_data"}, {"score": 0.0032689949867583633, "phrase": "input_data"}, {"score": 0.0029438813080245544, "phrase": "statistical_analyses"}, {"score": 0.0029131986574478046, "phrase": "real-world_documents"}, {"score": 0.0027645030021576926, "phrase": "classical_way"}, {"score": 0.0027356847952125433, "phrase": "data_processing"}, {"score": 0.0025156683465194967, "phrase": "dedicated_analyses"}, {"score": 0.002387214876538434, "phrase": "insufficiently_extensive_collections"}, {"score": 0.0022653055209664284, "phrase": "easily_extensible_framework"}, {"score": 0.0021049977753042253, "phrase": "computed_reports"}], "paper_keywords": ["XML data analysis", " XML data crawling", " XML data correction", " structural analysis", " XQuery analysis"], "paper_abstract": "Recently eXtensible Markup Language (XML) has achieved the leading role among languages for data representation and, thus, we can witness a massive boom of corresponding techniques for managing XML data. Most of the processing techniques, however, suffer from various bottlenecks worsening their time and/or space efficiency. We assume that the main reason is they consider XML collections too globally, involving all their possible features, although real-world data are often much simpler. Even though some techniques do restrict the input data, the restrictions are mostly unnatural. This paper aims to introduce Analyzer-a complex framework for performing statistical analyses of real-world documents. Exploitation of results of these analyses is a classical way how data processing can be optimized in many areas. Although this intent is legitimate, ad hoc and dedicated analyses soon become obsolete, they are usually built on insufficiently extensive collections and are difficult to repeat. Analyzer represents an easily extensible framework, which helps the user with gathering documents, managing analyses and browsing computed reports.", "paper_title": "Analyzer: A Complex System for Data Analysis", "paper_id": "WOS:000303654500009"}