{"auto_keywords": [{"score": 0.04947600830161959, "phrase": "face_recognition"}, {"score": 0.04927669935645088, "phrase": "video_surveillance"}, {"score": 0.040641859947900885, "phrase": "fusion_function"}, {"score": 0.04014807757799068, "phrase": "class_imbalance"}, {"score": 0.004815340879031441, "phrase": "adaptive"}, {"score": 0.0047142788290253385, "phrase": "decision_support_systems"}, {"score": 0.0045768485563508704, "phrase": "target_individuals"}, {"score": 0.004528738937534532, "phrase": "video_cameras"}, {"score": 0.004481132747216135, "phrase": "challenging_problem"}, {"score": 0.004415319911209701, "phrase": "capture_conditions"}, {"score": 0.004387409823768222, "phrase": "camera_interoperability"}, {"score": 0.0043412828088091795, "phrase": "limited_representativeness"}, {"score": 0.004322967486451877, "phrase": "target_facial_models"}, {"score": 0.004268481854915208, "phrase": "adaptive_classifier_ensembles"}, {"score": 0.004223599884418183, "phrase": "robust_face"}, {"score": 0.004083111614763562, "phrase": "non-target_individuals"}, {"score": 0.003799838110093287, "phrase": "input_data_stream"}, {"score": 0.003759865199238564, "phrase": "skew-sensitive_boolean_combination"}, {"score": 0.0037439952503722012, "phrase": "ssec"}, {"score": 0.0037124503096577183, "phrase": "active_approach"}, {"score": 0.003673393296800983, "phrase": "non-target_proportions"}, {"score": 0.0036347456860485075, "phrase": "hellinger_distance"}, {"score": 0.0035889029688641835, "phrase": "operational_class_imbalance"}, {"score": 0.0034989387309057817, "phrase": "diverse_pools"}, {"score": 0.003462120171132709, "phrase": "balanced_training_data"}, {"score": 0.0034329435101361355, "phrase": "potential_diversity"}, {"score": 0.0034040118925461557, "phrase": "abundant_non-target_data"}, {"score": 0.003361069456060196, "phrase": "adaptive_skew-sensitive_ensembles"}, {"score": 0.0032837390943136697, "phrase": "varying_levels"}, {"score": 0.003221789737624896, "phrase": "high_level"}, {"score": 0.0030171910207671205, "phrase": "reference_trajectory"}, {"score": 0.002991752697506459, "phrase": "selected_non-target"}, {"score": 0.0028136097467377458, "phrase": "input_trajectories"}, {"score": 0.002795795945512292, "phrase": "hdx_quantification_method"}, {"score": 0.002743026543312473, "phrase": "imbalanced_data_distributions"}, {"score": 0.002696954879930915, "phrase": "pre-computed_histograms"}, {"score": 0.002685558057339722, "phrase": "ensemble_fusion_functions"}, {"score": 0.00264044907457218, "phrase": "operational_data"}, {"score": 0.002612640527241776, "phrase": "ensemble_scores"}, {"score": 0.0025796555911178037, "phrase": "robust_spatio-temporal_recognition"}, {"score": 0.0025578967205807843, "phrase": "synthetic_data"}, {"score": 0.0025042971048592853, "phrase": "different_complexities"}, {"score": 0.002425991121756382, "phrase": "action_video_data"}, {"score": 0.002405525253848779, "phrase": "proposed_method"}, {"score": 0.002390288963853555, "phrase": "reference_techniques"}, {"score": 0.0023751489488091143, "phrase": "ssbc"}, {"score": 0.0023501278920397372, "phrase": "imbalanced_video_surveillance_environments"}, {"score": 0.002340193255754885, "phrase": "transaction-based_analysis"}, {"score": 0.0023008719389461373, "phrase": "operational_imbalances"}, {"score": 0.0022911450429253704, "phrase": "individual-specific_analysis"}, {"score": 0.002267006916133386, "phrase": "lamb-like_individuals"}, {"score": 0.0022241959099720864, "phrase": "operational_imbalance"}, {"score": 0.0022054286401057732, "phrase": "trajectory-based_analysis"}, {"score": 0.002186819377220387, "phrase": "video-to-video_fr_system"}, {"score": 0.0021319264406486124, "phrase": "overall_system_discrimination"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Adaptive classifier ensembles", " Boolean combination", " Imbalance estimation", " Video-to-video face recognition", " Video surveillance", " Adaptive multiple classifier systems"], "paper_abstract": "Decision support systems for surveillance rely more and more on face recognition (FR) to detect target individuals of interest captured with video cameras. FR is a challenging problem in video surveillance due to variations in capture conditions, to camera interoperability, and to the limited representativeness of target facial models used for matching. Although adaptive classifier ensembles have been applied for robust face matching, it is often assumed that the proportions of faces captured for target and non-target individuals are balanced, known a priori, and do not change over time. Recently, some techniques have been proposed to adapt the fusion function of an ensemble according to class imbalance of the input data stream. For instance, Skew-Sensitive Boolean combination (SSEC) is a active approach that estimates target vs. non-target proportions periodically during operations using Hellinger distance, and adapts its ensemble fusion function to operational class imbalance. Beyond the challenges of estimating class imbalance, such techniques commonly generate diverse pools of classifiers by selecting balanced training data, limiting the potential diversity produced using the abundant non-target data. In this paper, adaptive skew-sensitive ensembles are proposed to combine classifiers trained by selecting data with varying levels of imbalance and complexity, to sustain a high level the performance for video-to-video FR. Faces captured for each person in the scene are tracked and regrouped into trajectories. During enrollment, captures in a reference trajectory are combined with selected non-target captures to generate a pool of 2-class classifiers using data with various levels of imbalance and complexity. During operations, the level of imbalance is periodically estimated from the input trajectories using the HDx quantification method, and pre-computed histogram representations of imbalanced data distributions. This approach allows one to adapt pre-computed histograms and ensemble fusion functions based on the imbalance and complexity of operational data. Finally, the ensemble scores are accumulated of trajectories for robust spatio-temporal recognition. Results on synthetic data show that adapting the fusion function of ensemble trained with different complexities and levels of imbalance can significantly improve performance. Results on the Face in Action video data show that the proposed method can outperform reference techniques (including SSBC and meta-classification) in imbalanced video surveillance environments. Transaction-based analysis shows that performance is consistently higher across operational imbalances. Individual-specific analysis indicates that goat- and lamb-like individuals can benefit the most from adaptation to the operational imbalance. Finally, trajectory-based analysis shows that a video-to-video FR system based on the proposed approach can maintain, and even improve overall system discrimination. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Adaptive skew-sensitive ensembles for face recognition in video surveillance", "paper_id": "WOS:000359028900010"}