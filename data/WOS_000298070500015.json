{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "high-dimensional_data"}, {"score": 0.004586531354697466, "phrase": "novel_semi-supervised_dimensionality_reduction_technique"}, {"score": 0.004466519142879166, "phrase": "inefficient_learning"}, {"score": 0.0044272138900038095, "phrase": "costly_computation"}, {"score": 0.004235793609579307, "phrase": "dual_subspace_projections"}, {"score": 0.004198524315495852, "phrase": "dsp"}, {"score": 0.0040886093072615, "phrase": "optimal_low-dimensional_space"}, {"score": 0.003877329308854808, "phrase": "input_data"}, {"score": 0.0032057142600527, "phrase": "intrinsic_data_structure"}, {"score": 0.003149471116658739, "phrase": "existing_techniques"}, {"score": 0.0026501241093379786, "phrase": "nonlinearly_separable_data"}, {"score": 0.002592100731070259, "phrase": "linear_data_transformation"}, {"score": 0.0024579623598183355, "phrase": "new_data_points"}, {"score": 0.002382936364692606, "phrase": "large_datasets"}, {"score": 0.002351485871160907, "phrase": "empirical_study"}, {"score": 0.0023307492812556204, "phrase": "real_data"}, {"score": 0.002279702500235741, "phrase": "significant_improvements"}, {"score": 0.0022595974985992664, "phrase": "learning_accuracy"}, {"score": 0.002200337772403983, "phrase": "dsp-based_dimensionality_reduction"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Dimensionality reduction", " Semi-supervised learning", " Clustering", " Kernel methods", " Linear transformation", " Generalized eigenproblem"], "paper_abstract": "In this paper, we present a novel semi-supervised dimensionality reduction technique to address the problems of inefficient learning and costly computation in coping with high-dimensional data. Our method named the dual subspace projections (DSP) embeds high-dimensional data in an optimal low-dimensional space, which is learned with a few user-supplied constraints and the structure of input data. The method projects data into two different subspaces respectively the kernel space and the original input space. Each projection is designed to enforce one type of constraints and projections in the two subspaces interact with each other to satisfy constraints maximally and preserve the intrinsic data structure. Compared to existing techniques, our method has the following advantages: (1) it benefits from constraints even when only a few are available; (2) it is robust and free from overfitting; and (3) it handles nonlinearly separable data, but learns a linear data transformation. As a conclusion, our method can be easily generalized to new data points and is efficient in dealing with large datasets. An empirical study using real data validates our claims so that significant improvements in learning accuracy can be obtained after the DSP-based dimensionality reduction is applied to high-dimensional data. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Semi-supervised dimensionality reduction for analyzing high-dimensional data with constraints", "paper_id": "WOS:000298070500015"}