{"auto_keywords": [{"score": 0.04922237591220716, "phrase": "tm"}, {"score": 0.00481495049065317, "phrase": "transactional_memory_applications"}, {"score": 0.004771672073078768, "phrase": "transactional_memory"}, {"score": 0.004644146045859622, "phrase": "programmer_friendly_alternative"}, {"score": 0.004602395776895036, "phrase": "traditional_lock-based_concurrency"}, {"score": 0.004459190343665408, "phrase": "concurrent_programming"}, {"score": 0.004092463367307375, "phrase": "shared_data"}, {"score": 0.0038242899532391914, "phrase": "full_potential"}, {"score": 0.0037898820206470085, "phrase": "modern_multicore_platforms"}, {"score": 0.003688497722149817, "phrase": "complex_memory_hierarchies"}, {"score": 0.003638823482920949, "phrase": "different_levels"}, {"score": 0.0035095935622207956, "phrase": "memory_latencies"}, {"score": 0.0034780071331554003, "phrase": "bandwidth_problems"}, {"score": 0.003309278541665552, "phrase": "interesting_approach"}, {"score": 0.003235305151177897, "phrase": "memory_hierarchy"}, {"score": 0.0031062822219953524, "phrase": "single_fixed_thread_mapping"}, {"score": 0.003036832649117453, "phrase": "best_performance"}, {"score": 0.0029689311901364797, "phrase": "large_range"}, {"score": 0.002942196368747418, "phrase": "transactional_workloads"}, {"score": 0.002915701586760994, "phrase": "tm_systems"}, {"score": 0.0027367816003722252, "phrase": "tm_system"}, {"score": 0.002687702958515561, "phrase": "adaptive_thread_mapping_strategies"}, {"score": 0.0025456716198597627, "phrase": "simple_strategies"}, {"score": 0.0024774888010414206, "phrase": "prior_knowledge"}, {"score": 0.0024220634963019114, "phrase": "machine_learning_techniques"}, {"score": 0.00237861522566195, "phrase": "linux_default_strategy"}, {"score": 0.0023148964315569866, "phrase": "performance_improvements"}, {"score": 0.0022427071130840647, "phrase": "synthetic_applications"}, {"score": 0.0022124605840026313, "phrase": "overall_performance_improvement"}, {"score": 0.002162951519368368, "phrase": "standard_stamp_benchmark_suite"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Transactional memory", " Thread mapping", " Adaptivity", " Multicore"], "paper_abstract": "Transactional Memory (TM) is a programmer friendly alternative to traditional lock-based concurrency. Although it intends to simplify concurrent programming, the performance of the applications still relies on how frequent they synchronize and the way they access shared data. These aspects must be taken into consideration if one intends to exploit the full potential of modern multicore platforms. Since these platforms feature complex memory hierarchies composed of different levels of cache, applications may suffer from memory latencies and bandwidth problems if threads are not properly placed on cores. An interesting approach to efficiently exploit the memory hierarchy is called thread mapping. However, a single fixed thread mapping cannot deliver the best performance when dealing with a large range of transactional workloads, TM systems and platforms. In this article, we propose and implement in a TM system a set of adaptive thread mapping strategies for TM applications to tackle this problem. They range from simple strategies that do not require any prior knowledge to strategies based on Machine Learning techniques. Taking the Linux default strategy as baseline, we achieved performance improvements of up to 64.4% on a set of synthetic applications and an overall performance improvement of up to 16.5% on the standard STAMP benchmark suite. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Adaptive thread mapping strategies for transactional memory applications", "paper_id": "WOS:000339643200006"}