{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "probabilistic_decision_graphs"}, {"score": 0.0268697532045678, "phrase": "computational_efficiency"}, {"score": 0.004458722048888919, "phrase": "representation_language"}, {"score": 0.0043738432231020885, "phrase": "probability_distributions"}, {"score": 0.0042495320879288615, "phrase": "binary_decision_diagrams"}, {"score": 0.003750260412839128, "phrase": "bayesian_network_structure"}, {"score": 0.0035399770257915466, "phrase": "computationally_more_efficient_representations"}, {"score": 0.002977061391551631, "phrase": "first_experiments"}, {"score": 0.002730023736069673, "phrase": "optimal_pdg_representations"}, {"score": 0.00247944491239733, "phrase": "pdg_models"}, {"score": 0.0024088451312725924, "phrase": "real-life_data"}, {"score": 0.0022302306304023602, "phrase": "bayesian_network_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["probabilistic models", " learning"], "paper_abstract": "Probabilistic decision graphs (PDGs) are a representation language for probability distributions based on binary decision diagrams. PDGs can encode (context-specific) independence relations that cannot be captured in a Bayesian network structure, and can sometimes provide computationally more efficient representations than Bayesian networks. In this paper we present an algorithm for learning PDGs from data. First experiments show that the algorithm is capable of learning optimal PDG representations in some cases, and that the computational efficiency of PDG models learned from real-life data is very close to the computational efficiency of Bayesian network models. (C) 2005 Elsevier Inc. All rights reserved.", "paper_title": "Learning probabilistic decision graphs", "paper_id": "WOS:000237372100007"}