{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "model-based_sequence_clustering"}, {"score": 0.0043533862892678864, "phrase": "existing_alternatives"}, {"score": 0.0040978781692373005, "phrase": "model-based_distances"}, {"score": 0.003216804708106142, "phrase": "kullback-leibler_divergence"}, {"score": 0.0024742098091226203, "phrase": "spectral_clustering"}, {"score": 0.0023287359930308864, "phrase": "improved_performance"}, {"score": 0.0022365262201954643, "phrase": "real-world_scenarios"}, {"score": 0.0021049977753042253, "phrase": "model_selection_scheme"}], "paper_keywords": ["Clustering", " sequential data", " similarity measures"], "paper_abstract": "We review the existing alternatives for defining model-based distances for clustering sequences and propose a new one based on the Kullback-Leibler divergence. This distance is shown to be especially useful in combination with spectral clustering. For improved performance in real-world scenarios, a model selection scheme is also proposed.", "paper_title": "A New Distance Measure for Model-Based Sequence Clustering", "paper_id": "WOS:000266188900014"}