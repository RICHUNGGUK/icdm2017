{"auto_keywords": [{"score": 0.014501008217515321, "phrase": "second_challenge"}, {"score": 0.00481495049065317, "phrase": "clustering_data"}, {"score": 0.004622573396207846, "phrase": "cluster_interpretation"}, {"score": 0.004563427013973105, "phrase": "high-dimensional_data"}, {"score": 0.004485735417293941, "phrase": "real_similarities"}, {"score": 0.00440936064837018, "phrase": "evolving_nature"}, {"score": 0.00438105507792004, "phrase": "observed_phenomena"}, {"score": 0.004152102871968043, "phrase": "high-dimensionality_problem"}, {"score": 0.004090158967007812, "phrase": "co-clustering_approach"}, {"score": 0.003986103192038901, "phrase": "observed_objects"}, {"score": 0.0037453925386820254, "phrase": "hierarchical_fashion"}, {"score": 0.0032432180338975865, "phrase": "proposed_solution"}, {"score": 0.00314708280192844, "phrase": "produced_hierarchies"}, {"score": 0.0030735451757603555, "phrase": "multiple_splits"}, {"score": 0.003034158379493625, "phrase": "lower_level"}, {"score": 0.0029824243255516343, "phrase": "accumulating_nature"}, {"score": 0.002875391177926809, "phrase": "incremental_solution"}, {"score": 0.002778155724601111, "phrase": "incremental_version"}, {"score": 0.0027543636132088332, "phrase": "hierarchical_co-clustering"}, {"score": 0.002719055901632759, "phrase": "intermediate_solution"}, {"score": 0.002695768552609587, "phrase": "previous_version"}, {"score": 0.002649788894535286, "phrase": "co-clustering_results"}, {"score": 0.0025382329422915626, "phrase": "original_approach"}, {"score": 0.0024949335264641617, "phrase": "overall_dataset"}, {"score": 0.002462943191015058, "phrase": "incremental_algorithm_guarantees"}, {"score": 0.002426137929553724, "phrase": "original_version"}, {"score": 0.0023745087648471613, "phrase": "incremental_approach"}, {"score": 0.0023440589015485077, "phrase": "accurate_comparison"}, {"score": 0.0022843229316652255, "phrase": "art_competitors"}, {"score": 0.002259883463607508, "phrase": "obtained_results"}, {"score": 0.0022309002277247263, "phrase": "novel_usage"}, {"score": 0.0022165479912042807, "phrase": "co-clustering_algorithms"}, {"score": 0.0021049977753042253, "phrase": "on-going_co-clustering_solution"}], "paper_keywords": ["Co-clustering", " Hierarchical clustering", " Incremental clustering"], "paper_abstract": "Clustering data is challenging especially for two reasons. The dimensionality of the data is often very high which makes the cluster interpretation hard. Moreover, with high-dimensional data the classic metrics fail in identifying the real similarities between objects. The second challenge is the evolving nature of the observed phenomena which makes the datasets accumulating over time. In this paper we show how we propose to solve these problems. To tackle the high-dimensionality problem, we propose to apply a co-clustering approach on the dataset that stores the occurrence of features in the observed objects. Co-clustering computes a partition of objects and a partition of features simultaneously. The novelty of our co-clustering solution is that it arranges the clusters in a hierarchical fashion, and it consists of two hierarchies: one on the objects and one on the features. The two hierarchies are coupled because the clusters at a certain level in one hierarchy are coupled with the clusters at the same level of the other hierarchy and form the co-clusters. Each cluster of one of the two hierarchies thus provides insights on the clusters of the other hierarchy. Another novelty of the proposed solution is that the number of clusters is possibly unlimited. Nevertheless, the produced hierarchies are still compact and therefore more readable because our method allows multiple splits of a cluster at the lower level. As regards the second challenge, the accumulating nature of the data makes the datasets intractably huge over time. In this case, an incremental solution relieves the issue because it partitions the problem. In this paper we introduce an incremental version of our algorithm of hierarchical co-clustering. It starts from an intermediate solution computed on the previous version of the data and it updates the co-clustering results considering only the added block of data. This solution has the merit of speeding up the computation with respect to the original approach that would recompute the result on the overall dataset. In addition, the incremental algorithm guarantees approximately the same answer than the original version, but it saves much computational load. We validate the incremental approach on several high-dimensional datasets and perform an accurate comparison with both the original version of our algorithm and with the state of the art competitors as well. The obtained results open the way to a novel usage of the co-clustering algorithms in which it is advantageous to partition the data into several blocks and process them incrementally thus \"incorporating\" data gradually into an on-going co-clustering solution.", "paper_title": "Hierarchical co-clustering: off-line and incremental approaches", "paper_id": "WOS:000329229100002"}