{"auto_keywords": [{"score": 0.04882787382338285, "phrase": "dialogue_systems"}, {"score": 0.03824236520910253, "phrase": "dialogue_system"}, {"score": 0.00481495049065317, "phrase": "state_representations"}, {"score": 0.004764220976404241, "phrase": "spoken_dialogue_systems"}, {"score": 0.0044237033788643715, "phrase": "accurate_ways"}, {"score": 0.004353948887538618, "phrase": "different_systems"}, {"score": 0.004129248271757936, "phrase": "task_completion_rate"}, {"score": 0.004085713541752114, "phrase": "user_satisfaction"}, {"score": 0.004021267064832957, "phrase": "different_aspects"}, {"score": 0.003957833102043277, "phrase": "end-to-end_human-computer_dialogue_interaction"}, {"score": 0.0036942726653704213, "phrase": "complete_evaluation"}, {"score": 0.0031845067058084583, "phrase": "best_state_space_representations"}, {"score": 0.0031342307827666675, "phrase": "reinforcement_learning_model"}, {"score": 0.0030684249587688826, "phrase": "optimal_dialogue_control_strategy"}, {"score": 0.0029098743621130004, "phrase": "different_state_models"}, {"score": 0.0027741761880779535, "phrase": "spoken_dialogue"}, {"score": 0.0027594936602962075, "phrase": "tutoring_system"}, {"score": 0.0027015344365793016, "phrase": "relative_utility"}, {"score": 0.0022434880661725493, "phrase": "better_dialogue_manager"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["spoken dialogue systems", " evaluation", " adaptive systems", " Reinforcement Learning", " Markov decision processes", " feature selection", " machine learning", " affect", " tutoring systems"], "paper_abstract": "Although dialogue systems have been all area of research for decades, finding accurate ways of evaluating different systems is still a very active subfield since many leading methods, such as task completion rate or user satisfaction, capture different aspects of the end-to-end human-computer dialogue interaction. In this work, we step back the focus from the complete evaluation of a dialogue system to presenting metrics for evaluating one internal component of a dialogue system: its dialogue manager. Specifically, we investigate how to create and evaluate the best state space representations for a Reinforcement Learning model to learn an optimal dialogue control strategy. We present three metrics for evaluating the impact of different state models and demonstrate their use oil the domain of a spoken dialogue tutoring system by comparing the relative utility of adding three features to a model of user, or student, state. The motivation for this work is that if one knows which features are best to use, one can construct a better dialogue manager, and thus better performing dialogue systems. (c) 2008 Elsevier B.V. All rights reserved.", "paper_title": "A Reinforcement Learning approach to evaluating state representations in spoken dialogue systems", "paper_id": "WOS:000258814000005"}