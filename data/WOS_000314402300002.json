{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "kernel_entropy-based"}, {"score": 0.00462919213721188, "phrase": "individual_features"}, {"score": 0.004548939310612501, "phrase": "utility_criterion"}, {"score": 0.004450568197899267, "phrase": "optimal_feature"}, {"score": 0.004373398434399966, "phrase": "greedy_manner"}, {"score": 0.004278807087784626, "phrase": "feature_combinations"}, {"score": 0.0041316803676012155, "phrase": "optimal_classification_performance"}, {"score": 0.003769006950727621, "phrase": "novel_feature_selection_technique"}, {"score": 0.0037198532511087566, "phrase": "spectral_data_transformation"}, {"score": 0.003623453648863547, "phrase": "subset_selection"}, {"score": 0.0035141291835319682, "phrase": "new_two-step_spectral_regression_technique"}, {"score": 0.003393206299636482, "phrase": "first_step"}, {"score": 0.003334309053314909, "phrase": "kernel_entropy_component_analysis"}, {"score": 0.003191485583025302, "phrase": "lower-dimensional_space"}, {"score": 0.0031223774204093713, "phrase": "class_separation"}, {"score": 0.002749980017065414, "phrase": "data_transformation"}, {"score": 0.0027140798043053986, "phrase": "entropy_estimates"}, {"score": 0.0026786469998321084, "phrase": "input_data"}, {"score": 0.0026091594819333654, "phrase": "cluster_structure"}, {"score": 0.002497319603143104, "phrase": "feature_discriminant_analysis"}, {"score": 0.002464709648714996, "phrase": "regression_framework"}, {"score": 0.0023079225317714815, "phrase": "joint_feature_combinations"}, {"score": 0.0021993066642488237, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "standard_face_datasets"}], "paper_keywords": ["Kernel entropy component analysis", " unsupervised spectral feature selection"], "paper_abstract": "Most existing feature selection methods focus on ranking individual features based on a utility criterion, and select the optimal feature set in a greedy manner. However, the feature combinations found in this way do not give optimal classification performance, since they neglect the correlations among features. In an attempt to overcome this problem, we develop a novel feature selection technique using the spectral data transformation and by using l(1)-norm regularized models for subset selection. Specifically, we propose a new two-step spectral regression technique for unsupervised feature selection. In the first step, we use kernel entropy component analysis (kECA) to transform the data into a lower-dimensional space so as to improve class separation. Second, we use l(1)-norm regularization to select the features that best align with the data embedding resulting from kECA. The advantage of kECA is that dimensionality reducing data transformation maximally preserves entropy estimates for the input data whilst also best preserving the cluster structure of the data. Using l(1)-norm regularization, we cast feature discriminant analysis into a regression framework which accommodates the correlations among features. As a result, we can evaluate joint feature combinations, rather than being confined to consider them individually. Experimental results demonstrate the effectiveness of our feature selection method on a number of standard face datasets.", "paper_title": "KERNEL ENTROPY-BASED UNSUPERVISED SPECTRAL FEATURE SELECTION", "paper_id": "WOS:000314402300002"}