{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "matrix_completion"}, {"score": 0.004578783486828809, "phrase": "fast_alternating_least_squares"}, {"score": 0.004481132747216135, "phrase": "matrix-completion_problem"}, {"score": 0.004052148727852149, "phrase": "celebrated_netflix_competition"}, {"score": 0.0038256426589560774, "phrase": "nuclear-norm-regularized_matrix_approximation"}, {"score": 0.003611751858608048, "phrase": "mazumder_et_al"}, {"score": 0.002952745241052452, "phrase": "equivalent_problems"}, {"score": 0.0028689475587958917, "phrase": "quite_different_algorithms"}, {"score": 0.0025938977569302177, "phrase": "efficient_algorithm"}, {"score": 0.0025568135952982345, "phrase": "large_matrix_factorization"}, {"score": 0.0023451553255837317, "phrase": "software_package_softimpute"}, {"score": 0.0021049977753042253, "phrase": "spark_cluster_programming_environment"}], "paper_keywords": ["matrix completion", " alternating least squares", " svd", " nuclear norm"], "paper_abstract": "The matrix-completion problem has attracted a lot of attention, largely as a result of the celebrated Netflix competition. Two popular approaches for solving the problem are nuclear-norm-regularized matrix approximation (Candes and Tao, 2009; Mazumder et al., 2010), and maximum-margin matrix factorization (Srebro et al., 2005). These two procedures are in some cases solving equivalent problems, but with quite different algorithms. In this article we bring the two approaches together, leading to an efficient algorithm for large matrix factorization and completion that outperforms both of these. We develop a software package softImpute in R for implementing our approaches, and a distributed version for very large matrices using the Spark cluster programming environment", "paper_title": "Matrix Completion and Low-Rank SVD via Fast Alternating Least Squares", "paper_id": "WOS:000369888000033"}