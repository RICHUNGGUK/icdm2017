{"auto_keywords": [{"score": 0.03705913838294769, "phrase": "input_patterns"}, {"score": 0.00481495049065317, "phrase": "nonlinear_classification"}, {"score": 0.00476323161560059, "phrase": "simple_classifiers"}, {"score": 0.004561826854638056, "phrase": "side_effect"}, {"score": 0.00436890075128947, "phrase": "good_idea"}, {"score": 0.003921393143378986, "phrase": "complex_patterns"}, {"score": 0.003775803846431323, "phrase": "hybrid_classifier"}, {"score": 0.0032629585038738856, "phrase": "\"dividing\"_step"}, {"score": 0.0031417377608722, "phrase": "linearly_separable_and_nonlinearly_separable_groups"}, {"score": 0.0030250067691601967, "phrase": "first_group"}, {"score": 0.002944284514509205, "phrase": "simple_classifier"}, {"score": 0.0028968858148006823, "phrase": "second_group_patterns"}, {"score": 0.0027443174539994925, "phrase": "\"modeling\"_step"}, {"score": 0.0026710653215026685, "phrase": "previous_steps"}, {"score": 0.0025857324180891526, "phrase": "\"combining\"_step"}, {"score": 0.002333044307949414, "phrase": "experimental_results"}, {"score": 0.002270745003370529, "phrase": "new_classifier"}, {"score": 0.002246292543825748, "phrase": "famous_classifiers"}, {"score": 0.0022101055924375725, "phrase": "\"support_vector_machine"}, {"score": 0.0021049977753042253, "phrase": "classification_and_regression_trees"}], "paper_keywords": ["Linear classification", " Multiple classifier system", " Constrained classification", " Classifier boosting"], "paper_abstract": "Simple classifiers have the advantage of more generalization capability with the side effect of less power. It would be a good idea if we could build a classifier which is as simple as possible while giving it the ability of classifying complex patterns. In this paper, a hybrid classifier called \"constrained classifier\" is presented that classifies most of the input patterns using a simple, for example, a linear classifier. It performs the classification in four steps. In the \"Dividing\" step, the input patterns are divided into linearly separable and nonlinearly separable groups. The patterns belonging to the first group are classified using a simple classifier while the second group patterns (named \"constraints\") are modeled in the \"Modeling\" step. The results of previous steps are merged together in the \"Combining\" step. The \"Evaluation\" step tests and fine tunes the membership of patterns into two groups. The experimental results of comparison of the new classifier with famous classifiers such as \"support vector machine\", k-NN, and \"Classification and Regression Trees\" are very encouraging.", "paper_title": "Constrained classifier: a novel approach to nonlinear classification", "paper_id": "WOS:000326889800056"}