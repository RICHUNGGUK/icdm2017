{"auto_keywords": [{"score": 0.05007060954256109, "phrase": "ridge_regression"}, {"score": 0.033189123614918076, "phrase": "lasso"}, {"score": 0.026158192285301977, "phrase": "relevant_variables"}, {"score": 0.004455272634364756, "phrase": "simple_or_naive_approach"}, {"score": 0.0042148594491580324, "phrase": "current_residuals"}, {"score": 0.004076858589744185, "phrase": "usual_ridge_estimator"}, {"score": 0.0038998328617557013, "phrase": "regression_parameters"}, {"score": 0.003751228706861377, "phrase": "iterative_procedure"}, {"score": 0.003588291565092195, "phrase": "mandatory_variables"}, {"score": 0.003451517638449501, "phrase": "analysis_and_optional_variables"}, {"score": 0.003283272764794988, "phrase": "resulting_procedure"}, {"score": 0.0032470094613727433, "phrase": "optional_variables"}, {"score": 0.0031933617014256676, "phrase": "similar_way"}, {"score": 0.0030715948036518603, "phrase": "reduced_set"}, {"score": 0.0030376623293574905, "phrase": "influential_variables"}, {"score": 0.0029544572689681934, "phrase": "regularized_estimation"}, {"score": 0.002905629026254221, "phrase": "mandatory_parameters"}, {"score": 0.002857605453835429, "phrase": "suggested_procedures"}, {"score": 0.002779318608820933, "phrase": "classical_framework"}, {"score": 0.0027486060614330043, "phrase": "continuous_response_variables"}, {"score": 0.00262910358108176, "phrase": "generalized_linear_models"}, {"score": 0.0022007302738063566, "phrase": "pseudo_roc_curves"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["ridge regression", " boosting", " Lasso", " mandatory variables", " pseudo ROC curves"], "paper_abstract": "There are several possible approaches to combining ridge regression with boosting techniques. In the simple or naive approach the ridge estimator is used to fit iteratively the current residuals yielding an alternative to the usual ridge estimator. In partial boosting only part of the regression parameters are reestimated within one step of the iterative procedure. The technique allows to distinguish between mandatory variables that are always included in the analysis and optional variables that are chosen only if relevant. The resulting procedure selects optional variables in a similar way as the Lasso, yielding a reduced set of influential variables, while allowing for regularized estimation of the mandatory parameters. The suggested procedures are investigated within the classical framework of continuous response variables as well as in the case of generalized linear models. The performance in terms of prediction and the identification of relevant variables is compared to several competitors as the Lasso and the more recently proposed elastic net. For the evaluation of the identification of relevant variables pseudo ROC curves are introduced. (C) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Boosting ridge regression", "paper_id": "WOS:000249316000047"}