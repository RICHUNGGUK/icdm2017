{"auto_keywords": [{"score": 0.049558064870310475, "phrase": "multilabel_learning"}, {"score": 0.039956708727325464, "phrase": "variable_selection"}, {"score": 0.011857483191971628, "phrase": "multilabel_data"}, {"score": 0.010072782821426677, "phrase": "logistic_regression"}, {"score": 0.009435787426788574, "phrase": "elastic_net_penalty"}, {"score": 0.00481495049065317, "phrase": "sparse_logistic_regression"}, {"score": 0.004608730887154718, "phrase": "machine_learning"}, {"score": 0.004508942069742167, "phrase": "increasing_attention"}, {"score": 0.004268780663872836, "phrase": "high-dimensional_multilabel_data"}, {"score": 0.004130842663662047, "phrase": "real-world_applications"}, {"score": 0.0040192915527630995, "phrase": "open_issue"}, {"score": 0.0037636590459094762, "phrase": "traditional_data"}, {"score": 0.003429001377800258, "phrase": "novel_framework"}, {"score": 0.0027996401456881806, "phrase": "logistic_regression_model"}, {"score": 0.002753971418809189, "phrase": "ill-conditioned_and_over-fitting_problems"}, {"score": 0.002522662955545598, "phrase": "convex_optimization_problem"}, {"score": 0.0024143815950383647, "phrase": "quadratic_approximation_technique"}, {"score": 0.0023749823753904204, "phrase": "experimental_results"}, {"score": 0.002349073225500705, "phrase": "seven_multilabel_data_sets"}, {"score": 0.002273025527678093, "phrase": "encouraging_performance"}, {"score": 0.00221153232497724, "phrase": "six_popular_multilabel_learning_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Sparse learning", " Logistic regression", " Multilabel data", " Elastic net", " Variable selection"], "paper_abstract": "Multilabel learning, an emerging topic in machine learning, has received increasing attention in recent years. However, how to effectively tackle high-dimensional multilabel data, which are ubiquitous in real-world applications, is still an open issue in multilabel learning. Although many efforts have been made in variable selection for traditional data, little work concerns variable selection for multilabel data yet. In this paper, we propose a novel framework for multilabel learning, which can achieve the purposes of variable selection and classification learning simultaneously. Specifically, our method exploits logistic regression to train models on multilabel data for classification. Besides, an elastic net penalty is performed on the logistic regression model to handle ill-conditioned and over-fitting problems of high-dimensional data. To further improve the efficiency, we solve the convex optimization problem of logistic regression with the elastic net penalty by a quadratic approximation technique. The experimental results on seven multilabel data sets show that our method has achieved encouraging performance and is competitive with six popular multilabel learning algorithms in most cases. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "MLSLR: Multilabel Learning via Sparse Logistic Regression", "paper_id": "WOS:000340315600020"}