{"auto_keywords": [{"score": 0.04838919478929022, "phrase": "stochastic_complexity"}, {"score": 0.00481495049065317, "phrase": "discrete_data_clustering"}, {"score": 0.004757643419056999, "phrase": "feature_weighting"}, {"score": 0.004705340500732671, "phrase": "map"}, {"score": 0.0041703614123283165, "phrase": "discrete_data"}, {"score": 0.004096082254543022, "phrase": "important_component"}, {"score": 0.003633464433320317, "phrase": "published_work"}, {"score": 0.0035901685646972585, "phrase": "unsupervised_feature_selection"}, {"score": 0.0035051129798529, "phrase": "continuous_data"}, {"score": 0.0034016119212097826, "phrase": "probabilistic_approach"}, {"score": 0.0033409791799749434, "phrase": "relevance_weights"}, {"score": 0.0033011569787033297, "phrase": "discrete_features"}, {"score": 0.0032036590920314725, "phrase": "random_variables"}, {"score": 0.0031465436619697385, "phrase": "finite_discrete_mixtures"}, {"score": 0.003053598205821532, "phrase": "finite_mixture_models"}, {"score": 0.0028586409810976367, "phrase": "different_domains"}, {"score": 0.002660818568678647, "phrase": "bayesian"}, {"score": 0.0025202582748972122, "phrase": "experimental_results"}, {"score": 0.0023311233166534214, "phrase": "difficult_problem"}, {"score": 0.0022486729928886885, "phrase": "visual_concepts"}, {"score": 0.0022218413146898887, "phrase": "different_image_data"}, {"score": 0.0021821915946356168, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "text_clustering"}], "paper_keywords": ["Discrete data", " finite mixture models", " multinomial", " Dirichlet prior", " feature weighting/selection", " MAP", " stochastic complexity", " Fisher kernel", " image databases", " text clustering"], "paper_abstract": "In this paper, we consider the problem of unsupervised discrete feature selection/weighting. Indeed, discrete data are an important component in many data mining, machine learning, image processing, and computer vision applications. However, much of the published work on unsupervised feature selection has concentrated on continuous data. We propose a probabilistic approach that assigns relevance weights to discrete features that are considered as random variables modeled by finite discrete mixtures. The choice of finite mixture models is justified by its flexibility which has led to its widespread application in different domains. For the learning of the model, we consider both Bayesian and information-theoretic approaches through stochastic complexity. Experimental results are presented to illustrate the feasibility and merits of our approach on a difficult problem which is clustering and recognizing visual concepts in different image data. The proposed approach is successfully applied also for text clustering.", "paper_title": "A Model-Based Approach for Discrete Data Clustering and Feature Weighting Using MAP and Stochastic Complexity", "paper_id": "WOS:000271903700001"}