{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "faulty_memories"}, {"score": 0.004278807087784626, "phrase": "memory_faults"}, {"score": 0.0038624981944755813, "phrase": "memory_values"}, {"score": 0.0035699363258657212, "phrase": "correct_output"}, {"score": 0.003378385493203297, "phrase": "uncorrupted_values"}, {"score": 0.0021384748235753425, "phrase": "upper_bounds"}, {"score": 0.0021049977753042253, "phrase": "resilient_searching"}], "paper_keywords": ["Combinatorial algorithms", " Sorting", " Searching", " Memory faults", " Memory models", " Computing with unreliable information"], "paper_abstract": "In this paper we investigate the design and analysis of algorithms resilient to memory faults. We focus on algorithms that, despite the corruption of some memory values during their execution, are nevertheless able to produce a correct output at least on the set of uncorrupted values. In this framework, we consider two fundamental problems: sorting and searching. In particular, we prove that any O(n log n) comparison-based sorting algorithm can tolerate the corruption of at most O((n log n)(1/2)) keys. Furthermore, we present one comparison-based sorting algorithm with optimal space and running time that is resilient to O((n log n)(1/3)) memory faults. We also prove polylogarithmic lower and upper bounds on resilient searching.", "paper_title": "Sorting and Searching in Faulty Memories", "paper_id": "WOS:000260524000001"}