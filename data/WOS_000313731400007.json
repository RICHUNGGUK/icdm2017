{"auto_keywords": [{"score": 0.040179907029343674, "phrase": "particle_filtering"}, {"score": 0.004123781267600542, "phrase": "general_state-space_models"}, {"score": 0.003592859432554987, "phrase": "map_estimator"}, {"score": 0.0030414140732789186, "phrase": "last_part"}, {"score": 0.00283870598459543, "phrase": "map_estimation"}, {"score": 0.002790170184447136, "phrase": "global_optimization"}, {"score": 0.002472822097373027, "phrase": "map_sequence_estimation"}, {"score": 0.0024305268807926056, "phrase": "state-space_model"}, {"score": 0.0021049977753042253, "phrase": "numerical_results"}], "paper_keywords": ["Sequential Monte Carlo", " MAP sequence estimation", " Convergence of particle filters", " State space models", " Global optimization"], "paper_abstract": "This paper addresses the problem of maximum a posteriori (MAP) sequence estimation in general state-space models. We consider two algorithms based on the sequential Monte Carlo (SMC) methodology (also known as particle filtering). We prove that they produce approximations of the MAP estimator and that they converge almost surely. We also derive a lower bound for the number of particles that are needed to achieve a given approximation accuracy. In the last part of the paper, we investigate the application of particle filtering and MAP estimation to the global optimization of a class of (possibly non-convex and possibly non-differentiable) cost functions. In particular, we show how to convert the cost-minimization problem into one of MAP sequence estimation for a state-space model that is \"matched\" to the cost of interest. We provide examples that illustrate the application of the methodology as well as numerical results.", "paper_title": "On the convergence of two sequential Monte Carlo methods for maximum a posteriori sequence estimation and stochastic global optimization", "paper_id": "WOS:000313731400007"}