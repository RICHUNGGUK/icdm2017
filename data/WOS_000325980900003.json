{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "sparse_kernel_classifiers"}, {"score": 0.043284735713932626, "phrase": "mi_classification"}, {"score": 0.041947888026124834, "phrase": "individual_instances"}, {"score": 0.004762893197005439, "phrase": "multi-instance_classification"}, {"score": 0.004635187610736025, "phrase": "direct_approach"}, {"score": 0.004342430078306461, "phrase": "predictive_accuracy"}, {"score": 0.004272164161788242, "phrase": "proposed_method"}, {"score": 0.004180234323211199, "phrase": "convex_formulation"}, {"score": 0.004046020290832207, "phrase": "average_score"}, {"score": 0.003958937342925219, "phrase": "bag-level_prediction"}, {"score": 0.0038527044625533574, "phrase": "existing_formulations"}, {"score": 0.0037903327482565097, "phrase": "maximum_score"}, {"score": 0.003589602322126282, "phrase": "nonconvex_optimization_problems"}, {"score": 0.00349324530379071, "phrase": "convex_mi_framework"}, {"score": 0.003399466007862412, "phrase": "sparse_kernel"}, {"score": 0.003308195943172624, "phrase": "additional_constraints"}, {"score": 0.0032546105164772995, "phrase": "objective_function"}, {"score": 0.0031845067058084613, "phrase": "maximum_number"}, {"score": 0.0030821633718368206, "phrase": "prediction_function"}, {"score": 0.003032228032253871, "phrase": "formulated_sparse_learning_problem"}, {"score": 0.0028715299874549245, "phrase": "classifier_weights"}, {"score": 0.0027491084541806823, "phrase": "effective_optimization_strategy"}, {"score": 0.0026898636962522505, "phrase": "optimization_problem"}, {"score": 0.002631892325004253, "phrase": "joint_learning"}, {"score": 0.0025611773887867255, "phrase": "expansion_vectors"}, {"score": 0.0024788167298469455, "phrase": "proposed_formulation"}, {"score": 0.0023730978395564116, "phrase": "prediction_model"}, {"score": 0.0023219374444738723, "phrase": "competitive_predictive_performance"}, {"score": 0.0022967713922705, "phrase": "experimental_results"}, {"score": 0.0022718774783143203, "phrase": "benchmark_data_sets"}, {"score": 0.0021396960731214203, "phrase": "comparable_performance"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_mi_classifiers"}], "paper_keywords": ["Classification", " convex optimization", " kernel machines", " multi-instance learning (MI)"], "paper_abstract": "We propose a direct approach to learning sparse kernel classifiers for multi-instance (MI) classification to improve efficiency while maintaining predictive accuracy. The proposed method builds on a convex formulation for MI classification by considering the average score of individual instances for bag-level prediction. In contrast, existing formulations used the maximum score of individual instances in each bag, which leads to nonconvex optimization problems. Based on the convex MI framework, we formulate a sparse kernel learning algorithm by imposing additional constraints on the objective function to enforce the maximum number of expansions allowed in the prediction function. The formulated sparse learning problem for the MI classification is convex with respect to the classifier weights. Therefore, we can employ an effective optimization strategy to solve the optimization problem that involves the joint learning of both the classifier and the expansion vectors. In addition, the proposed formulation can explicitly control the complexity of the prediction model while still maintaining competitive predictive performance. Experimental results on benchmark data sets demonstrate that our proposed approach is effective in building very sparse kernel classifiers while achieving comparable performance to the state-of-the-art MI classifiers.", "paper_title": "Learning Sparse Kernel Classifiers for Multi-Instance Classification", "paper_id": "WOS:000325980900003"}