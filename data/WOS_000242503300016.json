{"auto_keywords": [{"score": 0.044073662538524724, "phrase": "turbo_decoder"}, {"score": 0.010612387000973441, "phrase": "maximum-likelihood_sequence_detection"}, {"score": 0.00999530067512479, "phrase": "optimization_problem"}, {"score": 0.008385236101902947, "phrase": "false_assumption"}, {"score": 0.004159446063902181, "phrase": "iterative_method"}, {"score": 0.004053362743156545, "phrase": "intuitively_pleasing_constrained_optimization_problem"}, {"score": 0.003899269293218826, "phrase": "maximum-likelihood_sequence"}, {"score": 0.0038658324462031916, "phrase": "mls"}, {"score": 0.0035620354052144656, "phrase": "parallel_case"}, {"score": 0.003441352119167824, "phrase": "outer_encoder"}, {"score": 0.003310447652300423, "phrase": "inner_encoder"}, {"score": 0.003267925215811654, "phrase": "serial_case"}, {"score": 0.002934098412396701, "phrase": "independent_messages"}, {"score": 0.0028468767420392945, "phrase": "constraining_probability"}, {"score": 0.0027861630854233693, "phrase": "global_maximum"}, {"score": 0.0027503564589458837, "phrase": "constrained_optimization_problem"}, {"score": 0.002622947550220266, "phrase": "theoretical_connection"}, {"score": 0.0026004229197334875, "phrase": "turbo_decoding"}, {"score": 0.002578091348028001, "phrase": "mlsd."}, {"score": 0.002469269628821745, "phrase": "nonlinear_block"}, {"score": 0.0024586427394152196, "phrase": "gauss-seidel_iteration"}, {"score": 0.002325124852044412, "phrase": "lagrangian"}, {"score": 0.002294686545883412, "phrase": "lagrange_multiplier"}, {"score": 0.0021232402128269906, "phrase": "existing_literature"}, {"score": 0.0021049977753042253, "phrase": "gauss-seidel_iterations"}], "paper_keywords": ["constrained optimization", " maximum-likelihood decoding", " turbo decoder convergence analysis"], "paper_abstract": "The turbo decoder was not originally introduced as a solution to an optimization problem, which has impeded attempts to explain its excellent performance. Here it is shown, that the turbo decoder is an iterative method seeking a solution to an intuitively pleasing constrained optimization problem. In particular, the turbo decoder seeks the maximum-likelihood sequence (MLS) under the false assumption that the input to the encoders are chosen independently of each other in the parallel case, or that the output of the outer encoder is chosen independently of the input to the inner encoder in the serial case. To control the. error introduced by the false assumption, the optimizations are performed subject to a constraint on the probability that the independent messages happen to coincide. When the constraining probability equals one, the global maximum of the constrained optimization problem is the maximum-likelihood sequence detection (MLSD), allowing for a theoretical connection between turbo decoding and MLSD. It is then shown that the turbo decoder is a nonlinear block Gauss-Seidel iteration that aims to solve the optimization problem by zeroing the gradient of the Lagrangian with a Lagrange multiplier of -1. Some conditions for the convergence for the turbo decoder are then given by adapting the existing literature for Gauss-Seidel iterations.", "paper_title": "Turbo decoding as iterative constrained maximum-likelihood sequence detection", "paper_id": "WOS:000242503300016"}