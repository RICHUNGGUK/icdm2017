{"auto_keywords": [{"score": 0.04255944800395906, "phrase": "rl-dot"}, {"score": 0.013897101050897021, "phrase": "npc"}, {"score": 0.012919690208659526, "phrase": "commander_npc"}, {"score": 0.00481495049065317, "phrase": "domination_games"}, {"score": 0.004524348699657099, "phrase": "reinforcement-_learning-based_domination_team"}, {"score": 0.003627800727103479, "phrase": "decision_cycle"}, {"score": 0.003467040410632942, "phrase": "troop_distribution"}, {"score": 0.0032946562900625187, "phrase": "action_orders"}, {"score": 0.0030606302942851027, "phrase": "goal-directed_way"}, {"score": 0.002958281631770322, "phrase": "final_ultimate_task"}, {"score": 0.002859345731792013, "phrase": "domination_point"}, {"score": 0.0028111220617485985, "phrase": "basic_actions"}, {"score": 0.0026113524778702624, "phrase": "ut_application_programming_interfaces"}, {"score": 0.002495521662819317, "phrase": "q-learning-style_algorithm"}, {"score": 0.0024395426929046415, "phrase": "optimal_decision-making_policy"}, {"score": 0.0023579143175099324, "phrase": "opponent_policies"}, {"score": 0.0021049977753042253, "phrase": "ut_domination_games"}], "paper_keywords": ["Domination game", " hierarchical task networks", " opponent modeling", " reinforcement learning", " unreal tournament"], "paper_abstract": "In this paper, we describe the design of reinforcement- learning-based domination team (RL-DOT), a nonplayer character (NPC) team for playing Unreal Tournament (UT) Domination games. In RL-DOT, there is a commander NPC and several soldier NPCs. The running process of RL-DOT consists of several decision cycles. In each decision cycle, the commander NPC makes a decision of troop distribution and, according to that decision, sends action orders to other soldier NPCs. Each soldier NPC tries to accomplish its task in a goal-directed way, i.e., decomposing the final ultimate task (attacking or defending a domination point) into basic actions (such as running and shooting) that are directly supported by UT application programming interfaces (APIs). We use a Q-learning-style algorithm to learn the optimal decision-making policy. We carefully choose some opponent policies for our illustrative experiments. In these experiments, RL-DOT shows a distinct learning characteristic, which illustrates its efficiency in playing UT Domination games.", "paper_title": "RL-DOT: A Reinforcement Learning NPC Team for Playing Domination Games", "paper_id": "WOS:000295471200002"}