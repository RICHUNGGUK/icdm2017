{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "lognormal_distribution"}, {"score": 0.04057628889870324, "phrase": "record_data"}, {"score": 0.015396094742000188, "phrase": "record_scheme"}, {"score": 0.012500201296972971, "phrase": "exponential_distribution"}, {"score": 0.01242589593416238, "phrase": "j._statist"}, {"score": 0.008950495938491232, "phrase": "inference"}, {"score": 0.004616624583337195, "phrase": "total_time"}, {"score": 0.004347327095048136, "phrase": "previous_ones"}, {"score": 0.003984391456005223, "phrase": "usual_random_sample_scheme"}, {"score": 0.00396050388346298, "phrase": "m._doostparast"}, {"score": 0.00393675895773741, "phrase": "n._balakrishnan"}, {"score": 0.0038431888954930083, "phrase": "associated_cost_analysis"}, {"score": 0.003438443236358964, "phrase": "samaniego"}, {"score": 0.0034178172945513855, "phrase": "whitaker"}, {"score": 0.003376933842097587, "phrase": "population_characteristics"}, {"score": 0.003356675879109443, "phrase": "record_breaking_observations_i._parametric_results"}, {"score": 0.0033365390352128065, "phrase": "naval_res"}, {"score": 0.0033165225911231115, "phrase": "logist"}, {"score": 0.003085460307255466, "phrase": "metrika"}, {"score": 0.002922759536495576, "phrase": "wide_range"}, {"score": 0.0028791027911595976, "phrase": "multiplicative_scale"}, {"score": 0.0027519956065269126, "phrase": "data_distribution"}, {"score": 0.0025371413754846474, "phrase": "point_estimates"}, {"score": 0.002506766880001808, "phrase": "confidence_intervals"}, {"score": 0.0024842242921857705, "phrase": "unknown_parameters"}, {"score": 0.00240328454980006, "phrase": "bayesian_point"}, {"score": 0.0022971354864013073, "phrase": "simulation_study"}, {"score": 0.0021693692831601745, "phrase": "lifetime_data"}, {"score": 0.002130514432266586, "phrase": "john_wiley"}, {"score": 0.0021049977753042253, "phrase": "new_york"}], "paper_keywords": ["Bayes estimation", " confidence interval", " Fisher information", " inter-record times", " LINEX loss function", " lognormal model", " maximum-likelihood estimator", " record values"], "paper_abstract": "Record scheme is a method to reduce the total time on test of an experiment. In this scheme, items are sequentially observed and only values smaller than all previous ones are recorded. In some situations, when the experiments are time-consuming and sometimes the items are lost during the experiment, the record scheme dominates the usual random sample scheme [M. Doostparast and N. Balakrishnan, Optimal sample size for record data and associated cost analysis for exponential distribution, J. Statist. Comput. Simul. 80(12) (2010), pp. 1389-1401]. Estimation of the mean of an exponential distribution based on record data has been treated by Samaniego and Whitaker [On estimating population characteristics from record breaking observations I. Parametric results, Naval Res. Logist. Q. 33 (1986), pp. 531-543] and Doostparast [A note on estimation based on record data, Metrika 69 (2009), pp. 69-80]. The lognormal distribution is used in a wide range of applications when the multiplicative scale is appropriate and the log-transformation removes the skew and brings about symmetry of the data distribution [N. T. Longford, Inference with the lognormal distribution, J. Statist. Plann. Inference 139 (2009), pp. 2329-2340]. In this paper, point estimates as well as confidence intervals for the unknown parameters are obtained. This will also be addressed by the Bayesian point of view. To carry out the performance of the estimators obtained, a simulation study is conducted. For illustration proposes, a real data set, due to Lawless [Statistical Models and Methods for Lifetime Data, 2nd ed., John Wiley & Sons, New York, 2003], is analysed using the procedures obtained.", "paper_title": "Estimation with the lognormal distribution on the basis of records", "paper_id": "WOS:000336520100011"}