{"auto_keywords": [{"score": 0.04887366145178028, "phrase": "support_vector_machines"}, {"score": 0.044107407862903625, "phrase": "out-of-sample_methods"}, {"score": 0.00481495049065317, "phrase": "-sample_model_selection"}, {"score": 0.004529093447865156, "phrase": "model_selection"}, {"score": 0.0033857878144822906, "phrase": "recent_and_not-so-recent_results"}, {"score": 0.003334309053314909, "phrase": "data-dependent_structural_risk_minimization_framework"}, {"score": 0.0032008144731234265, "phrase": "svm_learning_algorithm"}, {"score": 0.00290473242917264, "phrase": "simulated_and_real-world_datasets"}, {"score": 0.002622528664187849, "phrase": "latter_ones"}, {"score": 0.0025958582759972315, "phrase": "questionable_results"}, {"score": 0.0023435920614377306, "phrase": "microarray_data"}, {"score": 0.002284444272376043, "phrase": "conventional_out-of-sample_approaches"}, {"score": 0.0021051563748538797, "phrase": "bootstrap"}], "paper_keywords": ["Bootstrap", " cross validation", " error estimation", " leave one out", " model selection", " statistical learning theory (SLT)", " structural risk minimization (SRM)", " support vector machine (SVM)"], "paper_abstract": "In-sample approaches to model selection and error estimation of support vector machines (SVMs) are not as widespread as out-of-sample methods, where part of the data is removed from the training set for validation and testing purposes, mainly because their practical application is not straightforward and the latter provide, in many cases, satisfactory results. In this paper, we survey some recent and not-so-recent results of the data-dependent structural risk minimization framework and propose a proper reformulation of the SVM learning algorithm, so that the in-sample approach can be effectively applied. The experiments, performed both on simulated and real-world datasets, show that our in-sample approach can be favorably compared to out-of-sample methods, especially in cases where the latter ones provide questionable results. In particular, when the number of samples is small compared to their dimensionality, like in classification of microarray data, our proposal can outperform conventional out-of-sample approaches such as the cross validation, the leave-one-out, or the Bootstrap methods.", "paper_title": "In-Sample and Out-of-Sample Model Selection and Error Estimation for Support Vector Machines", "paper_id": "WOS:000308965800005"}