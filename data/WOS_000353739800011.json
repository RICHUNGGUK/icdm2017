{"auto_keywords": [{"score": 0.04020394874646987, "phrase": "prediction_performance"}, {"score": 0.03648392423631911, "phrase": "fit_criteria"}, {"score": 0.00481495049065317, "phrase": "neural_network_model_averaging"}, {"score": 0.004761494044422926, "phrase": "data_based_modeling_applications"}, {"score": 0.004682414867878963, "phrase": "complete_automation"}, {"score": 0.004630423009638876, "phrase": "model_creation"}, {"score": 0.004403480614319231, "phrase": "numerous_model_architectures"}, {"score": 0.00428222231579898, "phrase": "complex_data_structures"}, {"score": 0.00409508755819924, "phrase": "best_model"}, {"score": 0.004027031316965272, "phrase": "present_challenge"}, {"score": 0.0039380388343479384, "phrase": "model_ensembles"}, {"score": 0.00389427992231721, "phrase": "excellent_strategies"}, {"score": 0.003601235776892337, "phrase": "information_criteria"}, {"score": 0.003405472159599445, "phrase": "average_variance_error"}, {"score": 0.003348838095597268, "phrase": "model_structures"}, {"score": 0.0031140747752837826, "phrase": "sparse_data_sets"}, {"score": 0.0030794433253250476, "phrase": "complex_model_structures"}, {"score": 0.0027535633837592597, "phrase": "weight_calculation_building_model_ensembles"}, {"score": 0.002574788013427524, "phrase": "empirical_measures"}, {"score": 0.0024897902536499005, "phrase": "model_ensemble_prediction_performance"}, {"score": 0.0023807981747706376, "phrase": "model_class"}, {"score": 0.0023151088048303705, "phrase": "black_box_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Neural networks", " Nonlinear regression", " Model ensembles", " Empirical risk", " Information criteria"], "paper_abstract": "Data based modeling applications require the complete automation of model creation of, in general, nonlinear processes. Numerous model architectures are available to approximate complex data structures, however, creating and selecting the best model provides a present challenge for application. Model ensembles provide excellent strategies if the prediction performance of the models can be assessed in some way. Information criteria approaches, trading off goodness of fit criteria against the average variance error of the model structures, are theoretically applicable, but demonstratively perform poorly in settings with sparse data sets and complex model structures, settings which are present for many industrial purposes. This paper proposes and discusses a methodology how to regularise the weight calculation building model ensembles. Thereby, the weights trade off goodness of fit criteria against empirical measures of risk, increasing the model ensemble prediction performance. The methodology is independent of the model class, applicable to all black box models, and improves prediction performance for a variety of data in several industrial application areas. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Regularisation methods for neural network model averaging", "paper_id": "WOS:000353739800011"}