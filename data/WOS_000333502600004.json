{"auto_keywords": [{"score": 0.029234551140264024, "phrase": "incremental_learner"}, {"score": 0.00481495049065317, "phrase": "block-based_and_online_methods"}, {"score": 0.004685375117376838, "phrase": "data_streams"}, {"score": 0.004471270242168067, "phrase": "resource-aware_environments"}, {"score": 0.004283576270012874, "phrase": "stream's_underlying_data_distribution"}, {"score": 0.004168240841388958, "phrase": "established_research_line"}, {"score": 0.003977672712305348, "phrase": "natural_way"}, {"score": 0.0038106195546165574, "phrase": "class_labels"}, {"score": 0.0035660913513115267, "phrase": "sudden_changes"}, {"score": 0.00331125524068286, "phrase": "periodical_adaptation_mechanisms"}, {"score": 0.0032727116186194584, "phrase": "block-based_ensembles"}, {"score": 0.0032220148724914867, "phrase": "accurate_reactions"}, {"score": 0.003196960816092101, "phrase": "gradual_and_incremental_changes"}, {"score": 0.00300339527261653, "phrase": "incremental_processing"}, {"score": 0.0029338597685088603, "phrase": "new_types"}, {"score": 0.0029110398328258194, "phrase": "ensemble_classifiers"}, {"score": 0.0027886573969044042, "phrase": "block_ensemble"}, {"score": 0.002579140290642792, "phrase": "drift_detector"}, {"score": 0.0024418934977061876, "phrase": "new_incremental_ensemble_classifier"}, {"score": 0.0024134449026937586, "phrase": "online_accuracy_updated_ensemble"}, {"score": 0.002376027109070317, "phrase": "component_classifiers"}, {"score": 0.0023300677028248776, "phrase": "constant_time"}, {"score": 0.00228499525153, "phrase": "proposed_algorithm"}, {"score": 0.002171836484200008, "phrase": "real_and_synthetic_datasets"}, {"score": 0.002154930852763048, "phrase": "different_drift_scenarios"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Concept drift", " Data stream", " Online classifier", " Ensemble"], "paper_abstract": "Most stream classifiers are designed to process data incrementally, run in resource-aware environments, and react to concept drifts, i.e., unforeseen changes of the stream's underlying data distribution. Ensemble classifiers have become an established research line in this field, mainly due to their modularity which offers a natural way of adapting to changes. However, in environments where class labels are available after each example, ensembles which process instances in blocks do not react to sudden changes sufficiently quickly. On the other hand, ensembles which process streams incrementally, do not take advantage of periodical adaptation mechanisms known from block-based ensembles, which offer accurate reactions to gradual and incremental changes. In this paper, we analyze if and how the characteristics of block and incremental processing can be combined to produce new types of ensemble classifiers. We consider and experimentally evaluate three general strategies for transforming a block ensemble into an incremental learner: online component evaluation, the introduction of an incremental learner, and the use of a drift detector. Based on the results of this analysis, we put forward a new incremental ensemble classifier, called Online Accuracy Updated Ensemble, which weights component classifiers based on their error in constant time and memory. The proposed algorithm was experimentally compared with four state-of-the-art online ensembles and provided best average classification accuracy on real and synthetic datasets simulating different drift scenarios. (C) 2013 Elsevier Inc. All rights reserved.", "paper_title": "Combining block-based and online methods in learning ensembles from concept drifting data streams", "paper_id": "WOS:000333502600004"}