{"auto_keywords": [{"score": 0.04970903037225392, "phrase": "linear_regression"}, {"score": 0.04897776997473009, "phrase": "large_datasets"}, {"score": 0.04861597690075273, "phrase": "bayesian_models"}, {"score": 0.04236408605341747, "phrase": "variable_selection"}, {"score": 0.03184957124549912, "phrase": "sufficient_statistics"}, {"score": 0.00481495049065317, "phrase": "bayesian_variable_selection"}, {"score": 0.004578165674080246, "phrase": "markov_chain_monte_carlo"}, {"score": 0.00445550467119693, "phrase": "main_disadvantage"}, {"score": 0.004421063493736839, "phrase": "mcmc_methods"}, {"score": 0.00436989807912238, "phrase": "large_number"}, {"score": 0.004236321075918639, "phrase": "posterior_distributions"}, {"score": 0.0042035670399069485, "phrase": "model_parameters"}, {"score": 0.003996727479807572, "phrase": "challenging_problem"}, {"score": 0.003859500298805362, "phrase": "promising_solution"}, {"score": 0.003698136685049485, "phrase": "bayesian_model_computation"}, {"score": 0.0035711248264686415, "phrase": "fast_gibbs_sampler_algorithm"}, {"score": 0.0035027620578194692, "phrase": "mcmc"}, {"score": 0.003382141292426847, "phrase": "zellner"}, {"score": 0.003329994649432498, "phrase": "regression_coefficients"}, {"score": 0.0031806924874897636, "phrase": "gaussian"}, {"score": 0.0031171827624599693, "phrase": "dataset_summarization"}, {"score": 0.003033546013625887, "phrase": "augmented_set"}, {"score": 0.002917931350071647, "phrase": "main_memory"}, {"score": 0.002839625463110821, "phrase": "sparse_binary_vector"}, {"score": 0.0027958237350835607, "phrase": "matrix_projections"}, {"score": 0.002763415176377921, "phrase": "selected_variables"}, {"score": 0.002742017872865778, "phrase": "discovered_variable_subsets_probabilities"}, {"score": 0.002617059777997427, "phrase": "hash_table"}, {"score": 0.0025967927629150715, "phrase": "fast_retrieval"}, {"score": 0.0025766822940260963, "phrase": "future_iterations"}, {"score": 0.0024784363584530976, "phrase": "database_management_system"}, {"score": 0.002421291757425244, "phrase": "aggregate_user-defined_functions"}, {"score": 0.0022841153001549193, "phrase": "experimental_evaluation"}, {"score": 0.0022664208122072657, "phrase": "real_datasets"}, {"score": 0.002231441081806766, "phrase": "time_performance"}, {"score": 0.0021132002777359492, "phrase": "accurate_results"}], "paper_keywords": ["Sufficient statistics", " variable selection", " on-line algorithm", " MCMC", " Gibbs sampler"], "paper_abstract": "Bayesian models are generally computed with Markov Chain Monte Carlo (MCMC) methods. The main disadvantage of MCMC methods is the large number of iterations they need to sample the posterior distributions of model parameters, especially for large datasets. On the other hand, variable selection remains a challenging problem due to its combinatorial search space, where Bayesian models are a promising solution. In this work, we study how to accelerate Bayesian model computation for variable selection in linear regression. We propose a fast Gibbs sampler algorithm, a widely used MCMC method that incorporates several optimizations. We use a Zellner prior for the regression coefficients, an improper prior on variance, and a conjugate prior Gaussian distribution, which enable dataset summarization in one pass, thus exploiting an augmented set of sufficient statistics. Thereafter, the algorithm iterates in main memory. Sufficient statistics are indexed with a sparse binary vector to efficiently compute matrix projections based on selected variables. Discovered variable subsets probabilities, selecting and discarding each variable, are stored on a hash table for fast retrieval in future iterations. We study how to integrate our algorithm into a Database Management System (DBMS), exploiting aggregate User-Defined Functions for parallel data summarization and stored procedures to manipulate matrices with arrays. An experimental evaluation with real datasets evaluates accuracy and time performance, comparing our DBMS-based algorithm with the R package. Our algorithm is shown to produce accurate results, scale linearly on dataset size, and run orders of magnitude faster than the R package.", "paper_title": "Bayesian Variable Selection in Linear Regression in One Pass for Large Datasets", "paper_id": "WOS:000344353300003"}