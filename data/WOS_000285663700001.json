{"auto_keywords": [{"score": 0.049171581461506304, "phrase": "missing-feature_techniques"}, {"score": 0.04872396874382181, "phrase": "speech_recognition_accuracy"}, {"score": 0.03859683110806724, "phrase": "additive_noise"}, {"score": 0.03518291933112229, "phrase": "temporal_variation"}, {"score": 0.03216051450820661, "phrase": "incoming_speech"}, {"score": 0.00481495049065317, "phrase": "missing-feature_reconstruction"}, {"score": 0.004784331242964228, "phrase": "robust_speech_recognition"}, {"score": 0.00475390577915698, "phrase": "unknown_background_noise"}, {"score": 0.0046046429665581555, "phrase": "blind_determination"}, {"score": 0.0045317702763072445, "phrase": "spectrogram-like_display"}, {"score": 0.00396326346313272, "phrase": "previous_studies"}, {"score": 0.0038275385444116092, "phrase": "bayesian"}, {"score": 0.0037900142749506425, "phrase": "missing-feature_classification"}, {"score": 0.003635903652803253, "phrase": "seltzer_et_al"}, {"score": 0.0034327752490106818, "phrase": "best_type"}, {"score": 0.0034109154088832376, "phrase": "training_signal"}, {"score": 0.0032826392745833872, "phrase": "testing_environment"}, {"score": 0.003251328737784481, "phrase": "first_innovation"}, {"score": 0.0031591719975282073, "phrase": "frequency-dependent_classification"}, {"score": 0.0031290354217563938, "phrase": "independent_classification"}, {"score": 0.002992143937008144, "phrase": "parallel_sets"}, {"score": 0.002973081656751767, "phrase": "frequency-dependent_features"}, {"score": 0.0029447150254434842, "phrase": "second_innovation"}, {"score": 0.0028980357312095835, "phrase": "colored-noise_generation"}, {"score": 0.0028795712616923462, "phrase": "multi-band_partitioning"}, {"score": 0.002718581874516321, "phrase": "bayesian_classifier"}, {"score": 0.0026079240853929555, "phrase": "unknown_testing_environments"}, {"score": 0.0025830324526904427, "phrase": "third_innovation"}, {"score": 0.0025502118431246276, "phrase": "adaptive_method"}, {"score": 0.0024937735547989445, "phrase": "mask_classifier"}, {"score": 0.0024542249391904256, "phrase": "particular_time-frequency_segment"}, {"score": 0.0022948394240866555, "phrase": "improved_speech_recognition_accuracy"}, {"score": 0.0022729292542096077, "phrase": "small_vocabulary_test"}, {"score": 0.0022584385508256566, "phrase": "missing-feature_restoration"}, {"score": 0.002173409712988074, "phrase": "unknown_nature"}, {"score": 0.0021457826677689037, "phrase": "lower_signal-to-noise_ratios"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Robust speech recognition", " Missing-feature reconstruction", " Frequency-dependent mask classification", " Colored-noise masker generation", " Multi-band partition method"], "paper_abstract": "Missing-feature techniques to improve speech recognition accuracy are based on the blind determination of which cells in a spectrogram-like display of speech are corrupted by the effects of noise or other types of disturbance (and hence are \"missing\"). In this paper we present three new approaches that improve the speech recognition accuracy obtained using missing-feature techniques. It had been found in previous studies (e.g. Seltzer et al., 2004) that Bayesian approaches to missing-feature classification are effective in ameliorating the effects of various types of additive noise. While Seltzer et al. primarily used white noise for training their Bayesian classifier, we have found that this is not the best type of training signal when noise with greater spectral and/or temporal variation is encountered in the testing environment. The first innovation introduced in this paper, referred to as frequency-dependent classification, involves independent classification in each of the various frequency bands in which the incoming speech is analyzed based on parallel sets of frequency-dependent features. The second innovation, referred to as colored-noise generation using multi-band partitioning, involves the use of masking noises with artificially-introduced spectral and temporal variation in training the Bayesian classifier used to determine which spectro-temporal components of incoming speech are corrupted by noise in unknown testing environments. The third innovation consists of an adaptive method to estimate the a priori values of the mask classifier that determines whether a particular time-frequency segment of the test data should be considered to be reliable or not. It is shown that these innovations provide improved speech recognition accuracy on a small vocabulary test when missing-feature restoration is applied to incoming speech that is corrupted by additive noise of an unknown nature, especially at lower signal-to-noise ratios. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Mask classification for missing-feature reconstruction for robust speech recognition in unknown background noise", "paper_id": "WOS:000285663700001"}