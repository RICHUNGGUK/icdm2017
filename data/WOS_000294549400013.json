{"auto_keywords": [{"score": 0.04542490996391519, "phrase": "pblrnn"}, {"score": 0.007740489563401459, "phrase": "pipelined_bilinear_recurrent_neural_network"}, {"score": 0.006522106306681816, "phrase": "modular_architectures"}, {"score": 0.0046875099587735825, "phrase": "computational_complexity"}, {"score": 0.004612662942073808, "phrase": "bilinear_recurrent_neural_network"}, {"score": 0.004466519142879166, "phrase": "novel_low-complexity_nonlinear_adaptive_filter"}, {"score": 0.003990385737207714, "phrase": "pipelined_rnn"}, {"score": 0.003926626018798576, "phrase": "haykin"}, {"score": 0.003884846393389904, "phrase": "li"}, {"score": 0.0037615180375561805, "phrase": "blrnn_modules"}, {"score": 0.0036422425344358037, "phrase": "chained_form"}, {"score": 0.0034890505116128606, "phrase": "small-scale_blrnn"}, {"score": 0.0031845067058084583, "phrase": "pipelined_parallelism_fashion"}, {"score": 0.003066945490483524, "phrase": "significant_improvement"}, {"score": 0.003034158379493625, "phrase": "computational_efficiency"}, {"score": 0.002937879003671346, "phrase": "nesting_module"}, {"score": 0.002652639568848117, "phrase": "modified_adaptive_amplitude_real-time_recurrent_learning_algorithm"}, {"score": 0.0025273383208209922, "phrase": "extensive_simulations"}, {"score": 0.0023694065215394593, "phrase": "nonlinear_system_identification"}, {"score": 0.0022213218042340735, "phrase": "experimental_results"}, {"score": 0.0021507795710951384, "phrase": "considerably_better_performance"}, {"score": 0.0021049977753042253, "phrase": "single_blrnn_and_rnn_models"}], "paper_keywords": ["Bilinear recurrent neural network", " pipelined architecture", " pipelined recurrent neural network", " real-time recurrent learning", " Volterra filter"], "paper_abstract": "To reduce the computational complexity of the bilinear recurrent neural network (BLRNN), a novel low-complexity nonlinear adaptive filter with a pipelined bilinear recurrent neural network (PBLRNN) is presented in this paper. The PBLRNN, inheriting the modular architectures of the pipelined RNN proposed by Haykin and Li, comprises a number of BLRNN modules that are cascaded in a chained form. Each module is implemented by a small-scale BLRNN with internal dynamics. Since those modules of the PBLRNN can be performed simultaneously in a pipelined parallelism fashion, it would result in a significant improvement of computational efficiency. Moreover, due to nesting module, the performance of the PBLRNN can be further improved. To suit for the modular architectures, a modified adaptive amplitude real-time recurrent learning algorithm is derived on the gradient descent approach. Extensive simulations are carried out to evaluate the performance of the PBLRNN on nonlinear system identification, nonlinear channel equalization, and chaotic time series prediction. Experimental results show that the PBLRNN provides considerably better performance compared to the single BLRNN and RNN models.", "paper_title": "Low-Complexity Nonlinear Adaptive Filter Based on a Pipelined Bilinear Recurrent Neural Network", "paper_id": "WOS:000294549400013"}