{"auto_keywords": [{"score": 0.045032319739093496, "phrase": "rough_sets_theory"}, {"score": 0.00481495049065317, "phrase": "rough_classifiers"}, {"score": 0.004527024978801684, "phrase": "prime_area"}, {"score": 0.0035808664384880213, "phrase": "powerful_toolbox"}, {"score": 0.0033251716926666437, "phrase": "incomplete_and_contradicting_information"}, {"score": 0.0030123335878664064, "phrase": "obtained_classification_results"}, {"score": 0.0029027394930867902, "phrase": "crucial_importance"}, {"score": 0.002565345470805401, "phrase": "rough_performance_indices"}, {"score": 0.0023819914954155905, "phrase": "bi-_and_multinomial_classifiers"}, {"score": 0.0021845387990972543, "phrase": "comparative_experiments"}, {"score": 0.0021049977753042253, "phrase": "synthetically_generated_data"}], "paper_keywords": ["Rough Sets", " Classification", " Performance Indices", " Boundary Roughness"], "paper_abstract": "Since its introduction a prime area of application of rough sets theory has been in the field of classification. In this area rough sets theory provides a powerful toolbox of methods to deal with incomplete and contradicting information. Obviously, the assessment of the obtained classification results is of crucial importance. In our paper, we propose and evaluate some rough performance indices to evaluated the quality of bi- and multinomial classifiers. To illustrate their characteristics we perform comparative experiments on a synthetically generated data set.", "paper_title": "Assessing Rough Classifiers", "paper_id": "WOS:000351842400003"}