{"auto_keywords": [{"score": 0.04670707926114524, "phrase": "springer-verlag"}, {"score": 0.04642847898086282, "phrase": "london"}, {"score": 0.03855275576746506, "phrase": "d._precup"}, {"score": 0.03762062003569631, "phrase": "arlington"}, {"score": 0.037392159581623494, "phrase": "va"}, {"score": 0.004709434052130218, "phrase": "behavioral_similarity"}, {"score": 0.004650175539595746, "phrase": "probabilistic_transition_systems"}, {"score": 0.004255639740735269, "phrase": "j._worrell"}, {"score": 0.003970289891654048, "phrase": "markov"}, {"score": 0.0037729898581369673, "phrase": "robust_quantitative_analogue"}, {"score": 0.003749155155531426, "phrase": "stochastic_bisimulation"}, {"score": 0.003725470458263889, "phrase": "n._ferns"}, {"score": 0.0037019348293573675, "phrase": "p._panangaden"}, {"score": 0.003643741834170836, "phrase": "proceedings_of"}, {"score": 0.0032508114149214407, "phrase": "auai_press"}, {"score": 0.0030030808225723266, "phrase": "bisimulation_metrics"}, {"score": 0.002965229277927781, "phrase": "continuous_state_spaces"}, {"score": 0.0028909473120830842, "phrase": "first_distance-estimation_scheme"}, {"score": 0.0028274743316389437, "phrase": "continuous_probabilistic_transition_systems"}, {"score": 0.0027653910844724237, "phrase": "statistical_sampling"}, {"score": 0.0027479040199262393, "phrase": "infinite_dimensional_linear_programming"}, {"score": 0.002713260031399583, "phrase": "crucial_first_step"}, {"score": 0.00267905164093555, "phrase": "real-world_planning"}, {"score": 0.0024747842618794255, "phrase": "parametric_model"}, {"score": 0.0024591303299708604, "phrase": "crude_finite_approximation"}, {"score": 0.0023899010501421186, "phrase": "optimal_value_function"}, {"score": 0.002359759876402679, "phrase": "discounted_infinite-horizon_planning_task"}, {"score": 0.0023152577218214804, "phrase": "metric_distances"}, {"score": 0.0021049977753042253, "phrase": "state_aggregation"}], "paper_keywords": ["bisimulation", " metrics", " reinforcement learning", " continuous", " Markov decision process"], "paper_abstract": "In recent years, various metrics have been developed for measuring the behavioral similarity of states in probabilistic transition systems [J. Desharnais et al., Proceedings of CONCUR'99, Springer-Verlag, London, 1999, pp. 258-273; F. van Breugel and J. Worrell, Proceedings of ICALP'01, Springer-Verlag, London, 2001, pp. 421-432]. In the context of finite Markov decision processes (MDPs), we have built on these metrics to provide a robust quantitative analogue of stochastic bisimulation [N. Ferns, P. Panangaden, and D. Precup, Proceedings of UAI-04, AUAI Press, Arlington, VA, 2004, pp. 162-169] and an efficient algorithm for its calculation [N. Ferns, P. Panangaden, and D. Precup, Proceedings of UAI-06, AUAI Press, Arlington, VA, 2006, pp. 174-181]. In this paper, we seek to properly extend these bisimulation metrics to MDPs with continuous state spaces. In particular, we provide the first distance-estimation scheme for metrics based on bisimulation for continuous probabilistic transition systems. Our work, based on statistical sampling and infinite dimensional linear programming, is a crucial first step in formally guiding real-world planning, where tasks are usually continuous and highly stochastic in nature, e. g., robot navigation, and often a substitution with a parametric model or crude finite approximation must be made. We show that the optimal value function associated with a discounted infinite-horizon planning task is continuous with respect to metric distances. Thus, our metrics allow one to reason about the quality of solution obtained by replacing one model with another. Alternatively, they may potentially be used directly for state aggregation.", "paper_title": "BISIMULATION METRICS FOR CONTINUOUS MARKOV DECISION PROCESSES", "paper_id": "WOS:000298377900008"}