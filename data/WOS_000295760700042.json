{"auto_keywords": [{"score": 0.04800845694907027, "phrase": "large_datasets"}, {"score": 0.00481495049065317, "phrase": "optimum-path_forest_classification"}, {"score": 0.004688989566904871, "phrase": "data_acquisition_technologies"}, {"score": 0.0044863018460183784, "phrase": "statistical_analysis"}, {"score": 0.004388252997694986, "phrase": "tremendous_challenge"}, {"score": 0.0043496334756644535, "phrase": "pattern_recognition_techniques"}, {"score": 0.003911771812701971, "phrase": "fast_computation"}, {"score": 0.0038602215057106917, "phrase": "optimum-path_forest"}, {"score": 0.0038262601612859878, "phrase": "opf"}, {"score": 0.0036932254391253134, "phrase": "training_samples"}, {"score": 0.003502305158321511, "phrase": "multiple_trees"}, {"score": 0.00344087639309216, "phrase": "representative_samples"}, {"score": 0.0032774280543222843, "phrase": "new_sample"}, {"score": 0.0030942116765996426, "phrase": "different_graph_topologies"}, {"score": 0.003066945490483524, "phrase": "learning_techniques"}, {"score": 0.00289546142998427, "phrase": "supervised_approaches"}, {"score": 0.002832081745025006, "phrase": "considerable_advantages"}, {"score": 0.002807118943000936, "phrase": "support_vector_machines"}, {"score": 0.00278237555651743, "phrase": "artificial_neural_networks"}, {"score": 0.0026501241093379786, "phrase": "new_algorithm"}, {"score": 0.002490833392316362, "phrase": "negligible_effects"}, {"score": 0.002361923085067681, "phrase": "experimental_results"}, {"score": 0.002200337772403983, "phrase": "new_method"}, {"score": 0.0021809311689473493, "phrase": "valuable_contribution"}, {"score": 0.002161695357601592, "phrase": "large_dataset_analysis"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Optimum-path forest classifiers", " Support vector machines", " Artificial neural networks", " Pattern recognition", " Machine learning"], "paper_abstract": "Today data acquisition technologies come up with large datasets with millions of samples for statistical analysis. This creates a tremendous challenge for pattern recognition techniques, which need to be more efficient without losing their effectiveness. We have tried to circumvent the problem by reducing it into the fast computation of an optimum-path forest (OPF) in a graph derived from the training samples. In this forest, each class may be represented by multiple trees rooted at some representative samples. The forest is a classifier that assigns to a new sample the label of its most strongly connected root. The methodology has been successfully used with different graph topologies and learning techniques. In this work, we have focused on one of the supervised approaches, which has offered considerable advantages over Support Vector Machines and Artificial Neural Networks to handle large datasets. We propose (i) a new algorithm that speeds up classification and (ii) a solution to reduce the training set size with negligible effects on the accuracy of classification, therefore further increasing its efficiency. Experimental results show the improvements with respect to our previous approach and advantages over other existing methods, which make the new method a valuable contribution for large dataset analysis. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Efficient supervised optimum-path forest classification for large datasets", "paper_id": "WOS:000295760700042"}