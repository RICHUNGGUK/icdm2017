{"auto_keywords": [{"score": 0.02631304680263054, "phrase": "computational_learning"}, {"score": 0.00481495049065317, "phrase": "reconstructing_multivariate_polynomials_over_finite_fields."}, {"score": 0.004749377457292245, "phrase": "polynomial_reconstruction_problem"}, {"score": 0.004716924994370903, "phrase": "low-degree_multivariate_polynomials"}, {"score": 0.0035972293900260414, "phrase": "degree_d_polynomial"}, {"score": 0.0035603802089559716, "phrase": "good_agreement"}, {"score": 0.003465356029156569, "phrase": "np"}, {"score": 0.0030929051195273715, "phrase": "stronger_promise"}, {"score": 0.002771001596749451, "phrase": "even_np-completeness"}, {"score": 0.002631832840403278, "phrase": "celebrated_result"}, {"score": 0.0024152058731908544, "phrase": "nonproper_agnostic_learning"}, {"score": 0.0022240004131756095, "phrase": "first_nonproper_hardness_result"}, {"score": 0.002201187194326849, "phrase": "central_problem"}, {"score": 0.002126816206925344, "phrase": "polynomial_reconstruction"}, {"score": 0.0021049977753042253, "phrase": "finite_field"}], "paper_keywords": ["hardness of approximation", " polynomials", " finite fields", " coding theory", " computational learning"], "paper_abstract": "We study the polynomial reconstruction problem for low-degree multivariate polynomials over finite field F[2]. In this problem, we are given a set of points x is an element of {0, 1}(n) and target values f(x) is an element of {0, 1} for each of these points, with the promise that there is a polynomial over F[2] of degree at most d that agrees with f at 1-epsilon fraction of the points. Our goal is to find a degree d polynomial that has good agreement with f. We show that it is NP-hard to find a polynomial that agrees with f on more than 1-2(-d) + delta fraction of the points for any epsilon, delta > 0. This holds even with the stronger promise that the polynomial that fits the data is in fact linear, whereas the algorithm is allowed to find a polynomial of degree d. Previously the only known hardness of approximation (or even NP-completeness) was for the case when d = 1, which follows from a celebrated result of Hastad [J. ACM, 48 (2001), pp. 798-859]. In the setting of Computational Learning, our result shows the hardness of nonproper agnostic learning of parities, where the learner is allowed a low-degree polynomial over F[2] as a hypothesis. This is the first nonproper hardness result for this central problem in computational learning. Our results can be extended to multivariate polynomial reconstruction over any finite field.", "paper_title": "HARDNESS OF RECONSTRUCTING MULTIVARIATE POLYNOMIALS OVER FINITE FIELDS", "paper_id": "WOS:000277585000020"}