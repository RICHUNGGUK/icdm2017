{"auto_keywords": [{"score": 0.049651030276363126, "phrase": "wearable_pressure_sensors"}, {"score": 0.049226991195811136, "phrase": "full-body_kinematics"}, {"score": 0.00481495049065317, "phrase": "depth_cameras"}, {"score": 0.004562362497952548, "phrase": "new_method"}, {"score": 0.004521566043596533, "phrase": "full-body_motion_capture"}, {"score": 0.004284302478991387, "phrase": "pressure-sensing_shoes"}, {"score": 0.003677280504320639, "phrase": "novel_tracking_process"}, {"score": 0.0035794251590584563, "phrase": "input_data"}, {"score": 0.003376216135716632, "phrase": "optimization_framework"}, {"score": 0.0032863459256972896, "phrase": "observed_depth_data"}, {"score": 0.003256922225995089, "phrase": "pressure_data"}, {"score": 0.0032277611129050234, "phrase": "iterative_linear_solvers"}, {"score": 0.003085813569061001, "phrase": "depth_data"}, {"score": 0.003058179790439378, "phrase": "multiple_depth_cameras"}, {"score": 0.0030307927228223883, "phrase": "foot_pressure_data"}, {"score": 0.002845809662579165, "phrase": "unified_framework"}, {"score": 0.0027452053065200152, "phrase": "efficient_physics-based_motion_reconstruction_algorithm"}, {"score": 0.0026600905156986317, "phrase": "contact_forces"}, {"score": 0.002624423288947767, "phrase": "quadratic_programming_framework"}, {"score": 0.002543043781904587, "phrase": "newtonian_physics"}, {"score": 0.0025202582748972122, "phrase": "friction_cone_constraints"}, {"score": 0.00249767641333441, "phrase": "contact_pressure_information"}, {"score": 0.002398529964696261, "phrase": "kinematic_tracking_process"}, {"score": 0.002366361492754389, "phrase": "full-body_dynamics_data"}, {"score": 0.0022520496048464406, "phrase": "wide_range"}, {"score": 0.0022318655527987846, "phrase": "human_movements"}, {"score": 0.0021049977753042253, "phrase": "alternative_systems"}], "paper_keywords": ["motion capture", " human body tracking", " physics-based modeling", " full body shape modeling"], "paper_abstract": "We present a new method for full-body motion capture that uses input data captured by three depth cameras and a pair of pressure-sensing shoes. Our system is appealing because it is low-cost, non-intrusive and fully automatic, and can accurately reconstruct both full-body kinematics and dynamics data. We first introduce a novel tracking process that automatically reconstructs 3D skeletal poses using input data captured by three Kinect cameras and wearable pressure sensors. We formulate the problem in an optimization framework and incrementally update 3D skeletal poses with observed depth data and pressure data via iterative linear solvers. The system is highly accurate because we integrate depth data from multiple depth cameras, foot pressure data, detailed full-body geometry, and environmental contact constraints into a unified framework. In addition, we develop an efficient physics-based motion reconstruction algorithm for solving internal joint torques and contact forces in the quadratic programming framework. During reconstruction, we leverage Newtonian physics, friction cone constraints, contact pressure information, and 3D kinematic poses obtained from the kinematic tracking process to reconstruct full-body dynamics data. We demonstrate the power of our approach by capturing a wide range of human movements and achieve state-of-the-art accuracy in our comparison against alternative systems.", "paper_title": "Leveraging Depth Cameras and Wearable Pressure Sensors for Full-body Kinematics and Dynamics Capture", "paper_id": "WOS:000345855600050"}