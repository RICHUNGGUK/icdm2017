{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "distributed"}, {"score": 0.004770211811866158, "phrase": "online_fair_resource_management"}, {"score": 0.004725886853744007, "phrase": "video_surveillance_sensor_networks"}, {"score": 0.004595356579614969, "phrase": "wireless_sensor_networks"}, {"score": 0.00428451995524549, "phrase": "legacy_wsns"}, {"score": 0.004127394241838696, "phrase": "visual_sensor_networks"}, {"score": 0.0040890178236849825, "phrase": "additional_research_problems"}, {"score": 0.0040133278382101885, "phrase": "real-world_implementations"}, {"score": 0.003957477564354679, "phrase": "real-time_video_streams"}, {"score": 0.003920674807745575, "phrase": "resource_constrained_sensor_hardware"}, {"score": 0.0038301525703886585, "phrase": "challenging_task"}, {"score": 0.003672427620845944, "phrase": "fairness-based_approach"}, {"score": 0.003604421041893448, "phrase": "event_reporting"}, {"score": 0.0031770714776989282, "phrase": "whole_application_requirement"}, {"score": 0.003003726508522467, "phrase": "application_level_messaging_units"}, {"score": 0.0029069972482610403, "phrase": "crucial_network-wide_resources"}, {"score": 0.0028664985822266344, "phrase": "in-queue_processing_turn"}, {"score": 0.002787181295054319, "phrase": "channel_access_opportunities"}, {"score": 0.0026105159490849364, "phrase": "regular_flow"}, {"score": 0.002538263784314365, "phrase": "enhanced_performance"}, {"score": 0.002388487669097511, "phrase": "reporting_latency"}, {"score": 0.0023884163622997744, "phrase": "ebf"}, {"score": 0.002333258365963461, "phrase": "robust_mechanism"}, {"score": 0.002195552442011313, "phrase": "complementary_method"}], "paper_keywords": ["Video surveillance sensor networks", " fairness", " queue management", " event detection"], "paper_abstract": "Visual capability introduced to Wireless Sensor Networks (WSNs) render many novel applications that would otherwise be infeasible. However, unlike legacy WSNs which are commercially deployed in applications, visual sensor networks create additional research problems that delays the real-world implementations. Conveying real-time video streams over resource constrained sensor hardware remains to be a challenging task. As a remedy, we propose a fairness-based approach to enhance the event reporting and detection performance of the Video Surveillance Sensor Networks. Instead of achieving fairness only for flows or for nodes as investigated in the literature, we concentrate on the whole application requirement. Accordingly, our Event-Based Fairness (EBF) scheme aims at fair resource allocation for the application level messaging units called events. We identify the crucial network-wide resources as the in-queue processing turn of the frames and the channel access opportunities of the nodes. We show that fair treatment of events, as opposed to regular flow of frames, results in enhanced performance in terms of the number of frames reported per event and the reporting latency. EBF is a robust mechanism that can be used as a stand-alone or as a complementary method to other possible performance enhancement methods for video sensor networks implemented at other communication layers.", "paper_title": "Distributed and Online Fair Resource Management in Video Surveillance Sensor Networks", "paper_id": "WOS:000301746000011"}