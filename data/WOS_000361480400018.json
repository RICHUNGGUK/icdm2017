{"auto_keywords": [{"score": 0.035687560751607256, "phrase": "swarm"}, {"score": 0.00481495049065317, "phrase": "intelligence_based_file_replication"}, {"score": 0.00468627326602559, "phrase": "peer-to-peer_file_sharing_systems"}, {"score": 0.004561019117546361, "phrase": "file_owners"}, {"score": 0.00451491283266524, "phrase": "file_query_efficiency"}, {"score": 0.004204904449336037, "phrase": "replica_hit_rate"}, {"score": 0.0040373708328770306, "phrase": "increased_replication"}, {"score": 0.0038764861784138117, "phrase": "ideal_replication_method"}, {"score": 0.0038242899532391914, "phrase": "low_overhead_burden"}, {"score": 0.0037473054818679763, "phrase": "low_query_latency"}, {"score": 0.0036594395622282358, "phrase": "previous_replication_methods"}, {"score": 0.0036224139706218916, "phrase": "high_hit_rates"}, {"score": 0.003525493807130663, "phrase": "low_hit_rates"}, {"score": 0.0034428109010424175, "phrase": "high_hit_rate"}, {"score": 0.003294350220187021, "phrase": "swarm_intelligence"}, {"score": 0.0032279990773657215, "phrase": "collective_behaviors"}, {"score": 0.0031845067058084583, "phrase": "node_swarms"}, {"score": 0.0031629800646754474, "phrase": "common_node_interests"}, {"score": 0.0031415984808041324, "phrase": "close_proximity"}, {"score": 0.0030265495849271617, "phrase": "file_replica"}, {"score": 0.0029857633082091377, "phrase": "accumulated_query_rates"}, {"score": 0.002895986736522535, "phrase": "single_node"}, {"score": 0.0027429789393362703, "phrase": "high_querying_efficiency"}, {"score": 0.002669525619637691, "phrase": "novel_consistency_maintenance_algorithm"}, {"score": 0.0026335379469691997, "phrase": "update_message"}, {"score": 0.0026157259734105, "phrase": "proximity-close_nodes"}, {"score": 0.0025892330566358503, "phrase": "tree_fashion"}, {"score": 0.0025198864435531055, "phrase": "experimental_results"}, {"score": 0.002494361792853831, "phrase": "real-world_planetlab_testbed"}, {"score": 0.0024690951711813184, "phrase": "peersim"}, {"score": 0.0024111277643627154, "phrase": "swarm_mechanism"}, {"score": 0.0021410346041739804, "phrase": "consistency_maintenance_overhead"}, {"score": 0.0021049977753042253, "phrase": "previous_consistency_maintenance_methods"}], "paper_keywords": ["File replication", " consistency maintenance", " peer-to-peer", " distributed hash table", " swarm intelligence"], "paper_abstract": "In peer-to-peer file sharing systems, file replication helps to avoid overloading file owners and improve file query efficiency. There exists a tradeoff between minimizing the number of replicas (i.e., replication overhead) and maximizing the replica hit rate (which reduces file querying latency). More replicas lead to increased replication overhead and higher replica hit rates and vice versa. An ideal replication method should generate a low overhead burden to the system while providing low query latency to the users. However, previous replication methods either achieve high hit rates at the cost of many replicas or produce low hit rates. To reduce replicas while guaranteeing high hit rate, this paper presents SWARM, a file replication mechanism based on swarm intelligence. Recognizing the power of collective behaviors, SWARM identifies node swarms with common node interests and close proximity. Unlike most earlier methods, SWARM determines the placement of a file replica based on the accumulated query rates of nodes in a swarm rather than a single node. Replicas are shared by the nodes in a swarm, leading to fewer replicas and high querying efficiency. In addition, SWARM has a novel consistency maintenance algorithm that propagates an update message between proximity-close nodes in a tree fashion from the top to the bottom. Experimental results from the real-world PlanetLab testbed and the PeerSim simulator demonstrate the effectiveness of the SWARM mechanism in comparison with other file replication and consistency maintenance methods. SWARM can reduce querying latency by 40-58 percent, reduce the number of replicas by 39-76 percent, and achieves more than 84 percent higher hit rates compared to previous methods. It also can reduce the consistency maintenance overhead by 49-99 percent compared to previous consistency maintenance methods.", "paper_title": "Swarm Intelligence Based File Replication and Consistency Maintenance in Structured P2P File Sharing Systems", "paper_id": "WOS:000361480400018"}