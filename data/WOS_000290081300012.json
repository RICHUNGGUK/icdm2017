{"auto_keywords": [{"score": 0.04836165556138413, "phrase": "kernel_discriminant_analysis"}, {"score": 0.03883606375925058, "phrase": "training_sample"}, {"score": 0.00481495049065317, "phrase": "bayesian_multiscale"}, {"score": 0.004496280772084575, "phrase": "common_practice"}, {"score": 0.004414907432703781, "phrase": "smoothing_parameter"}, {"score": 0.004276016541197123, "phrase": "training_data"}, {"score": 0.004141476915000558, "phrase": "unlabeled_observations"}, {"score": 0.0039928721865882, "phrase": "single_scale"}, {"score": 0.0039027036493682887, "phrase": "major_issue"}, {"score": 0.003867206750827, "phrase": "model_uncertainty"}, {"score": 0.0036441884295335502, "phrase": "good_choice"}, {"score": 0.0034027387694902287, "phrase": "fixed_level"}, {"score": 0.003221111762383486, "phrase": "measurement_space"}, {"score": 0.003105428650735113, "phrase": "single_smoothing_parameter"}, {"score": 0.002953097497434808, "phrase": "classification_results"}, {"score": 0.002926212333939311, "phrase": "multiple_scales"}, {"score": 0.002782647772219627, "phrase": "final_decision"}, {"score": 0.0027073229284666294, "phrase": "bayesian_approach"}, {"score": 0.0026220103561723066, "phrase": "probabilistic_framework"}, {"score": 0.002327956449278255, "phrase": "unlabeled_test_set_observations"}, {"score": 0.0022857351723674004, "phrase": "decision_rule"}, {"score": 0.002254571365634257, "phrase": "well-known_benchmark_data_sets"}, {"score": 0.002163600705898299, "phrase": "proposed_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Bayes risk", " Gibbs sampling", " Kernel density estimation", " Misclassification rate", " Markov chain Monte Carlo", " Non-informative prior", " Transductive learning"], "paper_abstract": "In kernel discriminant analysis, it is common practice to select the smoothing parameter (bandwidth) based on the training data and use it for classifying all unlabeled observations. But this method of selecting a single scale of smoothing ignores the major issue of model uncertainty. Moreover, in addition to depending on the training sample, a good choice of bandwidth may also depend on the observation to be classified, and a fixed level of smoothing may not work well in all parts of the measurement space. So, instead of using a single smoothing parameter, it may be more useful in practice to study classification results for multiple scales of smoothing and judiciously aggregate them to arrive at the final decision. This paper adopts a Bayesian approach to carry out one such multiscale analysis using a probabilistic framework. This framework also helps us to extend our multiscale method for semi-supervised classification, where, in addition to the training sample, one uses unlabeled test set observations to form the decision rule. Some well-known benchmark data sets are analyzed to show the utility of these proposed methods. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Bayesian multiscale smoothing in supervised and semi-supervised kernel discriminant analysis", "paper_id": "WOS:000290081300012"}