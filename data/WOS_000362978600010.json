{"auto_keywords": [{"score": 0.02861882376215844, "phrase": "remote_gpus"}, {"score": 0.00481495049065317, "phrase": "user_experience"}, {"score": 0.004741167616693272, "phrase": "remote_gpu_virtualization_framework"}, {"score": 0.004704699244406775, "phrase": "graphics_processing_units"}, {"score": 0.004526503177267299, "phrase": "high-performance_computing_community"}, {"score": 0.004405779372462873, "phrase": "execution_time"}, {"score": 0.004288261454002681, "phrase": "remote_cuda"}, {"score": 0.004141742095830515, "phrase": "software_solution"}, {"score": 0.004078232992955235, "phrase": "high_acquisition_costs"}, {"score": 0.004046843083499649, "phrase": "energy_consumption"}, {"score": 0.003760385494931853, "phrase": "reduced_number"}, {"score": 0.003534889186471058, "phrase": "initial_prototype_versions"}, {"score": 0.0035076671532332203, "phrase": "rcuda"}, {"score": 0.0032718761046588835, "phrase": "new_cuda_features"}, {"score": 0.003123527559542239, "phrase": "new_rcuda_version"}, {"score": 0.003005039427642664, "phrase": "new_component"}, {"score": 0.0029589086332593674, "phrase": "automatic_transformation"}, {"score": 0.00292477450010107, "phrase": "cuda_source_code"}, {"score": 0.0028138046006772593, "phrase": "rcuda_framework"}, {"score": 0.0026551731045904854, "phrase": "improved_new_communication_architecture"}, {"score": 0.0025842289219860795, "phrase": "multithreaded_applications"}, {"score": 0.002564356756971406, "phrase": "cuda"}, {"score": 0.002476546030310661, "phrase": "cuda-compatible_program"}, {"score": 0.0023550410480905727, "phrase": "low_overhead"}, {"score": 0.0023099082804523044, "phrase": "single_application"}, {"score": 0.002171202123281881, "phrase": "single-node_capability"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["GPGPU", " CUDA", " virtualization", " HPC", " clusters"], "paper_abstract": "Graphics processing units (GPUs) are being increasingly embraced by the high-performance computing community as an effective way to reduce execution time by accelerating parts of their applications. remote CUDA (rCUDA) was recently introduced as a software solution to address the high acquisition costs and energy consumption of GPUs that constrain further adoption of this technology. Specifically, rCUDA is a middleware that allows a reduced number of GPUs to be transparently shared among the nodes in a cluster. Although the initial prototype versions of rCUDA demonstrated its functionality, they also revealed concerns with respect to usability, performance, and support for new CUDA features. In response, in this paper, we present a new rCUDA version that (1) improves usability by including a new component that allows an automatic transformation of any CUDA source code so that it conforms to the needs of the rCUDA framework, (2) consistently features low overhead when using remote GPUs thanks to an improved new communication architecture, and (3) supports multithreaded applications and CUDA libraries. As a result, for any CUDA-compatible program, rCUDA now allows the use of remote GPUs within a cluster with low overhead, so that a single application running in one node can use all GPUs available across the cluster, thereby extending the single-node capability of CUDA. Copyright (C) 2014 John Wiley & Sons, Ltd.", "paper_title": "Improving the user experience of the rCUDA remote GPU virtualization framework", "paper_id": "WOS:000362978600010"}