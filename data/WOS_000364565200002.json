{"auto_keywords": [{"score": 0.032394483004615865, "phrase": "data_adaptiveness"}, {"score": 0.00481495049065317, "phrase": "robust_locally_adaptive_multi-view_learning"}, {"score": 0.00429558848734449, "phrase": "intelligent_surveillance"}, {"score": 0.004256533389293113, "phrase": "perceptual_interface"}, {"score": 0.00419861271409079, "phrase": "content-based_video_retrieval"}, {"score": 0.004103817210338686, "phrase": "extrinsic_factors"}, {"score": 0.003974673997871831, "phrase": "action_recognition"}, {"score": 0.0039027036493682887, "phrase": "human_actions"}, {"score": 0.003814563533445401, "phrase": "arbitrary_camera_viewpoints"}, {"score": 0.0037798652680135106, "phrase": "realistic_scene"}, {"score": 0.003711409222544974, "phrase": "view-invariant_analysis"}, {"score": 0.0036441884295335502, "phrase": "action_recognition_algorithms"}, {"score": 0.003310684108128973, "phrase": "multi-view_learning_approach"}, {"score": 0.003221111762383486, "phrase": "different_views"}, {"score": 0.003021392767766593, "phrase": "nearest_neighborhood_graph_construction_procedure"}, {"score": 0.0029802289354540507, "phrase": "robust_locally_adaptive_multi-view_learning_algorithm"}, {"score": 0.0028082176224611542, "phrase": "efficient_iterative_optimization_method"}, {"score": 0.0027322025124213566, "phrase": "proposed_objective_function"}, {"score": 0.002610043728801011, "phrase": "ixmas"}, {"score": 0.0025744700786382913, "phrase": "wvu"}, {"score": 0.0023818288346547692, "phrase": "feature_dimension"}, {"score": 0.002254571365634257, "phrase": "proposed_algorithm"}, {"score": 0.002193509835371438, "phrase": "-the-art_counterparts"}, {"score": 0.0021340985236583034, "phrase": "recognition_accuracy"}], "paper_keywords": ["View-invariant", " Action recognition", " Multi-view learning", " L1-norm", " Local learning"], "paper_abstract": "Human action recognition is currently one of the most active research areas in computer vision. It has been widely used in many applications, such as intelligent surveillance, perceptual interface, and content-based video retrieval. However, some extrinsic factors are barriers for the development of action recognition; e.g., human actions may be observed from arbitrary camera viewpoints in realistic scene. Thus, view-invariant analysis becomes important for action recognition algorithms, and a number of researchers have paid much attention to this issue. In this paper, we present a multi-view learning approach to recognize human actions from different views. As most existing multi-view learning algorithms often suffer from the problem of lacking data adaptiveness in the nearest neighborhood graph construction procedure, a robust locally adaptive multi-view learning algorithm based on learning multiple local L1-graphs is proposed. Moreover, an efficient iterative optimization method is proposed to solve the proposed objective function. Experiments on three public view-invariant action recognition datasets, i.e., ViHASi, IXMAS, and WVU, demonstrate data adaptiveness, effectiveness, and efficiency of our algorithm. More importantly, when the feature dimension is correctly selected (i.e., > 60), the proposed algorithm stably outperforms state-of-the-art counterparts and obtains about 6% improvement in recognition accuracy on the three datasets.", "paper_title": "View-invariant human action recognition via robust locally adaptive multi-view learning", "paper_id": "WOS:000364565200002"}