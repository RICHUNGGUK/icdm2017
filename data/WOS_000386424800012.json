{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "udf-centric_workflows"}, {"score": 0.040484668400291746, "phrase": "complex_analytics"}, {"score": 0.03619647508467271, "phrase": "computation_bottleneck"}, {"score": 0.004601508848655033, "phrase": "increasingly_sophisticated_techniques"}, {"score": 0.004509694461067052, "phrase": "machine_learning"}, {"score": 0.0044644734709113985, "phrase": "advanced_statistics"}, {"score": 0.004331501320993783, "phrase": "complex_analytics_tasks"}, {"score": 0.004245051445971095, "phrase": "user-defined_functions"}, {"score": 0.0040978781692373005, "phrase": "algorithmic_step"}, {"score": 0.003995876175614403, "phrase": "typical_hardware_configurations"}, {"score": 0.003955787027818301, "phrase": "dataset_sizes"}, {"score": 0.0038964032225585117, "phrase": "core_challenge"}, {"score": 0.003780286517897356, "phrase": "sheer_data_volume"}, {"score": 0.0036125439380579626, "phrase": "next_generation"}, {"score": 0.0033832583769880576, "phrase": "query_compilation"}, {"score": 0.003332440548684892, "phrase": "widespread_popularity"}, {"score": 0.0031845067058084583, "phrase": "traditional_sql_workloads"}, {"score": 0.003152531962718477, "phrase": "relatively_little_work"}, {"score": 0.002907992115184249, "phrase": "novel_architecture"}, {"score": 0.002524688179363081, "phrase": "different_code"}, {"score": 0.002486734224234698, "phrase": "case-by-case_basis"}, {"score": 0.0023405260980363767, "phrase": "tupleware"}, {"score": 0.0021807544600219216, "phrase": "performance_improvements"}, {"score": 0.0021049977753042253, "phrase": "alternative_systems"}], "paper_keywords": [""], "paper_abstract": "Data analytics has recently grown to include increasingly sophisticated techniques, such as machine learning and advanced statistics. Users frequently express these complex analytics tasks as workflows of user-defined functions (UDFs) that specify each algorithmic step. However, given typical hardware configurations and dataset sizes, the core challenge of complex analytics is no longer sheer data volume but rather the computation itself, and the next generation of analytics frameworks must focus on optimizing for this computation bottleneck. While query compilation has gained widespread popularity as a way to tackle the computation bottleneck for traditional SQL workloads, relatively little work addresses UDF-centric workflows in the domain of complex analytics. In this paper, we describe a novel architecture for automatically compiling workflows of UDFs. We also propose several optimizations that consider properties of the data, UDFs, and hardware together in order to generate different code on a case-by-case basis. To evaluate our approach, we implemented these techniques in TUPLEWARE, a new high-performance distributed analytics system, and our benchmarks show performance improvements of up to three orders of magnitude compared to alternative systems.", "paper_title": "An Architecture for Compiling UDF-centric Workflows", "paper_id": "WOS:000386424800012"}