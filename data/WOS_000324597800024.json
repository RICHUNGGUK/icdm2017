{"auto_keywords": [{"score": 0.0464374488056209, "phrase": "video_texts"}, {"score": 0.00481495049065317, "phrase": "automatic_inpainting_scheme_for_video_text_detection"}, {"score": 0.004592214823540993, "phrase": "automatic_video_text_removal"}, {"score": 0.004288472456976113, "phrase": "appropriate_data"}, {"score": 0.004199101289890982, "phrase": "video_text_detection_stage"}, {"score": 0.003962779958955344, "phrase": "unsupervised_clustering"}, {"score": 0.00388016972840459, "phrase": "connected_components"}, {"score": 0.003799275066001196, "phrase": "stroke_width"}, {"score": 0.0036810797331981782, "phrase": "swt"}, {"score": 0.003623352647973122, "phrase": "accurate_edge_map"}, {"score": 0.003529149828147388, "phrase": "novel_edge_detector"}, {"score": 0.003437387719239532, "phrase": "geometric_features"}, {"score": 0.0033656930865509547, "phrase": "bandlet_transform"}, {"score": 0.003278167066287366, "phrase": "motion_patterns"}, {"score": 0.003226744277130179, "phrase": "text_objects"}, {"score": 0.0030449789178940787, "phrase": "detected_video_text_regions"}, {"score": 0.0028734230458881903, "phrase": "inpainting_scheme"}, {"score": 0.002828331235643921, "phrase": "proposed_video_inpainting_approach"}, {"score": 0.002798662730881037, "phrase": "spatio-temporal_geometric_flows"}, {"score": 0.002697245874076643, "phrase": "missing_data"}, {"score": 0.0025722202862084186, "phrase": "bandlet_bases"}, {"score": 0.002518525107994039, "phrase": "anisotropic_regularities"}, {"score": 0.0024144659350277954, "phrase": "inpainting_task"}, {"score": 0.002326938965568362, "phrase": "extra_processes"}, {"score": 0.0022904032758108775, "phrase": "visual_consistency"}, {"score": 0.0022544399432457164, "phrase": "experimental_results"}], "paper_keywords": ["Bandlets", " edge detection", " inpainting", " regularization", " text detection", " stroke width transform"], "paper_abstract": "We present a two stage framework for automatic video text removal to detect and remove embedded video texts and fill-in their remaining regions by appropriate data. In the video text detection stage, text locations in each frame are found via an unsupervised clustering performed on the connected components produced by the stroke width transform (SWT). Since SWT needs an accurate edge map, we develop a novel edge detector which benefits from the geometric features revealed by the bandlet transform. Next, the motion patterns of the text objects of each frame are analyzed to localize video texts. The detected video text regions are removed, then the video is restored by an inpainting scheme. The proposed video inpainting approach applies spatio-temporal geometric flows extracted by bandlets to reconstruct the missing data. A 3D volume regularization algorithm, which takes advantage of bandlet bases in exploiting the anisotropic regularities, is introduced to carry out the inpainting task. The method does not need extra processes to satisfy visual consistency. The experimental results demonstrate the effectiveness of both our proposed video text detection approach and the video completion technique, and consequently the entire automatic video text removal and restoration process.", "paper_title": "Automatic Inpainting Scheme for Video Text Detection and Removal", "paper_id": "WOS:000324597800024"}