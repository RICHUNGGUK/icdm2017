{"auto_keywords": [{"score": 0.024174738462501365, "phrase": "individual_problems"}, {"score": 0.004732785510739708, "phrase": "future_event"}, {"score": 0.004598933498016774, "phrase": "individual_assessments"}, {"score": 0.004392565073466714, "phrase": "forecast_performance"}, {"score": 0.003938650032712796, "phrase": "well-known_fact"}, {"score": 0.0038492126993451337, "phrase": "systematic_biases"}, {"score": 0.0035722806911457545, "phrase": "mean_judgments"}, {"score": 0.003511246498068952, "phrase": "two-parameter_calibration_function"}, {"score": 0.003277327351139926, "phrase": "calibration_function"}, {"score": 0.0029552551661591988, "phrase": "log-odds_space"}, {"score": 0.0028550709503536494, "phrase": "individual_differences"}, {"score": 0.002790170184447136, "phrase": "hierarchical_modeling"}, {"score": 0.002726740692380339, "phrase": "non-hierarchical_models"}, {"score": 0.0026041635822373265, "phrase": "individual_judgments"}, {"score": 0.0024305268807926056, "phrase": "simple_averaging"}, {"score": 0.002361632539339945, "phrase": "brier_score"}, {"score": 0.0023346234464901978, "phrase": "better_performance"}, {"score": 0.0022296340517805125, "phrase": "hierarchical_version"}, {"score": 0.0021049977753042253, "phrase": "mean_brier_score"}], "paper_keywords": ["Calibration", " Aggregation", " Forecasting", " Systematic distortions", " Hierarchical Bayesian models", " Individual differences", " Wisdom of the crowd"], "paper_abstract": "It is known that the average of many forecasts about a future event tends to outperform the individual assessments. With the goal of further improving forecast performance, this paper develops and compares a number of models for calibrating and aggregating forecasts that exploit the well-known fact that individuals exhibit systematic biases during judgment and elicitation. All of the models recalibrate judgments or mean judgments via a two-parameter calibration function, and differ in terms of whether (1) the calibration function is applied before or after the averaging, (2) averaging is done in probability or log-odds space, and (3) individual differences are captured via hierarchical modeling. Of the non-hierarchical models, the one that first recalibrates the individual judgments and then averages them in log-odds is the best relative to simple averaging, with 26.7 % improvement in Brier score and better performance on 86 % of the individual problems. The hierarchical version of this model does slightly better in terms of mean Brier score (28.2 %) and slightly worse in terms of individual problems (85 %).", "paper_title": "Forecast aggregation via recalibration", "paper_id": "WOS:000336034000002"}