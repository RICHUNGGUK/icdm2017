{"auto_keywords": [{"score": 0.03359064180929454, "phrase": "non-zero_elements"}, {"score": 0.00481495049065317, "phrase": "large-scale_mobile_ubiquitous_computing"}, {"score": 0.004688321299229397, "phrase": "user-centric_ubiquitous_computing"}, {"score": 0.004605748839642513, "phrase": "personalized_services"}, {"score": 0.004565007074039171, "phrase": "expressed_preferences"}, {"score": 0.004379572106088617, "phrase": "high_volumes"}, {"score": 0.004302413946305072, "phrase": "large_demands"}, {"score": 0.004264343940547844, "phrase": "context-aware_system"}, {"score": 0.004164455874158225, "phrase": "computational_terms"}, {"score": 0.004127601533040351, "phrase": "sequential_minimal_optimization"}, {"score": 0.004007083686875716, "phrase": "text_classification"}, {"score": 0.0039248128268720645, "phrase": "muc-oriented_context_analysis"}, {"score": 0.003754140294151593, "phrase": "multi-label_data"}, {"score": 0.0036553070575015344, "phrase": "efficient_classification_approach"}, {"score": 0.003517107332500739, "phrase": "semi-sparse_algorithm"}, {"score": 0.003394164702727995, "phrase": "svmtorch-based_classification_approaches"}, {"score": 0.002952516738708181, "phrase": "trained_vector"}, {"score": 0.0028662103095187293, "phrase": "traditional_svmtorch_approach"}, {"score": 0.0027989800906333784, "phrase": "single-label_data"}, {"score": 0.0027659570272100835, "phrase": "multi-class_multi-label_classification"}, {"score": 0.0027090988689455735, "phrase": "improved_svmtorch"}, {"score": 0.0026771333996253783, "phrase": "semi-spares_algorithm"}, {"score": 0.002629889135655667, "phrase": "multi-core_processor"}, {"score": 0.002530359917257626, "phrase": "classification_process"}, {"score": 0.0025079304766764616, "phrase": "experimental_results"}, {"score": 0.0024201785622872847, "phrase": "traditional_svmtorch"}, {"score": 0.002356380755825062, "phrase": "larger_training_and_testing_data_sets"}, {"score": 0.002253757988526137, "phrase": "context_classification"}, {"score": 0.002200861826643147, "phrase": "chinese_web_page_classifier"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Classification", " Semi-sparse algorithm", " Multi-class multi-label classification", " Parallelization", " Sequential minimal optimization (SMO)", " Mobile ubiquitous computing"], "paper_abstract": "Context classification is at the center of user-centric ubiquitous computing that targets the provision of personalized services based on expressed preferences and interests. Classification of context for Mobile Ubiquitous Computing (MUC), where there are high volumes of data and users place large demands on a context-aware system, must be effective and efficient in computational terms. The Sequential Minimal Optimization (SMO) based SVMTorch is widely used for text classification; it is however inefficient for MUC-oriented context analysis due to: (1) a low classification speed caused by inefficient matrix multiplication, and (2) the inability to classify multi-label data. In this paper, we propose an efficient classification approach to improve and extend the SVMTorch. Firstly, we propose a semi-sparse algorithm to speed up vector/matrix multiplication which lies at the core of the SVMTorch-based classification approaches. Theoretically, to multiply two vectors (i.e., a selected vector and a trained vector) with m and n non-zero elements respectively, the traditional SVMTorch needs O(m + n) time while our semi-sparse algorithm requires only O(n) time, where n is the number of non-zero elements in the trained vector. Secondly, we extend the functions of the traditional SVMTorch approach which is limited to the classification of single-label data, to support multi-class multi-label classification. Finally, we parallelize the improved SVMTorch which incorporates the semi-spares algorithm and function extensions to access multi-core processor and cluster systems to further improve the effectiveness and efficiency of the classification process. The experimental results demonstrate that our proposed solution significantly improves the performance and capability of the traditional SVMTorch. The results support the conclusion that the larger training and testing data sets are, the more improvement our solution brings to the effectiveness and efficiency of the context classification. This conclusion is verified in a Chinese web page classifier developed based on the solution presented in this paper. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "An efficient classification approach for large-scale mobile ubiquitous computing", "paper_id": "WOS:000316774700027"}