{"auto_keywords": [{"score": 0.0497274163233969, "phrase": "modified_adaptive_testing"}, {"score": 0.033579053218340996, "phrase": "mat"}, {"score": 0.00481495049065317, "phrase": "software_reliability_estimates"}, {"score": 0.004624337472244542, "phrase": "binary_notion"}, {"score": 0.004234129588974058, "phrase": "failure_severity"}, {"score": 0.0039053194919285725, "phrase": "extended_metrics"}, {"score": 0.0038483286199081, "phrase": "nelson's_software_reliability_model"}, {"score": 0.00373682045166829, "phrase": "user's_point"}, {"score": 0.0036285315458900284, "phrase": "observed_failures"}, {"score": 0.003601951458683923, "phrase": "model_formulation"}, {"score": 0.003562444653947001, "phrase": "multi-granularity_failure_severity"}, {"score": 0.003484721713676736, "phrase": "proposed_metrics"}, {"score": 0.003297728079517964, "phrase": "software_reliability"}, {"score": 0.0032376465741070274, "phrase": "extended_adaptive_testing_strategy"}, {"score": 0.003086492169113408, "phrase": "test_history_information"}, {"score": 0.0030526216870671325, "phrase": "resulting_test_process"}, {"score": 0.002942373803701752, "phrase": "limited_test_budget"}, {"score": 0.002878140062594849, "phrase": "real-life_programs"}, {"score": 0.0027946649584841754, "phrase": "mat._results"}, {"score": 0.0026252106881752067, "phrase": "\"true\"_reliability"}, {"score": 0.00257735013358606, "phrase": "random_testing"}, {"score": 0.002368160970983679, "phrase": "reliability_engineers"}, {"score": 0.00224094835951312, "phrase": "proposed_approach"}, {"score": 0.0022081920438290193, "phrase": "software_reliability_estimation_testing"}, {"score": 0.002175913488493802, "phrase": "test_case_selection_process"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Software engineering", " Software reliability", " Software testing"], "paper_abstract": "Context: Most software reliability models are based on a binary notion of correctness, i.e. \"successful\" or \"failed.\" However, in several instances, it is important to account of failure severity to obtain more descriptive and accurate estimates of the reliability of the software. Objective: In this paper, we develop a set of extended metrics based on the Nelson's software reliability model to account for information gained from a user's point of view regarding the severity of the observed failures. Model formulation based on multi-granularity failure severity is provided, and the proposed metrics are proved to be backward compatible. Method: In order to estimate the software reliability through testing, an extended adaptive testing strategy, namely Modified Adaptive Testing (MAT) is proposed. The use of test history information allows the resulting test process to be adaptive in the selection of tests under limited test budget. Simulations and experiments on real-life programs are conducted to evaluate the effectiveness of MAT. Results: Data show that the reliability estimates obtained using MAT (a) are closer to the \"true\" reliability than those obtained using random testing and (b) lead to lower variance than the techniques used for comparison, which means MAT can be applied to help testers and reliability engineers better understand the reliability of their programs. Conclusion: It is concluded that the proposed approach can enhance the software reliability estimation testing by guiding the test case selection process by providing more descriptive and accurate results. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Enhancing software reliability estimates using modified adaptive testing", "paper_id": "WOS:000312759500008"}