{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "scene_context"}, {"score": 0.004754600386388821, "phrase": "video_event_description"}, {"score": 0.004665483918844599, "phrase": "important_research_topic"}, {"score": 0.0046069985410261746, "phrase": "video_analysis"}, {"score": 0.00452063603944825, "phrase": "vast_amount"}, {"score": 0.0043527164193299574, "phrase": "visual_surveillance"}, {"score": 0.004298134888203576, "phrase": "video_retrieval"}, {"score": 0.004244234872662471, "phrase": "video_annotation"}, {"score": 0.004191007935893067, "phrase": "video_database_indexing"}, {"score": 0.004112411350177274, "phrase": "interactive_system"}, {"score": 0.0038365781437074017, "phrase": "automated_video_event_description"}, {"score": 0.0036707250689857348, "phrase": "context_knowledge"}, {"score": 0.0036018503805251424, "phrase": "accurate_and_reliable_event_description"}, {"score": 0.003317970131738248, "phrase": "objects_activities"}, {"score": 0.002887450071878095, "phrase": "contextual_cues"}, {"score": 0.0027625134766418266, "phrase": "semantic_video_event_description"}, {"score": 0.0023887436047824386, "phrase": "attractive_experimental_results"}, {"score": 0.0023290951071300433, "phrase": "system_efficiency"}, {"score": 0.002299830460180699, "phrase": "tracking_capability"}, {"score": 0.0022142194702079866, "phrase": "real-world_video"}, {"score": 0.002186395051086251, "phrase": "video_event_understanding_application"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Video understanding", " Video surveillance", " Visual event description", " Context"], "paper_abstract": "Video event description is an important research topic in video analysis with a vast amount of applications, such as visual surveillance, video retrieval, video annotation, video database indexing, and interactive system. In this paper, we present a framework for automated video event description, which features fused with the context knowledge to provide accurate and reliable event description. The processing framework is designed to describe the event and recognize objects activities composed of four components: object detection, classification, tracking, and semantic event description. Our contribution is to integrate the contextual cues into these components to facilitate the semantic video event description. Furthermore, in the tracking part, a novel adaptive shape kernel based mean shift tracking algorithm is proposed to improve object tracking performance under object deformation and background clutter. In the experiments, we show attractive experimental results, highlighting the system efficiency and tracking capability by using our video event description system on a real-world video for video event understanding application. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Video event description in scene context", "paper_id": "WOS:000323851800012"}