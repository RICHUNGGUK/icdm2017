{"auto_keywords": [{"score": 0.0353238326861397, "phrase": "clu"}, {"score": 0.012247822237899268, "phrase": "co-scheduled_threads"}, {"score": 0.007959512722964293, "phrase": "existing_approaches"}, {"score": 0.004815681837584665, "phrase": "utility"}, {"score": 0.004766683200410046, "phrase": "thread-aware_capacity_management"}, {"score": 0.004509694461067052, "phrase": "large_shared_last-level_cache"}, {"score": 0.004202472962684885, "phrase": "state-of-the-art_cache_management_proposals"}, {"score": 0.003975781274672803, "phrase": "existing_alternative_replacement_policies"}, {"score": 0.003916098498242888, "phrase": "partitioning_schemes"}, {"score": 0.0036125439380579626, "phrase": "best_performance"}, {"score": 0.0034003686971964707, "phrase": "novel_adaptive_scheme"}, {"score": 0.0031208772639433145, "phrase": "thread-aware_sllc_capacity_management"}, {"score": 0.0028642958603033466, "phrase": "bip"}, {"score": 0.0027370835853738626, "phrase": "individual_threads"}, {"score": 0.002524688179363081, "phrase": "concurrent_threads"}, {"score": 0.0023523750536537102, "phrase": "extensive_execution-driven_simulation_experiments"}, {"score": 0.002202894673025544, "phrase": "tadip"}, {"score": 0.0021807544600219216, "phrase": "nucache"}, {"score": 0.002158836285985314, "phrase": "ta-drrip"}, {"score": 0.002137139843388748, "phrase": "ucp"}, {"score": 0.0021049977753042253, "phrase": "pipp"}], "paper_keywords": ["Capacity management", " chip multiprocessors", " locality and utility co-optimization", " shared last level caches"], "paper_abstract": "Most chip-multiprocessors nowadays adopt a large shared last-level cache (SLLC). This paper is motivated by our analysis and evaluation of state-of-the-art cache management proposals which reveal a common weakness. That is, the existing alternative replacement policies and cache partitioning schemes, targeted at optimizing either locality or utility of co-scheduled threads, cannot deliver consistently the best performance under a variety of workloads. Therefore, we propose a novel adaptive scheme, called CLU, to interactively co-optimize the locality and utility of co-scheduled threads in thread-aware SLLC capacity management. CLU employs lightweight monitors to dynamically profile the LRU (least recently used) and BIP (bimodal insertion policy) hit curves of individual threads on runtime, enabling the scheme to co-optimize the locality and utility of concurrent threads and thus adapt to more diverse workloads than the existing approaches. We provide results from extensive execution-driven simulation experiments to demonstrate the feasibility and efficacy of CLU over the existing approaches (TADIP, NUCACHE, TA-DRRIP, UCP, and PIPP).", "paper_title": "CLU: Co-Optimizing Locality and Utility in Thread-Aware Capacity Management for Shared Last Level Caches", "paper_id": "WOS:000338511000005"}