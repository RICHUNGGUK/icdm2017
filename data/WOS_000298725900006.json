{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "cognitive_biases"}, {"score": 0.04938419617030255, "phrase": "distance-based_rewards"}, {"score": 0.030559982275233617, "phrase": "explicit_rewards"}, {"score": 0.004642105253191792, "phrase": "connectionist_model"}, {"score": 0.004574709094672837, "phrase": "complex_problem"}, {"score": 0.004099340908974491, "phrase": "distance-based_and_environmental_rewards"}, {"score": 0.004010342699414496, "phrase": "temporal-difference_learning_mechanism"}, {"score": 0.003810093416457147, "phrase": "experimental_data"}, {"score": 0.003700170452390401, "phrase": "well-defined_and_planning-intensive_problem"}, {"score": 0.003315374849824563, "phrase": "temporal-difference_learning_rule"}, {"score": 0.0032671780161107403, "phrase": "sarsa"}, {"score": 0.0031961879138783012, "phrase": "model_adequacy"}, {"score": 0.0031267359296488118, "phrase": "solution_space"}, {"score": 0.0030587884803931964, "phrase": "biased_models"}, {"score": 0.002992313172550772, "phrase": "observed_human_solutions"}, {"score": 0.002528300562452668, "phrase": "learning_rule"}, {"score": 0.002248553559414903, "phrase": "problem_solvers'_ability"}, {"score": 0.0021996478802839316, "phrase": "optimal_solutions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Problem solving", " Computational modeling", " Reinforcement learning", " Temporal-difference learning", " Cognitive biases", " Distance-reduction heuristic"], "paper_abstract": "We present a cognitive, connectionist-based model of complex problem solving that integrates cognitive biases and distance-based and environmental rewards under a temporal-difference learning mechanism. The model is tested against experimental data obtained in a well-defined and planning-intensive problem. We show that incorporating cognitive biases (symmetry and simplicity) in a temporal-difference learning rule (SARSA) increases model adequacy-the solution space explored by biased models better fits observed human solutions. While learning from explicit rewards alone is intrinsically slow, adding distance-based rewards, a measure of closeness to goal, to the learning rule significantly accelerates learning. Finally, the model correctly predicts that explicit rewards have little impact on problem solvers' ability to discover optimal solutions. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Including cognitive biases and distance-based rewards in a connectionist model of complex problem solving", "paper_id": "WOS:000298725900006"}