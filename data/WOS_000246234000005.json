{"auto_keywords": [{"score": 0.03923307184680597, "phrase": "cfs"}, {"score": 0.01546169062245044, "phrase": "data_distribution_scheme"}, {"score": 0.013144901938837208, "phrase": "data_compression_phase"}, {"score": 0.011245819186660106, "phrase": "ed_scheme"}, {"score": 0.010010307946572204, "phrase": "ed_schemes"}, {"score": 0.008713733242517882, "phrase": "sparse_arrays"}, {"score": 0.007550070002863669, "phrase": "data_partition_phase"}, {"score": 0.006475589599976059, "phrase": "cfs_scheme"}, {"score": 0.006304884431407954, "phrase": "data_distribution_phase"}, {"score": 0.005406645939297443, "phrase": "sfc_scheme"}, {"score": 0.004782848614014638, "phrase": "distributed_memory_multicomputers"}, {"score": 0.004745619559285371, "phrase": "sfc"}, {"score": 0.004656557209439822, "phrase": "distributed_memory_multicomputer"}, {"score": 0.004528479638303172, "phrase": "theoretical_analysis"}, {"score": 0.004498279065640151, "phrase": "experimental_tests"}, {"score": 0.0038178839445849374, "phrase": "test_cases"}, {"score": 0.0037587384888691645, "phrase": "compress_followed_send"}, {"score": 0.003696335049359496, "phrase": "encoding-decoding"}, {"score": 0.003622811707147052, "phrase": "sparse_array_distribution"}, {"score": 0.003265531406540679, "phrase": "encoding_step"}, {"score": 0.0032328778271536454, "phrase": "decoding_step"}, {"score": 0.0029139401928060123, "phrase": "row_partition"}, {"score": 0.002884792163423083, "phrase": "column_partition"}, {"score": 0.0027159094186967247, "phrase": "compression_phase"}, {"score": 0.002644050667977234, "phrase": "sparse_local_arrays"}, {"score": 0.002591403838835242, "phrase": "cfs_schemes"}, {"score": 0.0022890828779208016, "phrase": "data_distribution_time"}, {"score": 0.002140593237903078, "phrase": "experimental_results"}], "paper_keywords": ["data distribution schemes", " data compression methods", " partition methods", " sparse ratio", " distributed memory multicomputers"], "paper_abstract": "A data distribution scheme of sparse arrays on a distributed memory multicomputer, in general, is composed of three phases, data partition, data distribution, and data compression. To implement the data distribution scheme, many methods proposed in the literature first perform the data partition phase, then the data distribution phase, followed by the data compression phase. We called a data distribution scheme with this order as Send Followed Compress ( SFC) scheme. In this paper, we propose two other data distribution schemes, Compress Followed Send ( CFS) and Encoding-Decoding ( ED), for sparse array distribution. In the CFS scheme, the data compression phase is performed before the data distribution phase. In the ED scheme, the data compression phase can be divided into two steps, encoding and decoding. The encoding step and the decoding step are performed before and after the data distribution phase, respectively. To evaluate the CFS and the ED schemes, we compare them with the SFC scheme. In the data partition phase, the row partition, the column partition, and the 2D mesh partition with/without load-balancing methods are used for these three schemes. In the compression phase, the CRS/CCS methods are used to compress sparse local arrays for the SFC and the CFS schemes while the encoding/decoding step is used for the ED scheme. Both theoretical analysis and experimental tests were conducted. In the theoretical analysis, we analyze the SFC, the CFS, and the ED schemes in terms of the data distribution time and the data compression time. In experimental tests, we implemented these three schemes on an IBM SP2 parallel machine. From the experimental results, for most of test cases, the CFS and the ED schemes outperform the SFC scheme. For the CFS and the ED schemes, the ED scheme outperforms the CFS scheme for all test cases.", "paper_title": "Data distribution schemes of sparse arrays on distributed memory multicomputers", "paper_id": "WOS:000246234000005"}