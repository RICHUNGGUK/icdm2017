{"auto_keywords": [{"score": 0.039695600084995036, "phrase": "minimal_penalty"}, {"score": 0.00481495049065317, "phrase": "least-squares_regression"}, {"score": 0.004764542405129454, "phrase": "penalization_procedures"}, {"score": 0.0046164478775379105, "phrase": "multiplying_factors"}, {"score": 0.004243552607799184, "phrase": "completely_data-driven_calibration_algorithm"}, {"score": 0.004111584914709491, "phrase": "least-squares_regression_framework"}, {"score": 0.0040047396607954325, "phrase": "particular_shape"}, {"score": 0.0036810742597041565, "phrase": "birge"}, {"score": 0.003642497154823283, "phrase": "massart"}, {"score": 0.003492155652400838, "phrase": "penalized_least_squares"}, {"score": 0.0034555479218891638, "phrase": "gaussian_homoscedastic_regression"}, {"score": 0.003383475802364289, "phrase": "positive_side"}, {"score": 0.0031262984171100856, "phrase": "data-driven_estimation"}, {"score": 0.0030772505522663612, "phrase": "optimal_penalty"}, {"score": 0.00291923164591297, "phrase": "negative_side"}, {"score": 0.002813457986293993, "phrase": "homoscedastic_gaussian_nature"}, {"score": 0.0025586903829811296, "phrase": "data-driven_penalty"}, {"score": 0.0024017638230939514, "phrase": "penalized_least-squares_regression"}, {"score": 0.0023025177990160487, "phrase": "heteroscedastic_non-gaussian_data"}, {"score": 0.002219040041886641, "phrase": "exact_mathematical_results"}, {"score": 0.0021498955164659145, "phrase": "regressogram_bin-width_selection"}], "paper_keywords": ["data-driven calibration", " non-parametric regression", " model selection by penalization", " heteroscedastic data", " regressogram"], "paper_abstract": "Penalization procedures often suffer from their dependence on multiplying factors, whose optimal values are either unknown or hard to estimate from data. We propose a completely data-driven calibration algorithm for these parameters in the least-squares regression framework, without assuming a particular shape for the penalty. Our algorithm relies on the concept of minimal penalty, recently introduced by Birge and Massart (2007) in the context of penalized least squares for Gaussian homoscedastic regression. On the positive side, the minimal penalty can be evaluated from the data themselves, leading to a data-driven estimation of an optimal penalty which can be used in practice; on the negative side, their approach heavily relies on the homoscedastic Gaussian nature of their stochastic framework. The purpose of this paper is twofold: stating a more general heuristics for designing a data-driven penalty (the slope heuristics) and proving that it works for penalized least-squares regression with a random design, even for heteroscedastic non-Gaussian data. For technical reasons, some exact mathematical results will be proved only for regressogram bin-width selection. This is at least a first step towards further results, since the approach and the method that we use are indeed general.", "paper_title": "Data-driven Calibration of Penalties for Least-Squares Regression", "paper_id": "WOS:000270824200006"}