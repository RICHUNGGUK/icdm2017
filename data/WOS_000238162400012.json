{"auto_keywords": [{"score": 0.04594191530665988, "phrase": "learned_model"}, {"score": 0.01475742681720304, "phrase": "pictorial_structures"}, {"score": 0.010435409021063343, "phrase": "object_recognition"}, {"score": 0.004761010795871555, "phrase": "model_building"}, {"score": 0.004707672504464783, "phrase": "similar_activities"}, {"score": 0.004620093797504386, "phrase": "fully_automatic_system"}, {"score": 0.004237666411136617, "phrase": "original_video"}, {"score": 0.004035630066743877, "phrase": "generalized_tracker"}, {"score": 0.003729335910488339, "phrase": "visual_library"}, {"score": 0.003578255090799811, "phrase": "video_recognition_algorithm"}, {"score": 0.003407549468745519, "phrase": "novel_images"}, {"score": 0.0029984960344766705, "phrase": "discriminative_texture_model"}, {"score": 0.002953711377604328, "phrase": "texture_library"}, {"score": 0.0028986672783671147, "phrase": "novel_texture_descriptor"}, {"score": 0.0028553693643045795, "phrase": "state-_of-_the-_art"}, {"score": 0.0027706987570488084, "phrase": "entire_system"}, {"score": 0.0027499252661633525, "phrase": "real_video_sequences"}, {"score": 0.002560162916190598, "phrase": "learned_models"}, {"score": 0.002465593351432208, "phrase": "professional_photographers"}, {"score": 0.002437907960209364, "phrase": "corel_collection"}, {"score": 0.0024105326885334962, "phrase": "assorted_images"}, {"score": 0.0023567516921493277, "phrase": "google"}, {"score": 0.0023214774334744713, "phrase": "quite_good_performance"}, {"score": 0.002295406551990453, "phrase": "data_sets"}, {"score": 0.002252602622785975, "phrase": "simple_baselines"}, {"score": 0.0021857667493036786, "phrase": "google_set"}], "paper_keywords": ["tracking", " video analysis", " object recognition", " texture", " shape"], "paper_abstract": "This paper argues that tracking, object detection, and model building are all similar activities. We describe a fully automatic system that builds 2D articulated models known as pictorial structures from videos of animals. The learned model can be used to detect the animal in the original video - in this sense, the system can be viewed as a generalized tracker ( one that is capable of modeling objects while tracking them). The learned model can be matched to a visual library; here, the system can be viewed as a video recognition algorithm. The learned model can also be used to detect the animal in novel images - in this case, the system can be seen as a method for learning models for object recognition. We find that we can significantly improve the pictorial structures by augmenting them with a discriminative texture model learned from a texture library. We develop a novel texture descriptor that outperforms the state- of- the- art for animal textures. We demonstrate the entire system on real video sequences of three different animals. We show that we can automatically track and identify the given animal. We use the learned models to recognize animals from two data sets; images taken by professional photographers from the Corel collection, and assorted images from the Web returned by Google. We demonstrate quite good performance on both data sets. Comparing our results with simple baselines, we show that, for the Google set, we can detect, localize, and recover part articulations from a collection demonstrably hard for object recognition.", "paper_title": "Building models of animals from video", "paper_id": "WOS:000238162400012"}