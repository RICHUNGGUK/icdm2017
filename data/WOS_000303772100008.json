{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "meta-generalising"}, {"score": 0.004669845451682529, "phrase": "gaussian_processes_approach"}, {"score": 0.004437613070853689, "phrase": "novel_model"}, {"score": 0.004007083686875716, "phrase": "novel_tasks"}, {"score": 0.003807684498435389, "phrase": "multiple_different_but_related_tasks"}, {"score": 0.0034733518170738517, "phrase": "structured_covariance_function"}, {"score": 0.0032008144731234265, "phrase": "constrained_covariance_function"}, {"score": 0.002889928791032578, "phrase": "second_model"}, {"score": 0.0027459678326877744, "phrase": "new_tasks"}, {"score": 0.0021049977753042253, "phrase": "distributional_assumptions"}], "paper_keywords": ["transfer learning", " meta-generalising", " multi-task learning", " Gaussian processes", " mixture of experts"], "paper_abstract": "We propose a novel model for meta-generalisation, that is, performing prediction on novel tasks based on information from multiple different but related tasks. The model is based on two coupled Gaussian processes with structured covariance function; one model performs predictions by learning a constrained covariance function encapsulating the relations between the various training tasks, while the second model determines the similarity of new tasks to previously seen tasks. We demonstrate empirically on several real and synthetic data sets both the strengths of the approach and its limitations due to the distributional assumptions underpinning it.", "paper_title": "A Case Study on Meta-Generalising: A Gaussian Processes Approach", "paper_id": "WOS:000303772100008"}