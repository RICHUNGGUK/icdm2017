{"auto_keywords": [{"score": 0.029555701399733778, "phrase": "detected_objects"}, {"score": 0.02935287546480261, "phrase": "actual_number"}, {"score": 0.027271736123581573, "phrase": "visual_count"}, {"score": 0.004814978380654878, "phrase": "apple"}, {"score": 0.0047810714349158165, "phrase": "nighttime_tree_images"}, {"score": 0.004725132736474305, "phrase": "light_patches"}, {"score": 0.004636982629843122, "phrase": "tree_images"}, {"score": 0.0045719459699563895, "phrase": "numerous_studies"}, {"score": 0.004476089640861217, "phrase": "color_analysis"}, {"score": 0.004444584236456524, "phrase": "major_drawback"}, {"score": 0.004382234207023988, "phrase": "fruit_apparent_color"}, {"score": 0.004310592339589697, "phrase": "physiological_stage"}, {"score": 0.0041316803676012155, "phrase": "artificial_lighting"}, {"score": 0.0040737018909236585, "phrase": "present_work"}, {"score": 0.004035500442527029, "phrase": "novel_approach"}, {"score": 0.0039882499926006554, "phrase": "nighttime_images"}, {"score": 0.003950846696972114, "phrase": "spatial_distribution"}, {"score": 0.003760137090849196, "phrase": "artificial_illumination"}, {"score": 0.003716098757045306, "phrase": "strong_specular_reflection"}, {"score": 0.003595506260984908, "phrase": "almost_all_apples"}, {"score": 0.0034218902120916345, "phrase": "investigated_light_patch"}, {"score": 0.003272020272596001, "phrase": "gray_level_intensities"}, {"score": 0.0032260660374775854, "phrase": "patch_geometry"}, {"score": 0.0029845805271621942, "phrase": "twenty_images"}, {"score": 0.0028203552122952266, "phrase": "linear_relationship"}, {"score": 0.0026651421723078643, "phrase": "calibrated_procedure"}, {"score": 0.0026463494192477803, "phrase": "remaining_images"}, {"score": 0.0024655404714414297, "phrase": "apparent_size"}, {"score": 0.002385433137609532, "phrase": "apple_size"}, {"score": 0.0021911659901333587, "phrase": "estimated_number"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Artificial vision", " Fruit localization", " Specular highlights", " Yield estimation"], "paper_abstract": "Detection of fruit in tree images has been the focus of numerous studies. Although most studies considered approaches based primarily on color analysis, the major drawback of such approaches is that the fruit apparent color depends not only on variety or physiological stage but also on illumination, which is inherently non-uniform within the canopy, even if artificial lighting is used. In the present work we developed a novel approach to detect apples in nighttime images by analyzing the spatial distribution of the light around highlights (\"bright spots\"). The approach is based on the observation that, under the artificial illumination used, apples exhibit strong specular reflection so that a small, but very bright, spot is visible on almost all apples. Each of these highlights serves as the center of a region of interest and is the seed of the investigated light patch. This patch is initially very small but its size is increased iteratively by annexing pixels with predefined decreasing gray level intensities. The evolution of the patch geometry is used to determine whether it corresponds to an apple. The approach was tested with two datasets containing over 360 images (close to 13,000 apples) acquired in the same 'Golden Delicious' orchard in July 2012 and August 2013. Twenty images from the 2012 dataset were randomly selected to develop and calibrate the procedure. The results of these 20 images were used to establish a linear relationship between the number of detected objects and the actual number of apples visible in the images (R-2 similar to 0.75). Applying the calibrated procedure to the remaining images of this dataset led to an estimate of 6739 apples compared to a visual count of 6195 apples (similar to 9% overestimate). Analysis of the 2013 dataset, in which the apparent size of the apples was smaller, required only adjustment of the two parameters related to apple size. Following this adjustment, 12 images were randomly selected to determine the relationship between the number of detected objects and the actual number of apples (R-2 similar to 0.74). Using this relationship, the estimated number of apples was 6687, compared to the visual count of 6713 fruits. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Apple detection in nighttime tree images using the geometry of light patches around highlights", "paper_id": "WOS:000357241400017"}