{"auto_keywords": [{"score": 0.03906597166738946, "phrase": "staging_area"}, {"score": 0.006877318012402955, "phrase": "consumer_nodes"}, {"score": 0.005124497689488527, "phrase": "data-processing_code"}, {"score": 0.00481495049065317, "phrase": "dynamic_code_deployment"}, {"score": 0.0047804843375940835, "phrase": "extreme_scale_data_processing"}, {"score": 0.00471228691115201, "phrase": "large_volumes"}, {"score": 0.0046118021635786315, "phrase": "scientific_and_engineering_simulations"}, {"score": 0.004562362497952548, "phrase": "leadership-class_resources"}, {"score": 0.004497262692458022, "phrase": "critical_challenge"}, {"score": 0.004338530593157634, "phrase": "computing_nodes"}, {"score": 0.003965684670332574, "phrase": "data-related_challenges"}, {"score": 0.003798231095121328, "phrase": "smaller_set"}, {"score": 0.0037710151976096985, "phrase": "dedicated_computing_nodes"}, {"score": 0.0032423089921154503, "phrase": "alternate_approach"}, {"score": 0.002984794722633428, "phrase": "activespaces_framework"}, {"score": 0.002900090135006575, "phrase": "data-processing_routines"}, {"score": 0.002493184318829227, "phrase": "experimental_performance_evaluation"}, {"score": 0.0024136908511423875, "phrase": "oak_ridge_national_laboratory"}, {"score": 0.0023536149458842992, "phrase": "coupled_fusion_application_workflow"}, {"score": 0.0022379017425216917, "phrase": "data_processing"}, {"score": 0.0021821915946356168, "phrase": "sweet_spots"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["dynamic code deployment", " in situ data processing", " data-intensive application workflows", " coupled simulations"], "paper_abstract": "Managing the large volumes of data produced by emerging scientific and engineering simulations running on leadership-class resources has become a critical challenge. The data have to be extracted off the computing nodes and transported to consumer nodes so that it can be processed, analyzed, visualized, archived, and so on. Several recent research efforts have addressed data-related challenges at different levels. One attractive approach is to offload expensive input/output operations to a smaller set of dedicated computing nodes known as a staging area. However, even using this approach, the data still have to be moved from the staging area to consumer nodes for processing, which continues to be a bottleneck. In this paper, we investigate an alternate approach, namely moving the data-processing code to the staging area instead of moving the data to the data-processing code. Specifically, we describe the ActiveSpaces framework, which provides (1) programming support for defining the data-processing routines to be downloaded to the staging area and (2) runtime mechanisms for transporting codes associated with these routines to the staging area, executing the routines on the nodes that are part of the staging area, and returning the results. We also present an experimental performance evaluation of ActiveSpaces using applications running on the Cray XT5 at Oak Ridge National Laboratory. Finally, we use a coupled fusion application workflow to explore the trade-offs between transporting data and transporting the code required for data processing during coupling, and we characterize sweet spots for each option. Copyright (C) 2014 John Wiley & Sons, Ltd.", "paper_title": "ActiveSpaces: Exploring dynamic code deployment for extreme scale data processing", "paper_id": "WOS:000362978600009"}