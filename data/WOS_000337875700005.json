{"auto_keywords": [{"score": 0.047063104821016395, "phrase": "body_region"}, {"score": 0.014333489079376448, "phrase": "different_body_regions"}, {"score": 0.010715592977507276, "phrase": "irfc"}, {"score": 0.00481495049065317, "phrase": "medical_images"}, {"score": 0.004782977628406988, "phrase": "quantitative_radiology"}, {"score": 0.0047275327200245005, "phrase": "radiological_practice"}, {"score": 0.004680517945374273, "phrase": "automatic_anatomy_recognition"}, {"score": 0.004664952076676874, "phrase": "aar"}, {"score": 0.004580243025274209, "phrase": "general_aar_system"}, {"score": 0.004527137552710186, "phrase": "specific_organ_system"}, {"score": 0.00448958076531243, "phrase": "image_modality"}, {"score": 0.004444921827311577, "phrase": "aar_methodology"}, {"score": 0.004400705158735729, "phrase": "major_organs"}, {"score": 0.004364192646519588, "phrase": "fuzzy_modeling_ideas"}, {"score": 0.004342430078306461, "phrase": "tight_integration"}, {"score": 0.004327981760540394, "phrase": "fuzzy_models"}, {"score": 0.004207087817328151, "phrase": "image_data"}, {"score": 0.004186105377259855, "phrase": "building_models"}, {"score": 0.004158290806404304, "phrase": "aar_algorithms"}, {"score": 0.004069158284751546, "phrase": "precise_definitions"}, {"score": 0.003955465362027017, "phrase": "hierarchical_fuzzy_anatomy_models"}, {"score": 0.003832137365884996, "phrase": "hierarchical_models"}, {"score": 0.003694114717954992, "phrase": "object_size"}, {"score": 0.0036818155258964984, "phrase": "positional_relationships"}, {"score": 0.003620928857472811, "phrase": "object_recognition"}, {"score": 0.0035373693665579848, "phrase": "modality-independent_and_dependent_aspects"}, {"score": 0.0035079946851603186, "phrase": "model_encoding"}, {"score": 0.0034846700528752368, "phrase": "model_building_stage"}, {"score": 0.003467278055590987, "phrase": "learning_process"}, {"score": 0.003427032390942116, "phrase": "optimal_threshold-based_object_recognition_method"}, {"score": 0.0033035520810722886, "phrase": "local_manner"}, {"score": 0.0032870610622926445, "phrase": "fuzzy_model-based_version"}, {"score": 0.0032272929113113203, "phrase": "fuzzy_model_constraints"}, {"score": 0.0032111813445974244, "phrase": "delineation_algorithm"}, {"score": 0.003195149953590668, "phrase": "aar_system"}, {"score": 0.002983885361174063, "phrase": "model_building"}, {"score": 0.002954159491429859, "phrase": "training_and_testing_data_sets"}, {"score": 0.0029345064612953382, "phrase": "equal_size"}, {"score": 0.002881130228859848, "phrase": "aar_method"}, {"score": 0.0028667418348109603, "phrase": "mean_accuracy"}, {"score": 0.002842920225545139, "phrase": "non-sparse_blob-like_objects"}, {"score": 0.0028052155436760528, "phrase": "delineation_accuracy"}, {"score": 0.0027865506182608263, "phrase": "mean_false_positive_and_negative_volume_fractions"}, {"score": 0.002754184509461602, "phrase": "non-sparse_objects"}, {"score": 0.0027085964929870468, "phrase": "sparse_objects"}, {"score": 0.0026816057119800336, "phrase": "boundary_distance"}, {"score": 0.0026328173871352635, "phrase": "sparse_objects_-_venous_system"}, {"score": 0.002438203996977464, "phrase": "poor_recognition"}, {"score": 0.002421975107313603, "phrase": "mr_method"}, {"score": 0.002381872778203302, "phrase": "recent_literature"}, {"score": 0.0023463473826154397, "phrase": "ct_images"}, {"score": 0.0023036445575469046, "phrase": "dependent_aspects"}, {"score": 0.0022617171493115895, "phrase": "object_relationship_information"}, {"score": 0.002239169459464009, "phrase": "optimal_threshold-based_recognition_learning"}, {"score": 0.0022057677637040396, "phrase": "effective_concepts"}, {"score": 0.00216923754570397, "phrase": "general_mr_system"}, {"score": 0.0021261972801049573, "phrase": "different_modalities"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Anatomy modeling", " Fuzzy models", " Object recognition", " Image segmentation", " Fuzzy connectedness"], "paper_abstract": "To make Quantitative Radiology (QR) a reality in radiological practice, computerized body-wide Automatic Anatomy Recognition (AAR) becomes essential. With the goal of building a general AAR system that is not tied to any specific organ system, body region, or image modality, this paper presents an AAR methodology for localizing and delineating all major organs in different body regions based on fuzzy modeling ideas and a tight integration of fuzzy models with an Iterative Relative Fuzzy Connectedness (IRFC) delineation algorithm. The methodology consists of five main steps: (a) gathering image data for both building models and testing the AAR algorithms from patient image sets existing in our health system; (b) formulating precise definitions of each body region and organ and delineating them following these definitions; (c) building hierarchical fuzzy anatomy models of organs for each body region; (d) recognizing and locating organs in given images by employing the hierarchical models; and (e) delineating the organs following the hierarchy. In Step (c), we explicitly encode object size and positional relationships into the hierarchy and subsequently exploit this information in object recognition in Step (d) and delineation in Step (e). Modality-independent and dependent aspects are carefully separated in model encoding. At the model building stage, a learning process is carried out for rehearsing an optimal threshold-based object recognition method. The recognition process in Step (d) starts from large, well-defined objects and proceeds down the hierarchy in a global to local manner. A fuzzy model-based version of the IRFC algorithm is created by naturally integrating the fuzzy model constraints into the delineation algorithm. The AAR system is tested on three body regions - thorax (on CT), abdomen (on CT and MRI), and neck (on MRI and CT) - involving a total of over 35 organs and 130 data sets (the total used for model building and testing). The training and testing data sets are divided into equal size in all cases except for the neck. Overall the AAR method achieves a mean accuracy of about 2 voxels in localizing non-sparse blob-like objects and most sparse tubular objects. The delineation accuracy in terms of mean false positive and negative volume fractions is 2% and 8%, respectively, for non-sparse objects, and 5% and 15%, respectively, for sparse objects. The two object groups achieve mean boundary distance relative to ground truth of 0.9 and 1.5 voxels, respectively. Some sparse objects - venous system (in the thorax on CT), inferior vena cava (in the abdomen on CT), and mandible and naso-pharynx (in neck on MRI, but not on CT) - pose challenges at all levels, leading to poor recognition and/or delineation results. The MR method fares quite favorably when compared with methods from the recent literature for liver, kidneys, and spleen on CT images. We conclude that separation of modality-independent from dependent aspects, organization of objects in a hierarchy, encoding of object relationship information explicitly into the hierarchy, optimal threshold-based recognition learning, and fuzzy model-based IRFC are effective concepts which allowed us to demonstrate the feasibility of a general MR system that works in different body regions on a variety of organs and on different modalities. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Body-wide hierarchical fuzzy modeling, recognition, and delineation of anatomy in medical images", "paper_id": "WOS:000337875700005"}