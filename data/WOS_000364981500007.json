{"auto_keywords": [{"score": 0.048548170765263736, "phrase": "mods"}, {"score": 0.014876841288367516, "phrase": "view_synthesis"}, {"score": 0.014538937528638173, "phrase": "mods_algorithm"}, {"score": 0.00481495049065317, "phrase": "two-view_matching"}, {"score": 0.004748371393578422, "phrase": "novel_algorithm"}, {"score": 0.004704495156558224, "phrase": "wide-baseline_matching"}, {"score": 0.004307286039184164, "phrase": "broader_range"}, {"score": 0.004267468074128779, "phrase": "wide-baseline_problems"}, {"score": 0.004017437417375057, "phrase": "standard_matchers"}, {"score": 0.00398028819691605, "phrase": "simple_problems"}, {"score": 0.0039252049353279556, "phrase": "apparent_robustness"}, {"score": 0.003888905257972882, "phrase": "speed_trade-off"}, {"score": 0.003764469758319617, "phrase": "progressively_more_time-consuming_feature_detectors"}, {"score": 0.0036271080216837286, "phrase": "synthesized_images"}, {"score": 0.0035273744062641606, "phrase": "reliable_estimate"}, {"score": 0.0033828748627992193, "phrase": "improved_method"}, {"score": 0.0033515736929172644, "phrase": "tentative_correspondence_selection"}, {"score": 0.0030825404960282713, "phrase": "distance_rule"}, {"score": 0.0030117065110966414, "phrase": "correct_matches"}, {"score": 0.002942495422585405, "phrase": "additional_computational_cost"}, {"score": 0.0027570267191549774, "phrase": "new_set"}, {"score": 0.0027062100658653485, "phrase": "wide_baseline_problems"}, {"score": 0.002607362103727335, "phrase": "ground_truth"}, {"score": 0.0022889103976458437, "phrase": "difficult_two-view_problems"}, {"score": 0.0022258906408344973, "phrase": "different_modalities"}, {"score": 0.002195033004022173, "phrase": "wide_temporal_baseline"}, {"score": 0.0021646022201798247, "phrase": "significant_lighting_changes"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Wide baseline stereo", " Image matching", " Local feature detectors", " Local feature descriptors"], "paper_abstract": "A novel algorithm for wide-baseline matching called MODS matching on demand with view synthesis is presented. The MODS algorithm is experimentally shown to solve a broader range of wide-baseline problems than the state of the art while being nearly as fast as standard matchers on simple problems. The apparent robustness vs. speed trade-off is finessed by the use of progressively more time-consuming feature detectors and by on-demand generation of synthesized images that is performed until a reliable estimate of geometry is obtained. We introduce an improved method for tentative correspondence selection, applicable both with and without view synthesis. A modification of the standard first to second nearest distance rule increases the number of correct matches by 5-20% at no additional computational cost. Performance of the MODS algorithm is evaluated on several standard publicly available datasets, and on a new set of geometrically challenging wide baseline problems that is made public together with the ground truth. Experiments show that the MODS outperforms the state-of-the-art in robustness and speed. Moreover, MODS performs well on other classes of difficult two-view problems like matching of images from different modalities, with wide temporal baseline or with significant lighting changes. (c) 2015 Elsevier Inc. All rights reserved.", "paper_title": "MODS: Fast and robust method for two-view matching", "paper_id": "WOS:000364981500007"}