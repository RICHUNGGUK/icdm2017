{"auto_keywords": [{"score": 0.04882655221850924, "phrase": "apso"}, {"score": 0.005682294888622462, "phrase": "convergence_speed"}, {"score": 0.00481495049065317, "phrase": "adaptive_particle_swarm_optimization"}, {"score": 0.0047515546458205046, "phrase": "adaptive_particle_swarm"}, {"score": 0.004606843145343611, "phrase": "better_search_efficiency"}, {"score": 0.004566308708871429, "phrase": "classical_particle_swarm_optimization"}, {"score": 0.004526148970631683, "phrase": "pso"}, {"score": 0.004340166735586905, "phrase": "pso_paradigm"}, {"score": 0.004292337783332826, "phrase": "global_search"}, {"score": 0.004235793609579307, "phrase": "entire_search_space"}, {"score": 0.004198510172614725, "phrase": "faster_convergence_speed"}, {"score": 0.003964007795174772, "phrase": "population_distribution"}, {"score": 0.003929107176349023, "phrase": "particle_fitness"}, {"score": 0.003877329308854808, "phrase": "real-time_evolutionary_state_estimation_procedure"}, {"score": 0.0036932254391253134, "phrase": "evolutionary_states"}, {"score": 0.0033955105098235345, "phrase": "automatic_control"}, {"score": 0.003365598242636633, "phrase": "inertia_weight"}, {"score": 0.0032199307816384577, "phrase": "run_time"}, {"score": 0.003163439005885435, "phrase": "search_efficiency"}, {"score": 0.003066945490483524, "phrase": "elitist_learning_strategy"}, {"score": 0.002999823428906084, "phrase": "evolutionary_state"}, {"score": 0.0029471818883482688, "phrase": "convergence_state"}, {"score": 0.0028446460307503343, "phrase": "globally_best_particle"}, {"score": 0.0027700855441353165, "phrase": "likely_local_optima"}, {"score": 0.0026384167183586015, "phrase": "multimodal_benchmark_functions"}, {"score": 0.0025806490053534316, "phrase": "parameter_adaptation"}, {"score": 0.0025578967205807843, "phrase": "elitist_learning"}, {"score": 0.0023307492812556204, "phrase": "global_optimality"}, {"score": 0.0023101951336207955, "phrase": "solution_accuracy"}, {"score": 0.002279702500235741, "phrase": "algorithm_reliability"}, {"score": 0.002123730137917387, "phrase": "additional_design"}, {"score": 0.0021049977753042253, "phrase": "implementation_complexity"}], "paper_keywords": ["Adaptive particle swarm optimization (APSO)", " evolutionary computation", " global optimization", " particle swarm optimization (PSO)"], "paper_abstract": "An adaptive particle swarm optimization (APSO) that features better search efficiency than classical particle swarm optimization (PSO) is presented. More importantly, it can perform a global search over the entire search space with faster convergence speed. The APSO consists of two main steps. First, by evaluating the population distribution and particle fitness, a real-time evolutionary state estimation procedure is performed to identify one of the following four defined evolutionary states, including exploration, exploitation, convergence, and jumping out in each generation. It enables the automatic control of inertia weight, acceleration coefficients, and other algorithmic parameters at run time to improve the search efficiency and convergence speed. Then, an elitist learning strategy is performed when the evolutionary state is classified as convergence state. The strategy will act on the globally best particle to jump out of the likely local optima. The APSO has comprehensively been evaluated on 12 unimodal and multimodal benchmark functions. The effects of parameter adaptation and elitist learning will be studied. Results show that APSO substantially enhances the performance of the PSO paradigm in terms of convergence speed, global optimality, solution accuracy, and algorithm reliability. As APSO introduces two new parameters to the PSO paradigm only, it does not introduce an additional design or implementation complexity.", "paper_title": "Adaptive Particle Swarm Optimization", "paper_id": "WOS:000270143800003"}