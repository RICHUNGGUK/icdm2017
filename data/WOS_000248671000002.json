{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "full_mu-calculus"}, {"score": 0.004650896226390719, "phrase": "novel_game-based_approach"}, {"score": 0.004492406361795448, "phrase": "full_v-calculus"}, {"score": 0.004314285113050873, "phrase": "novel_notion"}, {"score": 0.004264697351852424, "phrase": "non-losing_strategy"}, {"score": 0.004071957673937727, "phrase": "previous_works"}, {"score": 0.0038431888954930083, "phrase": "direct_algorithm"}, {"score": 0.00265373679629359, "phrase": "corresponding_non-losing_strategies"}, {"score": 0.0022176487309947266, "phrase": "newly_developed_such_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": [""], "paper_abstract": "This work presents a novel game-based approach to abstraction- refinement for the full V-calculus, interpreted over 3-valued semantics. A novel notion of non-losing strategy is introduced and exploited for refinement. Previous works on refinement in the context of 3-valued semantics require a direct algorithm for solving a 3-valued model checking game. This was necessary in order to have the information needed for refinement available on one game board. In contrast, while still considering a 3-valued model checking game, here we reduce the problem of solving the game to solving two 2-valued model checking (parity) games. In case the result is indefinite (don ' t know), the corresponding non-losing strategies, when combined, hold all the information needed for refinement. This approach is beneficial since it can use any solver for 2-valued parity games. Thus, it can take advantage of newly developed such algorithms with improved complexity. (c) 2007 Elsevier Inc. All rights reserved.", "paper_title": "When not losing is better than winning: Abstraction and refinement for the full mu-calculus", "paper_id": "WOS:000248671000002"}