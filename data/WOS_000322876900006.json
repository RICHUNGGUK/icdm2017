{"auto_keywords": [{"score": 0.04849105041601803, "phrase": "model-based_cluster_analysis"}, {"score": 0.042953630786438136, "phrase": "component-specific_variance_matrices"}, {"score": 0.00481495049065317, "phrase": "conditional_independence"}, {"score": 0.004774530554776604, "phrase": "parsimonious_model-based_gaussian_clustering"}, {"score": 0.0045581828632009795, "phrase": "gaussian_components"}, {"score": 0.004500891637057374, "phrase": "important_class"}, {"score": 0.004463096299091981, "phrase": "statistical_models"}, {"score": 0.004351595642056769, "phrase": "quantitative_variables"}, {"score": 0.004207230913063179, "phrase": "novel_models"}, {"score": 0.004016485454498076, "phrase": "gaussian_parsimonious_clustering_models"}, {"score": 0.003932654396285872, "phrase": "proposed_models"}, {"score": 0.0035240305920962766, "phrase": "block_diagonal_structure"}, {"score": 0.0031710903727066313, "phrase": "gaussian_mixture_models"}, {"score": 0.003078740573398959, "phrase": "identifiability_conditions"}, {"score": 0.003014422649429416, "phrase": "model_parameters"}, {"score": 0.002951444412262927, "phrase": "maximum_likelihood_method"}, {"score": 0.0029020077365708966, "phrase": "expectation-maximization_algorithm"}, {"score": 0.0028654728453890426, "phrase": "bayesian_information_criterion"}, {"score": 0.002735392281320413, "phrase": "conditionally_independent_groups"}, {"score": 0.0025892330566358503, "phrase": "regularity_conditions"}, {"score": 0.002482126086922683, "phrase": "different_partitions"}, {"score": 0.0024097920845706795, "phrase": "hierarchical_algorithm"}, {"score": 0.0023594160789762227, "phrase": "wide_class"}, {"score": 0.0023395610923736595, "phrase": "parsimonious_gaussian_models"}, {"score": 0.002271372252250557, "phrase": "component-variance_matrices"}, {"score": 0.0021682027434117095, "phrase": "proposed_methodology"}, {"score": 0.0021049977753042253, "phrase": "real_datasets"}], "paper_keywords": ["Bayesian information criterion", " Conditional independence", " EM algorithm", " Gaussian mixture model", " Spectral decomposition"], "paper_abstract": "In the framework of model-based cluster analysis, finite mixtures of Gaussian components represent an important class of statistical models widely employed for dealing with quantitative variables. Within this class, we propose novel models in which constraints on the component-specific variance matrices allow us to define Gaussian parsimonious clustering models. Specifically, the proposed models are obtained by assuming that the variables can be partitioned into groups resulting to be conditionally independent within components, thus producing component-specific variance matrices with a block diagonal structure. This approach allows us to extend the methods for model-based cluster analysis and to make them more flexible and versatile. In this paper, Gaussian mixture models are studied under the above mentioned assumption. Identifiability conditions are proved and the model parameters are estimated through the maximum likelihood method by using the Expectation-Maximization algorithm. The Bayesian information criterion is proposed for selecting the partition of the variables into conditionally independent groups. The consistency of the use of this criterion is proved under regularity conditions. In order to examine and compare models with different partitions of the set of variables a hierarchical algorithm is suggested. A wide class of parsimonious Gaussian models is also presented by parameterizing the component-variance matrices according to their spectral decomposition. The effectiveness and usefulness of the proposed methodology are illustrated with two examples based on real datasets.", "paper_title": "Using conditional independence for parsimonious model-based Gaussian clustering", "paper_id": "WOS:000322876900006"}