{"auto_keywords": [{"score": 0.032996284423263945, "phrase": "conservationist_agent"}, {"score": 0.00481495049065317, "phrase": "reinforcement_learning_agent-based_model"}, {"score": 0.004776853267973129, "phrase": "multi-stakeholder_forest_management"}, {"score": 0.0044826811976193485, "phrase": "forest_management_research"}, {"score": 0.004377077848734575, "phrase": "multiple_stakeholders"}, {"score": 0.004223299391912042, "phrase": "optimization_procedures"}, {"score": 0.00405873677211836, "phrase": "agent-based_models"}, {"score": 0.003559675269411366, "phrase": "agent-based_model"}, {"score": 0.003517458289610994, "phrase": "optimal_forest_harvesting_strategies"}, {"score": 0.0034482025128821548, "phrase": "reinforcement_learning"}, {"score": 0.0033668870709083884, "phrase": "simulation_model"}, {"score": 0.0033005860945173136, "phrase": "forest_company_agents_harvest_trees"}, {"score": 0.0030481444896915504, "phrase": "species_habitat"}, {"score": 0.0030239842475439814, "phrase": "rl_algorithms"}, {"score": 0.00295264307195965, "phrase": "forest_company_agents"}, {"score": 0.002694375425481759, "phrase": "generated_solutions"}, {"score": 0.0026307897899760383, "phrase": "system_constraints"}, {"score": 0.002578946584040053, "phrase": "observed_agent_behavior"}, {"score": 0.002558495760339272, "phrase": "learning_functions"}, {"score": 0.002508073621696602, "phrase": "ri._algorithms"}, {"score": 0.002478297391121455, "phrase": "obtained_results"}, {"score": 0.0024488738006005133, "phrase": "non-linear_relationship"}, {"score": 0.0022345720876241044, "phrase": "relative_quality"}, {"score": 0.0022168460543913787, "phrase": "forest_areas"}, {"score": 0.0021559025985688255, "phrase": "different_optimal_solutions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Reinforcement learning", " Agent-based modeling", " Optimization", " Forest management"], "paper_abstract": "Spatial optimization and agent-based modeling present two distinct approaches that have been implemented in forest management research for incorporating the objectives of multiple stakeholders. However, challenges arise in their implementation as optimization procedures do not consider the interactions amongst stakeholders, and agent-based models generate results from which it is difficult to determine if objectives have been successfully achieved. The purpose of this research is to overcome these limitations by improving the ability of an agent-based model to achieve optimal forest harvesting strategies through the integration of reinforcement learning (RL). A simulation model is developed in which forest company agents harvest trees in order to maximize their profits while considering the potential to cooperate with a conservationist agent whose objectives are based on protecting species habitat. RL algorithms are implemented to allow the forest company agents and the conservationist agent to learn where harvesting should occur in order to achieve their objectives. The model is validated by determining if generated solutions can be considered optimal given system constraints, and by comparing observed agent behavior against learning functions as defined by the RI. algorithms. The obtained results demonstrate a non-linear relationship between different levels of cooperation and the ability of agents to achieve their objectives. The model also provides outputs that depict the relative quality of forest areas and the tradeoffs between objectives for different optimal solutions. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Simulation and validation of a reinforcement learning agent-based model for multi-stakeholder forest management", "paper_id": "WOS:000277220800007"}