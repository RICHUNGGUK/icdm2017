{"auto_keywords": [{"score": 0.04160367592541749, "phrase": "random_sampling"}, {"score": 0.015719716506582538, "phrase": "subspace_face_recognition"}, {"score": 0.01085387402958517, "phrase": "lda_classifiers"}, {"score": 0.004567596860086148, "phrase": "training_sample"}, {"score": 0.004429191773525288, "phrase": "high_dimensional_feature_vector"}, {"score": 0.004220086640742953, "phrase": "subspace_dimension"}, {"score": 0.0041102032028337366, "phrase": "single_optimal_subspace"}, {"score": 0.004020813632357377, "phrase": "ensemble_learning_framework"}, {"score": 0.0038647641000798135, "phrase": "classification_system"}, {"score": 0.0034168317227203206, "phrase": "small_sample_size_problem"}, {"score": 0.003170520716404193, "phrase": "useful_discriminative_information"}, {"score": 0.0031151864044353245, "phrase": "different_overfitting_problems"}, {"score": 0.002994178996584381, "phrase": "random_subspace"}, {"score": 0.0028526276660691525, "phrase": "feature_vectors"}, {"score": 0.0028276174348291923, "phrase": "training_samples"}, {"score": 0.0027782510491938315, "phrase": "fisherface_and_n-lda_classifiers"}, {"score": 0.002693919110230191, "phrase": "complementary_classifiers"}, {"score": 0.0026352496813713292, "phrase": "fusion_rule"}, {"score": 0.0025665261770229757, "phrase": "discriminative_information"}, {"score": 0.002434396049547248, "phrase": "parameter_selection"}, {"score": 0.002339771435910601, "phrase": "optimal_parameters"}, {"score": 0.002248816575548875, "phrase": "developed_random_sampling_framework"}, {"score": 0.0021998194157393353, "phrase": "multiple_features"}, {"score": 0.0021709339252206825, "phrase": "robust_random_sampling_face_recognition_system"}, {"score": 0.0021049977753042253, "phrase": "gabor_responses"}], "paper_keywords": ["random subspace method", " bagging", " LDA", " face recognition", " subspace analysis"], "paper_abstract": "Subspace face recognition often suffers from two problems: (1) the training sample set is small compared with the high dimensional feature vector; (2) the performance is sensitive to the subspace dimension. Instead of pursuing a single optimal subspace, we develop an ensemble learning framework based on random sampling on all three key components of a classification system: the feature space, training samples, and subspace parameters. Fisherface and Null Space LDA (N-LDA) are two conventional approaches to address the small sample size problem. But in many cases, these LDA classifiers are overfitted to the training set and discard some useful discriminative information. By analyzing different overfitting problems for the two kinds of LDA classifiers, we use random subspace and bagging to improve them respectively. By random sampling on feature vectors and training samples, multiple stabilized Fisherface and N-LDA classifiers are constructed and the two groups of complementary classifiers are integrated using a fusion rule, so nearly all the discriminative information is preserved. In addition, we further apply random sampling on parameter selection in order to overcome the difficulty of selecting optimal parameters in our algorithms. Then, we use the developed random sampling framework for the integration of multiple features. A robust random sampling face recognition system integrating shape, texture, and Gabor responses is finally constructed.", "paper_title": "Random sampling for subspace face recognition", "paper_id": "WOS:000239828100007"}