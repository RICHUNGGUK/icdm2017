{"auto_keywords": [{"score": 0.04845849110410783, "phrase": "mobile_communication_networks"}, {"score": 0.00481495049065317, "phrase": "dynamic_model-based_reinforcement_learning_schemes"}, {"score": 0.003970439654470374, "phrase": "handoff_failures"}, {"score": 0.003889206369317587, "phrase": "efficient_use"}, {"score": 0.003809628721278519, "phrase": "wireless_network_resources"}, {"score": 0.003731673223879279, "phrase": "performance_measure"}, {"score": 0.0036052633308076933, "phrase": "weighted_linear_function"}, {"score": 0.003531474887552889, "phrase": "blocking_probability"}, {"score": 0.003483120583663528, "phrase": "new_connection_requests"}, {"score": 0.0034118234596993836, "phrase": "handoff_failure_probability"}, {"score": 0.0031845067058084583, "phrase": "semi-markov_decision_process"}, {"score": 0.0031193028729331667, "phrase": "average_cost_criterion"}, {"score": 0.0030554300179552415, "phrase": "simulation-based_learning_algorithm"}, {"score": 0.002931569771634119, "phrase": "optimal_control_policy"}, {"score": 0.0028715299874549245, "phrase": "proposed_schemes"}, {"score": 0.0027741761880779535, "phrase": "dynamic_model"}, {"score": 0.0026616868981501006, "phrase": "control_policy"}, {"score": 0.002571429085596686, "phrase": "direct_interactions"}, {"score": 0.0024842242921857705, "phrase": "extensive_simulations"}, {"score": 0.0022399174232611853, "phrase": "traffic_conditions"}, {"score": 0.0021940118003312397, "phrase": "well-known_policies"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Resource management", " Handoff prioritization", " Cellular systems", " Mobile communication networks", " Reinforcement learning", " Semi-Markov decision process"], "paper_abstract": "This paper presents and compares three model-based reinforcement learning schemes for admission policy with handoff prioritization in mobile communication networks. The goal is to reduce the handoff failures while making efficient use of the wireless network resources. A performance measure is formed as a weighted linear function of the blocking probability of new connection requests and the handoff failure probability. Then, the problem is formulated as a semi-Markov decision process with an average cost criterion and a simulation-based learning algorithm is developed to approximate the optimal control policy. The proposed schemes are driven by a dynamic model estimated simultaneously while learning the control policy using samples generated from direct interactions with the network. Extensive simulations are provided to assess and compare their effectiveness of the algorithm under a variety of traffic conditions with some well-known policies. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Comparing a class of dynamic model-based reinforcement learning schemes for handoff prioritization in mobile communication networks", "paper_id": "WOS:000289047700092"}