{"auto_keywords": [{"score": 0.04596854881204733, "phrase": "tm"}, {"score": 0.045401996008669857, "phrase": "target_words"}, {"score": 0.04280239545514346, "phrase": "word-keeping_recommendation"}, {"score": 0.026908974405717698, "phrase": "mt-based_approaches"}, {"score": 0.00481495049065317, "phrase": "machine_translation"}, {"score": 0.004778145748896516, "phrase": "target-language_edit_hints"}, {"score": 0.004693353221764812, "phrase": "translation_memories"}, {"score": 0.0045982799222088235, "phrase": "general-purpose_machine_translation"}, {"score": 0.004493612177147829, "phrase": "computer-aided_translation"}, {"score": 0.004425154757824971, "phrase": "translation_memory"}, {"score": 0.004313358765705179, "phrase": "translation_proposals"}, {"score": 0.004066961972724756, "phrase": "mt"}, {"score": 0.004015069420294224, "phrase": "black_box"}, {"score": 0.0038936063605442594, "phrase": "translation_units"}, {"score": 0.003680352247048994, "phrase": "variable_length"}, {"score": 0.0036150713461818368, "phrase": "tl"}, {"score": 0.0035874095013132394, "phrase": "sl"}, {"score": 0.003541664079520869, "phrase": "bilingual_subsegments"}, {"score": 0.0034787373417055423, "phrase": "sl_segment"}, {"score": 0.003452135107284818, "phrase": "tu"}, {"score": 0.003288130735513798, "phrase": "binary_classifier"}, {"score": 0.0031319153105988217, "phrase": "mt_results"}, {"score": 0.002990752951987369, "phrase": "word-keeping_recommendation_system"}, {"score": 0.0029076286259980253, "phrase": "cat_system"}, {"score": 0.0026993603503504132, "phrase": "different_domains"}, {"score": 0.0026108940373486596, "phrase": "previous_works"}, {"score": 0.002584259877640948, "phrase": "statistical_word_alignment"}, {"score": 0.0023868275250400347, "phrase": "alignment-based_approach"}, {"score": 0.002350389897247675, "phrase": "out-of-domain_tms"}, {"score": 0.0022791711415834502, "phrase": "mt-based_recommender"}, {"score": 0.0022559132878182155, "phrase": "language_pair"}, {"score": 0.0022443733130746305, "phrase": "mt_system"}, {"score": 0.0021931680053401963, "phrase": "high_degree"}, {"score": 0.0021652260317080244, "phrase": "recommendation_models"}, {"score": 0.0021049977753042253, "phrase": "language_pairs"}], "paper_keywords": [""], "paper_abstract": "This paper explores the use of general-purpose machine translation (MT) in assisting the users of computer-aided translation (CAT) systems based on translation memory (TM) to identify the target words in the translation proposals that need to be changed (either replaced or removed) or kept unedited, a task we term as word-keeping recommendation. MT is used as a black box to align source and target sub-segments on the fly in the translation units (TUs) suggested to the user. Source-language (SL) and target-language (TL) segments in the matching TUs are segmented into overlapping sub-segments of variable length and machine-translated into the TL and the SL, respectively. The bilingual subsegments obtained and the matching between the SL segment in the TU and the segment to be translated are employed to build the features that are then used by a binary classifier to determine the target words to be changed and those to be kept unedited. In this approach, MT results are never presented to the translator. Two approaches are presented in this work: one using a word-keeping recommendation system which can be trained on the TM used with the CAT system, and a more basic approach which does not require any training. Experiments are conducted by simulating the translation of texts in several language pairs with corpora belonging to different domains and using three different MT systems. We compare the performance obtained to that of previous works that have used statistical word alignment for word-keeping recommendation, and show that the MT-based approaches presented in this paper are more accurate in most scenarios. In particular, our results confirm that the MT-based approaches are better than the alignment-based approach when using models trained on out-of-domain TMs. Additional experiments were also performed to check how dependent the MT-based recommender is on the language pair and MT system used for training. These experiments confirm a high degree of reusability of the recommendation models across various MT systems, but a low level of reusability across language pairs.", "paper_title": "Using Machine Translation to Provide Target-Language Edit Hints in Computer Aided Translation Based on Translation Memories", "paper_id": "WOS:000365176400005"}