{"auto_keywords": [{"score": 0.03856990221719121, "phrase": "biased_testimonies"}, {"score": 0.015610312655706086, "phrase": "reinforcement_learning"}, {"score": 0.011432197033582893, "phrase": "key_parameters"}, {"score": 0.00481495049065317, "phrase": "trust_opinions"}, {"score": 0.0047306971679760175, "phrase": "open_online_communities"}, {"score": 0.004330941610682453, "phrase": "potential_interaction_partner"}, {"score": 0.004255121395629569, "phrase": "participant's_well-being"}, {"score": 0.004136548839735555, "phrase": "research_community"}, {"score": 0.0041074234667687875, "phrase": "third-party_testimony_sharing"}, {"score": 0.003909185474360582, "phrase": "potential_interaction_partners"}, {"score": 0.0036167509502276294, "phrase": "participant's_long_term"}, {"score": 0.0035533891890176823, "phrase": "existing_trust_computational_models"}, {"score": 0.0035159043158639633, "phrase": "complicated_manual_tuning"}, {"score": 0.0033937776228549557, "phrase": "subjective_judgments"}, {"score": 0.003150900886669123, "phrase": "adaptive_trust_evidence_aggregation_model"}, {"score": 0.0030521898646210413, "phrase": "proposed_method"}, {"score": 0.002988101395789399, "phrase": "credible_witnesses"}, {"score": 0.0028944757265206332, "phrase": "direct_and_indirect_trust_evidence_sources"}, {"score": 0.0028037753646260937, "phrase": "trusting_entity"}, {"score": 0.002784007794229784, "phrase": "extensive_simulations"}, {"score": 0.002735194789581153, "phrase": "act_approach"}, {"score": 0.0027063176464371115, "phrase": "existing_approaches"}, {"score": 0.0026494723416072316, "phrase": "adverse_effect"}, {"score": 0.0025664295665392203, "phrase": "proposed_accountability_mechanism"}, {"score": 0.0025395053572628353, "phrase": "act"}, {"score": 0.0024597305738431226, "phrase": "individual_witnesses"}, {"score": 0.0024251568696803177, "phrase": "trust_evidence"}, {"score": 0.002391067964886602, "phrase": "future_evidence_aggregation_decisions"}, {"score": 0.0023491282852109757, "phrase": "human_intervention"}, {"score": 0.0022997683233147125, "phrase": "proposed_model"}, {"score": 0.002259426425685765, "phrase": "service_providers"}, {"score": 0.0021501863832966966, "phrase": "service_consumers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Trust", " Reputation", " Credibility", " Collusion"], "paper_abstract": "In open online communities such as e-commerce, participants need to rely on services provided by others in order to thrive. Accurately estimating the trustworthiness of a potential interaction partner is vital to a participant's well-being. It is generally recognized in the research community that third-party testimony sharing is an effective way for participants to gain knowledge about the trustworthiness of potential interaction partners without having to incur the risk of actually interacting with them. However, the presence of biased testimonies adversely affects a participant's long term well-being. Existing trust computational models often require complicated manual tuning of key parameters to combat biased testimonies. Such an approach heavily involves subjective judgments and adapts poorly to changes in an environment In this study, we propose the Actor Critic Trust (ACT) model, which is an adaptive trust evidence aggregation model based on the principles of reinforcement learning. The proposed method dynamically adjusts the selection of credible witnesses as well as the key parameters associated with the direct and indirect trust evidence sources based on the observed benefits received by the trusting entity. Extensive simulations have shown that the ACT approach significantly outperforms existing approaches in terms of mitigating the adverse effect of biased testimonies. Such a performance is due to the proposed accountability mechanism that enables ACT to attribute the outcome of an interaction to individual witnesses and sources of trust evidence, and adjust future evidence aggregation decisions without the need for human intervention. The advantage of the proposed model is particularly significant when service providers and witnesses strategically collude to improve their chances of being selected for interaction by service consumers. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Filtering trust opinions through reinforcement learning", "paper_id": "WOS:000344204800010"}