{"auto_keywords": [{"score": 0.03337015757271618, "phrase": "neural_network"}, {"score": 0.00481495049065317, "phrase": "predicted_time-frequency_masks"}, {"score": 0.004716520738331953, "phrase": "speech_separation_algorithms"}, {"score": 0.004620093797504386, "phrase": "difficult_task"}, {"score": 0.004563182153397349, "phrase": "high_degree"}, {"score": 0.00446987606516801, "phrase": "unwanted_artifacts"}, {"score": 0.0041666157975446564, "phrase": "unwanted_components"}, {"score": 0.004115267130977749, "phrase": "practical_difficulty"}, {"score": 0.004047781270412204, "phrase": "mask_estimation"}, {"score": 0.0039649719120779066, "phrase": "efficient_masks"}, {"score": 0.003916098498242888, "phrase": "separation_performance"}, {"score": 0.003835972725191194, "phrase": "unwanted_musical_noise_artifacts"}, {"score": 0.0037886833451021723, "phrase": "separated_signal"}, {"score": 0.00371115485111022, "phrase": "perceptual_quality"}, {"score": 0.0036052633308076933, "phrase": "microphone_arrays"}, {"score": 0.0034879261743468574, "phrase": "distant_speech"}, {"score": 0.0034024277222012597, "phrase": "feed-forward_neural_network"}, {"score": 0.003360464999544279, "phrase": "microphone_array's_spatial_features"}, {"score": 0.0033190180867511605, "phrase": "t-f_mask"}, {"score": 0.003291819583655508, "phrase": "wiener"}, {"score": 0.0032109670662222416, "phrase": "desired_mask"}, {"score": 0.003132236287543072, "phrase": "speech_examples"}, {"score": 0.0031064226956732497, "phrase": "simulated_setting"}, {"score": 0.0030680994147125364, "phrase": "t-f_masks"}, {"score": 0.0029437270961011077, "phrase": "enhanced_separation_mask"}, {"score": 0.0028010985923790036, "phrase": "final_mask"}, {"score": 0.0026107601878587816, "phrase": "separated_speech"}, {"score": 0.00255727386763536, "phrase": "recorded_speech"}, {"score": 0.0025361866386341796, "phrase": "distant_talkers"}, {"score": 0.0024232694434408093, "phrase": "instrumental_measure"}, {"score": 0.0023346234464901978, "phrase": "complex-valued_non-negative_matrix_factorization"}, {"score": 0.0022399174232611853, "phrase": "conventional_beamforming_methods"}, {"score": 0.002184943946549964, "phrase": "minimum_variance_distortionless_response"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Speech separation", " Microphone arrays", " Neural networks", " Beamforming", " Time-frequency masking"], "paper_abstract": "Speech separation algorithms are faced with a difficult task of producing high degree of separation without containing unwanted artifacts. The time frequency (T-F) masking technique applies a real-valued (or binary) mask on top of the signal's spectrum to filter out unwanted components. The practical difficulty lies in the mask estimation. Often, using efficient masks engineered for separation performance leads to presence of unwanted musical noise artifacts in the separated signal. This lowers the perceptual quality and intelligibility of the output. Microphone arrays have been long studied for processing of distant speech. This work uses a feed-forward neural network for mapping microphone array's spatial features into a T-F mask. Wiener filter is used as a desired mask for training the neural network using speech examples in simulated setting. The T-F masks predicted by the neural network are combined to obtain an enhanced separation mask that exploits the information regarding interference between all sources. The final mask is applied to the delay-and-sum beam-former (DSB) output. The algorithm's objective separation capability in conjunction with the separated speech intelligibility is tested with recorded speech from distant talkers in two rooms from two distances. The results show improvement in instrumental measure for intelligibility and frequency-weighted SNR over complex-valued non-negative matrix factorization (CNMF) source separation approach, spatial sound source separation, and conventional beamforming methods such as the DSB and minimum variance distortionless response (MVDR). (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Distant speech separation using predicted time-frequency masks from spatial features", "paper_id": "WOS:000352245800008"}