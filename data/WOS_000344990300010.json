{"auto_keywords": [{"score": 0.03494093206132192, "phrase": "iaware"}, {"score": 0.015719716506582538, "phrase": "live_migration"}, {"score": 0.0047732596509542135, "phrase": "virtual_machines_interference-aware"}, {"score": 0.004670597652149685, "phrase": "large-scale_datacenters"}, {"score": 0.004530552828603269, "phrase": "cloud_services"}, {"score": 0.004394688617163029, "phrase": "different_virtual_machines"}, {"score": 0.004244375827831527, "phrase": "shared_physical_servers"}, {"score": 0.004189337956225294, "phrase": "recent_studies"}, {"score": 0.0038906171474520756, "phrase": "different_servers"}, {"score": 0.003757480190200645, "phrase": "incurred_performance_interference"}, {"score": 0.003504670673093149, "phrase": "potential_violations"}, {"score": 0.0034441740127637336, "phrase": "sla"}, {"score": 0.003384695931421288, "phrase": "cloud_applications"}, {"score": 0.0032123932486671646, "phrase": "vm"}, {"score": 0.0030888830649190282, "phrase": "essential_relationships"}, {"score": 0.003062091606343783, "phrase": "vm_performance_interference"}, {"score": 0.00303553181618577, "phrase": "key_factors"}, {"score": 0.002957222630196853, "phrase": "realistic_experiments"}, {"score": 0.002931569771634119, "phrase": "benchmark_workloads"}, {"score": 0.002893505913503472, "phrase": "xen_virtualized_cluster_platform"}, {"score": 0.002770150086489194, "phrase": "co-location_interference"}, {"score": 0.002686935113435742, "phrase": "simple_multi-resource_demand-supply_model"}, {"score": 0.002629026692001082, "phrase": "complementary_large-scale_simulations"}, {"score": 0.0025611773887867255, "phrase": "performance_gain"}, {"score": 0.0025389513338018414, "phrase": "runtime_overhead"}, {"score": 0.0024519545383399773, "phrase": "network_throughput"}, {"score": 0.0024306740161601625, "phrase": "cpu_consumption"}, {"score": 0.002347378595930709, "phrase": "traditional_interference-unaware_vm_migration_approaches"}, {"score": 0.0022084059770026416, "phrase": "existing_vm_scheduling"}, {"score": 0.002151388538895855, "phrase": "complementary_manner"}, {"score": 0.0021049977753042253, "phrase": "load_balancing"}], "paper_keywords": ["Cloud computing", " virtualization", " live migration", " performance interference"], "paper_abstract": "Large-scale datacenters have been widely used to host cloud services, which are typically allocated to different virtual machines (VMs) through resource multiplexing across shared physical servers. Although recent studies have primarily focused on harnessing live migration of VMs to achieve load balancing and power saving among different servers, there has been little attention on the incurred performance interference and cost on both source and destination servers during and after such VM migration. To avoid potential violations of service-level-agreement (SLA) demanded by cloud applications, this paper proposes iAware, a lightweight interference-aware VM live migration strategy. It empirically captures the essential relationships between VM performance interference and key factors that are practically accessible through realistic experiments of benchmark workloads on a Xen virtualized cluster platform. iAware jointly estimates and minimizes both migration and co-location interference among VMs, by designing a simple multi-resource demand-supply model. Extensive experiments and complementary large-scale simulations are conducted to validate the performance gain and runtime overhead of iAware in terms of I/O and network throughput, CPU consumption, and scalability, compared to the traditional interference-unaware VM migration approaches. Moreover, we demonstrate that iAware is flexible enough to cooperate with existing VM scheduling or consolidation policies in a complementary manner, such that the load balancing or power saving can still be achieved without sacrificing performance.", "paper_title": "iAware: Making Live Migration of Virtual Machines Interference-Aware in the Cloud", "paper_id": "WOS:000344990300010"}