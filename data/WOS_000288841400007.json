{"auto_keywords": [{"score": 0.048539652036902976, "phrase": "infinite_size"}, {"score": 0.04559556617638774, "phrase": "asymptotic_prediction"}, {"score": 0.004817182060377787, "phrase": "inference"}, {"score": 0.004426882270402403, "phrase": "statistical_inference"}, {"score": 0.004324723240308028, "phrase": "parallel_classification_ensembles"}, {"score": 0.0040133278382101885, "phrase": "individual_classifiers"}, {"score": 0.003939033374807842, "phrase": "independent_executions"}, {"score": 0.003884212965525665, "phrase": "randomized_learning_algorithm"}, {"score": 0.00379452936798156, "phrase": "final_ensemble_prediction"}, {"score": 0.0037242701420971062, "phrase": "majority_voting"}, {"score": 0.0036553070575015344, "phrase": "unlabeled_test_instance"}, {"score": 0.0033919477901198716, "phrase": "individual_predictions"}, {"score": 0.003329117824699891, "phrase": "bayes'_theorem"}, {"score": 0.0030891871245908665, "phrase": "current_ensemble"}, {"score": 0.002989714021608139, "phrase": "corresponding_ensemble"}, {"score": 0.0028664985822266344, "phrase": "voting_process"}, {"score": 0.0026722904884984348, "phrase": "empirical_investigation"}, {"score": 0.0025741370320813968, "phrase": "test_instances"}, {"score": 0.002456486927713543, "phrase": "infinite_ensemble_prediction"}, {"score": 0.002422249273477746, "phrase": "high_degree"}, {"score": 0.002289993730291136, "phrase": "generalization_error"}, {"score": 0.0022580713471027996, "phrase": "finite_ensemble"}, {"score": 0.002226592967032469, "phrase": "infinite_ensemble_limit"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Classification ensembles", " Classification trees", " Bayesian inference", " Infinite ensembles"], "paper_abstract": "In this paper we introduce a framework for making statistical inference on the asymptotic prediction of parallel classification ensembles. The validity of the analysis is fairly general. It only requires that the individual classifiers are generated in independent executions of some randomized learning algorithm, and that the final ensemble prediction is made via majority voting. Given an unlabeled test instance, the predictions of the classifiers in the ensemble are obtained sequentially. As the individual predictions become known, Bayes' theorem is used to update an estimate of the probability that the class predicted by the current ensemble coincides with the classification of the corresponding ensemble of infinite size. Using this estimate, the voting process can be halted when the confidence on the asymptotic prediction is sufficiently high. An empirical investigation in several benchmark classification problems shows that most of the test instances require querying only a small number of classifiers to converge to the infinite ensemble prediction with a high degree of confidence. For these instances, the difference between the generalization error of the finite ensemble and the infinite ensemble limit is very small, often negligible. (c) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Inference on the prediction of ensembles of infinite size", "paper_id": "WOS:000288841400007"}