{"auto_keywords": [{"score": 0.04381934363111791, "phrase": "whole_face"}, {"score": 0.00481495049065317, "phrase": "facial_component_classifiers"}, {"score": 0.004596295252559861, "phrase": "novel_gender_classification_framework"}, {"score": 0.004410248125081398, "phrase": "external_information"}, {"score": 0.004364919932563366, "phrase": "i.e._hair"}, {"score": 0.004102528738941734, "phrase": "five_facial_components"}, {"score": 0.0037965243835456214, "phrase": "feature_extraction_methods"}, {"score": 0.0035497797026638033, "phrase": "previous_work"}, {"score": 0.003301899275278983, "phrase": "single_support_vector_machine_classifier"}, {"score": 0.0029164434911787187, "phrase": "major_contributions"}, {"score": 0.002769395841379498, "phrase": "gender_discriminative_ability"}, {"score": 0.002740885774408238, "phrase": "clothing_information"}, {"score": 0.0026570998719084153, "phrase": "facial_components"}, {"score": 0.0025625729433234644, "phrase": "higher_robustness"}, {"score": 0.0024333239726872604, "phrase": "hair_and_clothing_information"}, {"score": 0.0023958326775913165, "phrase": "gender_classification"}, {"score": 0.0023711591828229736, "phrase": "experimental_results"}, {"score": 0.002310578855290687, "phrase": "classification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Gender classification", " Facial components", " Clothing feature", " Hair feature", " Classifier combination", " Local binary pattern", " Support vector machine"], "paper_abstract": "In this paper, we propose a novel gender classification framework, which utilizes not only facial features, but also external information, i.e. hair and clothing. Instead of using the whole face, we consider five facial components: forehead, eyes, nose, mouth and chin. We also design feature extraction methods for hair and clothing; these features have seldom been used in previous work because of their large variability. For each type of feature, we train a single support vector machine classifier with probabilistic output. The outputs of these classifiers are combined using various strategies, namely fuzzy integral, maximal, sum, voting, and product rule. The major contributions of this paper are (1) investigating the gender discriminative ability of clothing information; (2) using facial components instead of the whole face to obtain higher robustness for occlusions and noise; (3) exploiting hair and clothing information to facilitate gender classification. Experimental results show that our proposed framework improves classification accuracy, even when images contain occlusions, noise, and illumination changes. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Gender classification by combining clothing, hair and facial component classifiers", "paper_id": "WOS:000298070500004"}