{"auto_keywords": [{"score": 0.03734631623252398, "phrase": "sparse_codes"}, {"score": 0.010612387000973441, "phrase": "hierarchical_group_sparsity"}, {"score": 0.010447122242144865, "phrase": "adaptive_dictionaries"}, {"score": 0.00468991337957911, "phrase": "sparse_coding"}, {"score": 0.004544127927346964, "phrase": "latest_research"}, {"score": 0.004426092397211699, "phrase": "promising_way"}, {"score": 0.004288472456976113, "phrase": "sparse_representation"}, {"score": 0.004155113657645735, "phrase": "discriminative_dictionaries"}, {"score": 0.004089991141220082, "phrase": "reconstructive_ones"}, {"score": 0.004025885154716127, "phrase": "significantly_improved_performance"}, {"score": 0.00398370478688858, "phrase": "pattern_recognition"}, {"score": 0.003839510177926892, "phrase": "powerful_method"}, {"score": 0.0037594599958631404, "phrase": "discriminative_dictionary_learning"}, {"score": 0.0036810726176482278, "phrase": "dictionary_learning_process"}, {"score": 0.003437387719239532, "phrase": "linear_prediction_error"}, {"score": 0.0032954888655173666, "phrase": "joint_within-class_collaborative_hierarchical_sparsity"}, {"score": 0.0031262984171100856, "phrase": "labeled_data"}, {"score": 0.0029346624184926305, "phrase": "group_level"}, {"score": 0.0029038817737006405, "phrase": "singleton_level"}, {"score": 0.002740253546178098, "phrase": "joint_dictionary"}, {"score": 0.002711506442590442, "phrase": "classifier_learning"}, {"score": 0.0025586903829811296, "phrase": "efficient_alternating_iterative_scheme"}, {"score": 0.0024789887640568093, "phrase": "proposed_model"}, {"score": 0.0023640560785711923, "phrase": "object_recognition"}, {"score": 0.002339246282204109, "phrase": "scene_classification"}, {"score": 0.0023146962503449186, "phrase": "experimental_results"}, {"score": 0.002266364679369248, "phrase": "excellent_performance"}, {"score": 0.0021957487795963666, "phrase": "existing_discriminative_dictionary"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Discriminative dictionary learning", " Structured sparse coding", " Group sparsity", " Image classification"], "paper_abstract": "Learning adaptive dictionaries for sparse coding has been the focus of latest research as it provides a promising way to maximize the efficiency of sparse representation. In particular, learning discriminative dictionaries rather than reconstructive ones has demonstrated significantly improved performance in pattern recognition. In this paper, a powerful method is proposed for discriminative dictionary learning. During the dictionary learning process, we enhance the discriminability of sparse codes by promoting hierarchical group sparsity and reducing linear prediction error on sparse codes. With the employment of joint within-class collaborative hierarchical sparsity, our method is able to learn adaptive dictionaries from labeled data for classification, which encourage coefficients to be sparse at both group level and singleton level and thus enforce the separability of sparse codes. Benefiting from joint dictionary and classifier learning, the discriminability of sparse codes is further strengthened. An efficient alternating iterative scheme is presented to solve the proposed model. We applied our method to face recognition, object recognition and scene classification. Experimental results have demonstrated the excellent performance of our method in comparison with existing discriminative dictionary learning approaches. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Discriminative structured dictionary learning with hierarchical group sparsity", "paper_id": "WOS:000356116800007"}