{"auto_keywords": [{"score": 0.03997447142565907, "phrase": "virtual_agents"}, {"score": 0.00481495049065317, "phrase": "affective_eye"}, {"score": 0.004530552828603269, "phrase": "person's_eye_movement"}, {"score": 0.004375613460102577, "phrase": "nonverbal_information"}, {"score": 0.004300133642951283, "phrase": "emotional_intent"}, {"score": 0.0038737214010638745, "phrase": "eye_behaviors"}, {"score": 0.0035507457285983268, "phrase": "au-coded_facial_expression_database_and_real-time_eye_movement_data"}, {"score": 0.0031984060035955292, "phrase": "rule-based_approach"}, {"score": 0.0023371689326096476, "phrase": "scripting_tool"}, {"score": 0.0021049977753042253, "phrase": "emotional_eye_movement"}], "paper_keywords": ["affective computing", " virtual agents", " emotional eye movement", " markup language"], "paper_abstract": "The manner of a person's eye movement conveys much about nonverbal information and emotional intent beyond speech. This paper describes work on expressing emotion through eye behaviors in virtual agents based on the parameters selected from the AU-Coded facial expression database and real-time eye movement data (pupil size, blink rate and saccade). A rule-based approach to generate primary (joyful, sad, angry, afraid, disgusted and surprise) and intermediate emotions (emotions that can be represented as the mixture of two primary emotions) utilized the MPEG4 FAPs (facial animation parameters) is introduced. Meanwhile, based on our research, a scripting tool, named EEMML (Emotional Eye Movement Markup Language) that enables authors to describe and generate emotional eye movement of virtual agents, is proposed.", "paper_title": "Generating and Describing Affective Eye Behaviors", "paper_id": "WOS:000279136500037"}