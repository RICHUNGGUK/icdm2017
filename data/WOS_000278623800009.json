{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "invariant_face_recognition"}, {"score": 0.004644451060812007, "phrase": "emergent_technology"}, {"score": 0.004588964055070299, "phrase": "better_results"}, {"score": 0.004399905285945236, "phrase": "depth_maps"}, {"score": 0.004256816146106783, "phrase": "face_recognition"}, {"score": 0.004093673695008595, "phrase": "highly_controlled_conditions"}, {"score": 0.0038431888954930083, "phrase": "surveillance_or_control_access_points"}, {"score": 0.0037069717781636194, "phrase": "recognition_process"}, {"score": 0.0036406779213379154, "phrase": "new_paradigm"}, {"score": 0.003586336325832857, "phrase": "recognition_systems"}, {"score": 0.003141675970409644, "phrase": "novel_method"}, {"score": 0.0030393807371663934, "phrase": "partial_principal_component_analysis"}, {"score": 0.0029670762930358394, "phrase": "partial_concept"}, {"score": 0.0029139757013408926, "phrase": "well_known_pca_algorithm"}, {"score": 0.0028106004823927723, "phrase": "pose_variation_scenarios"}, {"score": 0.002678433668156676, "phrase": "face_information"}, {"score": 0.0026543514413663893, "phrase": "available_data"}, {"score": 0.002583392808974657, "phrase": "novel_approach"}, {"score": 0.002560162916190598, "phrase": "automatic_creation"}, {"score": 0.002529513507222548, "phrase": "cylindrical_projected_face_images"}, {"score": 0.0025143263276317935, "phrase": "nine_different_views"}, {"score": 0.0024250944519924383, "phrase": "cylindrical_approximation"}, {"score": 0.00240328454980006, "phrase": "real_object_surface"}, {"score": 0.002290227534601535, "phrase": "afterward_a_local_transformation"}, {"score": 0.0022696277881969896, "phrase": "desired_face_features"}, {"score": 0.0022492129111567824, "phrase": "triangle_mesh"}, {"score": 0.0022289812518790824, "phrase": "local_alignment"}, {"score": 0.0022089311733832985, "phrase": "closer_look"}, {"score": 0.002189061053183049, "phrase": "feature_properties"}, {"score": 0.0021433882705962034, "phrase": "aligned_face_images"}, {"score": 0.0021049977753042253, "phrase": "pose_invariant_face_recognition_approach"}], "paper_keywords": ["3D Face recognition", " Partial PCA", " PCA", " Eigenfaces", " Image stitching", " Image alignment"], "paper_abstract": "In last years, Face recognition based on 3D techniques is an emergent technology which has demonstrated better results than conventional 2D approaches. Using texture (180A degrees multi-view image) and depth maps is supposed to increase the robustness towards the two main challenges in Face Recognition: Pose and illumination. Nevertheless, 3D data should be acquired under highly controlled conditions and in most cases depends on the collaboration of the subject to be recognized. Thus, in applications such as surveillance or control access points, this kind of 3D data may not be available during the recognition process. This leads to a new paradigm using some mixed 2D-3D face recognition systems where 3D data is used in the training but either 2D or 3D information can be used in the recognition depending on the scenario. Following this concept, where only part of the information (partial concept) is used in the recognition, a novel method is presented in this work. This has been called Partial Principal Component Analysis (P(2)CA) since they fuse the Partial concept with the fundamentals of the well known PCA algorithm. This strategy has been proven to be very robust in pose variation scenarios showing that the 3D training process retains all the spatial information of the face while the 2D picture effectively recovers the face information from the available data. Furthermore, in this work, a novel approach for the automatic creation of 180A degrees aligned cylindrical projected face images using nine different views is presented. These face images are created by using a cylindrical approximation for the real object surface. The alignment is done by applying first a global 2D affine transformation of the image, and afterward a local transformation of the desired face features using a triangle mesh. This local alignment allows a closer look to the feature properties and not the differences. Finally, these aligned face images are used for training a pose invariant face recognition approach (P(2)CA).", "paper_title": "Aligned texture map creation for pose invariant face recognition", "paper_id": "WOS:000278623800009"}