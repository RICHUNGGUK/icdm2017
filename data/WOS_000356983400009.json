{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "database_management_systems"}, {"score": 0.00472961267657106, "phrase": "short_character_strings"}, {"score": 0.004695900553353526, "phrase": "current_applications"}, {"score": 0.004579780586951551, "phrase": "genetic_sequences"}, {"score": 0.0045471315699087385, "phrase": "multidimensional_time_series"}, {"score": 0.004514714250357749, "phrase": "large_texts"}, {"score": 0.004450568197899267, "phrase": "\"complex\"_data_elements"}, {"score": 0.004324985524216987, "phrase": "fundamental_concept"}, {"score": 0.004055176557424983, "phrase": "complex_elements"}, {"score": 0.003969018740062018, "phrase": "exact_match"}, {"score": 0.003708033700676924, "phrase": "set_theoretical_concept"}, {"score": 0.003526735797659508, "phrase": "data_\"sets"}, {"score": 0.0032016639006812826, "phrase": "new_concept"}, {"score": 0.003167441161387607, "phrase": "similarity_sets"}, {"score": 0.0029590077170443666, "phrase": "central_properties"}, {"score": 0.0028548578165712643, "phrase": "basic_algorithm"}, {"score": 0.0027941308786390033, "phrase": "metric_datasets"}, {"score": 0.0027151607914592552, "phrase": "required_properties"}, {"score": 0.002509284173541882, "phrase": "efficient_algorithm"}, {"score": 0.0024122616475793206, "phrase": "simset_concept"}, {"score": 0.0023189818169615135, "phrase": "real_world"}, {"score": 0.0023024126375034066, "phrase": "synthetic_datasets"}, {"score": 0.0021507795710951384, "phrase": "increasing_data_sizes"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Metric space", " Similarity sets", " Independent dominating sets", " Graphs"], "paper_abstract": "Besides integers and short character strings, current applications require storing photos, videos, genetic sequences, multidimensional time series, large texts and several other types of \"complex\" data elements. Comparing them by equality is a fundamental concept for the Relational Model, the data model currently employed in most Database Management Systems. However, evaluating the equality of complex elements is usually senseless, since exact match almost never happens. Instead, it is much more significant to evaluate their similarity. Consequently, the set theoretical concept that a set cannot include the same element twice also becomes senseless for data \"sets\" that must be handled by similarity, suggesting that a new, equivalent definition must take place for them. Targeting this problem, this paper introduces the new concept of \"similarity sets\", or SimSets for short. Specifically, our main contributions are: (i) we highlight the central properties of SimSets; (ii) we develop the basic algorithm required to create SimSets from metric datasets, ensuring that they always meet the required properties; (iii) we formally define unary and binary operations over SimSets; and (iv) we develop an efficient algorithm to perform these operations. To validate our proposals, the SimSet concept and the tools developed for them were employed over both real world and synthetic datasets. We report results on the adequacy, stability, speed and scalability of our algorithms with regard to increasing data sizes. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Similarity sets: A new concept of sets to seamlessly handle similarity in database management systems", "paper_id": "WOS:000356983400009"}