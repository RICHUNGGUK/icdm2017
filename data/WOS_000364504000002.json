{"auto_keywords": [{"score": 0.0495037775396638, "phrase": "differential_privacy"}, {"score": 0.03924481492526573, "phrase": "search_logs"}, {"score": 0.00481495049065317, "phrase": "collaborative_search_log_sanitization"}, {"score": 0.0046621835537196754, "phrase": "severe_privacy_leakage"}, {"score": 0.004606148097788071, "phrase": "aol_search_log_incident"}, {"score": 0.004550783060775205, "phrase": "considerable_worldwide_attention"}, {"score": 0.00419823857480455, "phrase": "data_analysts"}, {"score": 0.004164516065972361, "phrase": "law_enforcement_personnel"}, {"score": 0.0041144374213500715, "phrase": "social_behavior_study"}, {"score": 0.004032302251481604, "phrase": "criminal_investigation"}, {"score": 0.003810909603178837, "phrase": "important_and_challenging_research_problem"}, {"score": 0.003704797078215222, "phrase": "strong_privacy_guarantee"}, {"score": 0.003675023529026644, "phrase": "sufficiently_retained_utility"}, {"score": 0.0036454883790271843, "phrase": "existing_approaches"}, {"score": 0.003616189733352126, "phrase": "search_log_sanitization"}, {"score": 0.003473178781851477, "phrase": "rigorous_standard"}, {"score": 0.003390092184270794, "phrase": "good_output_utility"}, {"score": 0.003040050100579337, "phrase": "high_standard"}, {"score": 0.002896274285996145, "phrase": "sanitization_framework"}, {"score": 0.0028155572612699976, "phrase": "distributed_manner"}, {"score": 0.0027370835853738626, "phrase": "different_parties"}, {"score": 0.0026715589067557526, "phrase": "boosted_utility"}, {"score": 0.0025145109881926143, "phrase": "collaborative_sanitization"}, {"score": 0.0024345529783611703, "phrase": "collaborative_parties"}, {"score": 0.002385872451981323, "phrase": "private_information"}, {"score": 0.0023099954987126, "phrase": "efficient_protocol_-_collaborative_search_log_sanitization"}, {"score": 0.00224558083320154, "phrase": "privacy_requirements"}, {"score": 0.0022006705963260433, "phrase": "cost_analysis"}, {"score": 0.0021049977753042253, "phrase": "real_data_sets"}], "paper_keywords": ["Search log", " differential privacy", " sampling", " optimization", " secure multiparty computation"], "paper_abstract": "Severe privacy leakage in the AOL search log incident has attracted considerable worldwide attention. However, all the web users' daily search intents and behavior are collected in such data, which can be invaluable for researchers, data analysts and law enforcement personnel to conduct social behavior study [14], criminal investigation [5] and epidemics detection [10]. Thus, an important and challenging research problem is how to sanitize search logs with strong privacy guarantee and sufficiently retained utility. Existing approaches in search log sanitization are capable of only protecting the privacy under a rigorous standard [24] or maintaining good output utility [25]. To the best of our knowledge, there is little work that has perfectly resolved such tradeoff in the context of search logs, meeting a high standard of both requirements. In this paper, we propose a sanitization framework to tackle the above issue in a distributed manner. More specifically, our framework enables different parties to collaboratively generate search logs with boosted utility while satisfying Differential Privacy. In this scenario, two privacy-preserving objectives arise: first, the collaborative sanitization should satisfy differential privacy; second, the collaborative parties cannot learn any private information from each other. We present an efficient protocol - Collaborative sEarch Log Sanitization (CELS) to meet both privacy requirements. Besides security/privacy and cost analysis, we demonstrate the utility and efficiency of our approach with real data sets.", "paper_title": "Collaborative Search Log Sanitization: Toward Differential Privacy and Boosted Utility", "paper_id": "WOS:000364504000002"}