{"auto_keywords": [{"score": 0.03891709922097912, "phrase": "contingency_tables"}, {"score": 0.015719716506582538, "phrase": "sparse_adtrees"}, {"score": 0.012589481577291412, "phrase": "one-dimensional_array"}, {"score": 0.012351741272918243, "phrase": "hash_map"}, {"score": 0.004723322467153553, "phrase": "data-mining_algorithms"}, {"score": 0.004516217254020583, "phrase": "adtrees"}, {"score": 0.004235938758522453, "phrase": "efficient_data_structure"}, {"score": 0.004155283263388382, "phrase": "sufficient_statistics"}, {"score": 0.0035399770257915466, "phrase": "non-recursive_approach"}, {"score": 0.003215295260684715, "phrase": "two-dimensional_array"}, {"score": 0.0029391032882625473, "phrase": "non-recursive_approaches"}, {"score": 0.0029017045975404327, "phrase": "python"}, {"score": 0.0027564303939865476, "phrase": "five_aspects"}, {"score": 0.002703869368554536, "phrase": "large_number"}, {"score": 0.0026693851900137953, "phrase": "randomly_generated_datasets"}, {"score": 0.002568542343945288, "phrase": "modified_algorithms"}, {"score": 0.002535779689260244, "phrase": "bayesian_networks"}, {"score": 0.0024556852466581527, "phrase": "performance_improvements"}, {"score": 0.002244596395352896, "phrase": "algorithm_performance"}, {"score": 0.0021322065604537617, "phrase": "higher_arities"}, {"score": 0.0021049977753042253, "phrase": "larger_arity_values"}], "paper_keywords": ["Data mining", " Contingency tables", " Sparse ADtrees", " Non-recursive algorithms", " Bayesian networks learning"], "paper_abstract": "In data-mining algorithms contingency tables are frequently built from ADtrees, as ADtrees have been demonstrated to be an efficient data structure for caching sufficient statistics. This paper introduces three modifications. The first two use a one-dimensional array and a hash map for representing contingency tables, and the third uses the non-recursive approach to build contingency tables from sparse ADtrees. We implement algorithms to construct contingency tables with a two-dimensional array, a tree, a one-dimensional array, and a hash map using recursion and non-recursive approaches in Python. We empirically test these algorithms in five aspects with a large number of randomly generated datasets. We also apply the modified algorithms to Bayesian networks learning and test the performance improvements using three real-life datasets. We demonstrate experimentally that all three of these modifications improve algorithm performance. The improvements are more significant with higher arities and larger arity values.", "paper_title": "Computing contingency tables from sparse ADtrees", "paper_id": "WOS:000353243900011"}