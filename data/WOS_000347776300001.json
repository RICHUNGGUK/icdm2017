{"auto_keywords": [{"score": 0.04624924834040988, "phrase": "labeled_data"}, {"score": 0.02899905057183092, "phrase": "data_sets"}, {"score": 0.00481495049065317, "phrase": "semi-supervised_classification_methods"}, {"score": 0.004657393640152439, "phrase": "training_sets"}, {"score": 0.004606023493393774, "phrase": "large_amounts"}, {"score": 0.004555217356295278, "phrase": "unlabeled_data"}, {"score": 0.0044800522651664695, "phrase": "small_quantity"}, {"score": 0.004191540451296395, "phrase": "different_assumptions"}, {"score": 0.004054299982508618, "phrase": "input_data"}, {"score": 0.0039433581938239926, "phrase": "self-labeled_techniques"}, {"score": 0.0038782499819752423, "phrase": "iterative_procedure"}, {"score": 0.003751228706861377, "phrase": "enlarged_labeled_data"}, {"score": 0.0033015555065209865, "phrase": "self-labeled_methods"}, {"score": 0.0032470094613727433, "phrase": "-supervised_classification"}, {"score": 0.003175676186323053, "phrase": "theoretical_point"}, {"score": 0.002987463078971627, "phrase": "main_characteristics"}, {"score": 0.0028260302580927856, "phrase": "exhaustive_study"}, {"score": 0.002763919794139171, "phrase": "large_number"}, {"score": 0.0026881926384093088, "phrase": "different_ratios"}, {"score": 0.0025287979714720423, "phrase": "transductive_and_inductive_classification_capabilities"}, {"score": 0.0024323098907299027, "phrase": "nonparametric_statistical_tests"}, {"score": 0.00230080652063411, "phrase": "best-performing_ones"}, {"score": 0.0022377394845878268, "phrase": "semi-supervised_learning_module"}, {"score": 0.002140400526572388, "phrase": "evolutionary_learning_software"}, {"score": 0.0021049977753042253, "phrase": "analyzed_methods"}], "paper_keywords": ["Learning from unlabeled data", " Semi-supervised learning", " Self-training", " Co-training", " Multi-view learning", " Classification"], "paper_abstract": "Semi-supervised classification methods are suitable tools to tackle training sets with large amounts of unlabeled data and a small quantity of labeled data. This problem has been addressed by several approaches with different assumptions about the characteristics of the input data. Among them, self-labeled techniques follow an iterative procedure, aiming to obtain an enlarged labeled data set, in which they accept that their own predictions tend to be correct. In this paper, we provide a survey of self-labeled methods for semi-supervised classification. From a theoretical point of view, we propose a taxonomy based on the main characteristics presented in them. Empirically, we conduct an exhaustive study that involves a large number of data sets, with different ratios of labeled data, aiming to measure their performance in terms of transductive and inductive classification capabilities. The results are contrasted with nonparametric statistical tests. Note is then taken of which self-labeled models are the best-performing ones. Moreover, a semi-supervised learning module has been developed for the Knowledge Extraction based on Evolutionary Learning software, integrating analyzed methods and data sets.", "paper_title": "Self-labeled techniques for semi-supervised learning: taxonomy, software and empirical study", "paper_id": "WOS:000347776300001"}