{"auto_keywords": [{"score": 0.04107868567004354, "phrase": "nmkmhks"}, {"score": 0.01481673793089547, "phrase": "kmhks"}, {"score": 0.013232522928250034, "phrase": "nystrom"}, {"score": 0.01037916248031296, "phrase": "inmkmhks"}, {"score": 0.00481495049065317, "phrase": "nystrom_approximation_technique"}, {"score": 0.004762893197005439, "phrase": "kernelized_modification"}, {"score": 0.0047113960612140335, "phrase": "ho-kashyap_algorithm"}, {"score": 0.004660453113061494, "phrase": "squared_approximation"}, {"score": 0.0045850648862091085, "phrase": "misclassification_errors"}, {"score": 0.004437910956996051, "phrase": "effective_algorithm"}, {"score": 0.004389912080394437, "phrase": "nonlinearly_separable_classification_problems"}, {"score": 0.004157561334726201, "phrase": "multi-kernel_classification_machine"}, {"score": 0.003958937342925219, "phrase": "multiple_kmhkss"}, {"score": 0.0033262524445013303, "phrase": "improved_multi-kernel_classification_machine"}, {"score": 0.0030821633718368206, "phrase": "new_way"}, {"score": 0.003032228032253871, "phrase": "kernel_functions"}, {"score": 0.0029830992938695007, "phrase": "new_nystrom_approximation_technique"}, {"score": 0.002646267286675984, "phrase": "comparable_space"}, {"score": 0.0026175952455594277, "phrase": "computational_complexities"}, {"score": 0.0024653491388223546, "phrase": "tighter_generalization_risk"}, {"score": 0.0023990982005125763, "phrase": "rademacher_complexity_analysis"}, {"score": 0.00230932021677234, "phrase": "better_recognition"}, {"score": 0.0021049977753042253, "phrase": "practical_images"}], "paper_keywords": ["Multiple kernel learning", " Nystrom approximation", " Generalization risk analysis", " Pattern classification"], "paper_abstract": "Kernelized modification of Ho-Kashyap algorithm with squared approximation of the misclassification errors (KMHKS) is an effective algorithm for nonlinearly separable classification problems. While KMHKS only adopts one kernel function. So a multi-kernel classification machine with reduced complexity named Nystrom approximation matrix with Multiple KMHKSs (NMKMHKS) has been developed. But NMKMHKS has to initialize many parameters and has not an ability to deal with noise well. To this end, we propose an improved multi-kernel classification machine with Nystrom approximation technique (INMKMHKS). INMKMHKS is based on a new way of generating kernel functions and a new Nystrom approximation technique. The contributions of INMKMHKS are that (1) avoiding the problem of setting too many parameters; (2) keeping comparable space and computational complexities after comparing with NMKMHKS; (3) having a tighter generalization risk bound in terms of Rademacher complexity analysis; (4) having a better recognition than NMKMHKS on average; (5) possessing an ability to deal with noise and practical images. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Improved multi-kernel classification machine with Nystrom approximation technique", "paper_id": "WOS:000348880300038"}