{"auto_keywords": [{"score": 0.04907049129770542, "phrase": "prototype_generation"}, {"score": 0.004815117103834276, "phrase": "taxonomy"}, {"score": 0.004673530058379246, "phrase": "nearest_neighbor_classification"}, {"score": 0.0046141941030386525, "phrase": "nearest_neighbor"}, {"score": 0.0043842558719324526, "phrase": "classification_and_pattern_recognition_tasks"}, {"score": 0.0041835168653521, "phrase": "time_response"}, {"score": 0.004148014765950199, "phrase": "noise_sensitivity"}, {"score": 0.004095323392273661, "phrase": "high_storage_requirements"}, {"score": 0.0038911408649026724, "phrase": "good_and_well-known_solution"}, {"score": 0.0035731269727067496, "phrase": "classification_rule"}, {"score": 0.0034828730516958807, "phrase": "prototype_reduction_techniques"}, {"score": 0.0033232673019931206, "phrase": "prototype_selection"}, {"score": 0.0031845067058084583, "phrase": "former_process"}, {"score": 0.0030776686414001964, "phrase": "original_training_data"}, {"score": 0.0030127172247606812, "phrase": "new_artificial_prototypes"}, {"score": 0.002924074850256874, "phrase": "nn_classification"}, {"score": 0.002790004829699627, "phrase": "pg_methods"}, {"score": 0.0027311076665349657, "phrase": "nn_rule"}, {"score": 0.00268488398249084, "phrase": "theoretical_point"}, {"score": 0.002561752783323717, "phrase": "main_characteristics"}, {"score": 0.002465210678474529, "phrase": "empirical_point"}, {"score": 0.0023926387830753033, "phrase": "wide_experimental_study"}, {"score": 0.002362192695471035, "phrase": "small_and_large_datasets"}, {"score": 0.0022926465161639633, "phrase": "accuracy_and_reduction_capabilities"}, {"score": 0.0022251433045184454, "phrase": "nonparametrical_statistical_tests"}, {"score": 0.0021049977753042253, "phrase": "different_datasets"}], "paper_keywords": ["Classification", " learning vector quantization (LVQ)", " nearest neighbor (NN)", " prototype generation (PG)", " taxonomy"], "paper_abstract": "The nearest neighbor (NN) rule is one of the most successfully used techniques to resolve classification and pattern recognition tasks. Despite its high classification accuracy, this rule suffers from several shortcomings in time response, noise sensitivity, and high storage requirements. These weaknesses have been tackled by many different approaches, including a good and well-known solution that we can find in the literature, which consists of the reduction of the data used for the classification rule (training data). Prototype reduction techniques can be divided into two different approaches, which are known as prototype selection and prototype generation (PG) or abstraction. The former process consists of choosing a subset of the original training data, whereas PG builds new artificial prototypes to increase the accuracy of the NN classification. In this paper, we provide a survey of PG methods specifically designed for the NN rule. From a theoretical point of view, we propose a taxonomy based on the main characteristics presented in them. Furthermore, from an empirical point of view, we conduct a wide experimental study that involves small and large datasets to measure their performance in terms of accuracy and reduction capabilities. The results are contrasted through nonparametrical statistical tests. Several remarks are made to understand which PG models are appropriate for application to different datasets.", "paper_title": "A Taxonomy and Experimental Study on Prototype Generation for Nearest Neighbor Classification", "paper_id": "WOS:000298300200009"}