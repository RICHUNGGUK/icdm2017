{"auto_keywords": [{"score": 0.029153668664146787, "phrase": "video_indexing"}, {"score": 0.00481495049065317, "phrase": "precision-oriented_text-based_video_retrieval"}, {"score": 0.0047314049780079765, "phrase": "automatically-extracted_concepts"}, {"score": 0.004426882270402403, "phrase": "search_process"}, {"score": 0.004084245825701289, "phrase": "typical_web_multimedia_retrieval_systems"}, {"score": 0.0038078492247427594, "phrase": "multimedia_documents"}, {"score": 0.003625537203803235, "phrase": "typical_user"}, {"score": 0.0035129562812850784, "phrase": "users'_behavior"}, {"score": 0.0034038593017883295, "phrase": "initial_documents"}, {"score": 0.0033564619316337634, "phrase": "search_session"}, {"score": 0.00330972235893118, "phrase": "multimedia_retrieval_system"}, {"score": 0.0032522091171602557, "phrase": "multimedia_content"}, {"score": 0.003151184191185831, "phrase": "first_retrieved_images"}, {"score": 0.0030747771905143273, "phrase": "user's_information"}, {"score": 0.0030002172602367682, "phrase": "keyword-based_approach"}, {"score": 0.0028866770996648057, "phrase": "high-level_index"}, {"score": 0.002767696345005216, "phrase": "expressive_frameworks"}, {"score": 0.0027005626126039204, "phrase": "huge_importance"}, {"score": 0.0026443135597866924, "phrase": "significant_retrieval_performance"}, {"score": 0.0025892330566358503, "phrase": "multi-facetted_conceptual_framework"}, {"score": 0.0025352969524471496, "phrase": "visual_and_audio_contents"}, {"score": 0.0025175684590726796, "phrase": "automatic_video_retrieval"}, {"score": 0.0024651215047303593, "phrase": "expressive_representation_formalism"}, {"score": 0.002447882520797866, "phrase": "high-level_video_descriptions"}, {"score": 0.002422249273477746, "phrase": "full-text_query_framework"}, {"score": 0.0023387234705715154, "phrase": "trivial_low-level_processes"}, {"score": 0.0021422669204408263, "phrase": "multimedia_topic_search_task"}, {"score": 0.0021198271568336063, "phrase": "trecvid_evaluation_campaign"}], "paper_keywords": ["Video indexing and retrieval", " Visual/audio integration", " Conceptual graphs", " Large-scale experimental validation"], "paper_abstract": "Traditional multimedia (video) retrieval systems use the keyword-based approach in order to make the search process fast although this approach has several shortcomings and limitations related to the way the user is able to formulate her/his information need. Typical Web multimedia retrieval systems illustrate this paradigm in the sense that the result of a search consists of a collection of thousands of multimedia documents, many of which would be irrelevant or not fully exploited by the typical user. Indeed, according to studies related to users' behavior, an individual is mostly interested in the initial documents returned during a search session and therefore a multimedia retrieval system is to model the multimedia content as precisely as possible to allow for the first retrieved images to be fully relevant to the user's information need. For this, the keyword-based approach proves to be clearly insufficient and the need for a high-level index and query language, addressing the issue of combining modalities within expressive frameworks for video indexing and retrieval is of huge importance and the only solution for achieving significant retrieval performance. This paper presents a multi-facetted conceptual framework integrating multiple characterizations of the visual and audio contents for automatic video retrieval. It relies on an expressive representation formalism handling high-level video descriptions and a full-text query framework in an attempt to operate video indexing and retrieval beyond trivial low-level processes, keyword-annotation frameworks and state-of-the art architectures loosely-coupling visual and audio descriptions. Experiments on the multimedia topic search task of the TRECVID evaluation campaign validate our proposal.", "paper_title": "CLOVIS: towards precision-oriented text-based video retrieval through the unification of automatically-extracted concepts and relations of the visual and audio/speech contents", "paper_id": "WOS:000275161000002"}