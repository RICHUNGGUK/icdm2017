{"auto_keywords": [{"score": 0.031140996391594396, "phrase": "unified_kernel_function"}, {"score": 0.014042902514581493, "phrase": "gvsm"}, {"score": 0.013762715815369945, "phrase": "lsi"}, {"score": 0.012593422822316335, "phrase": "retrieval_performance"}, {"score": 0.01190103367046439, "phrase": "document_space"}, {"score": 0.010756923917858844, "phrase": "dual_perspective"}, {"score": 0.00481495049065317, "phrase": "unified_linear_subspace_approach"}, {"score": 0.004775918707955445, "phrase": "semantic_analysis"}, {"score": 0.004585433265422727, "phrase": "information_retrieval"}, {"score": 0.004366808573435364, "phrase": "literal_term_matching"}, {"score": 0.004244102948402086, "phrase": "latent_semantic_indexing"}, {"score": 0.004008897491380646, "phrase": "underlying_latent_semantic_structure"}, {"score": 0.003392182098020722, "phrase": "latent_semantic_structure"}, {"score": 0.0031910037920846817, "phrase": "term_space"}, {"score": 0.0031012349116334606, "phrase": "new_viewpoint"}, {"score": 0.0030635374056374016, "phrase": "natural_connection"}, {"score": 0.0028467558213723697, "phrase": "vector_space_models"}, {"score": 0.002777949746964955, "phrase": "deeper_understanding"}, {"score": 0.0027441711627551064, "phrase": "semantic_space"}, {"score": 0.002623783458189614, "phrase": "new_semantic_analysis_methods"}, {"score": 0.0024680632991561074, "phrase": "gvsm."}, {"score": 0.0024083881142747954, "phrase": "new_methods"}, {"score": 0.002350152413458658, "phrase": "selected_rank"}, {"score": 0.002321563536990284, "phrase": "truncated_singular_value_decomposition"}, {"score": 0.0021309254505358253, "phrase": "standard_test_collections"}], "paper_keywords": [""], "paper_abstract": "The Basic Vector Space Model (BVSM) is well known in information retrieval. Unfortunately, its retrieval effectiveness is limited because it is based on literal term matching. The Generalizod Vector Space Model (GVSM) and Latent Semantic Indexing (LSI) are two prominent semantic retrieval methods, both of which assume there is some underlying latent semantic structure in a dataset that can be used to improve retrieval performance. However, while this structure may be derived from both the term space and the document space, GVSM exploits only the former and LSI the latter. In this article, the latent semantic structure of a dataset is examined from a dual perspective; namely, we consider the term space and the document space simultaneously. This new viewpoint has a natural connection to the notion of kernels. Specifically, a unified kernel function can be derived for a class of vector space models. The dual perspective provides a deeper understanding of the semantic space and makes transparent the geometrical meaning of the unified kernel function. New semantic analysis methods based on the unified kernel function are developed, which combine the advantages of I-SI and GVSM. We also prove that the new methods are stable because although the selected rank of the truncated Singular Value Decomposition (SVD) is far from the optimum, the retrieval performance will not be degraded significantly. Experiments performed on standard test collections show that our methods are promising.", "paper_title": "Unified Linear Subspace Approach to Semantic Analysis", "paper_id": "WOS:000273155100014"}