{"auto_keywords": [{"score": 0.049217710328296, "phrase": "tsvr"}, {"score": 0.015719716506582538, "phrase": "linear_programming"}, {"score": 0.004771435352180973, "phrase": "twin_support_vector_regression"}, {"score": 0.0045804107341714, "phrase": "novel_regressor"}, {"score": 0.004417012437860011, "phrase": "nonparallel_planes"}, {"score": 0.004051828608343507, "phrase": "good_performance"}, {"score": 0.003996983218174335, "phrase": "conventional_methods"}, {"score": 0.003960837517843981, "phrase": "svr"}, {"score": 0.0037336520904376687, "phrase": "model_complexity_control"}, {"score": 0.0036167509502276294, "phrase": "suboptimal_solution"}, {"score": 0.003424771860049617, "phrase": "quadratic_programming_problems"}, {"score": 0.0028944757265206332, "phrase": "novel_regression_algorithm"}, {"score": 0.002855251306715901, "phrase": "robust_and_sparse_twin_support_vector_regression"}, {"score": 0.0027159094186967247, "phrase": "convex_problem"}, {"score": 0.0026790983342162887, "phrase": "regularization_technique"}, {"score": 0.002391067964886602, "phrase": "resulting_lp_problem"}, {"score": 0.002305589818994465, "phrase": "newton_algorithm"}, {"score": 0.0022847009758393405, "phrase": "armijo_step-size"}, {"score": 0.0022434880661725493, "phrase": "corresponding_exact_exterior_penalty_problem"}, {"score": 0.0021049977753042253, "phrase": "proposed_method"}], "paper_keywords": ["Support vector machine", " Linear programming", " Exact exterior penalty function", " Newton method"], "paper_abstract": "Twin support vector regression (TSVR) was proposed recently as a novel regressor that tries to find a pair of nonparallel planes, i.e. epsilon-insensitive up- and down-bounds, by solving two related SVM-type problems. Though TSVR exhibits good performance compared with conventional methods like SVR, it suffers from the following issues: (1) it lacks model complexity control and thus may incur overfitting and suboptimal solution; (2) it needs to solve a pair of quadratic programming problems which are relatively complex to implement; (3) it is sensitive to outliers; and (4) its solution is not sparse. To address these problems, we propose in this paper a novel regression algorithm termed as robust and sparse twin support vector regression. The central idea is to reformulate TSVR as a convex problem by introducing regularization technique first and then derive a linear programming (LP) formulation which is not only simple but also allows robustness and sparseness. Instead of solving the resulting LP problem in the primal, we present a Newton algorithm with Armijo step-size to resolve the corresponding exact exterior penalty problem. The experimental results on several publicly available benchmark data sets show the feasibility and effectiveness of the proposed method.", "paper_title": "An improved robust and sparse twin support vector regression via linear programming", "paper_id": "WOS:000345097100001"}