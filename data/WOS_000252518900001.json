{"auto_keywords": [{"score": 0.04467661766774399, "phrase": "tracked_object"}, {"score": 0.00481495049065317, "phrase": "based_data_fusion"}, {"score": 0.004774115617883476, "phrase": "autonomous_vehicles"}, {"score": 0.00475382761232911, "phrase": "target_tracking"}, {"score": 0.0047135086583390585, "phrase": "interacting_multiple_dynamic_models"}, {"score": 0.004575053987970206, "phrase": "novel_algorithm"}, {"score": 0.0044786435725543685, "phrase": "vision-based_object_tracking"}, {"score": 0.004095323392273661, "phrase": "vehicle's_on-board_sensors"}, {"score": 0.003991932110277654, "phrase": "inertial_motion_sensors"}, {"score": 0.003841699919521703, "phrase": "stereo_pair_disparities"}, {"score": 0.003776750773624222, "phrase": "optical_features"}, {"score": 0.0037287578312533596, "phrase": "vehicle's_inertial_measurements"}, {"score": 0.003634587156159668, "phrase": "cameras'_motion"}, {"score": 0.003211788912325178, "phrase": "tracking_algorithm"}, {"score": 0.003104038398386081, "phrase": "proper_model"}, {"score": 0.0030515222178491923, "phrase": "dynamic_information"}, {"score": 0.002936577024096783, "phrase": "complex_nature"}, {"score": 0.0028992294924613327, "phrase": "moving_object"}, {"score": 0.0028139168128067343, "phrase": "robust_and_adaptive_dynamic_models"}, {"score": 0.002583713580625699, "phrase": "basic_linear_dynamic_models"}, {"score": 0.002550842302473891, "phrase": "detailed_description"}, {"score": 0.0024338491713531197, "phrase": "imm"}, {"score": 0.0023824468367751365, "phrase": "extended_kalman_filter"}, {"score": 0.002332133125576037, "phrase": "final_state"}, {"score": 0.002253826965566618, "phrase": "weighted_combination"}, {"score": 0.0021968238865548812, "phrase": "different_dynamic_model"}, {"score": 0.0021504218042734677, "phrase": "proposed_fusion"}, {"score": 0.0021412594173592513, "phrase": "based_imm_tracking_algorithm"}, {"score": 0.0021049977753042253, "phrase": "extensive_experimental_results"}], "paper_keywords": ["optical flow", " extended Kalman Filtering", " image segmentation and clustering", " stereo vision", " target tracking", " autonomous vehicles", " linear dynamics model", " kinematic model", " interacting multiple models (IMM)", " pinhole camera projection model", " template matching and updating", " sensor data fusion"], "paper_abstract": "In this paper, a novel algorithm is proposed for the vision-based object tracking by autonomous vehicles. To estimate the velocity of the tracked object, the algorithm fuses the information captured by the vehicle's on-board sensors such as the cameras and inertial motion sensors. Optical flow vectors, color features, stereo pair disparities are used as optical features while the vehicle's inertial measurements are used to determine the cameras' motion. The algorithm determines the velocity and position of the target in the world coordinate which are then tracked by the vehicle. In order to formulate this tracking algorithm, it is necessary to use a proper model which describes the dynamic information of the tracked object. However due to the complex nature of the moving object, it is necessary to have robust and adaptive dynamic models. Here, several simple and basic linear dynamic models are selected and combined to approximate the unpredictable, complex or highly nonlinear dynamic properties of the moving target. With these basic linear dynamic models, a detailed description of the three-dimensional (3D) target tracking scheme using the Interacting Multiple Models (IMM) along with an Extended Kalman Filter is presented. The final state of the target is estimated as a weighted combination of the outputs from each different dynamic model. Performance of the proposed fusion based IMM tracking algorithm is demonstrated through extensive experimental results. (c) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Vision based data fusion for autonomous vehicles target tracking using interacting multiple dynamic models", "paper_id": "WOS:000252518900001"}