{"auto_keywords": [{"score": 0.04317179544664411, "phrase": "belief_points"}, {"score": 0.019694093276123908, "phrase": "backup_operations"}, {"score": 0.009293567183874385, "phrase": "value_function"}, {"score": 0.00481495049065317, "phrase": "point-based_pomdp_solvers"}, {"score": 0.004692227830462433, "phrase": "partially_observable_markov_decision_process"}, {"score": 0.0045726187330434025, "phrase": "realistic_applications"}, {"score": 0.004475266375001531, "phrase": "point-based_methods"}, {"score": 0.004361163586439822, "phrase": "approximate_solution"}, {"score": 0.004323776691055635, "phrase": "medium-sized_domains"}, {"score": 0.004159446063902181, "phrase": "finite_reachable_set"}, {"score": 0.004035946043145475, "phrase": "point-based_algorithms"}, {"score": 0.003686935223424015, "phrase": "selected_belief_points"}, {"score": 0.003592859432554987, "phrase": "current_algorithms"}, {"score": 0.003546722347907148, "phrase": "large_number"}, {"score": 0.0031982609080278643, "phrase": "predefined_set"}, {"score": 0.0030898642396380662, "phrase": "simpler_domain"}, {"score": 0.00306334226516593, "phrase": "mdp_solvers"}, {"score": 0.002985130390111069, "phrase": "equivalent_backup_operations"}, {"score": 0.0027982016314450717, "phrase": "prioritized_backups"}, {"score": 0.002762240719058935, "phrase": "pomdp_framework"}, {"score": 0.0027150087516999047, "phrase": "existing_algorithms"}, {"score": 0.0025780912201045555, "phrase": "new_algorithm"}, {"score": 0.0025230952890994236, "phrase": "prioritized_value_iteration"}, {"score": 0.002437525632451029, "phrase": "current_point-based_algorithms"}, {"score": 0.0023855210798264205, "phrase": "new_empirical_evaluation_measure"}, {"score": 0.0023245746777044766, "phrase": "standard_runtime_comparison"}, {"score": 0.002226430168622392, "phrase": "atomic_operations"}], "paper_keywords": ["Partially observable Markov decision process (POMDP)", " point-based", " prioritized value iteration"], "paper_abstract": "Recent scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.", "paper_title": "Prioritizing Point-Based POMDP Solvers", "paper_id": "WOS:000261310500014"}