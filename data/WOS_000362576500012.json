{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "object_segmentation"}, {"score": 0.03497872780869258, "phrase": "improved_hcrf_model"}, {"score": 0.029420333683948783, "phrase": "local_and_middle_scales"}, {"score": 0.004615202066192795, "phrase": "multi-class_object_segmentation"}, {"score": 0.0043863636475983845, "phrase": "pairwise_potential"}, {"score": 0.004330941610682453, "phrase": "hcrf_model"}, {"score": 0.004240116703465252, "phrase": "over-smooth_boundaries"}, {"score": 0.0040298010803060495, "phrase": "higher-order_potential"}, {"score": 0.003978866233891427, "phrase": "multiple_unsupervised_segments"}, {"score": 0.0038953958723049287, "phrase": "incorrect_guidance"}, {"score": 0.003813669883040509, "phrase": "under-segmentation_situation"}, {"score": 0.0037336520904376687, "phrase": "co-occurrence_potential"}, {"score": 0.0036553070575015344, "phrase": "inter-object_relationships"}, {"score": 0.0035634522350563107, "phrase": "uncommon_combinations"}, {"score": 0.003533347967582184, "phrase": "object_classes"}, {"score": 0.0034886660821793576, "phrase": "joint_optimization"}, {"score": 0.003459191419478298, "phrase": "multi-potential_cost_function"}, {"score": 0.003097865379563127, "phrase": "global_scale"}, {"score": 0.003071682293903262, "phrase": "scene_categorization_technique"}, {"score": 0.002994449398035894, "phrase": "scene_category"}, {"score": 0.0029191527226078286, "phrase": "scene_consistency"}, {"score": 0.002833689453299307, "phrase": "feasible_labels"}, {"score": 0.002809732883291955, "phrase": "specific_scenes"}, {"score": 0.0027159094186967247, "phrase": "improved_pairwise_potential"}, {"score": 0.0026815368507715, "phrase": "segment-reliable_consistency_potential"}, {"score": 0.0025375331660958665, "phrase": "over-smoothness_issues"}, {"score": 0.0024947959375982614, "phrase": "believed_labeling"}, {"score": 0.0024632148715152393, "phrase": "unary_potential"}, {"score": 0.0024320326084093465, "phrase": "coherent_inference"}, {"score": 0.0024012441367538434, "phrase": "reliable_segment_consistency"}, {"score": 0.002380934815435267, "phrase": "experimental_results"}, {"score": 0.00229164285862567, "phrase": "better_subjective_results"}, {"score": 0.0021049977753042253, "phrase": "average_accuracy"}], "paper_keywords": ["Conditional random field", " Object segmentation", " Higher-order potential", " Co-occurrence potential", " Scene categorization"], "paper_abstract": "Although the hierarchical conditional random field (HCRF) model has been successfully applied to multi-class object segmentation, there is still room for improvement. Firstly, the pairwise potential in the HCRF model has the tendency to over-smooth boundaries of regions that are similar to their neighbors. Secondly, the higher-order potential associated with multiple unsupervised segments is prone to producing incorrect guidance to inference in the under-segmentation situation. Finally, the co-occurrence potential as a measure of inter-object relationships cannot completely suppress some uncommon combinations of object classes due to joint optimization of multi-potential cost function. To alleviate these problems, we propose an improved HCRF model that efficiently combines information from global, middle and local scales for object segmentation in this paper. At the global scale, scene categorization technique is adopted to recognize the scene category of an image. The scene consistency then enforces object segmentation to align with feasible labels in specific scenes at the local and middle scales. Furthermore, an improved pairwise potential and a segment-reliable consistency potential are developed at the local and middle scales, respectively. These potentials rectify the over-smoothness issues by propagating the believed labeling from the unary potential and perform coherent inference by ensuring reliable segment consistency. Experimental results on the MSRC-21 dataset demonstrate that the improved HCRF model achieves better subjective results, as well as state-of-the-art objective results in terms of both global accuracy of 87.98 % and average accuracy of 81.43 %.", "paper_title": "Improved hierarchical conditional random field model for object segmentation", "paper_id": "WOS:000362576500012"}