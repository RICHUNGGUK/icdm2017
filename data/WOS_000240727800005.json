{"auto_keywords": [{"score": 0.02716840606857693, "phrase": "proposed_algorithm"}, {"score": 0.012413791407317066, "phrase": "target_speech"}, {"score": 0.008714187141067318, "phrase": "target_voice"}, {"score": 0.00481495049065317, "phrase": "voice_conversion"}, {"score": 0.00475413908468027, "phrase": "speaker_characteristics"}, {"score": 0.004724020632103649, "phrase": "recording_conditions"}, {"score": 0.004679198657323125, "phrase": "signal_processing_algorithms"}, {"score": 0.004590820632326585, "phrase": "voice_conversion_systems"}, {"score": 0.004489810932879285, "phrase": "robust_techniques"}, {"score": 0.004447201233380302, "phrase": "codebook_mapping"}, {"score": 0.004294381488413906, "phrase": "voice_conversion_performance"}, {"score": 0.0040042529959108605, "phrase": "implementation_details"}, {"score": 0.003941086361584705, "phrase": "first_method"}, {"score": 0.003916098498242888, "phrase": "confidence_measures"}, {"score": 0.0038789122930433305, "phrase": "training_stage"}, {"score": 0.0038420778359143917, "phrase": "problematic_pairs"}, {"score": 0.0037217945534790903, "phrase": "possible_misalignments"}, {"score": 0.0036864465771943933, "phrase": "style_differences"}, {"score": 0.003663067281537946, "phrase": "pronunciation_variations"}, {"score": 0.003571018150056717, "phrase": "spectral_distance"}, {"score": 0.003459191419478298, "phrase": "energy_distance"}, {"score": 0.0033190180867511605, "phrase": "second_method"}, {"score": 0.0032355864829403413, "phrase": "line-spectral_frequency"}, {"score": 0.003215061362264435, "phrase": "lsf"}, {"score": 0.0031143426702382117, "phrase": "last_method"}, {"score": 0.0029037051302566942, "phrase": "source_and_target_recording_conditions"}, {"score": 0.0028487656293168795, "phrase": "voice_conversion_algorithm"}, {"score": 0.0028127163745564777, "phrase": "proposed_techniques"}, {"score": 0.0027594936602962075, "phrase": "baseline_voice_conversion_algorithm"}, {"score": 0.0026140878612307536, "phrase": "subjective_listening_test"}, {"score": 0.00247632489362785, "phrase": "abx_test"}, {"score": 0.0023986960505076784, "phrase": "baseline_algorithm"}, {"score": 0.0023532890136269986, "phrase": "third_test"}, {"score": 0.002279508335630797, "phrase": "subjective_quality"}, {"score": 0.002250646398370793, "phrase": "voice_conversion_output"}, {"score": 0.002208035721125305, "phrase": "subjective_output_quality"}, {"score": 0.002166230024967046, "phrase": "mean_opinion_score"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": [""], "paper_abstract": "Differences in speaker characteristics, recording conditions, and signal processing algorithms affect. output quality in voice conversion systems. This study focuses on formulating robust techniques for a codebook mapping based voice conversion algorithm. Three different methods are used to improve voice conversion performance: confidence measures, pre-emphasis, and, spectral equalization. Analysis is performed for each method and the implementation details are discussed. The first method employs confidence measures in the training stage to eliminate problematic pairs of source and target speech units that might result from possible misalignments, speaking style differences or pronunciation variations. Four confidence measures are developed based on the spectral distance, fundamental frequency (f(0)) distance, energy distance, and duration distance between the source and target speech units. The second method focuses on the importance of pre-emphasis in line-spectral frequency (LSF) based vocal tract modeling and transformmation. The last method, spectral equalization, is aimed at reducing the differences in the source and target long-term spectra when the source and target recording conditions are significantly different. The voice conversion algorithm that employs the proposed techniques, is compared with the baseline voice conversion algorithm with objective tests as well as three subjective listening tests. First, similarity to the target voice is evaluated in a subjective listening test and it is shown that the proposed algorithm improves similarity to the target voice by 23.0%. An ABX test is performed and the proposed algorithm is preferred over the baseline algorithm by 76.4%. In the third test, the two algorithms are compared in terms of the subjective quality. of the voice conversion output. The proposed algorithm improves the subjective output quality by 46.8% in terms of mean opinion score (MOS). (c) 2005 Elsevier Ltd. All rights reserved.", "paper_title": "Robust processing techniques for voice conversion", "paper_id": "WOS:000240727800005"}