{"auto_keywords": [{"score": 0.04616388974806529, "phrase": "viewpoint_changes"}, {"score": 0.00481495049065317, "phrase": "crowded_scenes"}, {"score": 0.004730338746443662, "phrase": "human_detection"}, {"score": 0.004647206916983993, "phrase": "real_world_crowded_scenes"}, {"score": 0.0044852808671980325, "phrase": "frequent_and_severe_occlusions"}, {"score": 0.004252864101987588, "phrase": "scene_aware_detection"}, {"score": 0.0041780882724537, "phrase": "block_assignment_tracking"}, {"score": 0.004061160863655662, "phrase": "available_scene_models"}, {"score": 0.0038506514553203683, "phrase": "sad"}, {"score": 0.003796355951305572, "phrase": "accurate_detection"}, {"score": 0.003486316700608598, "phrase": "feature_sharing_mechanism"}, {"score": 0.003437154518139677, "phrase": "three-level_hierarchical_structure"}, {"score": 0.0032937749380725317, "phrase": "negative_and_false_positive_samples"}, {"score": 0.003258871417680268, "phrase": "intermediate_detection_results"}, {"score": 0.003201516237269705, "phrase": "based_tracking_systems"}, {"score": 0.0031340167205149813, "phrase": "occluded_scenes"}, {"score": 0.0030354183220734064, "phrase": "multiple_objects"}, {"score": 0.0029294877178473043, "phrase": "block_assignment_process"}, {"score": 0.0026805109390121706, "phrase": "ensemble_level"}, {"score": 0.0025869338215971536, "phrase": "discriminative_models"}, {"score": 0.0025233755103976317, "phrase": "block_level"}, {"score": 0.0024526426124799085, "phrase": "target_object"}, {"score": 0.002435270624076196, "phrase": "appearance_and_motion_models"}, {"score": 0.0024094425220967273, "phrase": "main_advantage"}, {"score": 0.002220296517089146, "phrase": "extensive_experiments"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual surveillance", " Object detection", " Object tracking", " Particle filter"], "paper_abstract": "How far can human detection and tracking go in real world crowded scenes? Many algorithms often fail in such scenes due to frequent and severe occlusions as well as viewpoint changes. In order to handle these difficulties, we propose Scene Aware Detection (SAD) and Block Assignment Tracking (BAT) that incorporate with some available scene models (e.g. background, layout, ground plane and camera models). The SAD is proposed for accurate detection through utilizing 1) camera model to deal with viewpoint changes by rectifying sub-images, 2) a structural filter approach to handle occlusions based on a feature sharing mechanism in which a three-level hierarchical structure is built for humans, and 3) foregrounds for pruning negative and false positive samples and merging intermediate detection results. Many detection or appearance based tracking systems are prone to errors in occluded scenes because of failures of detectors and interactions of multiple objects. Differently, the BAT formulates tracking as a block assignment process, where blocks with the same label form the appearance of one object. In the BAT, we model objects on two levels, one is the ensemble level to measure how it is like an object by discriminative models, and the other one is the block level to measure how it is like a target object by appearance and motion models. The main advantage of BAT is that it can track an object even when all the part detectors fail as long as the object has assigned blocks. Extensive experiments in many challenging real world scenes demonstrate the efficiency and effectiveness of our approach, (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Scene Aware Detection and Block Assignment Tracking in crowded scenes", "paper_id": "WOS:000305726700003"}