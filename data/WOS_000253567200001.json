{"auto_keywords": [{"score": 0.049071348258906654, "phrase": "atmospheric_modeling_application"}, {"score": 0.025910796098196087, "phrase": "lossy_compression_schemes"}, {"score": 0.00481495049065317, "phrase": "message_compression"}, {"score": 0.004192937957960497, "phrase": "large_latency"}, {"score": 0.004163290958633733, "phrase": "low_bandwidth"}, {"score": 0.004133852714087407, "phrase": "major_bottlenecks"}, {"score": 0.004104621766670225, "phrase": "performance_scalability"}, {"score": 0.004075596668736259, "phrase": "response_curves"}, {"score": 0.004046775982578706, "phrase": "latency_shows"}, {"score": 0.004003925104720979, "phrase": "large_message_sizes_latency"}, {"score": 0.003796355951305572, "phrase": "message_size"}, {"score": 0.00346164863873186, "phrase": "compression_schemes"}, {"score": 0.003424972304865554, "phrase": "message_sizes"}, {"score": 0.0033886832371468954, "phrase": "compression_techniques"}, {"score": 0.0033173266816698783, "phrase": "cam"}, {"score": 0.003247319029344241, "phrase": "large_scale_parallel_application"}, {"score": 0.003212906206685004, "phrase": "global_climate_simulation"}, {"score": 0.0031451673059794205, "phrase": "gigabit_interconnect"}, {"score": 0.003089807081149136, "phrase": "floating_point"}, {"score": 0.0030788521585190802, "phrase": "intensive_application"}, {"score": 0.0028881548838751684, "phrase": "large_messages"}, {"score": 0.002748016244165687, "phrase": "cam_application_results"}, {"score": 0.0027092368768921542, "phrase": "lossless_compression"}, {"score": 0.0024789326485851666, "phrase": "acceptability_criteria"}, {"score": 0.0024613749081680474, "phrase": "information_loss"}, {"score": 0.0024094425220967273, "phrase": "perturbation_growth_test_procedure"}, {"score": 0.0023586032632567796, "phrase": "message_size_reduction"}, {"score": 0.002317055705600351, "phrase": "execution_time_speedup"}, {"score": 0.0021503823972534096, "phrase": "lossy_compression_techniques"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["cluster computing", " communication layer", " message compression", " parallel application", " atmospheric modeling"], "paper_abstract": "In this paper, we study the scalability of an atmospheric modeling application on a cluster with commercially available off-the-shelf interconnects. It is found that interconnects with large latency and low bandwidth are major bottlenecks for performance scalability. Response curves for latency shows that for large message sizes latency is extremely sensitive to the size of the message. Thus, decreasing the message size could reduce the latency and hence improve the scalability. We propose both lossless and lossy (i.e., with loss of some information) compression schemes to reduce message sizes. These compression techniques are investigated for the Community Atmospheric Model (CAM), which is a large scale parallel application used for global climate simulation, on a IBM Power 5 Cluster with Gigabit interconnect. This is a floating point intensive application which involves both point-to-point and collective all-to-all communication of large messages ( >128 KB). Floating point data which constitute the messages in CAM application results in 14.8% compression when lossless compression is employed and the speedup improves by about 18% on 32 processors. We further evaluate three lossy compression schemes with very low overheads (0.15%). We study the acceptability criteria for information loss in the lossy compression schemes using a perturbation growth test procedure. The lossy compression schemes achieve a message size reduction of 66.2% and an execution time speedup of up to 20.78 on 32 processors. We also look at the criteria for acceptability of loss of information in lossy compression techniques. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Impact of message compression on the scalability of an atmospheric modeling application on clusters", "paper_id": "WOS:000253567200001"}