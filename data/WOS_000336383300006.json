{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "hadoop"}, {"score": 0.032625335916472056, "phrase": "hail"}, {"score": 0.015597687031641593, "phrase": "hadoop_mapreduce"}, {"score": 0.004684157900507474, "phrase": "important_industry_standard"}, {"score": 0.004647442352794694, "phrase": "massive_parallel_data_processing"}, {"score": 0.00443308765153716, "phrase": "recent_works"}, {"score": 0.004261998281333649, "phrase": "selective_mapreduce_jobs"}, {"score": 0.00414616342377235, "phrase": "existing_approaches"}, {"score": 0.0041136473765874815, "phrase": "high_index_creation_costs"}, {"score": 0.0038473287864224516, "phrase": "hdfs"}, {"score": 0.003757480190200645, "phrase": "different_clustered_indexes"}, {"score": 0.003527998934981411, "phrase": "mapreduce_jobs"}, {"score": 0.0033518704336033874, "phrase": "static_indexing_efficiently_indexes_datasets"}, {"score": 0.003286486670483032, "phrase": "hdfs._thereby"}, {"score": 0.0032223742018434856, "phrase": "default_replication"}, {"score": 0.003134705849154561, "phrase": "logical_replication"}, {"score": 0.0030494153169181334, "phrase": "multiple_clustered_indexes"}, {"score": 0.002931569771634119, "phrase": "physical_replica"}, {"score": 0.002851790448644913, "phrase": "upload_time"}, {"score": 0.0027307746993761035, "phrase": "standard_hdfs."}, {"score": 0.0026986685585382347, "phrase": "hail_adaptive_indexing"}, {"score": 0.0026148807877309417, "phrase": "minimal_runtime_overhead"}, {"score": 0.0025537472239953807, "phrase": "adaptive_indexing"}, {"score": 0.002224510044064184, "phrase": "job_runtimes"}, {"score": 0.002130056082139311, "phrase": "extended_version"}], "paper_keywords": ["Hadoop", " Map reduce", " Indexing", " Adaptive indexing", " Big data", " HDFS", " Physical design"], "paper_abstract": "Hadoop MapReduce has evolved to an important industry standard for massive parallel data processing and has become widely adopted for a variety of use-cases. Recent works have shown that indexes can improve the performance of selective MapReduce jobs dramatically. However, one major weakness of existing approaches is high index creation costs. We present HAIL (Hadoop Aggressive Indexing Library), a novel indexing approach for HDFS and Hadoop MapReduce. HAIL creates different clustered indexes over terabytes of data with minimal, often invisible costs, and it dramatically improves runtimes of several classes of MapReduce jobs. HAIL features two different indexing pipelines, static indexing and adaptive indexing. HAIL static indexing efficiently indexes datasets while uploading them to HDFS. Thereby, HAIL leverages the default replication of Hadoop and enhances it with logical replication. This allows HAIL to create multiple clustered indexes for a dataset, e.g., one for each physical replica. Still, in terms of upload time, HAIL matches or even improves over the performance of standard HDFS. Additionally, HAIL adaptive indexing allows for automatic, incremental indexing at job runtime with minimal runtime overhead. For example, HAIL adaptive indexing can completely index a dataset as byproduct of only four MapReduce jobs while incurring an overhead as low as 11 % for the very first of those job only. In our experiments, we show that HAIL improves job runtimes by up to 68 over Hadoop. This article is an extended version of the VLDB 2012 paper (Dittrich et al. in PVLDB 5(11):1591-1602, 2012).", "paper_title": "Towards zero-overhead static and adaptive indexing in Hadoop", "paper_id": "WOS:000336383300006"}