{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "real_and_synthetic_objects"}, {"score": 0.012931230982774818, "phrase": "real_scene"}, {"score": 0.00470325458481566, "phrase": "novel_image-based_method"}, {"score": 0.004508661664944657, "phrase": "high_degree"}, {"score": 0.004466519142879166, "phrase": "visual_realism"}, {"score": 0.004362870617347183, "phrase": "first_technique"}, {"score": 0.004301834610818624, "phrase": "global_illumination"}, {"score": 0.004009175817816061, "phrase": "geometric_and_material_model"}, {"score": 0.003807242767474929, "phrase": "light_field_interface"}, {"score": 0.003771631577951067, "phrase": "real_and_synthetic_components"}, {"score": 0.003701401653850141, "phrase": "indirect_illumination"}, {"score": 0.0034171734618737436, "phrase": "multiple_bounces"}, {"score": 0.0031399038722901788, "phrase": "time-varying_scenes"}, {"score": 0.003095923814666088, "phrase": "dynamic_objects"}, {"score": 0.0030239842475439814, "phrase": "sharp_contrast"}, {"score": 0.0029816229984366374, "phrase": "alternative_approach"}, {"score": 0.002650857539177183, "phrase": "real-time_applications"}, {"score": 0.0024818877663889813, "phrase": "lens_array"}, {"score": 0.0024586427394152196, "phrase": "video_camera"}, {"score": 0.0024241817763927163, "phrase": "digital_projector"}, {"score": 0.0023678143146455017, "phrase": "full_global_illumination"}, {"score": 0.0023456351719724957, "phrase": "restricted_object_placement"}, {"score": 0.002301896758256575, "phrase": "moderately_specular_materials"}, {"score": 0.002248366278757655, "phrase": "complete_system"}, {"score": 0.0021857667493036786, "phrase": "global_illumination_effects"}, {"score": 0.0021652891317252994, "phrase": "dynamic_real_and_synthetic_objects"}, {"score": 0.0021049977753042253, "phrase": "single_point_light_source"}], "paper_keywords": ["augmented reality", " global illumination", " light field", " image-based relighting"], "paper_abstract": "We present a novel image-based method for compositing real and synthetic objects in the same scene with a high degree of visual realism. Ours is the first technique to allow global illumination and near-field lighting effects between both real and synthetic objects at interactive rates, without needing a geometric and material model of the real scene. We achieve this by using a light field interface between real and synthetic components-thus, indirect illumination can be simulated using only two 4D light fields, one captured from and one projected onto the real scene. Multiple bounces of inter-reflections are obtained simply by iterating this approach. The inter-activity of our technique enables its use with time-varying scenes, including dynamic objects. This is in sharp contrast to the alternative approach of using 6D or 8D light transport functions of real objects, which are very expensive in terms of acquisition and storage and hence not suitable for real-time applications. In our method, 4D radiance fields are simultaneously captured and projected by using a lens array, video camera, and digital projector. The method supports full global illumination with restricted object placement, and accommodates moderately specular materials. We implement a complete system and show several example scene compositions that demonstrate global illumination effects between dynamic real and synthetic objects. Our implementation requires a single point light source and dark background.", "paper_title": "Light field transfer: Global illumination between real and synthetic objects", "paper_id": "WOS:000258262000046"}