{"auto_keywords": [{"score": 0.04629659038512855, "phrase": "ap"}, {"score": 0.00481495049065317, "phrase": "spectral_clustering"}, {"score": 0.004741395005218184, "phrase": "high-quality_clusterings"}, {"score": 0.004692980391580608, "phrase": "small_data_sets"}, {"score": 0.004645057834614705, "phrase": "computational_cost"}, {"score": 0.004527371799277529, "phrase": "large_data_sets"}, {"score": 0.004481132747216135, "phrase": "affinity_propagation"}, {"score": 0.004127753467337283, "phrase": "parameter_'preference"}, {"score": 0.003982011128052839, "phrase": "optimal_clustering_solution"}, {"score": 0.0035932440062595252, "phrase": "novel_fast_two-stage_spectral_clustering_framework"}, {"score": 0.003143849342926373, "phrase": "high-quality_graph"}, {"score": 0.0028807718824400697, "phrase": "data_sets"}, {"score": 0.0026261108615242557, "phrase": "small_number"}, {"score": 0.0025992391074270097, "phrase": "final_representative_exemplars"}, {"score": 0.002533253511622532, "phrase": "simple_and_efficient_sampling_scheme"}, {"score": 0.002456272788591051, "phrase": "density-weighted_low-rank_approximation"}, {"score": 0.0023694065215394593, "phrase": "representative_exemplars"}, {"score": 0.0023331227492950422, "phrase": "global_underlying_structure"}, {"score": 0.002309242063033298, "phrase": "data_manifold"}, {"score": 0.0022856052476424344, "phrase": "experimental_results"}, {"score": 0.0022161333611134806, "phrase": "state-of-the-art_spectral_clustering"}, {"score": 0.0021049977753042253, "phrase": "memory_usage"}], "paper_keywords": ["Clustering", " Data mining", " Affinity propagation", " Spectral clustering", " Nystrom approximation", " Manifold structure"], "paper_abstract": "While spectral clustering can produce high-quality clusterings on small data sets, computational cost makes it infeasible for large data sets. Affinity Propagation (AP) has a limitation that it is hard to determine the value of parameter 'preference' which can lead to an optimal clustering solution. These problems limit the scope of application of the two methods. In this paper, we develop a novel fast two-stage spectral clustering framework with local and global consistency. Under this framework, we propose a Fast density-Weighted low-rank Approximation Spectral Clustering (FWASC) algorithm to address the above issues. The proposed algorithm is a high-quality graph partitioning method, and simultaneously considers both the local and global structure information contained in the data sets. Specifically, we first present a new Fast Two-Stage AP (FTSAP) algorithm to coarsen the input sparse graph and produce a small number of final representative exemplars, which is a simple and efficient sampling scheme. Then we present a density-weighted low-rank approximation spectral clustering algorithm to operate those representative exemplars on the global underlying structure of data manifold. Experimental results show that our algorithm outperforms the state-of-the-art spectral clustering and original AP algorithms in terms of speed, memory usage, and quality.", "paper_title": "Fast density-weighted low-rank approximation spectral clustering", "paper_id": "WOS:000289685300005"}