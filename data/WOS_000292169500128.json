{"auto_keywords": [{"score": 0.03537870345379016, "phrase": "eye_and_mouth_regions"}, {"score": 0.00481495049065317, "phrase": "neural_network_models"}, {"score": 0.003997343989408636, "phrase": "proposed_emotion_recognition_study"}, {"score": 0.0039322149318145845, "phrase": "required_video_data"}, {"score": 0.003784328428527216, "phrase": "center_for_education_technology"}, {"score": 0.003661987063211563, "phrase": "indian_institute_of_technology"}, {"score": 0.003622096242457086, "phrase": "iit"}, {"score": 0.003524227590204673, "phrase": "dynamic_nature"}, {"score": 0.003466780226380516, "phrase": "grey_values"}, {"score": 0.003175792987190496, "phrase": "specific_knowledge"}, {"score": 0.0031240075437664314, "phrase": "facial_expressions"}, {"score": 0.0030899524399043863, "phrase": "multiscale_morphological_erosion_and_dilation_operations"}, {"score": 0.0028460640294160383, "phrase": "left_eye"}, {"score": 0.0028150302583265655, "phrase": "right_eye_and_mouth_regions"}, {"score": 0.0027239390917424898, "phrase": "separate_models"}, {"score": 0.002679501909303057, "phrase": "emotion_category"}, {"score": 0.0025645065536826013, "phrase": "aann"}, {"score": 0.0024143815950383647, "phrase": "extracted_features"}, {"score": 0.0023749823753904204, "phrase": "developed_models"}, {"score": 0.002323446065342625, "phrase": "subject_dependent_and_independent_emotion_recognition_studies"}, {"score": 0.0022359278646792153, "phrase": "proposed_emotion_recognition_system"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Emotion recognition", " Eye and mouth region", " Autoassociative neural network (AANN)", " Multiscale morphological erosion and dilation"], "paper_abstract": "In this paper, facial features from the video sequence are explored for characterizing the emotions. The emotions considered for this study are Anger, Fear, Happy, Sad and Neutral. For carrying out the proposed emotion recognition study, the required video data is collected from the studio, Center for Education Technology (CET), at Indian Institute of Technology (IIT) Kharagpur. The dynamic nature of the grey values of the pixels within the eye and mouth regions are used as the features to capture the emotion specific knowledge from the facial expressions. Multiscale morphological erosion and dilation operations are used to extract features from eye and mouth regions, respectively. The features extracted from left eye, right eye and mouth regions are used to develop the separate models for each emotion category. Auto-associative neural network (AANN) models are used to capture the distribution of the extracted features. The developed models are validated using subject dependent and independent emotion recognition studies. The overall performance of the proposed emotion recognition system is observed to be about 87%. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Recognition of emotions from video using neural network models", "paper_id": "WOS:000292169500128"}