{"auto_keywords": [{"score": 0.0456315961504987, "phrase": "adp"}, {"score": 0.00481495049065317, "phrase": "on-line_learning"}, {"score": 0.004670896353428476, "phrase": "adaptive_dynamic_programming"}, {"score": 0.004422325007817267, "phrase": "novel_adaptive_dynamic_programming"}, {"score": 0.003845313870879042, "phrase": "internal_goal-representation"}, {"score": 0.003640516896245813, "phrase": "traditional_adp_design"}, {"score": 0.0035530197642369464, "phrase": "action_network"}, {"score": 0.0034887749053459584, "phrase": "critic_network"}, {"score": 0.003384262486955773, "phrase": "third_network"}, {"score": 0.003223494720348768, "phrase": "actor-critic_design_framework"}, {"score": 0.003089080923888397, "phrase": "internal_reinforcement_signal"}, {"score": 0.00303319936111073, "phrase": "learning_and_optimization_overtime"}, {"score": 0.0028890603352364273, "phrase": "detailed_design_architecture"}, {"score": 0.002636956926079255, "phrase": "new_adp_architecture"}, {"score": 0.002436289099444074, "phrase": "cart-pole_balancing_task"}, {"score": 0.002392188222609101, "phrase": "triple-link_inverted_pendulum"}, {"score": 0.0022923586577645143, "phrase": "popular_benchmarks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Adaptive dynamic programming", " Online learning and control", " Actor-critic design", " Three-network architecture", " Multi-state optimization", " Goal representation", " Reinforcement learning"], "paper_abstract": "In this paper, we propose a novel adaptive dynamic programming (ADP) architecture with three networks, an action network, a critic network, and a reference network, to develop internal goal-representation for online learning and optimization. Unlike the traditional ADP design normally with an action network and a critic network, our approach integrates the third network, a reference network, into the actor-critic design framework to automatically and adaptively build an internal reinforcement signal to facilitate learning and optimization overtime to accomplish goals. We present the detailed design architecture and its associated learning algorithm to explain how effective learning and optimization can be achieved in this new ADP architecture. Furthermore, we test the performance of our architecture both on the cart-pole balancing task and the triple-link inverted pendulum balancing task, which are the popular benchmarks in the community to demonstrate its learning and control performance over time. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "A three-network architecture for on-line learning and optimization based on adaptive dynamic programming", "paper_id": "WOS:000298528200002"}