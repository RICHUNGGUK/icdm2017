{"auto_keywords": [{"score": 0.05007718078584304, "phrase": "partial_least_squares"}, {"score": 0.028962429851037672, "phrase": "cca"}, {"score": 0.004671932143798307, "phrase": "recent_advances"}, {"score": 0.004451846834142146, "phrase": "efficient_multivariate_statistical_regression_technique"}, {"score": 0.004165987300206134, "phrase": "highly_collinear_data"}, {"score": 0.00406663414150229, "phrase": "response_variables_y_based_independent_variables_x"}, {"score": 0.0040178735376279265, "phrase": "pls"}, {"score": 0.0038516336597530614, "phrase": "common_orthogonal_latent_variables"}, {"score": 0.0036700484729006136, "phrase": "new_subspace"}, {"score": 0.0035609154384221567, "phrase": "increasing_interest"}, {"score": 0.0035181731203867456, "phrase": "multi-way_analysis"}, {"score": 0.0034135407979996673, "phrase": "multilinear_regression_model"}, {"score": 0.003232956879952914, "phrase": "two-multidimensional_tensor_data"}, {"score": 0.00306189690236109, "phrase": "pls-related_methods"}, {"score": 0.0029351141718104725, "phrase": "nonlinear_variants"}, {"score": 0.0027630232270330402, "phrase": "canonical_correlation_analysis"}, {"score": 0.0026646374739979694, "phrase": "similar_technique"}, {"score": 0.0021049977753042253, "phrase": "classification_techniques"}], "paper_keywords": [""], "paper_abstract": "Partial least squares (PLS) is an efficient multivariate statistical regression technique that has shown to be particularly useful for analysis of highly collinear data. To predict response variables Y based independent variables X, PLS attempts to find a set of common orthogonal latent variables by projecting both X and Y onto a new subspace respectively. As an increasing interest in multi-way analysis, the extension to multilinear regression model is also developed with the aim to analyzing two-multidimensional tensor data. In this article, we overview the PLS-related methods including linear, multilinear, and nonlinear variants and discuss the strength of the algorithms. As canonical correlation analysis (CCA) is another similar technique with the aim to extract the most correlated latent components between two datasets, we also briefly discuss the extension of CCA to tensor space. Finally, several examples are given to compare these methods with respect to the regression and classification techniques. Conflict of interest: The authors have declared no conflicts of interest for this article.", "paper_title": "Multilinear and nonlinear generalizations of partial least squares: an overview of recent advances", "paper_id": "WOS:000331918900020"}