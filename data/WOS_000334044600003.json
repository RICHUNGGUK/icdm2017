{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "rank_aggregation"}, {"score": 0.004761968711051715, "phrase": "feature_selection"}, {"score": 0.004709567162738894, "phrase": "well-developed_research_area"}, {"score": 0.004623503587186056, "phrase": "ongoing_need"}, {"score": 0.0043584824527198055, "phrase": "universal_feature_selection_technique"}, {"score": 0.004310501708408856, "phrase": "similar_outcomes"}, {"score": 0.004139028737420222, "phrase": "feature_selection_techniques"}, {"score": 0.004108589735101849, "phrase": "individual_statistical_biases"}, {"score": 0.0040334640350288, "phrase": "different_statistical_properties"}, {"score": 0.003930581102447622, "phrase": "numerous_situations"}, {"score": 0.0037463983616303786, "phrase": "selection_method"}, {"score": 0.0036508108698357932, "phrase": "vast_range"}, {"score": 0.0034540850937966306, "phrase": "consensus_properties"}, {"score": 0.003316567137142017, "phrase": "ensemble_nature"}, {"score": 0.002882160722418316, "phrase": "robustness_index"}, {"score": 0.0027982016314450717, "phrase": "extensive_empirical_evaluation"}, {"score": 0.0027571412070078703, "phrase": "eight_datasets"}, {"score": 0.0027368368719283298, "phrase": "different_dimensions"}, {"score": 0.0026867260506696455, "phrase": "lung_cancer"}, {"score": 0.00266693888510356, "phrase": "madelon"}, {"score": 0.0026277995163948263, "phrase": "internet_ads"}, {"score": 0.0025892330566358503, "phrase": "embryonal_tumor"}, {"score": 0.002551231163230566, "phrase": "real-world_dataset"}, {"score": 0.002258212866482022, "phrase": "classification_accuracy"}, {"score": 0.0021049977753042253, "phrase": "wide_range"}], "paper_keywords": [""], "paper_abstract": "Although feature selection is a well-developed research area, there is an ongoing need to develop methods to make classifiers more efficient. One important challenge is the lack of a universal feature selection technique that produces similar outcomes with all types of classifiers. This is because all feature selection techniques have individual statistical biases, whereas classifiers exploit different statistical properties of data for evaluation. In numerous situations, this can put researchers into dilemma with regard to which feature selection method and classifiers to choose from a vast range of choices. In this article, we propose a technique that aggregates the consensus properties of various feature selection methods in order to develop a more optimal solution. The ensemble nature of our technique makes it more robust across various classifiers. In other words, it is stable toward achieving similar and, ideally, higher classification accuracy across a wide variety of classifiers. We quantify this concept of robustness with a measure known as the robustness index (RI). We perform an extensive empirical evaluation of our technique on eight datasets with different dimensions, including arrythmia, lung cancer, Madelon, mfeat-fourier, Internet ads, leukemia-3c, embryonal tumor, and a real-world dataset, vis., acute myeloid leukemia (AML). We demonstrate not only that our algorithm is more robust, but also that, compared with other techniques, our algorithm improves the classification accuracy by approximately 3-4% in a dataset with fewer than 500 features and by more than 5% in a dataset with more than 500 features, across a wide range of classifiers.", "paper_title": "Robust Feature Selection Technique Using Rank Aggregation", "paper_id": "WOS:000334044600003"}