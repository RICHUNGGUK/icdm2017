{"auto_keywords": [{"score": 0.04314074539597285, "phrase": "nearest_neighbors"}, {"score": 0.00481495049065317, "phrase": "similarity_search_algorithms"}, {"score": 0.004776669953449352, "phrase": "multi-core_architectures"}, {"score": 0.004719816332271661, "phrase": "recent_times"}, {"score": 0.004682288586254123, "phrase": "large_high-dimensional_datasets"}, {"score": 0.004589763483242731, "phrase": "video_and_image_repositories"}, {"score": 0.004254467919664946, "phrase": "data_items"}, {"score": 0.004088413112926435, "phrase": "nn"}, {"score": 0.003943569631183138, "phrase": "common_query"}, {"score": 0.0038655854071187115, "phrase": "multiple_sets"}, {"score": 0.003714195746979591, "phrase": "different_query_items"}, {"score": 0.0036262124965265015, "phrase": "commodity_multi-core_cpus"}, {"score": 0.003526186748088922, "phrase": "lower_costs"}, {"score": 0.0034841647157189985, "phrase": "parallel_algorithms"}, {"score": 0.0034426417353349567, "phrase": "search_problems"}, {"score": 0.003334309053314909, "phrase": "core_nearest_neighbor_search_problem"}, {"score": 0.0028076592725295646, "phrase": "query_workloads"}, {"score": 0.0026022112631368223, "phrase": "query_throughput"}, {"score": 0.002581477142020187, "phrase": "parallelized_versions"}, {"score": 0.002530359917257626, "phrase": "high-dimensional_multi-nn_search_algorithms"}, {"score": 0.0022174005294867583, "phrase": "near-optimal_performance"}, {"score": 0.0021821915946356168, "phrase": "un-tuned_versions"}, {"score": 0.0021647968783414504, "phrase": "parallel_multi-nn_algorithms"}, {"score": 0.002147540520631409, "phrase": "real_video_repository_data"}, {"score": 0.0021049977753042253, "phrase": "multi-core_platforms"}], "paper_keywords": ["Nearest neighbor search", " Auto-tuning", " Parallelization"], "paper_abstract": "In recent times, large high-dimensional datasets have become ubiquitous. Video and image repositories, financial, and sensor data are just a few examples of such datasets in practice. Many applications that use such datasets require the retrieval of data items similar to a given query item, or the nearest neighbors (NN or -NN) of a given item. Another common query is the retrieval of multiple sets of nearest neighbors, i.e., multi -NN, for different query items on the same data. With commodity multi-core CPUs becoming more and more widespread at lower costs, developing parallel algorithms for these search problems has become increasingly important. While the core nearest neighbor search problem is relatively easy to parallelize, it is challenging to tune it for optimality. This is due to the fact that the various performance-specific algorithmic parameters, or \"tuning knobs\", are inter-related and also depend on the data and query workloads. In this paper, we present (1) a detailed study of the various tuning knobs and their contributions on increasing the query throughput for parallelized versions of the two most common classes of high-dimensional multi-NN search algorithms: linear scan and tree traversal, and (2) an offline auto-tuner for setting these knobs by iteratively measuring actual query execution times for a given workload and dataset. We show experimentally that our auto-tuner reaches near-optimal performance and significantly outperforms un-tuned versions of parallel multi-NN algorithms for real video repository data on a variety of multi-core platforms.", "paper_title": "Auto-tuning Similarity Search Algorithms on Multi-core Architectures", "paper_id": "WOS:000320285000001"}