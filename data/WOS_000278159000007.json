{"auto_keywords": [{"score": 0.00467855218490191, "phrase": "nonconvex_penalty"}, {"score": 0.004581615352991099, "phrase": "l"}, {"score": 0.003965684670332574, "phrase": "reweighed_iterative_algorithm"}], "paper_keywords": ["machine learning", " variable selection", " regularizer", " compressed sensing"], "paper_abstract": "In this paper we propose an L (1/2) regularizer which has a nonconvex penalty. The L (1/2) regularizer is shown to have many promising properties such as unbiasedness, sparsity and oracle properties. A reweighed iterative algorithm is proposed so that the solution of the L (1/2) regularizer can be solved through transforming it into the solution of a series of L (1) regularizers. The solution of the L (1/2) regularizer is more sparse than that of the L (1) regularizer, while solving the L (1/2) regularizer is much simpler than solving the L (0) regularizer. The experiments show that the L (1/2) regularizer is very useful and efficient, and can be taken as a representative of the L (p) (0 > p > 1)regularizer.", "paper_title": "L (1/2) regularization", "paper_id": "WOS:000278159000007"}