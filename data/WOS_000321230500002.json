{"auto_keywords": [{"score": 0.04119507495012034, "phrase": "unimpaired_speech"}, {"score": 0.00481495049065317, "phrase": "background_models"}, {"score": 0.004777392826700429, "phrase": "dysarthric_speech_recognition"}, {"score": 0.004740126725341152, "phrase": "speech_production_errors"}, {"score": 0.004575977644865379, "phrase": "low_accuracy"}, {"score": 0.00454027551702508, "phrase": "automatic_speech_recognition"}, {"score": 0.004504863841693066, "phrase": "asr"}, {"score": 0.0041981583430961734, "phrase": "rather_reduced_acoustic_working_space"}, {"score": 0.004100620365805411, "phrase": "speech_acoustics"}, {"score": 0.003547084456662448, "phrase": "currently_well-studied_adaptation_algorithms"}, {"score": 0.0033708244679086265, "phrase": "population_characteristics"}, {"score": 0.003241203549050267, "phrase": "interpolation-based_technique"}, {"score": 0.0031907572162427978, "phrase": "prior_acoustic_model"}, {"score": 0.0030440661915657175, "phrase": "dysarthric_talker"}, {"score": 0.002973261772253616, "phrase": "'background'_model"}, {"score": 0.0029384777371425862, "phrase": "dysarthric_talker's_general_speech_characteristics"}, {"score": 0.0027814417101979317, "phrase": "speaker-independent_model"}, {"score": 0.0026327757304477665, "phrase": "dysarthric_speech"}, {"score": 0.002551409948440577, "phrase": "sixteen_talkers"}, {"score": 0.002531463482341473, "phrase": "varying_levels"}, {"score": 0.002511672561475743, "phrase": "dysarthria_severity"}, {"score": 0.0024245061478930558, "phrase": "interpolation_technique"}, {"score": 0.0023588019302482367, "phrase": "well-known_maximum"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["HMM", " Dysarthria", " Acoustic model", " Adaptation", " UBM", " MAP"], "paper_abstract": "Speech production errors characteristic of dysarthria are chiefly responsible for the low accuracy of automatic speech recognition (ASR) when used by people diagnosed with it. A person with dysarthria produces speech in a rather reduced acoustic working space, causing typical measures of speech acoustics to have values in ranges very different from those characterizing unimpaired speech. It is unlikely then that models trained on unimpaired speech will be able to adjust to this mismatch when acted on by one of the currently well-studied adaptation algorithms (which make no attempt to address this extent of mismatch in population characteristics). In this work, we propose an interpolation-based technique for obtaining a prior acoustic model from one trained on unimpaired speech, before adapting it to the dysarthric talker. The method computes a 'background' model of the dysarthric talker's general speech characteristics and uses it to obtain a more suitable prior model for adaptation (compared to the speaker-independent model trained on unimpaired speech). The approach is tested with a corpus of dysarthric speech acquired by our research group, on speech of sixteen talkers with varying levels of dysarthria severity (as quantified by their intelligibility). This interpolation technique is tested in conjunction with the well-known maximum a posteriori (MAP) adaptation algorithm, and yields improvements of up to 8% absolute and up to 40% relative, over the standard MAP adapted baseline. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Acoustic model adaptation using in-domain background models for dysarthric speech recognition", "paper_id": "WOS:000321230500002"}