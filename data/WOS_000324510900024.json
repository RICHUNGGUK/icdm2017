{"auto_keywords": [{"score": 0.039981178811681256, "phrase": "mdslcs_algorithm"}, {"score": 0.028640399368116798, "phrase": "mdslcs"}, {"score": 0.00481495049065317, "phrase": "dynamic_hand_gesture_classification"}, {"score": 0.004643055780443262, "phrase": "dynamic_gestures"}, {"score": 0.004597244847332915, "phrase": "representative_sub-segments"}, {"score": 0.004374852170791322, "phrase": "automatic_extraction"}, {"score": 0.004204676524824095, "phrase": "full_gestures"}, {"score": 0.004081501148360605, "phrase": "mds"}, {"score": 0.003708086804757529, "phrase": "modified_longest_common_subsequence"}, {"score": 0.0035637545647574853, "phrase": "data_stream"}, {"score": 0.0035402494307399733, "phrase": "adaptive_window_parameters"}, {"score": 0.003459191419478298, "phrase": "successive_results"}, {"score": 0.0034363735647539267, "phrase": "multiple_calls"}, {"score": 0.0034024277222012597, "phrase": "lcs_classifier"}, {"score": 0.0033576858946833587, "phrase": "preprocessing_stage"}, {"score": 0.0033025823350563087, "phrase": "large_motion_variations"}, {"score": 0.0032376465741070274, "phrase": "lesser_variation"}, {"score": 0.0031634950012560384, "phrase": "adaptive_clustering"}, {"score": 0.003132236287543072, "phrase": "training_set"}, {"score": 0.0030504336050891185, "phrase": "lcs"}, {"score": 0.0030003014343035965, "phrase": "gesture_trajectories"}, {"score": 0.0029706504420983896, "phrase": "mdslcs_classifier"}, {"score": 0.0029412916164128925, "phrase": "gesture_recognition_rate"}, {"score": 0.0028549396580672417, "phrase": "pre-cut_free_hand_digit"}, {"score": 0.00280806350681826, "phrase": "hidden_markov_models"}, {"score": 0.002636828502928141, "phrase": "streamed_digit_gestures"}, {"score": 0.0025340874787959195, "phrase": "hmms_method"}, {"score": 0.002427286272201272, "phrase": "motion_trajectories"}, {"score": 0.0023795195973873636, "phrase": "higher_accuracy_rate"}, {"score": 0.002363806685815014, "phrase": "pre-cut_gestures"}, {"score": 0.0023019834179097607, "phrase": "streamed_gestures"}, {"score": 0.0022641658133181115, "phrase": "significant_advantage"}, {"score": 0.002147265537489893, "phrase": "small_training_sets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Gesture recognition", " Classification", " Longest common subsequence", " Digits"], "paper_abstract": "In this work, we consider the recognition of dynamic gestures based on representative sub-segments of a gesture, which are denoted as most discriminating segments (MDSs). The automatic extraction and recognition of such small representative segments, rather than extracting and recognizing the full gestures themselves, allows for a more discriminative classifier. A MDS is a sub-segment of a gesture that is most dissimilar to all other gesture sub-segments. Gestures are classified using a MDSLCS algorithm, which recognizes the MDSs using a modified longest common subsequence (LCS) measure. The extraction of MDSs from a data stream uses adaptive window parameters, which are driven by the successive results of multiple calls to the LCS classifier. In a preprocessing stage, gestures that have large motion variations are replaced by several forms of lesser variation. We learn these forms by adaptive clustering of a training set of gestures, where we reemploy the LCS to determine similarity between gesture trajectories. The MDSLCS classifier achieved a gesture recognition rate of 92.6% when tested using a set of pre-cut free hand digit (0-9) gestures, while hidden Markov models (HMMs) achieved an accuracy of 89.5%. When the MDSLCS was tested against a set of streamed digit gestures, an accuracy of 89.6% was obtained. At present the HMMs method is considered the state-of-the-art method for classifying motion trajectories. The MDSLCS algorithm had a higher accuracy rate for pre-cut gestures, and is also more suitable for streamed gestures. MDSLCS provides a significant advantage over HMMs by not requiring data re-sampling during run-time and performing well with small training sets. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Most discriminating segment - Longest common subsequence (MDSLCS) algorithm for dynamic hand gesture classification", "paper_id": "WOS:000324510900024"}