{"auto_keywords": [{"score": 0.04941887286567744, "phrase": "nonlinear_dimensionality_reduction"}, {"score": 0.03939520645819033, "phrase": "mvu"}, {"score": 0.00481495049065317, "phrase": "local_and_global_information"}, {"score": 0.004586531354697466, "phrase": "challenging_problem"}, {"score": 0.004399349717218995, "phrase": "high_dimensional_data_analysis"}, {"score": 0.004308630865024719, "phrase": "machine_learning"}, {"score": 0.004249188865832993, "phrase": "pattern_recognition"}, {"score": 0.004190563478825626, "phrase": "scientific_visualization"}, {"score": 0.004104132253183181, "phrase": "neural_computation"}, {"score": 0.003964007795174772, "phrase": "different_geometric_intuitions"}, {"score": 0.0036722834182246933, "phrase": "laplacian_eigenmaps"}, {"score": 0.0035222812668916736, "phrase": "different_aspects"}, {"score": 0.003196443585731476, "phrase": "laplacian"}, {"score": 0.0030650070965891653, "phrase": "new_nonlinear_dimensionality_reduction_method"}, {"score": 0.002879030825408203, "phrase": "dve"}, {"score": 0.002742196991950893, "phrase": "global_variance"}, {"score": 0.00266693888510356, "phrase": "proximity_relation_preservation_constraint"}, {"score": 0.0026118503041971976, "phrase": "laplacian_eigemnaps"}, {"score": 0.0024876840172100567, "phrase": "easily_visualized_examples"}, {"score": 0.0023043558058824572, "phrase": "actual_images"}, {"score": 0.002272501735900584, "phrase": "rotating_objects"}, {"score": 0.0021947755130109696, "phrase": "handwritten_digits"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Manifold learning", " Dimensionality reduction", " Variance analysis", " Image manifolds"], "paper_abstract": "Nonlinear dimensionality reduction is a challenging problem encountered in a variety of high dimensional data analysis, including machine learning, pattern recognition, scientific visualization, and neural computation. Based on the different geometric intuitions of manifolds, maximum variance unfolding (MVU) and Laplacian eigenmaps are designed for detecting the different aspects of dataset. In this paper, combining the ideas of MVU and Laplacian eigenmaps, we propose a new nonlinear dimensionality reduction method called distinguishing variance embedding (DVE). DVE unfolds the dataset by maximizing the global variance subject to the proximity relation preservation constraint originated in Laplacian eigemnaps. We illustrate the algorithm on easily visualized examples of curves and surfaces, as well as on the actual images of rotating objects, faces, and handwritten digits. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Combining local and global information for nonlinear dimensionality reduction", "paper_id": "WOS:000266702300019"}