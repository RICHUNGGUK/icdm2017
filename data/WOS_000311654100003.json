{"auto_keywords": [{"score": 0.04113078712184245, "phrase": "fpgas"}, {"score": 0.00481495049065317, "phrase": "pipelined_computational_cores"}, {"score": 0.0047395356621991935, "phrase": "increased_capacity"}, {"score": 0.00468991337957911, "phrase": "enhanced_features"}, {"score": 0.004640808212832262, "phrase": "modern_fpgas"}, {"score": 0.004592214823540993, "phrase": "new_opportunities"}, {"score": 0.004496542293425754, "phrase": "application_accelerators"}, {"score": 0.004265953661191515, "phrase": "mainstream_acceleration_solutions"}, {"score": 0.0042212686864468805, "phrase": "long_design_cycles"}, {"score": 0.004089991141220082, "phrase": "high-level_synthesis_tools"}, {"score": 0.003962779958955344, "phrase": "current_hls_tools"}, {"score": 0.003819339842998955, "phrase": "inefficient_use"}, {"score": 0.0037793152987497286, "phrase": "deeply_pipelined_arithmetic_operators"}, {"score": 0.0036810726176482278, "phrase": "high-throughput_fpga_designs"}, {"score": 0.0035477930970463432, "phrase": "efficient_generation"}, {"score": 0.0035106041824568618, "phrase": "fpga-specific_hardware_accelerators"}, {"score": 0.0034193226278107346, "phrase": "perfect_loop_nests"}, {"score": 0.003383475802364289, "phrase": "inner_statements"}, {"score": 0.0032954888655173666, "phrase": "pipelined_arithmetic_operator"}, {"score": 0.0031594291695784286, "phrase": "scientific_codes"}, {"score": 0.0031262984171100856, "phrase": "floating-point_arithmetic"}, {"score": 0.0030449789178940787, "phrase": "semi-automatic_code_generation_process"}, {"score": 0.002798662730881037, "phrase": "initial_program_execution"}, {"score": 0.002711506442590442, "phrase": "operator's_pipeline"}, {"score": 0.0025722202862084186, "phrase": "memory_access"}, {"score": 0.0023640560785711923, "phrase": "control_fsms"}, {"score": 0.002339246282204109, "phrase": "multiple_parallel_computing_cores"}, {"score": 0.002219040041886641, "phrase": "application's_accuracy"}, {"score": 0.002172701452347454, "phrase": "smaller_and_faster_operators"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["High-level synthesis", " FPGA", " Data-reuse", " Polyhedral compilation", " Pipelined arithmetic operators", " Floating-point", " Parallelization", " Kernel accuracy"], "paper_abstract": "The increased capacity and enhanced features of modern FPGAs opens new opportunities for their use as application accelerators. However, for FPGAs to be accepted as mainstream acceleration solutions, long design cycles must be shortened by using high-level synthesis tools in the design process. Current HLS tools targeting FPGAs have several limitations including the inefficient use of deeply pipelined arithmetic operators, commonly encountered in high-throughput FPGA designs. We focus here on the efficient generation of FPGA-specific hardware accelerators for regular codes with perfect loop nests where inner statements are implemented as a pipelined arithmetic operator, which is often the case of scientific codes using floating-point arithmetic. We propose a semi-automatic code generation process where the arithmetic operator is identified and generated. Its pipeline information is used to reschedule the initial program execution in order to keep the operator's pipeline as \"busy\" as possible, while minimizing memory access. Next, we show how our method can be used as a tool to generate control FSMs for multiple parallel computing cores. Finally, we show that accounting for the application's accuracy needs allows designing smaller and faster operators. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "FPGA-specific synthesis of loop-nests with pipelined computational cores", "paper_id": "WOS:000311654100003"}