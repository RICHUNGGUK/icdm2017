{"auto_keywords": [{"score": 0.04970198387475844, "phrase": "video_conferencing"}, {"score": 0.044030975314321714, "phrase": "far_end"}, {"score": 0.0340938190470123, "phrase": "meeting_participants"}, {"score": 0.00481495049065317, "phrase": "improved_visual_perception"}, {"score": 0.004702092660370367, "phrase": "video_conferencing_setting"}, {"score": 0.00459186790405058, "phrase": "elongated_meeting_table"}, {"score": 0.00453772385360173, "phrase": "major_axis"}, {"score": 0.004484215355348556, "phrase": "camera_direction"}, {"score": 0.00443133501650381, "phrase": "standard_wide-angle_perspective_image"}, {"score": 0.004344577216137524, "phrase": "significant_foreshortening"}, {"score": 0.003812896124654341, "phrase": "remote_participants"}, {"score": 0.0034674164050273568, "phrase": "waste_of_the_screen_space_and_network_bandwidth"}, {"score": 0.003115908199991072, "phrase": "novel_technique"}, {"score": 0.0030791137853734152, "phrase": "spatially-varying-uniform"}, {"score": 0.002947868524740683, "phrase": "head_sizes"}, {"score": 0.0028786467218197245, "phrase": "undue_distortion"}, {"score": 0.002456816881853114, "phrase": "camera_arrays"}, {"score": 0.002324238863944163, "phrase": "hardware_devices"}, {"score": 0.0023058910418682676, "phrase": "image_capturing"}, {"score": 0.0022606512324475584, "phrase": "head-size_equalization"}, {"score": 0.0022250978492127163, "phrase": "real_time"}, {"score": 0.002155656133617155, "phrase": "user_study"}, {"score": 0.0021049977753042253, "phrase": "head-size_equalized_images"}], "paper_keywords": ["head-size equalization", " video conferencing", " visual", " perception"], "paper_abstract": "In a video conferencing setting, people often use an elongated meeting table with the major axis along the camera direction. A standard wide-angle perspective image of this setting creates significant foreshortening, thus the people sitting at the far end of the table appear very small relative to those nearer the camera. This has two consequences. First, it is difficult for the remote participants to see the faces of those at the far end, thus affecting the experience of the video conferencing. Second, it is a waste of the screen space and network bandwidth because most of the pixels are used on the background instead of on the faces of the meeting participants. In this paper, we present a novel technique, called Spatially-Varying-Uniform scaling functions, to warp the images to equalize the head sizes of the meeting participants without causing undue distortion. This technique works for both the 180-degree views where the camera is placed at one end of the table and the 360-degree views where the camera is placed at the center of the table. We have implemented this algorithm on two types of camera arrays: one with 180-degree view, and the other with 360-degree view. On both hardware devices, image capturing, stitching, and head-size equalization are run in real time. In addition, we have conducted user study showing that people clearly prefer head-size equalized images.", "paper_title": "Head-size equalization for improved visual perception in video conferencing", "paper_id": "WOS:000250447400016"}