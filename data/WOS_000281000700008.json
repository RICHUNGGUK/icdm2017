{"auto_keywords": [{"score": 0.04512493687942277, "phrase": "density_estimation"}, {"score": 0.04448671687401457, "phrase": "support_vector_machine"}, {"score": 0.004767546015485477, "phrase": "nonparametric_kernel_methods"}, {"score": 0.004492717291734985, "phrase": "well-known_examples"}, {"score": 0.00442651096522781, "phrase": "kernel_density_estimate"}, {"score": 0.004382925660903583, "phrase": "kde"}, {"score": 0.0040491842732233154, "phrase": "kernel_classifier"}, {"score": 0.0038535940121005334, "phrase": "ise"}, {"score": 0.0036133077234252633, "phrase": "gaussian_kernel"}, {"score": 0.0031453010852936334, "phrase": "quadratic_program"}, {"score": 0.00308357048262018, "phrase": "statistical_performance_guarantees"}, {"score": 0.0029490571526071016, "phrase": "finite_sample_oracle_inequality"}, {"score": 0.002724207384182295, "phrase": "special_case"}, {"score": 0.0026443691099806003, "phrase": "previously_introduced_ise-based_method"}, {"score": 0.002278856202878812, "phrase": "natural_regularization_parameter"}, {"score": 0.002147180332779021, "phrase": "high_dimensions"}, {"score": 0.0021259846592569386, "phrase": "simulation_results"}], "paper_keywords": ["Kernel methods", " sparse classifiers", " integrated squared error", " difference of densities", " SMO algorithm"], "paper_abstract": "Nonparametric kernel methods are widely used and proven to be successful in many statistical learning problems. Well-known examples include the kernel density estimate (KDE) for density estimation and the support vector machine (SVM) for classification. We propose a kernel classifier that optimizes the L-2 or integrated squared error (ISE) of a \"difference of densities.\" We focus on the Gaussian kernel, although the method applies to other kernels suitable for density estimation. Like a support vector machine (SVM), the classifier is sparse and results from solving a quadratic program. We provide statistical performance guarantees for the proposed L-2 kernel classifier in the form of a finite sample oracle inequality and strong consistency in the sense of both ISE and probability of error. A special case of our analysis applies to a previously introduced ISE-based method for kernel density estimation. For dimensionality greater than 15, the basic L-2 kernel classifier performs poorly in practice. Thus, we extend the method through the introduction of a natural regularization parameter, which allows it to remain competitive with the SVM in high dimensions. Simulation results for both synthetic and real-world data are presented.", "paper_title": "L-2 Kernel Classification", "paper_id": "WOS:000281000700008"}