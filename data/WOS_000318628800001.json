{"auto_keywords": [{"score": 0.04977209300550506, "phrase": "homogeneous_multicore_architectures"}, {"score": 0.04856409924163315, "phrase": "brd"}, {"score": 0.038042569162216516, "phrase": "tile_data_layout"}, {"score": 0.03486761953836449, "phrase": "first_stage"}, {"score": 0.00481495049065317, "phrase": "tile_algorithms"}, {"score": 0.004692699265201631, "phrase": "new_high-performance_bidiagonal_reduction"}, {"score": 0.004486147558765763, "phrase": "high-performance_tridiagonal_reduction"}, {"score": 0.0042611497796259026, "phrase": "brd_case"}, {"score": 0.004179703591623336, "phrase": "first_step"}, {"score": 0.0041262692428189985, "phrase": "singular_value_decomposition"}, {"score": 0.003970013879881066, "phrase": "numerical_linear_algebra"}, {"score": 0.003906660012576505, "phrase": "computational_science"}, {"score": 0.003869132124880576, "phrase": "high_performance"}, {"score": 0.003558573794178866, "phrase": "efficient_data_representation"}, {"score": 0.0035357399513289904, "phrase": "main_memory"}, {"score": 0.003179397805415387, "phrase": "blas"}, {"score": 0.0031386977609818736, "phrase": "memory_traffic"}, {"score": 0.0031085239972726106, "phrase": "second_stage"}, {"score": 0.003049041251374798, "phrase": "bidiagonal_form"}, {"score": 0.003010017873923648, "phrase": "high-performance_kernels"}, {"score": 0.0029810774705309536, "phrase": "cache_reuse"}, {"score": 0.002858841145587906, "phrase": "general_algorithm"}, {"score": 0.002840484388249037, "phrase": "column-major_data_layout"}, {"score": 0.0026891227034884536, "phrase": "newly_implemented_kernels"}, {"score": 0.0026632593674563855, "phrase": "processing_units"}, {"score": 0.0026207039474589, "phrase": "data_dependencies"}, {"score": 0.002570531747243578, "phrase": "detailed_analysis"}, {"score": 0.002521317643120762, "phrase": "critical_impact"}, {"score": 0.0024970641749396784, "phrase": "tile_size"}, {"score": 0.0024730434312323296, "phrase": "total_execution_time"}, {"score": 0.002417887626368368, "phrase": "matrix_bandwidth_size"}, {"score": 0.0023487724551034227, "phrase": "performance_results"}, {"score": 0.002326174890933973, "phrase": "significant_improvement"}, {"score": 0.002311230481682913, "phrase": "currently_established_alternatives"}, {"score": 0.0022889932805175406, "phrase": "new_high-performance_brd"}, {"score": 0.0021880094145128957, "phrase": "state-of-the-art_open_source"}, {"score": 0.002132317877008799, "phrase": "lapack"}, {"score": 0.0021049977753042253, "phrase": "optimized_and_multithreaded_blas_from_mkl_as_well_as_intel_mkl_version"}], "paper_keywords": ["Algorithms", " Performance", " Bidiagional reduction", " tile algorithms", " two-stage approach", " bulge chasing", " data translation layer", " high performance kernels", " dynamic scheduling"], "paper_abstract": "This article presents a new high-performance bidiagonal reduction (BRD) for homogeneous multicore architectures. This article is an extension of the high-performance tridiagonal reduction implemented by the same authors [Luszczek et al., IPDPS 2011] to the BRD case. The BRD is the first step toward computing the singular value decomposition of a matrix, which is one of the most important algorithms in numerical linear algebra due to its broad impact in computational science. The high performance of the BRD described in this article comes from the combination of four important features: (1) tile algorithms with tile data layout, which provide an efficient data representation in main memory; (2) a two-stage reduction approach that allows to cast most of the computation during the first stage (reduction to band form) into calls to Level 3 BLAS and reduces the memory traffic during the second stage (reduction from band to bidiagonal form) by using high-performance kernels optimized for cache reuse; (3) a data dependence translation layer that maps the general algorithm with column-major data layout into the tile data layout; and (4) a dynamic runtime system that efficiently schedules the newly implemented kernels across the processing units and ensures that the data dependencies are not violated. A detailed analysis is provided to understand the critical impact of the tile size on the total execution time, which also corresponds to the matrix bandwidth size after the reduction of the first stage. The performance results show a significant improvement over currently established alternatives. The new high-performance BRD achieves up to a 30-fold speedup on a 16-core Intel Xeon machine with a 12000x12000 matrix size against the state-of-the-art open source and commercial numerical software packages, namely LAPACK, compiled with optimized and multithreaded BLAS from MKL as well as Intel MKL version 10.2.", "paper_title": "High-Performance Bidiagonal Reduction using Tile Algorithms on Homogeneous Multicore Architectures", "paper_id": "WOS:000318628800001"}