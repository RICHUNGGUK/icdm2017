{"auto_keywords": [{"score": 0.049146612112995945, "phrase": "support_vector_regression"}, {"score": 0.04347900416933489, "phrase": "support_vectors"}, {"score": 0.00481495049065317, "phrase": "improved_recursive"}, {"score": 0.004073359218158693, "phrase": "better_sparseness"}, {"score": 0.0037834649508375544, "phrase": "previously_selected_support_vectors"}, {"score": 0.003728000957725218, "phrase": "will-selected_ones"}, {"score": 0.0036733470451885465, "phrase": "selection_process"}, {"score": 0.0033950634506367235, "phrase": "improved_scheme"}, {"score": 0.0032160319265621285, "phrase": "support_weights"}, {"score": 0.0031532895341013297, "phrase": "new_sample"}, {"score": 0.003091767402370757, "phrase": "support_vector"}, {"score": 0.002986969236641105, "phrase": "training_sample"}, {"score": 0.002928682556953258, "phrase": "largest_reduction"}, {"score": 0.0028857130140890787, "phrase": "target_function"}, {"score": 0.0028016507334576216, "phrase": "approximation_subset"}, {"score": 0.0023346234464901978, "phrase": "almost_same_generalization_performance"}, {"score": 0.0022223176391038785, "phrase": "testing_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Support vector machine", " Support vector regression", " Kernel method", " Reduced technique", " Iterative strategy"], "paper_abstract": "Recently, an algorithm, namely recursive reduced least squares support vector regression (RR-LSSVR), was proposed to reduce the number of support vectors, which demonstrates better sparseness compared with other algorithms. However, it does not consider the effects between the previously selected support vectors and the will-selected ones during the selection process. Actually, they are not independent. Hence, in this paper, an improved scheme, named as IRR-LSSVR, is proposed to update the support weights immediately when a new sample is selected as support vector. As a result, the training sample leading to the largest reduction in the target function is chosen to construct the approximation subset. To show the efficacy and feasibility of our proposed IRR-LSSVR, a lot of experiments are done, which are all favorable for our viewpoints. That is, the IRR-LSSVR needs less number of support vectors to reach the almost same generalization performance as RR-LSSVR, which is beneficial to reducing the testing time and favorable for the realtime. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "An improved recursive reduced least squares support vector regression", "paper_id": "WOS:000303906100001"}