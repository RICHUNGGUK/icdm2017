{"auto_keywords": [{"score": 0.04586846484671967, "phrase": "high_dynamic_range_scenes"}, {"score": 0.039203366767089645, "phrase": "original_scenes"}, {"score": 0.00481495049065317, "phrase": "high_dynamic_range_images"}, {"score": 0.004598933498016774, "phrase": "learning-based_image_processing_technique"}, {"score": 0.004460309246062286, "phrase": "novel_method"}, {"score": 0.004347972379250724, "phrase": "low_dynamic_range_images"}, {"score": 0.004089725258435817, "phrase": "quantization_process"}, {"score": 0.004007083686875716, "phrase": "adaptive_conscience_learning_strategy"}, {"score": 0.003906116922372891, "phrase": "mapped_low_dynamic_range_displays"}, {"score": 0.003788296551609616, "phrase": "visual_features"}, {"score": 0.003636692152882991, "phrase": "full_use"}, {"score": 0.003581412258960711, "phrase": "available_display_levels"}, {"score": 0.003403122817578447, "phrase": "competitive_learning_neural_network"}, {"score": 0.003334309053314909, "phrase": "frequency_sensitive_competitive_learning_mechanism"}, {"score": 0.0030726480920918097, "phrase": "mapped_low_dynamic_images"}, {"score": 0.003025915966640355, "phrase": "visual_characteristics"}, {"score": 0.002889928791032578, "phrase": "sensitive_competitive_mechanism"}, {"score": 0.0028170314398963704, "phrase": "full_utilization"}, {"score": 0.0027741761880779535, "phrase": "limited_displayable_levels"}, {"score": 0.002690406375639144, "phrase": "deterministic_and_practicable_learning_procedure"}, {"score": 0.0026359661683151006, "phrase": "single_variable"}, {"score": 0.0025826247025542213, "phrase": "display_result"}, {"score": 0.0025174594088331853, "phrase": "detailed_description"}, {"score": 0.002479150189700726, "phrase": "implementation_procedure"}, {"score": 0.002441422510910065, "phrase": "new_learning-based_high_dynamic_range_compression_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["learning-based image processing", " quantization", " high dynamic range imaging", " dynamic range compression", " neural network", " competitive learning"], "paper_abstract": "In this paper, we present a learning-based image processing technique. We have developed a novel method to map high dynamic range scenes to low dynamic range images for display in standard (low dynamic range) reproduction media. We formulate the problem as a quantization process and employ an adaptive conscience learning strategy to ensure that the mapped low dynamic range displays not only faithfully reproduce the visual features of the original scenes, but also make full use of the available display levels. This is achieved by the use of a competitive learning neural network that employs a frequency sensitive competitive learning mechanism to adaptively design the quantizer. By optimizing an L-2 distortion function, we ensure that the mapped low dynamic images preserve the Visual characteristics of the original scenes. By incorporating a frequency sensitive competitive mechanism, we facilitate the full utilization of the limited displayable levels. We have developed a deterministic and practicable learning procedure which uses a single variable to control the display result. We give a detailed description of the implementation procedure of the new learning-based high dynamic range compression method and present experimental results to demonstrate the effectiveness of the method in displaying a variety of high dynamic range scenes. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "Learning to display high dynamic range images", "paper_id": "WOS:000247650000004"}