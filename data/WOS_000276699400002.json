{"auto_keywords": [{"score": 0.049324540543845184, "phrase": "hri"}, {"score": 0.00481495049065317, "phrase": "embodied_interactive_control_architecture"}, {"score": 0.004776853267973129, "phrase": "human-robot_interaction"}, {"score": 0.004664352260912174, "phrase": "growing_field"}, {"score": 0.004290969772225093, "phrase": "natural_human-like_behavior"}, {"score": 0.004173244935967375, "phrase": "important_target"}, {"score": 0.004140203942496321, "phrase": "hri._research"}, {"score": 0.0041074234667687875, "phrase": "human-human_communications"}, {"score": 0.00405873677211836, "phrase": "gaze_control"}, {"score": 0.003978866233891427, "phrase": "major_interactive_behaviors"}, {"score": 0.0039005612858880115, "phrase": "close_encounters"}, {"score": 0.0038696708318671446, "phrase": "human-like_gaze_control"}, {"score": 0.0037784540167266497, "phrase": "important_behaviors"}, {"score": 0.0036311617742547167, "phrase": "natural_interactions"}, {"score": 0.0036023971109946946, "phrase": "human_partners"}, {"score": 0.0035455471410184404, "phrase": "human-like_natural_gaze_control"}, {"score": 0.0033803056981691866, "phrase": "flexible_robotic_architecture"}, {"score": 0.0032614317990293695, "phrase": "autonomous_robots"}, {"score": 0.0029292375702719494, "phrase": "robotic_architectures"}, {"score": 0.0027594936602962075, "phrase": "new_cross-platform_robotic_architecture"}, {"score": 0.0025180781216911246, "phrase": "low_level_attention"}, {"score": 0.0024101837218440834, "phrase": "gaze_controllers"}, {"score": 0.002391067964886602, "phrase": "human-like_behavior"}, {"score": 0.0023532890136269986, "phrase": "mutual_attention"}, {"score": 0.002208035721125305, "phrase": "floating_point_genetic_algorithm"}, {"score": 0.0021905539771292096, "phrase": "fpga"}, {"score": 0.0021049977753042253, "phrase": "gaze_controller"}], "paper_keywords": ["Robotic architectures", " Action integration", " HRI", " Gaze control"], "paper_abstract": "Human-Robot Interaction (HRI) is a growing field of research that targets the development of robots which are easy to operate, more engaging and more entertaining. Natural human-like behavior is considered by many researchers as an important target of HRI. Research in Human-Human communications revealed that gaze control is one of the major interactive behaviors used by humans in close encounters. Human-like gaze control is then one of the important behaviors that a robot should have in order to provide natural interactions with human partners. To develop human-like natural gaze control that can integrate easily with other behaviors of the robot, a flexible robotic architecture is needed. Most robotic architectures available were developed with autonomous robots in mind. Although robots developed for HRI are usually autonomous, their autonomy is combined with interactivity, which adds more challenges on the design of the robotic architectures supporting them. This paper reports the development and evaluation of two gaze controllers using a new cross-platform robotic architecture for HRI applications called EICA (The Embodied Interactive Control Architecture), that was designed to meet those challenges emphasizing how low level attention focusing and action integration are implemented. Evaluation of the gaze controllers revealed human-like behavior in terms of mutual attention, gaze toward partner, and mutual gaze. The paper also reports a novel Floating Point Genetic Algorithm (FPGA) for learning the parameters of various processes of the gaze controller.", "paper_title": "Controlling gaze with an embodied interactive control architecture", "paper_id": "WOS:000276699400002"}