{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "graph-based_semisupervised_learning"}, {"score": 0.025241586477438193, "phrase": "proposed_approach"}, {"score": 0.004772818068176176, "phrase": "prototype_vector_machines"}, {"score": 0.004648609688625397, "phrase": "labeled_data"}, {"score": 0.004468304427278713, "phrase": "learner's_performance"}, {"score": 0.004371160978838441, "phrase": "often_easily_available_unlabeled_data"}, {"score": 0.004257360656055417, "phrase": "popular_approach"}, {"score": 0.004201571673071299, "phrase": "learned_function"}, {"score": 0.004092168350316413, "phrase": "underlying_data_manifold"}, {"score": 0.00395069818358908, "phrase": "weighted_graph"}, {"score": 0.003539252646181146, "phrase": "large_data_sets"}, {"score": 0.003298631258267805, "phrase": "sparse_prototypes"}, {"score": 0.003142732162296465, "phrase": "small_set"}, {"score": 0.0031151864044353245, "phrase": "data_representatives"}, {"score": 0.002994178996584381, "phrase": "graph-based_regularizer"}, {"score": 0.002941913249957503, "phrase": "model_complexity"}, {"score": 0.002729744174693491, "phrase": "gaussian_kernel"}, {"score": 0.0026585629592360085, "phrase": "graph_affinity"}, {"score": 0.002623669616798891, "phrase": "simple_and_principled_method"}, {"score": 0.0024667783849055634, "phrase": "real-world_data_sets"}, {"score": 0.0022192891418394514, "phrase": "model_sparsity"}, {"score": 0.0021049977753042253, "phrase": "highly_parsimonious_and_accurate_models"}], "paper_keywords": ["Graph-based methods", " large data sets", " low-rank approximation", " manifold regularization", " semisupervised learning"], "paper_abstract": "When the amount of labeled data are limited, semisupervised learning can improve the learner's performance by also using the often easily available unlabeled data. In particular, a popular approach requires the learned function to be smooth on the underlying data manifold. By approximating this manifold as a weighted graph, such graph-based techniques can often achieve state-of-the-art performance. However, their high time and space complexities make them less attractive on large data sets. In this paper, we propose to scale up graph-based semisupervised learning using a set of sparse prototypes derived from the data. These prototypes serve as a small set of data representatives, which can be used to approximate the graph-based regularizer and to control model complexity. Consequently, both training and testing become much more efficient. Moreover, when the Gaussian kernel is used to define the graph affinity, a simple and principled method to select the prototypes can be obtained. Experiments on a number of real-world data sets demonstrate encouraging performance and scaling properties of the proposed approach. It also compares favorably with models learned via l(1)-regularization at the same level of model sparsity. These results demonstrate the efficacy of the proposed approach in producing highly parsimonious and accurate models for semisupervised learning.", "paper_title": "Scaling Up Graph-Based Semisupervised Learning via Prototype Vector Machines", "paper_id": "WOS:000351834400003"}