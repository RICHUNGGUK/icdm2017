{"auto_keywords": [{"score": 0.03718034097391595, "phrase": "search_tree"}, {"score": 0.00481495049065317, "phrase": "particle_swarm_optimization"}, {"score": 0.004755650013733963, "phrase": "constraint_satisfaction_problem"}, {"score": 0.004414806639101985, "phrase": "nonempty_domain"}, {"score": 0.004378469469879815, "phrase": "possible_values"}, {"score": 0.004149429072483132, "phrase": "allowable_combinations"}, {"score": 0.0031845067058084583, "phrase": "instantiation_changes"}, {"score": 0.002778006389296707, "phrase": "variable_ordering"}, {"score": 0.0026875205754965537, "phrase": "current_problem_state"}, {"score": 0.002621590601574503, "phrase": "acceptable_performance"}, {"score": 0.0025892330566358503, "phrase": "wide_range"}, {"score": 0.002494531100339247, "phrase": "weighted_sum"}, {"score": 0.002473959963690124, "phrase": "process_indicators"}, {"score": 0.0024434201175883674, "phrase": "recent_improvement"}, {"score": 0.002305799666781492, "phrase": "particle_swarm_optimization_algorithm"}, {"score": 0.0022773309395419427, "phrase": "multilevel_approach"}, {"score": 0.0021579641460002523, "phrase": "individual_strategies"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Combinatorial optimization", " Constraints satisfaction", " Hyperheuristics", " Particle Swarm"], "paper_abstract": "A Constraint Satisfaction Problem is defined by a set of variables and a set of constraints, each variable has a nonempty domain of possible values. Each constraint involves some subset of the variables and specifies the allowable combinations of values for that subset. A solution of the problem is defined by an assignment of values to some or all of the variables that does not violate any constraints. To solve an instance, a search tree is created and each node in the tree represents a variable of the instance. The order in which the variables are selected for instantiation changes the form of the search tree and affects the cost of finding a solution. In this paper we explore the use of a Choice Function to dynamically select from a set of variable ordering heuristics the one that best matches the current problem state in order to show an acceptable performance over a wide range of instances. The Choice Function is defined as a weighted sum of process indicators expressing the recent improvement produced by the heuristic recently used. The weights are determined by a Particle Swarm Optimization algorithm in a multilevel approach. We report results where our combination of strategies outperforms the use of individual strategies. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Parameter tuning of a choice-function based hyperheuristic using Particle Swarm Optimization", "paper_id": "WOS:000314737600027"}