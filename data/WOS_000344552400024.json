{"auto_keywords": [{"score": 0.049648703742940906, "phrase": "nvidia_gpus"}, {"score": 0.04922237591220714, "phrase": "kernel_characterization_criteria"}, {"score": 0.04796412935568654, "phrase": "manycore_devices"}, {"score": 0.00481495049065317, "phrase": "apsp_implementation"}, {"score": 0.004623575575661583, "phrase": "gpu"}, {"score": 0.00447937340641839, "phrase": "computationally_intensive_problems"}, {"score": 0.004300951511110487, "phrase": "highly_parallel_algorithm"}, {"score": 0.004243064277617193, "phrase": "affordable_task"}, {"score": 0.00414830454375092, "phrase": "gpu_codes"}, {"score": 0.004092463367307375, "phrase": "challenging_activity"}, {"score": 0.004037370832877034, "phrase": "main_reason"}, {"score": 0.0038764861784138117, "phrase": "programming_choices"}, {"score": 0.0038242899532391914, "phrase": "tuning_techniques"}, {"score": 0.003557509959237602, "phrase": "useful_strategy"}, {"score": 0.0034780071331554003, "phrase": "optimization_problems"}, {"score": 0.003400274964240732, "phrase": "different_kernels"}, {"score": 0.003235305151177897, "phrase": "appropriate_configuration_parameters"}, {"score": 0.003023129616910419, "phrase": "well-known_problem"}, {"score": 0.0029025435402480326, "phrase": "shortest_paths"}, {"score": 0.002699889709390707, "phrase": "highly_parallel_and_computational_intensive_tasks"}, {"score": 0.0024440836179156593, "phrase": "apsp_algorithm_implementation"}, {"score": 0.0023571835517819124, "phrase": "combined_use"}, {"score": 0.00233594452829104, "phrase": "proper_configuration_policies"}, {"score": 0.0022940375532231145, "phrase": "concurrent_kernels_capability"}, {"score": 0.0022733662000757318, "phrase": "new_cuda_architectures"}, {"score": 0.00222249726328354, "phrase": "performance_improvement"}, {"score": 0.0021337783230121286, "phrase": "possible_configurations"}, {"score": 0.0021050372738988187, "phrase": "cuda"}], "paper_keywords": ["APSP", " Cache configuration", " Concurrent kernel", " GPU", " Kernel characterization", " Threadblock size"], "paper_abstract": "During the last years, GPU manycore devices have demonstrated their usefulness to accelerate computationally intensive problems. Although arriving at a parallelization of a highly parallel algorithm is an affordable task, the optimization of GPU codes is a challenging activity. The main reason for this is the number of parameters, programming choices, and tuning techniques available, many of them related with complex and sometimes hidden architecture details. A useful strategy to systematically attack these optimization problems is to characterize the different kernels of the application, and use this knowledge to select appropriate configuration parameters. The All-Pair Shortest-Path (APSP) problem is a well-known problem in graph theory whose objective is to find the shortest paths between any pairs of nodes in a graph. This problem can be solved by highly parallel and computational intensive tasks, being a good candidate to be exploited by manycore devices. In this paper, we use kernel characterization criteria to optimize an APSP algorithm implementation for NVIDIA GPUs. Our experimental results show that the combined use of proper configuration policies, and the concurrent kernels capability of new CUDA architectures, leads to a performance improvement of up to 62 % with respect to one of the possible configurations recommended by CUDA, considered as baseline.", "paper_title": "Optimizing an APSP implementation for NVIDIA GPUs using kernel characterization criteria", "paper_id": "WOS:000344552400024"}