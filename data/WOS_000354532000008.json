{"auto_keywords": [{"score": 0.004774324145784758, "phrase": "part-induced_multitask_structural_learning"}, {"score": 0.0046544807197808095, "phrase": "unified_framework"}, {"score": 0.004480307124735185, "phrase": "hierarchical_partwise_bag-of-words_representation"}, {"score": 0.004349337717774093, "phrase": "body_structure_cue"}, {"score": 0.00416882434439484, "phrase": "part-regularized_multitask_structural_learning"}, {"score": 0.004103270263112699, "phrase": "depth_modalities"}, {"score": 0.00378145978325955, "phrase": "body-based_action_classification"}, {"score": 0.0037336520904376687, "phrase": "part-based_action_classification"}, {"score": 0.003639835714755229, "phrase": "different_action_categories"}, {"score": 0.0036090884921108086, "phrase": "multiple_views"}, {"score": 0.0035183910023550246, "phrase": "action-specific_and_action-shared_feature_sub-spaces"}, {"score": 0.0030071857666598193, "phrase": "proposed_method"}, {"score": 0.002670183464675863, "phrase": "msr"}, {"score": 0.0024632148715152393, "phrase": "extensive_experimental_results"}, {"score": 0.0021229585266661845, "phrase": "mtsl"}, {"score": 0.0021049977753042253, "phrase": "part-based_regularization"}], "paper_keywords": ["Multitask learning (MTL)", " multiview human action recognition", " partwise bag-of-words", " structural learning"], "paper_abstract": "This paper proposes a unified framework for multiple/single-view human action recognition. First, we propose the hierarchical partwise bag-of-words representation which encodes both local and global visual saliency based on the body structure cue. Then, we formulate the multiple/single-view human action recognition as a part-regularized multitask structural learning (MTSL) problem which has two advantages on both model learning and feature selection: 1) preserving the consistence between the body-based action classification and the part-based action classification with the complementary information among different action categories and multiple views and 2) discovering both action-specific and action-shared feature sub-spaces to strengthen the generalization ability of model learning. Moreover, we contribute two novel human action recognition datasets, TJU (a single-view multimodal dataset) and MV-TJU (a multiview multimodal dataset). The proposed method is validated on three kinds of challenging datasets, including two single-view RGB datasets (KTH and TJU), two well-known depth dataset (MSR action 3-D and MSR daily activity 3-D), and one novel multiview multimodal dataset (MV-TJU). The extensive experimental results show that this method can outperform the popular 2-D/3-D part model-based methods and several other competing methods for multiple/single-view human action recognition in both RGB and depth modalities. To our knowledge, this paper is the first to demonstrate the applicability of MTSL with part-based regularization on multiple/single-view human action recognition in both RGB and depth modalities.", "paper_title": "Multiple/Single-View Human Action Recognition via Part-Induced Multitask Structural Learning", "paper_id": "WOS:000354532000008"}