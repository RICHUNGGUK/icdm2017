{"auto_keywords": [{"score": 0.029658645687597997, "phrase": "regression_plane"}, {"score": 0.008887631078850976, "phrase": "threshold_distance"}, {"score": 0.007581054407980731, "phrase": "svois"}, {"score": 0.00481495049065317, "phrase": "text_classification"}, {"score": 0.004780926543714981, "phrase": "automatic_text_classification"}, {"score": 0.004614362802631256, "phrase": "training_examples"}, {"score": 0.0044852808671980325, "phrase": "text_document_repositories"}, {"score": 0.004359794046948005, "phrase": "model_learning"}, {"score": 0.004267978415344142, "phrase": "instance_selection"}, {"score": 0.003975609222669783, "phrase": "noisy_data"}, {"score": 0.0038780652371817447, "phrase": "instance_selection_algorithms"}, {"score": 0.0037428390160675904, "phrase": "enn"}, {"score": 0.003690086329901995, "phrase": "icf"}, {"score": 0.003486316700608598, "phrase": "k-nearest_neighbor"}, {"score": 0.0032704647689720326, "phrase": "text_classification_domain"}, {"score": 0.003122905543460603, "phrase": "support_vector_machines"}, {"score": 0.0030679359570782595, "phrase": "core_text_classification_techniques"}, {"score": 0.0029294877178473043, "phrase": "support_vector_oriented_instance_selection"}, {"score": 0.002767613012044169, "phrase": "original_feature_space"}, {"score": 0.00257775722777195, "phrase": "identified_data"}, {"score": 0.002435270624076196, "phrase": "support_vectors"}, {"score": 0.0024094425220967273, "phrase": "selected_instances"}, {"score": 0.0023838876943453515, "phrase": "experimental_results"}, {"score": 0.002325306388085057, "phrase": "superior_performance"}, {"score": 0.002220296517089146, "phrase": "text_documents"}, {"score": 0.0021967433763351884, "phrase": "k-nn_and_svm_classifiers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Instance selection", " Data reduction", " Text classification", " Machine learning", " Support vector machines"], "paper_abstract": "Automatic text classification is usually based on models constructed through learning from training examples. However, as the size of text document repositories grows rapidly, the storage requirements and computational cost of model learning is becoming ever higher. Instance selection is one solution to overcoming this limitation. The aim is to reduce the amount of data by filtering out noisy data from a given training dataset A number of instance selection algorithms have been proposed in the literature, such as ENN, IB3, ICF, and DROP3. However, all of these methods have been developed for the k-nearest neighbor (k-NN) classifier. In addition, their performance has not been examined over the text classification domain where the dimensionality of the dataset is usually very high. The support vector machines (SVM) are core text classification techniques. In this study, a novel instance selection method, called Support Vector Oriented Instance Selection (SVOIS), is proposed. First of all, a regression plane in the original feature space is identified by utilizing a threshold distance between the given training instances and their class centers. Then, another threshold distance, between the identified data (forming the regression plane) and the regression plane, is used to decide on the support vectors for the selected instances. The experimental results based on the TechTC-100 dataset show the superior performance of SVOIS over other state-of-the-art algorithms. In particular, using SVOIS to select text documents allows the k-NN and SVM classifiers perform better than without instance selection. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "SVOIS: Support Vector Oriented Instance Selection for text classification", "paper_id": "WOS:000326991300003"}