{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "interactive_fusion"}, {"score": 0.004672444473700524, "phrase": "multi-modal_spatial_data_visualization"}, {"score": 0.004602773636967002, "phrase": "scientific_data"}, {"score": 0.004399905285945236, "phrase": "natural_phenomena"}, {"score": 0.004112175423546628, "phrase": "time-identified_events"}, {"score": 0.003901407184706592, "phrase": "interactive_techniques"}, {"score": 0.0034332736827447654, "phrase": "novel_interactive_visualization_technique"}, {"score": 0.003356675879109443, "phrase": "ground_truth_measurements"}, {"score": 0.003306559295382181, "phrase": "simulation_results"}, {"score": 0.0031606404966938568, "phrase": "continuous_tracking"}, {"score": 0.003066945490483524, "phrase": "spatiotemporal_patterns"}, {"score": 0.0029095936591723645, "phrase": "reference_model"}, {"score": 0.0028021527740710508, "phrase": "expected_temporal_behavior"}, {"score": 0.0026986685585382347, "phrase": "gpu_parallelism"}, {"score": 0.0026583500966092044, "phrase": "advect_measurements"}, {"score": 0.0022696277881969896, "phrase": "spatio-temporal_gaps"}, {"score": 0.00223570488212345, "phrase": "real_world_observations"}, {"score": 0.0021049977753042253, "phrase": "physical_phenomena"}], "paper_keywords": [""], "paper_abstract": "Scientific data acquired through sensors which monitor natural phenomena, as well as simulation data that imitate time-identified events, have fueled the need for interactive techniques to successfully analyze and understand trends and patterns across space and time. We present a novel interactive visualization technique that fuses ground truth measurements with simulation results in real-time to support the continuous tracking and analysis of spatiotemporal patterns. We start by constructing a reference model which densely represents the expected temporal behavior, and then use GPU parallelism to advect measurements on the model and track their location at any given point in time. Our results show that users can interactively fill the spatio-temporal gaps in real world observations, and generate animations that accurately describe physical phenomena.", "paper_title": "Interactive Fusion and Tracking For Multi-Modal Spatial Data Visualization", "paper_id": "WOS:000358328200028"}