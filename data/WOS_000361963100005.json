{"auto_keywords": [{"score": 0.004278807087784626, "phrase": "stateof-_art_model"}, {"score": 0.004223032986655664, "phrase": "binary_classification"}, {"score": 0.004140726362519362, "phrase": "decomposition_method"}, {"score": 0.003980875186335867, "phrase": "major_methods"}, {"score": 0.003928969293303814, "phrase": "training_svms"}, {"score": 0.003802135020791801, "phrase": "nonlinear_kernel"}, {"score": 0.0034911335714333507, "phrase": "bound-constrained_svms"}, {"score": 0.003445591238183763, "phrase": "projected_gradient_algorithm"}, {"score": 0.003400640983719424, "phrase": "interior_point_method"}, {"score": 0.003247868216333148, "phrase": "quadratic_subproblem"}, {"score": 0.0031636612155559267, "phrase": "main_difference"}, {"score": 0.00290473242917264, "phrase": "first_one"}, {"score": 0.0028480459059007468, "phrase": "first_order_derivative_information"}, {"score": 0.00270221723573854, "phrase": "second_one"}, {"score": 0.0026321198895843173, "phrase": "second_order_information"}, {"score": 0.002547043222086858, "phrase": "working_set_selection"}, {"score": 0.0023538840032613535, "phrase": "global_convergent"}, {"score": 0.0022928018832993387, "phrase": "new_algorithms"}, {"score": 0.002218668420806254, "phrase": "famous_package_bsvm._numerical_experiments"}, {"score": 0.0021049977753042253, "phrase": "proposed_methods"}], "paper_keywords": ["decomposition algorithm", " support vector machine", " quadratic programming", " global convergence"], "paper_abstract": "Bound-constrained Support Vector Machine(SVM) is one of the stateof- art model for binary classification. The decomposition method is currently one of the major methods for training SVMs, especially when the nonlinear kernel is used. In this paper, we proposed two new decomposition algorithms for training bound-constrained SVMs. Projected gradient algorithm and interior point method are combined together to solve the quadratic subproblem effciently. The main difference between the two algorithms is the way of choosing working set. The first one only uses first order derivative information of the model for simplicity. The second one incorporate part of second order information into the process of working set selection, besides the gradient. Both algorithms are proved to be global convergent in theory. New algorithms is compared with the famous package BSVM. Numerical experiments on several public data sets validate the effciency of the proposed methods.", "paper_title": "TWO NEW DECOMPOSITION ALGORITHMS FOR TRAINING BOUND-CONSTRAINED SUPPORT VECTOR MACHINES", "paper_id": "WOS:000361963100005"}