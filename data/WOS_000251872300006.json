{"auto_keywords": [{"score": 0.04889532068804289, "phrase": "computational_grids"}, {"score": 0.00481495049065317, "phrase": "high-level_parallel_language"}, {"score": 0.004227064760262924, "phrase": "parallel_execution"}, {"score": 0.004060986196931943, "phrase": "serious_challenges"}, {"score": 0.00392100783796804, "phrase": "hierarchical_and_often_shared_interconnects"}, {"score": 0.0038624981944755813, "phrase": "high_and_variable_latencies"}, {"score": 0.0036921366375716005, "phrase": "programming_language"}, {"score": 0.0036553070575015344, "phrase": "high-level_parallel_coordination"}, {"score": 0.00354700018079049, "phrase": "good_and_scalable_performance"}, {"score": 0.003459191419478298, "phrase": "computational_grid_configurations"}, {"score": 0.0033735490732324713, "phrase": "glasgow_parallel_haskell"}, {"score": 0.0032571885279065126, "phrase": "architectural_complexities"}, {"score": 0.0032085525502105836, "phrase": "computational_grid"}, {"score": 0.002976020822964243, "phrase": "gph"}, {"score": 0.002902304851882577, "phrase": "first_high-level_dsm_parallel_language_implementation"}, {"score": 0.0027881294891497115, "phrase": "systematic_performance_evaluation"}, {"score": 0.0025730425700096365, "phrase": "small_set"}, {"score": 0.002534596206835737, "phrase": "parallel_programs"}, {"score": 0.0024717881264735477, "phrase": "application_areas"}, {"score": 0.002362620540317279, "phrase": "communication_degree"}, {"score": 0.0023390219342052623, "phrase": "parallel_irregularity"}, {"score": 0.0022696277881969896, "phrase": "medium-scale_heterogeneous_and_high-latency_computational_grids"}, {"score": 0.0021693692831601745, "phrase": "program_characteristics"}, {"score": 0.0021476967767071233, "phrase": "communication_frequency"}, {"score": 0.0021049977753042253, "phrase": "irregular_parallelism"}], "paper_keywords": ["concurrent", " distributed", " parallel languages", " grid computing", " functional languages"], "paper_abstract": "Computational GRIDs potentially offer low-cost, readily available, and large-scale high-performance platforms. For the parallel execution of programs, however, computational GRIDs pose serious challenges: they are heterogeneous and have hierarchical and often shared interconnects, with high and variable latencies between clusters. This paper investigates whether a programming language with high-level parallel coordination and a Distributed Shared Memory (DSM) model can deliver good and scalable performance on a range of computational GRID configurations. The high-level language Glasgow parallel Haskell (GpH) abstracts over the architectural complexities of the computational GRID, and we have developed GRID-GUM2, a sophisticated grid-specific implementation of GpH, to produce the first high-level DSM parallel language implementation for computational GRIDs. We report a systematic performance evaluation of GRID-GUM2 on combinations of high/low and homogeneous/heterogeneous computational GRIDs. We measure the performance of a small set of kernel parallel programs representing a variety of application areas, two parallel paradigms, and ranges of communication degree and parallel irregularity. We investigate GRID-GUM2's performance scalability on medium-scale heterogeneous and high-latency computational GRIDs and analyze the performance with respect to the program characteristics of communication frequency and degree of irregular parallelism.", "paper_title": "Evaluating a high-level parallel language (GpH) for computational GRIDs", "paper_id": "WOS:000251872300006"}