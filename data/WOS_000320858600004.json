{"auto_keywords": [{"score": 0.036247390364484336, "phrase": "visual_words"}, {"score": 0.00481495049065317, "phrase": "concept-based_visual_word_clustering"}, {"score": 0.004681971826924847, "phrase": "visual_concept_discovery"}, {"score": 0.004552648949390462, "phrase": "semantic_gap"}, {"score": 0.004468415400599571, "phrase": "visual_content"}, {"score": 0.004385733482617193, "phrase": "multiple_concepts"}, {"score": 0.0042446888127531945, "phrase": "discovery_accuracy"}, {"score": 0.0039024014688338964, "phrase": "pre-segmented_training_images"}, {"score": 0.003848088904418221, "phrase": "cvwc"}, {"score": 0.0037768417338850274, "phrase": "prior_knowledge"}, {"score": 0.003604421041893448, "phrase": "web_images"}, {"score": 0.0033447157263095223, "phrase": "image_segmentation"}, {"score": 0.00329813918116714, "phrase": "concept-based_genetic_algorithm"}, {"score": 0.0032674478600540477, "phrase": "cbga"}, {"score": 0.003162252895465901, "phrase": "near-optimal_clusters"}, {"score": 0.0029757667083164627, "phrase": "co-occurrence_probability"}, {"score": 0.002893434697072309, "phrase": "clustering_procedure"}, {"score": 0.0028133741785871867, "phrase": "neighboring_vws"}, {"score": 0.0027483472371835865, "phrase": "concept_representation"}, {"score": 0.002550165781755603, "phrase": "discovered_concepts"}, {"score": 0.002514625755809045, "phrase": "clustered_results"}, {"score": 0.002410942838102255, "phrase": "video_retrieval"}, {"score": 0.0023442013458139497, "phrase": "proposed_cvwc_method"}, {"score": 0.0022902064558254984, "phrase": "ce"}, {"score": 0.0022686625017583387, "phrase": "satisfactory_improvements"}, {"score": 0.002185301851004467, "phrase": "pixel-based_image_segmentation_approach"}, {"score": 0.0021049977753042253, "phrase": "category_\"nation_defense"}], "paper_keywords": ["Multiple visual concept discovery", " Visual word clustering", " Genetic algorithm", " Image segmentation"], "paper_abstract": "In recent research, visual concept discovery was used to fill the semantic gap for representing the visual content. However, multiple concepts in an image generally degrade the discovery accuracy. In this paper, a Concept-based Visual Word Clustering (CVWC) method is proposed to discover multiple concepts from an image without pre-segmented training images. The CVWC is based on prior knowledge of concepts, which are trained from meta-text of web images. First, concepts are obtained by clustering the visual words in the regions extracted from image segmentation. A concept-based genetic algorithm (CBGA) is applied for searching the near-optimal clusters according to the visual words (VWs) in a concept and the co-occurrence probability of two concepts. The clustering procedure is also performed on the neighboring VWs to discover all the regions for concept representation. A concept extension method (CE) is further applied for iteratively updating the discovered concepts from the clustered results. In the experiments on the application to video retrieval, the mAP of the proposed CVWC method based on CBGA and CE obtained satisfactory improvements of 0.04 and 0.06, compared to pixel-based image segmentation approach and conventional concept model approach for the category \"nation defense,\" and 0.06 and 0.05 for the category \"ecology,\" respectively.", "paper_title": "Multiple visual concept discovery using concept-based visual word clustering", "paper_id": "WOS:000320858600004"}