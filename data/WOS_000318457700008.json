{"auto_keywords": [{"score": 0.0407769748728513, "phrase": "rsec"}, {"score": 0.00481495049065317, "phrase": "k-nearest_neighbor_approaches"}, {"score": 0.00411064950774695, "phrase": "new_classifier"}, {"score": 0.004027586827290042, "phrase": "random_subspace_evidence_classifier"}, {"score": 0.003807684498435389, "phrase": "local_hyperplane_distance"}, {"score": 0.0035997452281985465, "phrase": "whole_feature_space"}, {"score": 0.003509006038574667, "phrase": "randomly_generated_feature_subspaces"}, {"score": 0.00342054627009158, "phrase": "basic_belief_assignment"}, {"score": 0.0030726480920918097, "phrase": "basic_belief_assignments"}, {"score": 0.0029798924689472014, "phrase": "dempster's_rule"}, {"score": 0.002875200380397413, "phrase": "class_label"}, {"score": 0.002831462722290752, "phrase": "test_sample"}, {"score": 0.0027741761880779535, "phrase": "combined_belief_assignment"}, {"score": 0.0026630475331025955, "phrase": "uci_machine_learning_repository"}, {"score": 0.0025826247025542213, "phrase": "image_database"}, {"score": 0.002530359917257626, "phrase": "proposed_approach"}, {"score": 0.0025046245057922557, "phrase": "lower_classification_error"}, {"score": 0.002479150189700726, "phrase": "average_comparing"}, {"score": 0.0023798115577749225, "phrase": "classification_task"}, {"score": 0.0022961534630650347, "phrase": "good_performance"}, {"score": 0.0022382002476510573, "phrase": "high_dimensional_data"}, {"score": 0.0022041312401435346, "phrase": "minority_class"}, {"score": 0.0021705796895687864, "phrase": "imbalanced_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Evidence theory", " Nearest neighbors", " Local hyperplane", " Random subspace"], "paper_abstract": "Although there exist a lot of k-nearest neighbor approaches and their variants, few of them consider how to make use of the information in both the whole feature space and subspaces. In order to address this limitation, we propose a new classifier named as the random subspace evidence classifier (RSEC). Specifically, RSEC first calculates the local hyperplane distance for each class as the evidences not only in the whole feature space, but also in randomly generated feature subspaces. Then, the basic belief assignment is computed according to these distances for the evidences of each class. In the following, all the evidences represented by basic belief assignments are pooled together by the Dempster's rule. Finally, RSEC assigns the class label to each test sample based on the combined belief assignment. The experiments in the datasets from UCI machine learning repository, artificial data and face image database illustrate that the proposed approach yields lower classification error in average comparing to 7 existing k-nearest neighbor approaches and variants when performing the classification task. In addition, RSEC has good performance in average on the high dimensional data and the minority class of the imbalanced data. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Random subspace evidence classifier", "paper_id": "WOS:000318457700008"}