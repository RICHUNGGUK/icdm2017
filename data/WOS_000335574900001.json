{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "sound_source_perception"}, {"score": 0.004778594263962987, "phrase": "gestural_sound_description"}, {"score": 0.004706699397060569, "phrase": "gesture_description"}, {"score": 0.004671156704912419, "phrase": "sound_stimuli"}, {"score": 0.004600870784042767, "phrase": "listening_task"}, {"score": 0.0044634416051962545, "phrase": "gestural_responses"}, {"score": 0.004313713204732449, "phrase": "sound_source"}, {"score": 0.003953409087444568, "phrase": "first_experiment"}, {"score": 0.0038207243221070166, "phrase": "first_corpus"}, {"score": 0.003763186299187111, "phrase": "identifiable_causal_actions"}, {"score": 0.0036368625017975343, "phrase": "causal_actions"}, {"score": 0.0035550029054401016, "phrase": "corpora_properties"}, {"score": 0.0034881908940439213, "phrase": "listening_test"}, {"score": 0.003435643372146385, "phrase": "second_experiment"}, {"score": 0.0029629009627331355, "phrase": "listened_sounds"}, {"score": 0.0028309318332306703, "phrase": "causal_action"}, {"score": 0.0024785689583828796, "phrase": "sound_acoustic_features"}, {"score": 0.002413531395475291, "phrase": "interparticipants'_gesture_variability"}, {"score": 0.0023771343615901185, "phrase": "causal_sounds"}, {"score": 0.002350196395175188, "phrase": "noncausal_sounds"}, {"score": 0.002279841453843241, "phrase": "first_case"}, {"score": 0.002169968849836984, "phrase": "second_case"}, {"score": 0.0021453734588569823, "phrase": "sound_features"}, {"score": 0.0021049977753042253, "phrase": "gesture_responses"}], "paper_keywords": ["Experimentation", " Human Factors", " Gesture", " environmental sound perception", " cross-modal relationships", " sound source identification", " sound tracing", " sound mimicry", " embodied cognition"], "paper_abstract": "We investigated gesture description of sound stimuli performed during a listening task. Our hypothesis is that the strategies in gestural responses depend on the level of identification of the sound source and specifically on the identification of the action causing the sound. To validate our hypothesis, we conducted two experiments. In the first experiment, we built two corpora of sounds. The first corpus contains sounds with identifiable causal actions. The second contains sounds for which no causal actions could be identified. These corpora properties were validated through a listening test. In the second experiment, participants performed arm and hand gestures synchronously while listening to sounds taken from these corpora. Afterward, we conducted interviews asking participants to verbalize their experience while watching their own video recordings. They were questioned on their perception of the listened sounds and on their gestural strategies. We showed that for the sounds where causal action can be identified, participants mainly mimic the action that has produced the sound. In the other case, when no action can be associated with the sound, participants trace contours related to sound acoustic features. We also found that the interparticipants' gesture variability is higher for causal sounds compared to noncausal sounds. Variability demonstrates that, in the first case, participants have several ways of producing the same action, whereas in the second case, the sound features tend to make the gesture responses consistent.", "paper_title": "The Role of Sound Source Perception in Gestural Sound Description", "paper_id": "WOS:000335574900001"}