{"auto_keywords": [{"score": 0.03662858525081541, "phrase": "proposed_algorithm"}, {"score": 0.010612387000973441, "phrase": "online_adaptive_policy_learning_algorithm"}, {"score": 0.0047527118741586055, "phrase": "h-infinity_state_feedback_control_of_unknown_affine_nonlinear_discrete-time_systems"}, {"score": 0.004600596158672458, "phrase": "h-infinity_state_feedback_control"}, {"score": 0.0045411156682300695, "phrase": "affine_nonlinear_discrete-time_systems"}, {"score": 0.004172722575842674, "phrase": "apla"}, {"score": 0.004065474891313382, "phrase": "adaptive_dynamic_programming"}, {"score": 0.004012891184103925, "phrase": "adp"}, {"score": 0.003569050665799723, "phrase": "h-infinity_control_problem"}, {"score": 0.003257960296952439, "phrase": "suitable_approximations"}, {"score": 0.003194898129853895, "phrase": "optimal_value_function"}, {"score": 0.003133052778244851, "phrase": "saddle_point_feedback_control"}, {"score": 0.0030326180561817497, "phrase": "novel_weight_updating_laws"}, {"score": 0.0026274936167233515, "phrase": "system_trajectories"}, {"score": 0.002576603426735759, "phrase": "nn_approximation_errors"}, {"score": 0.0024939618994290016, "phrase": "stability_analysis"}, {"score": 0.002413964586947992, "phrase": "lyapunov_approach"}, {"score": 0.0022912596877648723, "phrase": "system_input_dynamics"}, {"score": 0.002160640052461594, "phrase": "nn_identification_scheme"}, {"score": 0.0021049977753042253, "phrase": "simulation_examples"}], "paper_keywords": ["Adaptive dynamic programming", " H-infinity control", " neural networks", " nonlinear discrete-time system", " zero-sum game"], "paper_abstract": "The problem of H-infinity state feedback control of affine nonlinear discrete-time systems with unknown dynamics is investigated in this paper. An online adaptive policy learning algorithm (APLA) based on adaptive dynamic programming (ADP) is proposed for learning in real-time the solution to the Hamilton-Jacobi-Isaacs (HJI) equation, which appears in the H-infinity control problem. In the proposed algorithm, three neural networks (NNs) are utilized to find suitable approximations of the optimal value function and the saddle point feedback control and disturbance policies. Novel weight updating laws are given to tune the critic, actor, and disturbance NNs simultaneously by using data generated in real-time along the system trajectories. Considering NN approximation errors, we provide the stability analysis of the proposed algorithm with Lyapunov approach. Moreover, the need of the system input dynamics for the proposed algorithm is relaxed by using a NN identification scheme. Finally, simulation examples show the effectiveness of the proposed algorithm.", "paper_title": "Online Adaptive Policy Learning Algorithm for H-infinity State Feedback Control of Unknown Affine Nonlinear Discrete-Time Systems", "paper_id": "WOS:000345629000038"}