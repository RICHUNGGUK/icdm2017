{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "atomic_human_actions"}, {"score": 0.04960770684597511, "phrase": "variable-length_markov_models"}, {"score": 0.04844894171082025, "phrase": "human_behavior"}, {"score": 0.04406602779400211, "phrase": "atomic_actions"}, {"score": 0.004582528208024817, "phrase": "considerable_interest"}, {"score": 0.004470539706227421, "phrase": "computer_vision"}, {"score": 0.004361276005140776, "phrase": "potential_applications"}, {"score": 0.004069280130346136, "phrase": "basic_and_complete_movement"}, {"score": 0.0038919354605673104, "phrase": "human_behavior_analysis"}, {"score": 0.0032887360307856635, "phrase": "vlmm"}, {"score": 0.003114283314285167, "phrase": "posture_template_selection_algorithm"}, {"score": 0.003038066486989815, "phrase": "modified_shape_context_matching_technique"}, {"score": 0.0029490571526071016, "phrase": "selected_posture_templates"}, {"score": 0.0028203950416405563, "phrase": "input_posture_sequences"}, {"score": 0.0027925723953701083, "phrase": "discrete_symbol_sequences"}, {"score": 0.0027650234530228923, "phrase": "subsequent_processing"}, {"score": 0.0026973310437053573, "phrase": "vlmm_technique"}, {"score": 0.002618278365749875, "phrase": "training_symbol_sequences"}, {"score": 0.0025289662786567896, "phrase": "constructed_vlmms"}, {"score": 0.0024793019587009035, "phrase": "hidden_markov_models"}, {"score": 0.00240662380079115, "phrase": "input_atomic_actions"}, {"score": 0.002301572462091142, "phrase": "excellent_learning_function"}, {"score": 0.002234092591045251, "phrase": "fault-tolerant_recognition_ability"}, {"score": 0.002168586864007222, "phrase": "realistic_data"}, {"score": 0.0021049977753042253, "phrase": "proposed_system"}], "paper_keywords": ["Atomic action learning", " atomic action recognition", " human behavior analysis", " variable-length Markov models (VLMMs)"], "paper_abstract": "Visual analysis of human behavior has generated considerable interest in the field of computer vision because of its wide spectrum of potential applications. Human behavior can be segmented into atomic actions, each of which indicates a basic and complete movement. Learning and recognizing atomic human actions are essential to human behavior analysis. In this paper, we propose a framework for handling this task using variable-length Markov models (VLMMs). The framework is comprised of the following two modules: a posture labeling module and a VLMM atomic action learning and recognition module. First, a posture template selection algorithm, based on a modified shape context matching technique, is developed. The selected posture templates form a codebook that is used to convert input posture sequences into discrete symbol sequences for subsequent processing. Then, the VLMM technique is applied to learn the training symbol sequences of atomic actions. Finally, the constructed VLMMs are transformed into hidden Markov models (HMMs) for recognizing input atomic actions. This approach combines the advantages of the excellent learning function of a VLMM and the fault-tolerant recognition ability of an HMM. Experiments on realistic data demonstrate the efficacy of the proposed system.", "paper_title": "Learning Atomic Human Actions Using Variable-Length Markov Models", "paper_id": "WOS:000262562700023"}