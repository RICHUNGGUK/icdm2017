{"auto_keywords": [{"score": 0.027594428301500454, "phrase": "roshaq"}, {"score": 0.011434897902675514, "phrase": "shared_queues"}, {"score": 0.007726869676487897, "phrase": "vc_router"}, {"score": 0.00481495049065317, "phrase": "shared-buffer_routers"}, {"score": 0.00473320761888448, "phrase": "chip_routers"}, {"score": 0.004496174406337201, "phrase": "case_contention"}, {"score": 0.00443878620915958, "phrase": "output_physical_channels"}, {"score": 0.004307700591183651, "phrase": "significant_portions"}, {"score": 0.004270960586542813, "phrase": "router_area"}, {"score": 0.004234532601573088, "phrase": "power_budgets"}, {"score": 0.004144810537437608, "phrase": "traffic_trace"}, {"score": 0.004005176784823524, "phrase": "incoming_packets"}, {"score": 0.003837205620832367, "phrase": "large_number"}, {"score": 0.0038044630943383497, "phrase": "buffer_queues"}, {"score": 0.003522027550662857, "phrase": "router_architecture"}, {"score": 0.003359816816853762, "phrase": "buffer_utilization"}, {"score": 0.0033026956021014204, "phrase": "sharing_multiple_buffer_queues"}, {"score": 0.0030183163057929687, "phrase": "higher_throughput"}, {"score": 0.0029797347088361056, "phrase": "network_load"}, {"score": 0.0028669153591624696, "phrase": "light_traffic_load"}, {"score": 0.0028181504086563967, "phrase": "low_latency"}, {"score": 0.0026998264237910884, "phrase": "experimental_results"}, {"score": 0.0025207284405252914, "phrase": "typical_virtualchannel"}, {"score": 0.0022936610196951962, "phrase": "real_multitask_applications"}, {"score": 0.002235356010935877, "phrase": "near-optimal_nmap_mapping_algorithm"}], "paper_keywords": ["Application mapping", " networks on-chip", " router architecture", " shared-buffer", " synthetic traffics"], "paper_abstract": "On-chip routers typically have buffers dedicated to their input or output ports for temporarily storing packets in case contention occurs on output physical channels. Buffers, unfortunately, consume significant portions of router area and power budgets. While running a traffic trace, however, not all input ports of routers have incoming packets needed to be transferred simultaneously. Therefore, a large number of buffer queues in the network are empty and other queues are mostly busy. This observation motivates us to design router architecture with shared queues (RoShaQ), router architecture that maximizes buffer utilization by allowing the sharing multiple buffer queues among input ports. Sharing queues, in fact, makes using buffers more efficient hence is able to achieve higher throughput when the network load becomes heavy. On the other side, at light traffic load, our router achieves low latency by allowing packets to effectively bypass these shared queues. Experimental results on a 65-nm CMOS standard-cell process show that over synthetic traffics RoShaQ has 17% less latency and 18% higher saturation throughput than a typical virtualchannel (VC) router. Because of its higher performance, RoShaQ consumes 9% less energy per transferred packet than VC router given the same buffer space capacity. Over real multitask applications and E3S embedded benchmarks using near-optimal NMAP mapping algorithm, RoShaQ has 32% lower latency than VC router and targeting the same application throughput with 30% lower energy per packet.", "paper_title": "Achieving High-Performance On-Chip Networks With Shared-Buffer Routers", "paper_id": "WOS:000337167600017"}