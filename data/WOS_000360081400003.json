{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "koza's_performance_measures"}, {"score": 0.004765173195920904, "phrase": "john_r._koza"}, {"score": 0.004547438494330851, "phrase": "evolutionary_algorithm"}, {"score": 0.0025657442830956017, "phrase": "analytical_and_empirical_approach"}, {"score": 0.0025259712348798323, "phrase": "theoretical_boundaries"}, {"score": 0.002422890839801611, "phrase": "new_method"}, {"score": 0.0022407927161620855, "phrase": "common_experimental_configurations"}, {"score": 0.0021945833590668973, "phrase": "unacceptable_error"}], "paper_keywords": ["Genetic Programming", " Computational effort", " Performance measures", " Experimental methods", " Measurement error"], "paper_abstract": "John R. Koza defined several metrics to measure the performance of an Evolutionary Algorithm that have been widely used by the Genetic Programming community. Despite the importance of these metrics, and the doubts that they have generated in many authors, their reliability has attracted little research attention, and is still not well understood. The lack of knowledge about these metrics has likely contributed to the decline in their usage in the last years. This paper is an attempt to increase the knowledge about these measures, exploring in which circumstances they are more reliable, providing some clues to improve how they are used, and eventually making their use more justifiable. Specifically, we investigate the amount of uncertainty associated with the measures, taking an analytical and empirical approach and reaching theoretical boundaries to the error. Additionally, a new method to calculate Koza's performance measures is presented. It is shown that these metrics, under common experimental configurations, have an unacceptable error, which can be arbitrary large in certain conditions.", "paper_title": "A study on Koza's performance measures", "paper_id": "WOS:000360081400003"}