{"auto_keywords": [{"score": 0.0402525648889651, "phrase": "light_field_camera"}, {"score": 0.00481495049065317, "phrase": "lenslet_light_field"}, {"score": 0.004754447398742591, "phrase": "light_field_cameras"}, {"score": 0.0047145329604366395, "phrase": "full_spatio-angular_information"}, {"score": 0.004278807087784626, "phrase": "spatial_and_angular_resolution"}, {"score": 0.004171891198117439, "phrase": "limited_understanding"}, {"score": 0.0037861265016041813, "phrase": "new_design"}, {"score": 0.0036759314172445934, "phrase": "rendering_algorithm"}, {"score": 0.0034504423179340738, "phrase": "light_transport_framework"}, {"score": 0.0033926758710459866, "phrase": "fundamental_limits"}, {"score": 0.0033641551050434663, "phrase": "light_field_camera_resolution"}, {"score": 0.0032800186243040663, "phrase": "prefiltering_model"}, {"score": 0.0032524418285459324, "phrase": "lenslet-based_light_field_cameras"}, {"score": 0.003104849179057156, "phrase": "full_space-angle_sensitivity_profile"}, {"score": 0.0029020077365708966, "phrase": "grazing_angles"}, {"score": 0.0028293966058473476, "phrase": "full_sensor_profile"}, {"score": 0.0027937732927852646, "phrase": "important_role"}, {"score": 0.0026782279715171866, "phrase": "proposed_method"}, {"score": 0.002633355582628613, "phrase": "existing_lenslet-based_light_field_cameras"}, {"score": 0.0025458479274370832, "phrase": "unified_way"}, {"score": 0.002471661547432869, "phrase": "practical_differences"}, {"score": 0.002450864311898833, "phrase": "particular_prototypes"}, {"score": 0.00214995338990007, "phrase": "flatland_simulation"}, {"score": 0.002131857309586904, "phrase": "real_data"}, {"score": 0.0021049977753042253, "phrase": "lytro_light_field_camera"}], "paper_keywords": ["Algorithms", " Theory", " Light field camera", " light transport analysis", " superresolution"], "paper_abstract": "Light field cameras capture full spatio-angular information of the light field, and enable many novel photographic and scientific applications. It is often stated that there is a fundamental trade-off between spatial and angular resolution, but there has been limited understanding of this trade-off theoretically or numerically. Moreover, it is very difficult to evaluate the design of a light field camera because a new design is usually reported with its prototype and rendering algorithm, both of which affect resolution. In this article, we develop a light transport framework for understanding the fundamental limits of light field camera resolution. We first derive the prefiltering model of lenslet-based light field cameras. The main novelty of our model is in considering the full space-angle sensitivity profile of the photosensor-in particular, real pixels have nonuniform angular sensitivity, responding more to light along the optical axis rather than at grazing angles. We show that the full sensor profile plays an important role in defining the performance of a light field camera. The proposed method can model all existing lenslet-based light field cameras and allows to compare them in a unified way in simulation, independent of the practical differences between particular prototypes. We further extend our framework to analyze the performance of two rendering methods: the simple projection-based method and the inverse light transport process. We validate our framework with both flatland simulation and real data from the Lytro light field camera.", "paper_title": "A Light Transport Framework for Lenslet Light Field Cameras", "paper_id": "WOS:000350565200003"}