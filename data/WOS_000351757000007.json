{"auto_keywords": [{"score": 0.04962396550254858, "phrase": "optical_see-through_head-mounted_displays"}, {"score": 0.04306043741334064, "phrase": "user's_eye_position"}, {"score": 0.00481495049065317, "phrase": "spatial_calibration"}, {"score": 0.0047013405841819025, "phrase": "critical_requirement"}, {"score": 0.004656647251517823, "phrase": "ar_applications"}, {"score": 0.004334657104697421, "phrase": "current_viewpoint"}, {"score": 0.0040735909648053105, "phrase": "recently-proposed_interaction-free_calibration_methods"}, {"score": 0.0037199473428123175, "phrase": "tedious_manual_calibrations"}, {"score": 0.003529364798514874, "phrase": "systematic_calibration_errors"}, {"score": 0.003332537728389913, "phrase": "conventional_eye-hmd_model"}, {"score": 0.003285068275570087, "phrase": "hmd"}, {"score": 0.003072285184441679, "phrase": "optical_elements"}, {"score": 0.0030140547908298404, "phrase": "incoming_world-light_rays"}, {"score": 0.002887028262617443, "phrase": "corrective_glasses"}, {"score": 0.002791932344920906, "phrase": "optical_element"}, {"score": 0.002739001004969201, "phrase": "virtual_screen"}, {"score": 0.0026742419973883134, "phrase": "different_distortions"}, {"score": 0.002598543802992702, "phrase": "distorted_world"}, {"score": 0.0024771000236931836, "phrase": "projection_quality"}, {"score": 0.0024185182010749273, "phrase": "light-field_correction_method"}, {"score": 0.0023613185213421173, "phrase": "machine_learning_technique"}, {"score": 0.00230546852838578, "phrase": "world-scene_distortion"}, {"score": 0.0022725931637071852, "phrase": "ost-hmd_optics"}, {"score": 0.002187194307878705, "phrase": "systematic_error"}, {"score": 0.0021354538918029286, "phrase": "calibration_accuracy"}, {"score": 0.0021049977753042253, "phrase": "interaction-free_calibration"}], "paper_keywords": ["OST-HMD", " calibration", " undistortion", " optical see-through display", " light field", " INDICA", " SPAAM", " eye tracking"], "paper_abstract": "A critical requirement for AR applications with Optical See-Through Head-Mounted Displays (OST-HMD) is to project 3D information correctly into the current viewpoint of the user - more particularly, according to the user's eye position. Recently-proposed interaction-free calibration methods [16, 17] automatically estimate this projection by tracking the user's eye position, thereby freeing users from tedious manual calibrations. However, the method is still prone to contain systematic calibration errors. Such errors stem from eye-/HMD-related factors and are not represented in the conventional eye-HMD model used for HMD calibration. This paper investigates one of these factors - the fact that optical elements of OST-HMDs distort incoming world-light rays before they reach the eye, just as corrective glasses do. Any OST-HMD requires an optical element to display a virtual screen. Each such optical element has different distortions. Since users see a distorted world through the element, ignoring this distortion degenerates the projection quality. We propose a light-field correction method, based on a machine learning technique, which compensates the world-scene distortion caused by OST-HMD optics. We demonstrate that our method reduces the systematic error and significantly increases the calibration accuracy of the interaction-free calibration.", "paper_title": "Light-Field Correction for Spatial Calibration of Optical See-Through Head-Mounted Displays", "paper_id": "WOS:000351757000007"}