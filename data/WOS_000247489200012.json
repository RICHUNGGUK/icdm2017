{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "support_value"}, {"score": 0.004685375117376838, "phrase": "numerous_imaging_sensors"}, {"score": 0.004317109072311102, "phrase": "complete_picture"}, {"score": 0.004283576270012874, "phrase": "image_fusion"}, {"score": 0.004233762728640565, "phrase": "important_approach"}, {"score": 0.004103728794623367, "phrase": "single_image"}, {"score": 0.004040211152784802, "phrase": "relevant_information"}, {"score": 0.00396218934254591, "phrase": "different_sensors"}, {"score": 0.0038255128976509545, "phrase": "new_image_fusion_method"}, {"score": 0.0036363418376496484, "phrase": "salient_features"}, {"score": 0.0034564928013639125, "phrase": "support_vector_machines"}, {"score": 0.0033502512757488433, "phrase": "larger_support_values"}, {"score": 0.00331125524068286, "phrase": "physical_meaning"}, {"score": 0.0032220148724914867, "phrase": "relative_more_importance"}, {"score": 0.0031845067058084613, "phrase": "data_points"}, {"score": 0.0031229578623834394, "phrase": "svm_model"}, {"score": 0.0030865992688177005, "phrase": "mapped_least_squares"}, {"score": 0.0030387772044457623, "phrase": "ls-svm"}, {"score": 0.0029453365339797933, "phrase": "support_values"}, {"score": 0.002888396879326153, "phrase": "support_value_analysis"}, {"score": 0.0027995677499976406, "phrase": "multiscale_support_value_filters"}, {"score": 0.0026923527275481804, "phrase": "basic_support_value_filter"}, {"score": 0.0026506222660465126, "phrase": "mapped_ls-svm"}, {"score": 0.002579140290642792, "phrase": "desired_level"}, {"score": 0.0025292620341476283, "phrase": "widely_used_image_fusion_methods"}, {"score": 0.0024803459795996116, "phrase": "laplacian_pyramid"}, {"score": 0.0024610448251906453, "phrase": "discrete_wavelet_transform_methods"}, {"score": 0.00243237365704391, "phrase": "proposed_method"}, {"score": 0.0024040357029838774, "phrase": "undecimated_transform-based_approach"}, {"score": 0.0023300677028248776, "phrase": "multisource_images"}, {"score": 0.0022672107906933714, "phrase": "proposed_approach"}, {"score": 0.002197443382039439, "phrase": "conventional_image_fusion_methods"}, {"score": 0.002154930852763048, "phrase": "pertained_quantitative_fusion_evaluation_indexes"}, {"score": 0.0021049977753042253, "phrase": "visual_information"}], "paper_keywords": ["image fusion", " mapped least squares support vector machine (mapped LS-SVM)", " support vector machine (SVM)", " support value transform (SVT)"], "paper_abstract": "With the development of numerous imaging sensors, many images can be simultaneously pictured by various sensors. However, there are many scenarios where no one sensor can give the complete picture. Image fusion is an important approach to solve this problem and produces a single image which preserves all relevant information from a set of different sensors. In this paper, we proposed a new image fusion method using the support value transform, which uses the support value to represent the salient features of image. This is based on the fact that, in support vector machines (SVMs), the data with larger support values have a physical meaning in the sense that they reveal relative more importance of the data points for contributing to the SVM model. The mapped least squares SVM (mapped LS-SVM) is used to efficiently compute the support values of image. The support value analysis is developed by using a series of multiscale support value filters, which are obtained by filling zeros in the basic support value filter deduced from the mapped LS-SVM to match the resolution of the desired level. Compared with the widely used image fusion methods, such as the Laplacian pyramid, discrete wavelet transform methods, the proposed method is an undecimated transform-based approach. The fusion experiments are undertaken on multisource images. The results demonstrate that the proposed approach is effective and is superior to the conventional image fusion methods in terms of the pertained quantitative fusion evaluation indexes, such as quality of visual information (Q(AB/F)), the mutual information, etc.", "paper_title": "Multisource image fusion method using support value transform", "paper_id": "WOS:000247489200012"}