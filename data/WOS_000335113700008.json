{"auto_keywords": [{"score": 0.028559947580613393, "phrase": "ega"}, {"score": 0.00481495049065317, "phrase": "high_dimensional_instance_selection"}, {"score": 0.0046781613377273774, "phrase": "data_reduction"}, {"score": 0.004611224230543916, "phrase": "important_data_pre-processing_step"}, {"score": 0.004545247604211428, "phrase": "kdd"}, {"score": 0.00429057323623293, "phrase": "instance_selection_algorithms"}, {"score": 0.004208881856146758, "phrase": "unrepresentative_or_noisy_data"}, {"score": 0.003643607569483598, "phrase": "novel_efficient_genetic_algorithm"}, {"score": 0.0035229930971258316, "phrase": "\"biological_evolution"}, {"score": 0.0034558655164987134, "phrase": "evolutionary_process"}, {"score": 0.0033575566897536906, "phrase": "long-term_evolution"}, {"score": 0.003154012038613403, "phrase": "experimental_study"}, {"score": 0.0029343925814926787, "phrase": "state-of-the-art_algorithms"}, {"score": 0.0028508866613313763, "phrase": "icf"}, {"score": 0.0027564303939865476, "phrase": "ega."}, {"score": 0.002730023736069673, "phrase": "experimental_results"}, {"score": 0.0026523079380037706, "phrase": "k-nn_and_svm_classifiers"}, {"score": 0.0025644240336018045, "phrase": "baseline_classifiers"}, {"score": 0.0023972750359328235, "phrase": "average_classification_accuracy"}, {"score": 0.0023066880707738736, "phrase": "largest_reduction_rates"}, {"score": 0.002251947274576707, "phrase": "ga"}, {"score": 0.002198242191529977, "phrase": "relatively_less_computational_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Data reduction", " Instance selection", " Data mining", " Machine learning", " Genetic algorithms", " High dimensional data"], "paper_abstract": "Data reduction is an important data pre-processing step in the KDD process. It can be approached by the application of some instance selection algorithms to filter out unrepresentative or noisy data from a given (training) dataset. However, the performance of instance selection over very high dimensional data has not yet been fully examined. In this paper, we introduce a novel efficient genetic algorithm (EGA), which fits \"biological evolution\" into the evolutionary process. In other words, after long-term evolution, individuals find the most efficient way to allocate resources and evolve. The experimental study is based on four very high dimensional datasets ranging from 200 to 18,236 dimensions. In addition, four state-of-the-art algorithms including IB3, DROP3, ICF, and GA are compared with EGA. The experimental results show that EGA allows the k-NN and SVM classifiers to provide the most comparable classification performance with the baseline classifiers without instance selection. Particularly, EGA outperforms the four algorithms in terms of average classification accuracy. Moreover, EGA can produce the largest reduction rates (the same as GA) and it requires relatively less computational time than the other four algorithms. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Towards high dimensional instance selection: An evolutionary approach", "paper_id": "WOS:000335113700008"}