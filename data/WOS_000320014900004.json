{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "approximate_algorithmic_transformation"}, {"score": 0.004613516457919661, "phrase": "new_class"}, {"score": 0.00332375606483146, "phrase": "von_neumann_model"}, {"score": 0.0031845067058084583, "phrase": "neural_model"}, {"score": 0.0028006988338192375, "phrase": "general-purpose_approximate_programs"}, {"score": 0.0024630345285372958, "phrase": "significant_performance_and_efficiency_gains"}, {"score": 0.0022287497627555895, "phrase": "full_accuracy"}, {"score": 0.0021049977753042253, "phrase": "general-purpose_computing"}], "paper_keywords": [""], "paper_abstract": "This work proposes an approximate algorithmic transformation and a new class of accelerators, called neural processing units (NPUs). NPUs leverage the approximate algorithmic transformation that converts regions of code from a Von Neumann model to a neural model. NPUs achieve an average 2.3x speedup and 3.0x energy savings for general-purpose approximate programs. This new class of accelerators shows that significant performance and efficiency gains are possible when the abstraction of full accuracy is relaxed in general-purpose computing.", "paper_title": "NEURAL ACCELERATION FOR GENERAL-PURPOSE APPROXIMATE PROGRAMS", "paper_id": "WOS:000320014900004"}