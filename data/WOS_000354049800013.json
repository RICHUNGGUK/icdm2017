{"auto_keywords": [{"score": 0.04601890194668995, "phrase": "ballet_dance_movements"}, {"score": 0.029237135610446486, "phrase": "dance_sequence"}, {"score": 0.00481495049065317, "phrase": "ballet_dance_training"}, {"score": 0.004778088905211055, "phrase": "ms_kinect"}, {"score": 0.004687159050154687, "phrase": "cave_virtual_reality_environment"}, {"score": 0.004580314008293946, "phrase": "novel_framework"}, {"score": 0.004527804152066942, "phrase": "real-time_capture"}, {"score": 0.0041287394089001405, "phrase": "human_movement_data"}, {"score": 0.004065721092116729, "phrase": "skeletal_joint_tracking"}, {"score": 0.003735862292632131, "phrase": "cave_virtual_environment"}, {"score": 0.0035810720634458933, "phrase": "proposed_framework"}, {"score": 0.003512841739654183, "phrase": "unsupervised_parsing"}, {"score": 0.003485913728272778, "phrase": "ballet_dance_movement"}, {"score": 0.003445906915464945, "phrase": "structured_posture_space"}, {"score": 0.0034063576796640603, "phrase": "spherical_self-organizing_map"}, {"score": 0.003328611206488653, "phrase": "unique_feature_descriptor"}, {"score": 0.0031298260299218684, "phrase": "gesture_trajectories"}, {"score": 0.0031058249097051555, "phrase": "posture_space"}, {"score": 0.003070166825722112, "phrase": "ssom."}, {"score": 0.003046621804854539, "phrase": "recognition_subsystem"}, {"score": 0.002842655426951218, "phrase": "virtual_instructor"}, {"score": 0.002788454815865172, "phrase": "particular_dance_sequence"}, {"score": 0.002631959004685823, "phrase": "gestural_components"}, {"score": 0.002532526438148958, "phrase": "score-based_assessment"}, {"score": 0.0024181413029825205, "phrase": "immersive_interface"}, {"score": 0.0023178219772486868, "phrase": "vantage_points"}, {"score": 0.002273605493468005, "phrase": "unique_perspective"}, {"score": 0.002256155453630723, "phrase": "spatial_context"}, {"score": 0.0021049977753042253, "phrase": "virtual_feedback_systems"}], "paper_keywords": ["Design", " Algorithm", " Performance", " MS Kinect", " ballet", " dance", " immersive training and simulation", " virtual reality", " human-computer interaction", " gesture recognition", " self-organizing maps", " CAVE"], "paper_abstract": "This article proposes a novel framework for the real-time capture, assessment, and visualization of ballet dance movements as performed by a student in an instructional, virtual reality (VR) setting. The acquisition of human movement data is facilitated by skeletal joint tracking captured using the popular Microsoft (MS) Kinect camera system, while instruction and performance evaluation are provided in the form of 3D visualizations and feedback through a CAVE virtual environment, in which the student is fully immersed. The proposed framework is based on the unsupervised parsing of ballet dance movement into a structured posture space using the spherical self-organizing map (SSOM). A unique feature descriptor is proposed to more appropriately reflect the subtleties of ballet dance movements, which are represented as gesture trajectories through posture space on the SSOM. This recognition subsystem is used to identify the category of movement the student is attempting when prompted (by a virtual instructor) to perform a particular dance sequence. The dance sequence is then segmented and cross-referenced against a library of gestural components performed by the teacher. This facilitates alignment and score-based assessment of individual movements within the context of the dance sequence. An immersive interface enables the student to review his or her performance from a number of vantage points, each providing a unique perspective and spatial context suggestive of how the student might make improvements in training. An evaluation of the recognition and virtual feedback systems is presented.", "paper_title": "An Approach to Ballet Dance Training through MS Kinect and Visualization in a CAVE Virtual Reality Environment", "paper_id": "WOS:000354049800013"}