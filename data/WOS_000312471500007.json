{"auto_keywords": [{"score": 0.036238691988388944, "phrase": "prosodic_word_prominence"}, {"score": 0.02785401173435866, "phrase": "factored_translation_models"}, {"score": 0.00481495049065317, "phrase": "machine-mediated_speech-to-speech_translation"}, {"score": 0.00449183202322304, "phrase": "key_contextual_information"}, {"score": 0.0043147264956783565, "phrase": "translation_process"}, {"score": 0.004054598617367474, "phrase": "complementary_knowledge_source"}, {"score": 0.0039665679106594106, "phrase": "end_users"}, {"score": 0.003937649447496154, "phrase": "improved_understanding"}, {"score": 0.0037823114064881357, "phrase": "general_framework"}, {"score": 0.003741016338085083, "phrase": "rich_contextual_information"}, {"score": 0.003659768899837118, "phrase": "novel_methodologies"}, {"score": 0.0036198068824262464, "phrase": "source_side_context"}, {"score": 0.0035541673947328163, "phrase": "dialog_act"}, {"score": 0.0034642599795044445, "phrase": "target_side_context"}, {"score": 0.0033397385936467204, "phrase": "da_tags"}, {"score": 0.003161271802988128, "phrase": "lexical_choice_model"}, {"score": 0.0030925761790620027, "phrase": "interpretable_da_annotated_target_language_translations"}, {"score": 0.003036468052876648, "phrase": "significant_improvements"}, {"score": 0.002992313172550772, "phrase": "automatic_evaluation_metrics"}, {"score": 0.002959617637433, "phrase": "lexical_selection_accuracy"}, {"score": 0.0029380187414193653, "phrase": "bleu_score"}, {"score": 0.0028741605025505435, "phrase": "finer_representation"}, {"score": 0.002853183476661506, "phrase": "dialog_information"}, {"score": 0.00276066021951467, "phrase": "open_questions"}, {"score": 0.002690771424958613, "phrase": "translation_quality"}, {"score": 0.0026613618933208467, "phrase": "target_side_enrichment"}, {"score": 0.0024462867877027435, "phrase": "significant_improvement"}, {"score": 0.0024106932919085097, "phrase": "correct_pitch_accents"}, {"score": 0.0023843376332011936, "phrase": "target_words"}, {"score": 0.00234104879370883, "phrase": "post-processing_approach"}, {"score": 0.002248553559414903, "phrase": "utterance_level_contextual_information"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Speech-to-speech translation", " Rich context", " Dialog acts", " Prosody"], "paper_abstract": "Conventional approaches to speech-to-speech (S2S) translation typically ignore key contextual information such as prosody, emphasis, discourse state in the translation process. Capturing and exploiting such contextual information is especially important in machine-mediated S2S translation as it can serve as a complementary knowledge source that can potentially aid the end users in improved understanding and disambiguation. In this work, we present a general framework for integrating rich contextual information in S2S translation. We present novel methodologies for integrating source side context in the form of dialog act (DA) tags, and target side context using prosodic word prominence. We demonstrate the integration of the DA tags in two different statistical translation frameworks, phrase-based translation and a bag-of-words lexical choice model. In addition to producing interpretable DA annotated target language translations, we also obtain significant improvements in terms of automatic evaluation metrics such as lexical selection accuracy and BLEU score. Our experiments also indicate that finer representation of dialog information such as yes no questions, wit-questions and open questions are the most useful in improving translation quality. For target side enrichment, we employ factored translation models to integrate the assignment and transfer of prosodic word prominence (pitch accents) during translation. The factored translation models provide significant improvement in assignment of correct pitch accents to the target words in comparison with a post-processing approach. Our framework is suitable for integrating any word or utterance level contextual information that can be reliably detected (recognized) from speech and/or text. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Enriching machine-mediated speech-to-speech translation using contextual information", "paper_id": "WOS:000312471500007"}