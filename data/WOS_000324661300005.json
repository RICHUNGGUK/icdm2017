{"auto_keywords": [{"score": 0.03616457540369227, "phrase": "web_video_event_mining"}, {"score": 0.00481495049065317, "phrase": "novel_web_video_event_mining_framework"}, {"score": 0.004513255056769647, "phrase": "massive_web_videos"}, {"score": 0.004446349752828045, "phrase": "imperative_demand"}, {"score": 0.004337028108577593, "phrase": "major_events"}, {"score": 0.004230382915464492, "phrase": "distinct_characteristics"}, {"score": 0.004188459638572375, "phrase": "web_videos"}, {"score": 0.0040854526743211396, "phrase": "limited_number"}, {"score": 0.003984968827278219, "phrase": "noisy_text_information"}, {"score": 0.003906357144047631, "phrase": "unavoidable_error"}, {"score": 0.0038676325043529524, "phrase": "near-duplicate_keyframes"}, {"score": 0.0037537380967196123, "phrase": "make_web_video_event"}, {"score": 0.0036980501827538455, "phrase": "challenging_task"}, {"score": 0.0035358770665604657, "phrase": "novel_four-stage_framework"}, {"score": 0.0033306180744375616, "phrase": "first_stage"}, {"score": 0.0032975819773787985, "phrase": "multiple_correspondence_analysis"}, {"score": 0.003264883173470498, "phrase": "mca"}, {"score": 0.002925728709297618, "phrase": "high-level_semantic_concepts"}, {"score": 0.00286795254228461, "phrase": "co-occurrence_information"}, {"score": 0.002687922713487696, "phrase": "ndk-within-video_information"}, {"score": 0.0024693981263926488, "phrase": "ndk"}, {"score": 0.002349228457383314, "phrase": "relatively_low_frequencies"}, {"score": 0.0023028105026714533, "phrase": "useful_information"}, {"score": 0.0022573076362326135, "phrase": "experimental_results"}, {"score": 0.002234893735225432, "phrase": "large-scale_web_videos"}, {"score": 0.002158179521369965, "phrase": "proposed_framework"}, {"score": 0.0021049977753042253, "phrase": "good_results"}], "paper_keywords": ["web video event mining", " multiple correspondence analysis", " co-occurrence", " near-duplicate keyframe"], "paper_abstract": "The massive web videos prompt an imperative demand on efficiently grasping the major events. However, the distinct characteristics of web videos, such as the limited number of features, the noisy text information, and the unavoidable error in near-duplicate keyframes (NDKs) detection, make web video event mining a challenging task. In this paper, we propose a novel four-stage framework to improve the performance of web video event mining. Data preprocessing is the first stage. Multiple Correspondence Analysis (MCA) is then applied to explore the correlation between terms and classes, targeting for bridging the gap between NDKs and high-level semantic concepts. Next, co-occurrence information is used to detect the similarity between NDKs and classes using the NDK-within-video information. Finally, both of them are integrated for web video event mining through negative NDK pruning and positive NDK enhancement. Moreover, both NDKs and terms with relatively low frequencies are treated as useful information in our experiments. Experimental results on large-scale web videos from You Tube demonstrate that the proposed framework outperforms several existing mining methods and obtains good results for web video event mining.", "paper_title": "A Novel Web Video Event Mining Framework with the Integration of Correlation and Co-Occurrence Information", "paper_id": "WOS:000324661300005"}