{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "k_nearest_neighbors"}, {"score": 0.04274518365190484, "phrase": "knn_searching_algorithm"}, {"score": 0.03558000142781926, "phrase": "nearest_neighbors"}, {"score": 0.004755650013733963, "phrase": "point_clouds"}, {"score": 0.00446987606516801, "phrase": "point_cloud_model"}, {"score": 0.00443308765153716, "phrase": "noise_removal"}, {"score": 0.004396600680348434, "phrase": "surface_curvature_computation"}, {"score": 0.004201202199968683, "phrase": "point_cloud_model_increase"}, {"score": 0.0039323225960857956, "phrase": "better_knn_approach"}, {"score": 0.0036352070472201086, "phrase": "new_strategy"}, {"score": 0.003590383760209319, "phrase": "corresponding_algorithm"}, {"score": 0.003473529187092258, "phrase": "target_points"}, {"score": 0.0032376465741070274, "phrase": "reverse_nearest_neighborhood"}, {"score": 0.0031452231581533814, "phrase": "nearest_points"}, {"score": 0.0031064226956732497, "phrase": "query_point"}, {"score": 0.0030680994147125364, "phrase": "repetitive_euclidean_distance_calculation"}, {"score": 0.003030247482854539, "phrase": "extracting_process"}, {"score": 0.0027665315772006575, "phrase": "inner_product"}, {"score": 0.002709862658377861, "phrase": "direct_euclidean_distance_calculations"}, {"score": 0.0026543514413663893, "phrase": "initial_neighbors"}, {"score": 0.0025257081555100556, "phrase": "partial_set"}, {"score": 0.0023540387251475615, "phrase": "proposed_approach"}, {"score": 0.0023346234464901978, "phrase": "experimental_results"}, {"score": 0.002203117204010397, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["kNN searching algorithm", " Extracting algorithm", " Distance comparison using vector inner product", " Point clouds"], "paper_abstract": "k Nearest neighbors (kNN) searching algorithm is widely used for finding k nearest neighbors for each point in a point cloud model for noise removal and surface curvature computation. When the number of points and their density in a point cloud model increase significantly, the efficiency of a kNN searching algorithm becomes critical to various applications, thus, a better kNN approach is needed. In order to improve the efficiency of a kNN searching algorithm, in this paper, a new strategy and the corresponding algorithm are developed for reducing the amount of target points in a given data set by extracting nearest neighbors before the search begins. The nearest neighbors of a reverse nearest neighborhood are proposed to use in extracting nearest points of a query point, avoiding repetitive Euclidean distance calculation in an extracting process for saving time and memories. For any point in the model, its initial nearest neighbors can be extracted from its reverse neighborhood using an inner product of two related vectors other than direct Euclidean distance calculations and comparisons. The initial neighbors can be its full or partial set of the all nearest neighbors. If it is a partial set, the rest can be obtained by using other fast searching algorithms, which can be integrated with the proposed approach. Experimental results show that integrating extracting algorithm proposed in this paper with other excellent algorithms provides a better performance by comparing to their performances alone. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A new extracting algorithm of k nearest neighbors searching for point clouds", "paper_id": "WOS:000343852400022"}