{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "volume_graphics"}, {"score": 0.00473509474652851, "phrase": "transparent_and_translucent_objects"}, {"score": 0.004155822339559211, "phrase": "heterogeneous_refractive_properties"}, {"score": 0.004086853315059217, "phrase": "refractive_effects"}, {"score": 0.004034275571593995, "phrase": "refractive_rendering"}, {"score": 0.003992207640169795, "phrase": "light_travels"}, {"score": 0.003939107874750185, "phrase": "straight_line"}, {"score": 0.003822191555851545, "phrase": "smoothly_distributed_normals"}, {"score": 0.0037839928025418896, "phrase": "good-quality_visual_representations"}, {"score": 0.003445316481824611, "phrase": "comprehensive_study"}, {"score": 0.0032112897905024976, "phrase": "voxel_gradients"}, {"score": 0.00318984544993994, "phrase": "discretely_sampled_volume_datasets"}, {"score": 0.003168543855125077, "phrase": "nonlinear_diffusion_methods"}, {"score": 0.0030031579316332994, "phrase": "unnecessary_geometrical_distortion"}, {"score": 0.0029631742332058087, "phrase": "functional_specification"}, {"score": 0.0029335351665967396, "phrase": "volumetric_filter"}, {"score": 0.0029139401928060123, "phrase": "regularized_anisotropic_nonlinear_diffusion"}, {"score": 0.002662231916149843, "phrase": "gaussian"}, {"score": 0.0026263842544386948, "phrase": "linear_diffusion_filter"}, {"score": 0.002539802613867159, "phrase": "significant_improvements"}, {"score": 0.002522830979240594, "phrase": "image_quality"}, {"score": 0.0024892263318773704, "phrase": "excessive_distortion"}, {"score": 0.0024478477463201302, "phrase": "practical_feasibility"}, {"score": 0.0022967713922705, "phrase": "volume_graphics_api"}, {"score": 0.0021987994275190314, "phrase": "increased_demands"}, {"score": 0.002184101477091303, "phrase": "computational_resources"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": [""], "paper_abstract": "Modeling and rendering transparent and translucent objects is one of the most important features of volume graphics. Refraction is a phenomenon closely coupled with such objects, but has largely been overlooked in volume graphics and visualization. There are two main technical difficulties. First, it is expensive to model heterogeneous refractive properties, and to incorporate refractive effects into volume rendering engines that assume light travels only along a straight line. Second, rendering refraction in volume graphics requires smoothly distributed normals to synthesize good-quality visual representations. Such refractive visualization is more susceptible to noise in the data than visualizations that do not involve refraction. In this paper, we present a comprehensive study of modeling and rendering refraction in volume graphics. In particular, we address the need for improving the continuity of voxel gradients in discretely sampled volume datasets using nonlinear diffusion methods, which were originally developed for image denoising. We consider the need for minimizing unnecessary geometrical distortion, detail the functional specification of a volumetric filter for regularized anisotropic nonlinear diffusion (R-ANLD), discuss further improvements of the filter, and compare the efficacy of the filter with an anisotropic nonlinear diffusion (ANLD) filter as well as a Gaussian filter and a linear diffusion filter. Our results indicate that it is possible to make significant improvements in image quality in refractive rendering without excessive distortion. To demonstrate the practical feasibility of modeling and rendering refraction in volume graphics, we describe the implementation of refractive rendering through vlib, a volume graphics API, and discuss the parallelization of vlib in order to meet the increased demands of computational resources imposed by refractive volume rendering. (C) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Refraction in volume graphics", "paper_id": "WOS:000241927300004"}