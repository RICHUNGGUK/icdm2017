{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "visual_arts"}, {"score": 0.004586531354697466, "phrase": "specific_areas"}, {"score": 0.004235793609579307, "phrase": "successful_grouping"}, {"score": 0.004198510172614725, "phrase": "similar_pieces"}, {"score": 0.004161553532799662, "phrase": "visual_art"}, {"score": 0.0040347380310668994, "phrase": "eye_tracking"}, {"score": 0.003929107176349023, "phrase": "large_groups"}, {"score": 0.0036445446531633368, "phrase": "novel_algorithm"}, {"score": 0.0035965032173588753, "phrase": "eye_movements"}, {"score": 0.00354909279546064, "phrase": "scan_paths"}, {"score": 0.0034868462688262864, "phrase": "time_frames"}, {"score": 0.003456132182564149, "phrase": "real_time"}, {"score": 0.003335948601271999, "phrase": "attention_model"}, {"score": 0.0032629585038738856, "phrase": "rectangle_features"}, {"score": 0.0032342481528929465, "phrase": "adaboost"}, {"score": 0.00289546142998427, "phrase": "significant_improvements"}, {"score": 0.0028572658971252616, "phrase": "previous_approaches"}, {"score": 0.0027578496677536373, "phrase": "eye_tracker"}, {"score": 0.0026736945502820303, "phrase": "standard_eye-tracking_software"}, {"score": 0.002615156460073562, "phrase": "recorded_data"}, {"score": 0.002592100731070259, "phrase": "eye_tracking_experiments"}, {"score": 0.0024579623598183355, "phrase": "stimulus_areas"}, {"score": 0.0023101951336207955, "phrase": "earlier_works"}, {"score": 0.0022297712188622293, "phrase": "presented_algorithm"}, {"score": 0.0021049977753042253, "phrase": "human_perception"}], "paper_keywords": ["Algorithms", " Experimentation", " Human Factors", " Visual attention", " eye movement", " perception"], "paper_abstract": "When people look at pictures, they fixate on specific areas. The sequences of such fixations are so characteristic for certain pictures that metrics can be derived that allow successful grouping of similar pieces of visual art. However, determining enough fixation sequences by eye tracking is not practically feasible for large groups of people and pictures. In order to get around this limitation, we present a novel algorithm that simulates eye movements by calculating scan paths for images and time frames in real time. The basis of our algorithm is an attention model that combines and optimizes rectangle features with Adaboost. The model is adapted to the characteristics of the retina, and its input is dependent on a few earlier fixations. This method results in significant improvements compared to previous approaches. Our simulation process delivers the same data structures as an eye tracker, thus can be analyzed by standard eye-tracking software. A comparison with recorded data from eye tracking experiments shows that our algorithm for simulating fixations has a very good prediction quality for the stimulus areas on which many subjects focus. We also compare the results with those from earlier works. Finally, we demonstrate how the presented algorithm can be used to calculate the similarity of pictures in terms of human perception.", "paper_title": "Simulating Fixations When Looking at Visual Arts", "paper_id": "WOS:000360006600003"}