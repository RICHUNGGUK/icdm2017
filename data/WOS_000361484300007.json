{"auto_keywords": [{"score": 0.04197910533074167, "phrase": "hmax"}, {"score": 0.008713765066461175, "phrase": "invariant_visual_object_recognition"}, {"score": 0.007454388028467992, "phrase": "visnet"}, {"score": 0.004703149944841539, "phrase": "key_properties"}, {"score": 0.004666460260366703, "phrase": "inferior_temporal_cortex_neurons"}, {"score": 0.00452252857066346, "phrase": "biological_plausibility"}, {"score": 0.004434824354230475, "phrase": "visual_object_recognition"}, {"score": 0.004383016741930174, "phrase": "ventral_visual_system"}, {"score": 0.004084584884062157, "phrase": "object_classification"}, {"score": 0.004052701031142039, "phrase": "random_exemplars"}, {"score": 0.003927625349474979, "phrase": "final_layer_c_neurons"}, {"score": 0.0036600862989330106, "phrase": "single-neuron_responses"}, {"score": 0.0036172962914449826, "phrase": "object_class"}, {"score": 0.0035056109035307716, "phrase": "invariant_representations"}, {"score": 0.0034510635632071978, "phrase": "different_views"}, {"score": 0.003279559293934528, "phrase": "biologically_plausible_pattern_association_network"}, {"score": 0.0031658283119347396, "phrase": "view_invariance"}, {"score": 0.003092200512475624, "phrase": "visnet_neurons"}, {"score": 0.0030321497870310077, "phrase": "scrambled_images"}, {"score": 0.0029500270981001058, "phrase": "shape_information"}, {"score": 0.002926973459215349, "phrase": "hmax_neurons"}, {"score": 0.002892729377519916, "phrase": "similarly_high_rates"}, {"score": 0.0027167292419065514, "phrase": "hmax_performance"}, {"score": 0.0024150092189446424, "phrase": "learning_mechanism"}, {"score": 0.002358801930248239, "phrase": "view-invariant_learning"}, {"score": 0.002285883886723896, "phrase": "neurobiological_mechanisms"}, {"score": 0.0022680085357731196, "phrase": "high-level_vision"}, {"score": 0.002223927963267319, "phrase": "different_approaches"}, {"score": 0.0021467260992026295, "phrase": "fundamental_underlying_principles"}, {"score": 0.0021049977753042253, "phrase": "ventral_visual_stream"}], "paper_keywords": ["Visual object recognition", " Invariant representations", " Inferior temporal visual cortex", " VisNet", " HMAX", " Trace learning rule"], "paper_abstract": "Key properties of inferior temporal cortex neurons are described, and then, the biological plausibility of two leading approaches to invariant visual object recognition in the ventral visual system is assessed to investigate whether they account for these properties. Experiment 1 shows that VisNet performs object classification with random exemplars comparably to HMAX, except that the final layer C neurons of HMAX have a very non-sparse representation (unlike that in the brain) that provides little information in the single-neuron responses about the object class. Experiment 2 shows that VisNet forms invariant representations when trained with different views of each object, whereas HMAX performs poorly when assessed with a biologically plausible pattern association network, as HMAX has no mechanism to learn view invariance. Experiment 3 shows that VisNet neurons do not respond to scrambled images of faces, and thus encode shape information. HMAX neurons responded with similarly high rates to the unscrambled and scrambled faces, indicating that low-level features including texture may be relevant to HMAX performance. Experiment 4 shows that VisNet can learn to recognize objects even when the view provided by the object changes catastrophically as it transforms, whereas HMAX has no learning mechanism in its S-C hierarchy that provides for view-invariant learning. This highlights some requirements for the neurobiological mechanisms of high-level vision, and how some different approaches perform, in order to help understand the fundamental underlying principles of invariant visual object recognition in the ventral visual stream.", "paper_title": "Invariant visual object recognition: biologically plausible approaches", "paper_id": "WOS:000361484300007"}