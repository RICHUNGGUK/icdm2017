{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "characters_-_creating_new_human_performances"}, {"score": 0.004750873844061641, "phrase": "multi-view_video_database"}, {"score": 0.00458412183693466, "phrase": "plausible_video_sequences"}, {"score": 0.004482873744893272, "phrase": "user-defined_body_motions"}, {"score": 0.004325487452170154, "phrase": "small_database"}, {"score": 0.004287008195370748, "phrase": "multi-view_video_sequences"}, {"score": 0.0037997077863530897, "phrase": "marker-less_model-based_performance_capture_approach"}, {"score": 0.0035532533960012298, "phrase": "database_frame"}, {"score": 0.0034902664176377943, "phrase": "novel_video_sequences"}, {"score": 0.003278447235176858, "phrase": "novel_motion"}, {"score": 0.0031632120077478066, "phrase": "realistic_video_sequence"}, {"score": 0.0030794433253250476, "phrase": "specified_motion"}, {"score": 0.0030113280682863234, "phrase": "initial_database"}, {"score": 0.002971182100871581, "phrase": "first_key_component"}, {"score": 0.002905454531687249, "phrase": "new_efficient_retrieval_strategy"}, {"score": 0.0028667159745494933, "phrase": "appropriate_spatio-temporally_coherent_database_frames"}, {"score": 0.0028032928749970026, "phrase": "target_video_frames"}, {"score": 0.0027659126653647712, "phrase": "second_key_component"}, {"score": 0.002729029534060092, "phrase": "warping-based_texture_synthesis_approach"}, {"score": 0.0026806139086152365, "phrase": "retrieved_most-similar_database_frames"}, {"score": 0.002644865209801606, "phrase": "spatio-temporally_coherent_target_video_frames"}, {"score": 0.0025178072071268534, "phrase": "video_sequences"}, {"score": 0.002473129577319634, "phrase": "dangerous_stunts"}, {"score": 0.0024075916292945715, "phrase": "harm's_way"}, {"score": 0.002322895056238477, "phrase": "result_videos"}, {"score": 0.002291905937251069, "phrase": "user_study"}, {"score": 0.002241171326888997, "phrase": "realistic_videos"}, {"score": 0.0021720199689914464, "phrase": "target_motions"}, {"score": 0.0021526564019119466, "phrase": "camera_views"}, {"score": 0.0021049977753042253, "phrase": "database_content"}], "paper_keywords": [""], "paper_abstract": "We present a method to synthesize plausible video sequences of humans according to user-defined body motions and viewpoints. We first capture a small database of multi-view video sequences of an actor performing various basic motions. This database needs to be captured only once and serves as the input to our synthesis algorithm. We then apply a marker-less model-based performance capture approach to the entire database to obtain pose and geometry of the actor in each database frame. To create novel video sequences of the actor from the database, a user animates a 3D human skeleton with novel motion and viewpoints. Our technique then synthesizes a realistic video sequence of the actor performing the specified motion based only on the initial database. The first key component of our approach is a new efficient retrieval strategy to find appropriate spatio-temporally coherent database frames from which to synthesize target video frames. The second key component is a warping-based texture synthesis approach that uses the retrieved most-similar database frames to synthesize spatio-temporally coherent target video frames. For instance, this enables us to easily create video sequences of actors performing dangerous stunts without them being placed in harm's way. We show through a variety of result videos and a user study that we can synthesize realistic videos of people, even if the target motions and camera views are different from the database content.", "paper_title": "Video-based Characters - Creating New Human Performances from a Multi-view Video Database", "paper_id": "WOS:000297216400006"}