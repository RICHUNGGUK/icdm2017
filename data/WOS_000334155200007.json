{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "g-hadoop"}, {"score": 0.007788475325773707, "phrase": "hadoop"}, {"score": 0.007409100623666662, "phrase": "mapreduce_tasks"}, {"score": 0.004637478829869904, "phrase": "distributed_cloud_data_centres"}, {"score": 0.0045798077999572645, "phrase": "mapreduce"}, {"score": 0.004438642216475526, "phrase": "adequate_programming_model"}, {"score": 0.004383406949799696, "phrase": "large-scale_data-intensive_applications"}, {"score": 0.004195418010131832, "phrase": "well-known_mapreduce_implementation"}, {"score": 0.004015458740397976, "phrase": "cluster_system"}, {"score": 0.0035648266669315943, "phrase": "multiple_clusters"}, {"score": 0.0033905067962602515, "phrase": "user_authentication"}, {"score": 0.0033482708495261864, "phrase": "job_submission_mechanism"}, {"score": 0.0031646057802503526, "phrase": "single_cluster"}, {"score": 0.003047776993499616, "phrase": "new_security_model"}, {"score": 0.002953711377604328, "phrase": "security_model"}, {"score": 0.0028268629720802772, "phrase": "public_key_cryptography"}, {"score": 0.0027741761880779535, "phrase": "ssl_protocol"}, {"score": 0.002655017467085696, "phrase": "distributed_environments"}, {"score": 0.0026055251533586804, "phrase": "security_framework"}, {"score": 0.0025569530630374995, "phrase": "users_authentication_and_job_submission_process"}, {"score": 0.002431797888365548, "phrase": "single-sign-on_approach"}, {"score": 0.0023419588513908783, "phrase": "designed_security_framework"}, {"score": 0.0022696277881969896, "phrase": "different_security_mechanisms"}, {"score": 0.0022133711375320244, "phrase": "g-hadoop_system"}, {"score": 0.0021857667493036786, "phrase": "traditional_attacks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Cloud computing", " Massive data processing", " Data-intensive computing", " Security model", " Map Reduce"], "paper_abstract": "MapReduce is regarded as an adequate programming model for large-scale data-intensive applications. The Hadoop framework is a well-known MapReduce implementation that runs the MapReduce tasks on a cluster system. G-Hadoop is an extension of the Hadoop MapReduce framework with the functionality of allowing the MapReduce tasks to run on multiple clusters. However, G-Hadoop simply reuses the user authentication and job submission mechanism of Hadoop, which is designed for a single cluster. This work proposes a new security model for G-Hadoop. The security model is based on several security solutions such as public key cryptography and the SSL protocol, and is dedicatedly designed for distributed environments. This security framework simplifies the users authentication and job submission process of the current G-Hadoop implementation with a single-sign-on approach. In addition, the designed security framework provides a number of different security mechanisms to protect the G-Hadoop system from traditional attacks. (c) 2014 Elsevier Inc. All rights reserved.", "paper_title": "A security framework in G-Hadoop for big data computing across distributed Cloud data centres", "paper_id": "WOS:000334155200007"}