{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "structural_risk_minimization_problem"}, {"score": 0.004608284537368354, "phrase": "novel_approach"}, {"score": 0.004442824994700736, "phrase": "structural_risk_minimization"}, {"score": 0.004221072004655573, "phrase": "general_setting"}, {"score": 0.0041294419262414995, "phrase": "machine_learning_problem"}, {"score": 0.0038946650372062783, "phrase": "fundamental_concept"}, {"score": 0.003838078705946304, "phrase": "supervised_learning"}, {"score": 0.003754731210715724, "phrase": "bi-objective_optimization_problem"}, {"score": 0.0033890026927890058, "phrase": "empirical_training_error"}, {"score": 0.003315374849824563, "phrase": "machine_complexity"}, {"score": 0.002970476379751357, "phrase": "particular_practical_case"}, {"score": 0.002905914725757534, "phrase": "minimum_gradient_method"}, {"score": 0.0026613618933208467, "phrase": "fat-shattering_dimension"}, {"score": 0.0026035011274172753, "phrase": "practical_mechanism"}, {"score": 0.0023324855762635616, "phrase": "aforementioned_definitions"}, {"score": 0.002298544073884724, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "proposed_ideas"}], "paper_keywords": ["complexity measure", " multiobjective training algorithms", " neural networks", " parallel layer perceptron (PLP)", " regularization methods", " structural risk minimization (SRM)"], "paper_abstract": "This paper presents a novel approach for dealing with the structural risk minimization (SRM) applied to a general setting of the machine learning problem. The formulation is based on the fundamental concept that supervised learning is a bi-objective optimization problem in which two conflicting objectives should be minimized. The objectives are related to the empirical training error and the machine complexity. In this paper, one general Q-norm method to compute the machine complexity is presented, and, as a particular practical case, the minimum gradient method (MGM) is derived relying on the definition of the fat-shattering dimension. A practical mechanism for parallel layer perceptron (PLP) network training, involving only quasi-convex functions, is generated using the aforementioned definitions. Experimental results on 15 different benchmarks are presented, which show the potential of the proposed ideas.", "paper_title": "The Q-norm complexity measure and the minimum gradient method: A novel approach to the machine learning structural risk minimization problem", "paper_id": "WOS:000258505700008"}