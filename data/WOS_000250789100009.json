{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "dd-grnn"}, {"score": 0.0047057084749407485, "phrase": "function_approximation"}, {"score": 0.004494570360108983, "phrase": "new_nonparametric_regression_method"}, {"score": 0.004260134699483774, "phrase": "generalized_regression_neural_networks"}, {"score": 0.0041001740903338834, "phrase": "density-dependent_multiple_kernel_bandwidths"}, {"score": 0.003916098498242888, "phrase": "presented_model"}, {"score": 0.003545024951402821, "phrase": "trainable_weights"}, {"score": 0.003438058620195309, "phrase": "regression_model"}, {"score": 0.0032585499655442404, "phrase": "extracted_data_density_features"}, {"score": 0.003160200215473349, "phrase": "density_properties"}, {"score": 0.0031121406603482112, "phrase": "distribution_irregularities"}, {"score": 0.0030414140732789186, "phrase": "training_data_sets"}, {"score": 0.0029270797740550973, "phrase": "efficient_initialization_scheme"}, {"score": 0.002860546817196148, "phrase": "second-order_algorithm"}, {"score": 0.0026494723416072316, "phrase": "overtitting_control_mechanism"}, {"score": 0.0025892330566358503, "phrase": "bayesian_regularization"}, {"score": 0.00254983442025512, "phrase": "numerical_results"}, {"score": 0.002472822097373027, "phrase": "proposed_network"}, {"score": 0.002361632539339945, "phrase": "computational_demands"}, {"score": 0.0023079225317714815, "phrase": "individual_bandwidths"}, {"score": 0.0021705796895687864, "phrase": "competitive_function_approximation_accuracy"}, {"score": 0.0021049977753042253, "phrase": "existing_methods"}], "paper_keywords": ["density based", " function approximation", " Generalized Regression Neural Network (GRNN)", " regularization."], "paper_abstract": "This paper proposes a new nonparametric regression method, based on the combination of generalized regression neural networks (GRNNs), density-dependent multiple kernel bandwidths, and regularization. The presented model is generic and substitutes the very large number of bandwidths with a much smaller number of trainable weights that control the regression model. It depends on sets of extracted data density features which reflect the density properties and distribution irregularities of the training data sets. We provide an efficient initialization scheme and a second-order algorithm to train the model, as well as an overtitting control mechanism based on Bayesian regularization. Numerical results show that the proposed network manages to reduce significantly the computational demands of having individual bandwidths, while at the same time, provides competitive function approximation accuracy in relation to existing methods.", "paper_title": "Density-driven generalized regression neural networks (DD-GRNN) for function approximation", "paper_id": "WOS:000250789100009"}