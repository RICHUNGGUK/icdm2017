{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "sparse_coding"}, {"score": 0.011271891304515518, "phrase": "laplace"}, {"score": 0.004692227830462433, "phrase": "novel_hierarchical_latent_topic_model"}, {"score": 0.004342430078306461, "phrase": "computer_vision_field"}, {"score": 0.003916098498242888, "phrase": "n-dimensional_vectors"}, {"score": 0.003531474887552889, "phrase": "probability_distribution"}, {"score": 0.0034771228725942846, "phrase": "continuous_words"}, {"score": 0.0031845067058084583, "phrase": "latent_variables"}, {"score": 0.0028715299874549245, "phrase": "latent_dirichlet_allocation"}, {"score": 0.002684740763324991, "phrase": "traditional_lda"}, {"score": 0.0026297428083782875, "phrase": "concept-continuous_words"}, {"score": 0.0025625729433234623, "phrase": "em_algorithm"}, {"score": 0.0024333239726872604, "phrase": "proposed_method"}, {"score": 0.0023711591828229736, "phrase": "significant_computer_vision_problems"}, {"score": 0.0023346234464901978, "phrase": "natural_scene_categorization"}, {"score": 0.002310578855290687, "phrase": "object_classification"}, {"score": 0.0022749744354271816, "phrase": "experimental_results"}, {"score": 0.0022053994402287925, "phrase": "valuable_direction"}, {"score": 0.0021714122348552747, "phrase": "topic_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Latent topic model", " Sparse coding", " Laplace distribution"], "paper_abstract": "We propose a novel hierarchical latent topic model based on sparse coding in this paper. Unlike the other topic models applied in the computer vision field, the words in our model are not discrete but continuous. They are generated by sparse coding and represented with n-dimensional vectors in R-n. In sparse coding, only a small set of components of each word is active, so we assume the probability distribution over these continuous words is Laplace and the parameters of the Laplace distribution depend on topics, which are the latent variables in this model. The relationship among word, topic, document and corpus in our model is similar to latent Dirichlet Allocation (LDA). Thereby this model is a generalization of the traditional LDA by introducing the concept-continuous words. We use an EM algorithm to estimate the parameters in our model. And the proposed method is applied to some significant computer vision problems such as natural scene categorization and object classification. The experimental results show the method is a valuable direction to generalize topic models. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "A hierarchical latent topic model based on sparse coding", "paper_id": "WOS:000298070500005"}