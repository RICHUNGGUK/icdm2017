{"auto_keywords": [{"score": 0.049203403415225284, "phrase": "imbalanced_learning_problems"}, {"score": 0.033413566842277836, "phrase": "mwmote"}, {"score": 0.00481495049065317, "phrase": "mwmote-majority_weighted_minority_oversampling_technique"}, {"score": 0.0047707093928203, "phrase": "imbalanced_data_set_learning"}, {"score": 0.004661868629458321, "phrase": "unequal_distribution"}, {"score": 0.004619027561771169, "phrase": "data_samples"}, {"score": 0.0045765783794477505, "phrase": "different_classes"}, {"score": 0.004270347498153512, "phrase": "minority_class_samples"}, {"score": 0.004231089088705995, "phrase": "synthetic_oversampling_methods"}, {"score": 0.004096493540086106, "phrase": "synthetic_minority_class_samples"}, {"score": 0.0038756055612167942, "phrase": "minority_classes"}, {"score": 0.0037177622939493084, "phrase": "existing_oversampling_methods"}, {"score": 0.0036496814103475174, "phrase": "wrong_synthetic_minority_samples"}, {"score": 0.0035498822293046884, "phrase": "learning_tasks"}, {"score": 0.0034210342328868017, "phrase": "new_method"}, {"score": 0.0033739270918502285, "phrase": "majority_weighted_minority"}, {"score": 0.0030336118627011786, "phrase": "informative_minority_class_samples"}, {"score": 0.002896535621940078, "phrase": "nearest_majority_class_samples"}, {"score": 0.0028172726995962173, "phrase": "synthetic_samples"}, {"score": 0.0027784560880013886, "phrase": "weighted_informative_minority_class_samples"}, {"score": 0.0025802660239538353, "phrase": "minority_class_cluster"}, {"score": 0.002225196379204285, "phrase": "geometric_mean"}, {"score": 0.0021245712108461227, "phrase": "receiver_operating_curve"}, {"score": 0.002105022227239558, "phrase": "roc"}], "paper_keywords": ["Imbalanced learning", " undersampling", " oversampling", " synthetic sample generation", " clustering"], "paper_abstract": "Imbalanced learning problems contain an unequal distribution of data samples among different classes and pose a challenge to any classifier as it becomes hard to learn the minority class samples. Synthetic oversampling methods address this problem by generating the synthetic minority class samples to balance the distribution between the samples of the majority and minority classes. This paper identifies that most of the existing oversampling methods may generate the wrong synthetic minority samples in some scenarios and make learning tasks harder. To this end, a new method, called Majority Weighted Minority Oversampling TEchnique (MWMOTE), is presented for efficiently handling imbalanced learning problems. MWMOTE first identifies the hard-to-learn informative minority class samples and assigns them weights according to their euclidean distance from the nearest majority class samples. It then generates the synthetic samples from the weighted informative minority class samples using a clustering approach. This is done in such a way that all the generated samples lie inside some minority class cluster. MWMOTE has been evaluated extensively on four artificial and 20 real-world data sets. The simulation results show that our method is better than or comparable with some other existing methods in terms of various assessment metrics, such as geometric mean (G-mean) and area under the receiver operating curve (ROC), usually known as area under curve (AUC).", "paper_title": "MWMOTE-Majority Weighted Minority Oversampling Technique for Imbalanced Data Set Learning", "paper_id": "WOS:000329051000011"}