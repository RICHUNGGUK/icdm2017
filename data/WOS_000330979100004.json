{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "extreme_learning_machine"}, {"score": 0.004589763483242731, "phrase": "traditional_learning_methods"}, {"score": 0.004375061788023814, "phrase": "back_propagation"}, {"score": 0.002841545331522694, "phrase": "variable_learning_coefficient"}, {"score": 0.0021561514733516654, "phrase": "better_performance"}], "paper_keywords": ["Extreme learning machine (ELM)", " L-1/2 regularizer", " Network pruning"], "paper_abstract": "Compared with traditional learning methods such as the back propagation (BP) method, extreme learning machine provides much faster learning speed and needs less human intervention, and thus has been widely used. In this paper we combine the L (1/2) regularization method with extreme learning machine to prune extreme learning machine. A variable learning coefficient is employed to prevent too large a learning increment. A numerical experiment demonstrates that a network pruned L (1/2) regularization has fewer hidden nodes but provides better performance than both the original network and the network pruned by L (2) regularization.", "paper_title": "A pruning algorithm with L (1/2) regularizer for extreme learning machine", "paper_id": "WOS:000330979100004"}