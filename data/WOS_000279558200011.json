{"auto_keywords": [{"score": 0.046384974269406076, "phrase": "ca"}, {"score": 0.00481495049065317, "phrase": "cache-efficient_visualization"}, {"score": 0.004695900553353526, "phrase": "large_data_sets"}, {"score": 0.004625881588444304, "phrase": "data_transfer"}, {"score": 0.004488946121663966, "phrase": "cache-aware"}, {"score": 0.004143196873246147, "phrase": "memory_hierarchy"}, {"score": 0.004081385289516914, "phrase": "cache_efficient_algorithms"}, {"score": 0.004040688646993605, "phrase": "co_approaches"}, {"score": 0.003901407184706592, "phrase": "unknown_and_varying_memory_hierarchies"}, {"score": 0.0038624981944755813, "phrase": "recent_ca_and_co_algorithms"}, {"score": 0.0037106898330901534, "phrase": "previous_approaches"}, {"score": 0.0036007478932719417, "phrase": "theoretical_performance_guarantees"}, {"score": 0.0033231814056233103, "phrase": "co_layout"}, {"score": 0.0032900200522703923, "phrase": "unstructured_but_well_shaped_meshes"}, {"score": 0.0031925019616678217, "phrase": "coherent_traversal_of_a_n-size_mesh"}, {"score": 0.0028877818105020434, "phrase": "block_size"}, {"score": 0.0028446460307503343, "phrase": "cache_size"}, {"score": 0.0026120705848349055, "phrase": "best_known_co_algorithm"}, {"score": 0.002496722870659199, "phrase": "classical_visualization_algorithm_access_patterns"}, {"score": 0.002422661411769552, "phrase": "bsp_tree"}, {"score": 0.0023040642263522505, "phrase": "acceleration_data_structure"}, {"score": 0.0021802872319258977, "phrase": "oblivious_approaches"}, {"score": 0.0021049977753042253, "phrase": "recent_gpu_architectures"}], "paper_keywords": ["Cache-aware", " cache-oblivious", " mesh layouts", " data locality", " unstructured mesh", " isosurface extraction"], "paper_abstract": "One important bottleneck when visualizing large data sets is the data transfer between processor and memory. Cache-aware (CA) and cache-oblivious (CO) algorithms take into consideration the memory hierarchy to design cache efficient algorithms. CO approaches have the advantage to adapt to unknown and varying memory hierarchies. Recent CA and CO algorithms developed for 3D mesh layouts significantly improve performance of previous approaches, but they lack of theoretical performance guarantees. We present in this paper a O(N log N) algorithm to compute a CO layout for unstructured but well shaped meshes. We prove that a coherent traversal of a N-size mesh in dimension d induces less than N/B + O(N/M-1/d) cache-misses where B and M are the block size and the cache size, respectively. Experiments show that our layout computation is faster and significantly less memory consuming than the best known CO algorithm. Performance is comparable to this algorithm for classical visualization algorithm access patterns, or better when the BSP tree produced while computing the layout is used as an acceleration data structure adjusted to the layout. We also show that cache oblivious approaches lead to significant performance increases on recent GPU architectures.", "paper_title": "Binary Mesh Partitioning for Cache-Efficient Visualization", "paper_id": "WOS:000279558200011"}