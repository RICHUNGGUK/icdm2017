{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "speech_recognition"}, {"score": 0.004603525341738782, "phrase": "new_approach"}, {"score": 0.004322967486451877, "phrase": "hidden_markov_model"}, {"score": 0.003846483241152999, "phrase": "gaussians"}, {"score": 0.0030171910207671205, "phrase": "global_mapping"}, {"score": 0.002936849401568391, "phrase": "vector_space"}, {"score": 0.0027328854215129647, "phrase": "gmm."}, {"score": 0.0025892330566358503, "phrase": "better_results"}, {"score": 0.0025202582748972122, "phrase": "conventional_model"}, {"score": 0.0024311346712789553, "phrase": "extra_structure"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Speech recognition", " Gaussian Mixture Model", " Subspace Gaussian Mixture Model"], "paper_abstract": "We describe a new approach to speech recognition, in which all Hidden Markov Model (HMM) states share the same Gaussian Mixture Model (GMM) structure with the same number of Gaussians in each state. The model is defined by vectors associated with each state with a dimension of, say, 50, together with a global mapping from this vector space to the space of parameters of the GMM. This model appears to give better results than a conventional model, and the extra structure offers many new opportunities for modeling innovations while maintaining compatibility with most standard techniques. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "The subspace Gaussian mixture model-A structured model for speech recognition", "paper_id": "WOS:000284670200017"}