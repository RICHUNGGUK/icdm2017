{"auto_keywords": [{"score": 0.0412505315606271, "phrase": "proposed_algorithm"}, {"score": 0.00481495049065317, "phrase": "stereoscopic_scene_flow_computation"}, {"score": 0.004650896226390719, "phrase": "recent_developments"}, {"score": 0.004597457370802855, "phrase": "optical_flow"}, {"score": 0.004544629724830453, "phrase": "stereo_matching_estimation"}, {"score": 0.004415189385015778, "phrase": "variational_framework"}, {"score": 0.004289419884432487, "phrase": "stereoscopic_scene_flow"}, {"score": 0.004048483412089098, "phrase": "three-dimensional_world"}, {"score": 0.004001938457469328, "phrase": "stereo_image_sequences"}, {"score": 0.0038654774211631564, "phrase": "account_image_pairs"}, {"score": 0.0034233569308012982, "phrase": "previous_works"}, {"score": 0.003306559295382181, "phrase": "depth_estimation"}, {"score": 0.0032496585171039797, "phrase": "motion_estimation"}, {"score": 0.003120657021758196, "phrase": "variational_formulation"}, {"score": 0.0029794666460666646, "phrase": "sparse_or_dense_disparity_maps"}, {"score": 0.0027003157818610386, "phrase": "fpga"}, {"score": 0.0025633247416430994, "phrase": "gpu"}, {"score": 0.0024756080101497086, "phrase": "frame_rates"}, {"score": 0.002391067964886602, "phrase": "qvga_images"}, {"score": 0.0021794454466797382, "phrase": "scene_flow_estimation"}, {"score": 0.002129527338875116, "phrase": "intensity_consistency"}, {"score": 0.0021049977753042253, "phrase": "input_images"}], "paper_keywords": ["Scene flow", " 3D motion", " 3D reconstruction", " Structure from motion", " Motion segmentation"], "paper_abstract": "Building upon recent developments in optical flow and stereo matching estimation, we propose a variational framework for the estimation of stereoscopic scene flow, i.e., the motion of points in the three-dimensional world from stereo image sequences. The proposed algorithm takes into account image pairs from two consecutive times and computes both depth and a 3D motion vector associated with each point in the image. In contrast to previous works, we partially decouple the depth estimation from the motion estimation, which has many practical advantages. The variational formulation is quite flexible and can handle both sparse or dense disparity maps. The proposed method is very efficient; with the depth map being computed on an FPGA, and the scene flow computed on the GPU, the proposed algorithm runs at frame rates of 20 frames per second on QVGA images (320 x 240 pixels). Furthermore, we present solutions to two important problems in scene flow estimation: violations of intensity consistency between input images, and the uncertainty measures for the scene flow result.", "paper_title": "Stereoscopic Scene Flow Computation for 3D Motion Understanding", "paper_id": "WOS:000294569300003"}