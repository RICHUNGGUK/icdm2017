{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "affine-invariant_anisotropic_regions"}, {"score": 0.0047152877145889656, "phrase": "wide_range"}, {"score": 0.004666228956744244, "phrase": "feature_detectors"}, {"score": 0.004569630374630379, "phrase": "computer_vision_community"}, {"score": 0.004475022550508119, "phrase": "direct_application"}, {"score": 0.004359500411441827, "phrase": "surgical_navigation"}, {"score": 0.004291617358806677, "phrase": "significant_difficulties"}, {"score": 0.0041589926969138585, "phrase": "reliable_salient_features"}, {"score": 0.0040942189695983185, "phrase": "free-form_tissue_deformation"}, {"score": 0.00396767023935381, "phrase": "surgical_scenes"}, {"score": 0.0037456980766939836, "phrase": "novel_probabilistic_framework"}, {"score": 0.0036489343475053187, "phrase": "contrastingly_different_visual_appearances"}, {"score": 0.003610929883213109, "phrase": "minimally_invasive_surgery"}, {"score": 0.003573372429809867, "phrase": "mis"}, {"score": 0.0034992667091713813, "phrase": "theoretical_background"}, {"score": 0.003444732262403694, "phrase": "affine-invariant_anisotropic_feature_detector"}, {"score": 0.003355717283753749, "phrase": "real-time_implementation"}, {"score": 0.003303412571939192, "phrase": "computational_power"}, {"score": 0.0032521680936918877, "phrase": "gpu"}, {"score": 0.003069867656852932, "phrase": "parameterization_scheme"}, {"score": 0.0029593432468318745, "phrase": "optimal_templates"}, {"score": 0.0029131986574478046, "phrase": "detected_regions"}, {"score": 0.002867771524071872, "phrase": "accurate_identification"}, {"score": 0.0027936239349923464, "phrase": "tracked_features"}, {"score": 0.002750056254309311, "phrase": "effective_tracking_verification"}, {"score": 0.002721388234661538, "phrase": "spatial_context"}, {"score": 0.0024764383700305722, "phrase": "ekf"}, {"score": 0.0024377918036784336, "phrase": "potential_tracking_failure"}, {"score": 0.002374735066990346, "phrase": "false_positives"}, {"score": 0.002337684811187166, "phrase": "proposed_framework"}, {"score": 0.0022772115643656153, "phrase": "existing_methods"}, {"score": 0.0021951623041245897, "phrase": "vivo_video_sequences"}, {"score": 0.0021609076467365247, "phrase": "robotic-assisted_mis_procedures"}, {"score": 0.0021049977753042253, "phrase": "real-world_scenes"}], "paper_keywords": ["Salient feature extraction", " feature point tracking", " image-guided navigation"], "paper_abstract": "Despite a wide range of feature detectors developed in the computer vision community over the years, direct application of these techniques to surgical navigation has shown significant difficulties due to the paucity of reliable salient features coupled with free-form tissue deformation and changing visual appearance of surgical scenes. The aim of this paper is to propose a novel probabilistic framework to track affine-invariant anisotropic regions under contrastingly different visual appearances during Minimally Invasive Surgery (MIS). The theoretical background of the affine-invariant anisotropic feature detector is presented and a real-time implementation exploiting the computational power of the GPU is proposed. An Extended Kalman Filter (EKF) parameterization scheme is used to adaptively adjust the optimal templates of the detected regions, enabling accurate identification and matching of the tracked features. For effective tracking verification, spatial context and region similarity have also been incorporated. They are used to boost the prediction of the EKF and recover potential tracking failure due to drift or false positives. The proposed framework is compared to the existing methods and their respective performance is evaluated with in vivo video sequences recorded from robotic-assisted MIS procedures, as well as real-world scenes.", "paper_title": "Probabilistic Tracking of Affine-Invariant Anisotropic Regions", "paper_id": "WOS:000311127700013"}