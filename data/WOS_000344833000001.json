{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "analytic_sfm_filters"}, {"score": 0.004706699397060569, "phrase": "frame_features"}, {"score": 0.004531637625717547, "phrase": "image_features"}, {"score": 0.004330099613414957, "phrase": "consecutive_frames"}, {"score": 0.004264923517966271, "phrase": "sfm_filters"}, {"score": 0.003879138659123195, "phrase": "multiple_frames"}, {"score": 0.0038498211283780484, "phrase": "stronger_constraints"}, {"score": 0.0035820833812158005, "phrase": "desirable_property"}, {"score": 0.0034881908940439213, "phrase": "large_similarity"}, {"score": 0.003435643372146385, "phrase": "closely_spaced_frames"}, {"score": 0.003245520963944678, "phrase": "inter-frame_camera_motion"}, {"score": 0.0031845067058084583, "phrase": "significant_improvements"}, {"score": 0.0031246358910995316, "phrase": "online_filter-based_sfm"}, {"score": 0.0030082398041055003, "phrase": "lr_features"}, {"score": 0.0029741713977710495, "phrase": "main_contributions"}, {"score": 0.002841701708055512, "phrase": "new_method"}, {"score": 0.002746225320405654, "phrase": "analytical_filter"}, {"score": 0.0026843584448921543, "phrase": "minimal_change"}, {"score": 0.00265394824073552, "phrase": "existing_filter"}, {"score": 0.002564763827975352, "phrase": "large_increases"}, {"score": 0.0024227171881502614, "phrase": "mathematical_simplifications"}, {"score": 0.00233240715947344, "phrase": "computational_burden"}, {"score": 0.002203200914130907, "phrase": "real_and_simulated_data"}, {"score": 0.002153540857619362, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Structure from motion", " Filtering", " Complexity reduction", " Frame-to-frame features"], "paper_abstract": "In Structure From Motion (SFM), image features are matched in either an extended number of frames or only in pairs of consecutive frames. Traditionally. SFM filters have been applied using only one of the two matching paradigms, with the Long Range (LR) feature technique being more popular because of the fact that features that are matched across multiple frames provide stronger constraints on structure and motion. Nevertheless, Frame-to-Frame (F2F) features possess the desirable property of being abundant because of the large similarity that exists between closely spaced frames. Although the use of such features has been limited mostly to the determination of inter-frame camera motion, we argue that significant improvements can be attained in online filter-based SFM by integrating the F2F features into filters that use LR features. The main contributions of this paper are twofold. First, it presents a new method that enables the incorporation of F2F information in any analytical filter in a fashion that requires minimal change to the existing filter. Our results show that by doing so, large increases in accuracy are achieved in both the structure and motion estimates. Second, thanks to mathematical simplifications we realize in the filter, we minimize the computational burden of F2F integration by two orders of magnitude, thereby enabling its real-time implementation. Experimental results on real and simulated data prove the success of the proposed approach. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Augmenting analytic SFM filters with frame-to-frame features", "paper_id": "WOS:000344833000001"}