{"auto_keywords": [{"score": 0.04957466661795795, "phrase": "prototype-based_classification"}, {"score": 0.04128881285829009, "phrase": "high_classification_accuracy"}, {"score": 0.00481495049065317, "phrase": "prototype_optimisation_algorithms"}, {"score": 0.004240116703465252, "phrase": "small_set"}, {"score": 0.004042635935882651, "phrase": "computational_complexity"}, {"score": 0.0038748022659578865, "phrase": "experimental_study"}, {"score": 0.003813669883040509, "phrase": "old_and_new_prototype_optimisation_techniques"}, {"score": 0.003466536738232506, "phrase": "condensing_techniques"}, {"score": 0.0033937776228549557, "phrase": "real_data"}, {"score": 0.003322540556404882, "phrase": "vector_spaces"}, {"score": 0.002988101395789399, "phrase": "nearest_neighbour_rule"}, {"score": 0.002744888626958772, "phrase": "important_point"}, {"score": 0.002658863179011018, "phrase": "adaptive_condensing_schemes"}, {"score": 0.0023532890136269986, "phrase": "linear_dissimilarity-based_classifiers"}, {"score": 0.0022916428586256723, "phrase": "best_trade-off"}, {"score": 0.0022674379203603224, "phrase": "small_condensed_sets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["dissimilarity representation", " prototype selection", " adaptive condensing", " EM algorithm", " normal density based classifier", " nearest neighbour rule"], "paper_abstract": "Prototype-based classification relies on the distances between the examples to be classified and carefully chosen prototypes. A small set of prototypes is of interest to keep the computational complexity low, while maintaining high classification accuracy. An experimental study of some old and new prototype optimisation techniques is presented, in which the prototypes are either selected or generated from the given data. These condensing techniques are evaluated on real data, represented in vector spaces, by comparing their resulting reduction rates and classification performance. Usually the determination of prototypes is studied in relation with the nearest neighbour rule. We will show that the use of more general dissimilarity-based classifiers can be more beneficial. An important point in our study is that the adaptive condensing schemes here discussed allow the user to choose the number of prototypes freely according to the needs. If such techniques are combined with linear dissimilarity-based classifiers, they provide the best trade-off of small condensed sets and high classification accuracy. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "Experimental study on prototype optimisation algorithms for prototype-based classification in vector spaces", "paper_id": "WOS:000239475000003"}