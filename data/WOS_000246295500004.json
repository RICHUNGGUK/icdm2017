{"auto_keywords": [{"score": 0.04352907958329157, "phrase": "ams"}, {"score": 0.02322674737397314, "phrase": "novel_word"}, {"score": 0.022273442176435107, "phrase": "material_biases"}, {"score": 0.009543688146491558, "phrase": "lba"}, {"score": 0.0047132864404860865, "phrase": "known_words"}, {"score": 0.00435403401018622, "phrase": "bias_account"}, {"score": 0.0042490799524136594, "phrase": "concrete_computational_mechanism"}, {"score": 0.003913112416104065, "phrase": "corresponding_instance"}, {"score": 0.0038071107470976045, "phrase": "known_word"}, {"score": 0.0037266467875257136, "phrase": "ad-hoc_template"}, {"score": 0.0036926830072270076, "phrase": "ams_function"}, {"score": 0.0036702119930393903, "phrase": "fast_mapping"}, {"score": 0.0036478772206217282, "phrase": "vocabulary_spurt"}, {"score": 0.003592630978298206, "phrase": "ams_process"}, {"score": 0.0034109556126786693, "phrase": "explicit_representation"}, {"score": 0.0033490453422160677, "phrase": "inductive_learning_function"}, {"score": 0.003248340791706116, "phrase": "wdp"}, {"score": 0.003189372286182993, "phrase": "biased_vocabulary"}, {"score": 0.003169954314343514, "phrase": "young_children"}, {"score": 0.0030746180465357374, "phrase": "shape_biases"}, {"score": 0.002910159235873015, "phrase": "early_biased_vocabulary"}, {"score": 0.00261507100872001, "phrase": "material_bias"}, {"score": 0.0025912115192027485, "phrase": "early_small_vocabulary"}, {"score": 0.0024227511485666697, "phrase": "simpler_and_valider_mechanisms"}, {"score": 0.002386014719597134, "phrase": "previous_studies"}, {"score": 0.002190326602897302, "phrase": "simple_ad-hoc_learning"}, {"score": 0.00214396012113301, "phrase": "innate_language-specific_ones"}, {"score": 0.002105001119157694, "phrase": "elsevier"}], "paper_keywords": ["connectionist model", " prototype model", " cognitive process", " fast mapping", " shape bias", " material bias", " overgeneralized shape bias"], "paper_abstract": "Taking the stance that two well-known word learning biases ( shape and material bias) are formed through learning ( learned bias account, LBA), we illustrated a concrete computational mechanism with \"ad-hoc meaning substitution (AMS)'' hypothesis, and verified it by two computer simulations. AMS represents that when given a novel word and a corresponding instance, children create novel word meaning by using the known word meaning and the instance as an ad-hoc template. The AMS function enables fast mapping and vocabulary spurt. To describe the AMS process computationally, we introduced \"word distributional prototype (WDP),'' which is the explicit representation of word meaning with an inductive learning function. Simulation 1 revealed that when a network with WDP and AMS was given a biased vocabulary reflecting young children, it demonstrated shape, material, and overgeneralized shape biases. This result suggested that a triad of word meaning induction, ad-hoc meaning substitution, and early biased vocabulary is essential for the emergence of biases. Simulation 2 introduced the notion of maturity that denoted a degree of learning convergence for each word meaning, and then the network showed neither shape nor material bias during an early small vocabulary. This result indicated that the period at which each bias emerges is decided by maturity. Though AMS consists of simpler and valider mechanisms than those proposed in previous studies, it could reproduce behavior of shape and material biases and explain their emergence process clearly. These results suggest that phenomena concerning shape and material biases are explicable with a simple ad-hoc learning instead of meta-learning among LBA or innate language-specific ones. (c) 2007 Elsevier B. V. All rights reserved.", "paper_title": "Children construct novel word meaning ad-hoc based on known words: Computational model of shape and material biases", "paper_id": "WOS:000246295500004"}