{"auto_keywords": [{"score": 0.046633245390760206, "phrase": "new_classification_method"}, {"score": 0.00481495049065317, "phrase": "variable_weighting"}, {"score": 0.004638788604042707, "phrase": "decision_cluster_classification_model."}, {"score": 0.004413847218107373, "phrase": "adcc"}, {"score": 0.004332322079100859, "phrase": "high-dimensional_data"}, {"score": 0.003802135020791801, "phrase": "dominant_class"}, {"score": 0.003662892058072211, "phrase": "new_objects"}, {"score": 0.003506851152129303, "phrase": "cluster_tree"}, {"score": 0.003378385493203297, "phrase": "training_data"}, {"score": 0.0030582832134483685, "phrase": "dcc_model"}, {"score": 0.0028917056916949744, "phrase": "anderson-darling_test"}, {"score": 0.0027857115172243226, "phrase": "stopping_condition"}, {"score": 0.0022967713922705, "phrase": "existing_methods"}, {"score": 0.0021715812867126884, "phrase": "svm._adcc"}], "paper_keywords": ["Clustering", " classification", " W-k-means", " k-NN"], "paper_abstract": "In this paper, a new classification method (ADCC) for high-dimensional data is proposed. In this method, a decision cluster classification (DCC) model consists of a set of disjoint decision clusters, each labeled with a dominant class that determines the class of new objects falling in the cluster. A cluster tree is first generated from a training data set by recursively calling a variable weighting k-means algorithm. Then, the DCC model is extracted from the tree. Various tests including Anderson-Darling test are used to determine the stopping condition of the tree growing. A series of experiments on both synthetic and real data sets have been conducted. Their results show that the new classification method (ADCC) performed better in accuracy and scalability than existing methods like k-NN, decision tree and SVM. ADCC is particularly suitable for large, high-dimensional data with many classes.", "paper_title": "USING A VARIABLE WEIGHTING k-MEANS METHOD TO BUILD A DECISION CLUSTER CLASSIFICATION MODEL", "paper_id": "WOS:000308104300001"}