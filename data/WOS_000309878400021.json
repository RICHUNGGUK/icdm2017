{"auto_keywords": [{"score": 0.02984434606366457, "phrase": "changed_states"}, {"score": 0.015165850718457646, "phrase": "multi-agent_systems"}, {"score": 0.012510484682478612, "phrase": "multi-agent_environment"}, {"score": 0.012068306016884786, "phrase": "current_learning_models"}, {"score": 0.00899819802685964, "phrase": "learned_multi-agent_model"}, {"score": 0.008882910060435728, "phrase": "hopfield_learning_algorithm"}, {"score": 0.008589967553730343, "phrase": "boltzmann_learning_algorithm"}, {"score": 0.00481495049065317, "phrase": "convergence_speed"}, {"score": 0.0047776860292876025, "phrase": "stochastic_multi-agent_system"}, {"score": 0.004089856113955833, "phrase": "continuously_changing_environment"}, {"score": 0.003923719062831927, "phrase": "agent's_action"}, {"score": 0.0036395453437040215, "phrase": "deterministic_environment"}, {"score": 0.003491636564620199, "phrase": "complex_environments"}, {"score": 0.0033323878473928317, "phrase": "learning_models"}, {"score": 0.003289451206583327, "phrase": "stochastic_environments"}, {"score": 0.003147549342151965, "phrase": "hopfield_and_boltzmann_learning_algorithms"}, {"score": 0.0030195743686320183, "phrase": "unlearned_multi-agent_model"}, {"score": 0.002874325505148923, "phrase": "specific_value"}, {"score": 0.0028520371267470573, "phrase": "predicated_index"}, {"score": 0.002584197578549356, "phrase": "obtained_figures"}, {"score": 0.002384392412106145, "phrase": "average_number"}, {"score": 0.0021049977753042253, "phrase": "global_solution_increases"}], "paper_keywords": ["Multi-agent system", " Learning", " Hopfield learning algorithm", " Boltzmann Machine", " Convergence", " Stochastic"], "paper_abstract": "One problem in the design of multi-agent systems is the difficulty of predicting the occurrences that one agent might face, also to recognize and to predict their optimum behavior in these situations. Therefore, one of the most important characteristic of the agent is their ability during adoption, to learn, and correct their behavior. With consideration of the continuously changing environment, the back and forth learning of the agents, the inability to see the agent's action first hand, and their chosen strategies, learning in a multi-agent environment can be very complex. On the one hand, with recognition to the current learning models that are used in deterministic environment that behaves linearly, which contain weaknesses; therefore, the current learning models are unproductive in complex environments that the actions of agents are stochastic. Therefore, it is necessary for the creation of learning models that are effective in stochastic environments. Purpose of this research is the creation of such a learning model. For this reason, the Hopfield and Boltzmann learning algorithms are used. In order to demonstrate the performance of their algorithms, first, an unlearned multi-agent model is created. During the interactions of the agents, they try to increase their knowledge to reach a specific value. The predicated index is the number of changed states needed to reach the convergence. Then, the learned multi-agent model is created with the Hopfield learning algorithm, and in the end, the learned multi-agent model is created with the Boltzmann learning algorithm. After analyzing the obtained figures, a conclusion can be made that when learning impose to multi-agent environment the average number of changed states needed to reach the convergence decreased and the use of Boltzmann learning algorithm decreased the average number of changed states even further in comparison with Hopfield learning algorithm due to the increase in the number of choices in each situation. Therefore, it is possible to say that the multi-agent systems behave stochastically, the more closer they behave to their true character, the speed of reaching the global solution increases.", "paper_title": "A novel approach to accelerate the convergence speed of a stochastic multi-agent system using recurrent neural nets", "paper_id": "WOS:000309878400021"}