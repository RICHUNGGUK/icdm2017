{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "random_forests"}, {"score": 0.04357394901675967, "phrase": "combination_function"}, {"score": 0.02933362925417577, "phrase": "dynamic_integration"}, {"score": 0.004477595431209663, "phrase": "successful_ensemble_prediction_technique"}, {"score": 0.004357245559948974, "phrase": "majority_voting"}, {"score": 0.0037336520904376687, "phrase": "random_forest"}, {"score": 0.003600351201298387, "phrase": "different_contribution"}, {"score": 0.003170060683860338, "phrase": "prediction_performance"}, {"score": 0.003113301019413328, "phrase": "rf"}, {"score": 0.0026188490199688013, "phrase": "local_performance_estimates"}, {"score": 0.0022434880661725493, "phrase": "local_estimates"}, {"score": 0.0021049977753042253, "phrase": "classification_random_forests"}], "paper_keywords": [""], "paper_abstract": "Random Forests (RF) are a successful ensemble prediction technique that uses majority voting or averaging as a combination function. However, it is clear that each tree in a random forest may have a different contribution in processing a certain instance. In this paper, we demonstrate that the prediction performance of RF may still be improved in some domains by replacing the combination function with dynamic integration, which is based on local performance estimates. Our experiments also demonstrate that the RF Intrinsic Similarity is better than the commonly used Heterogeneous Euclidean/Overlap Metric in finding a neighbourhood for local estimates in the context of dynamic integration of classification random forests.", "paper_title": "Dynamic integration with random forests", "paper_id": "WOS:000242308000077"}