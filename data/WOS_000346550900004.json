{"auto_keywords": [{"score": 0.042253255654354865, "phrase": "hardware_states"}, {"score": 0.039510674444560676, "phrase": "wcet"}, {"score": 0.03571439348662484, "phrase": "irrelevant_program_parts"}, {"score": 0.034955520627756066, "phrase": "program_parts"}, {"score": 0.03277104434327558, "phrase": "analysis_overhead"}, {"score": 0.00481495049065317, "phrase": "worst-case_execution_time_bounds"}, {"score": 0.004724365740062236, "phrase": "real-time_systems"}, {"score": 0.004476816511183382, "phrase": "worst-case_execution_time"}, {"score": 0.004392565073466714, "phrase": "real-time_programs"}, {"score": 0.004122964978180509, "phrase": "increasing_program_size"}, {"score": 0.004058180509184539, "phrase": "potentially_relevant_program"}, {"score": 0.003944112858235306, "phrase": "wcet_analysis_increases"}, {"score": 0.003725470458263889, "phrase": "large_parts"}, {"score": 0.0035525230119401153, "phrase": "best_case"}, {"score": 0.003496670470065125, "phrase": "increased_analysis_time"}, {"score": 0.003199687131875466, "phrase": "novel_technique"}, {"score": 0.0030126187386121613, "phrase": "analysis'_precision"}, {"score": 0.0029840952148215733, "phrase": "basic_idea"}, {"score": 0.002909342017421165, "phrase": "analysis_problem"}, {"score": 0.002538400273615248, "phrase": "wcet."}, {"score": 0.002412758703672514, "phrase": "memory_accesses"}, {"score": 0.0023899010501421186, "phrase": "loop_bounds"}, {"score": 0.002337403139264533, "phrase": "processor_state"}, {"score": 0.0022933216359142736, "phrase": "commercial_wcet_analysis_tool_show"}, {"score": 0.0021797840569206697, "phrase": "standard_ipet_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Worst-case execution time analysis", " Iterative refinement", " Graph pruning"], "paper_abstract": "As real-time systems increase in complexity to provide more and more functionality and perform more demanding computations, the problem of statically analyzing the Worst-Case Execution Time (WCET) bound of real-time programs is becoming more and more time-consuming and imprecise. The problem stems from the fact that with increasing program size, the number of potentially relevant program and hardware states that need to be considered during WCET analysis increases as well. However, only a relatively small portion of the program actually contributes to the final WCET bound. Large parts of the program are thus irrelevant and are analyzed in vain. In the best case this only leads to increased analysis time. Very often, however, the analysis of irrelevant program parts interferes with the analysis of those program parts that turn out to be relevant. We explore a novel technique based on graph pruning that promises to reduce the analysis overhead and, at the same time, increase the analysis' precision. The basic idea is to eliminate those program parts from the analysis problem that are known to be irrelevant for the final WCET bound. This reduces the analysis overhead, since only a subset of the program and hardware states have to be tracked. Consequently, more aggressive analysis techniques may be applied, effectively reducing the overestimation of the WCET. As a side-effect, interference from irrelevant program parts is eliminated, e.g., on addresses of memory accesses, on loop bounds, or on the cache or processor state. First experiments using a commercial WCET analysis tool show that our approach is feasible in practice and leads to reductions of up to 12% when a standard IPET approach is used for the analysis. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Refinement of worst-case execution time bounds by graph pruning", "paper_id": "WOS:000346550900004"}