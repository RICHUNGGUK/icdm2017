{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "vertex_coloring"}, {"score": 0.04017252768992576, "phrase": "inequivalence_constraints"}, {"score": 0.0310010277965212, "phrase": "regular_inference"}, {"score": 0.013447237274190591, "phrase": "vertex_coloring_problem"}, {"score": 0.0046526806928044485, "phrase": "supervised_learning"}, {"score": 0.004620885890478087, "phrase": "deterministic_finite_state_automata"}, {"score": 0.004557943646825813, "phrase": "technical_sense"}, {"score": 0.0044498415012873965, "phrase": "complete_data"}, {"score": 0.003932929770322298, "phrase": "hypothesis_space"}, {"score": 0.00369736218441293, "phrase": "equivalence_constraints"}, {"score": 0.003572621286677047, "phrase": "previous_coloring-based_translations"}, {"score": 0.0034402448248944434, "phrase": "vertex_coloring_instance"}, {"score": 0.0033127570056253252, "phrase": "satisfiability_problems"}, {"score": 0.0032563753253986912, "phrase": "first_translation"}, {"score": 0.0031464653712924436, "phrase": "pure_vertex_coloring_instance"}, {"score": 0.0030402538087882015, "phrase": "coloring_approach"}, {"score": 0.0029680398526914565, "phrase": "combinatorial_optimization"}, {"score": 0.002947723206640026, "phrase": "graph_theory"}, {"score": 0.002877700749616268, "phrase": "new_complexity_bounds"}, {"score": 0.002799703831407504, "phrase": "new_learning_algorithms"}, {"score": 0.002733187900351625, "phrase": "exact_hypotheses"}, {"score": 0.0026958888229781618, "phrase": "fast_approximations"}, {"score": 0.002148860300945803, "phrase": "full_regular_inference_problem"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Grammar induction", " Automata induction", " Vertex coloring", " Satisfiability", " Identification in the limit"], "paper_abstract": "This paper is concerned with the problem of supervised learning of deterministic finite state automata, in the technical sense of identification in the limit from complete data, by finding a minimal DFA consistent with a sample. We solve this problem by translating it in its entirety to a vertex coloring problem. Essentially, such a problem consists of two types of constraints that restrict the hypothesis space: inequivalence and equivalence constraints. The inequivalence constraints translate to the vertex coloring problem in a very natural way. The equivalence constraints however greatly complicate the translation to vertex coloring. In previous coloring-based translations, these were therefore encoded either dynamically by modifying the vertex coloring instance on-the-fly, or by encoding them as satisfiability problems. We provide the first translation that encodes both types of constraints together in a pure vertex coloring instance and prove the correctness of the construction. The coloring approach offers many opportunities for applying insights from combinatorial optimization and graph theory to regular inference. We immediately obtain new complexity bounds, as well as a family of new learning algorithms which can be used to obtain exact hypotheses as well as fast approximations. We also demonstrate that satisfying all inequivalence constraints in regular inference and vertex coloring are in some sense equally hard. This immediately implies that regular inference is not approximable within vertical bar S vertical bar(1-is an element of) (vertical bar S vertical bar being the cardinality of the sample) for any is an element of> 1/2 unless P = NP. It also indicates that solving only for inequivalence constraints is easier than the full regular inference problem. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Regular inference as vertex coloring", "paper_id": "WOS:000345181900003"}