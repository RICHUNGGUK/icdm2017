{"auto_keywords": [{"score": 0.04643744880562088, "phrase": "instruction_cache"}, {"score": 0.015719716506582538, "phrase": "embedded_processors"}, {"score": 0.015556930206334117, "phrase": "energy_efficiency"}, {"score": 0.012303333224662658, "phrase": "dynamic_energy_consumption"}, {"score": 0.00471465954562773, "phrase": "cache_memories"}, {"score": 0.004520272777451894, "phrase": "energy_consumption"}, {"score": 0.0042212686864468805, "phrase": "significant_portion"}, {"score": 0.004177049813981273, "phrase": "total_processor_energy"}, {"score": 0.004047141845635495, "phrase": "new_instruction_cache_architecture"}, {"score": 0.0029657683623403085, "phrase": "dynamic_energy_reduction"}, {"score": 0.002654911400878851, "phrase": "performance_gap"}, {"score": 0.002613239644974825, "phrase": "conventional_instruction_cache"}, {"score": 0.0025586903829811296, "phrase": "pi-cache"}, {"score": 0.002492098272172066, "phrase": "physical_cache_access_time"}, {"score": 0.0023516185395256505, "phrase": "cycle_accurate_simulator"}, {"score": 0.002326938965568362, "phrase": "simplescalar"}, {"score": 0.0022904032758108775, "phrase": "power_parameters"}, {"score": 0.0022544399432457164, "phrase": "cacti._simulation_results"}, {"score": 0.002172701452347454, "phrase": "energy-delay_product"}, {"score": 0.0021049977753042253, "phrase": "conventional_direct-mapped_instruction_cache"}], "paper_keywords": ["instruction cache", " partitioned cache", " low power design", " dynamic energy", " embedded processor"], "paper_abstract": "Energy efficiency of cache memories is crucial in designing embedded processors. Reducing energy consumption in the instruction cache is especially important, since the instruction cache consumes a significant portion of total processor energy. This paper proposes a new instruction cache architecture, named Partitioned Instruction Cache (PI-Cache), for reducing dynamic energy consumption in the instruction cache by partitioning it to smaller (less power-consuming) sub-caches. When the proposed PI-Cache is accessed, only one sub-cache is accessed by utilizing the temporal/spatial locality of applications. In the meantime, other sub-caches are not accessed, leading to dynamic energy reduction. The PI-Cache also reduces dynamic energy consumption by eliminating the energy consumed in tag lookup and comparison. Moreover, the performance gap between the conventional instruction cache and the proposed PI-Cache becomes little when the physical cache access time is considered. We evaluated the energy efficiency by running a cycle accurate simulator, SimpleScalar, with power parameters obtained from CACTI. Simulation results show that the PI-Cache improves the energy-delay product by 20%-54% compared to the conventional direct-mapped instruction cache.", "paper_title": "An energy-efficient partitioned instruction cache architecture for embedded processors", "paper_id": "WOS:000237203100015"}