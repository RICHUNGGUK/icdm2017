{"auto_keywords": [{"score": 0.027325564729984462, "phrase": "extended_families"}, {"score": 0.00481495049065317, "phrase": "parametric_families"}, {"score": 0.00460125407969429, "phrase": "statistical_inference"}, {"score": 0.004397000006837371, "phrase": "simple_method"}, {"score": 0.004240116703465252, "phrase": "new_families"}, {"score": 0.003802135020791801, "phrase": "convex_and_concave_functions"}, {"score": 0.002666939282064268, "phrase": "matusita"}, {"score": 0.00245724480030654, "phrase": "smoothly_these_divergences"}, {"score": 0.002391067964886602, "phrase": "kullback_divergence"}, {"score": 0.0022434880661725493, "phrase": "particular_divergences"}, {"score": 0.0021049977753042253, "phrase": "metric_properties"}], "paper_keywords": ["divergences", " metric divergences", " families of f-divergences"], "paper_abstract": "We propose a simple method of construction of new families of phi-divergences. This method called convex standardization is applicable to convex and concave functions psi(t) twice continuously differentiable in a neighborhood of t = 1 with nonzero second derivative at the point t = 1. Using this method we introduce several extensions of the LeCam, power, chi(a) and Matusita divergences. The extended families are shown to connect smoothly these divergences with the Kullback divergence or they connect various pairs of these particular divergences themselves. We investigate also the metric properties of divergences from these extended families.", "paper_title": "Extensions of the parametric families of divergences used in statistical inference", "paper_id": "WOS:000255247900009"}