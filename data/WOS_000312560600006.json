{"auto_keywords": [{"score": 0.02891883656442249, "phrase": "proposed_model"}, {"score": 0.01325990137196661, "phrase": "center-surround_difference"}, {"score": 0.010064892106881846, "phrase": "super_features"}, {"score": 0.00481495049065317, "phrase": "earth_mover's_distance-based_saliency_measurement"}, {"score": 0.004506968388996092, "phrase": "new_computational_visual-attention_model"}, {"score": 0.004447766706144458, "phrase": "static_and_dynamic_saliency_maps"}, {"score": 0.00424659225577246, "phrase": "earth_mover's_distance"}, {"score": 0.0039748192550806815, "phrase": "receptive_field"}, {"score": 0.0033465923623290034, "phrase": "biologically_inspired_nonlinear_operations"}, {"score": 0.0032807941194429235, "phrase": "different_features"}, {"score": 0.0031739835218110015, "phrase": "basic_features"}, {"score": 0.0028549396580672417, "phrase": "winner-take-all_mechanism"}, {"score": 0.002671990515821213, "phrase": "dynamic_saliency_maps"}, {"score": 0.0025849670068072853, "phrase": "emd"}, {"score": 0.0024678216843278806, "phrase": "spatiotemporal_receptive_field"}, {"score": 0.002294369814584028, "phrase": "static_image_data"}, {"score": 0.0022641658133181115, "phrase": "video_data"}, {"score": 0.002234358539133758, "phrase": "comparison_results"}, {"score": 0.0021049977753042253, "phrase": "unified_evaluation"}], "paper_keywords": ["Visual attention", " saliency maps", " dynamic saliency maps", " earth mover's distance (EMD)", " spatiotemporal receptive field (STRF)"], "paper_abstract": "This paper introduces a new computational visual-attention model for static and dynamic saliency maps. First, we use the Earth Mover's Distance (EMD) to measure the center-surround difference in the receptive field, instead of using the Difference-of-Gaussian filter that is widely used in many previous visual-attention models. Second, we propose to take two steps of biologically inspired nonlinear operations for combining different features: combining subsets of basic features into a set of super features using the L-m-norm and then combining the super features using the Winner-Take-All mechanism. Third, we extend the proposed model to construct dynamic saliency maps from videos by using EMD for computing the center-surround difference in the spatiotemporal receptive field. We evaluate the performance of the proposed model on both static image data and video data. Comparison results show that the proposed model outperforms several existing models under a unified evaluation setting.", "paper_title": "A Visual-Attention Model Using Earth Mover's Distance-Based Saliency Measurement and Nonlinear Feature Combination", "paper_id": "WOS:000312560600006"}