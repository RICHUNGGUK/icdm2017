{"auto_keywords": [{"score": 0.0429841867448742, "phrase": "sign_language"}, {"score": 0.00481495049065317, "phrase": "chinese_sign_language_videos"}, {"score": 0.004318881178805575, "phrase": "chinese_sign_language"}, {"score": 0.0038737214010638745, "phrase": "vision_component"}, {"score": 0.0036553070575015344, "phrase": "volume_local_binary_patterns"}, {"score": 0.0033262524445013303, "phrase": "semantic_component"}, {"score": 0.00320770578058916, "phrase": "semantic_distance"}, {"score": 0.0029400959763737364, "phrase": "hand_shape"}, {"score": 0.0023990982005125763, "phrase": "location_andmovement"}, {"score": 0.0023644936731468252, "phrase": "experiment_results"}, {"score": 0.0023135183406982414, "phrase": "proposed_assessment_model"}, {"score": 0.0021049977753042253, "phrase": "subjective_scoring"}], "paper_keywords": ["Chinese sign language video", " human visual system (HVS)", " sign language semantic", " video similarity assessment"], "paper_abstract": "This paper proposes a model for measuring similarity between videos which content is Chinese Sign Language (CSL), vision and sign language semantic are considered for the model. Vision component of the model is distance based on Volume Local Binary Patterns (VLBP), which is robust for motion and illumination. Semantic component of the model computes semantic distance based on definition of sign language semantic, which is defined as hand shape, location, orientation and movements. While quantizing the sign language semantic, contour is used to measure shape and orientation; trajectory is used for measuring location andmovement. Experiment results show that proposed assessment model is effective and assessing result given by the model is close to subjective scoring.", "paper_title": "Similarity Assessment Model for Chinese Sign Language Videos", "paper_id": "WOS:000333111500015"}