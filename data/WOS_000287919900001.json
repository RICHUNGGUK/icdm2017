{"auto_keywords": [{"score": 0.03828152818695625, "phrase": "lagrangian"}, {"score": 0.00481495049065317, "phrase": "constrained_optimization"}, {"score": 0.004576253356889219, "phrase": "simulation-based_optimization"}, {"score": 0.004518442937844318, "phrase": "multiple_inequality_constraints"}, {"score": 0.004377077848734575, "phrase": "constraint_functions"}, {"score": 0.004240116703465252, "phrase": "long-run_averages"}, {"score": 0.003978866233891427, "phrase": "simulation_optimization_framework"}, {"score": 0.0038789122930433305, "phrase": "lagrange_multiplier_method"}, {"score": 0.003718774909305331, "phrase": "hessian"}, {"score": 0.002564613964408878, "phrase": "simultaneous_perturbation"}, {"score": 0.002316105585203396, "phrase": "numerical_experiments"}, {"score": 0.0022292394795878643, "phrase": "open_jackson_network"}, {"score": 0.0021870332034407817, "phrase": "newton-based_sf_algorithm"}, {"score": 0.0021049977753042253, "phrase": "best_overall_performance"}], "paper_keywords": ["Simulation-based constrained optimization", " inequality constraints", " Lagrange multiplier", " SF estimates", " SPSA estimates", " stochastic approximation"], "paper_abstract": "We develop four algorithms for simulation-based optimization under multiple inequality constraints. Both the cost and the constraint functions are considered to be long-run averages of certain state-dependent single-stage functions. We pose the problem in the simulation optimization framework by using the Lagrange multiplier method. Two of our algorithms estimate only the gradient of the Lagrangian, while the other two estimate both the gradient and the Hessian of it. In the process, we also develop various new estimators for the gradient and Hessian. All our algorithms use two simulations each. Two of these algorithms are based on the smoothed functional (SF) technique, while the other two are based on the simultaneous perturbation stochastic approximation (SPSA) method. We prove the convergence of our algorithms and show numerical experiments on a setting involving an open Jackson network. The Newton-based SF algorithm is seen to show the best overall performance.", "paper_title": "Stochastic Approximation Algorithms for Constrained Optimization via Simulation", "paper_id": "WOS:000287919900001"}