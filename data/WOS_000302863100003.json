{"auto_keywords": [{"score": 0.027027738905295983, "phrase": "auc"}, {"score": 0.00481495049065317, "phrase": "data_points"}, {"score": 0.004009555045206973, "phrase": "isolation_forest"}, {"score": 0.0036438571248352362, "phrase": "orca"}, {"score": 0.003588291565092195, "phrase": "density_measure"}, {"score": 0.0034707339811048403, "phrase": "existing_methods"}, {"score": 0.0031405975280029913, "phrase": "low_linear_time-complexity"}, {"score": 0.0030922140218643075, "phrase": "lof"}, {"score": 0.003088702479841264, "phrase": "small_memory-requirement"}, {"score": 0.002275369652100353, "phrase": "high_dimensional_problems"}, {"score": 0.0022377394845878268, "phrase": "large_number"}, {"score": 0.0022129983153880467, "phrase": "irrelevant_attributes"}, {"score": 0.0021049977753042253, "phrase": "training_sample"}], "paper_keywords": ["Anomaly detection", " outlier detection", " ensemble methods", " binary tree", " random tree ensemble", " isolation", " isolation forest"], "paper_abstract": "Anomalies are data points that are few and different. As a result of these properties, we show that, anomalies are susceptible to a mechanism called isolation. This article proposes a method called Isolation Forest (iForest), which detects anomalies purely based on the concept of isolation without employing any distance or density measure-fundamentally different from all existing methods. As a result, iForest is able to exploit subsampling (i) to achieve a low linear time-complexity and a small memory-requirement and (ii) to deal with the effects of swamping and masking effectively. Our empirical evaluation shows that iForest outperforms ORCA, one-class SVM, LOF and Random Forests in terms of AUC, processing time, and it is robust against masking and swamping effects. iForest also works well in high dimensional problems containing a large number of irrelevant attributes, and when anomalies are not available in training sample.", "paper_title": "Isolation-Based Anomaly Detection", "paper_id": "WOS:000302863100003"}