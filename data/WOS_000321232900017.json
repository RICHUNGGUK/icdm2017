{"auto_keywords": [{"score": 0.04941714403605284, "phrase": "mkl"}, {"score": 0.009076328207939776, "phrase": "smkl"}, {"score": 0.006674540192474885, "phrase": "complementary_information"}, {"score": 0.00481495049065317, "phrase": "ensemble_strategy"}, {"score": 0.004617949594931096, "phrase": "better_result"}, {"score": 0.004307287063280365, "phrase": "mkl."}, {"score": 0.003943481134959376, "phrase": "redundant_solution"}, {"score": 0.0034624082435775676, "phrase": "sparse_solution"}, {"score": 0.003414467360488913, "phrase": "pre-selection_procedure"}, {"score": 0.0031697368057340895, "phrase": "high_discrimination"}, {"score": 0.003140401552000472, "phrase": "large_diversity"}, {"score": 0.0031113369425402287, "phrase": "pre-selected_sub-kernels"}, {"score": 0.002942495422585405, "phrase": "new_kernel_evaluation"}, {"score": 0.0028218877037665484, "phrase": "mkl_optimization"}, {"score": 0.002523828967909659, "phrase": "fast_smkl_method"}, {"score": 0.002500456462028735, "phrase": "l_infinity-norm_constraint"}, {"score": 0.002420339995088838, "phrase": "mic_optimization_process"}, {"score": 0.0022571810910697013, "phrase": "large_scale_problem"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Ensemble learning", " Kernel evaluation", " Multiple kernel learning", " Selective multiple kernel learning", " Fast selective multiple kernel learning"], "paper_abstract": "Multiple Kernel Learning (MKL) aims to seek a better result than single kernel learning by combining a compact set of sub-kernels. However, MKL. with L1-norm easily discards the sub-kernels with complementary information and MKL with Lp-norm(p >= 2) often gets the redundant solution. To address these problems, a Selective Multiple Kernel Learning (SMKL) method, inspired by Ensemble Learning (EL), is proposed. Comparing MKL with Lp-norm(p >= 2), SMKL obtains a sparse solution by a pre-selection procedure. Comparing MKL with Lp-norm, SMKL preserves the sub-kernels with complementary information by guaranteeing the high discrimination and large diversity of pre-selected sub-kernels. For quantifying the discrimination and diversity of sub-kernels, a new kernel evaluation is designed. SMKL reduces the scale of MKL optimization and saves the memory storing of the sub-kernels, which extends the scale of problem that MKL could solve. Specially, a fast SMKL method using L infinity-norm constraint is focused, which needs no MIC optimization process. It means that the memory is hardly a limitation for MKL with the large scale problem. Experiments state that our method is effective for classification. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Selective multiple kernel learning for classification with ensemble strategy", "paper_id": "WOS:000321232900017"}