{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "information_systems"}, {"score": 0.048603687852811175, "phrase": "ranking-type_delphi_method"}, {"score": 0.004755054742217193, "phrase": "-type_delphi_studies"}, {"score": 0.004066076430818046, "phrase": "geographically_dispersed_participants"}, {"score": 0.0037480753312398754, "phrase": "particular_task"}, {"score": 0.0031646057802503526, "phrase": "delphi_studies"}, {"score": 0.0028805474861014722, "phrase": "leading_delphi_methodologists"}, {"score": 0.0026055251533586804, "phrase": "clear_and_precise_instructions"}, {"score": 0.002327310963701377, "phrase": "retention_rates"}, {"score": 0.002298288831092204, "phrase": "instrument_pretesting"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Ranking-type Delphi", " Descriptive review", " Information systems research", " Rigor"], "paper_abstract": "The ranking-type Delphi method is well suited as a means for consensus-building by using a series of questionnaires to collect data from a panel of geographically dispersed participants. This method allows a group of experts to systematically approach a particular task or problem. While information systems researchers have been using this method for almost three decades, no research to date has attempted to assess the extent to which Delphi studies have been rigorously conducted. Using the guidelines that have been prescribed by the leading Delphi methodologists, our descriptive review reveals many positive signs of rigor such as ensuring the anonymity of experts and providing clear and precise instructions to participants. Nevertheless, there are still several areas for improvement, such as reporting response and retention rates, instrument pretesting, and explicitly justifying modifications to the ranking-type Delphi method. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A systematic assessment of rigor in information systems ranking-type Delphi studies", "paper_id": "WOS:000321232400002"}