{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "small_input_feature_variations"}, {"score": 0.013331354524807503, "phrase": "back_propagation_learning_algorithm"}, {"score": 0.011778500872366631, "phrase": "cost_function"}, {"score": 0.010042068153047062, "phrase": "proposed_algorithm"}, {"score": 0.004646258518859209, "phrase": "new_error"}, {"score": 0.00430067200637091, "phrase": "output_mapping"}, {"score": 0.0041995784967999985, "phrase": "high-pass_filter_characteristic"}, {"score": 0.003818326867123525, "phrase": "sensitive_discrimination"}, {"score": 0.0037731618765688584, "phrase": "novel_class_data"}, {"score": 0.003728529119516347, "phrase": "slightly_different_characteristics"}, {"score": 0.0036625643243684827, "phrase": "normal_class_data"}, {"score": 0.0035341028694769036, "phrase": "proposed_neural_network_algorithm"}, {"score": 0.0033497809969621267, "phrase": "output_sensitivity"}, {"score": 0.003290494847464381, "phrase": "weight_update_rules"}, {"score": 0.003118838635447237, "phrase": "gradient_descent_method"}, {"score": 0.0029737652463012318, "phrase": "auto-associative_multilayer_perceptron_neural_network"}, {"score": 0.002639845784408318, "phrase": "laser_spot"}, {"score": 0.002608583927848071, "phrase": "complex_backgrounds"}, {"score": 0.0025623821393275146, "phrase": "automatic_inspection_system"}, {"score": 0.0025169965861573185, "phrase": "reliable_detection"}, {"score": 0.00248718591918233, "phrase": "mura_defects"}, {"score": 0.002385595105638277, "phrase": "flat_panel_liquid_crystal_displays"}, {"score": 0.0023018188296933923, "phrase": "conventional_error"}, {"score": 0.0022077827041801193, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "input-output_mapping_sensitivity"}], "paper_keywords": ["Auto-associative multilayer perceptron", " Input and output mapping sensitivity", " Laser spot", " Automatic inspection system", " Mura defect"], "paper_abstract": "This paper proposes a new error back propagation learning algorithm that properly enhances the sensitivity of input and output mapping by applying a high-pass filter characteristic to the conventional error back propagation learning algorithm, allowing small input feature variations to be successfully indicated. For the sensitive discrimination of novel class data with slightly different characteristics from the normal class data, the cost function in the proposed neural network algorithm is modified by further increasing the input and output sensitivity, where weight update rules are used to minimize the cost function using a gradient descent method. The proposed algorithm is applied to an auto-associative multilayer perceptron neural network and its performance evaluated with two real-world applications: a laser spot detection-based computer interface system for detecting a laser spot in complex backgrounds and an automatic inspection system for the reliable detection of Mura defects that occur during the manufacture of flat panel liquid crystal displays. When compared with the conventional error back propagation learning algorithm, the proposed algorithm shows a better performance as regards detecting small input feature variations by increasing the input-output mapping sensitivity.", "paper_title": "Novel input and output mapping-sensitive error back propagation learning algorithm for detecting small input feature variations", "paper_id": "WOS:000304160200010"}