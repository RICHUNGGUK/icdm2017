{"auto_keywords": [{"score": 0.04545357036670984, "phrase": "rare_event"}, {"score": 0.00481495049065317, "phrase": "ergodic_control"}, {"score": 0.004763895422211728, "phrase": "markov_chains"}, {"score": 0.004688321299229397, "phrase": "rare_events"}, {"score": 0.00451659023910662, "phrase": "long-run_average_cost_control"}, {"score": 0.004469307916600144, "phrase": "markov"}, {"score": 0.004259293347851015, "phrase": "related_recent_work"}, {"score": 0.004191690483929023, "phrase": "simulation_based_algorithm"}, {"score": 0.0041251561573501455, "phrase": "performance_measures"}, {"score": 0.004038076978795421, "phrase": "markov_chain"}, {"score": 0.003668333531296882, "phrase": "adaptive_algorithm"}, {"score": 0.003404244237372396, "phrase": "step-size_schedules"}, {"score": 0.003332332086930163, "phrase": "slowest_timescale"}, {"score": 0.0032793933580835574, "phrase": "gradient_search_algorithm"}, {"score": 0.003244567402785763, "phrase": "policy_updates"}, {"score": 0.003010893527930816, "phrase": "appropriate_normalized_hadamard_matrices"}, {"score": 0.0029159568444629053, "phrase": "fast_timescale_recursions"}, {"score": 0.002869613770219469, "phrase": "conditional_transition_probabilities"}, {"score": 0.002824005136794786, "phrase": "associated_chain"}, {"score": 0.0027349450784503273, "phrase": "multiplicative_poisson_equation"}, {"score": 0.002592693161475495, "phrase": "risk_parameter"}, {"score": 0.002537880772794665, "phrase": "value_function"}, {"score": 0.0022685255265595624, "phrase": "convergence_analysis"}, {"score": 0.002196944917134202, "phrase": "numerical_application"}, {"score": 0.0021276181317652163, "phrase": "multiple_flows"}, {"score": 0.0021049977753042253, "phrase": "communication_networks"}], "paper_keywords": ["Markov decision processes", " optimal control conditioned on a rare event", " simulation based algorithms", " SPSA with deterministic perturbations", " reinforcement learning"], "paper_abstract": "We study the problem of long-run average cost control of Markov chains conditioned on a rare event. In a related recent work, a simulation based algorithm for estimating performance measures associated with a Markov chain conditioned on a rare event has been developed. We extend ideas from this work and develop an adaptive algorithm for obtaining, online, optimal control policies conditioned on a rare event. Our algorithm uses three timescales or step-size schedules. On the slowest timescale, a gradient search algorithm for policy updates that is based on one-simulation simultaneous perturbation stochastic approximation (SPSA) type estimates is used. Deterministic perturbation sequences obtained from appropriate normalized Hadamard matrices are used here. The fast timescale recursions compute the conditional transition probabilities of an associated chain by obtaining solutions to the multiplicative Poisson equation ( for a given policy estimate). Further, the risk parameter associated with the value function for a given policy estimate is updated on a timescale that lies in between the two scales above. We briefly sketch the convergence analysis of our algorithm and present a numerical application in the setting of routing multiple flows in communication networks.", "paper_title": "A simulation-based algorithm for ergodic control of Markov chains conditioned on rare events", "paper_id": "WOS:000245390500001"}