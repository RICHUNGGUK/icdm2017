{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "anomaly-detection_algorithms"}, {"score": 0.02653803703052746, "phrase": "detector_performance"}, {"score": 0.004577869668211548, "phrase": "mouse_operating_behaviors"}, {"score": 0.0038447943243941685, "phrase": "promising_research_directions"}, {"score": 0.0037231102027070724, "phrase": "performance-evaluation_study"}, {"score": 0.0035395987202335223, "phrase": "equal_basis"}, {"score": 0.0032585499655442404, "phrase": "repeatable_evaluation_methodology"}, {"score": 0.003097865379563127, "phrase": "pattern-recognition_literatures"}, {"score": 0.002985988377995789, "phrase": "detection_accuracy"}, {"score": 0.002825681384008326, "phrase": "sample_length"}, {"score": 0.002613163083407071, "phrase": "six_top-performing_detectors"}, {"score": 0.0025892330566358503, "phrase": "equal-error_rates"}, {"score": 0.0025420267431501367, "phrase": "detection_time"}, {"score": 0.002461472107682778, "phrase": "training_sample_size"}, {"score": 0.0024389277933858054, "phrase": "sample_length_increase"}, {"score": 0.0023400004981080818, "phrase": "user_space"}, {"score": 0.002255431275670053, "phrase": "error_range"}, {"score": 0.0022041312401435346, "phrase": "space_size"}, {"score": 0.002124461969404541, "phrase": "shared_data"}, {"score": 0.0021049977753042253, "phrase": "evaluation_methodology"}], "paper_keywords": ["Anomaly detection", " Behavioral biometrics", " Mouse dynamics", " Performance evaluation", " Benchmark study", " Algorithm comparison"], "paper_abstract": "Mouse dynamics-the analysis of mouse operating behaviors to identify users has been proposed for detecting impostors. Since many anomaly-detection algorithms have been proposed for this task, it is natural to ask how well these algorithms perform and how they compare with each other (e.g., to identify promising research directions). This paper presents a performance-evaluation study of a range of anomaly-detection algorithms in mouse dynamics on an equal basis. We collected a mouse-dynamics data set consisting of 17,400 samples from 58 subjects, developed a repeatable evaluation methodology, and implemented and evaluated 17 detectors from the mouse-dynamics and pattern-recognition literatures. Performance is measured in terms of detection accuracy, sensitivity to training sample size, usability with respect to sample length, and scalability with respect to the number of users (user space). The six top-performing detectors achieve equal-error rates between 8.81% and 11.63% with a detection time of 6.1 s; detector performance improves as training sample size and sample length increase and becomes saturated gradually; detector performance decreases as user space becomes large, but only small fluctuations with the error range are apparent when the space size exceeds a certain number. Along with the shared data and evaluation methodology, the results constitute a benchmark for comparing detectors and measuring progress. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Performance evaluation of anomaly-detection algorithms for mouse dynamics", "paper_id": "WOS:000341340600011"}