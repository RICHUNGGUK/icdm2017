{"auto_keywords": [{"score": 0.03618870164102205, "phrase": "higher_level"}, {"score": 0.00481495049065317, "phrase": "reactive_plan_execution"}, {"score": 0.004765173195920904, "phrase": "reactive_learning"}, {"score": 0.004715908063787721, "phrase": "developing_software_agents"}, {"score": 0.004098397888277889, "phrase": "complex_representations"}, {"score": 0.003931402465972151, "phrase": "\"the_world"}, {"score": 0.0034881076466982226, "phrase": "knowledge_representation"}, {"score": 0.0027454383581457555, "phrase": "utilising_knowledge"}, {"score": 0.002579140290642792, "phrase": "reactive_learner"}, {"score": 0.002512850690695835, "phrase": "reactive_plan_execution_engine"}, {"score": 0.0022291501521610737, "phrase": "bdi_framework"}, {"score": 0.0021945833590668973, "phrase": "low-level_reinforcement_learner"}], "paper_keywords": [""], "paper_abstract": "Developing software agents has been complicated by the problem of how knowledge should be represented and used. Many researchers have identified that agents need not require the use of complex representations, but in many cases suffice to use \"the world\" as their representation. However, the problem of introspection, both by the agents themselves and by (human) domain experts, requires a knowledge representation with a higher level of abstraction that is more 'understandable'. Learning and adaptation in agents has traditionally required knowledge to be represented at an arbitrary, low-level of abstraction. We seek to create an agent that has the capability of learning as well as utilising knowledge represented at a higher level of abstraction. We firstly explore a reactive learner (FALCON) and reactive plan execution engine based on BDI (JACK) through experiments and analysis. We then describe an architecture we have developed that combines the BDI framework to the low-level reinforcement learner and present promising results from experiments using our minefield navigation domain.", "paper_title": "A hybrid architecture combining reactive plan execution and reactive learning", "paper_id": "WOS:000240091500023"}