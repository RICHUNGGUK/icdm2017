{"auto_keywords": [{"score": 0.028214801741057678, "phrase": "bdmpi"}, {"score": 0.00481495049065317, "phrase": "big_data"}, {"score": 0.0046741260449047976, "phrase": "old_dog"}, {"score": 0.0045599093158915326, "phrase": "massive_amounts"}, {"score": 0.00442651096522781, "phrase": "finite_amount"}, {"score": 0.004296998284839309, "phrase": "important_problem"}, {"score": 0.004171259063201874, "phrase": "mapreduce-style_technologies"}, {"score": 0.00393066798511457, "phrase": "mapreduce_paradigm"}, {"score": 0.0035249212996297332, "phrase": "runtime_system"}, {"score": 0.0034901729647741353, "phrase": "traditional_mpi_programs"}, {"score": 0.003421697038352743, "phrase": "efficient_and_transparent_out-of-core_execution"}, {"score": 0.0031297538950335233, "phrase": "mpi's_api"}, {"score": 0.003023047748772801, "phrase": "large_number"}, {"score": 0.002993231973906559, "phrase": "mpi_processes"}, {"score": 0.0028911669203979156, "phrase": "running_processes"}, {"score": 0.0025924443774713473, "phrase": "efficient_out-of-core_parallel_distributed_memory_codes"}, {"score": 0.002467038647952607, "phrase": "multiple_levels"}, {"score": 0.002394719113232821, "phrase": "significantly_better_performance"}, {"score": 0.0023710856920150574, "phrase": "existing_technologies"}, {"score": 0.002336071138145897, "phrase": "single_node"}, {"score": 0.0022675820982741347, "phrase": "small_cluster"}, {"score": 0.0021902063413831545, "phrase": "optimized_out-of-core_implementations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Out-of-core", " Distributed", " High performance", " Big Data"], "paper_abstract": "The processing of massive amounts of data on clusters with finite amount of memory has become an important problem facing the parallel/distributed computing community. While MapReduce-style technologies provide an effective means for addressing various problems that fit within the MapReduce paradigm, there are many classes of problems for which this paradigm is ill-suited. In this paper we present a runtime system for traditional MPI programs that enables the efficient and transparent out-of-core execution of distributed-memory parallel programs. This system, called BDMPI,(1) leverages the semantics of MPI's API to orchestrate the execution of a large number of MPI processes on much fewer compute nodes, so that the running processes maximize the amount of computation that they perform with the data fetched from the disk. BDMPI enables the development of efficient out-of-core parallel distributed memory codes without the high engineering and algorithmic complexities associated with multiple levels of blocking. BDMPI achieves significantly better performance than existing technologies on a single node as well as on a small cluster, and performs within 30% of optimized out-of-core implementations. (C) 2014 Published by Elsevier B.V.", "paper_title": "MPI for Big Data: New tricks for an old dog", "paper_id": "WOS:000347018800014"}