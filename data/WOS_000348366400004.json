{"auto_keywords": [{"score": 0.04953663923501101, "phrase": "sparse_approximation"}, {"score": 0.00481495049065317, "phrase": "empirical_intersection_removal"}, {"score": 0.004706453355638515, "phrase": "subspace_models"}, {"score": 0.004445739135694758, "phrase": "individual_subspace_model"}, {"score": 0.0043208252177835815, "phrase": "linear_regression"}, {"score": 0.004175533280178052, "phrase": "minimum_distance_criteria"}, {"score": 0.004081385289516914, "phrase": "final_decision"}, {"score": 0.003989351600022163, "phrase": "generalized_subspace_model"}, {"score": 0.0039216854691927865, "phrase": "full_linear_subspace"}, {"score": 0.003725470458263889, "phrase": "lower_dimensions"}, {"score": 0.003641433168173135, "phrase": "unknown_basis"}, {"score": 0.003459191419478298, "phrase": "testing_pattern"}, {"score": 0.003419943984098415, "phrase": "adaptively_selected_training_samples"}, {"score": 0.0033619033669956317, "phrase": "training_data_selection"}, {"score": 0.003051073364818384, "phrase": "classification_performance"}, {"score": 0.0029148831519944358, "phrase": "regression_error"}, {"score": 0.0028006988338192375, "phrase": "class_separability"}, {"score": 0.0027218799769229596, "phrase": "novel_approach"}, {"score": 0.002690975370565776, "phrase": "empirical_subspace_intersection"}, {"score": 0.002660437354822856, "phrase": "esi"}, {"score": 0.00224151735457093, "phrase": "wooden_logs"}, {"score": 0.002216054733102974, "phrase": "microwave_signals"}, {"score": 0.0021784009230363627, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "classical_methods"}], "paper_keywords": ["Classification", " linear subspace", " sparse representation", " training data selection"], "paper_abstract": "Subspace models are widely used in many applications. By assuming an individual subspace model for each class, linear regression is applied and combined with minimum distance criteria for making the final decision. In a generalized subspace model, the full linear subspace of each class is split into subspaces with lower dimensions, and the unknown basis needs to be estimated with respect to the testing pattern using adaptively selected training samples. The training data selection is implemented using either least-squares regression or sparse approximation. In this paper, to further improve the classification performance, instead of attempting to minimize the regression error for each class, the between class separability is enhanced by a novel approach called Empirical Subspace Intersection (ESI) Removal technique. Evaluations are performed on (1) standard UCI data set, and (2) a computer aided system along with the proposed classification technique to determine the quality in wooden logs using microwave signals. The experimental results are shown and compared with classical methods.", "paper_title": "A robust subspace classification scheme based on empirical intersection removal and sparse approximation", "paper_id": "WOS:000348366400004"}