{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "visible-light_and_thermal_imageries"}, {"score": 0.03647553486591155, "phrase": "human_figures"}, {"score": 0.004689650818647484, "phrase": "thermal_cameras"}, {"score": 0.004628223381645729, "phrase": "increased_availability"}, {"score": 0.0045877173513910055, "phrase": "camera_sensors"}, {"score": 0.004527619017250708, "phrase": "visible_spectrum"}, {"score": 0.004257360656055417, "phrase": "hyperspectral_cameras"}, {"score": 0.004201571673071299, "phrase": "regular_rgb_camera"}, {"score": 0.00416478405812793, "phrase": "information_fusion"}, {"score": 0.004128317208406523, "phrase": "multiple_heterogeneous_cameras"}, {"score": 0.0039333604469462356, "phrase": "different_levels"}, {"score": 0.0038309141193444015, "phrase": "even_semantic_objects"}, {"score": 0.003780692127133743, "phrase": "large_variations"}, {"score": 0.0036660436272785476, "phrase": "computation_costs"}, {"score": 0.003492840830999027, "phrase": "robust_segmentation"}, {"score": 0.0034319005131102495, "phrase": "video_sequences"}, {"score": 0.003284145698220425, "phrase": "geometric_transformation"}, {"score": 0.003255364511414329, "phrase": "visual_blobs"}, {"score": 0.003007389443770562, "phrase": "high_computation_and_communication_costs"}, {"score": 0.002941913249957503, "phrase": "computational_complexity"}, {"score": 0.002903311792572216, "phrase": "geometric_fusion"}, {"score": 0.0028652153774536967, "phrase": "efficient_calibration_procedure"}, {"score": 0.0027417911324611917, "phrase": "complex_procedure"}, {"score": 0.002693919110230191, "phrase": "intrinsic_parameters"}, {"score": 0.002600661525224505, "phrase": "different_blobs"}, {"score": 0.0025665261770229757, "phrase": "pixel_level"}, {"score": 0.0024451427672857458, "phrase": "rectified_domain"}, {"score": 0.002298902547676131, "phrase": "precise_segmentation"}, {"score": 0.0022389308000757037, "phrase": "two-tier_tracking_algorithm"}, {"score": 0.0022095328812245852, "phrase": "unified_background_model"}, {"score": 0.002142426911242168, "phrase": "significant_improvements"}, {"score": 0.0021236300589450143, "phrase": "existing_schemes"}], "paper_keywords": ["Sensor fusion", " Human segmentation", " Multi-camera fusion", " Thermal cameras"], "paper_abstract": "From depth sensors to thermal cameras, the increased availability of camera sensors beyond the visible spectrum has created many exciting applications. Most of these applications require combining information from these hyperspectral cameras with a regular RGB camera. Information fusion from multiple heterogeneous cameras can be a very complex problem. They can be fused at different levels from pixel to voxel or even semantic objects, with large variations in accuracy, communication, and computation costs. In this paper, we propose a system for robust segmentation of human figures in video sequences by fusing visible-light and thermal imageries. Our system focuses on the geometric transformation between visual blobs corresponding to human figures observed at both cameras. This approach provides the most reliable fusion at the expense of high computation and communication costs. To reduce the computational complexity of the geometric fusion, an efficient calibration procedure is first applied to rectify the two camera views without the complex procedure of estimating the intrinsic parameters of the cameras. To geometrically register different blobs at the pixel level, a blob-to-blob homography in the rectified domain is then computed in real-time by estimating the disparity for each blob-pair. Precise segmentation is finally achieved using a two-tier tracking algorithm and a unified background model. Our experimental results show that our proposed system provides significant improvements over existing schemes under various conditions.", "paper_title": "Human segmentation by geometrically fusing visible-light and thermal imageries", "paper_id": "WOS:000342418700004"}