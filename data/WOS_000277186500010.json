{"auto_keywords": [{"score": 0.028142596432288305, "phrase": "optimal_rate"}, {"score": 0.00481495049065317, "phrase": "bagged_nearest_neighbor_estimate"}, {"score": 0.004645057834614705, "phrase": "simple_way"}, {"score": 0.004170375667661055, "phrase": "breiman"}, {"score": 0.00333697550984782, "phrase": "crude_nearest_neighbor_regression_estimate"}, {"score": 0.0032190636347671675, "phrase": "consistent_weighted_nearest_neighbor_regression_estimate"}, {"score": 0.0030830390264125923, "phrase": "statistical_analysis"}, {"score": 0.002166530105679438, "phrase": "unknown_distribution"}], "paper_keywords": ["bagging", " resampling", " nearest neighbor estimate", " rates of convergence"], "paper_abstract": "Bagging is a simple way to combine estimates in order to improve their performance. This method, suggested by Breiman in 1996, proceeds by resampling from the original data set, constructing a predictor from each subsample, and decide by combining. By bagging an n-sample, the crude nearest neighbor regression estimate is turned into a consistent weighted nearest neighbor regression estimate, which is amenable to statistical analysis. Letting the resampling size k(n) grows appropriately with n, it is shown that this estimate may achieve optimal rate of convergence, independently from the fact that resampling is done with or without replacement. Since the estimate with the optimal rate of convergence depends on the unknown distribution of the observations, adaptation results by data-splitting are presented.", "paper_title": "On the Rate of Convergence of the Bagged Nearest Neighbor Estimate", "paper_id": "WOS:000277186500010"}