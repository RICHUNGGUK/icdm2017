{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "trust_values"}, {"score": 0.004761494044422926, "phrase": "binary_decisions"}, {"score": 0.00470862827326028, "phrase": "open_multi-agent_systems"}, {"score": 0.004322267755421529, "phrase": "different_agents'_capabilities"}, {"score": 0.0037101871762082153, "phrase": "focal_agent's_point"}, {"score": 0.003614678418617691, "phrase": "focal_agent"}, {"score": 0.0032444113660668743, "phrase": "trust_and_reputation_values"}, {"score": 0.0028903278985330117, "phrase": "binary_variable"}, {"score": 0.002847540262784593, "phrase": "computer_simulation_experiments"}, {"score": 0.0028053842615436706, "phrase": "relative_efficacy"}, {"score": 0.0027535633837592597, "phrase": "decision-making_methods"}, {"score": 0.0026626797255348287, "phrase": "systematic_analysis"}, {"score": 0.0025178072071268534, "phrase": "different_methods"}, {"score": 0.002499094513009327, "phrase": "different_classes"}, {"score": 0.002480520548392772, "phrase": "parameter_settings"}, {"score": 0.0021687806803474367, "phrase": "particular_setting"}], "paper_keywords": [""], "paper_abstract": "In open multi-agent systems, agents typically need to rely on others for the provision of information or the delivery of resources. However, since different agents' capabilities, goals and intentions do not necessarily agree with each other, trust can not be taken for granted in the sense that an agent can not always be expected to be willing and able to perform optimally from a focal agent's point of view. Instead, the focal agent has to form and update beliefs about other agents' capabilities and intentions. Many different approaches, models and techniques have been used for this purpose in the past, which generate trust and reputation values. In this paper, employing one particularly popular trust model, we focus on the way an agent may use such trust values in trust-based decision-making about the value of a binary variable. We use computer simulation experiments to assess the relative efficacy of a variety of decision-making methods. In doing so, we argue for systematic analysis of such methods beforehand, so that, based on an investigation of characteristics of different methods, different classes of parameter settings can be distinguished. Whether, on average across many random problem instances, a certain method performs better or worse than alternatives is not the issue, given that the agent using the method always exists in a particular setting. We find that combining trust values using our likelihood method gives performance which is relatively robust to changes in the setting an agent may find herself in.", "paper_title": "A versatile approach to combining trust values for making binary decisions", "paper_id": "WOS:000238108800016"}