{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "convergence_analysis_of_graph_regularized_non-negative_matrix_factorization"}, {"score": 0.0047152877145889656, "phrase": "non-negative_matrix_factorization"}, {"score": 0.004498490110526062, "phrase": "information_retrieval"}, {"score": 0.004451676867747938, "phrase": "image_processing"}, {"score": 0.004382364826200616, "phrase": "pattern_recognition"}, {"score": 0.003946960862020283, "phrase": "geometrical_structure"}, {"score": 0.0038854765143440965, "phrase": "data_space"}, {"score": 0.0037261429556468217, "phrase": "convergence_properties"}, {"score": 0.003373334961160647, "phrase": "euclidian_distance"}, {"score": 0.003355717283753749, "phrase": "based_algorithms"}, {"score": 0.003251920460276645, "phrase": "fixed_points"}, {"score": 0.003118486096035156, "phrase": "learning_algorithms"}, {"score": 0.0030378759123133644, "phrase": "invariant_sets"}, {"score": 0.0030062165552187086, "phrase": "update_rules"}, {"score": 0.0029438813080245544, "phrase": "lyapunov_indirect_method"}, {"score": 0.0026649432435828842, "phrase": "nmf_algorithms"}, {"score": 0.002387214876538434, "phrase": "different_initializations"}, {"score": 0.002362320344521919, "phrase": "data_sets"}, {"score": 0.0023133055945761235, "phrase": "cost_functions"}, {"score": 0.002289180040240783, "phrase": "decomposition_data"}, {"score": 0.002183684303511462, "phrase": "convergence_features"}, {"score": 0.0021496083700137305, "phrase": "discussed_nmf_update_rules"}, {"score": 0.0021049977753042253, "phrase": "convergence_speed"}], "paper_keywords": ["Structure retrieving", " convergence analysis", " manifold structure", " NMF", " Euclidian distance"], "paper_abstract": "Graph regularized non-negative matrix factorization (NMF) algorithms can be applied to information retrieval, image processing, and pattern recognition. However, challenge that still remains is to prove the convergence of this class of learning algorithms since the geometrical structure of the data space is considered. This paper presents the convergence properties of the graph regularized NMF learning algorithms. In the analysis, we focus on the study of Euclidian distance based algorithms. The structures of the fixed points are presented. The non-divergence of the learning algorithms is analyzed by constructing invariant sets for update rules. Based on Lyapunov indirect method, the stability of the algorithms is discussed in detail. The analysis shows that this class of NMF algorithms can converge to their fixed points under some given conditions. In the simulations, theoretical results presented in the paper are confirmed. For different initializations and data sets, variations of cost functions and decomposition data in the learning are presented to show the convergence features of the discussed NMF update rules, and the convergence speed of the algorithms is also investigated.", "paper_title": "Convergence Analysis of Graph Regularized Non-Negative Matrix Factorization", "paper_id": "WOS:000341571100006"}