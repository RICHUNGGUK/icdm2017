{"auto_keywords": [{"score": 0.049764804068700534, "phrase": "small_semantic_gaps"}, {"score": 0.009651191896927218, "phrase": "high-level_concepts"}, {"score": 0.006697642688029344, "phrase": "concept-based_multimedia_retrieval"}, {"score": 0.006545369540099164, "phrase": "good_lexicon"}, {"score": 0.006251065608894889, "phrase": "data_collection"}, {"score": 0.005498768924580342, "phrase": "semantic_gap_analysis"}, {"score": 0.0052685798726459865, "phrase": "semantic_gaps"}, {"score": 0.00481495049065317, "phrase": "concept_lexica"}, {"score": 0.004537938301016805, "phrase": "fast_development"}, {"score": 0.00433350214927936, "phrase": "first_and_important_step"}, {"score": 0.004179328666330398, "phrase": "model_construction"}, {"score": 0.004124630249202334, "phrase": "open_question"}, {"score": 0.003964775996909873, "phrase": "low-level_visual_features"}, {"score": 0.003790573435223069, "phrase": "lcss"}, {"score": 0.0036392821787269727, "phrase": "multimedia_concepts"}, {"score": 0.0032858160838749196, "phrase": "novel_framework"}, {"score": 0.0032002934215958068, "phrase": "large-scale_web_image_dataset"}, {"score": 0.0030660263386795526, "phrase": "confidence_score"}, {"score": 0.003035847903759329, "phrase": "content-context_similarity_matrix"}, {"score": 0.0029862071871499295, "phrase": "textual_space"}, {"score": 0.002927705457700311, "phrase": "surrounding_descriptions"}, {"score": 0.002643168068896905, "phrase": "content-contextual_consistency"}, {"score": 0.0025999315182615823, "phrase": "lexicon_family"}, {"score": 0.0025155632965105533, "phrase": "different_low-level_features"}, {"score": 0.0022412113034595903, "phrase": "large-scale_image_retrieval"}, {"score": 0.0021972723598946446, "phrase": "promising_application_potential"}, {"score": 0.002182817892930808, "phrase": "image_annotation_refinement"}, {"score": 0.0021470954708827125, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "developed_concept"}], "paper_keywords": ["Image retrieval", " large-scale", " lexica", " semantic gap"], "paper_abstract": "In recent years, constructing mathematical models for visual concepts by using content features, i.e., color, texture, shape, or local features, has led to the fast development of concept-based multimedia retrieval. In concept-based multimedia retrieval, defining a good lexicon of high-level concepts is the first and important step. However, which concepts should be used for data collection and model construction is still an open question. People agree that concepts that can be easily described by low-level visual features can construct a good lexicon. These concepts are called concepts with small semantic gaps. Unfortunately, there is very little research found on semantic gap analysis and on automatically choosing multimedia concepts with small semantic gaps, even though differences of semantic gaps among concepts are well worth investigating. In this paper, we propose a method to quantitatively analyze semantic gaps and develop a novel framework to identify high-level concepts with small semantic gaps from a large-scale web image dataset. Images with small semantic gaps are selected and clustered first by defining a confidence score and a content-context similarity matrix in visual space and textual space. Then, from the surrounding descriptions (titles, categories, and comments) of these images, concepts with small semantic gaps are automatically mined. In addition, considering that semantic gap analysis depends on both features and content-contextual consistency, we construct a lexicon family of high-level concepts with small semantic gaps (LCSS) based on different low-level features and different consistency measurements. This set of lexica is both independent to each other and mutually complimentary. LCSS is very helpful for data collection, feature selection, annotation, and modeling for large-scale image retrieval. It also shows a promising application potential for image annotation refinement and rejection. The experimental results demonstrate the validity of the developed concept lexica.", "paper_title": "Constructing Concept Lexica With Small Semantic Gaps", "paper_id": "WOS:000277668100006"}