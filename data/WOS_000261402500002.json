{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "furthest_reference_points"}, {"score": 0.004169226023596022, "phrase": "user-specified_parameters"}, {"score": 0.003965468669507077, "phrase": "general_divisive_hierarchical_clustering_methods"}, {"score": 0.0038431888954930083, "phrase": "practical_use"}, {"score": 0.003771631577951067, "phrase": "expensive_computation"}, {"score": 0.0035648266669315943, "phrase": "automatic_divisive_hierarchical_clustering_method"}, {"score": 0.0033905067962602515, "phrase": "bipartition_clusters"}, {"score": 0.003306559295382181, "phrase": "novel_dissimilarity_measure"}, {"score": 0.0031845067058084583, "phrase": "sliding_average"}, {"score": 0.002953711377604328, "phrase": "cluster_number"}, {"score": 0.0028625406368744995, "phrase": "optimum_number"}, {"score": 0.002756832447586547, "phrase": "spurious_clusters"}, {"score": 0.0026055251533586804, "phrase": "user-specified_parameter"}, {"score": 0.0023419588513908783, "phrase": "computational_cost"}, {"score": 0.0022273034991008326, "phrase": "general_divisive_clustering_methods"}, {"score": 0.0021995257343837547, "phrase": "numerical_experimental_results"}, {"score": 0.0021049977753042253, "phrase": "divfrp."}], "paper_keywords": ["Divisive clustering", " Automatic clustering", " Furthest reference point", " Dissimilarity measure", " Peak", " Spurious cluster"], "paper_abstract": "Although many clustering methods have been presented in the literature, most of them suffer from some drawbacks such as the requirement of user-specified parameters and being sensitive to outliers. For general divisive hierarchical clustering methods, an obstacle to practical use is the expensive computation. in this paper, we propose an automatic divisive hierarchical clustering method (DIVFRP). Its basic idea is to bipartition clusters repeatedly with a novel dissimilarity measure based on furthest reference points. A sliding average of sum-of-error is employed to estimate the Cluster number preliminarily, and the optimum number of clusters is achieved after spurious clusters identified. The method does not require any user-specified parameter, even any cluster validity index. Furthermore it is robust to outliers, and the computational cost of its partition process is lower than that of general divisive clustering methods. Numerical experimental results on both synthetic and real data sets show the performances of DIVFRP. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "DIVFRP: An automatic divisive hierarchical clustering method based on the furthest reference points", "paper_id": "WOS:000261402500002"}