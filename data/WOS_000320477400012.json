{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "dirichlet_process"}, {"score": 0.004761494044422926, "phrase": "generalized_dirichlet_distributions"}, {"score": 0.00470862827326028, "phrase": "simultaneous_clustering"}, {"score": 0.00465634671242413, "phrase": "feature_selection"}, {"score": 0.004502943680955863, "phrase": "novel_enhancement"}, {"score": 0.00445293569103488, "phrase": "unsupervised_feature_selection"}, {"score": 0.004118026552723285, "phrase": "finite_mixture_model"}, {"score": 0.003916098498242888, "phrase": "infinite_case"}, {"score": 0.0037869901077566526, "phrase": "dirichlet_process_mixtures"}, {"score": 0.003601235776892337, "phrase": "purely_nonparametric_model"}, {"score": 0.003501991125315889, "phrase": "mixture_components"}, {"score": 0.0033301694494391612, "phrase": "infinite_assumption"}, {"score": 0.0031845067058084583, "phrase": "model_selection"}, {"score": 0.002977835845437357, "phrase": "simultaneous_separation"}, {"score": 0.002895721231882758, "phrase": "similar_clusters"}, {"score": 0.0028316582436089064, "phrase": "relevant_features"}, {"score": 0.002722930209707764, "phrase": "principled_variational_bayesian_framework"}, {"score": 0.002618366076489732, "phrase": "experimental_results"}, {"score": 0.0025604233506352375, "phrase": "synthetic_data"}, {"score": 0.002531933388815139, "phrase": "real-world_challenging_applications"}, {"score": 0.0024620842899061614, "phrase": "automatic_semantic_annotation"}, {"score": 0.0023281003994670714, "phrase": "accurate_models"}, {"score": 0.002276566401216226, "phrase": "relevant_and_irrelevant_features"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Infinite mixture models", " Dirichlet process", " Generalized Dirichlet", " Feature selection", " Clustering", " Images categorization", " Image auto-annotation"], "paper_abstract": "This paper introduces a novel enhancement for unsupervised feature selection based on generalized Dirichlet (GD) mixture models. Our proposal is based on the extension of the finite mixture model previously developed in [1] to the infinite case, via the consideration of Dirichlet process mixtures, which can be viewed actually as a purely nonparametric model since the number of mixture components can increase as data are introduced. The infinite assumption is used to avoid problems related to model selection (i.e. determination of the number of clusters) and allows simultaneous separation of data in to similar clusters and selection of relevant features. Our resulting model is learned within a principled variational Bayesian framework that we have developed. The experimental results reported for both synthetic data and real-world challenging applications involving image categorization, automatic semantic annotation and retrieval show the ability of our approach to provide accurate models by distinguishing between relevant and irrelevant features without over- or under-fitting the data. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Variational learning of a Dirichlet process of generalized Dirichlet distributions for simultaneous clustering and feature selection", "paper_id": "WOS:000320477400012"}