{"auto_keywords": [{"score": 0.02707307859652855, "phrase": "hybrid_methods"}, {"score": 0.00481495049065317, "phrase": "evolutionary_heuristics"}, {"score": 0.004762893197005439, "phrase": "dynamic_environments"}, {"score": 0.004535481695403089, "phrase": "growing_interest"}, {"score": 0.004462105963334103, "phrase": "genetic_algorithms"}, {"score": 0.004413846562278824, "phrase": "dynamic_optimization_problems"}, {"score": 0.004203030435498069, "phrase": "extensive_performance_evaluation"}, {"score": 0.003980531478122155, "phrase": "common_platform"}, {"score": 0.0038948525410795517, "phrase": "moving_peaks_benchmark"}, {"score": 0.0037493114715625784, "phrase": "problem_parameters"}, {"score": 0.0037087324991876727, "phrase": "shift_length"}, {"score": 0.0034180189629740426, "phrase": "solution_quality"}, {"score": 0.0031500213134140953, "phrase": "offline_error_metric_and_dissimilarity_factor"}, {"score": 0.0029029754274913803, "phrase": "signal_similarity"}, {"score": 0.0028715299874549245, "phrase": "computational_effort"}, {"score": 0.0027341763737751467, "phrase": "average_number"}, {"score": 0.002704554429386671, "phrase": "fitness_evaluations"}, {"score": 0.0025059724686541263, "phrase": "related_work"}, {"score": 0.002235040467016128, "phrase": "offline_error"}, {"score": 0.0021631447601689444, "phrase": "dissimilarity_factor"}], "paper_keywords": ["Dynamic optimization problems", " Evolutionary algorithms", " Performance evaluation"], "paper_abstract": "In recent years, there has been a growing interest in applying genetic algorithms to dynamic optimization problems. In this study, we present an extensive performance evaluation and comparison of 13 leading evolutionary algorithms with different characteristics on a common platform by using the moving peaks benchmark and by varying a set of problem parameters including shift length, change frequency, correlation value and number of peaks in the landscape. In order to compare solution quality or the efficiency of algorithms, the results are reported in terms of both offline error metric and dissimilarity factor, our novel comparison metric presented in this paper, which is based on signal similarity. Computational effort of each algorithm is reported in terms of average number of fitness evaluations and the average execution time. Our experimental evaluation indicates that the hybrid methods outperform the related work with respect to quality of solutions for various parameters of the given benchmark problem. Specifically, hybrid methods provide up to 24% improvement with respect to offline error and up to 30% improvement with respect to dissimilarity factor by requiring more computational effort than other methods.", "paper_title": "Performance evaluation of evolutionary heuristics in dynamic environments", "paper_id": "WOS:000305396200009"}