{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "haptic_rendering"}, {"score": 0.004669845451682529, "phrase": "visual_data"}, {"score": 0.004068907083697369, "phrase": "force-field_haptic_rendering_method"}, {"score": 0.003711723285313348, "phrase": "haptic_data"}, {"score": 0.0033857878144822906, "phrase": "novel_framework"}, {"score": 0.002860546817196148, "phrase": "final_force_fields"}, {"score": 0.0025694584194998356, "phrase": "implicit_surface_approximation_algorithms"}, {"score": 0.0024918548761791435, "phrase": "visually_impaired_people"}, {"score": 0.0021049977753042253, "phrase": "off-the-shelf_haptic_devices"}], "paper_keywords": [""], "paper_abstract": "We introduce a force-field haptic rendering method for converting visual data to haptic data. The method includes a novel framework to convert specialized 3D map models into force fields. We generate the final force fields by using structure from motion and implicit surface approximation algorithms. Visually impaired people then can learn to navigate with these maps, using off-the-shelf haptic devices.", "paper_title": "Haptic rendering of visual data for the visually impaired", "paper_id": "WOS:000243262800008"}