{"auto_keywords": [{"score": 0.030945308178596188, "phrase": "host_cpu"}, {"score": 0.004763565662615503, "phrase": "heterogeneous_platforms"}, {"score": 0.004563427013973105, "phrase": "video_encoders"}, {"score": 0.004324985524216987, "phrase": "computational_demand"}, {"score": 0.004233119608341877, "phrase": "frame_resolution"}, {"score": 0.0040334640350288, "phrase": "great_interest"}, {"score": 0.003926626018798576, "phrase": "parallel_processing"}, {"score": 0.0038431888954930083, "phrase": "graphics_processing_units"}, {"score": 0.0036815763368083197, "phrase": "viable_target"}, {"score": 0.0036227329311981195, "phrase": "general_purpose_applications"}, {"score": 0.0035648266669315943, "phrase": "fine-grain_data_parallelisms"}, {"score": 0.0035078427258024613, "phrase": "extensive_research_efforts"}, {"score": 0.003050508020268648, "phrase": "fastest_cpu_implementation"}, {"score": 0.002969628818856786, "phrase": "significant_communication_overhead"}, {"score": 0.0028756102213955722, "phrase": "gpu"}, {"score": 0.0028446460307503343, "phrase": "intra-frame_dependency"}, {"score": 0.0026242910203213383, "phrase": "nvidia"}, {"score": 0.0025003054002226944, "phrase": "novel_pipelining_technique"}, {"score": 0.0023440589015485077, "phrase": "communication_overhead"}, {"score": 0.0022696666517058317, "phrase": "gpu."}, {"score": 0.002209406458446019, "phrase": "frame-level_parallelization_technique"}, {"score": 0.002162379426839795, "phrase": "overall_throughput"}, {"score": 0.0021392418081444798, "phrase": "experimental_results"}], "paper_keywords": ["H.264", " Motion estimation", " CUDA", " GPU"], "paper_abstract": "H.264/AVC video encoders have been widely used for its high coding efficiency. Since the computational demand proportional to the frame resolution is constantly increasing, it has been of great interest to accelerate H.264/AVC by parallel processing. Recently, graphics processing units (GPUs) have emerged as a viable target for accelerating general purpose applications by exploiting fine-grain data parallelisms. Despite extensive research efforts to use GPUs to accelerate the H.264/AVC algorithm, it has not been successful to achieve any speed-up over the x264 algorithm that is known as the fastest CPU implementation, mainly due to significant communication overhead between the host CPU and the GPU and intra-frame dependency in the algorithm. In this paper, we propose a novel motion-estimation (ME) algorithm tailored for NVIDIA GPU implementation. It is accompanied by a novel pipelining technique, called sub-frame ME processing, to effectively hide the communication overhead between the host CPU and the GPU. Further, we incorporate frame-level parallelization technique to improve the overall throughput. Experimental results show that our proposed H.264 encoder has higher performance than x264 encoder.", "paper_title": "An efficient parallelization technique for x264 encoder on heterogeneous platforms consisting of CPUs and GPUs", "paper_id": "WOS:000331639800002"}