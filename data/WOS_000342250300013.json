{"auto_keywords": [{"score": 0.024128454305129176, "phrase": "convolutional"}, {"score": 0.00481495049065317, "phrase": "additive_input_noise_annealing"}, {"score": 0.00460125407969429, "phrase": "improved_handwritten_character_recognition"}, {"score": 0.004317848984770719, "phrase": "learning_process"}, {"score": 0.004240116703465252, "phrase": "artificial_neural_networks"}, {"score": 0.0041637779492720295, "phrase": "back_propagation"}, {"score": 0.0034717929086014636, "phrase": "local_minima"}, {"score": 0.0030847461428168614, "phrase": "handwritten_digits"}, {"score": 0.00297454367746853, "phrase": "mnist_dataset"}, {"score": 0.0028682668647074397, "phrase": "modest_sized_ann"}, {"score": 0.0027910516355928983, "phrase": "proposed_combination"}, {"score": 0.0027407299369891502, "phrase": "input_data_transformations"}, {"score": 0.0025951294037626174, "phrase": "test_error"}, {"score": 0.0022231606165229235, "phrase": "deep_neural_networks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Artificial Neural Networks", " Back Propagation", " MNIST", " Handwritten text recognition"], "paper_abstract": "Two problems that burden the learning process of Artificial Neural Networks with Back Propagation are the need of building a full and representative learning data set, and the avoidance of stalling in local minima. Both problems seem to be closely related when working with the handwritten digits contained in the MNIST dataset. Using a modest sized ANN, the proposed combination of input data transformations enables the achievement of a test error as low as 0.43%, which is up to standard compared to other more complex neural architectures like Convolutional or Deep Neural Networks. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Combining additive input noise annealing and pattern transformations for improved handwritten character recognition", "paper_id": "WOS:000342250300013"}