{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "multi-label_classification"}, {"score": 0.012394865572114907, "phrase": "overall_performance"}, {"score": 0.009896609753883246, "phrase": "moml"}, {"score": 0.004751216062917875, "phrase": "multi-objective_optimization"}, {"score": 0.004565007074039171, "phrase": "potentially_multiple_labels"}, {"score": 0.004308791766002289, "phrase": "single_objective_setting"}, {"score": 0.004232875294230749, "phrase": "learning_algorithm"}, {"score": 0.004158290806404304, "phrase": "single_performance_criterion"}, {"score": 0.003995226376780718, "phrase": "heuristic_function"}, {"score": 0.003942299471749811, "phrase": "basic_assumption"}, {"score": 0.003754140294151593, "phrase": "multilabel_classification"}, {"score": 0.003527550673371394, "phrase": "optimal_multi-label_classifier"}, {"score": 0.003404244237372396, "phrase": "multiple_inconsistent_objectives"}, {"score": 0.003329368827624161, "phrase": "hamming_loss"}, {"score": 0.003128336741911927, "phrase": "multi-objective_multi-label_classification"}, {"score": 0.002965684305115369, "phrase": "overmultiple_objectives"}, {"score": 0.002900426826591769, "phrase": "optimization_objectives"}, {"score": 0.0027252240573281163, "phrase": "single_solution"}, {"score": 0.002572001496778222, "phrase": "nondominated_solutions"}, {"score": 0.0025042115651986332, "phrase": "different_trade-offs"}, {"score": 0.002290858045013009, "phrase": "different_application_scenarios"}, {"score": 0.0022705467477443417, "phrase": "empirical_studies"}, {"score": 0.002250415129116109, "phrase": "real-world_tasks"}, {"score": 0.0021049977753042253, "phrase": "multiple_objectives"}], "paper_keywords": ["Measurement", " Classification", " multi-label classification", " multi-objective optimization", " model selection", " classifier design and evaluation", " pattern analysis"], "paper_abstract": "Multi-label classification refers to the task of predicting potentially multiple labels for a given instance. Conventional multi-label classification approaches focus on single objective setting, where the learning algorithm optimizes over a single performance criterion (e.g., Ranking Loss) or a heuristic function. The basic assumption is that the optimization over one single objective can improve the overall performance of multilabel classification and meet the requirements of various applications. However, in many real applications, an optimal multi-label classifier may need to consider the trade-offs among multiple inconsistent objectives, such as minimizing Hamming Loss while maximizing Micro F1. In this article, we study the problem of multi-objective multi-label classification and propose a novel solution (called MOML) to optimize overmultiple objectives simultaneously. Note that optimization objectives may be inconsistent, even conflicting, thus one cannot identify a single solution that is optimal on all objectives. Our MOML algorithm finds a set of nondominated solutions which are optimal according to different trade-offs among multiple objectives. So users can flexibly construct various predictive models from the solution set, which provides more meaningful classification results in different application scenarios. Empirical studies on real-world tasks demonstrate that the MOML can effectively boost the overall performance of multi-label classification by optimizing over multiple objectives simultaneously.", "paper_title": "Multi-Label Classification Based on Multi-Objective Optimization", "paper_id": "WOS:000335576200014"}