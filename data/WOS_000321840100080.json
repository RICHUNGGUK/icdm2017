{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "richly_annotated_catalog_of_surface_appearance"}, {"score": 0.004677032188041644, "phrase": "real-world_scenes"}, {"score": 0.004180919839686364, "phrase": "rich_surface_appearance"}, {"score": 0.004044251230868813, "phrase": "home_remodeling"}, {"score": 0.003570218982072853, "phrase": "consumer_photographs"}, {"score": 0.0034678302347682694, "phrase": "material_parameters"}, {"score": 0.003048449231088915, "phrase": "usable_surface_information"}, {"score": 0.0030231983220281836, "phrase": "uncalibrated_internet_photo_collections"}, {"score": 0.002948689937518561, "phrase": "human_annotations"}, {"score": 0.002900037689072025, "phrase": "new_methodology"}, {"score": 0.002816814445002924, "phrase": "internet_photo_collections"}, {"score": 0.0027246145918972, "phrase": "amazon's_mechanical_turk"}, {"score": 0.002602734354498382, "phrase": "internet_photos"}, {"score": 0.002581165831422692, "phrase": "novice_annotators"}, {"score": 0.0025385621498128243, "phrase": "annotation_engine"}, {"score": 0.0025070703395635133, "phrase": "key_challenge"}, {"score": 0.0024554476124885806, "phrase": "multi-stage_set"}, {"score": 0.002404885278896803, "phrase": "quality_checks"}, {"score": 0.002249961956629804, "phrase": "concept_applications"}, {"score": 0.002231310272815607, "phrase": "surface_retexturing"}, {"score": 0.0021492686054379755, "phrase": "future_uses"}, {"score": 0.0021314498639048085, "phrase": "opensurfaces"}, {"score": 0.0021049977753042253, "phrase": "public_resource"}], "paper_keywords": ["materials", " reflectance", " textures", " crowdsourcing"], "paper_abstract": "The appearance of surfaces in real-world scenes is determined by the materials, textures, and context in which the surfaces appear. However, the datasets we have for visualizing and modeling rich surface appearance in context, in applications such as home remodeling, are quite limited. To help address this need, we present OpenSurfaces, a rich, labeled database consisting of thousands of examples of surfaces segmented from consumer photographs of interiors, and annotated with material parameters (reflectance, material names), texture information (surface normals, rectified textures), and contextual information (scene category, and object names). Retrieving usable surface information from uncalibrated Internet photo collections is challenging. We use human annotations and present a new methodology for segmenting and annotating materials in Internet photo collections suitable for crowdsourcing (e.g., through Amazon's Mechanical Turk). Because of the noise and variability inherent in Internet photos and novice annotators, designing this annotation engine was a key challenge; we present a multi-stage set of annotation tasks with quality checks and validation. We demonstrate the use of this database in proof-of-concept applications including surface retexturing and material and image browsing, and discuss future uses. OpenSurfaces is a public resource available at http://opensurfaces.cs.cornell.edu/.", "paper_title": "OPENSURFACES: A Richly Annotated Catalog of Surface Appearance", "paper_id": "WOS:000321840100080"}