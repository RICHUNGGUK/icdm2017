{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "medical_image_retrieval."}, {"score": 0.004754600386388821, "phrase": "cbir_study"}, {"score": 0.0046361494357125355, "phrase": "traditional_supervised_learning"}, {"score": 0.004463958296056236, "phrase": "labeled_data"}, {"score": 0.0044079880067019765, "phrase": "semi-supervised_learning"}, {"score": 0.004271100220705305, "phrase": "labeled_and_unlabeled_data"}, {"score": 0.004112411350177274, "phrase": "unlabeled_data"}, {"score": 0.0038365781437074017, "phrase": "unlabeled_examples"}, {"score": 0.0037409118365761894, "phrase": "new_svm-based_co-training_algorithm"}, {"score": 0.003317970131738248, "phrase": "relevance_feedback_round"}, {"score": 0.00301801991152303, "phrase": "relevance_feedback"}, {"score": 0.002609770322855842, "phrase": "top_result-size_ranks"}], "paper_keywords": ["Co-training", " Unlabeled data", " SVM", " PR-graphs", " BEP-graphs"], "paper_abstract": "In CBIR study, different from traditional supervised learning which only makes use of labeled data, semi-supervised learning makes use of both labeled and unlabeled data. For the importance of unlabeled data, it is necessary to define conditions to utilize the unlabeled examples enough. A new SVM-based co-training algorithm that defining two learners is presented in this paper, where both the learners are re-trained after every relevance feedback round, and then each of them gives every image in a Tank. In relevance feedback, the user may label several images according to whether they are relevant or not to a query, and images with the top result-size ranks are returned. Finally, to test the performance Of our methodology, a database consisting of 500 chest CT images were used, PR-graphs and BEP-graphs all illustrate that the performance of our method is better.", "paper_title": "AN ALGORITHM FOR CO-TRAINING IN MEDICAL IMAGE RETRIEVAL", "paper_id": "WOS:000271852600029"}