{"auto_keywords": [{"score": 0.03727908513632229, "phrase": "lee"}, {"score": 0.008722997547279036, "phrase": "nmf"}, {"score": 0.006913535373620658, "phrase": "lin"}, {"score": 0.00481495049065317, "phrase": "nonnegative_matrix_factorization"}, {"score": 0.004608284537368354, "phrase": "data_analysis_technique"}, {"score": 0.004475436844227947, "phrase": "great_variety"}, {"score": 0.0043147264956783565, "phrase": "text_mining"}, {"score": 0.004252063063815893, "phrase": "image_processing"}, {"score": 0.004190305872545087, "phrase": "hyperspectral_data_analysis"}, {"score": 0.0041294419262414995, "phrase": "computational_biology"}, {"score": 0.003700170452390401, "phrase": "nmf_problems"}, {"score": 0.0035843142096276216, "phrase": "seung"}, {"score": 0.003291188255149539, "phrase": "cichocki_et_al"}, {"score": 0.0031728680535262083, "phrase": "simple_way"}, {"score": 0.002948798472453167, "phrase": "careful_analysis"}, {"score": 0.0028847066125323893, "phrase": "computational_cost"}, {"score": 0.0026613618933208467, "phrase": "acceleration_technique"}, {"score": 0.002419542935774618, "phrase": "projected_gradient_method"}, {"score": 0.0022817585639886883, "phrase": "accelerated_algorithms"}, {"score": 0.00219964788028393, "phrase": "image_and_text_data_sets"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_alternating_nonnegative_least_squares_algorithm"}], "paper_keywords": [""], "paper_abstract": "Nonnegative matrix factorization (NMF) is a data analysis technique used in a great variety of applications such as text mining, image processing, hyperspectral data analysis, computational biology, and clustering. In this letter, we consider two well-known algorithms designed to solve NMF problems: the multiplicative updates of Lee and Seung and the hierarchical alternating least squares of Cichocki et al. We propose a simple way to significantly accelerate these schemes, based on a careful analysis of the computational cost needed at each iteration, while preserving their convergence properties. This acceleration technique can also be applied to other algorithms, which we illustrate on the projected gradient method of Lin. The efficiency of the accelerated algorithms is empirically demonstrated on image and text data sets and compares favorably with a state-of-the-art alternating nonnegative least squares algorithm.", "paper_title": "Accelerated Multiplicative Updates and Hierarchical ALS Algorithms for Nonnegative Matrix Factorization", "paper_id": "WOS:000301223200009"}