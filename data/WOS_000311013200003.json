{"auto_keywords": [{"score": 0.011948071210281422, "phrase": "requirements_engineers"}, {"score": 0.011819472849107573, "phrase": "modelling_errors"}, {"score": 0.009251976984406832, "phrase": "contextual_goal_models"}, {"score": 0.00481495049065317, "phrase": "contextual_requirements"}, {"score": 0.0045794780139433834, "phrase": "autonomous_ability"}, {"score": 0.004441796302539144, "phrase": "requirements_analysis_stage"}, {"score": 0.00441283351404103, "phrase": "strong_mutual_influence"}, {"score": 0.004270815799190556, "phrase": "main_factor"}, {"score": 0.004160485763981557, "phrase": "activated_requirement"}, {"score": 0.004061845315919927, "phrase": "system_actions"}, {"score": 0.0038714978747718776, "phrase": "complex_task"}, {"score": 0.0038462393577390233, "phrase": "error-free_models"}, {"score": 0.003787939389391368, "phrase": "automated_support"}, {"score": 0.003763223967073368, "phrase": "main_objective"}, {"score": 0.003681993718155892, "phrase": "automated_analysis_mechanisms"}, {"score": 0.003594656829488919, "phrase": "contextual_requirements_models"}, {"score": 0.0035170523043206612, "phrase": "contextual_goal_model"}, {"score": 0.003486479998882841, "phrase": "requirements_model"}, {"score": 0.0033963429747226074, "phrase": "goal_models"}, {"score": 0.0033594748181681564, "phrase": "early_stages"}, {"score": 0.0033448394826490766, "phrase": "software_development"}, {"score": 0.0032654736807577254, "phrase": "development_process"}, {"score": 0.0031327834636704376, "phrase": "inconsistent_specification"}, {"score": 0.003098767416044413, "phrase": "goal_model"}, {"score": 0.003045105974650457, "phrase": "conflicting_context_changes"}, {"score": 0.0029469753851169, "phrase": "different_requirements"}, {"score": 0.0028959348946595675, "phrase": "case_tool"}, {"score": 0.0028707461560694763, "phrase": "systematic_process"}, {"score": 0.0027661086119566006, "phrase": "case_study"}, {"score": 0.0027480420060477235, "phrase": "smart-home_system"}, {"score": 0.0027004376341701886, "phrase": "dementia_problems"}, {"score": 0.002653655719152516, "phrase": "significant_ability"}, {"score": 0.0025513306964625258, "phrase": "acceptable_performance"}, {"score": 0.0025071253905738695, "phrase": "medium-sized_contextual_goal_models"}, {"score": 0.0023124099173913357, "phrase": "essential_step"}, {"score": 0.002297299779913422, "phrase": "entire_system_correctness"}, {"score": 0.0022673743936812833, "phrase": "unusable_and_unwanted_functionalities"}, {"score": 0.002175152729495803, "phrase": "large-sized_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Requirements engineering", " Contextual requirements", " Goal modelling", " Consistency and conflicts analysis", " Adaptive systems engineering"], "paper_abstract": "Context: The environment in which the system operates, its context, is variable. The autonomous ability of a software to adapt to context has to be planned since the requirements analysis stage as a strong mutual influence between requirements and context does exist. On the one hand, context is a main factor to decide whether to activate a requirement, the applicable alternatives to meet an activated requirement as well as their qualities. On the other hand, the system actions to reach requirements could cause changes in the context. Objectives: Modelling the relationship between requirements and context is a complex task and developing error-free models is hard to achieve without an automated support. The main objective of this paper is to develop a set of automated analysis mechanisms to support the requirements engineers to detect and analyze modelling errors in contextual requirements models. Method: We study the analysis of the contextual goal model which is a requirements model that weaves together the variability of both context and requirements. Goal models are used during the early stages of software development and, thus, our analysis detects errors early in the development process. We develop two analysis mechanisms to detect two kinds of modelling errors. The first: mechanism concerns the detection of inconsistent specification of contexts in a goal model. The second concerns the detection of conflicting context changes that arise as a consequence of the actions performed by the system to meet different requirements simultaneously. We support our analysis with a CASE tool and provide a systematic process that guides the construction and analysis of contextual goal models. We illustrate and evaluate our framework via a case study on a smart-home system for supporting the life of people having dementia problems. Results: The evaluation showed a significant ability of our analysis mechanisms to detect errors which were not notable by requirements engineers. Moreover, the evaluation showed acceptable performance of these mechanisms when processing up to medium-sized contextual goal models. The modelling constructs which we proposed as an input to enable the analysis were found easy to understand and capture. Conclusions: Our developed analysis for the detection of inconsistency and conflicts in contextual goal models is an essential step for the entire system correctness. It avoids us developing unusable and unwanted functionalities and functionalities which lead to conflicts when they operate together. Further research to improve our analysis to scale with large-sized models and to consider other kinds of errors is still needed. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Reasoning with contextual requirements: Detecting inconsistency and conflicts", "paper_id": "WOS:000311013200003"}