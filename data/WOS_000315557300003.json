{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multithreaded_applications"}, {"score": 0.04954756810706401, "phrase": "shared_caches"}, {"score": 0.0041642891310893, "phrase": "theoretical_performance_gain"}, {"score": 0.00400459716272594, "phrase": "parallel_execution"}, {"score": 0.0037449033166879874, "phrase": "cache_access_bottleneck"}, {"score": 0.003501991125315889, "phrase": "shared_cache_levels"}, {"score": 0.003405472159599442, "phrase": "performance_gain"}, {"score": 0.0032747835779400212, "phrase": "greater_reuse"}, {"score": 0.0030451958332949735, "phrase": "analytical_model"}, {"score": 0.0028316582436089064, "phrase": "loop_level"}, {"score": 0.0026626797255348287, "phrase": "first_analytical_model"}, {"score": 0.0025461386232786356, "phrase": "realistic_shared_caches"}, {"score": 0.0024620842899061614, "phrase": "experimental_results"}, {"score": 0.0024075916292945715, "phrase": "model_predictions"}, {"score": 0.002176887956041267, "phrase": "best_parallelization_strategy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Shared caches", " Analytical modeling", " Parallel applications", " Loop parallelism", " Performance prediction", " Optimization"], "paper_abstract": "Multicores are the norm nowadays and in many of them there are cores that share one or several levels of cache. The theoretical performance gain expected when several cores cooperate in the parallel execution of an application can be reduced in some cases by a cache access bottleneck, as the data accessed by them can interfere in the shared cache levels. In other cases the performance gain can be increased due to a greater reuse of the data loaded in the cache. This paper presents an analytical model that can predict the behavior of shared caches when executing applications parallelized at loop level. To the best of our knowledge, this is the first analytical model that tackles the behavior of multithreaded applications on realistic shared caches without requiring profiling. The experimental results show that the model predictions are precise and very fast and that the model can help a compiler or programmer choose the best parallelization strategy. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Accurate prediction of the behavior of multithreaded applications in shared caches", "paper_id": "WOS:000315557300003"}