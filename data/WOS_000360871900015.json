{"auto_keywords": [{"score": 0.049792109409163725, "phrase": "heterogeneous_systems"}, {"score": 0.010269345942724478, "phrase": "big_data_analytics"}, {"score": 0.00481495049065317, "phrase": "map_reduce"}, {"score": 0.004630517016920072, "phrase": "performance_improvements"}, {"score": 0.004426431307429982, "phrase": "time-energy_performance_analysis"}, {"score": 0.004399940151196971, "phrase": "mapreduce"}, {"score": 0.004193316635088688, "phrase": "diverse_resource_demands"}, {"score": 0.004155670607078649, "phrase": "hadoop-cuda_framework"}, {"score": 0.00396050388346298, "phrase": "novel_lazy_processing_technique"}, {"score": 0.0038780151896468194, "phrase": "underlying_hadoop_framework"}, {"score": 0.0037069717781636194, "phrase": "homogeneous_cpu-only_execution"}, {"score": 0.0036516442918817214, "phrase": "diverse_characteristics"}, {"score": 0.0035328029694928296, "phrase": "nvidia_gpu"}, {"score": 0.0035010659378711816, "phrase": "latest_maxwell_generation"}, {"score": 0.003438441702164516, "phrase": "wimpy_platform"}, {"score": 0.003326524714332428, "phrase": "nvidia"}, {"score": 0.003198912570466607, "phrase": "intra-node_heterogeneity"}, {"score": 0.0031511440119092447, "phrase": "intra-chip_heterogeneity"}, {"score": 0.003030247482854539, "phrase": "-intensive_workloads"}, {"score": 0.0030030115662983987, "phrase": "brawny_heterogeneous_system"}, {"score": 0.002940406485632161, "phrase": "energy_usage"}, {"score": 0.0028877818105020434, "phrase": "brawny_homogeneous_system"}, {"score": 0.002819073586200239, "phrase": "data_transfers"}, {"score": 0.002793730385549585, "phrase": "execution_time"}, {"score": 0.002776961266279729, "phrase": "heterogeneity_exhibits"}, {"score": 0.0027686143852727156, "phrase": "worse_time-energy_performance"}, {"score": 0.002662422377168988, "phrase": "gpu"}, {"score": 0.002583392808974657, "phrase": "system_resource_imbalances"}, {"score": 0.0025678829712650437, "phrase": "high_power_overhead"}, {"score": 0.0025447921872619435, "phrase": "discrete_cpu."}, {"score": 0.0024693083555454133, "phrase": "integrated_cpu"}, {"score": 0.002447101794397243, "phrase": "lowest_energy"}, {"score": 0.002367368688024317, "phrase": "execution_time_equivalence_ratio"}, {"score": 0.0023460767171603054, "phrase": "single_brawny_node"}, {"score": 0.00233198831578686, "phrase": "multiple_wimpy_nodes"}, {"score": 0.0022971354864013073, "phrase": "equivalence_ratio"}, {"score": 0.0022764737473071296, "phrase": "wimpy_nodes"}, {"score": 0.002262802370005939, "phrase": "energy_savings"}, {"score": 0.0021824773921574636, "phrase": "potential_usage"}, {"score": 0.0021693692831601745, "phrase": "heterogeneous_wimpy_systems"}, {"score": 0.0021563397322290445, "phrase": "integrated_cpus"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Heterogeneous systems", " GPU", " Map Reduce", " Time energy performance analysis", " Energy efficiency"], "paper_abstract": "Motivated by the explosion of Big Data analytics, performance improvements in low-power (wimpy) systems and the increasing energy efficiency of CPUs, this paper presents a time-energy performance analysis of MapReduce on heterogeneous systems with GPUs. We evaluate the time and energy performance of three MapReduce applications with diverse resource demands on a Hadoop-CUDA framework. As executing these applications on heterogeneous systems with GPUs is challenging, we introduce a novel lazy processing technique which requires no modifications to the underlying Hadoop framework. To analyze the impact of heterogeneity, we compare the heterogeneous CPU+GPU with the homogeneous CPU-only execution across three systems with diverse characteristics, (i) a traditional high-performance (brawny) Intel i7 system hosting a discrete 640-core Nvidia GPU of the latest Maxwell generation, (ii) a wimpy platform consisting of a quad-core ARM Cortex-A9 hosting the same discrete Maxwell CPU, and (iii) a wimpy platform integrating four ARM Cortex-A15 cores and 192 Nvidia Kepler CPU cores on the same chip. These systems encompass both intra-node heterogeneity with discrete CPUs and intra-chip heterogeneity with integrated CPUs. Our measurement-based performance analysis highlights the following results. For compute-intensive workloads, the brawny heterogeneous system achieves speedups of up to 2.3 and reduces the energy usage by almost half compared to the brawny homogeneous system. As expected, for applications where data transfers dominate the execution time, heterogeneity exhibits worse time-energy performance compared to homogeneous systems. For such applications, the heterogeneous wimpy A9 system with discrete GPU uses around 14 times the energy of homogeneous A9 system due to both system resource imbalances and high power overhead of the discrete CPU. However, comparing among heterogeneous systems, the wimpy A15 with integrated CPU uses the lowest energy across all workloads. This allows us to establish an execution time equivalence ratio between a single brawny node and multiple wimpy nodes. Based on this equivalence ratio, the wimpy nodes exhibit energy savings of two-thirds while maintaining the same execution time. This result advocates the potential usage of heterogeneous wimpy systems with integrated CPUs for Big Data analytics. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "A time-energy performance analysis of Map Reduce on heterogeneous systems with GPUs", "paper_id": "WOS:000360871900015"}