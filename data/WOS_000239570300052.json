{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "automatic_facial_expression_classification"}, {"score": 0.004593787100061613, "phrase": "emotional_component"}, {"score": 0.004382737590042589, "phrase": "new_technologies"}, {"score": 0.004295269532032448, "phrase": "multimedia_sector"}, {"score": 0.00418134346679498, "phrase": "stunning_pace"}, {"score": 0.00398916666053909, "phrase": "high-capacity_mass_storage_devices"}, {"score": 0.003935892934907777, "phrase": "low_cost_private_multimedia_libraries"}, {"score": 0.0038833278847237858, "phrase": "digital_video_and_audio_items"}, {"score": 0.0033268412940032103, "phrase": "preferred_contents"}, {"score": 0.003131393466870228, "phrase": "specific_part"}, {"score": 0.002927626967420519, "phrase": "time_code"}, {"score": 0.0027741761880779535, "phrase": "broaference_system"}, {"score": 0.0025761937402886954, "phrase": "meta-data_creation"}, {"score": 0.002524688179363081, "phrase": "recorded_user_experience"}, {"score": 0.0024742098091226203, "phrase": "facial_expressions"}, {"score": 0.002297585503415527, "phrase": "interest_focus_data"}, {"score": 0.002206606452557159, "phrase": "system_layout"}, {"score": 0.0021049977753042253, "phrase": "system_verification"}], "paper_keywords": ["facial expression", " emotion", " video retrieval"], "paper_abstract": "Within the last decade the development of new technologies in the multimedia sector has advanced with stunning pace. Due to the availability of high-capacity mass storage devices at low cost private multimedia libraries containing digital video and audio items have recently gained popularity. Although attached meta-data like title, actor's/actress' name and creation time eases the task of finding preferred contents, it is still difficult to find a specific part within a movie one enjoyed before by remembering the time code. In this paper we introduce the BROAFERENCE system that provides a solution for the above problem. We propose meta-data creation based on recorded user experience derived from facial expressions containing joy, sadness and anger events as well as interest focus data. In the following the system layout, functionality and conducted experiments for system verification will be introduced to the reader.", "paper_title": "Using automatic facial expression classification for contents indexing based on the emotional component", "paper_id": "WOS:000239570300052"}