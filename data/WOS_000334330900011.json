{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "shared_caches"}, {"score": 0.004692227830462433, "phrase": "main_sources"}, {"score": 0.004596295252559861, "phrase": "current_caches"}, {"score": 0.004525629293824217, "phrase": "non-uniform_distribution"}, {"score": 0.004364919932563366, "phrase": "cache_sets"}, {"score": 0.004188198923320451, "phrase": "mapping_restrictions"}, {"score": 0.004145143433523008, "phrase": "non_fully_associative_caches"}, {"score": 0.004081385289516914, "phrase": "access_patterns"}, {"score": 0.003531474887552889, "phrase": "coordinated_way"}, {"score": 0.003370907075333389, "phrase": "chip_multiprocessors"}, {"score": 0.0032176163279340206, "phrase": "different_patterns"}, {"score": 0.0026986685585382347, "phrase": "appropriate_combination"}, {"score": 0.0023834640793589414, "phrase": "average_throughput_improvement"}, {"score": 0.002298649369775623, "phrase": "traditional_cache_design"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["thread-awareness", " coordination policies", " last-level cache memories"], "paper_abstract": "Two of the main sources of inefficiency in current caches are the non-uniform distribution of the memory accesses across the cache sets, which causes misses due to the mapping restrictions of non fully associative caches and the access patterns with little locality that degrade the performance of caches under the traditional least recently used. replacement policy. This paper proposes a technique to tackle in a coordinated way both kinds of problems in the context of chip multiprocessors, whose last level caches can be shared by threads with different patterns of locality. Our proposal, called thread-aware mapping and replacement miss reduction (TAMR2) policy, tracks the behavior of each thread in each set in order to decide the appropriate combination of policies to deal with these problems. Despite its small overhead, TAMR2 achieved in our experiments average power consumption and memory latency reductions of 10% and 12%, respectively, resulting in an average throughput improvement of 5.6%, relative to a traditional cache design using four cores. TAMR2 also outperformed many recent related approaches in the field. Copyright (c) 2013 John Wiley & Sons, Ltd.", "paper_title": "A fine-grained thread-aware management policy for shared caches", "paper_id": "WOS:000334330900011"}