{"auto_keywords": [{"score": 0.04597142052282097, "phrase": "de_novo_assembly"}, {"score": 0.00481495049065317, "phrase": "large_genomes"}, {"score": 0.00471465954562773, "phrase": "second-generation_sequencing_technology"}, {"score": 0.004356741449157895, "phrase": "higher_eukaryotes"}, {"score": 0.004047141845635495, "phrase": "wide_scale_biological_variation"}, {"score": 0.003962779958955344, "phrase": "human_biomedicine"}, {"score": 0.0038597866217852353, "phrase": "direct_way"}, {"score": 0.0037793152987497286, "phrase": "large-scale_structural_variation"}, {"score": 0.0037397086147485897, "phrase": "fine-scale_sequence_variation"}, {"score": 0.0036043137580229873, "phrase": "computational_feasibility"}, {"score": 0.003383475802364289, "phrase": "sequence_data"}, {"score": 0.002858313353461727, "phrase": "entropy_compressed_or_succinct_data_structures"}, {"score": 0.002740253546178098, "phrase": "de_bruijn_assembly_graph"}, {"score": 0.0025452314655691165, "phrase": "deployed_methods"}, {"score": 0.0023640560785711923, "phrase": "sequencing_errors"}, {"score": 0.002326938965568362, "phrase": "better_scaling"}, {"score": 0.0022783523466965187, "phrase": "conventional_approaches"}, {"score": 0.0021957487795963666, "phrase": "proof-of-concept_assembly"}, {"score": 0.0021049977753042253, "phrase": "modest_commodity_server"}], "paper_keywords": [""], "paper_abstract": "Motivation: Second-generation sequencing technology makes it feasible for many researches to obtain enough sequence reads to attempt the de novo assembly of higher eukaryotes (including mammals). De novo assembly not only provides a tool for understanding wide scale biological variation, but within human biomedicine, it offers a direct way of observing both large-scale structural variation and fine-scale sequence variation. Unfortunately, improvements in the computational feasibility for de novo assembly have not matched the improvements in the gathering of sequence data. This is for two reasons: the inherent computational complexity of the problem and the in-practice memory requirements of tools. Results: In this article, we use entropy compressed or succinct data structures to create a practical representation of the de Bruijn assembly graph, which requires at least a factor of 10 less storage than the kinds of structures used by deployed methods. Moreover, because our representation is entropy compressed, in the presence of sequencing errors it has better scaling behaviour asymptotically than conventional approaches. We present results of a proof-of-concept assembly of a human genome performed on a modest commodity server.", "paper_title": "Succinct data structures for assembling large genomes", "paper_id": "WOS:000287246000006"}