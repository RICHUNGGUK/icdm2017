{"auto_keywords": [{"score": 0.04165700301537225, "phrase": "active_learning"}, {"score": 0.014200156009357439, "phrase": "random_sampling"}, {"score": 0.011480191019888005, "phrase": "training_samples"}, {"score": 0.00481495049065317, "phrase": "best_paper"}, {"score": 0.004750873844061641, "phrase": "balanced_classifier-independent_training_samples"}, {"score": 0.004523103062368843, "phrase": "balanced_training_samples"}, {"score": 0.004462892860919036, "phrase": "unlabeled_data_set"}, {"score": 0.004403480614319231, "phrase": "unknown_class_distribution"}, {"score": 0.004081385289516914, "phrase": "unbalanced_data"}, {"score": 0.0039380388343479384, "phrase": "cost-sensitive_learning"}, {"score": 0.0037157201349604222, "phrase": "misclassification_costs"}, {"score": 0.0035532533960012298, "phrase": "new_strategy"}, {"score": 0.003397866151093552, "phrase": "underlying_class_distribution"}, {"score": 0.0032059442984238664, "phrase": "labeled_data"}, {"score": 0.002957919048133256, "phrase": "-supervised_clustering"}, {"score": 0.0028795712616923462, "phrase": "biased_sampling"}, {"score": 0.002741269087816162, "phrase": "underlying_class_distributions"}, {"score": 0.0025518429503461736, "phrase": "highly_skewed_and_balanced_data"}, {"score": 0.0025178103930698537, "phrase": "uci"}, {"score": 0.0023437863565921053, "phrase": "uncertainty_sampling"}, {"score": 0.002241171326888997, "phrase": "active_learning_methods"}], "paper_keywords": ["Training data selection", " Semi-supervised active learning", " Skewed data", " Imbalanced data", " Machine learning"], "paper_abstract": "We consider the problem of generating balanced training samples from an unlabeled data set with an unknown class distribution. While random sampling works well when the data are balanced, it is very ineffective for unbalanced data. Other approaches, such as active learning and cost-sensitive learning, are also suboptimal as they are classifier-dependent and require misclassification costs and labeled samples, respectively. We propose a new strategy for generating training samples, which is independent of the underlying class distribution of the data and the classifier that will be trained using the labeled data. Our methods are iterative and can be seen as variants of active learning, where we use semi-supervised clustering at each iteration to perform biased sampling from the clusters. We provide several strategies to estimate the underlying class distributions in the clusters and to increase the balancedness in the training samples. Experiments with both highly skewed and balanced data from the UCI repository and a private data set show that our algorithm produces much more balanced samples than random sampling or uncertainty sampling. Further, our sampling strategy is substantially more efficient than active learning methods. The experiments also validate that, with more balanced training data, classifiers trained with our samples outperform classifiers trained with random sampling or active learning.", "paper_title": "PAKDD'12 best paper: generating balanced classifier-independent training samples from unlabeled data", "paper_id": "WOS:000344743100012"}