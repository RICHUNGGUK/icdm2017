{"auto_keywords": [{"score": 0.0442768880333846, "phrase": "runtime_verification"}, {"score": 0.010612387000973441, "phrase": "collaborative_runtime_verification"}, {"score": 0.004722038375317162, "phrase": "pre-deployment_test_coverage"}, {"score": 0.004594951819987416, "phrase": "large_applications"}, {"score": 0.004367898947304223, "phrase": "application's_deployment"}, {"score": 0.004103728794623367, "phrase": "unexpected_situations"}, {"score": 0.004024485331377682, "phrase": "prohibitive_performance_cost"}, {"score": 0.003993216345115755, "phrase": "runtime_monitors"}, {"score": 0.003931402465972151, "phrase": "deployed_code"}, {"score": 0.003580032420161922, "phrase": "multiple_users"}, {"score": 0.0035383712891119937, "phrase": "multiple_runs"}, {"score": 0.0034564928013639125, "phrase": "partially_instrumented_program"}, {"score": 0.0033633514001658086, "phrase": "instrumentation_overhead"}, {"score": 0.0032094634756436595, "phrase": "specification_formalism"}, {"score": 0.0031351720217878917, "phrase": "runtime_verification_properties"}, {"score": 0.0031107911390188055, "phrase": "regular_expressions"}, {"score": 0.0030865992688177005, "phrase": "free_variables"}, {"score": 0.0030506626796257077, "phrase": "dynamic_execution_trace"}, {"score": 0.0028436364707396613, "phrase": "different_copies"}, {"score": 0.0027886573969044042, "phrase": "different_program_points"}, {"score": 0.0027347383772384102, "phrase": "temporal_partitioning"}, {"score": 0.002579140290642792, "phrase": "relative_impact"}, {"score": 0.0025292620341476283, "phrase": "user's_runtime"}, {"score": 0.0024803459795996116, "phrase": "partitioning_technique"}, {"score": 0.002385326947545194, "phrase": "significant_instrumentation_overhead"}, {"score": 0.0022939396079753463, "phrase": "runtime_overhead"}, {"score": 0.0022583704173318123, "phrase": "particular_benchmark_copy"}, {"score": 0.0021049977753042253, "phrase": "'pay_as_you_go'_basis"}], "paper_keywords": ["Runtime monitoring", " verification", " randomization", " whole-program analysis", " aspect-oriented programming"], "paper_abstract": "Perfect pre-deployment test coverage is notoriously difficult to achieve for large applications. Given enough end users, however, many more test cases will be encountered during an application's deployment than during testing. The use of runtime verification after deployment would enable developers to detect unexpected situations. Unfortunately, the prohibitive performance cost of runtime monitors prevents their use in deployed code. In this work, we study the feasibility of collaborative runtime verification, a verification approach which can distribute the burden of runtime verification among multiple users and over multiple runs. Each user executes a partially instrumented program and therefore suffers only a fraction of the instrumentation overhead. We focus on runtime verification using tracematches. Tracematches are a specification formalism that allows users to specify runtime verification properties via regular expressions with free variables over the dynamic execution trace. We propose two techniques for soundly partitioning the instrumentation required for tracematches: spatial partitioning, where different copies of a program monitor different program points for violations, and temporal partitioning, where monitoring is switched on and off over time. We evaluate the relative impact of partitioning on a user's runtime overhead by applying each partitioning technique to a collection of benchmarks that would otherwise incur significant instrumentation overhead. Our results show that spatial partitioning almost completely eliminates runtime overhead (for any particular benchmark copy) on many of our test cases, and that temporal partitioning scales well and provides runtime verification on a 'pay as you go' basis.", "paper_title": "Collaborative Runtime Verification with Tracematches", "paper_id": "WOS:000279004000004"}