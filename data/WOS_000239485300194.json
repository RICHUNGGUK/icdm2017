{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "analogue_neural_network_chip"}, {"score": 0.004165105357908494, "phrase": "neural_network_hardware"}, {"score": 0.003070996252787868, "phrase": "random_weight_change"}, {"score": 0.0029830992938695007, "phrase": "simulated_annealing_algorithms"}, {"score": 0.0027741761880779535, "phrase": "prwc_algorithm"}, {"score": 0.002469830206270585, "phrase": "multi-dimensional_function_approximations"}, {"score": 0.0021987994275190314, "phrase": "training_strategy"}, {"score": 0.0021049977753042253, "phrase": "experiment_results"}], "paper_keywords": [""], "paper_abstract": "In this paper we present the results of neural network hardware in-the-loop training for an analogue Local Cluster Neural Network (LCNN) chip. We use a Probabilistic Random Weight Change (PRWC) algorithm that is a combination of the random weight change and simulated annealing algorithms. We applied the PRWC algorithm to in-the-loop training for multi-dimensional function approximations and for predictions. We discuss the training strategy and the experiment results.", "paper_title": "Hardware in-the-loop training of analogue neural network chip", "paper_id": "WOS:000239485300194"}