{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "scalable_model-based_testing"}, {"score": 0.004619356874848538, "phrase": "modern_software_systems"}, {"score": 0.00446004569562802, "phrase": "model-based_testing"}, {"score": 0.004361526027730043, "phrase": "systematic_and_automated_test_case_generation_technique"}, {"score": 0.004251582719171643, "phrase": "industrial-scale_systems"}, {"score": 0.004184274042752558, "phrase": "commercial_tools"}, {"score": 0.004078780515171644, "phrase": "open_issue"}, {"score": 0.004052823656906696, "phrase": "large_systems"}, {"score": 0.003826492478418294, "phrase": "industrial_contexts"}, {"score": 0.003777932022044434, "phrase": "standard_coverage_criteria"}, {"score": 0.0037419150096899127, "phrase": "resulting_test_suites"}, {"score": 0.0037062400890170064, "phrase": "mbt_techniques"}, {"score": 0.003566897271386661, "phrase": "system_level_testing"}, {"score": 0.003544186382527181, "phrase": "real_deployment_platforms"}, {"score": 0.0035216195857272403, "phrase": "network_facilities"}, {"score": 0.003465827053421054, "phrase": "scalable_mbt_technique"}, {"score": 0.003367611042980526, "phrase": "generated_test_suites"}, {"score": 0.0032826392745833872, "phrase": "resource_and_time_constraints"}, {"score": 0.003169281681417552, "phrase": "generated_test_suite"}, {"score": 0.002954140458190344, "phrase": "revealing_power"}, {"score": 0.0029259540174253426, "phrase": "original_test_suite"}, {"score": 0.0028980357312095835, "phrase": "maximum_extent"}, {"score": 0.0027535633837592597, "phrase": "similarity-based_test_case_selection_techniques"}, {"score": 0.0027012576751290433, "phrase": "state_machines"}, {"score": 0.002599600404892265, "phrase": "best_similarity-based_selection_technique"}, {"score": 0.002438581238635582, "phrase": "embedded_systems"}, {"score": 0.002415302004206426, "phrase": "significant_benefits"}, {"score": 0.0023922444655593046, "phrase": "large_improvement"}, {"score": 0.002346786090713685, "phrase": "similarity-based_approach"}, {"score": 0.00221551716210208, "phrase": "failure_rate"}, {"score": 0.00213893083537587, "phrase": "optimal_tradeoffs"}, {"score": 0.0021049977753042253, "phrase": "test_cases"}], "paper_keywords": ["Verification", " Test case selection", " test case minimization", " model-based testing", " similarity function", " search-based software engineering"], "paper_abstract": "The increase in size and complexity of modern software systems requires scalable, systematic, and automated testing approaches. Model-based testing (MBT), as a systematic and automated test case generation technique, is being successfully applied to verify industrial-scale systems and is supported by commercial tools. However, scalability is still an open issue for large systems, as in practice there are limits to the amount of testing that can be performed in industrial contexts. Even with standard coverage criteria, the resulting test suites generated by MBT techniques can be very large and expensive to execute, especially for system level testing on real deployment platforms and network facilities. Therefore, a scalable MBT technique should be flexible regarding the size of the generated test suites and should be easily accommodated to fit resource and time constraints. Our approach is to select a subset of the generated test suite in such a way that it can be realistically executed and analyzed within the time and resource constraints, while preserving the fault revealing power of the original test suite to a maximum extent. In this article, to address this problem, we introduce a family of similarity-based test case selection techniques for test suites generated from state machines. We evaluate 320 different similarity-based selection techniques and then compare the effectiveness of the best similarity-based selection technique with other common selection techniques in the literature. The results based on two industrial case studies, in the domain of embedded systems, show significant benefits and a large improvement in performance when using a similarity-based approach. We complement these analyses with further studies on the scalability of the technique and the effects of failure rate on its effectiveness. We also propose a method to identify optimal tradeoffs between the number of test cases to run and fault detection.", "paper_title": "Achieving Scalable Model-Based Testing Through Test Case Diversity", "paper_id": "WOS:000330483700006"}