{"auto_keywords": [{"score": 0.048868122179027106, "phrase": "action_models"}, {"score": 0.020221611659197065, "phrase": "lamp"}, {"score": 0.01226449094255522, "phrase": "logical_implications"}, {"score": 0.007740489563401452, "phrase": "complex_action_models"}, {"score": 0.004853047142218282, "phrase": "candidate_formulas"}, {"score": 0.004723322467153553, "phrase": "automated_planning"}, {"score": 0.0038600230206554792, "phrase": "simple_action_models"}, {"score": 0.003714368305523811, "phrase": "real_world"}, {"score": 0.003631945391344252, "phrase": "universal_and_existential_quantifiers"}, {"score": 0.003494866798828308, "phrase": "underlying_mechanisms"}, {"score": 0.0032777653153451265, "phrase": "novel_algorithm"}, {"score": 0.003103833117910855, "phrase": "observed_plan"}, {"score": 0.002958021635132416, "phrase": "markov_logic_network"}, {"score": 0.0028463059289874637, "phrase": "selected_subset"}, {"score": 0.0027830917623582903, "phrase": "learned_action_models"}, {"score": 0.0027125596072406525, "phrase": "domain_experts"}, {"score": 0.0026693851900137953, "phrase": "final_models"}, {"score": 0.002495411946660959, "phrase": "human_effort"}, {"score": 0.0024011255612605776, "phrase": "user_study"}, {"score": 0.0023327506323251074, "phrase": "real-world_application_domain"}, {"score": 0.002259054486157494, "phrase": "software_requirements"}, {"score": 0.002166711569953301, "phrase": "real-world_knowledge"}, {"score": 0.0021049997816464257, "phrase": "elsevier"}], "paper_keywords": ["Action model learning", " Machine learning", " Knowledge engineering", " Automated planning"], "paper_abstract": "Automated planning requires action models described using languages such as the Planning Domain Definition Language (PDDL) as input, but building action models from scratch is a very difficult and time-consuming task, even for experts. This is because it is difficult to formally describe all conditions and changes, reflected in the preconditions and effects of action models. In the past, there have been algorithms that can automatically learn simple action models from plan traces. However, there are many cases in the real world where we need more complicated expressions based on universal and existential quantifiers, as well as logical implications in action models to precisely describe the underlying mechanisms of the actions. Such complex action models cannot be learned using many previous algorithms. In this article, we present a novel algorithm called LAMP (Learning Action Models from Plan traces), to learn action models with quantifiers and logical implications from a set of observed plan traces with only partially observed intermediate state information. The LAMP algorithm generates candidate formulas that are passed to a Markov Logic Network (MLN) for selecting the most likely subsets of candidate formulas. The selected subset of formulas is then transformed into learned action models, which can then be tweaked by domain experts to arrive at the final models. We evaluate our approach in four planning domains to demonstrate that LAMP is effective in learning complex action models. We also analyze the human effort saved by using LAMP in helping to create action models through a user study. Finally, we apply LAMP to a real-world application domain for software requirement engineering to help the engineers acquire software requirements and show that LAMP can indeed help experts a great deal in real-world knowledge-engineering applications. (C) 2010 Elsevier By. All rights reserved.", "paper_title": "Learning complex action models with quantifiers and logical implications", "paper_id": "WOS:000284667900006"}