{"auto_keywords": [{"score": 0.038826374424210316, "phrase": "automated_tools"}, {"score": 0.031901763874956926, "phrase": "research_questions"}, {"score": 0.00481495049065317, "phrase": "multiple_cost_estimation_methods"}, {"score": 0.0047701277915006, "phrase": "automated_visualization_toolkit"}, {"score": 0.004667149874736771, "phrase": "accurate_predictions"}, {"score": 0.004290262018446916, "phrase": "wide_variety"}, {"score": 0.004263581204982932, "phrase": "cost_estimation_methods"}, {"score": 0.004145547550709817, "phrase": "different_measures"}, {"score": 0.004081385289516914, "phrase": "new_problems"}, {"score": 0.0040307683311441534, "phrase": "inconsistent_findings"}, {"score": 0.003993216345115755, "phrase": "conclusion_instability"}, {"score": 0.003798746478986171, "phrase": "specific_dataset"}, {"score": 0.0037516215763875225, "phrase": "well-established_statistical_frameworks"}, {"score": 0.0036137129449624727, "phrase": "comprehensive_experimentation"}, {"score": 0.0035912243639260846, "phrase": "comparison_process"}, {"score": 0.0035356111195810483, "phrase": "thorough_study"}, {"score": 0.0035026559604409125, "phrase": "cost_estimation_errors"}, {"score": 0.0033216097307700175, "phrase": "statistical_comparison"}, {"score": 0.0031994574580544, "phrase": "automated_tool"}, {"score": 0.0031302806539556145, "phrase": "intelligent_decision-making"}, {"score": 0.0028951712636442906, "phrase": "graphical_user_interface_statistical_toolkit"}, {"score": 0.0027799596509593166, "phrase": "simple_data_matrix"}, {"score": 0.002745438358145758, "phrase": "multiple_models"}, {"score": 0.002686051638007268, "phrase": "graphical_tools"}, {"score": 0.002669320541871186, "phrase": "statistical_hypothesis_tests"}, {"score": 0.0025710943379540175, "phrase": "appropriate_model"}, {"score": 0.002507621527279442, "phrase": "prediction_errors"}, {"score": 0.0024842242921857705, "phrase": "proposed_framework"}, {"score": 0.002430474136314913, "phrase": "prediction_performance"}, {"score": 0.002415331146563814, "phrase": "different_models"}, {"score": 0.0023927929565329873, "phrase": "systematic_examination"}, {"score": 0.0023778841785229835, "phrase": "candidate_models"}, {"score": 0.0022903576812801432, "phrase": "final_decision"}, {"score": 0.002261939142879624, "phrase": "structured"}, {"score": 0.0022198795731382137, "phrase": "statrec"}, {"score": 0.0021448505687807796, "phrase": "cost_estimation_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Software Cost Estimation", " Prediction models", " Graphical comparison", " REC curves", " Automated tools"], "paper_abstract": "Context: The importance of accurate predictions in Software Cost Estimation and the related challenging research problems, led to the introduction of a plethora of methodologies in literature. However, the wide variety of cost estimation methods, the techniques for improving them and the different measures of accuracy have caused new problems such as the inconsistent findings and the conclusion instability. Today, there is a confusion regarding the choice of the most appropriate method for a specific dataset and therefore a need for well-established statistical frameworks as well as for automated tools that will reinforce and lead a comprehensive experimentation and comparison process, based on the thorough study of the cost estimation errors. Objective: The purpose of this paper is to present a framework for visualization and statistical comparison of the errors of several cost estimation methods. It is based on an automated tool which can facilitate strategies for an intelligent decision-making. Method: A systematic procedure comprised of a series of steps corresponding to research questions is proposed. For each of the steps, StatREC, a Graphical User Interface statistical toolkit is utilized. StatREC was designed and developed to take as input a simple data matrix of predictions by multiple models and to provide a variety of graphical tools and statistical hypothesis tests for aiding the users to answer the questions and choose the appropriate model themselves. Results: The study of prediction errors by the proposed framework provides insight of several aspects related to prediction performance of different models. The systematic examination of candidate models by a series of research questions supports the user to make the final decision. Conclusion: Structured procedures based on automated tools like StatREC can efficiently be used for studying the error and comparing cost estimation models. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A framework for comparing multiple cost estimation methods using an automated visualization toolkit", "paper_id": "WOS:000345947500018"}