{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "map-reduce_data_distribution"}, {"score": 0.004448169552315403, "phrase": "map-reduce_paradigm"}, {"score": 0.004156012879026324, "phrase": "simple_and_feasible_way"}, {"score": 0.003927203683176278, "phrase": "large_data_sets"}, {"score": 0.0037532257703888315, "phrase": "cluster_systems"}, {"score": 0.0033893426032054366, "phrase": "regular_data_distribution_patterns"}, {"score": 0.0032760377953971248, "phrase": "appropriate_use"}, {"score": 0.0030606302942851027, "phrase": "good_scalability"}, {"score": 0.0029249294679606656, "phrase": "map-reduce_applications"}, {"score": 0.0027017308406240563, "phrase": "regular_intermediate_data_generation-consumption_patterns"}, {"score": 0.0023848164282879885, "phrase": "data_distribution_patterns"}, {"score": 0.002305014991156598, "phrase": "current_map-reduce_read_mapping_bioinformatics_applications"}, {"score": 0.002202742267484358, "phrase": "data_decomposition_principles"}], "paper_keywords": ["Bioinformatics", " Read mapping", " Map reduce", " Scalability"], "paper_abstract": "The map-reduce paradigm has shown to be a simple and feasible way of filtering and analyzing large data sets in cloud and cluster systems. Algorithms designed for the paradigm must implement regular data distribution patterns so that appropriate use of resources is ensured. Good scalability and performance on Map-Reduce applications greatly depend on the design of regular intermediate data generation-consumption patterns at the map and reduce phases. We describe the data distribution patterns found in current Map-Reduce read mapping bioinformatics applications and show some data decomposition principles to greatly improve their scalability and performance.", "paper_title": "Analysis and improvement of map-reduce data distribution in read mapping applications", "paper_id": "WOS:000310428700011"}