{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "state_representations"}, {"score": 0.004764859786310636, "phrase": "robotic_priors"}, {"score": 0.0047152877145889656, "phrase": "robot_learning"}, {"score": 0.004522080178250592, "phrase": "appropriate_state_representations"}, {"score": 0.004405348628112645, "phrase": "robotics-specific_approach"}, {"score": 0.004115697805448384, "phrase": "physical_world"}, {"score": 0.0040094142308666975, "phrase": "representation_learning"}, {"score": 0.003069867656852932, "phrase": "learning_task"}, {"score": 0.0029905104479072482, "phrase": "prior_knowledge"}, {"score": 0.002867771524071872, "phrase": "physical_world_robotic_priors"}, {"score": 0.002808298910480358, "phrase": "five_robotic_priors"}, {"score": 0.0026649432435828842, "phrase": "pertinent_state_representations"}, {"score": 0.0025288869172313674, "phrase": "simulated_and_real_robotic_experiments"}, {"score": 0.002387214876538434, "phrase": "task-relevant_state_representations"}, {"score": 0.002362320344521919, "phrase": "high-dimensional_observations"}, {"score": 0.0022772115643656153, "phrase": "task-irrelevant_distractions"}, {"score": 0.0021049977753042253, "phrase": "reinforcement_learning"}], "paper_keywords": ["Robot learning", " Reinforcement learning", " Representation learning", " Prior knowledge"], "paper_abstract": "Robot learning is critically enabled by the availability of appropriate state representations. We propose a robotics-specific approach to learning such state representations. As robots accomplish tasks by interacting with the physical world, we can facilitate representation learning by considering the structure imposed by physics; this structure is reflected in the changes that occur in the world and in the way a robot can effect them. By exploiting this structure in learning, robots can obtain state representations consistent with the aspects of physics relevant to the learning task. We name this prior knowledge about the structure of interactions with the physical world robotic priors. We identify five robotic priors and explain how they can be used to learn pertinent state representations. We demonstrate the effectiveness of this approach in simulated and real robotic experiments with distracting moving objects. We show that our method extracts task-relevant state representations from high-dimensional observations, even in the presence of task-irrelevant distractions. We also show that the state representations learned by our method greatly improve generalization in reinforcement learning.", "paper_title": "Learning state representations with robotic priors", "paper_id": "WOS:000361459500012"}