{"auto_keywords": [{"score": 0.037821806585904484, "phrase": "adaptive_multi-core_architectures"}, {"score": 0.00481495049065317, "phrase": "task_scheduling"}, {"score": 0.004771196027464407, "phrase": "adaptive_multi-core"}, {"score": 0.004579147045265106, "phrase": "general-purpose_computing"}, {"score": 0.004516856326107826, "phrase": "embedded_domain"}, {"score": 0.004455409162867219, "phrase": "current_technology_trends"}, {"score": 0.004335000368745273, "phrase": "on-chip_cores"}, {"score": 0.004085115444878828, "phrase": "thermal_constraints"}, {"score": 0.0040479661688863884, "phrase": "increasing_number"}, {"score": 0.0040111533608228195, "phrase": "simple_cores"}, {"score": 0.003974673997871831, "phrase": "parallel_applications"}, {"score": 0.003920573616298175, "phrase": "abundant_thread-level_parallelism"}, {"score": 0.003814563533445401, "phrase": "sequential_fragments"}, {"score": 0.0037626342268042997, "phrase": "poor_exploitation"}, {"score": 0.0037284065559949064, "phrase": "instruction-level_parallelism"}, {"score": 0.0036441884295335502, "phrase": "recent_research"}, {"score": 0.00349734405943853, "phrase": "simple_physical_cores"}, {"score": 0.003371773890338284, "phrase": "sequential_code"}, {"score": 0.003265608603091855, "phrase": "ilp"}, {"score": 0.0032358711888153227, "phrase": "tlp."}, {"score": 0.0030771609361092164, "phrase": "performance_potential"}, {"score": 0.0029128614098881253, "phrase": "adaptive_multi-cores"}, {"score": 0.0027073229284666294, "phrase": "adaptive_multi-core_platform"}, {"score": 0.0026461080202599694, "phrase": "adaptive_architectures"}, {"score": 0.0026220103561723066, "phrase": "challenging_resource_allocation_problems"}, {"score": 0.0025862736445290088, "phrase": "existing_schedulers"}, {"score": 0.0025162511343171, "phrase": "online_schedulers"}, {"score": 0.0023386327847292805, "phrase": "overall_makespan"}, {"score": 0.002275299774554847, "phrase": "realistic_adaptive_multi-core_architecture"}, {"score": 0.0021243539405631866, "phrase": "static_symmetric"}, {"score": 0.0021049977753042253, "phrase": "asymmetric_multi-core_architectures"}], "paper_keywords": ["Scheduling", " adaptive multi-cores", " dynamic heterogeneous multi-core", " ILP", " TLP", " malleable and moldable tasks"], "paper_abstract": "Multi-cores have become ubiquitous both in the general-purpose computing and the embedded domain. The current technology trends show that the number of on-chip cores is rapidly increasing, while their complexity is decreasing due to power and thermal constraints. Increasing number of simple cores enable parallel applications benefit from abundant thread-level parallelism (TLP), while sequential fragments suffer from poor exploitation of instruction-level parallelism (ILP). Recent research has proposed adaptive multi-core architectures that are capable of coalescing simple physical cores to create more complex virtual cores so as to accelerate sequential code. Such adaptive architectures can seamlessly exploit both ILP and TLP. The goal of this paper is to quantitatively characterize the performance potential of adaptive multi-core architectures. Previous research have primarily focused on only sequential workload on adaptive multi-cores. We address a more realistic scenario where parallel and sequential applications co-exist on an adaptive multi-core platform. Scheduling tasks on adaptive architectures reveal challenging resource allocation problems for the existing schedulers. We construct offline and online schedulers that intelligently reconfigure and allocate the cores to the applications so as to minimize the overall makespan under the constraints of a realistic adaptive multi-core architecture. Experimental results reveal that adaptive multi-core architectures can substantially decrease the makespan compared to both static symmetric and asymmetric multi-core architectures.", "paper_title": "Task Scheduling on Adaptive Multi-Core", "paper_id": "WOS:000343886800017"}