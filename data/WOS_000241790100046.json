{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "stochastic_context"}, {"score": 0.004579780586951551, "phrase": "variational_bayes"}, {"score": 0.004466519142879166, "phrase": "variational_bayesian_learning"}, {"score": 0.004248294537944227, "phrase": "approximation_method"}, {"score": 0.004143196873246147, "phrase": "bayesian_learning"}, {"score": 0.003795335309109018, "phrase": "experimental_good_performance"}, {"score": 0.0031845067058084613, "phrase": "variational_bayesian_stochastic_context_free_grammar"}, {"score": 0.003028727936200845, "phrase": "true_distribution"}, {"score": 0.002447101794397243, "phrase": "prior_conditions"}, {"score": 0.0023566987138026285, "phrase": "free_energy"}, {"score": 0.0022133711375320244, "phrase": "identifiable_models"}, {"score": 0.0021049977753042253, "phrase": "redundant_non-terminals"}], "paper_keywords": [""], "paper_abstract": "Variational Bayesian learning is proposed for approximation method of Bayesian learning. In spite of efficiency and experimental good performance, their mathematical property has not yet been clarified. In this paper we analyze variational Bayesian Stochastic Context Free Grammar which includes the true distribution thus the model is non-identifiable. We derive their asymptotic free energy. It is shown that in some prior conditions, the free energy is much smaller than identifiable models and satisfies eliminating redundant non-terminals.", "paper_title": "Free energy of stochastic context free grammar on variational Bayes", "paper_id": "WOS:000241790100046"}