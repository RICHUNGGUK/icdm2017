{"auto_keywords": [{"score": 0.04966008989090485, "phrase": "adaptive_ensembles"}, {"score": 0.04107868567004354, "phrase": "facial_models"}, {"score": 0.034510927288868586, "phrase": "high_level"}, {"score": 0.00481495049065317, "phrase": "reference_data"}, {"score": 0.0046079260641779755, "phrase": "video_surveillance"}, {"score": 0.004238682850598745, "phrase": "video_cameras"}, {"score": 0.004146510711518748, "phrase": "face_recognition"}, {"score": 0.004003169429008801, "phrase": "limited_spatial_and_temporal_constraints"}, {"score": 0.003780692127133743, "phrase": "limited_number"}, {"score": 0.003747575730190958, "phrase": "representative_reference_samples"}, {"score": 0.0036660436272785476, "phrase": "specific_conditions"}, {"score": 0.0036020923276404403, "phrase": "facial_trajectories"}, {"score": 0.00355485940716082, "phrase": "new_reference_samples"}, {"score": 0.0034168317227203206, "phrase": "self-updating_process"}, {"score": 0.00308788133472785, "phrase": "robust_modelling"}, {"score": 0.00304737045343781, "phrase": "individual's_facial_appearance"}, {"score": 0.0030206579994328975, "phrase": "reference_data_samples"}, {"score": 0.0028276174348291923, "phrase": "memory_management_strategy"}, {"score": 0.002646880721119838, "phrase": "adaptive_individual-specific_ensembles"}, {"score": 0.002499590390751339, "phrase": "new_and_previously-stored_samples"}, {"score": 0.0024236964502593254, "phrase": "highest_kl_divergence"}, {"score": 0.0023604768913655463, "phrase": "future_adaptations"}, {"score": 0.002288797099841088, "phrase": "reference_classifiers"}, {"score": 0.0022192891418394514, "phrase": "action_data"}, {"score": 0.0021998194157393353, "phrase": "simulation_results"}, {"score": 0.0021613897794439227, "phrase": "proposed_strategy"}, {"score": 0.0021236300589450143, "phrase": "discriminative_samples"}, {"score": 0.0021049977753042253, "phrase": "wolf-like_individuals"}], "paper_keywords": [""], "paper_abstract": "During video surveillance, face re-identification allows recognition and targeting of individuals of interest from faces captured across a network of video cameras. In such applications, face recognition is challenging because faces are captured under limited spatial and temporal constraints. In addition, facial models for recognition are commonly designed using a limited number of representative reference samples from faces captured under specific conditions, regrouped into facial trajectories. Given new reference samples (provided by an operator or through some self-updating process), updating facial models may allow maintenance of a high level of performance over time. Although adaptive ensembles have been successfully applied to robust modelling of an individual's facial appearance, reference data samples from a trajectory must be stored for validation. In this study, a memory management strategy based on Kullback-Leiber (KL) divergence is proposed to rank and select the most relevant validation samples over time in adaptive individual-specific ensembles. When new reference samples become available for an individual, updates to the corresponding ensemble are validated using a mixture of new and previously-stored samples. Only the samples with the highest KL divergence are preserved in memory for future adaptations. This strategy is compared with reference classifiers using videos from the face in action data. Simulation results show that the proposed strategy tends to select discriminative samples from wolf-like individuals for validation. It allows maintenance of a high level of performance, while reducing the number of samples per individual by up to 80%.", "paper_title": "Individual-specific management of reference data in adaptive ensembles for face re-identification", "paper_id": "WOS:000361362400013"}