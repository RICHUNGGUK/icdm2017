{"auto_keywords": [{"score": 0.042294571292837035, "phrase": "scheduling_decisions"}, {"score": 0.03548517282140461, "phrase": "task_models"}, {"score": 0.032576110574299134, "phrase": "scheduling_process"}, {"score": 0.00481495049065317, "phrase": "sophisticated_control"}, {"score": 0.004788504414069974, "phrase": "taems_agents"}, {"score": 0.004762202897268383, "phrase": "open_environments"}, {"score": 0.0045694710501318235, "phrase": "available_resources"}, {"score": 0.004506968388996092, "phrase": "goal_criteria"}, {"score": 0.004218602458288531, "phrase": "resource_constraints"}, {"score": 0.004172360444377281, "phrase": "optimal_markov_decision_process_based_policy"}, {"score": 0.004115267130977746, "phrase": "best_way"}, {"score": 0.00409264825541748, "phrase": "complex_problem"}, {"score": 0.0038518661517315533, "phrase": "soft_real-time"}, {"score": 0.003809628721278519, "phrase": "off-line_policy_computationally"}, {"score": 0.0035953368057880593, "phrase": "design-to-criteria_scheduling"}, {"score": 0.0035657203308982065, "phrase": "soft_real-time_process"}, {"score": 0.003478321590910367, "phrase": "agent's_current_objectives"}, {"score": 0.0034306925765832633, "phrase": "dynamic_goal_criteria"}, {"score": 0.0034024277222012597, "phrase": "real-time_deadlines"}, {"score": 0.0033373756615875517, "phrase": "alternate_ways"}, {"score": 0.00327356326590461, "phrase": "recent_advances"}, {"score": 0.00325555555110395, "phrase": "design-to-criteria_control"}, {"score": 0.0028993944292191433, "phrase": "better_control_decisions"}, {"score": 0.002883439044844259, "phrase": "uncertain_environments"}, {"score": 0.0028127163745564777, "phrase": "heuristic_approach"}, {"score": 0.0027972366418863347, "phrase": "on-line_scheduling"}, {"score": 0.00278184186397901, "phrase": "medium_granularity_tasks"}, {"score": 0.0027061261559800744, "phrase": "optimal_policy"}, {"score": 0.0026912314574352196, "phrase": "heuristically_reasoning"}, {"score": 0.002639740960006001, "phrase": "task_execution"}, {"score": 0.0025678829712650437, "phrase": "post-scheduling_contingency_analysis_step"}, {"score": 0.00241658945942583, "phrase": "added_computational_cost"}, {"score": 0.00235729022949073, "phrase": "uncertainty_representation"}, {"score": 0.0022679195103377124, "phrase": "empirical_examples"}, {"score": 0.0021049977753042253, "phrase": "optimal_controller"}], "paper_keywords": ["intelligent agents", " control", " agent scheduling", " MDPs", " contingency analysis", " uncertainty"], "paper_abstract": "Open environments are characterized by their uncertainty and non-determinism. Agents need to adapt their task processing to available resources, deadlines, the goal criteria specified by the clients as well their current problem solving context in order to survive in these environments. If there were no resource constraints, then an optimal Markov Decision Process based policy would obviously be the best way for complex problem solving agents to make scheduling decisions. However in many agent systems, these scheduling decisions have to be made on-line or in soft real-time, making the off-line policy computationally infeasible in open environments. The hybrid planner/scheduler used to control Task Analysis, Environment Modeling, and Simulation (T AE MS) agents is the Design-to-Criteria (DTC) agent scheduler. Design-to-Criteria scheduling is the soft real-time process of custom building a plan/schedule to meet an agent's current objectives which are expressed as dynamic goal criteria (including real-time deadlines), using task models that describe alternate ways to achieve tasks and subtasks. Recent advances in Design-to-Criteria control include the addition of uncertainty to the T AE MS computational task models analyzed by the scheduler and the incorporation of uncertainty in the scheduling process. As we show, the use of uncertainty in T AE MS and Design-to-Criteria enables agents to make better control decisions in uncertain environments. Design-to-Criteria uses a heuristic approach for on-line scheduling of medium granularity tasks.It approximates the analysis used to generate an optimal policy by heuristically reasoning about the implications of uncertainty in task execution. The addition of uncertainty has also spawned a post-scheduling contingency analysis step for situations in which an agent must produce a result by a given deadline (deadline critical situations) and where the added computational cost is worth the expense. We describe the uncertainty representation in T AE MS and how it improves task models and the scheduling process, and provide empirical examples of reasoning about uncertainty in action. We also evaluate the performance of our heuristic-based approach to agent control using the performance of the policy generated by an optimal controller as the benchmark.", "paper_title": "Modeling uncertainty and its implications to sophisticated control in TAEMS agents", "paper_id": "WOS:000240316500001"}