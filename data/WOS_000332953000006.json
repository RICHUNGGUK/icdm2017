{"auto_keywords": [{"score": 0.02375580606425023, "phrase": "gfr"}, {"score": 0.00481495049065317, "phrase": "online_value_function_approximation"}, {"score": 0.0046069985410261746, "phrase": "real-world_problems"}, {"score": 0.0043527164193299574, "phrase": "appropriate_feature_representations"}, {"score": 0.004298134888203576, "phrase": "representational_expansion_techniques"}, {"score": 0.004217537792708984, "phrase": "linear_approximators"}, {"score": 0.004164644263639545, "phrase": "value_functions"}, {"score": 0.0038124354878360032, "phrase": "low_dimensional_problems"}, {"score": 0.0036018503805251424, "phrase": "greedy_feature_replacement"}, {"score": 0.003338992028053874, "phrase": "value-based_rl_algorithms"}, {"score": 0.003174464741377186, "phrase": "simple_initial_representation"}, {"score": 0.0031148723927633955, "phrase": "feature_representation"}, {"score": 0.00301801991152303, "phrase": "new_feature_dependencies"}, {"score": 0.002905752244360772, "phrase": "current_representation"}, {"score": 0.0028692628457408025, "phrase": "conjunctive_features"}, {"score": 0.002780025943393764, "phrase": "current_features"}, {"score": 0.0027106334164712057, "phrase": "virtual_temporal_difference"}, {"score": 0.002560751416355291, "phrase": "conjunctive_feature"}, {"score": 0.0023887436047824386, "phrase": "correctness_guarantees"}, {"score": 0.0023587312574818208, "phrase": "computational_complexity_analysis"}, {"score": 0.002299830460180699, "phrase": "gfr._experimental_results"}, {"score": 0.0021049977753042253, "phrase": "large-scale_problems"}], "paper_keywords": ["Reinforcement learning", " Function approximation", " Feature dependency", " Online expansion", " Feature replacement"], "paper_abstract": "Reinforcement learning (RL) in real-world problems requires function approximations that depend on selecting the appropriate feature representations. Representational expansion techniques can make linear approximators represent value functions more effectively; however, most of these techniques function well only for low dimensional problems. In this paper, we present the greedy feature replacement (GFR), a novel online expansion technique, for value-based RL algorithms that use binary features. Given a simple initial representation, the feature representation is expanded incrementally. New feature dependencies are added automatically to the current representation and conjunctive features are used to replace current features greedily. The virtual temporal difference (TD) error is recorded for each conjunctive feature to judge whether the replacement can improve the approximation. Correctness guarantees and computational complexity analysis are provided for GFR. Experimental results in two domains show that GFR achieves much faster learning and has the capability to handle large-scale problems.", "paper_title": "Greedy feature replacement for online value function approximation", "paper_id": "WOS:000332953000006"}