{"auto_keywords": [{"score": 0.0399501531664237, "phrase": "wls-svms"}, {"score": 0.01407991447812487, "phrase": "training_dataset"}, {"score": 0.00481495049065317, "phrase": "robust_least_squares"}, {"score": 0.004773904938276846, "phrase": "vector_machine"}, {"score": 0.004613175917207636, "phrase": "least_squares"}, {"score": 0.004573842508130535, "phrase": "vector_machines"}, {"score": 0.004271057999410818, "phrase": "weighted"}, {"score": 0.004216434794603139, "phrase": "support_vector_machines"}, {"score": 0.003988055287053139, "phrase": "different_weights"}, {"score": 0.003954030683259778, "phrase": "different_training_samples"}, {"score": 0.003837205620832367, "phrase": "difficult_task"}, {"score": 0.003692040748097991, "phrase": "training_samples"}, {"score": 0.003359816816853762, "phrase": "novel_robust_ls-svm"}, {"score": 0.003205052842427402, "phrase": "truncated_least_squares_loss_function"}, {"score": 0.002929056388593134, "phrase": "rls-svm"}, {"score": 0.0026538960171433985, "phrase": "iterative_algorithm"}, {"score": 0.002608744950946475, "phrase": "concave-convex_procedure"}, {"score": 0.0025864652511554268, "phrase": "cccp"}, {"score": 0.002542716442471356, "phrase": "newton"}, {"score": 0.00249919111154604, "phrase": "statistical_tests"}, {"score": 0.002467228805628948, "phrase": "experimental_results"}, {"score": 0.0024356742694508662, "phrase": "fourteen_benchmark_regression_datasets"}, {"score": 0.0024148618915672353, "phrase": "ten_benchmark_classification_datasets"}, {"score": 0.0021599099979586946, "phrase": "superior_robustness"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Least squares support vector machines", " Weighted least squares support vector machines", " Robust least squares support vector machine", " Regression", " Classification", " Noise"], "paper_abstract": "Least squares support vector machines (LS-SVMs) are sensitive to outliers or noise in the training dataset. Weighted least squares support vector machines (WLS-SVMs) can partly overcome this shortcoming by assigning different weights to different training samples. However, it is a difficult task for WLS-SVMs to set the weights of the training samples, which greatly influences the robustness of WLS-SVMs. In order to avoid setting weights, in this paper, a novel robust LS-SVM (RLS-SVM) is presented based on the truncated least squares loss function for regression and classification with noise. Based on its equivalent model, we theoretically analyze the reason why the robustness of RLS-SVM is higher than that of LS-SVMs and WLS-SVMs. In order to solve the proposed RLS-SVM, we propose an iterative algorithm based on the concave-convex procedure (CCCP) and the Newton algorithm. The statistical tests of the experimental results conducted on fourteen benchmark regression datasets and ten benchmark classification datasets show that compared with LS-SVMs, WLS-SVMs and iteratively reweighted LS-SVM (IRLS-SVM), the proposed RLS-SVM significantly reduces the effect of the noise in the training dataset and provides superior robustness. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "A robust least squares support vector machine for regression and classification with noise", "paper_id": "WOS:000337775400005"}