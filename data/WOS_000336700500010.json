{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "pseudo_relevance_feedback"}, {"score": 0.004761132425263795, "phrase": "relevance-based_language_models"}, {"score": 0.00462919213721188, "phrase": "relevance_models"}, {"score": 0.004551781491498328, "phrase": "successful_approaches"}, {"score": 0.0043029342321223825, "phrase": "statistical_language_modelling_framework"}, {"score": 0.0041136473765874815, "phrase": "state-of-the-art_retrieval_performance"}, {"score": 0.0036553070575015344, "phrase": "pseudo_relevance_feedback_robustness"}, {"score": 0.0034944094552943, "phrase": "harmful_expansion_terms"}, {"score": 0.003266201217790818, "phrase": "crucial_point"}, {"score": 0.003140004304719746, "phrase": "non-relevant_documents"}, {"score": 0.003087419032091453, "phrase": "pseudo_relevant_set"}, {"score": 0.00293487292076612, "phrase": "original_approach"}, {"score": 0.0026370661343466354, "phrase": "pseudo-relevant_set"}, {"score": 0.0024926348205500715, "phrase": "score_distributions"}, {"score": 0.002450864311898833, "phrase": "initial_retrieval"}, {"score": 0.0023166075278110237, "phrase": "relevant_and_non-relevant_documents"}, {"score": 0.0022270182923887012, "phrase": "important_improvements"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Information Retrieval", " Pseudo Relevance Feedback", " Score distribution", " Pseudo Relevance Feedback set", " Relevance Model"], "paper_abstract": "Relevance-Based Language Models, commonly known as Relevance Models, are successful approaches to explicitly introduce the concept of relevance in the statistical language modelling framework of Information Retrieval. These models achieve state-of-the-art retrieval performance in the Pseudo Relevance Feedback task. It is known that one of the factors that more affect to the Pseudo Relevance Feedback robustness is the selection for some queries of harmful expansion terms. In order to minimise this effect in these methods a crucial point is to reduce the number of non-relevant documents in the pseudo relevant set. In this paper, we propose an original approach to tackle this problem. We try to automatically determine for each query how many documents we should select as pseudo-relevant set. For achieving this objective we will study the score distributions of the initial retrieval and trying to discern in base of their distribution between relevant and non-relevant documents. Evaluation of our proposal showed important improvements in terms of robustness. (c) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Score distributions for Pseudo Relevance Feedback", "paper_id": "WOS:000336700500010"}