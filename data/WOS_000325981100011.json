{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "conditional_information_inequalities"}, {"score": 0.004679812572120008, "phrase": "entropic"}, {"score": 0.004548253531664032, "phrase": "almost_entropic"}, {"score": 0.0042354707960660706, "phrase": "conditional_linear_information_inequalities"}, {"score": 0.004000853888373829, "phrase": "shannon"}, {"score": 0.0035189057079817285, "phrase": "linear_constraints"}, {"score": 0.002923214590192792, "phrase": "unconditional_linear_inequalities"}, {"score": 0.0027218799769229596, "phrase": "conditional_inequalities"}, {"score": 0.0026077803487003, "phrase": "almost_entropic_points"}, {"score": 0.0021049977753042253, "phrase": "kolmogorov_complexity"}], "paper_keywords": ["Almost entropic points", " conditional inequalities", " information inequalities", " Kolmogorov complexity", " non-Shannon-type inequalities"], "paper_abstract": "We study conditional linear information inequalities, i.e., linear inequalities for Shannon entropy that hold for distributions whose joint entropies meet some linear constraints. We prove that some conditional information inequalities cannot be extended to any unconditional linear inequalities. Some of these conditional inequalities hold for almost entropic points, while others do not. We also discuss some counterparts of conditional information inequalities for Kolmogorov complexity.", "paper_title": "Conditional Information Inequalities for Entropic and Almost Entropic Points", "paper_id": "WOS:000325981100011"}