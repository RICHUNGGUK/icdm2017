{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "driven_foveated_video_quality_assessment"}, {"score": 0.004633429997452688, "phrase": "human_visual_system"}, {"score": 0.004574449773348889, "phrase": "visual_stimuli"}, {"score": 0.0041287394089001405, "phrase": "existing_studies"}, {"score": 0.004076157223660074, "phrase": "foveation_based_video_quality_assessment"}, {"score": 0.003947601392882997, "phrase": "static_foveation_mechanism"}, {"score": 0.0037743802306714545, "phrase": "advanced_foveal_imaging_model"}, {"score": 0.0036788184374592706, "phrase": "perceived_representation"}, {"score": 0.0035627492415494216, "phrase": "visual_attention"}, {"score": 0.003494866798828308, "phrase": "foveation_mechanism"}, {"score": 0.003362944428837724, "phrase": "dynamic_foveation_mechanism"}, {"score": 0.003215295260684715, "phrase": "video_fixations"}, {"score": 0.0030938932434437178, "phrase": "essential_functionality"}, {"score": 0.003054450075234415, "phrase": "eye_movement"}, {"score": 0.002958021635132416, "phrase": "advanced_contrast_sensitivity_function"}, {"score": 0.0028463059289874637, "phrase": "driven_foveation_mechanism"}, {"score": 0.0026865721000905235, "phrase": "wavelet-based_distortion_visibility_measure"}, {"score": 0.0026184796288543878, "phrase": "full_reference_attention"}, {"score": 0.0024556852466581527, "phrase": "afviq"}, {"score": 0.0024243586247372087, "phrase": "adequately_perceptual_visual_mechanisms"}, {"score": 0.0023934306706217797, "phrase": "video_quality_assessment"}, {"score": 0.00236289633510808, "phrase": "extensive_evaluation_results"}, {"score": 0.002145942273032774, "phrase": "fixation_prediction_approach"}, {"score": 0.0021049977753042253, "phrase": "quality_metric"}], "paper_keywords": ["Fixation prediction", " foveal imaging model", " video attention model", " video quality assessment", " visual perception"], "paper_abstract": "Contrast sensitivity of the human visual system to visual stimuli can be significantly affected by several mechanisms, e. g., vision foveation and attention. Existing studies on foveation based video quality assessment only take into account static foveation mechanism. This paper first proposes an advanced foveal imaging model to generate the perceived representation of video by integrating visual attention into the foveation mechanism. For accurately simulating the dynamic foveation mechanism, a novel approach to predict video fixations is proposed by mimicking the essential functionality of eye movement. Consequently, an advanced contrast sensitivity function, derived from the attention driven foveation mechanism, is modeled and then integrated into a wavelet-based distortion visibility measure to build a full reference attention driven foveated video quality (AFViQ) metric. AFViQ exploits adequately perceptual visual mechanisms in video quality assessment. Extensive evaluation results with respect to several publicly available eye-tracking and video quality databases demonstrate promising performance of the proposed video attention model, fixation prediction approach, and quality metric.", "paper_title": "Attention Driven Foveated Video Quality Assessment", "paper_id": "WOS:000329195500016"}