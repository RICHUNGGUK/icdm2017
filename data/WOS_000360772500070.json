{"auto_keywords": [{"score": 0.042369356770580104, "phrase": "error_rate"}, {"score": 0.03895321879707142, "phrase": "test_sample"}, {"score": 0.004814989107368919, "phrase": "ocr"}, {"score": 0.004749106104067268, "phrase": "ocr_process"}, {"score": 0.004652016085325825, "phrase": "language_model"}, {"score": 0.004609501561741445, "phrase": "best_transformation"}, {"score": 0.004577869668211548, "phrase": "ocr_hypothesis"}, {"score": 0.0042928648367867835, "phrase": "confidence_value"}, {"score": 0.003997891221012094, "phrase": "widespread_tools"}, {"score": 0.0039796153927276505, "phrase": "roc"}, {"score": 0.003680587852807675, "phrase": "confidence_distribution"}, {"score": 0.0035152829179318596, "phrase": "post-processed_ocr_strings"}, {"score": 0.003459191419478298, "phrase": "particularly_careful_handwriting_styles"}, {"score": 0.003427540517249369, "phrase": "free_styles"}, {"score": 0.003349670229755675, "phrase": "adaptive_method"}, {"score": 0.0033266548137541175, "phrase": "automatic_estimation"}, {"score": 0.0033037970113095577, "phrase": "rejection_threshold"}, {"score": 0.003213920601037463, "phrase": "expected_error_rate"}, {"score": 0.003020510250874471, "phrase": "single_string"}, {"score": 0.00283870598459543, "phrase": "resulting_data"}, {"score": 0.0028191914473630394, "phrase": "proposed_system"}, {"score": 0.002780562786032381, "phrase": "suitable_rejection_threshold"}, {"score": 0.002711109302199029, "phrase": "expected_error"}, {"score": 0.0025892330566358503, "phrase": "erroneously_transcribed_string"}, {"score": 0.0025478802613869895, "phrase": "supervised_ocr_hypotheses"}, {"score": 0.0024956789310376635, "phrase": "cumulative_error"}, {"score": 0.0024899450411323115, "phrase": "vs._cost_curve"}, {"score": 0.0024389277933858054, "phrase": "appropriate_threshold"}, {"score": 0.00241658945942583, "phrase": "user-defined_error_rate"}, {"score": 0.0023400004981080818, "phrase": "different_writing_styles"}, {"score": 0.002286781334850213, "phrase": "original_procedure"}, {"score": 0.0022710523337245337, "phrase": "distorted_strings"}, {"score": 0.0021889694778800682, "phrase": "presented_method"}, {"score": 0.002163930783583212, "phrase": "real_supervised_ocr_hypotheses"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Rejection threshold", " OCR post-processing", " Language models", " Weighted finite-state transducers", " Error vs. cost curve", " Cumulative error vs. cost curve", " OCR error-generation model"], "paper_abstract": "An OCR process is often followed by the application of a language model to find the best transformation of an OCR hypothesis into a string compatible with the constraints of the document, field or item under consideration. The cost of this transformation can be taken as a confidence value and compared to a threshold to decide if a string is accepted as correct or rejected in order to satisfy the need for bounding the error rate of the system. Widespread tools like ROC, precision-recall, or error-reject curves, are commonly used along with fixed thresholding in order to achieve that goal. However, those methodologies fail when a test sample has a confidence distribution that differs from the one of the sample used to train the system, which is a very frequent case in post-processed OCR strings (e.g., string batches showing particularly careful handwriting styles in contrast to free styles). In this paper, we propose an adaptive method for the automatic estimation of the rejection threshold that overcomes this drawback, allowing the operator to define an expected error rate within the set of accepted (non-rejected) strings of a complete batch of documents (as opposed to trying to establish or control the probability of error of a single string), regardless of its confidence distribution. The operator (eXpert) is assumed to know the error rate that can be acceptable to the user of the resulting data. The proposed system transforms that knowledge into a suitable rejection threshold. The approach is based on the estimation of an expected error vs. transformation cost distribution. First, a model predicting the probability of a cost to arise from an erroneously transcribed string is computed from a sample of supervised OCR hypotheses. Then, given a test sample, a cumulative error vs. cost curve is computed and used to automatically set the appropriate threshold that meets the user-defined error rate on the overall sample. The results of experiments on batches coming from different writing styles show very accurate error rate estimations where fixed thresholding clearly fails. An original procedure to generate distorted strings from a given language is also proposed and tested, which allows the use of the presented method in tasks where no real supervised OCR hypotheses are available to train the system. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Batch-adaptive rejection threshold estimation with application to OCR post-processing", "paper_id": "WOS:000360772500070"}