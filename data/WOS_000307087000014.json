{"auto_keywords": [{"score": 0.0475596004207704, "phrase": "global_motion_pattern"}, {"score": 0.004737579882204798, "phrase": "classic_multi-image-based_super-resolution"}, {"score": 0.003879234831701853, "phrase": "highly_accurate_registration"}, {"score": 0.0038375280115736958, "phrase": "sub-pixel_accuracy"}, {"score": 0.0037352048741373816, "phrase": "practical_applications"}, {"score": 0.00355782527287734, "phrase": "real_lr_inputs"}, {"score": 0.0033163269450817716, "phrase": "aforementioned_problems"}, {"score": 0.0032278559855285975, "phrase": "novel_sr_framework"}, {"score": 0.003193129886123359, "phrase": "video_sequence"}, {"score": 0.0028502479839354637, "phrase": "proposed_framework"}, {"score": 0.002789226820897593, "phrase": "explicit_motion_estimation"}, {"score": 0.0026423134393535265, "phrase": "weighted_average"}, {"score": 0.0024761702541879213, "phrase": "input_video_sequence"}, {"score": 0.0024495111090152857, "phrase": "temporal_dimension"}, {"score": 0.002295463032589125, "phrase": "fundamental_experiments"}, {"score": 0.002222102813520549, "phrase": "proposed_sr_framework"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Normalized convolution (NC)", " Motion estimation", " Video super-resolution (SR)"], "paper_abstract": "The classic multi-image-based super-resolution (SR) methods typically take global motion pattern to produce one or multiple high-resolution (HR) versions from a set of low-resolution (LR) images. However, due to the influence of aliasing and noise, it is difficult to obtain highly accurate registration with sub-pixel accuracy. Moreover, in practical applications, the global motion pattern is rarely found in the real LR inputs. In this paper, to surmount or at least reduce the aforementioned problems, we develop a novel SR framework for video sequence by extending the traditional 2-dimentional (2D) normalized convolution (NC) to 3-dimentional (3D) case. In the proposed framework, to bypass explicit motion estimation, we estimate a target pixel by taking a weighted average of pixels from its neighborhood. We further up-scale the input video sequence in temporal dimension based on the extended 3D NC and hence more video frames can be generated. Fundamental experiments demonstrate the effectiveness of the proposed SR framework both quantitatively and perceptually. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Video super-resolution with 3D adaptive normalized convolution", "paper_id": "WOS:000307087000014"}