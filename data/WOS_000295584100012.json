{"auto_keywords": [{"score": 0.04534196037351314, "phrase": "search_direction"}, {"score": 0.009474897078384099, "phrase": "rank_degeneracies"}, {"score": 0.00481495049065317, "phrase": "efficient_revised_simplex_method"}, {"score": 0.004771672073078768, "phrase": "svm_training"}, {"score": 0.004728780808284175, "phrase": "existing_active_set_methods"}, {"score": 0.004602395776895036, "phrase": "support_vector_machine"}, {"score": 0.004167086373747367, "phrase": "infinite_descent_direction"}, {"score": 0.003841610436545169, "phrase": "algorithm_implementation"}, {"score": 0.003309278541665552, "phrase": "revised_simplex_method"}, {"score": 0.003264695125552653, "phrase": "rusin"}, {"score": 0.003023129616910419, "phrase": "simpler_and_more_computationally_efficient_implementation"}, {"score": 0.0028634235895823594, "phrase": "also_the_need"}, {"score": 0.0027993885490232677, "phrase": "solution_methods"}, {"score": 0.0025572160146590623, "phrase": "efficient_method"}, {"score": 0.0024220634963019114, "phrase": "svm-qp"}, {"score": 0.0022836785412390544, "phrase": "nonbound_support_vectors"}, {"score": 0.0021925226977381244, "phrase": "competitive_performance"}, {"score": 0.002162951519368368, "phrase": "proposed_algorithm"}, {"score": 0.0021241414408077895, "phrase": "svmlight"}, {"score": 0.0021049980887991684, "phrase": "libsvm."}], "paper_keywords": ["Active set method", " null space method", " quadratic programming", " revised simplex method", " support vector machine"], "paper_abstract": "Existing active set methods reported in the literature for support vector machine (SVM) training must contend with singularities when solving for the search direction. When a singularity is encountered, an infinite descent direction can be carefully chosen that avoids cycling and allows the algorithm to converge. However, the algorithm implementation is likely to be more complex and less computationally efficient than would otherwise be required for an algorithm that does not have to contend with the singularities. We show that the revised simplex method introduced by Rusin provides a guarantee of nonsingularity when solving for the search direction. This method provides for a simpler and more computationally efficient implementation, as it avoids the need to test for rank degeneracies and also the need to modify factorizations or solution methods based upon those rank degeneracies. In our approach, we take advantage of the guarantee of nonsingularity by implementing an efficient method for solving the search direction and show that our algorithm is competitive with SVM-QP and also that it is a particularly effective when the fraction of nonbound support vectors is large. In addition, we show competitive performance of the proposed algorithm against two popular SVM training algorithms, SVMLight and LIBSVM.", "paper_title": "Efficient Revised Simplex Method for SVM Training", "paper_id": "WOS:000295584100012"}