{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "genetic_algorithms"}, {"score": 0.04896221231267542, "phrase": "decision_trees"}, {"score": 0.004178935413340453, "phrase": "key_tree_quality_parameters"}, {"score": 0.003626626504149897, "phrase": "partially_similar_decision_trees"}, {"score": 0.003459191419478298, "phrase": "instance_indices"}, {"score": 0.002966438503447793, "phrase": "lossless_fashion"}, {"score": 0.0025137856138000014, "phrase": "attractive_property"}, {"score": 0.002455009746748708, "phrase": "lossless_fitness_inheritance"}, {"score": 0.0023694065215394593, "phrase": "divide-and-conquer_nature"}, {"score": 0.0022070310530794097, "phrase": "theoretical_results"}, {"score": 0.0021049977753042253, "phrase": "experimental_evidence"}], "paper_keywords": ["Decision trees", " Genetic algorithms", " Fitness inheritance", " Fitness approximation", " Learning speedup"], "paper_abstract": "When genetic algorithms are used to evolve decision trees, key tree quality parameters can be recursively computed and re-used across generations of partially similar decision trees. Simply storing instance indices at leaves is sufficient for fitness to be piecewise computed in a lossless fashion. We show the derivation of the (substantial) expected speedup on two bounding case problems and trace the attractive property of lossless fitness inheritance to the divide-and-conquer nature of decision trees. The theoretical results are supported by experimental evidence.", "paper_title": "Lossless fitness inheritance in genetic algorithms for decision trees", "paper_id": "WOS:000277013200007"}