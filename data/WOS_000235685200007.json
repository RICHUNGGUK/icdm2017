{"auto_keywords": [{"score": 0.03998275230530837, "phrase": "gang_scheduling"}, {"score": 0.03436832331861641, "phrase": "physical_memory"}, {"score": 0.015405701639645041, "phrase": "cluster_resources"}, {"score": 0.00481495049065317, "phrase": "interface_applications"}, {"score": 0.004749913509007163, "phrase": "time_sharing"}, {"score": 0.004622450915803531, "phrase": "major_issue"}, {"score": 0.004560002169647084, "phrase": "grid_integration"}, {"score": 0.004529093447865156, "phrase": "classical_grid_architecture"}, {"score": 0.004483120978156604, "phrase": "higher-level_scheduler"}, {"score": 0.004437613070853689, "phrase": "non-overlapping_jobs"}, {"score": 0.004392565073466714, "phrase": "independent_batch_schedulers"}, {"score": 0.004117647922204903, "phrase": "expected_number"}, {"score": 0.0040619911719900976, "phrase": "job_heterogeneity"}, {"score": 0.004007083686875716, "phrase": "time_sharing_techniques"}, {"score": 0.003926105480202798, "phrase": "simultaneous_executions"}, {"score": 0.0036428866026996707, "phrase": "operating_system"}, {"score": 0.003357091486708983, "phrase": "previous_work"}, {"score": 0.0033116807159861766, "phrase": "co-scheduling_techniques"}, {"score": 0.0031254169757175257, "phrase": "new_hybrid_sharing_technique"}, {"score": 0.003104201872147936, "phrase": "checkpoint-based_explicit_memory_management"}, {"score": 0.003051790083321992, "phrase": "co-scheduling_parallel_applications"}, {"score": 0.0029798924689472014, "phrase": "memory_capacity"}, {"score": 0.0028703075616629634, "phrase": "related_techniques"}, {"score": 0.002565084553019013, "phrase": "out-of-core_computing"}, {"score": 0.002487612781045517, "phrase": "grid_context"}, {"score": 0.0023636455694730787, "phrase": "heterogeneous_applications"}, {"score": 0.002339601774631419, "phrase": "hybrid_scheduling"}, {"score": 0.0023158019935841235, "phrase": "optimized_version"}, {"score": 0.002292243761395491, "phrase": "paired_scheduling"}, {"score": 0.0022382002476510573, "phrase": "hybrid_solution"}, {"score": 0.0021928902836049363, "phrase": "co-scheduling_technique"}, {"score": 0.0021049977753042253, "phrase": "paired_scheduling_optimization_technique"}], "paper_keywords": ["scheduling", " performance", " message passing interface", " time sharing", " grid", " gang scheduling", " co-scheduling"], "paper_abstract": "Time sharing between cluster resources in a grid is a major issue in cluster and grid integration. Classical grid architecture involves a higher-level scheduler which submits non-overlapping jobs to the independent batch schedulers of each cluster of the grid. The sequentiality induced by this approach does not fit with the expected number of users and job heterogeneity of grids. Time sharing techniques address this issue by allowing simultaneous executions of many applications on the same resources. Co-scheduling and gang scheduling are the two best known techniques for time sharing cluster resources. Co-scheduling relies on the operating system of each node to schedule the processes of every application. Gang scheduling ensures that the same application is scheduled on all nodes simultaneously. Previous work has proven that co-scheduling techniques outperform gang scheduling when physical memory is not exhausted. In this paper, we introduce a new hybrid sharing technique providing checkpoint-based explicit memory management. It consists in co-scheduling parallel applications within a set, until the memory capacity of the node is reached, and using gang scheduling related techniques to switch from one set to another one. We compare experimentally the merits of the three solutions (co-scheduling, gang scheduling, and hybrid scheduling) in the context of out-of-core computing, which is likely to occur in the grid context, where many users share the same resources. Additionally, we address the problem of heterogeneous applications by comparing hybrid scheduling to an optimized version relying on paired scheduling. The experiments show that the hybrid solution is as efficient as the co-scheduling technique when the physical memory is not exhausted, can benefit from the paired scheduling optimization technique when applications are heterogeneous, and is more efficient than gang scheduling and co-scheduling when physical memory is exhausted.", "paper_title": "Hybrid preemptive scheduling of message passing interface applications on grids", "paper_id": "WOS:000235685200007"}