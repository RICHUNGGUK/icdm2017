{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "human_implicit_visual_search_intention"}, {"score": 0.048846087603041044, "phrase": "pupillary_analysis"}, {"score": 0.014485609560573565, "phrase": "eye_movement_patterns"}, {"score": 0.012243956633809231, "phrase": "proposed_model"}, {"score": 0.01193093582206767, "phrase": "task-oriented_visual_search"}, {"score": 0.011476171522529343, "phrase": "task-oriented_visual_search_intent_maintenance"}, {"score": 0.010849383847967728, "phrase": "pupillary_response"}, {"score": 0.01061743236601995, "phrase": "external_factors"}, {"score": 0.009086190791308776, "phrase": "different_intent_conditions"}, {"score": 0.007444179459358499, "phrase": "hierarchical_support_vector_machine"}, {"score": 0.004590052784169268, "phrase": "novel_approach"}, {"score": 0.004244375827831527, "phrase": "pupil_size"}, {"score": 0.00417115038996633, "phrase": "pupil_size_variation"}, {"score": 0.004135010810625326, "phrase": "fixation_length"}, {"score": 0.00367658459781873, "phrase": "task-free_visual_browsing"}, {"score": 0.003535320700255283, "phrase": "task-oriented_visual_search_intent_generation"}, {"score": 0.003459191419478298, "phrase": "task-oriented_visual_search_intent_disappearance"}, {"score": 0.003129509028432954, "phrase": "visual_stimulus"}, {"score": 0.0029701328654852246, "phrase": "robust_baseline_model"}, {"score": 0.002868404184756449, "phrase": "graphical_representation"}, {"score": 0.002831158147480665, "phrase": "measured_parameter_values"}, {"score": 0.002806595775343074, "phrase": "significant_differences"}, {"score": 0.0024842242921857705, "phrase": "different_implicit_intentions-task-free_visual_browsing_intent"}], "paper_keywords": ["Implicit intention detection", " Task-free visual browsing intent", " Task-oriented visual search intent", " Intention recognition", " Human computer interface & interaction", " Pupillary analysis", " Eye tracking", " Pupil dilation"], "paper_abstract": "We propose a novel approach for the identification of human implicit visual search intention based on eye movement patterns and pupillary analysis, in general, as well as pupil size, gradient of pupil size variation, fixation length and fixation count corresponding to areas of interest, and fixation count corresponding to non-areas of interest, in particular. The proposed model identifies human implicit visual search intention as task-free visual browsing or task-oriented visual search. Task-oriented visual search is further identified as task-oriented visual search intent generation, task-oriented visual search intent maintenance, or task-oriented visual search intent disappearance. During a visual search, measurement of the pupillary response is greatly influenced by external factors such the intensity and size of the visual stimulus. To alleviate the effects of external factors, we propose a robust baseline model that can accurately measure the pupillary response. Graphical representation of the measured parameter values shows significant differences among the different intent conditions, which can then be used as features for identification. By using the eye movement patterns and pupillary analysis, we can detect the transitions between different implicit intentions-task-free visual browsing intent to task-oriented visual search intent and task-oriented visual search intent maintenance to task-oriented visual search intent disappearance-using a hierarchical support vector machine. In the proposed model, the hierarchical support vector machine is able to identify the transitions between different intent conditions with greater than 90 % accuracy.", "paper_title": "Identification of human implicit visual search intention based on eye movement and pupillary analysis", "paper_id": "WOS:000342084600002"}