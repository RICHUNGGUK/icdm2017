{"auto_keywords": [{"score": 0.04325124255431723, "phrase": "search_query"}, {"score": 0.015719716506582538, "phrase": "temporal_databases"}, {"score": 0.015335200277381332, "phrase": "k_entities"}, {"score": 0.015167290319680346, "phrase": "temporal_database"}, {"score": 0.014513567195218497, "phrase": "relational_databases"}, {"score": 0.010192904276683568, "phrase": "\"virtual_record"}, {"score": 0.004331868846727089, "phrase": "single_record"}, {"score": 0.003962709690230563, "phrase": "historical_records"}, {"score": 0.0037795163893761027, "phrase": "open_problem"}, {"score": 0.0037480753312398754, "phrase": "main_challenging"}, {"score": 0.00347657813672945, "phrase": "different_time_points"}, {"score": 0.003334309053314909, "phrase": "record_granularity"}, {"score": 0.0031712256091350316, "phrase": "\"virtual_records"}, {"score": 0.0031360786664165093, "phrase": "attribute_values"}, {"score": 0.003066945490483524, "phrase": "different_records"}, {"score": 0.0029660842349637255, "phrase": "novel_evaluation_model"}, {"score": 0.0027974705482714884, "phrase": "maximum_similarity"}, {"score": 0.002474546341064081, "phrase": "dominating_tree_algorithm"}, {"score": 0.002406503256754213, "phrase": "bounding-pruning-refining_strategy"}, {"score": 0.0023599867869259663, "phrase": "greatest_similarities"}, {"score": 0.002333809817752256, "phrase": "extensive_experiments"}, {"score": 0.002314367370568359, "phrase": "real_and_synthetic_datasets"}, {"score": 0.0022950865214535843, "phrase": "encouraging_results"}, {"score": 0.0021766418372878835, "phrase": "proposed_dta"}, {"score": 0.002146499103321978, "phrase": "magnitude_improvement"}, {"score": 0.0021049977753042253, "phrase": "naive_approach"}], "paper_keywords": ["temporal databases", " approximate entity extraction", " bounding-pruning-refining", " n-partite graph"], "paper_abstract": "We study the problem of efficiently extracting K entities, in a temporal database, which are most similar to a given search query. This problem is well studied in relational databases, where each entity is represented as a single record and there exist a variety of methods to define the similarity between a record and the search query. However, in temporal databases, each entity is represented as a sequence of historical records. How to properly define the similarity of each entity in the temporal database still remains an open problem. The main challenging is that, when a user issues a search query for an entity, he or she is prone to mix up information of the same entity at different time points. As a result, methods, which are used in relational databases based on record granularity, cannot work any further. Instead, we regard each entity as a set of \"virtual records\", where attribute values of a \"virtual record\" can be from different records of the same entity. In this paper, we propose a novel evaluation model, based on which the similarity between each \"virtual record\" and the query can be effectively quantified, and the maximum similarity of its \"virtual records\" is taken as the similarity of an entity. For each entity, as the number of its \"virtual records\" is exponentially large, calculating the similarity of the entity is challenging. As a result, we further propose a Dominating Tree Algorithm (DTA), which is based on the bounding-pruning-refining strategy, to efficiently extract K entities with greatest similarities. We conduct extensive experiments on both real and synthetic datasets. The encouraging results show that our model for defining the similarity between each entity and the search query is effective, and the proposed DTA can perform at least two orders of magnitude improvement on the performance comparing with the naive approach.", "paper_title": "Approximate entity extraction in temporal databases", "paper_id": "WOS:000288761200003"}