{"auto_keywords": [{"score": 0.047352961049336624, "phrase": "abstract_domains"}, {"score": 0.00481495049065317, "phrase": "abstract_interpretations"}, {"score": 0.004721893473387288, "phrase": "abstract_interpretation-based_static_analysis"}, {"score": 0.004424441580112395, "phrase": "systematic_guidelines"}, {"score": 0.004338898899247236, "phrase": "abstract_semantic_functions"}, {"score": 0.004227398267369744, "phrase": "concrete_system_behaviors"}, {"score": 0.003986844722309844, "phrase": "abstract_domain"}, {"score": 0.003935267970727097, "phrase": "redundant_information"}, {"score": 0.003859146369720225, "phrase": "specific_purpose"}, {"score": 0.003569050665799723, "phrase": "correctness_kernel"}, {"score": 0.0034999880739789257, "phrase": "abstract_interpretation"}, {"score": 0.0032792555200980783, "phrase": "abstract_values"}, {"score": 0.0031535341431377837, "phrase": "maximal_way"}, {"score": 0.0030924870122337905, "phrase": "exactly_the_same_approximate_behavior"}, {"score": 0.002878556952876824, "phrase": "abstract_model_checking_correctness_kernels"}, {"score": 0.0027501697136375555, "phrase": "abstract_state_space"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": [""], "paper_abstract": "In abstract interpretation-based static analysis, approximation is encoded by abstract domains. They provide systematic guidelines for designing abstract semantic functions that approximate some concrete system behaviors under analysis. It may happen that an abstract domain contains redundant information for the specific purpose of approximating a given concrete semantic function. This paper introduces the notion of correctness kernel of an abstract interpretation, a methodology for simplifying abstract domains, i.e. removing abstract values from them, in a maximal way while retaining exactly the same approximate behavior of the system under analysis. We show that in abstract model checking correctness kernels provide a simplification paradigm of the abstract state space that is guided by examples, meaning that this simplification preserves spuriousness of examples (i.e., abstract paths). In particular, we show how correctness kernels can be integrated with the well-known CEGAR (CounterExample-Guided Abstraction Refinement) methodology. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Correctness kernels of abstract interpretations", "paper_id": "WOS:000339468300009"}