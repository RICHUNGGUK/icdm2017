{"auto_keywords": [{"score": 0.0491799345505193, "phrase": "activity_recognition"}, {"score": 0.00481495049065317, "phrase": "mobile_sensors"}, {"score": 0.00468627326602559, "phrase": "emerging_general_area"}, {"score": 0.004635765943321778, "phrase": "computer_science"}, {"score": 0.004585800466151371, "phrase": "construction_engineering"}, {"score": 0.004536400054785921, "phrase": "cem"}, {"score": 0.0043793594257092805, "phrase": "complex_and_dynamic_nature"}, {"score": 0.004262273304740847, "phrase": "key_activities"}, {"score": 0.004170852889139735, "phrase": "human_crew"}, {"score": 0.0039722339911940205, "phrase": "simulation_modeling"}, {"score": 0.0038242899532391914, "phrase": "input_parameters"}, {"score": 0.003803608030258807, "phrase": "simulation_models"}, {"score": 0.0037119096760649065, "phrase": "activity_durations"}, {"score": 0.003671865026158296, "phrase": "resource_flows"}, {"score": 0.003642114262258148, "phrase": "site_layout"}, {"score": 0.003506422098649799, "phrase": "built-in_smartphone_sensors"}, {"score": 0.003487453200471476, "phrase": "ubiquitous_multi-modal_data_collection"}, {"score": 0.003412594747737725, "phrase": "detailed_construction_equipment_activities"}, {"score": 0.0033302915283097367, "phrase": "simulation_input_modeling"}, {"score": 0.0033032991393331787, "phrase": "case_study"}, {"score": 0.003285425464512383, "phrase": "front-end_loader_activity_recognition"}, {"score": 0.0032148895624688188, "phrase": "action_recognition"}, {"score": 0.0031544100787919828, "phrase": "developed_system"}, {"score": 0.0031203609829058587, "phrase": "designed_methodology"}, {"score": 0.0030616543376177003, "phrase": "collected_data"}, {"score": 0.0030286034168878835, "phrase": "gyroscope_sensors"}, {"score": 0.0029716179574996626, "phrase": "extracted_features"}, {"score": 0.002931569771634119, "phrase": "supervised_machine"}, {"score": 0.002829945165524915, "phrase": "discriminating_features"}, {"score": 0.002799388549023265, "phrase": "sensitivity_analysis"}, {"score": 0.0027842338450514655, "phrase": "data_segmentation_window_size"}, {"score": 0.0025734659461785553, "phrase": "equipment_actions"}, {"score": 0.0025318869445353654, "phrase": "important_factor"}, {"score": 0.0025181767240440417, "phrase": "major_impact"}, {"score": 0.002497750121448195, "phrase": "classification_performance"}, {"score": 0.002398069885234319, "phrase": "classification_output"}, {"score": 0.0023211909152089606, "phrase": "single_activity"}, {"score": 0.002277485549459112, "phrase": "classified_activities"}, {"score": 0.0022651497894502714, "phrase": "computational_efficiency"}, {"score": 0.002246771033171679, "phrase": "end_use"}, {"score": 0.002228541063618486, "phrase": "classification_process"}, {"score": 0.002198485165633691, "phrase": "one's_decision"}, {"score": 0.002174731931803965, "phrase": "optimal_lod"}, {"score": 0.0021570852132316294, "phrase": "equipment_activities"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Construction equipment action recognition", " Smartphone sensors", " Accelerometer", " Data-driven simulation", " Supervised machine learning", " Big data analytics"], "paper_abstract": "Although activity recognition is an emerging general area of research in computer science, its potential in construction engineering and management (CEM) domain has not yet been fully investigated. Due to the complex and dynamic nature of many construction and infrastructure projects, the ability to detect and classify key activities performed in the field by various equipment and human crew can improve the quality and reliability of project decision-making and control. In particular to simulation modeling, process-level knowledge obtained as a result of activity recognition can help verify and update the input parameters of simulation models. Such input parameters include but are not limited to activity durations and precedence, resource flows, and site layout. The goal of this research is to investigate the prospect of using built-in smartphone sensors as ubiquitous multi-modal data collection and transmission nodes in order to detect detailed construction equipment activities which can ultimately contribute to the process of simulation input modeling. A case study of front-end loader activity recognition is presented to describe the methodology for action recognition and evaluate the performance of the developed system. In the designed methodology, certain key features are extracted from the collected data using accelerometer and gyroscope sensors, and a subset of the extracted features is used to train supervised machine learning classifiers. In doing so, several important technical details such as selection of discriminating features to extract, sensitivity analysis of data segmentation window size, and choice of the classifier to be trained are investigated. It is shown that the choice of the level of detail (LoD) in describing equipment actions (classes) is an important factor with major impact on the classification performance. Results also indicate that although decreasing the number of classes generally improves the classification output, considering other factors such as actions to be combined as a single activity, methodologies to extract knowledge from classified activities, computational efficiency, and end use of the classification process may as well influence one's decision in selecting an optimal LoD in describing equipment activities (classes). (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Construction equipment activity recognition for simulation input modeling using mobile sensors and machine learning classifiers", "paper_id": "WOS:000366769500012"}