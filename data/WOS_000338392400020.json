{"auto_keywords": [{"score": 0.046800023565389516, "phrase": "compressed_sensing_problem"}, {"score": 0.030536894057490962, "phrase": "kappa-error_diagram"}, {"score": 0.00481495049065317, "phrase": "efficient_ensemble_learning"}, {"score": 0.004686791459644141, "phrase": "improved_ensemble_learning"}, {"score": 0.004455575231721042, "phrase": "ensemble_learning_methods"}, {"score": 0.0043663006236597975, "phrase": "learned_predictor"}, {"score": 0.00430777589162606, "phrase": "weighted_combination"}, {"score": 0.004278807087784626, "phrase": "multiple_predictive_models"}, {"score": 0.003959288961559545, "phrase": "included_model"}, {"score": 0.0037133478610481994, "phrase": "sparse_solution"}, {"score": 0.0036388906120614012, "phrase": "under-determined_linear_system"}, {"score": 0.003401278997237025, "phrase": "additional_contribution"}, {"score": 0.003299460925313939, "phrase": "new_performance_evaluation_method"}, {"score": 0.00305285084207725, "phrase": "different_weightings"}, {"score": 0.0029614320534324104, "phrase": "total_number"}, {"score": 0.002815093247670994, "phrase": "roulette-wheel_selection_method"}, {"score": 0.002426137929553722, "phrase": "compressed_sensing_ensembles"}, {"score": 0.0023139986108451946, "phrase": "comparison_experiments"}, {"score": 0.002275214783528274, "phrase": "five_state-of-the-art_pruning_methods"}, {"score": 0.0022070310530794097, "phrase": "comparable_or_better_accuracy"}, {"score": 0.002148136905808445, "phrase": "compared_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Ensemble learning", " Classification", " Classifier ensemble", " Sparse reconstruction", " Compressed sensing", " Roulette-wheel selection", " Kappa-error"], "paper_abstract": "This paper presents a method for improved ensemble learning, by treating the optimization of an ensemble of classifiers as a compressed sensing problem. Ensemble learning methods improve the performance of a learned predictor by integrating a weighted combination of multiple predictive models. Ideally, the number of models needed in the ensemble should be minimized, while optimizing the weights associated with each included model. We solve this problem by treating it as an example of the compressed sensing problem, in which a sparse solution must be reconstructed from an under-determined linear system. Compressed sensing techniques are then employed to find an ensemble which is both small and effective. An additional contribution of this paper, is to present a new performance evaluation method (a new pairwise diversity measurement) called the roulette-wheel kappa-error. This method takes into account the different weightings of the classifiers, and also reduces the total number of pairs of classifiers needed in the kappa-error diagram, by selecting pairs through a roulette-wheel selection method according to the weightings of the classifiers. This approach can greatly improve the clarity and informativeness of the kappa-error diagram, especially when the number of classifiers in the ensemble is large. We use 25 different public data sets to evaluate and compare the performance of compressed sensing ensembles using four different sparse reconstruction algorithms, combined with two different classifier learning algorithms and two different training data manipulation techniques. We also give the comparison experiments of our method against another five state-of-the-art pruning methods. These experiments show that our method produces comparable or better accuracy, while being significantly faster than the compared methods. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "A compressed sensing approach for efficient ensemble learning", "paper_id": "WOS:000338392400020"}