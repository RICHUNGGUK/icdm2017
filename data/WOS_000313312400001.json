{"auto_keywords": [{"score": 0.010035002683568254, "phrase": "randomly_stopped_sums"}, {"score": 0.0093052580826016, "phrase": "worst_case_efficiency"}, {"score": 0.00481495049065317, "phrase": "monte_carlo"}, {"score": 0.004774530554776604, "phrase": "fixed_relative_precision"}, {"score": 0.004721162131188487, "phrase": "monte_carlo_algorithms"}, {"score": 0.004668387447312965, "phrase": "integral_theta"}, {"score": 0.004642220710209137, "phrase": "integral_fd_pi"}, {"score": 0.004388450908826472, "phrase": "sequence_x-n"}, {"score": 0.004363846362238565, "phrase": "uniformly_bounded_random_variables"}, {"score": 0.003910595307634916, "phrase": "relative_precision_epsilon"}, {"score": 0.003749033935324126, "phrase": "cap_-_theta_vertical_bar"}, {"score": 0.0036245864938417964, "phrase": "problem_instances"}, {"score": 0.0035339597999254064, "phrase": "sample_size_n"}, {"score": 0.0033405704229694656, "phrase": "expected_number"}, {"score": 0.003131178497790961, "phrase": "main_tool"}, {"score": 0.0030787405733989615, "phrase": "new_exponential_inequality"}, {"score": 0.0029764767329116875, "phrase": "worst_case_complexity"}, {"score": 0.002727700630869639, "phrase": "expected_sample_size"}, {"score": 0.0024577772550219332, "phrase": "expected_cost"}, {"score": 0.0023166075278110237, "phrase": "mean_square_error"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["(epsilon, alpha)-approximation", " Worst case complexity", " Rare event simulation", " Exponential inequalities", " Mean square error", " Sequential methods"], "paper_abstract": "We consider Monte Carlo algorithms for computing an integral theta = integral fd pi which is positive but can be arbitrarily close to 0. It is assumed that we can generate a sequence X-n of uniformly bounded random variables with expectation theta. Estimator (theta) over cap = (theta) over cap (X-1, X-2, ... , X-N) is called an (epsilon, alpha)-approximation if it has fixed relative precision epsilon at a given level of confidence 1 - alpha, that is it satisfies P(vertical bar(theta) over cap - theta vertical bar <= epsilon theta) >= 1 - alpha for all problem instances. Such an estimator exists only if we allow the sample size N to be random and adaptively chosen. We propose an (epsilon, alpha)-approximation for which the cost, that is the expected number of samples, satisfies EN similar to 2 In alpha(-1)/(theta epsilon(2)) for epsilon -> 0 and alpha -> 0. The main tool in the analysis is a new exponential inequality for randomly stopped sums. We also derive a lower bound on the worst case complexity of the (epsilon, alpha)-approximation. This bound behaves as 2 In alpha(-1)/(theta epsilon(2)). Thus the worst case efficiency of our algorithm, understood as the ratio of the lower bound to the expected sample size EN, approaches 1 if epsilon -> 0 and alpha -> 0. An L-2 analogue is to find (theta) over cap such that E((theta) over cap - theta)(2) <= epsilon(2)theta(2). We derive an algorithm with the expected cost EN similar to 1/(theta epsilon(2)) for epsilon -> 0. To this end, we prove an inequality for the mean square error of randomly stopped sums. A corresponding lower bound also behaves as 1/(theta epsilon(2)). The worst case efficiency of our algorithm, in the L-2 sense, approaches 1 if epsilon -> 0. (c) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Optimal Monte Carlo integration with fixed relative precision", "paper_id": "WOS:000313312400001"}