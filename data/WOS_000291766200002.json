{"auto_keywords": [{"score": 0.0257166746483632, "phrase": "tan"}, {"score": 0.00481495049065317, "phrase": "classification_accuracy"}, {"score": 0.004542441734438654, "phrase": "bayesian_classifiers"}, {"score": 0.004353948887538618, "phrase": "precise_probability_estimates"}, {"score": 0.004240116703465252, "phrase": "unrestricted_bayesian_networks"}, {"score": 0.004173244935967375, "phrase": "computational_efficiency"}, {"score": 0.004129248271757936, "phrase": "naive_bayes"}, {"score": 0.004000010693331517, "phrase": "proposed_approach"}, {"score": 0.0038953958723049287, "phrase": "fundamental_principles"}, {"score": 0.0038339398365449507, "phrase": "network_learning"}, {"score": 0.0036359780843400625, "phrase": "\"approximate_markov_blanket"}, {"score": 0.0033937776228549557, "phrase": "bayesian_network"}, {"score": 0.0032184697893776052, "phrase": "usually_high_computational_cost"}, {"score": 0.0031676593724896075, "phrase": "heuristic_search_learning_algorithms"}, {"score": 0.0030684249587688826, "phrase": "bayesian_network_structures"}, {"score": 0.0029253546782349875, "phrase": "resulting_algorithms"}, {"score": 0.002879158342988017, "phrase": "dmbc"}, {"score": 0.0028487656293168795, "phrase": "dynamic_markov_blanket_classifier"}, {"score": 0.0026307897899760383, "phrase": "twelve_domains"}, {"score": 0.002561892963059385, "phrase": "particular_interest"}, {"score": 0.0025214217930287003, "phrase": "obtained_results"}, {"score": 0.002468633156143815, "phrase": "nb"}, {"score": 0.0024423826953133844, "phrase": "tree_augmented_network"}, {"score": 0.002316105585203396, "phrase": "proposed_algorithms"}, {"score": 0.002279508335630797, "phrase": "good_classification_accuracies"}, {"score": 0.002255431275670053, "phrase": "better_probability_estimates"}], "paper_keywords": ["Bayesian networks", " classifiers", " supervised learning"], "paper_abstract": "This work proposes and discusses an approach for inducing Bayesian classifiers aimed at balancing the tradeoff between the precise probability estimates produced by time consuming unrestricted Bayesian networks and the computational efficiency of Naive Bayes (NB) classifiers. The proposed approach is based on the fundamental principles of the Heuristic Search Bayesian network learning. The Markov Blanket concept, as well as a proposed \"approximate Markov Blanket\" are used to reduce the number of nodes that form the Bayesian network to be induced from data. Consequently, the usually high computational cost of the heuristic search learning algorithms can be lessened, while Bayesian network structures better than NB can be achieved. The resulting algorithms, called DMBC (Dynamic Markov Blanket Classifier) and A-DMBC (Approximate DMBC), are empirically assessed in twelve domains that illustrate scenarios of particular interest. The obtained results are compared with NB and Tree Augmented Network (TAN) classifiers, and confinn that both proposed algorithms can provide good classification accuracies and better probability estimates than NB and TAN, while being more computationally efficient than the widely used K2 Algorithm.", "paper_title": "Bayesian network classifiers: Beyond classification accuracy", "paper_id": "WOS:000291766200002"}