{"auto_keywords": [{"score": 0.04080705021857224, "phrase": "probabilistic_models"}, {"score": 0.00481495049065317, "phrase": "practical_probabilistic_programming"}, {"score": 0.004749226720942433, "phrase": "monads"}, {"score": 0.004652016085325825, "phrase": "machine_learning_community"}, {"score": 0.004372442291178139, "phrase": "practical_probabilistic_programming_systems"}, {"score": 0.004195418010131832, "phrase": "bayesian_inference"}, {"score": 0.004053362743156545, "phrase": "different_forms"}, {"score": 0.003835972725191194, "phrase": "computational_processes"}, {"score": 0.003731673223879279, "phrase": "programming_languages"}, {"score": 0.0036301992752948956, "phrase": "functional_programming_community"}, {"score": 0.003459191419478298, "phrase": "convenient_and_elegant_abstraction"}, {"score": 0.0033651019362620866, "phrase": "probability_distributions"}, {"score": 0.0029518598926717332, "phrase": "monad_abstraction"}, {"score": 0.002851790448644913, "phrase": "machine_learning"}, {"score": 0.002755104031926742, "phrase": "good_performance"}, {"score": 0.002680114113899346, "phrase": "challenging_models"}, {"score": 0.002589233442060453, "phrase": "gadt"}, {"score": 0.0025361866386341796, "phrase": "underlying_representation"}, {"score": 0.0024842242921857705, "phrase": "probability_distribution"}, {"score": 0.0024333239726872604, "phrase": "sequential_monte_carlo-based_methods"}, {"score": 0.0023834640793589435, "phrase": "efficient_inference"}, {"score": 0.002302619021497886, "phrase": "formal_semantics"}, {"score": 0.0022710523337245337, "phrase": "measure_theory"}, {"score": 0.0021940118003312397, "phrase": "clean_and_elegant_implementation"}, {"score": 0.002104998715788785, "phrase": "anglican"}], "paper_keywords": ["Haskell", " probabilistic programming", " Bayesian statistics", " monads", " Monte Carlo"], "paper_abstract": "The machine learning community has recently shown a lot of interest in practical probabilistic programming systems that target the problem of Bayesian inference. Such systems come in different forms, but they all express probabilistic models as computational processes using syntax resembling programming languages. In the functional programming community monads are known to offer a convenient and elegant abstraction for programming with probability distributions, but their use is often limited to very simple inference problems. We show that it is possible to use the monad abstraction to construct probabilistic models for machine learning, while still offering good performance of inference in challenging models. We use a GADT as an underlying representation of a probability distribution and apply Sequential Monte Carlo-based methods to achieve efficient inference. We define a formal semantics via measure theory. We demonstrate a clean and elegant implementation that achieves performance comparable with Anglican, a stateof- the-art probabilistic programming system.", "paper_title": "Practical Probabilistic Programming with Monads", "paper_id": "WOS:000370549100016"}