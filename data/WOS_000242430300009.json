{"auto_keywords": [{"score": 0.02945426422750087, "phrase": "correct_answers"}, {"score": 0.015719716506582538, "phrase": "clinician-selected_electronic_information_resources"}, {"score": 0.014913878674034748, "phrase": "simulated_clinical_questions"}, {"score": 0.012035725387405325, "phrase": "searching_techniques"}, {"score": 0.004764004403553372, "phrase": "primary_care_physicians'_information_needs"}, {"score": 0.004614362802631256, "phrase": "primary_care_physicians'_abilities"}, {"score": 0.0044535760439663235, "phrase": "hour-long_interviews"}, {"score": 0.003212906206685004, "phrase": "wide_variety"}, {"score": 0.0026900523406547827, "phrase": "correct_answer"}, {"score": 0.0024701382170046462, "phrase": "incorrect_answer"}, {"score": 0.002317055705600351, "phrase": "primary_care_physicians"}, {"score": 0.0022924784914292026, "phrase": "electronic_information_resources"}, {"score": 0.0021503823972534096, "phrase": "individual_resources"}, {"score": 0.0021049977753042253, "phrase": "initially_correct_answer"}], "paper_keywords": [""], "paper_abstract": "Objective: To determine if clinician-selected electronic information resources improve primary care physicians' abilities to answer simulated clinical questions. Design: Observational study using hour-long interviews in physician offices and think-aloud protocols. Participants answered 23 multiple-choice questions and chose 2 to obtain further information using their own information resources. We established which resources physicians chose, processes used, and results obtained when looking for information to support their answers. Measurements: Correctness of answers before and after searching, resources used, and searching techniques. Results: 23 physicians sought answers to 46 questions using their own information resources. They spent a mean of 13.0 (SD 5.5) minutes searching for information for the two questions using an average of 1.8 resources per question and a wide variety of searching techniques. On average 43.5% of the answers to the original 23 questions were correct. For the questions that were searched, 18 (39.1%) of the 46 answers were correct before searching. After searching, the number of correct answers was 19 (42.1%). This difference of I correct answer was attributed to 6 questions (13.0%) going from an incorrect to correct answer and 5 (10.9%) questions going from a correct to incorrect answer. We found differences in the ability of various resources to provide correct answers. Conclusion: For the primary care physicians studied, electronic information resources of choice did not always provide support for finding correct answers to simulated clinical questions and in some instances, individual resources may have contributed to an initially correct answer becoming incorrect.", "paper_title": "Effectiveness of clinician-selected electronic information resources for answering primary care physicians' information needs", "paper_id": "WOS:000242430300009"}