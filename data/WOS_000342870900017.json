{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "feature_weighting_schemes"}, {"score": 0.004696608876994947, "phrase": "nearest_neighbor_classifiers"}, {"score": 0.0046269981365987915, "phrase": "nearest_neighbor_rule"}, {"score": 0.0044685410845412745, "phrase": "machine_learning"}, {"score": 0.0040854526743211396, "phrase": "feature_weighting_methods"}, {"score": 0.0038676325043529524, "phrase": "similarity_function"}, {"score": 0.0035358770665604657, "phrase": "classification_task"}, {"score": 0.0034317185678527672, "phrase": "new_feature"}, {"score": 0.0031845067058084583, "phrase": "novel_idea"}, {"score": 0.003152915289414825, "phrase": "imputation_methods"}, {"score": 0.0030600032877646263, "phrase": "new_distribution"}, {"score": 0.0028253682745674608, "phrase": "kolmogorov-smirnov_nonparametric_statistical_test"}, {"score": 0.0027284410545226306, "phrase": "original_and_imputed_distribution"}, {"score": 0.0026086775334428617, "phrase": "classic_and_recent_feature_weighting_methods"}, {"score": 0.002420611343093316, "phrase": "imputation_method"}, {"score": 0.0023727863021828547, "phrase": "effective_way"}, {"score": 0.0022913497040895586, "phrase": "nearest_neighbor_classifier"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Feature weighting", " Imputation methods", " Nearest neighbor", " Classification"], "paper_abstract": "The Nearest Neighbor rule is one of the most successful classifiers in machine learning. However, it is very sensitive to noisy, redundant and irrelevant features, which may cause its performance to deteriorate. Feature weighting methods try to overcome this problem by incorporating weights into the similarity function to increase or reduce the importance of each feature, according to how they behave in the classification task. This paper proposes a new feature weighting classifier, in which the computation of the weights is based on a novel idea combining imputation methods - used to estimate a new distribution of values for each feature based on the rest of the data - and the Kolmogorov-Smirnov nonparametric statistical test to measure the changes between the original and imputed distribution of values. This proposal is compared with classic and recent feature weighting methods. The experimental results show that our feature weighting scheme is very resilient to the choice of imputation method and is an effective way of improving the performance of the Nearest Neighbor classifier, outperforming the rest of the classifiers considered in the comparisons. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Statistical computation of feature weighting schemes through data estimation for nearest neighbor classifiers", "paper_id": "WOS:000342870900017"}