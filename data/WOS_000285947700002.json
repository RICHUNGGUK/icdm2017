{"auto_keywords": [{"score": 0.03286917812756054, "phrase": "basic_action_theories"}, {"score": 0.0037040785566765954, "phrase": "present_state"}, {"score": 0.0033937776228549557, "phrase": "reiter's_basic_action_theories"}, {"score": 0.003313741359811683, "phrase": "situation_calculus"}, {"score": 0.0030119758165837625, "phrase": "markov_property_restriction"}, {"score": 0.0027594936602962075, "phrase": "executability_conditions"}, {"score": 0.0025687008721685454, "phrase": "reiter's_regression_operator"}, {"score": 0.002468450551616404, "phrase": "main_computational_mechanism"}, {"score": 0.002208035721125305, "phrase": "non-markovian_theories"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Reasoning about actions", " Situation Calculus"], "paper_abstract": "In reasoning about actions, it is commonly assumed that the dynamics of domains satisfies the Markov Property: the executability conditions and the effects of all actions are fully determined by the present state of the system. This is true in particular in Reiter's Basic Action Theories in the Situation Calculus. In this paper, we generalize Basic Action Theories by removing the Markov property restriction, making it possible to directly axiomatize actions whose effects and executability conditions may depend on past and even alternative, hypothetical situations. We then generalize Reiter's regression operator, which is the main computational mechanism used for reasoning with Basic Action Theories, so that it can be used with non-Markovian theories. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Non-Markovian control in the Situation Calculus", "paper_id": "WOS:000285947700002"}