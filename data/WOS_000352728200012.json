{"auto_keywords": [{"score": 0.03971271696133976, "phrase": "gpu"}, {"score": 0.008640379014344083, "phrase": "novel_methodology"}, {"score": 0.008408727178445194, "phrase": "many-core_coprocessor"}, {"score": 0.00481495049065317, "phrase": "gpu_acceleration"}, {"score": 0.004758987153057194, "phrase": "massively_parallel_many-core_platforms"}, {"score": 0.004594951819987416, "phrase": "general-purpose_processor"}, {"score": 0.004559270778306828, "phrase": "many-core_programmable_accelerators"}, {"score": 0.004488734023485018, "phrase": "increasing_demand"}, {"score": 0.004453874101119545, "phrase": "novel_methods"}, {"score": 0.004217286731331736, "phrase": "full_system"}, {"score": 0.004200874581076468, "phrase": "many-core_architectures"}, {"score": 0.004119762981892093, "phrase": "complexity_issues"}, {"score": 0.003993216345115755, "phrase": "parallel_simulator"}, {"score": 0.0037224647319912293, "phrase": "main_idea"}, {"score": 0.0034162643819889054, "phrase": "highly_parallel_gpu_platforms"}, {"score": 0.0032599633778910516, "phrase": "many-core_coprocessors"}, {"score": 0.0030506626796257077, "phrase": "heterogeneous_system"}, {"score": 0.002956858061485755, "phrase": "future_architecture"}, {"score": 0.0029338597685088603, "phrase": "many-core_heterogeneous_platforms"}, {"score": 0.0027995677499976406, "phrase": "arm_general_purpose"}, {"score": 0.0027134630181926854, "phrase": "simple_in-order_cores"}, {"score": 0.002671406231520296, "phrase": "tile_network"}, {"score": 0.002619748321217153, "phrase": "optimization_techniques"}, {"score": 0.002470676601347937, "phrase": "full_system_simulation"}, {"score": 0.0024514908878829076, "phrase": "cpu"}, {"score": 0.0023946630984825207, "phrase": "target_general_purpose"}, {"score": 0.0023391880766516285, "phrase": "host_cpu"}, {"score": 0.002154930852763048, "phrase": "entire_heterogeneous_chip"}, {"score": 0.0021049977753042253, "phrase": "increasing_cores"}], "paper_keywords": ["Parallel simulation", " heterogeneous architectures", " many-core processors", " accelerators", " GPGPU", " CUDA", " QEMU"], "paper_abstract": "Emerging massively parallel architectures such as a general-purpose processor plus many-core programmable accelerators are creating an increasing demand for novel methods to perform their architectural simulation. Most state-of-the-art simulation technologies are exceedingly slow and the need to model full system many-core architectures adds further to the complexity issues. This paper presents a fast, scalable and parallel simulator, which uses a novel methodology to accelerate the simulation of a many-core coprocessor using GPU platforms. The main idea is to use. The target architecture of the associated. Simulation of many target nodes is mapped to the many hardware-threads available on highly parallel GPU platforms. This paper presents a novel methodology to accelerate the simulation of many-core coprocessors using GPU platforms. We demonstrate the challenges, feasibility and benefits of our idea to use heterogeneous system (CPU and GPU) to simulate future architecture of many-core heterogeneous platforms. The target architecture selected to evaluate our methodology consists of an ARM general purpose CPU coupled with many-core coprocessor with thousands of simple in-order cores connected in a tile network. This work presents optimization techniques used to parallelize the simulation specifically for acceleration on GPUs. We partition the full system simulation between CPU and GPU, where the target general purpose CPU is simulated on the host CPU, whereas the many-core coprocessor is simulated on the NVIDIA Tesla 2070 GPU platform. Our experiments show performance of up to 50 MIPS when simulating the entire heterogeneous chip, and high scalability with increasing cores on coprocessor.", "paper_title": "GPU Acceleration for Simulating Massively Parallel Many-Core Platforms", "paper_id": "WOS:000352728200012"}