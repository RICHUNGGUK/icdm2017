{"auto_keywords": [{"score": 0.04844894171082025, "phrase": "nonnegative_learning"}, {"score": 0.03623561938966862, "phrase": "proposed_method"}, {"score": 0.030923053106664926, "phrase": "general_objective_costs"}, {"score": 0.00481495049065317, "phrase": "class-specific_entropy_component_analysis"}, {"score": 0.004537401559396022, "phrase": "part-based_representation"}, {"score": 0.0043183186953102805, "phrase": "nonnegative_matrix_factorization"}, {"score": 0.003989487818395848, "phrase": "optimization_problem"}, {"score": 0.00395017798595193, "phrase": "bound_constraints"}, {"score": 0.003815607281455725, "phrase": "informative_components"}, {"score": 0.0037593414153801394, "phrase": "nonnegative_patterns"}, {"score": 0.0033545600622020464, "phrase": "general_objective_functions"}, {"score": 0.0032887360307856635, "phrase": "conjugate_gradient_technique"}, {"score": 0.003192406091820197, "phrase": "iterative_optimization"}, {"score": 0.003053159610975692, "phrase": "general_nonnegative_learning_framework"}, {"score": 0.0029490571526071016, "phrase": "nonnegative_optimization_problem"}, {"score": 0.002806449337145999, "phrase": "nonnegative_bound_constraints"}, {"score": 0.0027650234530228923, "phrase": "diseased_nonnegative_learning_problem"}, {"score": 0.00263129148531588, "phrase": "modified_line_search_criterion"}, {"score": 0.0025415366388578465, "phrase": "null_trap"}, {"score": 0.002516457934208144, "phrase": "insured_conditions"}, {"score": 0.002467038647952607, "phrase": "feasible_step_descendent"}, {"score": 0.0023947191132328233, "phrase": "numerical_stopping_rule"}, {"score": 0.002336071138145897, "phrase": "optimized_efficiency"}, {"score": 0.002278856202878812, "phrase": "popular_gradient-based_one"}, {"score": 0.002234092591045251, "phrase": "face_recognition"}, {"score": 0.0021259846592569386, "phrase": "better_performance"}], "paper_keywords": ["Nonnegative learning", " General objective functions", " Diseased nonnegative learning problem", " Line search"], "paper_abstract": "Nonnegative learning aims to learn the part-based representation of nonnegative data and receives much attention in recent years. Nonnegative matrix factorization has been popular to make nonnegative learning applicable, which can also be explained as an optimization problem with bound constraints. In order to exploit the informative components hidden in nonnegative patterns, a novel nonnegative learning method, termed nonnegative class-specific entropy component analysis, is developed in this work. Distinguish from the existing methods, the proposed method aims to conduct the general objective functions, and the conjugate gradient technique is applied to enhance the iterative optimization. In view of the development, a general nonnegative learning framework is presented to deal with the nonnegative optimization problem with general objective costs. Owing to the general objective costs and the nonnegative bound constraints, the diseased nonnegative learning problem usually occurs. To address this limitation, a modified line search criterion is proposed, which prevents the null trap with insured conditions while keeping the feasible step descendent. In addition, the numerical stopping rule is employed to achieve optimized efficiency, instead of the popular gradient-based one. Experiments on face recognition with varieties of conditions reveal that the proposed method possesses better performance over other methods.", "paper_title": "Nonnegative class-specific entropy component analysis with adaptive step search criterion", "paper_id": "WOS:000330839400009"}