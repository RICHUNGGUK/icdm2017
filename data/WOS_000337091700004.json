{"auto_keywords": [{"score": 0.04299750205171382, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "weakly-supervised_cross-domain_dictionary_learning_for_visual_recognition"}, {"score": 0.004669845451682529, "phrase": "visual_categorization_problem"}, {"score": 0.00428629884026304, "phrase": "auxiliary_source_data"}, {"score": 0.0041825926310470616, "phrase": "original_learning_system"}, {"score": 0.003982617095636925, "phrase": "intra-class_diversity"}, {"score": 0.0039341294012600085, "phrase": "original_training_data"}, {"score": 0.0037921662574137535, "phrase": "source_data"}, {"score": 0.0036329805216306576, "phrase": "original_target_domain_data"}, {"score": 0.0035668128900149814, "phrase": "auxiliary_source_domain_data"}, {"score": 0.0033961782274326948, "phrase": "weakly-supervised_cross-domain_dictionary_learning_method"}, {"score": 0.003116913644889395, "phrase": "prior_information"}, {"score": 0.0030043508031729277, "phrase": "high_level"}, {"score": 0.002860546817196148, "phrase": "different_cross-domain_applications"}, {"score": 0.0027572166867780275, "phrase": "auxiliary_domain_data"}, {"score": 0.002641360377825228, "phrase": "web_pages"}, {"score": 0.00257735013358606, "phrase": "human_actions"}, {"score": 0.0025459275963373496, "phrase": "specific_categories"}, {"score": 0.002499508839669243, "phrase": "different_dataset"}, {"score": 0.0023944552329463035, "phrase": "human_action_recognition"}, {"score": 0.0023652572260178637, "phrase": "image_classification"}, {"score": 0.002336414425972225, "phrase": "event_recognition"}, {"score": 0.0022797772939670063, "phrase": "ucf_youtube_dataset"}, {"score": 0.002183938718432764, "phrase": "kodak"}, {"score": 0.0021049977753042253, "phrase": "outstanding_results"}], "paper_keywords": ["Visual categorization", " Image classification", " Human action recognition", " Event recognition", " Transfer learning", " Weakly-supervised dictionary learning"], "paper_abstract": "We address the visual categorization problem and present a method that utilizes weakly labeled data from other visual domains as the auxiliary source data for enhancing the original learning system. The proposed method aims to expand the intra-class diversity of original training data through the collaboration with the source data. In order to bring the original target domain data and the auxiliary source domain data into the same feature space, we introduce a weakly-supervised cross-domain dictionary learning method, which learns a reconstructive, discriminative and domain-adaptive dictionary pair and the corresponding classifier parameters without using any prior information. Such a method operates at a high level, and it can be applied to different cross-domain applications. To build up the auxiliary domain data, we manually collect images from Web pages, and select human actions of specific categories from a different dataset. The proposed method is evaluated for human action recognition, image classification and event recognition tasks on the UCF YouTube dataset, the Caltech101/256 datasets and the Kodak dataset, respectively, achieving outstanding results.", "paper_title": "Weakly-Supervised Cross-Domain Dictionary Learning for Visual Recognition", "paper_id": "WOS:000337091700004"}