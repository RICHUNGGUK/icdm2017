{"auto_keywords": [{"score": 0.04937303236560827, "phrase": "software_testing"}, {"score": 0.03963329481008671, "phrase": "software_testing_tasks"}, {"score": 0.00481495049065317, "phrase": "crowd_size"}, {"score": 0.004550585106483935, "phrase": "single_testing_task"}, {"score": 0.0044967977146747684, "phrase": "software_verification"}, {"score": 0.004430452655732319, "phrase": "software_review"}, {"score": 0.004404188306112211, "phrase": "usability_evaluation_contexts"}, {"score": 0.004378078970574258, "phrase": "positive_effects"}, {"score": 0.004339203636449911, "phrase": "multiple_individuals"}, {"score": 0.004004436217742343, "phrase": "time_pressure"}, {"score": 0.003921926812074958, "phrase": "manual_testing_tasks"}, {"score": 0.0038640303886081444, "phrase": "group_productivity_theory"}, {"score": 0.0038411109150557504, "phrase": "social_psychology"}, {"score": 0.0036516837986048795, "phrase": "manual_testing"}, {"score": 0.003576416581189713, "phrase": "time_restriction"}, {"score": 0.003329901594166227, "phrase": "manual_software_testing"}, {"score": 0.0033003027425118005, "phrase": "additive_task"}, {"score": 0.0032709661258673206, "phrase": "ceiling_effect"}, {"score": 0.003241889436209603, "phrase": "software_reviews"}, {"score": 0.0032226482496329626, "phrase": "usability_inspections"}, {"score": 0.0031468151597922214, "phrase": "five_time-restricted_testers"}, {"score": 0.003054520564249659, "phrase": "single_non-time-restricted_tester"}, {"score": 0.0029826318985134944, "phrase": "f-score_measure"}, {"score": 0.0029561107046138136, "phrase": "information_retrieval_domain"}, {"score": 0.002921114512115261, "phrase": "optimal_number"}, {"score": 0.0028269905110337094, "phrase": "testing_results"}, {"score": 0.0027852126030055305, "phrase": "future_studies"}, {"score": 0.0027522340188241446, "phrase": "validation_practices"}, {"score": 0.002600826330254548, "phrase": "time-pressured_crowds"}, {"score": 0.00257002536323506, "phrase": "multiple_time-pressured_individuals"}, {"score": 0.0025547615880525745, "phrase": "superior_defect_detection_effectiveness"}, {"score": 0.002524504774013978, "phrase": "non-time-pressured_individuals"}, {"score": 0.002385595105638277, "phrase": "future_works"}, {"score": 0.002214370556271579, "phrase": "invalid_reports"}, {"score": 0.002142970278347126, "phrase": "duplicate_handling_mechanisms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Software testing", " Group performance", " Division of labor", " Human factors", " Crowdsourcing", " Methods for SQA and V&V"], "paper_abstract": "Context: The questions of how many individuals and how much time to use for a single testing task are critical in software verification and validation. In software review and usability evaluation contexts, positive effects of using multiple individuals for a task have been found, but software testing has not been studied from this viewpoint. Objective: We study how adding individuals and imposing time pressure affects the effectiveness and efficiency of manual testing tasks. We applied the group productivity theory from social psychology to characterize the type of software testing tasks. Method: We conducted an experiment where 130 students performed manual testing under two conditions, one with a time restriction and pressure, i.e., a 2-h fixed slot, and another where the individuals could use as much time as they needed. Results: We found evidence that manual software testing is an additive task with a ceiling effect, like software reviews and usability inspections. Our results show that a crowd of five time-restricted testers using 10 h in total detected 71% more defects than a single non-time-restricted tester using 9.9 h. Furthermore, we use F-score measure from the information retrieval domain to analyze the optimal number of testers in terms of both effectiveness and validity of testing results. We suggest that future studies on verification and validation practices use F-score to provide a more transparent view of the results. Conclusions: The results seem promising for the time-pressured crowds by indicating that multiple time-pressured individuals deliver superior defect detection effectiveness in comparison to non-time-pressured individuals. However, caution is needed, as the limitations of this study need to be addressed in future works. Finally, we suggest that the size of the crowd used in software testing tasks should be determined based on the share of duplicate and invalid reports produced by the crowd and by the effectiveness of the duplicate handling mechanisms. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "More testers - The effect of crowd size and time restriction in software testing", "paper_id": "WOS:000318584800005"}