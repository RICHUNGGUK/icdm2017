{"auto_keywords": [{"score": 0.046840734843818926, "phrase": "video_sequences"}, {"score": 0.00481495049065317, "phrase": "efficient_event-based_indexing"}, {"score": 0.004159997145421619, "phrase": "different_approaches"}, {"score": 0.003639835714755229, "phrase": "event-based_retrieval"}, {"score": 0.003525861581971337, "phrase": "large_databases"}, {"score": 0.0033295966773779174, "phrase": "novel_index"}, {"score": 0.0030457198309616694, "phrase": "local_feature_trajectories"}, {"score": 0.0029691377785333872, "phrase": "spatio-temporal_volume"}, {"score": 0.0026475981474045414, "phrase": "represented_events"}, {"score": 0.002421726275597666, "phrase": "standard_video_sequence_corpus"}, {"score": 0.002316105585203396, "phrase": "complex_human_activities"}, {"score": 0.002215081186105616, "phrase": "art_methods"}, {"score": 0.0021049977753042253, "phrase": "generic_classes"}], "paper_keywords": [""], "paper_abstract": "We address the problem of indexing video sequences according to the events they depict. While a number of different approaches have been proposed in order to describe events, none is sufficiently generic and computationally efficient to be applied to event-based retrieval of video sequences within large databases. In this paper, we propose a novel index of video sequences which aims at describing their dynamic content. This index relies on the local feature trajectories estimated from the spatio-temporal volume of the video sequences. The computation of this index is efficient, makes assumption neither about the represented events nor about the video sequences. We show through a batch of experimentations on standard video sequence corpus that this index permits to classify complex human activities as efficiently as state of the art methods while being far more efficient to retrieve generic classes of events.", "paper_title": "Local feature trajectories for efficient event-based indexing of video sequences", "paper_id": "WOS:000239566500009"}