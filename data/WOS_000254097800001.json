{"auto_keywords": [{"score": 0.048799520930917564, "phrase": "sentence_compression"}, {"score": 0.00481495049065317, "phrase": "global_inference"}, {"score": 0.003772793879444995, "phrase": "subtitle_generation"}, {"score": 0.0036224139706218916, "phrase": "work_views"}, {"score": 0.00338493754743055, "phrase": "optimization_problem"}, {"score": 0.003249966782844541, "phrase": "integer_linear_programming"}, {"score": 0.003162996298548772, "phrase": "ilp"}, {"score": 0.002955533639862811, "phrase": "optimal_compressions"}, {"score": 0.0027616550517346066, "phrase": "linguistically_motivated_constraints"}, {"score": 0.0025804616931593897, "phrase": "previous_formulations"}, {"score": 0.002162951519368368, "phrase": "novel_global_constraints"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": [""], "paper_abstract": "Sentence compression holds promise for many applications ranging from summarization to subtitle generation. Out work views sentence compression as an optimization problem and uses integer linear programming (ILP) to infer globally optimal compressions in the presence of linguistically motivated constraints. We show how previous formulations of sentence compression can be recast as ILPs and extend these models with novel global constraints. Experimental results on written and spoken texts demonstrate improvements over state-of-the-art models.", "paper_title": "Global inference for sentence compression an integer linear programming approach", "paper_id": "WOS:000254097800001"}