{"auto_keywords": [{"score": 0.05007840182816714, "phrase": "active_appearance_models"}, {"score": 0.03425198723795155, "phrase": "ground_truth"}, {"score": 0.03095259042471494, "phrase": "aam"}, {"score": 0.004779271042959125, "phrase": "pain"}, {"score": 0.004691136491297242, "phrase": "patient_self-report"}, {"score": 0.00465634671242413, "phrase": "self-reported_pain"}, {"score": 0.004102719715406821, "phrase": "behavioral_scientists"}, {"score": 0.0040571383470418085, "phrase": "reliable_and_valid_facial_indicators"}, {"score": 0.0039088121438737924, "phrase": "manual_measurement"}, {"score": 0.0038798015183611275, "phrase": "highly_skilled_human_observers"}, {"score": 0.0037101871762082153, "phrase": "acute_pain"}, {"score": 0.003641713874009232, "phrase": "human_observers"}, {"score": 0.0034824716857663114, "phrase": "adult_patients"}, {"score": 0.0034566143156030426, "phrase": "rotator_cuff_injuries"}, {"score": 0.003392804886610623, "phrase": "video_input"}, {"score": 0.0031963987773420068, "phrase": "sequence-level_ground_truth"}, {"score": 0.003160854709666311, "phrase": "likert-type"}, {"score": 0.0031257046538823354, "phrase": "skilled_observers"}, {"score": 0.003102488033561956, "phrase": "frame-level_ground_truth"}, {"score": 0.0030113280682863234, "phrase": "facial_actions"}, {"score": 0.0028053842615436706, "phrase": "digitized_face_images"}, {"score": 0.002784540221128404, "phrase": "support_vector_machines"}, {"score": 0.0026330549554033876, "phrase": "varying_granularity"}, {"score": 0.002499094513009327, "phrase": "automatic_pain_detection_systems"}, {"score": 0.0023107943665108465, "phrase": "satisfactory_automatic_pain_detection_performance"}], "paper_keywords": ["Active appearance models", " Support vector machines", " Pain", " Facial expression", " Automatic facial image analysis", " FACS"], "paper_abstract": "Pain is typically assessed by patient self-report. Self-reported pain, however, is difficult to interpret and may be impaired or in some circumstances (i.e., young children and the severely ill) not even possible. To circumvent these problems behavioral scientists have identified reliable and valid facial indicators of pain. Hitherto, these methods have required manual measurement by highly skilled human observers. In this paper we explore an approach for automatically recognizing acute pain without the need for human observers. Specifically, our study was restricted to automatically detecting pain in adult patients with rotator cuff injuries. The system employed video input of the patients as they moved their affected and unaffected shoulder. Two types of ground truth were considered. Sequence-level ground truth consisted of Likert-type ratings by skilled observers. Frame-level ground truth was calculated from presence/absence and intensity of facial actions previously associated with pain. Active appearance models (AAM) were used to decouple shape and appearance in the digitized face images. Support vector machines (SVM) were compared for several representations from the AAM and of ground truth of varying granularity. We explored two questions pertinent to the construction, design and development of automatic pain detection systems. First, at what level (i.e., sequence- or frame-level) should datasets be labeled in order to obtain satisfactory automatic pain detection performance? Second, how important is it, at both levels of labeling, that we non-rigidly register the face? (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "The painful face - Pain expression recognition using active appearance models", "paper_id": "WOS:000271335000005"}