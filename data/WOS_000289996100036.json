{"auto_keywords": [{"score": 0.031435923708716486, "phrase": "retargeted_images"}, {"score": 0.02994846263118798, "phrase": "global_geometric_structures"}, {"score": 0.02811644268570192, "phrase": "local_pixel_correspondence"}, {"score": 0.00481495049065317, "phrase": "content-aware_image_retargeting"}, {"score": 0.004581162468419365, "phrase": "different_aspect_ratios"}, {"score": 0.004490842671590769, "phrase": "salient_regions"}, {"score": 0.004230382915464492, "phrase": "image_quality"}, {"score": 0.004188459638572375, "phrase": "different_retargeting_methods"}, {"score": 0.004065156038847781, "phrase": "objective_metric"}, {"score": 0.0040048667115255, "phrase": "human_vision_system"}, {"score": 0.0037724857647796813, "phrase": "traditional_objective_assessment_methods"}, {"score": 0.0036980501827538455, "phrase": "bottom-up_manner"}, {"score": 0.0036070601923916196, "phrase": "pixel-level_features"}, {"score": 0.0034834098902271626, "phrase": "global_way"}, {"score": 0.0032975819773787985, "phrase": "reverse_order"}, {"score": 0.003152915289414825, "phrase": "image_features"}, {"score": 0.0030906666356950887, "phrase": "local_viewpoints"}, {"score": 0.003014576010931602, "phrase": "new_objective_assessment"}, {"score": 0.002925728709297618, "phrase": "scale-space_matching_method"}, {"score": 0.0027284410545226306, "phrase": "scale_space"}, {"score": 0.0026745503978347143, "phrase": "fine_levels"}, {"score": 0.00256993314099902, "phrase": "objective_assessment"}, {"score": 0.002408565679880478, "phrase": "color_images"}, {"score": 0.0023609780669713288, "phrase": "color_space"}, {"score": 0.0023143284925318916, "phrase": "experimental_results"}, {"score": 0.002223770196464436, "phrase": "objective_assessments"}, {"score": 0.0021907299375981356, "phrase": "proposed_metric"}, {"score": 0.002136747803494932, "phrase": "good_consistency"}, {"score": 0.0021049977753042253, "phrase": "proposed_objective_metric_and_subjective_assessment"}], "paper_keywords": [""], "paper_abstract": "Content-aware image retargeting is a technique that can flexibly display images with different aspect ratios and simultaneously preserve salient regions in images. Recently many image retargeting techniques have been proposed. To compare image quality by different retargeting methods fast and reliably, an objective metric simulating the human vision system (HVS) is presented in this paper. Different from traditional objective assessment methods that work in bottom-up manner (i.e., assembling pixel-level features in a local-to-global way), in this paper we propose to use a reverse order (top-down manner) that organizes image features from global to local viewpoints, leading to a new objective assessment metric for retargeted images. A scale-space matching method is designed to facilitate extraction of global geometric structures from retargeted images. By traversing the scale space from coarse to fine levels, local pixel correspondence is also established. The objective assessment metric is then based on both global geometric structures and local pixel correspondence. To evaluate color images, CIE L*a*b* color space is utilized. Experimental results are obtained to measure the performance of objective assessments with the proposed metric. The results show good consistency between the proposed objective metric and subjective assessment by human observers.", "paper_title": "Image Retargeting Quality Assessment", "paper_id": "WOS:000289996100036"}