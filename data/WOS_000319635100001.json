{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "deep_web"}, {"score": 0.009980173039493502, "phrase": "existing_methods"}, {"score": 0.004724878518219719, "phrase": "hidden_web"}, {"score": 0.0046364836476864325, "phrase": "hidden_part"}, {"score": 0.004464602028530629, "phrase": "structured_databases"}, {"score": 0.004339867166576126, "phrase": "standard_web_crawlers"}, {"score": 0.004043003243656031, "phrase": "significant_gap"}, {"score": 0.003948613642680196, "phrase": "search_engines"}, {"score": 0.0038382392088338784, "phrase": "novel_deep_web_crawling_framework"}, {"score": 0.0035587046945919788, "phrase": "deep_web_database"}, {"score": 0.0029454679553901613, "phrase": "deep_web_databases"}, {"score": 0.002917736974519881, "phrase": "full-text_search_interfaces"}, {"score": 0.0028227597542492705, "phrase": "tf"}, {"score": 0.0027961991123212834, "phrase": "df"}, {"score": 0.0027567336518542858, "phrase": "acquired_data_records"}, {"score": 0.0027050595279115015, "phrase": "next_query"}, {"score": 0.00266693888510356, "phrase": "reinforcement_learning_framework"}, {"score": 0.0025678829712650437, "phrase": "promising_crawling_strategy"}, {"score": 0.002460825108719896, "phrase": "diverse_features"}, {"score": 0.002437645786158106, "phrase": "query_keywords"}, {"score": 0.0024146842687658467, "phrase": "experimental_results"}, {"score": 0.0023139986108451967, "phrase": "art_methods"}, {"score": 0.002196609505859369, "phrase": "full-text_search"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Hidden web", " Deep web crawling", " Reinforcement learning"], "paper_abstract": "Deep web or hidden web refers to the hidden part of the Web (usually residing in structured databases) that remains unavailable for standard Web crawlers. Obtaining content of the deep web is challenging and has been acknowledged as a significant gap in the coverage of search engines. The paper proposes a novel deep web crawling framework based on reinforcement learning, in which the crawler is regarded as an agent and deep web database as the environment. The agent perceives its current state and selects an action (query) to submit to the environment (the deep web database) according to Q-value. While the existing methods rely on an assumption that all deep web databases possess full-text search interfaces and solely utilize the statistics (TF or DF) of acquired data records to generate the next query, the reinforcement learning framework not only enables crawlers to learn a promising crawling strategy from its own experience, but also allows for utilizing diverse features of query keywords. Experimental results show that the method outperforms the state of art methods in terms of crawling capability and relaxes the assumption of full-text search implied by existing methods. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Learning to crawl deep web", "paper_id": "WOS:000319635100001"}