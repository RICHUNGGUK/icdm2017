{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "optimization"}, {"score": 0.004624751696958501, "phrase": "strategic_decisions"}, {"score": 0.004509694461067052, "phrase": "tactical_management"}, {"score": 0.0043533862892678864, "phrase": "strategic_level"}, {"score": 0.004160319763461951, "phrase": "possible_options"}, {"score": 0.0040978781692373005, "phrase": "final_selection"}, {"score": 0.003975781274672803, "phrase": "best_option"}, {"score": 0.0037993970934472243, "phrase": "real_world_problems"}, {"score": 0.0034003686971964707, "phrase": "classical_upper_confidence"}, {"score": 0.0033156708990372047, "phrase": "exponential_exploration-exploitation_algorithm"}, {"score": 0.0032658649336454923, "phrase": "successive_reject_algorithm"}, {"score": 0.0031845067058084583, "phrase": "simple_regret"}, {"score": 0.003105168935158648, "phrase": "bernstein_races"}, {"score": 0.0028498718992429825, "phrase": "empirically_best_arm"}, {"score": 0.0026688629249775925, "phrase": "reward_distribution"}, {"score": 0.0025892330566358503, "phrase": "risk_control"}, {"score": 0.0025119730908615104, "phrase": "systematic_study"}, {"score": 0.0024247382451294255, "phrase": "sequential_exploration_and_recommendation_variants"}, {"score": 0.0022937210378944457, "phrase": "secondary_contribution"}, {"score": 0.0021479597698614373, "phrase": "first_win"}, {"score": 0.0021049977753042253, "phrase": "computer-kill-all_go_player"}], "paper_keywords": ["multi-armed bandit problems", " metagaming", " strategic choices", " investment optimization", " upper confidence bounds", " simple regret", " games"], "paper_abstract": "Many decision problems have two levels: one for strategic decisions, and another for tactical management. This paper focuses on the strategic level, more specifically the sequential exploration of the possible options and the final selection (recommendation) of the best option. Several sequential exploration and recommendation criteria are considered and empirically compared on real world problems (board games, card games and energy management problems) in the uniform (1-player) and adversarial (2-player) settings W.r.t the sequential exploration part, the classical upper confidence bound algorithm, the exponential exploration-exploitation algorithm, the successive reject algorithm (designed specifically for simple regret), and the Bernstein races, are considered. W.r.t. the recommendation part, the selection is based on the empirically best arm, most played arm, lower confidence bounds, based on the reward distribution or variants thereof designed for risk control. This paper presents a systematic study, comparing the coupling of the sequential exploration and recommendation variants on the considered problems in terms of their simple regret. A secondary contribution is that, to the best of our knowledge, this is the first win ever of a computer-kill-all Go player against professional human players [16].", "paper_title": "Strategic Choices in Optimization", "paper_id": "WOS:000340075300013"}