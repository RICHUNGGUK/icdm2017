{"auto_keywords": [{"score": 0.03933785737409739, "phrase": "bottom_layer"}, {"score": 0.013360661645070953, "phrase": "new_memetic_computing_model"}, {"score": 0.009543629985088224, "phrase": "top_layer"}, {"score": 0.00481495049065317, "phrase": "latin_sampling_based_memetic_algorithm"}, {"score": 0.004692980391580608, "phrase": "memetic_algorithms"}, {"score": 0.004322967486451877, "phrase": "numerous_optimization_problems"}, {"score": 0.004278807087784626, "phrase": "diverse_fields"}, {"score": 0.004002513373645485, "phrase": "hierarchical_particle_swarm_optimizer"}, {"score": 0.0039010428828989826, "phrase": "latin_hypercube_sampling"}, {"score": 0.0037057255600764475, "phrase": "hierarchical_pso"}, {"score": 0.0035021127041237887, "phrase": "local_optima"}, {"score": 0.0034485432592912917, "phrase": "learning_strategy"}, {"score": 0.003343841875107018, "phrase": "well-known_comprehensive_learning_method"}, {"score": 0.003292685392413911, "phrase": "newly_designed_mutation_operator"}, {"score": 0.0032256881625734777, "phrase": "evolution_process"}, {"score": 0.0027223626424366207, "phrase": "local_search_strategy"}, {"score": 0.0023211517663846346, "phrase": "cylindricity_error_evaluation_problem"}, {"score": 0.0022390533383717715, "phrase": "proposed_algorithm"}, {"score": 0.002193447487477984, "phrase": "conventional_pso"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Memetic algorithm", " Particle swarm optimizer", " Latin hypercube sampling", " Comprehensive learning", " Cylindricity"], "paper_abstract": "Memetic algorithms, one type of algorithms inspired by nature, have been successfully applied to solve numerous optimization problems in diverse fields. In this paper, we propose a new memetic computing model, using a hierarchical particle swarm optimizer (HPSO) and latin hypercube sampling (LHS) method. In the bottom layer of hierarchical PSO, several swarms evolve in parallel to avoid being trapped in local optima. The learning strategy for each swarm is the well-known comprehensive learning method with a newly designed mutation operator. After the evolution process accomplished in bottom layer, one particle for each swarm is selected as candidate to construct the swarm in the top layer, which evolves by the same strategy employed in the bottom layer. The local search strategy based on LHS is imposed on particles in the top layer every specified number of generations. The new memetic computing model is extensively evaluated on a suite of 16 numerical optimization functions as well as the cylindricity error evaluation problem. Experimental results show that the proposed algorithm compares favorably with conventional PSO and several variants. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "A hierarchical particle swarm optimizer with latin sampling based memetic algorithm for numerical optimization", "paper_id": "WOS:000319205200053"}