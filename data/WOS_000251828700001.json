{"auto_keywords": [{"score": 0.04014362523824072, "phrase": "action_recognition"}, {"score": 0.00481495049065317, "phrase": "transferable_belief_model"}, {"score": 0.004655285779819366, "phrase": "human_behavior_recognition"}, {"score": 0.004577440795549049, "phrase": "main_problem"}, {"score": 0.004450568197899267, "phrase": "semantic_gap"}, {"score": 0.004376131419366239, "phrase": "analogue_observations"}, {"score": 0.0043029342321223825, "phrase": "real_world"}, {"score": 0.004230956171850591, "phrase": "symbolic_world"}, {"score": 0.004183638135671596, "phrase": "human_interpretation"}, {"score": 0.004044822781630218, "phrase": "fusion_architecture"}, {"score": 0.003954837422946628, "phrase": "transferable_belief_model_framework"}, {"score": 0.003717528595128948, "phrase": "video_sequences"}, {"score": 0.0035539019235553897, "phrase": "relevant_features"}, {"score": 0.003284637361174143, "phrase": "particular_points"}, {"score": 0.0032296377835432533, "phrase": "athlete's_silhouette"}, {"score": 0.003035711716881469, "phrase": "numerical_features"}, {"score": 0.002743105561254975, "phrase": "temporal_belief_filter"}, {"score": 0.0025638362414466278, "phrase": "proposed_approach"}, {"score": 0.002535115422089855, "phrase": "good_performance"}, {"score": 0.0024786330057813204, "phrase": "real_videos"}, {"score": 0.002450864311898833, "phrase": "athletics_sports_videos"}, {"score": 0.0022270182923887012, "phrase": "moving_camera"}, {"score": 0.0022020622730208514, "phrase": "different_view_angles"}, {"score": 0.0021651504858015364, "phrase": "proposed_system"}, {"score": 0.0021049977753042253, "phrase": "bayesian_networks"}], "paper_keywords": ["human action recognition", " Transferable Belief Model", " Temporal Belief Filter", " moving camera"], "paper_abstract": "This paper focuses on human behavior recognition where the main problem is to bridge the semantic gap between the analogue observations of the real world and the symbolic world of human interpretation. For that, a fusion architecture based on the Transferable Belief Model framework is proposed and applied to action recognition of an athlete in video sequences of athletics meeting with moving camera. Relevant features are extracted from videos, based on both the camera motion analysis and the tracking of particular points on the athlete's silhouette. Some models of interpretation are used to link the numerical features to the symbols to be recognized, which are running, jumping and falling actions. A Temporal Belief Filter is then used to improve the robustness of action recognition. The proposed approach demonstrates good performance when tested on real videos of athletics sports videos (high jumps, pole vaults, triple jumps and long jumps) acquired by a moving camera and different view angles. The proposed system is also compared to Bayesian Networks.", "paper_title": "Human action recognition in videos based on the Transferable Belief Model", "paper_id": "WOS:000251828700001"}