{"auto_keywords": [{"score": 0.04939619318571274, "phrase": "autonomous_robot_navigation"}, {"score": 0.015608416624520713, "phrase": "visual_landmark_recognition"}, {"score": 0.013830820529520378, "phrase": "visual_landmarks"}, {"score": 0.013347074786027204, "phrase": "pre-attentive_and_attentive_stages"}, {"score": 0.012607580214792226, "phrase": "object_recognition"}, {"score": 0.009142806096390937, "phrase": "earlier_stages"}, {"score": 0.00481495049065317, "phrase": "neural_processing_paradigm"}, {"score": 0.004546000131069232, "phrase": "known_routes"}, {"score": 0.004401342842183475, "phrase": "human_visual_system"}, {"score": 0.004322967486451877, "phrase": "feedforward-feedbackward_architecture"}, {"score": 0.0042004472903194616, "phrase": "real_time"}, {"score": 0.004125634486868786, "phrase": "theoretical_concepts"}, {"score": 0.003965684670332574, "phrase": "selective_attention_adaptive_resonance_theory_neural_network"}, {"score": 0.0038810583785936505, "phrase": "computational_approaches"}, {"score": 0.0038256426589560774, "phrase": "computer_vision"}, {"score": 0.003637822529522622, "phrase": "neural_network_processing_paradigm"}, {"score": 0.003598786417573615, "phrase": "computational_template-matching_approach"}, {"score": 0.003521961918342562, "phrase": "real-time_landmark_recognition_capability"}, {"score": 0.0034467717443162015, "phrase": "pre-attentive_stage"}, {"score": 0.003373181367365139, "phrase": "selective_attention_mechanism"}, {"score": 0.0033490008882413103, "phrase": "optimal_computational_resource_allocation"}, {"score": 0.0032075033252058835, "phrase": "computational_restrictive_nature"}, {"score": 0.0031845067058084583, "phrase": "current_computer_processing_power"}, {"score": 0.003071965703296204, "phrase": "clean_and_cluttered_backgrounds"}, {"score": 0.0030171910207671205, "phrase": "attentive_stage"}, {"score": 0.0029740732099993706, "phrase": "memory_feedback_modulation"}, {"score": 0.0026410082462069596, "phrase": "bottom-up_facilitatory"}, {"score": 0.0024223970976460173, "phrase": "adjacent_features"}, {"score": 0.0022785613865764923, "phrase": "cluttered_backgrounds"}, {"score": 0.0022379017425216917, "phrase": "indoor_and_outdoor_scenes"}, {"score": 0.0021979660485319523, "phrase": "architecture_application"}, {"score": 0.0021202154023229123, "phrase": "real-time_trials"}], "paper_keywords": ["Visual landmark recognition", " Mobile robot", " Biological neural network", " Artificial intelligent"], "paper_abstract": "This article addresses the issue of visual landmark recognition in autonomous robot navigation along known routes, by intuitively exploiting the functions of the human visual system and its navigational ability. A feedforward-feedbackward architecture has been developed for recognising visual landmarks in real time. It integrates the theoretical concepts from the pre-attentive and attentive stages in the human visual system, the selective attention adaptive resonance theory neural network and its derivatives, and computational approaches towards object recognition in computer vision. The architecture mimics the pre-attentive and attentive stages in the context of object recognition, embedding neural network processing paradigm into a computational template-matching approach in computer vision. The real-time landmark recognition capability is achieved by mimicking the pre-attentive stage, where it models a selective attention mechanism for optimal computational resource allocation, focusing only on the regions of interest to address the computational restrictive nature of current computer processing power. Similarly, the recognition of visual landmarks in both clean and cluttered backgrounds is implemented in the attentive stage by developing a memory feedback modulation (MFM) mechanism that enables knowledge from the memory to interact and enhance the efficiency of earlier stages in the architecture. Furthermore, it also incorporates both top-down and bottom-up facilitatory and inhibition pathways between the memory and the earlier stages to enable the architecture to recognise a 2D landmark, which is partially occluded by adjacent features in the surroundings. The results show that the architecture is able to recognise objects in cluttered backgrounds using real-images in both indoor and outdoor scenes. Furthermore, the architecture application in autonomous robot navigation has been demonstrated through a number of real-time trials in both indoor and outdoor environments.", "paper_title": "Application of neural processing paradigm in visual landmark recognition and autonomous robot navigation", "paper_id": "WOS:000275421900008"}