{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "radial_basis_function_networks"}, {"score": 0.0045324756541157574, "phrase": "approximation_capability"}, {"score": 0.004139401327448803, "phrase": "machine_learning_theory"}, {"score": 0.0038573081851680656, "phrase": "almost_optimal_rates"}, {"score": 0.0033156708990372047, "phrase": "large_classes"}, {"score": 0.003152531962718477, "phrase": "convergence_rate"}, {"score": 0.002821247621250663, "phrase": "multivariate_algebraic_polynomials"}, {"score": 0.002524688179363081, "phrase": "classical_empirical_risk_minimization"}, {"score": 0.0024493494346360415, "phrase": "rbfns_estimator"}, {"score": 0.0023287359930308864, "phrase": "almost_optimal_learning_rate"}, {"score": 0.0022592313766072658, "phrase": "obtained_results"}, {"score": 0.0021917966722180132, "phrase": "successful_application"}], "paper_keywords": ["Learning theory", " Approximation theory", " Radial basis function networks", " Rate of convergence"], "paper_abstract": "This paper quantifies the approximation capability of radial basis function networks (RBFNs) and their applications in machine learning theory. The target is to deduce almost optimal rates of approximation and learning by RBFNs. For approximation, we show that for large classes of functions, the convergence rate of approximation by RBFNs is not slower than that of multivariate algebraic polynomials. For learning, we prove that, using the classical empirical risk minimization, the RBFNs estimator can theoretically realize the almost optimal learning rate. The obtained results underlie the successful application of RBFNs in various machine learning problems.", "paper_title": "Almost optimal estimates for approximation and learning by radial basis function networks", "paper_id": "WOS:000334269800001"}