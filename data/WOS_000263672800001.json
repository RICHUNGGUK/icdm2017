{"auto_keywords": [{"score": 0.03193798136705121, "phrase": "spatio-temporal_saliency_map"}, {"score": 0.00481495049065317, "phrase": "spatio-temporal_saliency"}, {"score": 0.004761132425263795, "phrase": "predict_gaze_direction"}, {"score": 0.004707913053935566, "phrase": "short_videos"}, {"score": 0.004551781491498328, "phrase": "spatio-temporal_saliency_model"}, {"score": 0.004400804926266097, "phrase": "video_free_viewing"}, {"score": 0.00413684709497912, "phrase": "first_steps"}, {"score": 0.004067635935640407, "phrase": "human_visual_system"}, {"score": 0.003910595307634916, "phrase": "video_stream"}, {"score": 0.0034944094552943, "phrase": "elementary_feature_maps"}, {"score": 0.00345530020388352, "phrase": "cortical-like_filters"}, {"score": 0.0033974527047473044, "phrase": "feature_maps"}, {"score": 0.0028695095228791724, "phrase": "salient_areas"}, {"score": 0.00266693888510356, "phrase": "different_subjects"}, {"score": 0.0026222551419772867, "phrase": "free_video_viewing_experiment"}, {"score": 0.00257831812581194, "phrase": "large_database"}, {"score": 0.0024097920845706795, "phrase": "dynamic_pathways"}, {"score": 0.0021288561076024844, "phrase": "poor_predictor"}, {"score": 0.0021049977753042253, "phrase": "eye_movement"}], "paper_keywords": ["Saliency", " Spatio-temporal model", " Gaze prediction", " Video viewing"], "paper_abstract": "This paper presents a spatio-temporal saliency model that predicts eye movement during video free viewing. This model is inspired by the biology of the first steps of the human visual system. The model extracts two signals from video stream corresponding to the two main outputs of the retina: parvocellular and magnocellular. Then, both signals are split into elementary feature maps by cortical-like filters. These feature maps are used to form two saliency maps: a static and a dynamic one. These maps are then fused into a spatio-temporal saliency map. The model is evaluated by comparing the salient areas of each frame predicted by the spatio-temporal saliency map to the eye positions of different subjects during a free video viewing experiment with a large database (17000 frames). In parallel, the static and the dynamic pathways are analyzed to understand what is more or less salient and for what type of videos our model is a good or a poor predictor of eye movement.", "paper_title": "Modelling Spatio-Temporal Saliency to Predict Gaze Direction for Short Videos", "paper_id": "WOS:000263672800001"}