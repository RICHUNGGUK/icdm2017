{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "japanese"}, {"score": 0.04918725889190486, "phrase": "situated_dialogs"}, {"score": 0.029276188710545648, "phrase": "potential_uses"}, {"score": 0.004690025569165577, "phrase": "identifying_objects"}, {"score": 0.004602773636967002, "phrase": "fundamental_human_capability"}, {"score": 0.004534136929881113, "phrase": "efficient_collaboration"}, {"score": 0.004483328889361545, "phrase": "real_world_task"}, {"score": 0.004350594827104932, "phrase": "human_referential_behaviour"}, {"score": 0.004127657126534723, "phrase": "meaningful_way"}, {"score": 0.004020492138367616, "phrase": "rex-j"}, {"score": 0.003771631577951067, "phrase": "collaborative_task"}, {"score": 0.0037153426267756452, "phrase": "tangram_puzzle"}, {"score": 0.0034203874753429113, "phrase": "collected_data"}, {"score": 0.003356675879109443, "phrase": "important_differences"}, {"score": 0.0033315236647127734, "phrase": "previous_corpora"}, {"score": 0.0032694619052789768, "phrase": "extra-linguistic_information"}, {"score": 0.003021141590548526, "phrase": "participants'_utterances"}, {"score": 0.0028661330049356186, "phrase": "unified_model"}, {"score": 0.0028446460307503343, "phrase": "linguistic_and_extra-linguistic_information"}, {"score": 0.0026483647033436674, "phrase": "specific_type"}, {"score": 0.002628506002255396, "phrase": "referring_expression"}, {"score": 0.002437907960209364, "phrase": "demonstrative_pronouns"}, {"score": 0.00223570488212345, "phrase": "valuable_addition"}, {"score": 0.0022105951175680856, "phrase": "existing_databases"}, {"score": 0.0021049977753042253, "phrase": "situated_dialog"}], "paper_keywords": ["Multi-modal corpus", " Referring expressions", " Collaborative task", " Japanese"], "paper_abstract": "Identifying objects in conversation is a fundamental human capability necessary to achieve efficient collaboration on any real world task. Hence the deepening of our understanding of human referential behaviour is indispensable for the creation of systems that collaborate with humans in a meaningful way. We present the construction of REX-J, a multi-modal Japanese corpus of referring expressions in situated dialogs, based on the collaborative task of solving the Tangram puzzle. This corpus contains 24 dialogs with over 4 h of recordings and over 1,400 referring expressions. We outline the characteristics of the collected data and point out the important differences from previous corpora. The corpus records extra-linguistic information during the interaction (e.g. the position of pieces, the actions on the pieces) in synchronization with the participants' utterances. This in turn allows us to discuss the importance of creating a unified model of linguistic and extra-linguistic information from a new perspective. Demonstrating the potential uses of this corpus, we present the analysis of a specific type of referring expression (\"action-mentioning expression\") as well as the results of research into the generation of demonstrative pronouns. Furthermore, we discuss some perspectives on potential uses of this corpus as well as our planned future work, underlining how it is a valuable addition to the existing databases in the community for the study and modeling of referring expressions in situated dialog.", "paper_title": "REX-J: Japanese referring expression corpus of situated dialogs", "paper_id": "WOS:000310164600005"}