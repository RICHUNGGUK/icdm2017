{"auto_keywords": [{"score": 0.022532944576440818, "phrase": "src"}, {"score": 0.010519569757466537, "phrase": "pattern_classification"}, {"score": 0.00726903882395532, "phrase": "nonzero_representation_coefficients"}, {"score": 0.005221290340007234, "phrase": "proposed_classifiers"}, {"score": 0.00470975295439431, "phrase": "newly-emerging_sparse_representation-based_classifier"}, {"score": 0.0044863018460183784, "phrase": "theoretical_justification"}, {"score": 0.0042734067085669885, "phrase": "reasonable_supports"}, {"score": 0.0040347380310668994, "phrase": "computational_convenience"}, {"score": 0.003759142310009214, "phrase": "pattern_recognition_tasks"}, {"score": 0.0033658215550414565, "phrase": "sparsity"}, {"score": 0.0033212215487678854, "phrase": "small_number"}, {"score": 0.003149471116658739, "phrase": "training_samples"}, {"score": 0.00286994286986659, "phrase": "src."}, {"score": 0.0024798965981600953, "phrase": "lasso"}, {"score": 0.002320449502337321, "phrase": "five_databases"}, {"score": 0.002289821830549781, "phrase": "experimental_results"}, {"score": 0.002200337772403983, "phrase": "classification_performance"}, {"score": 0.0021809311689473493, "phrase": "computational_efficiency"}, {"score": 0.002161695357601592, "phrase": "large_sample_size_problems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Sparse representation", " Pattern classification", " Classifier", " Feature extraction"], "paper_abstract": "The newly-emerging sparse representation-based classifier (SRC) shows great potential for pattern classification but lacks theoretical justification. This paper gives an insight into SRC and seeks reasonable supports for its effectiveness. SRC uses L-1-optimizer instead of L-0-optimizer on account of computational convenience and efficiency. We re-examine the role of L-1-optimizer and find that for pattern recognition tasks, L-1-optimizer provides more classification meaningful information than L-0-optimizer does. L-0-optimizer can achieve sparsity only, whereas L-1-optimizer can achieve closeness as well as sparsity. Sparsity determines a small number of nonzero representation coefficients, while closeness makes the nonzero representation coefficients concentrate on the training samples with the same class label as the given test sample. Thus, it is closeness that guarantees the effectiveness of the L-1-optimizer based SRC. Based on the closeness prior, we further propose two kinds of class L-1-optimizer classifiers (CL1C), the closeness rule based CL1C (C-CL1C) and its improved version: the Lasso rule based CL1C (L-CL1C). The proposed classifiers are evaluated on five databases and the experimental results demonstrate advantages of the proposed classifiers over SRC in classification performance and computational efficiency for large sample size problems. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Beyond sparsity: The role of L-1-optimizer in pattern classification", "paper_id": "WOS:000297906200015"}