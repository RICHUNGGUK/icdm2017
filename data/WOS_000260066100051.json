{"auto_keywords": [{"score": 0.048534495128882256, "phrase": "neural_networks"}, {"score": 0.014924970804386286, "phrase": "suzuki"}, {"score": 0.00481495049065317, "phrase": "suzuki's_neural_networks"}, {"score": 0.00406001734835979, "phrase": "lower_bound_estimations"}, {"score": 0.004007083686875716, "phrase": "approximation_order"}, {"score": 0.003928969293303814, "phrase": "essential_approximation_order"}, {"score": 0.0032908057622663732, "phrase": "approximation_ability"}, {"score": 0.002943147037670826, "phrase": "hidden-layer_units"}, {"score": 0.0028480459059007468, "phrase": "approximated_functions"}, {"score": 0.0027200305495826797, "phrase": "error_estimations"}, {"score": 0.0023384629381463054, "phrase": "numerical_example"}, {"score": 0.002146926767291475, "phrase": "suzuki's_results"}], "paper_keywords": ["Artificial neural network", " The essential order of approximation", " Modulus of smoothness"], "paper_abstract": "For three kinds of neural networks constructed by Suzuki [Constructive function approximation by three layer artificial neural networks, Neural Networks 11 (1998) 1049-1058], by establishing both upper and lower bound estimations on approximation order, the essential approximation order of these networks is estimated and the theorem of saturation (the largest capacity of approximation) is proved. These results can precisely characterize the approximation ability of these networks and clarify the relationship among the rate of approximation, the number of hidden-layer units and the properties of approximated functions. Our paper extends and perfects the error estimations of Suzuki [Constructive function approximation by three layer artificial neural networks, Neural Networks 11 (1998) 1049-1058]. On the basis of the numerical example, we can conclude that the accuracy of our estimations outperform to the Suzuki's results. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "The essential order of approximation for Suzuki's neural networks", "paper_id": "WOS:000260066100051"}