{"auto_keywords": [{"score": 0.03200681068712548, "phrase": "traffic_bursts"}, {"score": 0.014517105445595988, "phrase": "large_number"}, {"score": 0.00481495049065317, "phrase": "interleaved_memories"}, {"score": 0.004779876533667754, "phrase": "statistics_counters"}, {"score": 0.004710489616113198, "phrase": "network_measurement"}, {"score": 0.00390894650886488, "phrase": "sram"}, {"score": 0.003646399625591736, "phrase": "line_rate"}, {"score": 0.003528244907944199, "phrase": "dram-based_architecture"}, {"score": 0.0034264254358037653, "phrase": "modern_commodity_dram"}, {"score": 0.0033890026927890058, "phrase": "counter_updates"}, {"score": 0.00336428077531883, "phrase": "multiple_memory_banks"}, {"score": 0.0032196786163178107, "phrase": "internet_consist"}, {"score": 0.0031961879138783012, "phrase": "multiple_packets"}, {"score": 0.0031267359296488118, "phrase": "relatively_short_period"}, {"score": 0.002948798472453167, "phrase": "simple_randomization_scheme"}, {"score": 0.002895291306821514, "phrase": "small_fully_associative_request_queues"}, {"score": 0.00284275228258112, "phrase": "near-perfect_load_balancing"}, {"score": 0.002780958897911242, "phrase": "memory_banks"}, {"score": 0.0026516301310428756, "phrase": "maximum_size"}, {"score": 0.002622647280008795, "phrase": "request_queues"}, {"score": 0.002584494385587982, "phrase": "diminishing_overflow_probability_guarantee"}, {"score": 0.00253758084385033, "phrase": "queuing_models"}, {"score": 0.0024642796422450755, "phrase": "flow_sizes"}, {"score": 0.0023669270875629205, "phrase": "maximum_request_queue_length"}, {"score": 0.0023154527779996213, "phrase": "small_constant"}, {"score": 0.002290135975651888, "phrase": "simulation_results"}, {"score": 0.0022239665922395104, "phrase": "proposed_statistics"}, {"score": 0.002175594509651082, "phrase": "line_rate_updates"}, {"score": 0.0021049977753042253, "phrase": "diminishing_overflow_probability"}], "paper_keywords": ["Interleaved memories", " statistics counter array", " random access memories", " queuing theory"], "paper_abstract": "Statistics counters are essential in network measurement on tracking various network statistics and implementing various network counting sketches. For such applications it is crucial to maintain a large number of statistics counters at very high speeds. On the Internet with millions of flows, potentially millions of counters are required to be updated at wirespeed of 40 Gb/s and beyond. It is widely accepted that SRAM is too costly to store such large counter arrays entirely, and DRAM is too slow to catch up with the line rate. In this paper, we propose a DRAM-based architecture that takes advantage of the performance of modern commodity DRAM by interleaving counter updates to multiple memory banks. Our architecture is based on the observation that most flows on the Internet consist of multiple packets that are transmitted during a relatively short period of time, which are referred to as traffic bursts. Our proposed architecture makes use of a simple randomization scheme and a set of small fully associative request queues to statistically guarantee a near-perfect load balancing of counter updates to the memory banks. The architecture explores the benefit of traffic bursts to greatly reduce the maximum size of the request queues while providing a diminishing overflow probability guarantee. We also develop queuing models to show that as long as the flow sizes are heavy-tailed distributed due to traffic bursts, the maximum request queue length is always bounded by a small constant. The simulation results confirm the effectiveness of our queuing models. The proposed statistics counter arrays can effectively maintain line rate updates to a large number of counters while guaranteeing a diminishing overflow probability in the system.", "paper_title": "Robust Statistics Counter Arrays with Interleaved Memories", "paper_id": "WOS:000322516200018"}