{"auto_keywords": [{"score": 0.033442073514453816, "phrase": "intrinsic_and_extrinsic_camera_parameters"}, {"score": 0.014748062932936064, "phrase": "camera_pose"}, {"score": 0.01434179617773818, "phrase": "intrinsic_camera_parameters"}, {"score": 0.010207908977816985, "phrase": "energy_minimization_framework"}, {"score": 0.009573632759979299, "phrase": "zoom_values"}, {"score": 0.00481495049065317, "phrase": "dynamic_intrinsic_parameter_change"}, {"score": 0.004232232993872917, "phrase": "augmented_reality"}, {"score": 0.003935892934907777, "phrase": "virtual_objects"}, {"score": 0.0038885527668812807, "phrase": "real_environment"}, {"score": 0.003765067028482197, "phrase": "through-based_ar"}, {"score": 0.0036898803847106023, "phrase": "image_magnification"}, {"score": 0.0035726811019151984, "phrase": "camera's_field"}, {"score": 0.003229815147800001, "phrase": "novel_method"}, {"score": 0.003003452468800793, "phrase": "offline_stages"}, {"score": 0.0029672941061574375, "phrase": "intrinsic_camera_parameter_change"}, {"score": 0.002861402531078998, "phrase": "offline_stage"}, {"score": 0.0027260525536580912, "phrase": "online_stage"}, {"score": 0.0026181517251690606, "phrase": "conventional_marker-based_method"}, {"score": 0.0025761937402886954, "phrase": "camera_parameters"}, {"score": 0.002504374718975704, "phrase": "epipolar_constraint"}, {"score": 0.0023762535034673017, "phrase": "novel_energy_function"}, {"score": 0.002254672021120091, "phrase": "proposed_method"}, {"score": 0.002227508035618043, "phrase": "accurate_camera_parameter_estimation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Camera pose estimation", " Augmented reality", " Zoomable camera", " Epipolar constraint"], "paper_abstract": "In this paper, we propose a method for estimating the camera pose for an environment in which the intrinsic camera parameters change dynamically. In video see-through augmented reality (AR) technology, image-based methods for estimating the camera pose are used to superimpose virtual objects onto the real environment. In general, video see-through-based AR cannot change the image magnification that results from a change in the camera's field-of-view because of the difficulty of dealing with changes in the intrinsic camera parameters. To remove this limitation, we propose a novel method for simultaneously estimating the intrinsic and extrinsic camera parameters based on an energy minimization framework. Our method is composed of both online and offline stages. An intrinsic camera parameter change depending on the zoom values is calibrated in the offline stage. Intrinsic and extrinsic camera parameters are then estimated based on the energy minimization framework in the online stage. In our method, two energy terms are added to the conventional marker-based method to estimate the camera parameters: reprojection errors based on the epipolar constraint and the constraint of the continuity of zoom values. By using a novel energy function, our method can accurately estimate intrinsic and extrinsic camera parameters. We confirmed experimentally that the proposed method can achieve accurate camera parameter estimation during camera zooming. (C) 2014 The Authors. Published by Elsevier Ltd.", "paper_title": "Camera pose estimation under dynamic intrinsic parameter change for augmented reality", "paper_id": "WOS:000343842400002"}