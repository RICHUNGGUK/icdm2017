{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "programmability_proxy"}, {"score": 0.03363896917055258, "phrase": "larger_application"}, {"score": 0.00453113241842654, "phrase": "test_beds"}, {"score": 0.004263972370406983, "phrase": "new_algorithms"}, {"score": 0.004161553532799662, "phrase": "data_structures"}, {"score": 0.004012500850311087, "phrase": "programming_models"}, {"score": 0.003775803846431323, "phrase": "larger_applications"}, {"score": 0.0033433365160336842, "phrase": "prototyped_change"}, {"score": 0.0022371907579775796, "phrase": "large_applications"}], "paper_keywords": ["Languages", " Measurement", " Performance", " Programmability Proxy", " miniapp", " benchmark", " POP", " conjugate gradient", " parallel programming"], "paper_abstract": "Miniapps serve as test beds for prototyping and evaluating new algorithms, data structures, and programming models before incorporating such changes into larger applications. For the miniapp to accurately predict how a prototyped change would affect a larger application it is necessary that the miniapp be shown to serve as a proxy for that larger application. Although many benchmarks claim to proxy the performance for a set of large applications, little work has explored what criteria must be met for a benchmark to serve as a proxy for examining programmability. In this poster we describe criteria that can be used to establish that a miniapp serves as a performance and programmability proxy.", "paper_title": "Establishing a Miniapp as a Programmability Proxy", "paper_id": "WOS:000309350200055"}