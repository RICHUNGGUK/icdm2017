{"auto_keywords": [{"score": 0.04466781698087983, "phrase": "target_category"}, {"score": 0.036514819179016056, "phrase": "search_session"}, {"score": 0.00481495049065317, "phrase": "image_category_search"}, {"score": 0.004767261858417823, "phrase": "mental_picture"}, {"score": 0.004642377903273107, "phrase": "image_database"}, {"score": 0.004596390584582711, "phrase": "\"query_image"}, {"score": 0.004402295697276237, "phrase": "visual_similarity"}, {"score": 0.004315487055548749, "phrase": "additional_instances"}, {"score": 0.004105850229681625, "phrase": "query_image"}, {"score": 0.003829290275367182, "phrase": "subjective_visual_patterns"}, {"score": 0.003803939387792038, "phrase": "psychological_impressions"}, {"score": 0.0037662262006579023, "phrase": "\"_mental_pictures"}, {"score": 0.003691913669486176, "phrase": "image_databases"}, {"score": 0.003595097948724078, "phrase": "reliable_semantic_annotations"}, {"score": 0.003408990700300338, "phrase": "\"page_zero_problem"}, {"score": 0.003341703245432554, "phrase": "new_statistical_framework"}, {"score": 0.003308557560574077, "phrase": "relevance_feedback"}, {"score": 0.0032324864013225166, "phrase": "semantic_category"}, {"score": 0.0032004205378150354, "phrase": "unstructured_image_database"}, {"score": 0.0031686717525002935, "phrase": "semantic_annotation"}, {"score": 0.0030855348881460107, "phrase": "random_sample"}, {"score": 0.002877502286766111, "phrase": "displayed_images"}, {"score": 0.0027741761880779535, "phrase": "target_class"}, {"score": 0.002510801832283111, "phrase": "standard_techniques"}, {"score": 0.002420611343093316, "phrase": "bayesian_formulation"}, {"score": 0.0023886223145816376, "phrase": "large_databases"}, {"score": 0.00234142781099973, "phrase": "response_model"}, {"score": 0.0023028105026714533, "phrase": "user's_subjective_perception"}, {"score": 0.0022648286660146314, "phrase": "display_algorithm"}, {"score": 0.0021762030438262046, "phrase": "real_users"}, {"score": 0.0021049977753042253, "phrase": "search_process"}], "paper_keywords": ["Image retrieval", " relevance feedback", " page zero problem", " mental matching", " Bayesian system", " statistical learning"], "paper_abstract": "Starting from a member of an image database designated the \"query image,\" traditional image retrieval techniques, for example, search by visual similarity, allow one to locate additional instances of a target category residing in the database. However, in many cases, the query image or, more generally, the target category, resides only in the mind of the user as a set of subjective visual patterns, psychological impressions, or \" mental pictures.\" Consequently, since image databases available today are often unstructured and lack reliable semantic annotations, it is often not obvious how to initiate a search session; this is the \"page zero problem.\" We propose a new statistical framework based on relevance feedback to locate an instance of a semantic category in an unstructured image database with no semantic annotation. A search session is initiated from a random sample of images. At each retrieval round, the user is asked to select one image from among a set of displayed images-the one that is closest in his opinion to the target class. The matching is then \"mental.\" Performance is measured by the number of iterations necessary to display an image which satisfies the user, at which point standard techniques can be employed to display other instances. Our core contribution is a Bayesian formulation which scales to large databases. The two key components are a response model which accounts for the user's subjective perception of similarity and a display algorithm which seeks to maximize the flow of information. Experiments with real users and two databases of 20,000 and 60,000 images demonstrate the efficiency of the search process.", "paper_title": "A Statistical Framework for Image Category Search from a Mental Picture", "paper_id": "WOS:000265100000010"}