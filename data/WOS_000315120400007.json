{"auto_keywords": [{"score": 0.03221581422402985, "phrase": "finite-state_hidden_markov_models"}, {"score": 0.00481495049065317, "phrase": "hidden_markov_models"}, {"score": 0.004404994123834589, "phrase": "mild_assumptions"}, {"score": 0.0040298010803060495, "phrase": "large_numbers"}, {"score": 0.0038789122930433305, "phrase": "central_limit_theorem"}, {"score": 0.0037336520904376687, "phrase": "error_estimate"}, {"score": 0.003164342007653559, "phrase": "chernoff"}, {"score": 0.0026475981474045414, "phrase": "information_theory"}, {"score": 0.002360796860462937, "phrase": "limit_theorems"}, {"score": 0.0021049977753042253, "phrase": "maximum_likelihood"}], "paper_keywords": ["Entropy", " hidden Markov models", " limit theorem", " Shannon-McMillan-Breiman theorem"], "paper_abstract": "In this paper, under mild assumptions, we derive a law of large numbers, a central limit theorem with an error estimate, an almost sure invariance principle, and a variant of the Chernoff bound in finite-state hidden Markov models. These limit theorems are of interest in certain areas of information theory and statistics. Particularly, we apply the limit theorems to derive the rate of convergence of the maximum likelihood estimator in finite-state hidden Markov models.", "paper_title": "Limit Theorems in Hidden Markov Models", "paper_id": "WOS:000315120400007"}