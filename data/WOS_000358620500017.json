{"auto_keywords": [{"score": 0.03734218400951655, "phrase": "respiratory_rates"}, {"score": 0.015719716506582538, "phrase": "respiratory_rate"}, {"score": 0.015580713050369914, "phrase": "photoplethysmographic_imaging_videos"}, {"score": 0.004708056866527125, "phrase": "pulse_oximetry"}, {"score": 0.0043619799095455415, "phrase": "camera_lens"}, {"score": 0.004322967486451877, "phrase": "amobile_phone"}, {"score": 0.0041891398413899435, "phrase": "smart_fusion"}, {"score": 0.00415166680936294, "phrase": "empirical_mode_decomposition"}, {"score": 0.004023120753104693, "phrase": "previously_developed_signal_processing_methods"}, {"score": 0.003916098498242888, "phrase": "respiratory_induced_variations"}, {"score": 0.0038810583785936505, "phrase": "photoplethysmographic_signals"}, {"score": 0.0037778009042360758, "phrase": "custom-built_software"}, {"score": 0.0037272031155266556, "phrase": "android_phone"}, {"score": 0.003361069456060196, "phrase": "algorithms'_performance"}, {"score": 0.00333097896868937, "phrase": "mobile_phone_data"}, {"score": 0.0033011569787033297, "phrase": "clinical_data"}, {"score": 0.003198860258228543, "phrase": "reference_respiratory_rates"}, {"score": 0.003044455555031339, "phrase": "insufficient_respiratory_information"}, {"score": 0.0030036501770192865, "phrase": "photoplethysmographic_imaging_data"}, {"score": 0.002910545717767559, "phrase": "root_mean_square_error"}, {"score": 0.0027452053065200152, "phrase": "pulse_oximeter"}, {"score": 0.0025892330566358503, "phrase": "data_sources"}, {"score": 0.0025089420019955232, "phrase": "emd_method"}, {"score": 0.002453116398642071, "phrase": "inconsistent_results"}, {"score": 0.002262209824105154, "phrase": "mobile_phone_camera"}, {"score": 0.0021049977753042253, "phrase": "data_source"}], "paper_keywords": ["Empiricalmode decomposition", " photoplethysmographic imaging", " pulse oximetry", " respiratory rate", " vital signs from video"], "paper_abstract": "We present a study evaluating two respiratory rate estimation algorithms using videos obtained from placing a finger on the camera lens of amobile phone. The two algorithms, based on Smart Fusion and empirical mode decomposition (EMD), consist of previously developed signal processing methods to detect features and extract respiratory induced variations in photoplethysmographic signals to estimate respiratory rate. With custom-built software on an Android phone, photoplethysmographic imaging videos were recorded from 19 healthy adults while breathing spontaneously at respiratory rates between 6 to 32 breaths/min. Signals from two pulse oximeters were simultaneously recorded to compare the algorithms' performance using mobile phone data and clinical data. Capnometry was recorded to obtain reference respiratory rates. Two hundred seventy-two recordings were analyzed. The Smart Fusion algorithm reported 39 recordings with insufficient respiratory information from the photoplethysmographic imaging data. Of the 232 remaining recordings, a root mean square error (RMSE) of 6 breaths/min was obtained. The RMSE for the pulse oximeter datawas lower at 2.3 breaths/min. RMSEfor the EMDmethod was higher throughout all data sources as, unlike the Smart Fusion, the EMD method did not screen for inconsistent results. The study showed that it is feasible to estimate respiratory rates by placing a finger on a mobile phone camera, but that it becomes increasingly challenging at respiratory rates greater than 20 breaths/min, independent of data source or algorithm tested.", "paper_title": "Estimation of Respiratory Rate From Photoplethysmographic Imaging Videos Compared to Pulse Oximetry", "paper_id": "WOS:000358620500017"}