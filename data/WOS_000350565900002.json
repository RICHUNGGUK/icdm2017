{"auto_keywords": [{"score": 0.033961708538626435, "phrase": "else"}, {"score": 0.01314898453423896, "phrase": "accuracy_variability"}, {"score": 0.008162713071976427, "phrase": "design_space"}, {"score": 0.00481495049065317, "phrase": "architectural_design_spaces"}, {"score": 0.004771905408750457, "phrase": "base_models"}, {"score": 0.004479855062309818, "phrase": "machine_learning"}, {"score": 0.004450568197899267, "phrase": "statistical_techniques"}, {"score": 0.004363846362238565, "phrase": "regression_models"}, {"score": 0.004278807087784626, "phrase": "architectural_configurations"}, {"score": 0.003967835031625103, "phrase": "different_design_spaces"}, {"score": 0.00376488621224566, "phrase": "high_risk"}, {"score": 0.0036673238814279286, "phrase": "previous_modeling_tasks"}, {"score": 0.003548905904860611, "phrase": "design_objective"}, {"score": 0.003502612572302602, "phrase": "new_task"}, {"score": 0.0034342984674830533, "phrase": "powerful_tools"}, {"score": 0.003237221368901582, "phrase": "robust_framework"}, {"score": 0.0031532895341013297, "phrase": "design_space_modeling"}, {"score": 0.003091767402370757, "phrase": "single_learning_technique"}, {"score": 0.0030614565460256897, "phrase": "previous_investigations"}, {"score": 0.003021502415143067, "phrase": "distinct_learning_techniques"}, {"score": 0.0029918783504666894, "phrase": "multiple_base_regression_models"}, {"score": 0.002962543869356265, "phrase": "modeling_task"}, {"score": 0.00290473242917264, "phrase": "trivial_combination"}, {"score": 0.0028857130140890787, "phrase": "different_techniques"}, {"score": 0.0028201176703481186, "phrase": "regression_model"}, {"score": 0.0027924625350414655, "phrase": "smallest_error"}, {"score": 0.0026933542552712033, "phrase": "base_regression_models"}, {"score": 0.0025977542995083646, "phrase": "accurate_predictions"}, {"score": 0.0024007585788965655, "phrase": "final_prediction_errors"}, {"score": 0.002361632539339945, "phrase": "experimental_results"}, {"score": 0.002285278663862646, "phrase": "widely_used_artificial_neural_network"}, {"score": 0.0021682027434117095, "phrase": "average_prediction_error"}, {"score": 0.0021188825171510094, "phrase": "investigated_mips"}, {"score": 0.0021049977753042253, "phrase": "power_design_spaces"}], "paper_keywords": ["Algorithms", " Design", " Experimentation"], "paper_abstract": "Architectural design spaces of microprocessors are often exponentially large with respect to the pending processor parameters. To avoid simulating all configurations in the design space, machine learning and statistical techniques have been utilized to build regression models for characterizing the relationship between architectural configurations and responses (e.g., performance or power consumption). However, this article shows that the accuracy variability of many learning techniques over different design spaces and benchmarks can be significant enough to mislead the decision-making. This clearly indicates a high risk of applying techniques that work well on previous modeling tasks (each involving a design space, benchmark, and design objective) to a new task, due to which the powerful tools might be impractical. Inspired by ensemble learning in the machine learning domain, we propose a robust framework called ELSE to reduce the accuracy variability of design space modeling. Rather than employing a single learning technique as in previous investigations, ELSE employs distinct learning techniques to build multiple base regression models for each modeling task. This is not a trivial combination of different techniques (e.g., always trusting the regression model with the smallest error). Instead, ELSE carefully maintains the diversity of base regression models and constructs a metamodel from the base models that can provide accurate predictions even when the base models are far from accurate. Consequently, we are able to reduce the number of cases in which the final prediction errors are unacceptably large. Experimental results validate the robustness of ELSE: compared with the widely used artificial neural network over 52 distinct modeling tasks, ELSE reduces the accuracy variability by about 62%. Moreover, ELSE reduces the average prediction error by 27% and 85% for the investigated MIPS and POWER design spaces, respectively.", "paper_title": "Robust Design Space Modeling", "paper_id": "WOS:000350565900002"}