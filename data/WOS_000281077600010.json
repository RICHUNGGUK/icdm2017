{"auto_keywords": [{"score": 0.04943641191677376, "phrase": "visual_search"}, {"score": 0.04872336114839414, "phrase": "photo_collections"}, {"score": 0.015667269923099636, "phrase": "unstructured_picture_collections"}, {"score": 0.01305517506491532, "phrase": "lateral_columns"}, {"score": 0.009618572059686444, "phrase": "perspective_distortions"}, {"score": 0.007993259315049909, "phrase": "spatial_memory"}, {"score": 0.004615802001043284, "phrase": "possible_effects"}, {"score": 0.004600228893803583, "phrase": "geometrical_distortions"}, {"score": 0.004584708086169002, "phrase": "visual_search_effectiveness"}, {"score": 0.004469951607635361, "phrase": "participants'_performance_results"}, {"score": 0.0043506951029334984, "phrase": "lateral_surface"}, {"score": 0.004328689762198895, "phrase": "vertical_cylinder"}, {"score": 0.00414256015958164, "phrase": "virtual_space"}, {"score": 0.004086909263004707, "phrase": "virtual_object"}, {"score": 0.004032002950217453, "phrase": "different_perspective_distortions"}, {"score": 0.003944342835697915, "phrase": "central_columns"}, {"score": 0.0038325685550319863, "phrase": "second_study"}, {"score": 0.0037239498774586897, "phrase": "initial_pilot_study"}, {"score": 0.003593999116885713, "phrase": "computer_users"}, {"score": 0.00349803055484394, "phrase": "basic_visual_tasks"}, {"score": 0.0034046158318845354, "phrase": "photo_meeting"}, {"score": 0.0032636081157166445, "phrase": "visually_familiar_photo"}, {"score": 0.0031710629942521685, "phrase": "post-experiment_questionnaires"}, {"score": 0.0029836308177984775, "phrase": "clear_opinion"}, {"score": 0.0029236411702330428, "phrase": "thumbnail_visibility"}, {"score": 0.002889204171893095, "phrase": "interaction_metaphors"}, {"score": 0.0028215388473875388, "phrase": "large_inter-individual_differences"}, {"score": 0.002746358585446922, "phrase": "iv"}, {"score": 0.002713788077665689, "phrase": "error_rates"}, {"score": 0.002654710992834754, "phrase": "performance_results"}, {"score": 0.0025317885500546287, "phrase": "participants'_visual_strategies"}, {"score": 0.0025061958206961995, "phrase": "dynamic_feature"}, {"score": 0.002480861153464561, "phrase": "qualitative_analyses"}, {"score": 0.0024724731632666235, "phrase": "participants'_behaviours"}, {"score": 0.0023982429927366907, "phrase": "locomotion_metaphor"}, {"score": 0.002373997003363685, "phrase": "perspective_views"}, {"score": 0.0023066199295447686, "phrase": "users'_individual_visual_capabilities"}, {"score": 0.0022525679373791817, "phrase": "actual_relations"}, {"score": 0.0022449500876874804, "phrase": "visual_exploration_strategies"}, {"score": 0.002237357942660354, "phrase": "geometrical_properties"}, {"score": 0.002229791415953468, "phrase": "perspective_visualisations"}, {"score": 0.002203509076886664, "phrase": "locomotion_metaphors"}, {"score": 0.0021373366163721518, "phrase": "large_unstructured_picture_collections"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Interactive 3D visualisations", " Interaction metaphors", " Picture browsers", " Visual search", " Ergonomic evaluation", " Usability"], "paper_abstract": "We present two empirical studies of visual search in dynamic 3D visualisations of large, randomly ordered, photo collections. The aim is to assess the possible effects of geometrical distortions on visual search effectiveness, efficiency and comfort, by comparing the influence of two perspective representations of photo collections on participants' performance results and subjective judgments. Thumbnails of the 1000 or so photographs in each collection are plastered on the lateral surface of a vertical cylinder, either on the inside (inner view, IV) or on the outside (outer view, OV). IV and OV suggest two different interaction metaphors: locomotion in a virtual space (IV) versus manipulation of a virtual object (DV). They also implement different perspective distortions: enlargement and distortion of lateral columns (IV) versus enlargement of central columns and dwindling plus distortion of lateral columns (OV). Presentation of results focus on the second study, S2, which involved 20 participants and offered them strictly identical interaction facilities with the two views, unlike the initial pilot study, Si (8 participants and slightly different interaction facilities between the two views). Participants in both studies were experienced computer users (average age: 25.15 years, SD: 3.13). They performed two types of basic visual tasks that are carried out repeatedly while navigating photo collections: (i) searching for a photo meeting specific, visual and thematic, criteria, the photo and its location in the collection being unknown to participants (ST1) and (ii) looking for a visually familiar photo, the location of the photo being familiar to participants (ST2). According to post-experiment questionnaires and debriefings, all participants in S2 save one judged both 3D views positively in reference to standard 2D visualisations. Half of them preferred IV over OV, four appreciated OV better, and six expressed no clear opinion. Preferences were mainly motivated by the effects of perspective distortions on thumbnail visibility. They were barely influenced by interaction metaphors (e.g., the feeling of immersion induced by IV). Despite large inter-individual differences in performance, a majority of participants carried out ST1 tasks more effectively and efficiently with IV than with OV, as regards error rates (statistically significant difference) and search times (tendency). Performance results for ST2 tasks were similar with the two views, due, probably, to the simplicity and brevity of ST2 tasks. Perspective distortions seem to have exerted less influence on participants' visual strategies than horizontal scrolling, a dynamic feature common to both views. Qualitative analyses of participants' behaviours suggest that IV has the potential to support spatial memory better than OV, presumably thanks to the locomotion metaphor. These results indicate that perspective views have the potential to facilitate and improve visual search in unstructured picture collections provided that distortions are adapted to users' individual visual capabilities. Further research is needed to better understand: (i) the actual relations between visual exploration strategies and geometrical properties of perspective visualisations and (ii) the influence of the manipulation and locomotion metaphors on spatial memory. This knowledge is necessary to further improve the comfort and effectiveness of visual search in large unstructured picture collections, using 3D visualisations. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Visual search in dynamic 3D visualisations of unstructured picture collections", "paper_id": "WOS:000281077600010"}