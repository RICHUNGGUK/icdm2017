{"auto_keywords": [{"score": 0.04283466066833854, "phrase": "objective_function"}, {"score": 0.02819806867961193, "phrase": "clustering_results"}, {"score": 0.027217304358135155, "phrase": "progressive_constraint_relaxation_technique"}, {"score": 0.00481495049065317, "phrase": "depth_control"}, {"score": 0.004780183091824403, "phrase": "progressive_constraint_relaxation"}, {"score": 0.004660453113061494, "phrase": "domain_knowledge"}, {"score": 0.004626796109657584, "phrase": "application-dependent_parameters"}, {"score": 0.004576763709613412, "phrase": "data_mining_systems"}, {"score": 0.004543708337879809, "phrase": "constraint-based_mining"}, {"score": 0.004445961412092278, "phrase": "research_attention"}, {"score": 0.004195418010131832, "phrase": "constraint_attributes"}, {"score": 0.003944606115768627, "phrase": "constrained_clustering"}, {"score": 0.00376293585033711, "phrase": "optimization_attributes"}, {"score": 0.003642070943285037, "phrase": "imposed_constraint"}, {"score": 0.003461702544605219, "phrase": "numerical_constraints"}, {"score": 0.003399466007862412, "phrase": "constraint_attribute"}, {"score": 0.0032310733124059536, "phrase": "corresponding_constraint_range"}, {"score": 0.0031960852616842207, "phrase": "numerical_constrained_clustering_problem"}, {"score": 0.003070996252787868, "phrase": "conventional_clustering_algorithms"}, {"score": 0.002876747208161839, "phrase": "intrinsic_nature"}, {"score": 0.0028455850650967477, "phrase": "numerical_constrained_clustering"}, {"score": 0.0027943943921568456, "phrase": "order_dependency"}, {"score": 0.002487835869510301, "phrase": "overall_performance"}, {"score": 0.002255431275670053, "phrase": "better_solutions"}, {"score": 0.002239103860494545, "phrase": "subsequent_iterations"}, {"score": 0.0021049977753042253, "phrase": "clustering_duality"}], "paper_keywords": ["data mining", " data clustering", " constrained clustering"], "paper_abstract": "In order to import the domain knowledge or application-dependent parameters into the data mining systems, constraint-based mining has attracted a lot of research attention recently. In this paper, the attributes employed to model the constraints are called constraint attributes and those attributes involved in the objective function to be optimized are called optimization attributes. The constrained clustering considered in this paper is conducted in such a way that the objective function of optimization attributes is optimized subject to the condition that the imposed constraint is satisfied. Explicitly, we address the problem of constrained clustering with numerical constraints, in which the constraint attribute values of any two data items in the same cluster are required to be within the corresponding constraint range. This numerical constrained clustering problem, however, cannot be dealt with by any conventional clustering algorithms. Consequently, we devise several effective and efficient algorithms to solve such a clustering problem. It is noted that due to the intrinsic nature of the numerical constrained clustering, there is an order dependency on the process of attaining the clustering, which in many cases degrades the clustering results. In view of this, we devise a progressive constraint relaxation technique to remedy this drawback and improve the overall performance of clustering results. Explicitly, by using a smaller (tighter) constraint range in earlier iterations of merge, we will have more room to relax the constraint and seek for better solutions in subsequent iterations. It is empirically shown that the progressive constraint relaxation technique is able to improve not only the execution efficiency but also the clustering duality.", "paper_title": "Constrained data clustering by depth control and progressive constraint relaxation", "paper_id": "WOS:000244647700003"}