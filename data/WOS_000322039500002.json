{"auto_keywords": [{"score": 0.04869658238235114, "phrase": "spectral_clustering"}, {"score": 0.00481495049065317, "phrase": "dictionary_learning-based"}, {"score": 0.004461761855323898, "phrase": "dictionary_learning"}, {"score": 0.004207734323806386, "phrase": "low-dimensional_subspaces"}, {"score": 0.0041586840496756474, "phrase": "high-dimensional_and_nonnegative_data"}, {"score": 0.0039218440805789965, "phrase": "affinity_matrix"}, {"score": 0.0038761135052054765, "phrase": "different_subspaces"}, {"score": 0.0038309141193444015, "phrase": "data_clustering"}, {"score": 0.00376409764683147, "phrase": "main_contribution"}, {"score": 0.0032505921489759224, "phrase": "sparse_coding_coefficients"}, {"score": 0.003212663446866794, "phrase": "nonnegative_dictionary_bases"}, {"score": 0.00304737045343781, "phrase": "proximal_point_technique"}, {"score": 0.002994178996584381, "phrase": "resulting_dl"}, {"score": 0.0029592333031063156, "phrase": "sparsity_optimization_problem"}, {"score": 0.0026624684547385718, "phrase": "extensive_experiments"}, {"score": 0.0026313840069327713, "phrase": "real-world_high-dimensional_and_nonnegative_data_sets"}, {"score": 0.0024379730432321656, "phrase": "proposed_method"}, {"score": 0.0023674192513753996, "phrase": "experimental_results"}, {"score": 0.002206290313627494, "phrase": "high_sc_performance"}, {"score": 0.0021550502873107654, "phrase": "clustering_results"}], "paper_keywords": ["Dictionary learning (DL)", " high-dimensional data", " nonnegative data", " proximal optimization", " sparsity", " spectral clustering (SC)", " subspace structure"], "paper_abstract": "In this paper, we study dictionary learning (DL) approach to identify the representation of low-dimensional subspaces from high-dimensional and nonnegative data. Such representation can be used to provide an affinity matrix among different subspaces for data clustering. The main contribution of this paper is to consider both nonnegativity and sparsity constraints together in DL such that data can be represented effectively by nonnegative and sparse coding coefficients and nonnegative dictionary bases. In the algorithm, we employ the proximal point technique for the resulting DL and sparsity optimization problem. We make use of coding coefficients to perform spectral clustering (SC) for data partitioning. Extensive experiments on real-world high-dimensional and nonnegative data sets, including text, microarray, and image data demonstrate that the proposed method can discover their subspace structures. Experimental results also show that our algorithm is computationally efficient and effective for obtaining high SC performance and interpreting the clustering results compared with the other testing methods.", "paper_title": "Dictionary Learning-Based Subspace Structure Identification in Spectral Clustering", "paper_id": "WOS:000322039500002"}