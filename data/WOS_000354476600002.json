{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "cross-language_person-entity"}, {"score": 0.004190796368475121, "phrase": "unstructured_natural_language_content"}, {"score": 0.0041084684278314305, "phrase": "authoritative_inventory"}, {"score": 0.004054479957160662, "phrase": "known_entities"}, {"score": 0.003623199939953831, "phrase": "fully_automated_components"}, {"score": 0.003413705707789296, "phrase": "ground-truth_annotations"}, {"score": 0.003216285378512588, "phrase": "completely_manual_process"}, {"score": 0.003153041030690117, "phrase": "resulting_test_collections"}, {"score": 0.0028549396580672417, "phrase": "english_wikipedia"}, {"score": 0.0027437235598539904, "phrase": "similar_number"}, {"score": 0.0026545390779533647, "phrase": "english"}, {"score": 0.002636937604432706, "phrase": "wikipedia"}, {"score": 0.00250073564820402, "phrase": "cross-language_person-name"}, {"score": 0.0022641685104794512, "phrase": "romanian"}, {"score": 0.002161542155696987, "phrase": "previously_reported_cross-language_entity"}, {"score": 0.0021050266159024626, "phrase": "spanish"}], "paper_keywords": ["natural language processing"], "paper_abstract": "The goal of entity linking is to associate references to an entity that is found in unstructured natural language content to an authoritative inventory of known entities. This article describes the construction of 6 test collections for cross-language person-entity linking that together span 22 languages. Fully automated components were used together with 2 crowdsourced validation stages to affordably generate ground-truth annotations with an accuracy comparable to that of a completely manual process. The resulting test collections each contain between 642 (Arabic) and 2,361 (Romanian) person references in non-English texts for which the correct resolution in English Wikipedia is known, plus a similar number of references for which no correct resolution into English Wikipedia is believed to exist. Fully automated cross-language person-name linking experiments with 20 non-English languages yielded a resolution accuracy of between 0.84 (Serbian) and 0.98 (Romanian), which compares favorably with previously reported cross-language entity linking results for Spanish.", "paper_title": "Cross-Language Person-Entity Linking from 20 Languages", "paper_id": "WOS:000354476600002"}