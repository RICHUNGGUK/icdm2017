{"auto_keywords": [{"score": 0.039027278312474004, "phrase": "proposed_algorithm"}, {"score": 0.015719716506582538, "phrase": "k-medoids_clustering"}, {"score": 0.004485735417293941, "phrase": "new_algorithm"}, {"score": 0.004129873531628877, "phrase": "k-means_algorithm"}, {"score": 0.00384731849108269, "phrase": "initial_medoids"}, {"score": 0.003584025547693836, "phrase": "distance_matrix"}, {"score": 0.003299460925313939, "phrase": "new_medoids"}, {"score": 0.0031845067058084583, "phrase": "iterative_step"}, {"score": 0.0028293966058473476, "phrase": "real_and_artificial_data_sets"}, {"score": 0.002455009746748708, "phrase": "adjusted_rand_index"}, {"score": 0.0023976048394496446, "phrase": "experimental_results"}, {"score": 0.0022070310530794097, "phrase": "significantly_reduced_time"}, {"score": 0.0021049977753042253, "phrase": "comparable_performance"}], "paper_keywords": ["Clustering", " K-means", " K-medoids", " Rand index"], "paper_abstract": "This paper proposes a new algorithm for K-medoids clustering which runs like the K-means algorithm and tests several methods for selecting initial medoids. The proposed algorithm calculates the distance matrix once and uses it for finding new medoids at every iterative step. To evaluate the proposed algorithm, we use some real and artificial data sets and compare with the results of other algorithms in terms of the adjusted Rand index. Experimental results show that the proposed algorithm takes a significantly reduced time ill computation with comparable performance against the partitioning around medoids. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "A simple and fast algorithm for K-medoids clustering", "paper_id": "WOS:000262178100077"}