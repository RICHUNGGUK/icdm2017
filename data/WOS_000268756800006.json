{"auto_keywords": [{"score": 0.024003077356899834, "phrase": "bam"}, {"score": 0.00481495049065317, "phrase": "bam_learning_of"}, {"score": 0.00478557489890886, "phrase": "nonlinearly_separable_tasks"}, {"score": 0.004669845451682529, "phrase": "asymmetrical_output_function"}, {"score": 0.004339108074589304, "phrase": "symmetrical_output_function"}, {"score": 0.00428629884026304, "phrase": "dual_fixed-point_behavior"}, {"score": 0.0038862297330905836, "phrase": "recently_introduced_chaotic_bam_output_function"}, {"score": 0.0036553070575015344, "phrase": "desired_attractors"}, {"score": 0.003501846136829077, "phrase": "search_space"}, {"score": 0.003438058620195309, "phrase": "recall_performance"}, {"score": 0.003293688299319582, "phrase": "chaotic_wandering"}, {"score": 0.003097865379563127, "phrase": "reinforcement_learning"}, {"score": 0.0030043508031729277, "phrase": "dual_bam_architecture"}, {"score": 0.002913650880082273, "phrase": "nonlinearly_separable_patterns"}, {"score": 0.0024842242921857705, "phrase": "cognitive_modeling_viewpoint"}, {"score": 0.0024389277933858054, "phrase": "new_bam_model"}, {"score": 0.0023507916951658455, "phrase": "engineering_perspective"}, {"score": 0.0022797772939670063, "phrase": "notable_overall_increase"}, {"score": 0.0021441057555396013, "phrase": "hybrid_model"}, {"score": 0.0021049977753042253, "phrase": "general_regression_neural_network"}], "paper_keywords": ["Bidirectional associative memory (BAM)", " chaos control", " cusp catastrophe", " hybrid model", " nonlinearly separable tasks", " prior knowledge", " reinforcement learning"], "paper_abstract": "Most bidirectional associative memory (BAM) networks use a symmetrical output function for dual fixed-point behavior. In this paper, we show that by introducing an asymmetry parameter into a recently introduced chaotic BAM output function, prior knowledge can be used to momentarily disable desired attractors from memory, hence biasing the search space to improve recall performance. This property allows control of chaotic wandering, favoring given subspaces over others. In addition, reinforcement learning can then enable a dual BAM architecture to store and recall nonlinearly separable patterns. Our results allow the same BAM framework to model three different types of learning: supervised, reinforcement, and unsupervised. This ability is very promising from the cognitive modeling viewpoint. The new BAM model is also useful from an engineering perspective; our simulations results reveal a notable overall increase in BAM learning and recall performances when using a hybrid model with the general regression neural network (GRNN).", "paper_title": "BAM Learning of Nonlinearly Separable Tasks by Using an Asymmetrical Output Function and Reinforcement Learning", "paper_id": "WOS:000268756800006"}