{"auto_keywords": [{"score": 0.015719716506582538, "phrase": "best_views"}, {"score": 0.004697655699119423, "phrase": "sketch_contour"}, {"score": 0.004444037594955185, "phrase": "novel_learning-based_approach"}, {"score": 0.003625347557965931, "phrase": "hand-drawn_sketches"}, {"score": 0.0035588302267335046, "phrase": "relevant_datasets"}, {"score": 0.0031845067058084583, "phrase": "context_information"}, {"score": 0.0030123335878664064, "phrase": "learning_framework"}, {"score": 0.002797121441432477, "phrase": "automatic_best_view_selector"}, {"score": 0.002629539710839523, "phrase": "princeton_shape_benchmark_dataset"}, {"score": 0.0021049977753042253, "phrase": "shape_retrieval_tasks"}], "paper_keywords": ["Best view selection", " Sketch-based modeling", " Context similarity", " Bag-of-features"], "paper_abstract": "In this paper, we introduce a novel learning-based approach to automatically select the best views of 3D shapes using a new prior. We think that a viewpoint of the 3D shape is reasonable if a human usually draws the shape from it. Hand-drawn sketches collected from relevant datasets are used to model this concept. We reveal the connection between sketches and viewpoints by taking context information of their contours into account. Furthermore, a learning framework is proposed to generalize this connection which aims to learn an automatic best view selector for different kinds of 3D shapes. Experiments on the Princeton Shape Benchmark dataset are conducted to demonstrate the superiority of our approach. The results show that compared with other state-of-the-art methods, our approach is not only robust but also efficient when applied to shape retrieval tasks.", "paper_title": "Learning best views of 3D shapes from sketch contour", "paper_id": "WOS:000357487500003"}