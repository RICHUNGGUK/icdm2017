{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "cross-lingual_link_discovery"}, {"score": 0.008095067505079665, "phrase": "wikipedia"}, {"score": 0.004624751696958501, "phrase": "new_problem"}, {"score": 0.004578382275810468, "phrase": "information_retrieval"}, {"score": 0.004397487039229447, "phrase": "meaningful_and_relevant_hypertext_links"}, {"score": 0.004309725894724034, "phrase": "different_languages"}, {"score": 0.004160319763461951, "phrase": "knowledge_discovery"}, {"score": 0.0040978781692373005, "phrase": "multi-lingual_knowledge_base"}, {"score": 0.0038964032225585117, "phrase": "topical_coverage"}, {"score": 0.003576286811853861, "phrase": "new_and_topically_relevant_cross-lingual_links"}, {"score": 0.003434848647927327, "phrase": "ntcir"}, {"score": 0.0033832583769880576, "phrase": "crosslink_task"}, {"score": 0.0031845067058084583, "phrase": "evaluation_framework"}, {"score": 0.002907992115184249, "phrase": "document_collections"}, {"score": 0.0025119730908615104, "phrase": "human_assessors"}, {"score": 0.002282166507956957, "phrase": "manual_assessment"}, {"score": 0.0022252591643049744, "phrase": "automatic_assessment"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Wikipedia", " Cross-lingual link discovery", " Evaluation framework", " Validation", " Assessment", " Evaluation metrics"], "paper_abstract": "Cross-Lingual Link Discovery (CLLD) is a new problem in Information Retrieval. The aim is to automatically identify meaningful and relevant hypertext links between documents in different languages. This is particularly helpful in knowledge discovery if a multi-lingual knowledge base is sparse in one language or another, or the topical coverage in each language is different; such is the case with Wikipedia. Techniques for identifying new and topically relevant cross-lingual links are a current topic of interest at NTCIR where the CrossLink task has been running since the 2011 NTCIR-9. This paper presents the evaluation framework for benchmarking algorithms for cross-lingual link discovery evaluated in the context of NTCIR-9. This framework includes topics, document collections, assessments, metrics, and a toolkit for pooling, assessment, and evaluation. The assessments are further divided into two separate sets: manual assessments performed by human assessors; and automatic assessments based on links extracted from Wikipedia itself. Using this framework we show that manual assessment is more robust than automatic assessment in the context of cross-lingual link discovery. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "An evaluation framework for cross-lingual link discovery", "paper_id": "WOS:000327287500001"}