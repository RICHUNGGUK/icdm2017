{"auto_keywords": [{"score": 0.0482733743041587, "phrase": "esn"}, {"score": 0.00481495049065317, "phrase": "crj-type_reservoir"}, {"score": 0.004753670676591174, "phrase": "echo_state_networks"}, {"score": 0.004693167092003573, "phrase": "echo_state_network"}, {"score": 0.004401955895933783, "phrase": "recurrent_neural_network"}, {"score": 0.003922378980031565, "phrase": "manual_tuning"}, {"score": 0.0037743802306714545, "phrase": "best_performance"}, {"score": 0.0035856674209019234, "phrase": "adaptation_algorithm"}, {"score": 0.0035173498506324476, "phrase": "reservoir_parameters"}, {"score": 0.0033845816848753073, "phrase": "recently_proposed_reservoir_type"}, {"score": 0.0032359856233193504, "phrase": "regular_jumps"}, {"score": 0.003015508235745547, "phrase": "average_mutual_information"}, {"score": 0.002901627749562029, "phrase": "reservoir's_neurons"}, {"score": 0.0028463059289874637, "phrase": "desired_response"}, {"score": 0.0026693851900137953, "phrase": "pre-training_process"}, {"score": 0.00236289633510808, "phrase": "comparable_performance"}, {"score": 0.0021876814398268775, "phrase": "supervised_brute-force_search"}, {"score": 0.002145942273032774, "phrase": "reservoir_parameter_space"}], "paper_keywords": ["Echo state network", " Reservoir pre-training", " Mutual information", " Nonlinear adaptive filters"], "paper_abstract": "Echo state network (ESN) had emerged as an alternative to recurrent neural network (RNN). Currently in practice, the reservoir of ESN is generated randomly, and manual tuning of its parameters is required for best performance. In this paper we present an adaptation algorithm for the reservoir parameters or \"pre-training\" of a recently proposed reservoir type called deterministically constructed cycle reservoir with regular jumps (CRJ). Pre-training is achieved by maximizing the average mutual information between the states of the reservoir's neurons and the desired response. Our method does not train the readout during the pre-training process, thus it has much lower computational cost than supervised pre-training. Reservoirs pre-trained with our method outperformed or have comparable performance to those generated using parameters reported in Ill, obtained by supervised brute-force search of the reservoir parameter space. (c) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Evolutionary pre-training for CRJ-type reservoir of echo state networks", "paper_id": "WOS:000356105100020"}