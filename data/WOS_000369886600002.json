{"auto_keywords": [{"score": 0.02726764469056726, "phrase": "clm"}, {"score": 0.00481495049065317, "phrase": "large-population_graphical_games"}, {"score": 0.00477190623242136, "phrase": "behavioral_data"}, {"score": 0.0046242451772036145, "phrase": "strictly_behavioral_data"}, {"score": 0.004481132747216135, "phrase": "linear_influence_games"}, {"score": 0.004322967486451877, "phrase": "parametric_graphical_games"}, {"score": 0.004265099930438495, "phrase": "irfan"}, {"score": 0.004226961605405158, "phrase": "ortiz"}, {"score": 0.004096082254543022, "phrase": "causal_strategic_inference"}, {"score": 0.003951453722517865, "phrase": "causal_interventions"}, {"score": 0.003916098498242888, "phrase": "stable_behavior"}, {"score": 0.0038810583785936505, "phrase": "strategic_settings"}, {"score": 0.003595552309967789, "phrase": "policy-making_analysis"}, {"score": 0.0035156341294017685, "phrase": "computational_work"}, {"score": 0.003406713877432236, "phrase": "learning_problem"}, {"score": 0.003376216135716629, "phrase": "maximum-likelihood_estimation"}, {"score": 0.0032863459256972896, "phrase": "generative_model"}, {"score": 0.0032423089921154503, "phrase": "pure-strategy_nash_equilibria"}, {"score": 0.003113696267229798, "phrase": "fundamental_interplay"}, {"score": 0.0030171910207671205, "phrase": "good_models"}, {"score": 0.0029901699209266435, "phrase": "equilibrium_behavior"}, {"score": 0.002897482096228207, "phrase": "true_number"}, {"score": 0.002708399936381754, "phrase": "sample_complexity"}, {"score": 0.002684233909102925, "phrase": "mle"}, {"score": 0.0025892330566358503, "phrase": "convex_loss_minimization"}, {"score": 0.0025316254589087973, "phrase": "sigmoidal_approximations"}, {"score": 0.0024421008630165046, "phrase": "exact_psne"}, {"score": 0.002366361492754389, "phrase": "high_probability"}, {"score": 0.0022419349154472806, "phrase": "synthetic_data"}, {"score": 0.0022118619998034742, "phrase": "u.s._congressional_voting_records"}, {"score": 0.002143247921132179, "phrase": "framework's_generality"}, {"score": 0.002124036931047162, "phrase": "potential_applicability"}, {"score": 0.0021049977753042253, "phrase": "general_graphical_games"}], "paper_keywords": ["linear influence games", " graphical games", " structure and parameter learning", " behavioral data in strategic settings"], "paper_abstract": "We consider learning, from strictly behavioral data, the structure and parameters of linear influence games (LIGs), a class of parametric graphical games introduced by Irfan and Ortiz (2014). LIGs facilitate causal strategic inference (CSI) : Making inferences from causal interventions on stable behavior in strategic settings. Applications include the identification of the most influential individuals in large (social) networks. Such tasks can also support policy-making analysis. Motivated by the computational work on LIGs, we cast the learning problem as maximum-likelihood estimation (MLE) of a generative model defined by pure-strategy Nash equilibria (PS NE). Our simple formulation uncovers the fundamental interplay between goodness-of-fit and model complexity: good models capture equilibrium behavior within the data while controlling the true number of equilibria, including those unobserved. We provide a generalization bound establishing the sample complexity for MLE in our framework. We propose several algorithms including convex loss minimization (CLM) and sigmoidal approximations. We prove that the number of exact PSNE in LIGs is small, with high probability; thus, CLM is sound. We illustrate our approach on synthetic data and real-world U.S. congressional voting records. We briefly discuss our learning framework's generality and potential applicability to general graphical games.", "paper_title": "Learning the Structure and Parameters of Large-Population Graphical Games from Behavioral Data", "paper_id": "WOS:000369886600002"}