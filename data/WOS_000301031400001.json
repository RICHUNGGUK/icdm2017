{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "sparse_approximation"}, {"score": 0.03689565391010681, "phrase": "c_columns"}, {"score": 0.00473509474652851, "phrase": "real_matrix_a"}, {"score": 0.004625506452304716, "phrase": "rank_r"}, {"score": 0.0044286400018187354, "phrase": "outer_products"}, {"score": 0.004399102320426124, "phrase": "top_k_singular_vectors"}, {"score": 0.004340614094598847, "phrase": "corresponding_singular_values"}, {"score": 0.004086853315059217, "phrase": "specific_meaning"}, {"score": 0.003978866233891427, "phrase": "good_approximations"}, {"score": 0.0038867116254051363, "phrase": "small_number"}, {"score": 0.0037713445867641393, "phrase": "simple_greedy_algorithm"}, {"score": 0.0037087324991876727, "phrase": "frobenius_norm"}, {"score": 0.0026977641744883826, "phrase": "normalized_columns"}, {"score": 0.0025740882809779913, "phrase": "greedy_solution"}, {"score": 0.002522830979240594, "phrase": "well_known_sparse_approximation_problem"}, {"score": 0.0024152394732063908, "phrase": "empirical_results"}, {"score": 0.0023513172266105982, "phrase": "previous_deterministic_approaches"}, {"score": 0.0023277839538663834, "phrase": "qr_factorizations"}, {"score": 0.0023044856709624494, "phrase": "recently_proposed_randomized_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Subset selection", " SVD", " Sparse approximation"], "paper_abstract": "Given a real matrix A is an element of R-mxn of rank r, and an integer k < r, the sum of the outer products of top k singular vectors scaled by the corresponding singular values provide the best rank-k approximation A(k) to A. When the columns of A have specific meaning, it might be desirable to find good approximations to A(k) which use a small number of columns of A. This paper provides a simple greedy algorithm for this problem in Frobenius norm, with guarantees on the performance and the number of columns chosen. The algorithm selects c columns from A with c = <(O)over tilde> (k log k/epsilon(2) eta(2)(A)) such that parallel to A - Pi(C)A parallel to(F) <= (1 + epsilon) parallel to A - A(k)parallel to(F). where C is the matrix composed of the c columns, Pi(c) is the matrix projecting the columns of A onto the space spanned by C and eta(A) is a measure related to the coherence in the normalized columns of A. The algorithm is quite intuitive and is obtained by combining a greedy solution to the generalization of the well known sparse approximation problem and an existence result on the possibility of sparse approximation. We provide empirical results on various specially constructed matrices comparing our algorithm with the previous deterministic approaches based on QR factorizations and a recently proposed randomized algorithm. The results indicate that in practice, the performance of the algorithm can be significantly better than the bounds suggest. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Column subset selection via sparse approximation of SVD", "paper_id": "WOS:000301031400001"}