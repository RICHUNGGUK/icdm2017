{"auto_keywords": [{"score": 0.039717311925460824, "phrase": "bootstrap"}, {"score": 0.00481495049065317, "phrase": "bootstrap_sampling"}, {"score": 0.00475413908468027, "phrase": "image_fusion"}, {"score": 0.00454725669814484, "phrase": "complementary_information"}, {"score": 0.004489810932879285, "phrase": "multiple_image_sensors'_data"}, {"score": 0.004294381488413906, "phrase": "new_images"}, {"score": 0.004186534737631288, "phrase": "human_visual_perception"}, {"score": 0.0041074234667687875, "phrase": "computation_processing_tasks"}, {"score": 0.0038789122930433305, "phrase": "non-parametric_and_region-based_image_fusion"}, {"score": 0.003548368289666932, "phrase": "dependence_effect"}, {"score": 0.003459191419478298, "phrase": "real_images"}, {"score": 0.00337224813954299, "phrase": "fusion_time"}, {"score": 0.003287482882222731, "phrase": "original_image"}, {"score": 0.0031643005824589917, "phrase": "small_representative_set"}, {"score": 0.0030651710672229926, "phrase": "statistical_image_formation_model"}, {"score": 0.002912963877144772, "phrase": "true_scene"}, {"score": 0.002857849698346116, "phrase": "additive_non-gaussian_distortion"}, {"score": 0.0025810006125483835, "phrase": "fused_image"}, {"score": 0.002532151331015729, "phrase": "non-parametric_aspect"}, {"score": 0.002421726275597666, "phrase": "orthogonal_series"}, {"score": 0.002360796860462937, "phrase": "obtained_results"}, {"score": 0.0023013968622710825, "phrase": "bs_method"}, {"score": 0.00227225841515826, "phrase": "better_results"}, {"score": 0.0022292394795878643, "phrase": "classical_one"}, {"score": 0.0021731423856364003, "phrase": "fused_image_quality"}, {"score": 0.0021049977753042253, "phrase": "computation_time"}], "paper_keywords": ["Region-based image fusion", " Bootstrap sampling", " Non-parametric Expectation-Maximization", " Orthogonal series estimator"], "paper_abstract": "image fusion refers to the techniques that integrate complementary information from multiple image sensors' data in a way that makes the new images more suitable for human Visual perception and reduces computation processing tasks. In this paper, we propose a non-parametric and region-based image fusion based oil the Bootstrap sampling (BS) principle, which reduces the dependence effect of pixels in real images and minimizes the fusion time. Given an original image, we randomly select a small representative set of pixels In the statistical image formation model, image sensors are described as the true scene corrupted by additive non-Gaussian distortion Then, a Non-parametric Expectation-Maximization (NEM) algorithm would be used to estimate both the model parameters and the fused image. The non-parametric aspect comes from the use of the orthogonal series' estimator. Obtained results show that the BS method gives better results than the classical one, both for fused image quality as well as for computation time. (C) 2008 Elsevier B.V All rights reserved.", "paper_title": "Non-parametric and region-based image fusion with Bootstrap sampling", "paper_id": "WOS:000274927200004"}