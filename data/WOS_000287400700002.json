{"auto_keywords": [{"score": 0.04325124255431723, "phrase": "inner_products"}, {"score": 0.010333605473831744, "phrase": "kernel_versions"}, {"score": 0.008445366163706548, "phrase": "nonlinear_mappings"}, {"score": 0.007795649262165868, "phrase": "kernel_function"}, {"score": 0.00481495049065317, "phrase": "kernel_maximum_autocorrelation_factor"}, {"score": 0.004778258911940497, "phrase": "minimum_noise_fraction_transformations"}, {"score": 0.004652016085325825, "phrase": "maximum_autocorrelation_factor"}, {"score": 0.0045464538515249085, "phrase": "minimum_noise_fraction"}, {"score": 0.004342430078306461, "phrase": "dual_formulation"}, {"score": 0.0042928648367867835, "phrase": "q-mode_analysis"}, {"score": 0.004084510791138056, "phrase": "gram_matrix"}, {"score": 0.004007083686875716, "phrase": "kernel_version"}, {"score": 0.003916098498242888, "phrase": "original_data"}, {"score": 0.003797978200741566, "phrase": "higher_dimensional_feature_space"}, {"score": 0.003697538418750941, "phrase": "kernel_trick"}, {"score": 0.0031723302551782324, "phrase": "principal_component_analysis"}, {"score": 0.0031482315914769365, "phrase": "pca"}, {"score": 0.0030648097361278856, "phrase": "kernel_mnf_analyses"}, {"score": 0.0028715299874549245, "phrase": "linear_analysis"}, {"score": 0.0026091594819333654, "phrase": "busy_motorway"}, {"score": 0.002540078552743003, "phrase": "hyperspectral_hymap_scanner_data"}, {"score": 0.0025110337774260773, "phrase": "small_agricultural_area"}, {"score": 0.0022728015376571186, "phrase": "pca."}, {"score": 0.002255431275670053, "phrase": "leading_kernel"}, {"score": 0.0021622717349518744, "phrase": "even_abruptly_varying_multi"}, {"score": 0.0021049977753042253, "phrase": "extreme_observations"}], "paper_keywords": ["Dual formulation", " kernel maximum autocorrelation factor (MAF)", " kernel minimum noise fraction (MNF)", " kernel substitution", " kernel trick", " orthogonal transformations", " Q-mode analysis"], "paper_abstract": "This paper introduces kernel versions of maximum autocorrelation factor (MAF) analysis and minimum noise fraction (MNF) analysis. The kernel versions are based upon a dual formulation also termed Q-mode analysis in which the data enter into the analysis via inner products in the Gram matrix only. In the kernel version, the inner products of the original data are replaced by inner products between nonlinear mappings into higher dimensional feature space. Via kernel substitution also known as the kernel trick these inner products between the mappings are in turn replaced by a kernel function and all quantities needed in the analysis are expressed in terms of this kernel function. This means that we need not know the nonlinear mappings explicitly. Kernel principal component analysis (PCA), kernel MAF, and kernel MNF analyses handle nonlinearities by implicitly transforming data into high (even infinite) dimensional feature space via the kernel function and then performing a linear analysis in that space. Three examples show the very successful application of kernel MAF/MNF analysis to: 1) change detection in DLR 3K camera data recorded 0.7 s apart over a busy motorway, 2) change detection in hyperspectral HyMap scanner data covering a small agricultural area, and 3) maize kernel inspection. In the cases shown, the kernel MAF/MNF transformation performs better than its linear counterpart as well as linear and kernel PCA. The leading kernel MAF/MNF variates seem to possess the ability to adapt to even abruptly varying multi and hypervariate backgrounds and focus on extreme observations.", "paper_title": "Kernel Maximum Autocorrelation Factor and Minimum Noise Fraction Transformations", "paper_id": "WOS:000287400700002"}