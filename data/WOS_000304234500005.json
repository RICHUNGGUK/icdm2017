{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "optimization_strategies"}, {"score": 0.03722306137409307, "phrase": "memory-bound_algorithms"}, {"score": 0.004724365740062236, "phrase": "memory-bound_neuroimaging_algorithms"}, {"score": 0.004462663711734448, "phrase": "cpu_performance"}, {"score": 0.0043786774510943625, "phrase": "image_resolution"}, {"score": 0.004337276328199398, "phrase": "data-parallel_computing_methods"}, {"score": 0.004195418010131832, "phrase": "high_performance"}, {"score": 0.004058180509184539, "phrase": "modern_graphical_processing_units"}, {"score": 0.003944112858235306, "phrase": "computational_times"}, {"score": 0.003725470458263889, "phrase": "gpu_resources"}, {"score": 0.003485605409687907, "phrase": "cuda_architecture"}, {"score": 0.003436242862104006, "phrase": "compute-bound_algorithms"}, {"score": 0.00332375606483146, "phrase": "variable_reuse"}, {"score": 0.0032922964156452696, "phrase": "shared_memory"}, {"score": 0.0032456625605347417, "phrase": "data_throughput"}, {"score": 0.0031845067058084583, "phrase": "heavier_thread_workloads"}, {"score": 0.0031244995579170465, "phrase": "thread_configuration"}, {"score": 0.0030802351224657673, "phrase": "single_thread_block"}, {"score": 0.002909342017421165, "phrase": "fast_but_limited_gpu_resources"}, {"score": 0.0028006988338192375, "phrase": "self-contained_structures"}, {"score": 0.0027479040199262393, "phrase": "multi-pass_approach"}, {"score": 0.0026452734009203764, "phrase": "memory_resources"}, {"score": 0.002570817338292482, "phrase": "algorithm's_access_patterns"}, {"score": 0.0024513404432665153, "phrase": "optimized_gpu_implementations"}, {"score": 0.002359759876402679, "phrase": "unoptimized_ones"}, {"score": 0.0023152577218214804, "phrase": "cpu_implementations"}, {"score": 0.0022715929119140194, "phrase": "peak_gpu_speedups"}, {"score": 0.0021659920594094407, "phrase": "non-local_means_surface_denoising_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ireland_ltd."}], "paper_keywords": ["Graphics Processing Unit (GPU)", " Performance Optimization", " Compute-bound", " Memory-bound", " CUDA", " Neuroimaging"], "paper_abstract": "As neuroimaging algorithms and technology continue to grow faster than CPU performance in complexity and image resolution, data-parallel computing methods will be increasingly important. The high performance, data-parallel architecture of modern graphical processing units (GPUs) can reduce computational times by orders of magnitude. However, its massively threaded architecture introduces challenges when GPU resources are exceeded. This paper presents optimization strategies for compute- and memory-bound algorithms for the CUDA architecture. For compute-bound algorithms, the registers are reduced through variable reuse via shared memory and the data throughput is increased through heavier thread workloads and maximizing the thread configuration for a single thread block per multiprocessor. For memory-bound algorithms, fitting the data into the fast but limited GPU resources is achieved through reorganizing the data into self-contained structures and employing a multi-pass approach. Memory latencies are reduced by selecting memory resources whose cache performance are optimized for the algorithm's access patterns. We demonstrate the strategies on two computationally expensive algorithms and achieve optimized GPU implementations that perform up to 6x faster than unoptimized ones. Compared to CPU implementations, we achieve peak GPU speedups of 129x for the 3D unbiased nonlinear image registration technique and 93x for the non-local means surface denoising algorithm. (C) 2010 Elsevier Ireland Ltd. All rights reserved.", "paper_title": "CUDA optimization strategies for compute- and memory-bound neuroimaging algorithms", "paper_id": "WOS:000304234500005"}