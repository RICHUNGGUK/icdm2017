{"auto_keywords": [{"score": 0.03530148030097879, "phrase": "med"}, {"score": 0.012421347808356334, "phrase": "rank_similarity_measures"}, {"score": 0.008854951001469592, "phrase": "associated_measure"}, {"score": 0.00765242496663571, "phrase": "maximized_effectiveness_difference"}, {"score": 0.004581373625744533, "phrase": "search_engine_results"}, {"score": 0.004494570360108983, "phrase": "relevance_judgments"}, {"score": 0.004342430078306461, "phrase": "search_service"}, {"score": 0.004179392391349015, "phrase": "proposed_algorithmic_change"}, {"score": 0.0041316803676012155, "phrase": "large_number"}, {"score": 0.0036413370053909886, "phrase": "associated_effectiveness_measure"}, {"score": 0.00346449481422526, "phrase": "effectiveness_difference"}, {"score": 0.0032585499655442404, "phrase": "optimization_problem"}, {"score": 0.0030182298705055525, "phrase": "ap"}, {"score": 0.0029837010452721663, "phrase": "err."}, {"score": 0.002949598537993663, "phrase": "experimental_validation"}, {"score": 0.0028715299874549245, "phrase": "meaningful_differences"}, {"score": 0.0028496055358577512, "phrase": "retrieval_runs"}, {"score": 0.0026091594819333654, "phrase": "rank_similarity"}, {"score": 0.002444544487772349, "phrase": "previous_proposals"}, {"score": 0.0023525950486853937, "phrase": "user_behavior"}, {"score": 0.002325689073229477, "phrase": "established_effectiveness_measure"}, {"score": 0.002290291401956985, "phrase": "corresponding_rank_similarity_measure"}, {"score": 0.0022211005680689666, "phrase": "partial_relevance_judgments"}, {"score": 0.0021872912745910127, "phrase": "complete_relevance_information"}, {"score": 0.0021212055097236527, "phrase": "simple_difference"}, {"score": 0.0021049977753042253, "phrase": "effectiveness_values"}], "paper_keywords": ["Search", " rank similarity", " information retrieval", " effectiveness measures", " search engines"], "paper_abstract": "Rank similarity measures provide a method for quantifying differences between search engine results without the need for relevance judgments. For example, the providers of a search service might use such measures to estimate the impact of a proposed algorithmic change across a large number of queries-perhaps millions-identifying those queries where the impact is greatest. In this paper, we propose and validate a family of rank similarity measures, each derived from an associated effectiveness measure. Each member of the family is based on the maximization of effectiveness difference under this associated measure. Computing this maximized effectiveness difference (MED) requires the solution of an optimization problem that varies in difficulty, depending on the associated measure. We present solutions for several standard effectiveness measures, including nDCG, AP, and ERR. Through an experimental validation, we show that MED reveals meaningful differences between retrieval runs. Mathematically, MED is a metric, regardless of the associated measure. Prior work has established a number of other desiderata for rank similarity in the context of search, and we demonstrate that MED satisfies these requirements. Unlike previous proposals, MED allows us to directly translate assumptions about user behavior from any established effectiveness measure to create a corresponding rank similarity measure. In addition, MED cleanly accommodates partial relevance judgments, and if complete relevance information is available, it reduces to a simple difference between effectiveness values.", "paper_title": "A Family of Rank Similarity Measures Based on Maximized Effectiveness Difference", "paper_id": "WOS:000362943700001"}