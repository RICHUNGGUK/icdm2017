{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "thread_row_buffers"}, {"score": 0.01409993695545415, "phrase": "dram_memories"}, {"score": 0.00802611932951522, "phrase": "cache_dram."}, {"score": 0.0046695744138206575, "phrase": "throughput"}, {"score": 0.004628223381645729, "phrase": "multiprogrammed_environments"}, {"score": 0.004567596860086148, "phrase": "widespread_adoption"}, {"score": 0.004527619017250708, "phrase": "chip_multiprocessors"}, {"score": 0.004238682850598745, "phrase": "memory_access_patterns"}, {"score": 0.004092168350316413, "phrase": "row_buffer_locality"}, {"score": 0.0040385352882334235, "phrase": "degrading_performance"}, {"score": 0.004003169429008801, "phrase": "energy_efficiency"}, {"score": 0.0039333604469462356, "phrase": "concurrent_execution"}, {"score": 0.003780692127133743, "phrase": "performance_isolation"}, {"score": 0.003698442219929622, "phrase": "memory_controller"}, {"score": 0.0035705347414368726, "phrase": "virtualized_environments"}, {"score": 0.003539252646181146, "phrase": "existing_dram_memories"}, {"score": 0.0030608148631528767, "phrase": "active_row"}, {"score": 0.002981026404927824, "phrase": "dram_efficiency"}, {"score": 0.002941913249957503, "phrase": "alternate_accesses"}, {"score": 0.002903311792572216, "phrase": "limited_number"}, {"score": 0.002790511479398411, "phrase": "memory_scheduler"}, {"score": 0.002729744174693491, "phrase": "throughput-isolation_tradeoff"}, {"score": 0.002682081928174866, "phrase": "service_partitioning"}, {"score": 0.0025892330566358503, "phrase": "row_hit-rate"}, {"score": 0.0023708980662168547, "phrase": "overall_performance"}, {"score": 0.002238930800075706, "phrase": "standard_deviation"}, {"score": 0.0022095328812245852, "phrase": "memory_access_time"}, {"score": 0.0021049977753042253, "phrase": "par-bs"}], "paper_keywords": ["Memory controllers", " DRAM", " thread row buffers"], "paper_abstract": "The widespread adoption of chip multiprocessors in recent years has increased the number of applications simultaneously accessing DRAM memories. Therefore, memory access patterns have also changed and this has reduced row buffer locality significantly, degrading performance and energy efficiency. Furthermore, concurrent execution of applications also has shown the need of performance isolation among threads in the memory controller to enforce a quality of service in virtualized environments. Existing DRAM memories, however, enforce a tradeoff between throughput and isolation. To solve these problems, this paper proposes the addition of Thread Row Buffers (TRBs) to DRAM memories. TRBs keep an active row per thread, thereby increasing DRAM efficiency by avoiding alternate accesses to a limited number of rows and allowing the implementation of a memory scheduler not bound to the throughput-isolation tradeoff. Thread Row Buffers with Service Partitioning (TRB-SP) increase the row hit-rate by 38 percent with respect to FR-FCFS and by 11 percent with respect to Cache DRAM. This, in turn, increases overall performance by 17 and 7 percent, respectively. TRB-SP is also able to reduce the standard deviation of the memory access time of an application by 40 percent over FR-FCFS, 31 percent over PAR-BS, and 42 percent over Cache DRAM.", "paper_title": "Thread Row Buffers: Improving Memory Performance Isolation and Throughput in Multiprogrammed Environments", "paper_id": "WOS:000322453200016"}