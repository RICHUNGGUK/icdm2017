{"auto_keywords": [{"score": 0.0440036547704531, "phrase": "weak_typicality"}, {"score": 0.02926876360393358, "phrase": "strong_typicality"}, {"score": 0.015719716506582538, "phrase": "information_divergence_measures"}, {"score": 0.01221959282601733, "phrase": "countable_alphabets"}, {"score": 0.009796197223176921, "phrase": "unified_typicality"}, {"score": 0.004010624853427534, "phrase": "finite_alphabets"}, {"score": 0.003287482882222731, "phrase": "new_definition"}, {"score": 0.0032355864829403413, "phrase": "information_divergence_measure"}, {"score": 0.0029409171055888804, "phrase": "finite_or_countably_infinite_alphabets"}, {"score": 0.0026518169452004465, "phrase": "asymptotic_equipartition_property"}, {"score": 0.0025892330566358503, "phrase": "structural_properties"}, {"score": 0.0021049977753042253, "phrase": "rate-distortion_theory"}], "paper_keywords": ["Asymptotic equipartition property", " countably infinite alphabet", " multisource network coding", " Shannon theory", " strong typicality", " weak typicality"], "paper_abstract": "Strong typicality, which is more powerful for theorem proving than weak typicality, can be applied to finite alphabets only, while weak typicality can be applied to countable alphabets. In this paper, the relation between typicality and information divergence measures is discussed. The new definition of information divergence measure in this paper leads to the definition of a unified typicality for finite or countably infinite alphabets which is stronger than both weak typicality and strong typicality. Unified typicality retains the asymptotic equipartition property and the structural properties of strong typicality, and it can potentially be used to generalize those theorems which are previously established by strong typicality to countable alphabets. The applications in rate-distortion theory and multisource network coding problems are discussed.", "paper_title": "On Information Divergence Measures and a Unified Typicality", "paper_id": "WOS:000284419900001"}