{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "kernel_centers"}, {"score": 0.004743806810821005, "phrase": "support_vector_regression_approach"}, {"score": 0.0046390482426405324, "phrase": "kernel_number"}, {"score": 0.004553510708976456, "phrase": "significant_role"}, {"score": 0.004486212539464774, "phrase": "approximation_power"}, {"score": 0.00445293569103488, "phrase": "nearly_all_kernel_methods"}, {"score": 0.004322267755421529, "phrase": "optimal_kernels"}, {"score": 0.004226778595997366, "phrase": "global_optimization_task"}, {"score": 0.0040571383470418085, "phrase": "improved_algorithm"}, {"score": 0.0039674831861175935, "phrase": "support_vector_regression"}, {"score": 0.003808209866576388, "phrase": "global_nonparametric_offline_model"}, {"score": 0.003737934295442975, "phrase": "significant_advantage"}, {"score": 0.0036826452656927877, "phrase": "support_vectors"}, {"score": 0.0034437574674180365, "phrase": "weights_varying_least_squares_support_vector_regression"}, {"score": 0.003418186564522323, "phrase": "wv-lssvr"}, {"score": 0.003102488033561956, "phrase": "multikernel_semiparametric_support_vector_regression"}, {"score": 0.0030338645940033875, "phrase": "kernel_extension"}, {"score": 0.002977835845437357, "phrase": "recursive_regression_framework"}, {"score": 0.002933756577145939, "phrase": "recursive_kernel_method"}, {"score": 0.002911961514073769, "phrase": "gaussian_process_kernel_least_squares_support_vector_regression"}, {"score": 0.0028053842615436706, "phrase": "compound_kernel_type"}, {"score": 0.0027535633837592597, "phrase": "gaussian_process_regression"}, {"score": 0.0027331033178323145, "phrase": "numerical_experiments"}, {"score": 0.002712794864739074, "phrase": "benchmark_data_sets"}, {"score": 0.0026330549554033876, "phrase": "presented_algorithms"}, {"score": 0.002603758927691463, "phrase": "wv-lssvr_algorithm"}, {"score": 0.0025844090835070986, "phrase": "higher_approximation_accuracy"}, {"score": 0.0025556529150386168, "phrase": "recursive_parametric_kernel_method"}, {"score": 0.0024620842899061614, "phrase": "clustering_approach"}, {"score": 0.0024346858809238766, "phrase": "extended_recursive_kernel_method"}, {"score": 0.0023021895404322767, "phrase": "global_approximation_accuracy"}, {"score": 0.002268088741853586, "phrase": "test_data"}, {"score": 0.0022428442879034614, "phrase": "real-time_updates"}, {"score": 0.0021687806803474367, "phrase": "real-time_identification"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Support vector machine", " Multikernel", " Recursive nonlinear identification", " Adaptive global model", " Kernel basis function"], "paper_abstract": "The optimality of the kernel number and kernel centers plays a significant role in determining the approximation power of nearly all kernel methods. However, the process of choosing optimal kernels is always formulated as a global optimization task, which is hard to accomplish. Recently, an improved algorithm called recursive reduced least squares support vector regression (IRR-LSSVR) was proposed for establishing a global nonparametric offline model. IRR-LSSVR demonstrates a significant advantage in choosing representing support vectors compared with others. Inspired by the IRR-LSSVR, a new online adaptive parametric kernel method called Weights Varying Least Squares Support Vector Regression (WV-LSSVR) is proposed in this paper using the same type of kernels and the same centers as those used in the IRR-LSSVR. Furthermore, inspired by the multikernel semiparametric support vector regression, the effect of the kernel extension is investigated in a recursive regression framework, and a recursive kernel method called Gaussian Process Kernel Least Squares Support Vector Regression (GPK-LSSVR) is proposed using a compound kernel type which is recommended for Gaussian process regression. Numerical experiments on benchmark data sets confirm the validity and effectiveness of the presented algorithms. The WV-LSSVR algorithm shows higher approximation accuracy than the recursive parametric kernel method using the centers calculated by the k-means clustering approach. The extended recursive kernel method (i.e. GPK-LSSVR) has not shown any advantage in terms of global approximation accuracy when validating the test data set without real-time updates, but it can increase modeling accuracy if real-time identification is involved. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A novel online adaptive kernel method with kernel centers determined by a support vector regression approach", "paper_id": "WOS:000326853600014"}