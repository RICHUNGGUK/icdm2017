{"auto_keywords": [{"score": 0.010283889366395401, "phrase": "entity_matching"}, {"score": 0.006186273252752373, "phrase": "precision_constraint"}, {"score": 0.00590003226621985, "phrase": "black_box"}, {"score": 0.00481495049065317, "phrase": "active_sampling"}, {"score": 0.004610058444728656, "phrase": "fundamental_issue"}, {"score": 0.00425951071471662, "phrase": "informative_training_examples"}, {"score": 0.004209269012699911, "phrase": "active_learning"}, {"score": 0.004159617445102161, "phrase": "attractive_solution"}, {"score": 0.004078157608867258, "phrase": "previous_approaches"}, {"score": 0.0040300463421312225, "phrase": "misclassification_rate"}, {"score": 0.003812896124654341, "phrase": "unsuitable_metric"}, {"score": 0.003738200814271716, "phrase": "class_imbalance"}, {"score": 0.0034811680446852054, "phrase": "recent_paper"}, {"score": 0.003453719071347967, "phrase": "arasu"}, {"score": 0.003153140905312787, "phrase": "specified_threshold"}, {"score": 0.0030913302090179967, "phrase": "proposed_technique"}, {"score": 0.0030187498405804315, "phrase": "n_input_pairs"}, {"score": 0.0029830992938695007, "phrase": "worst_case"}, {"score": 0.0029246121262946384, "phrase": "active_learning_algorithm"}, {"score": 0.0027778413437997613, "phrase": "provably_sublinear_label_complexity"}, {"score": 0.002546002312015341, "phrase": "label_complexity"}, {"score": 0.0024763626300729575, "phrase": "times_the_label_complexity"}, {"score": 0.0022606512324475584, "phrase": "optimal_classifier"}, {"score": 0.0021901023885734, "phrase": "empirical_evaluation"}], "paper_keywords": ["Algorithms", " Experimentation", " Theory", " Performance", " Entity matching", " deduplication", " active learning", " imbalanced data"], "paper_abstract": "In entity matching, a fundamental issue while training a classifier to label pairs of entities as either duplicates or nonduplicates is the one of selecting informative training examples. Although active learning presents an attractive solution to this problem, previous approaches minimize the misclassification rate (0-1 loss) of the classifier, which is an unsuitable metric for entity matching due to class imbalance (i.e., many more nonduplicate pairs than duplicate pairs). To address this, a recent paper [Arasu et al. 2010] proposes to maximize recall of the classifier under the constraint that its precision should be greater than a specified threshold. However, the proposed technique requires the labels of all n input pairs in the worst case. Our main result is an active learning algorithm that approximately maximizes recall of the classifier while respecting a precision constraint with provably sublinear label complexity (under certain distributional assumptions). Our algorithm uses as a black box any active learning module that minimizes 0-1 loss. We show that label complexity of our algorithm is at most log n times the label complexity of the black box, and also bound the difference in the recall of classifier learnt by our algorithm and the recall of the optimal classifier satisfying the precision constraint. We provide an empirical evaluation of our algorithm on several real-world matching data sets that demonstrates the effectiveness of our approach.", "paper_title": "Active Sampling for Entity Matching with Guarantees", "paper_id": "WOS:000329435400004"}