{"auto_keywords": [{"score": 0.004320421465896323, "phrase": "compositional_distributional_semantics"}, {"score": 0.004204904449336037, "phrase": "distributional_semantics"}, {"score": 0.0036224139706218916, "phrase": "composition_operations"}, {"score": 0.0032061793819537633, "phrase": "similarity_measurements"}, {"score": 0.003036832649117453, "phrase": "similarity_equations"}, {"score": 0.002915701586760994, "phrase": "important_class"}, {"score": 0.0028376361457661415, "phrase": "composition_methods"}, {"score": 0.0024111277643627154, "phrase": "input_phrases"}, {"score": 0.002252880693912436, "phrase": "strong_link"}, {"score": 0.0021049977753042253, "phrase": "convolution_kernels"}], "paper_keywords": [""], "paper_abstract": "Distributional semantics has been extended to phrases and sentences by means of composition operations. We look at how these operations affect similarity measurements, showing that similarity equations of an important class of composition methods can be decomposed into operations performed on the subparts of the input phrases. This establishes a strong link between these models and convolution kernels.", "paper_title": "When the Whole Is Not Greater Than the Combination of Its Parts: A \"Decompositional\" Look at Compositional Distributional Semantics", "paper_id": "WOS:000353049400011"}