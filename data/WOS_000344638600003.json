{"auto_keywords": [{"score": 0.036817037816123374, "phrase": "object_parameters"}, {"score": 0.00481495049065317, "phrase": "efficient_occlusive_components_analysis"}, {"score": 0.004723847090183984, "phrase": "unsupervised_learning"}, {"score": 0.004656647251517823, "phrase": "probabilistic_generative_model"}, {"score": 0.004460703838987562, "phrase": "latent_variables"}, {"score": 0.003996458454723708, "phrase": "depth_order"}, {"score": 0.003702206069379459, "phrase": "model_parameters"}, {"score": 0.0033969001271637964, "phrase": "unlabeled_set"}, {"score": 0.003300813776412652, "phrase": "occlude_one"}, {"score": 0.003253791343615811, "phrase": "exact_maximum-likelihood_learning"}, {"score": 0.0031921317979928406, "phrase": "tractable_approximations"}, {"score": 0.003043031131345537, "phrase": "truncated_variational_approach"}, {"score": 0.0030140547908298404, "phrase": "expectation_maximization"}, {"score": 0.002928765962664163, "phrase": "numerical_experiments"}, {"score": 0.0028053237950173508, "phrase": "underlying_set"}, {"score": 0.002752139271586703, "phrase": "data_noise"}, {"score": 0.002661474607275484, "phrase": "novel_version"}, {"score": 0.0025861368747446324, "phrase": "colored_bars"}, {"score": 0.0023954743066925714, "phrase": "generating_components"}, {"score": 0.0023613185213421173, "phrase": "studied_approach"}, {"score": 0.0022834993174767016, "phrase": "generative_approach"}, {"score": 0.0022188370388602813, "phrase": "occluding_components"}, {"score": 0.0021049977753042253, "phrase": "sparse_coding_approaches"}], "paper_keywords": ["generative models", " occlusion", " unsupervised learning", " sparse coding", " expectation truncation"], "paper_abstract": "We study unsupervised learning in a probabilistic generative model for occlusion. The model uses two types of latent variables: one indicates which objects are present in the image, and the other how they are ordered in depth. This depth order then determines how the positions and appearances of the objects present, specified in the model parameters, combine to form the image. We show that the object parameters can be learned from an unlabeled set of images in which objects occlude one another. Exact maximum-likelihood learning is intractable. Tractable approximations can be derived, however, by applying a truncated variational approach to Expectation Maximization (EM). In numerical experiments it is shown that these approximations recover the underlying set of object parameters including data noise and sparsity. Experiments on a novel version of the bars test using colored bars, and experiments on more realistic data, show that the algorithm performs well in extracting the generating components. The studied approach demonstrates that the multiple-causes generative approach can be generalized to extract occluding components, which links research on occlusion to the field of sparse coding approaches.", "paper_title": "Efficient Occlusive Components Analysis", "paper_id": "WOS:000344638600003"}