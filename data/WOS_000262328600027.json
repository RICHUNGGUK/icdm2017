{"auto_keywords": [{"score": 0.0392651775812754, "phrase": "training_sequence"}, {"score": 0.009199655457528724, "phrase": "probability_distribution"}, {"score": 0.00481495049065317, "phrase": "universal_simulation_with"}, {"score": 0.004762202897268383, "phrase": "fidelity_criteria"}, {"score": 0.004408729661992651, "phrase": "universal_simulation"}, {"score": 0.004265354774450696, "phrase": "memoryless_source"}, {"score": 0.004081385289516914, "phrase": "partial_extensions"}, {"score": 0.003992385826251404, "phrase": "markov_sources"}, {"score": 0.00327356326590461, "phrase": "conditional_entropy"}, {"score": 0.0031669873302916, "phrase": "simulated_sequence"}, {"score": 0.002713604305939145, "phrase": "output_sequence"}, {"score": 0.0022741894748181243, "phrase": "single-letter_expressions"}, {"score": 0.002200077887697072, "phrase": "maximum_attainable_conditional_entropy"}, {"score": 0.0021049977753042253, "phrase": "corresponding_universal_simulation_schemes"}], "paper_keywords": ["Universal simulation", " distance measures", " epsilon-contaminated model", " generalized divergence", " (rho)over-bar-distance"], "paper_abstract": "We consider the problem of universal simulation of a memoryless source (with some partial extensions to Markov sources), based on a training sequence emitted from the source. The objective is to maximize the conditional entropy of the simulated sequence given the training sequence, subject to a certain distance constraint between the probability distribution of the output sequence and the probability distribution of the input, training sequence. We derive, for several distance criteria, single-letter expressions for the maximum attainable conditional entropy as well as corresponding universal simulation schemes that asymptotically attain these maxima.", "paper_title": "Universal Simulation With Fidelity Criteria", "paper_id": "WOS:000262328600027"}