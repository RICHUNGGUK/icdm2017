{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "least-squares_support_vector_machines"}, {"score": 0.004347057700479576, "phrase": "simpler_optimization_problem"}, {"score": 0.004201381218977942, "phrase": "standard_support_vector_machines"}, {"score": 0.0036657110980445416, "phrase": "slow_testing_speed"}, {"score": 0.0031440159350875057, "phrase": "classification_problems"}, {"score": 0.0029871209444889716, "phrase": "different_reduced_training_set"}, {"score": 0.0028139168128067343, "phrase": "ls-svm."}, {"score": 0.002742787059497186, "phrase": "new_procedure"}, {"score": 0.002475755804232436, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["least-squares support vector machines", " sparse LS-SVM", " pruning method"], "paper_abstract": "The least-squares support vector machines (LS-SVM) can be obtained by solving a simpler optimization problem than that in standard support vector machines (SVM). Its shortcoming is the loss of sparseness and this usually results in slow testing speed. Several pruning methods have been proposed. It is found that these methods can be further improved for classification problems. In this paper a different reduced training set is selected to re-train LS-SVM. Then a new procedure is proposed to obtain the sparseness. The performance of the proposed method is compared with other typical ones and the results indicate that it is more effective. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Improved sparse least-squares support vector machine classifiers", "paper_id": "WOS:000239015000025"}