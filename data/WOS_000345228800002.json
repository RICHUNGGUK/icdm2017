{"auto_keywords": [{"score": 0.05007605932177463, "phrase": "communication_concurrency"}, {"score": 0.04859537978619134, "phrase": "mpi"}, {"score": 0.004739773204474094, "phrase": "flexible_mpi_endpoints"}, {"score": 0.004556901872357751, "phrase": "one-to-one_relationship"}, {"score": 0.003832198214757852, "phrase": "mpi_and_programming_models"}, {"score": 0.0035699363258657212, "phrase": "mpi_endpoints_extension"}, {"score": 0.003432044343307207, "phrase": "longstanding_one-to-one_relationship"}, {"score": 0.003378385493203297, "phrase": "mpi_processes"}, {"score": 0.0031719830393831115, "phrase": "mpi_implementation"}, {"score": 0.003097865379563127, "phrase": "separate_communication_contexts"}, {"score": 0.00266693888510356, "phrase": "mpi_operations"}, {"score": 0.002332322771009122, "phrase": "empirical_study"}, {"score": 0.0022777800735119405, "phrase": "current_multithreaded_communication_performance"}, {"score": 0.0021896891011033088, "phrase": "high_degrees"}, {"score": 0.0021049977753042253, "phrase": "peak_communication_performance"}], "paper_keywords": ["MPI", " endpoints", " hybrid parallel programming", " interoperability", " communication concurrency"], "paper_abstract": "MPI defines a one-to-one relationship between MPI processes and ranks. This model captures many use cases effectively; however, it also limits communication concurrency and interoperability between MPI and programming models that utilize threads. This paper describes the MPI endpoints extension, which relaxes the longstanding one-to-one relationship between MPI processes and ranks. Using endpoints, an MPI implementation can map separate communication contexts to threads, allowing them to drive communication independently. Endpoints also enable threads to be addressable in MPI operations, enhancing interoperability between MPI and other programming models. These characteristics are illustrated through several examples and an empirical study that contrasts current multithreaded communication performance with the need for high degrees of communication concurrency to achieve peak communication performance.", "paper_title": "Enabling communication concurrency through flexible MPI endpoints", "paper_id": "WOS:000345228800002"}