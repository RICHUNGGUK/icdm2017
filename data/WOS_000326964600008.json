{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "chinese_sentiment"}, {"score": 0.0047113960612140335, "phrase": "partitioned_self-training"}, {"score": 0.004576763709613412, "phrase": "rapid_evolution"}, {"score": 0.004195418010131832, "phrase": "increasing_demand"}, {"score": 0.00393032656248792, "phrase": "new_domains"}, {"score": 0.0038737214010638745, "phrase": "minimum_supervision"}, {"score": 0.0035766032751309677, "phrase": "chinese_sentiment_classification"}, {"score": 0.0033748847621075536, "phrase": "self-training_algorithm"}, {"score": 0.0032310733124059567, "phrase": "test_dataset"}, {"score": 0.0031386091093713706, "phrase": "classification_results"}, {"score": 0.0030048355421601705, "phrase": "pseudo-labelled_training_set"}, {"score": 0.0029400959763737364, "phrase": "unlabelled_test_set"}, {"score": 0.0028352726653271187, "phrase": "initial_classifier"}, {"score": 0.0027741761880779535, "phrase": "pseudo-labelled_training"}, {"score": 0.002675252546913683, "phrase": "standard_self-learning_cycle"}, {"score": 0.002598652897946253, "phrase": "overall_classification_results"}, {"score": 0.0023817332409567403, "phrase": "competitive_advantages"}, {"score": 0.002347378595930709, "phrase": "baseline_approaches"}, {"score": 0.0022472527731744974, "phrase": "supervised_approach"}, {"score": 0.0021049977753042253, "phrase": "labelled_documents"}], "paper_keywords": ["opinion mining", " self-training", " sentiment classification", " weakly supervised"], "paper_abstract": "With the rapid evolution of documents on the World Wide Web which express opinions, there exists an increasing demand for developing such a sentiment analysis technique that can easily adapt to new domains with minimum supervision. This article introduces a novel weakly supervised approach for Chinese sentiment classification. The approach applies a variant of self-training algorithm on two partitions split from test dataset, and combines classification results of the two partitions into a pseudo-labelled training set and an unlabelled test set, then trains an initial classifier on the pseudo-labelled training set and adopts a standard self-learning cycle to obtain the overall classification results. Experiments on the four datasets from two domains show that our approach has competitive advantages over baseline approaches; it even outperforms the supervised approach in some of the datasets despite using no labelled documents.", "paper_title": "A weakly supervised approach to Chinese sentiment classification using partitioned self-training", "paper_id": "WOS:000326964600008"}