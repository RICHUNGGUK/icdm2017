{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "traveling_salesman_problem"}, {"score": 0.004135010810625326, "phrase": "fixed_time"}, {"score": 0.0034742854447532678, "phrase": "fixed_solution_quality"}, {"score": 0.0027143926774929957, "phrase": "high-performing_ant_colony"}, {"score": 0.0023644936731468252, "phrase": "synchronous_and_asynchronous_communications"}, {"score": 0.0023303871145705954, "phrase": "different_interconnection_topologies"}, {"score": 0.002230984431056064, "phrase": "simplest_way"}, {"score": 0.0021670777282518424, "phrase": "aco_algorithms"}, {"score": 0.0021049977753042253, "phrase": "parallel_independent_runs"}], "paper_keywords": [""], "paper_abstract": "There are two reasons for parallelizing a metaheuristic if one is interested in performance: (i) given a fixed time to search, the aim is to increase the quality of the solutions found in that time; (ii) given a fixed solution quality, the aim is to reduce the time needed to find a solution not worse than that quality. In this article, we study the impact of communication when we parallelize a high-performing ant colony optimization (ACO) algorithm for the traveling salesman problem using message passing libraries. In particular, we examine synchronous and asynchronous communications on different interconnection topologies. We find that the simplest way of parallelizing the ACO algorithms, based on parallel independent runs, is surprisingly effective; we give some reasons as to why this is the case.", "paper_title": "Parallel ant colony optimization for the traveling salesman problem", "paper_id": "WOS:000241466100020"}