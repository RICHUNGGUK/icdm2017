{"auto_keywords": [{"score": 0.033075462967634923, "phrase": "transcribed_expression"}, {"score": 0.00481495049065317, "phrase": "based_ground-truth_annotation"}, {"score": 0.0047732596509542135, "phrase": "online_handwritten_mathematical_expressions"}, {"score": 0.004690952711665194, "phrase": "mathematical_expression_recognition"}, {"score": 0.004650330504968421, "phrase": "expression_level"}, {"score": 0.00443308765153716, "phrase": "different_recognition_systems"}, {"score": 0.00428146713705618, "phrase": "different_levels"}, {"score": 0.004189337956225294, "phrase": "ground-truth_data"}, {"score": 0.004046020290832207, "phrase": "symbol_segmentation"}, {"score": 0.004010960493946656, "phrase": "symbol_classification"}, {"score": 0.003907586297783078, "phrase": "whole_expression_levels"}, {"score": 0.0037903327482565097, "phrase": "ground-truthed_datasets"}, {"score": 0.003757480190200645, "phrase": "handwritten_mathematical_expressions"}, {"score": 0.0037087324991876727, "phrase": "challenging_task"}, {"score": 0.0035662378173267647, "phrase": "large_variability"}, {"score": 0.003535320700255283, "phrase": "symbol_classes"}, {"score": 0.003504670673093149, "phrase": "expression_layouts"}, {"score": 0.003340768341189764, "phrase": "manual_annotation"}, {"score": 0.0032974089700312423, "phrase": "error-prone_procedure"}, {"score": 0.003062091606343783, "phrase": "corresponding_symbols"}, {"score": 0.0030223381739019894, "phrase": "respective_model_expression"}, {"score": 0.002931569771634119, "phrase": "simple_linear_assignment_problem"}, {"score": 0.002831158147480665, "phrase": "weighted_linear_combination"}, {"score": 0.0024306740161601625, "phrase": "cost_function_terms"}, {"score": 0.002357632753637638, "phrase": "mean_symbol_assignment_rates"}, {"score": 0.0022180544041790697, "phrase": "useful_tool"}, {"score": 0.0021607883988873492, "phrase": "ground-truthed_online_mathematical_expression_datasets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Structural pattern analysis", " Shape information", " Handwriting recognition", " Linear assignment problem", " Ground-truth annotation", " Mathematical expression dataset"], "paper_abstract": "Assessment of mathematical expression recognition at expression level only is not sufficient to diagnose strengths and weaknesses of different recognition systems. In order to make assessment at different levels possible, large datasets annotated with ground-truth data at different levels, such as at symbol segmentation, symbol classification, symbol/sub-expression spatial relationships, baselines or whole expression levels, are needed. Creation of ground-truthed datasets of handwritten mathematical expressions is a challenging task due to the need to cope with a large variability of symbol classes, expression layouts, writing styles, among other issues including the fact that manual annotation is an error-prone procedure. We propose an expression matching approach where symbols in a transcribed expression are assigned to the corresponding symbols in the respective model expression. Matching is formulated as a simple linear assignment problem where matching cost is defined as a weighted linear combination of local (symbol) and global (structural) characteristics. Once a symbol-to-symbol assignment is computed, not only symbol labels but all other ground-truth data attached to the model expression can be automatically transferred to the transcribed expression. We use two independent large test sets to empirically evaluate the influence of the cost function terms on matching performance. Results show mean symbol assignment rates above 99% on both sets, suggesting the potential of the method as an useful tool for helping the creation of ground-truthed online mathematical expression datasets. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Matching based ground-truth annotation for online handwritten mathematical expressions", "paper_id": "WOS:000347747000019"}