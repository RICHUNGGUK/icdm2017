{"auto_keywords": [{"score": 0.03408947994643344, "phrase": "active_meta-learning"}, {"score": 0.03171202851278049, "phrase": "meta-example_generation"}, {"score": 0.00481495049065317, "phrase": "uncertainty_sampling_methods"}, {"score": 0.004703149944841539, "phrase": "meta-examples"}, {"score": 0.004666465805849168, "phrase": "meta-learning"}, {"score": 0.0037471850931318942, "phrase": "algorithm_performance"}, {"score": 0.003717925116469845, "phrase": "new_problems"}, {"score": 0.0036315039559860654, "phrase": "good_set"}, {"score": 0.003547084456662448, "phrase": "costly_process"}, {"score": 0.0033840673522948592, "phrase": "empirical_evaluation"}, {"score": 0.0032924448113309797, "phrase": "previous_work"}, {"score": 0.0031782684007251403, "phrase": "active_learning"}, {"score": 0.0029500270981001058, "phrase": "current_work"}, {"score": 0.0028701222153940283, "phrase": "different_uncertainty_sampling_methods"}, {"score": 0.002792375587031108, "phrase": "individual_method"}, {"score": 0.0027597018725736165, "phrase": "useful_information"}, {"score": 0.002727409429089543, "phrase": "relevant_problems"}, {"score": 0.0026431267487109543, "phrase": "outlier_detection"}, {"score": 0.002462867872567125, "phrase": "sampling_methods"}, {"score": 0.0023680783509308525, "phrase": "meta-learning_performance"}, {"score": 0.002340357706078868, "phrase": "proposed_combining_method"}, {"score": 0.0022948742034852917, "phrase": "individual_active_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Meta-Learning", " Algorithm selection", " Active Learning", " Uncertainty Sampling", " Outlier Detection"], "paper_abstract": "Meta-Learning aims to automatically acquire knowledge relating features of learning problems to the performance of learning algorithms. Each training example in Meta-Learning (i.e. each meta-example) stores features of a learning problem plus the performance obtained by a set of algorithms when evaluated on the problem. Based on a set of meta-examples, a Meta-Learner will be used to predict algorithm performance for new problems. The generation of a good set of meta-examples can be a costly process, since for each problem it is necessary to perform an empirical evaluation of the algorithms. In a previous work, we proposed the Active Meta-Learning, in which Active Learning was used to reduce the set of meta-examples by selecting only the most relevant problems for meta-example generation. In the current work, we extend our previous research by combining different Uncertainty Sampling methods for Active Meta-Learning, considering that each individual method will provide useful information to select relevant problems. We also investigated the use of Outlier Detection to remove a priori those problems considered as outliers, aiming to improve the performance of the sampling methods. In our experiments, we observed a gain in Meta-Learning performance when the proposed combining method was compared to the individual active methods being combined and also when outliers were removed from the set of problems available for meta-example generation. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Combining Uncertainty Sampling methods for supporting the generation of Meta-examples", "paper_id": "WOS:000303093000001"}