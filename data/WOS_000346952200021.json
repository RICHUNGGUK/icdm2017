{"auto_keywords": [{"score": 0.04918525798794706, "phrase": "human_limbs"}, {"score": 0.01533375605348132, "phrase": "human_multi-limb_segmentation"}, {"score": 0.004815640425350362, "phrase": "dataset"}, {"score": 0.004784795480627637, "phrase": "ecoc-graph-cut"}, {"score": 0.004521720473366683, "phrase": "research_community"}, {"score": 0.004465243405240743, "phrase": "huge_amount"}, {"score": 0.0044372687709897446, "phrase": "possible_applications"}, {"score": 0.004381841876150705, "phrase": "human-computer_interaction"}, {"score": 0.004076256554327002, "phrase": "different_points"}, {"score": 0.0040000913037139115, "phrase": "lighting_conditions"}, {"score": 0.0038762863757919237, "phrase": "human_body"}, {"score": 0.0038158228131483854, "phrase": "huge_pose_variability"}, {"score": 0.003756298824153418, "phrase": "large_annotated_datasets"}, {"score": 0.003354180941665089, "phrase": "action_annotations"}, {"score": 0.0032708180619317423, "phrase": "single_person_actions"}, {"score": 0.0032503020402680385, "phrase": "person-person_interactive_actions"}, {"score": 0.0031695126964559235, "phrase": "two-stage_approach"}, {"score": 0.003081015075417782, "phrase": "first_stage"}, {"score": 0.0029482236540308952, "phrase": "tree-structure_way"}, {"score": 0.002733723435814484, "phrase": "binary_mask"}, {"score": 0.0026741446768534824, "phrase": "gmm_color_modelling"}, {"score": 0.0026573612772397832, "phrase": "graph-cuts_theory"}, {"score": 0.0026241089938360634, "phrase": "second_stage"}, {"score": 0.0025831266474492308, "phrase": "similar_tree-structure"}, {"score": 0.0025588443155279855, "phrase": "ecoc_framework"}, {"score": 0.002510960575700234, "phrase": "limb-like_probability_maps"}, {"score": 0.00248735493939454, "phrase": "segmented_user_mask"}, {"score": 0.002440805709023898, "phrase": "multi-label_graph-cut_procedure"}, {"score": 0.0024178580026395276, "phrase": "final_multi-limb_segmentation"}, {"score": 0.002335542599406245, "phrase": "performance_improvements"}, {"score": 0.0022068324655021374, "phrase": "standard_action_recognition_methods"}, {"score": 0.0021655216339356693, "phrase": "novel_dataset"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Human limb segmentation", " ECOC", " Graph-Cuts"], "paper_abstract": "Human multi-limb segmentation in RGB images has attracted a lot of interest in the research community because of the huge amount of possible applications in fields like Human-Computer Interaction, Surveillance, eHealth, or Gaming. Nevertheless, human multi-limb segmentation is a very hard task because of the changes in appearance produced by different points of view, clothing, lighting conditions, occlusions, and number of articulations of the human body. Furthermore, this huge pose variability makes the availability of large annotated datasets difficult. In this paper, we introduce the HuPBA8k+ dataset. The dataset contains more than 8000 labeled frames at pixel precision, including more than 120 000 manually labeled samples of 14 different limbs. For completeness, the dataset is also labeled at frame-level with action annotations drawn from an 11 action dictionary which includes both single person actions and person-person interactive actions. Furthermore, we also propose a two-stage approach for the segmentation of human limbs. In the first stage, human limbs are trained using cascades of classifiers to be split in a tree-structure way, which is included in an Error-Correcting Output Codes (ECOC) framework to define a body-like probability map. This map is used to obtain a binary mask of the subject by means of GMM color modelling and Graph-Cuts theory. In the second stage, we embed a similar tree-structure in an ECOC framework to build a more accurate set of limb-like probability maps within the segmented user mask that are fed to a multi-label Graph-Cut procedure to obtain final multi-limb segmentation. The methodology is tested on the novel HuPBA8k+ dataset, showing performance improvements in comparison to state-of-the-art approaches. In addition, a baseline of standard action recognition methods for the 11 actions categories of the novel dataset is also provided. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "HuPBA8k+: Dataset and ECOC-Graph-Cut based segmentation of human limbs", "paper_id": "WOS:000346952200021"}