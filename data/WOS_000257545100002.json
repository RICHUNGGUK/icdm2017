{"auto_keywords": [{"score": 0.040192891355061745, "phrase": "bilevel_program"}, {"score": 0.00481495049065317, "phrase": "bilevel_programming"}, {"score": 0.004757227624616643, "phrase": "support_vector_machines"}, {"score": 0.004700193486903964, "phrase": "related_classification_models"}, {"score": 0.004560568143816105, "phrase": "convex_optimization_problems"}, {"score": 0.004191200981137508, "phrase": "cross-validated_estimates"}, {"score": 0.004116012194714212, "phrase": "out-of-sample_classification_error"}, {"score": 0.003969640975997097, "phrase": "cross-validation_optimization_problem"}, {"score": 0.0037371212381934853, "phrase": "outer-level_objective"}, {"score": 0.0036700484729006136, "phrase": "average_number"}, {"score": 0.003626000977962191, "phrase": "misclassified_points"}, {"score": 0.0035609154384221567, "phrase": "cross-validation_folds"}, {"score": 0.0034759420565135253, "phrase": "inner-level_constraints"}, {"score": 0.0033929894721242367, "phrase": "classification_functions"}, {"score": 0.0031367803372203498, "phrase": "selected_hyper-parameters"}, {"score": 0.002899861600151726, "phrase": "bound_constraints"}, {"score": 0.002796616969627065, "phrase": "resulting_bilevel_problem"}, {"score": 0.0027133856739937133, "phrase": "mathematical_program"}, {"score": 0.002680789041160613, "phrase": "linear_equilibrium_constraints"}, {"score": 0.0025853238923610076, "phrase": "state-of-the-art_optimization_methods"}, {"score": 0.002448446849997207, "phrase": "commonly_used_grid_search_procedures"}, {"score": 0.0021306081217770173, "phrase": "model_selection"}, {"score": 0.0021049977753042253, "phrase": "machine_learning"}], "paper_keywords": ["support vector classification", " cross-validation", " bilevel programming", " model selection", " feature selection"], "paper_abstract": "Support vector machines and related classification models require the solution of convex optimization problems that have one or more regularization hyper-parameters. Typically, the hyper-parameters are selected to minimize the cross-validated estimates of the out-of-sample classification error of the model. This cross-validation optimization problem can be formulated as a bilevel program in which the outer-level objective minimizes the average number of misclassified points across the cross-validation folds, subject to inner-level constraints such that the classification functions for each fold are (exactly or nearly) optimal for the selected hyper-parameters. Feature selection is included in the bilevel program in the form of bound constraints in the weights. The resulting bilevel problem is converted to a mathematical program with linear equilibrium constraints, which is solved using state-of-the-art optimization methods. This approach is significantly more versatile than commonly used grid search procedures, enabling, in particular, the use of models with many hyper-parameters. Numerical results demonstrate the practicality of this approach for model selection in machine learning.", "paper_title": "Classification model selection via bilevel programming", "paper_id": "WOS:000257545100002"}