{"auto_keywords": [{"score": 0.0372178806315936, "phrase": "related_surveillance_events"}, {"score": 0.015719716506582538, "phrase": "surveillance_big_data"}, {"score": 0.004774937143916685, "phrase": "video_structural_description_technology"}, {"score": 0.004656871909510407, "phrase": "emerging_paradigm"}, {"score": 0.004466519142879166, "phrase": "commonly_used_software_tools"}, {"score": 0.004248294537944227, "phrase": "tolerable_elapsed_time"}, {"score": 0.004160531596936783, "phrase": "data_volume"}, {"score": 0.004108742905942481, "phrase": "video_surveillance_devices"}, {"score": 0.004074583059879287, "phrase": "shanghai"}, {"score": 0.004040812051782239, "phrase": "china"}, {"score": 0.0037480753312398754, "phrase": "video_content"}, {"score": 0.0036400696415545813, "phrase": "potential_videos"}, {"score": 0.00347657813672945, "phrase": "raw_data"}, {"score": 0.0034476484413811987, "phrase": "low_level_features"}, {"score": 0.003376369479008885, "phrase": "video_based_task"}, {"score": 0.003279039724748895, "phrase": "semantic_based_model"}, {"score": 0.0031845067058084583, "phrase": "video_big_data"}, {"score": 0.0031448288291084, "phrase": "proposed_surveillance_video_representation_method"}, {"score": 0.0028926147550022607, "phrase": "defined_concepts"}, {"score": 0.0028091907694771613, "phrase": "traffic_sighs"}, {"score": 0.0026941587813581274, "phrase": "video_traffic_events"}, {"score": 0.0026164433143193015, "phrase": "spatial_and_temporal_relation"}, {"score": 0.002426717832834137, "phrase": "semantic_relation"}, {"score": 0.002346861891137455, "phrase": "semantic_link_network"}, {"score": 0.002298288831092204, "phrase": "video_resources"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Video structural description", " Surveillance big data", " Big data representing and organizing"], "paper_abstract": "Big data is an emerging paradigm applied to datasets whose size is beyond the ability of commonly used software tools to capture, manage, and process the data within a tolerable elapsed time. Especially, the data volume of all video surveillance devices in Shanghai, China, is up to 1 TB every day. Thus, it is important to accurately describe the video content and enable the organizing and searching potential videos in order to detect and analyze related surveillance events. Unfortunately, raw data and low level features cannot meet the video based task. In this paper, a semantic based model is proposed for representing and organizing video big data. The proposed surveillance video representation method defines a number of concepts and their relations, which allows users to use them to annotate related surveillance events. The defined concepts include person, vehicles, and traffic sighs, which can be used for annotating and representing video traffic events unambiguous. In addition, the spatial and temporal relation between objects in an event is defined, which can be used for annotating and representing the semantic relation between objects in related surveillance events. Moreover, semantic link network is used for organizing video resources based on their associations. In the application, one case study is presented to analyze the surveillance big data. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Semantic based representing and organizing surveillance big data using video structural description technology", "paper_id": "WOS:000350927300017"}