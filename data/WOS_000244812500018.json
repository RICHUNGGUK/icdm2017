{"auto_keywords": [{"score": 0.0417692326868065, "phrase": "medline_abstracts"}, {"score": 0.025620021403935284, "phrase": "conclusion_class"}, {"score": 0.00481495049065317, "phrase": "key_sentences"}, {"score": 0.0047707093928203, "phrase": "biomedical_abstracts"}, {"score": 0.0046834372388970405, "phrase": "key_word_assignment"}, {"score": 0.004555507078728864, "phrase": "medline"}, {"score": 0.004472146692254812, "phrase": "indicative_\"gist"}, {"score": 0.0042506731642425275, "phrase": "biomedical_articles"}, {"score": 0.0038756055612167942, "phrase": "long_documents"}, {"score": 0.0037006243674469657, "phrase": "unique_key_sentence"}, {"score": 0.0036496814103475174, "phrase": "key_sentence"}, {"score": 0.0035498822293046884, "phrase": "article's_content"}, {"score": 0.003468796799802612, "phrase": "abstract's_conclusions"}, {"score": 0.0034368818187904744, "phrase": "good_candidates"}, {"score": 0.003281643474564305, "phrase": "automatic_key_sentence_selector"}, {"score": 0.0031668816762956816, "phrase": "purpose"}, {"score": 0.002991823455621222, "phrase": "bayesian_classifiers"}, {"score": 0.002950608985750058, "phrase": "automatically_acquired_data"}, {"score": 0.0029234476524900794, "phrase": "features_representation"}, {"score": 0.0028172726995962147, "phrase": "classification_effectiveness"}, {"score": 0.0027275289970185015, "phrase": "confusion_matrices"}, {"score": 0.0026284507395498897, "phrase": "simple_heuristics"}, {"score": 0.0022878396720586044, "phrase": "automatic_argumentative_classification"}, {"score": 0.002266765479420981, "phrase": "bayesian_learners"}, {"score": 0.0021843879253500894, "phrase": "user_navigation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ireland_ltd."}], "paper_keywords": ["machine learning", " abstracting and indexing", " information storage and retrieval", " natural language processing", " digital libraries"], "paper_abstract": "PROBLEM: key word assignment has been largely used in MEDLINE to provide an indicative \"gist\" of the content of articles and to help retrieving biomedical articles. Abstracts are also used for this purpose. However with usually more than 300 words, MEDLINE abstracts can still be regarded as long documents; therefore we design a system to select a unique key sentence. This key sentence must be indicative of the article's content and we assume that abstract's conclusions are good candidates. We design and assess the performance of an automatic key sentence selector, which classifies sentences into four argumentative moves: PURPOSE, METHODS, RESULTS and CONCLUSION. METHODS: we rely on Bayesian classifiers trained on automatically acquired data. Features representation, selection and weighting are reported and classification effectiveness is evaluated on the four classes using confusion matrices. We also explore the use of simple heuristics to take the position of sentences into account. Recall, precision and F-scores are computed for the CONCLUSION class. For the CONCLUSION class, the F-score reaches 84%. Automatic argumentative classification using Bayesian learners is feasible on MEDLINE abstracts and should help user navigation in such repositories. (c) 2006 Elsevier Ireland Ltd. All rights reserved.", "paper_title": "Using argumentation to extract key sentences from biomedical abstracts", "paper_id": "WOS:000244812500018"}