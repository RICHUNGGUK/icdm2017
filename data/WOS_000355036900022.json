{"auto_keywords": [{"score": 0.05007747893386848, "phrase": "visual_orientation"}, {"score": 0.046840734843818926, "phrase": "sift"}, {"score": 0.00454725669814484, "phrase": "scale-invariant_feature_transform"}, {"score": 0.004240116703465252, "phrase": "local_features"}, {"score": 0.003928572641266562, "phrase": "multimedia_content_analysis"}, {"score": 0.003829877278269543, "phrase": "image_classification"}, {"score": 0.003459191419478298, "phrase": "new_path"}, {"score": 0.0034154440860550564, "phrase": "sift_research"}, {"score": 0.0029691377785333872, "phrase": "human_system"}, {"score": 0.0028761045789798103, "phrase": "visual_orientation_inhomogeneity_sift"}, {"score": 0.002733260122876447, "phrase": "better_or_at_least_comparable_performance"}, {"score": 0.0026307897899760383, "phrase": "time_cost"}, {"score": 0.002564613964408878, "phrase": "real_world_conditions"}, {"score": 0.0025000985765154028, "phrase": "image_matching"}, {"score": 0.002468450551616404, "phrase": "object_recognition"}, {"score": 0.002360796860462937, "phrase": "wider_range"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Orientation inhomogeneity", " Real-world distribution", " Scale-invariant feature transform", " Least discriminability"], "paper_abstract": "Scale-invariant feature transform (SIFT) is an algorithm to detect and describe local features in images. In the last fifteen years, SIFT plays a very important role in multimedia content analysis, such as image classification and retrieval, because of its attractive character on invariance. This paper intends to explore a new path for SIFT research by making use of the findings from neuroscience. We propose a more efficient and compact scale-invariant feature detector and descriptor by simulating visual orientation inhomogeneity in human system. We validate that visual orientation inhomogeneity SIFT (v-SIFT) can achieve better or at least comparable performance with less computation resource and time cost in various computer vision tasks under real world conditions, such as image matching and object recognition. This work also illuminates a wider range of opportunities for integrating the inhomogeneity of visual orientation with other local position-dependent detectors and descriptors. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Visual orientation inhomogeneity based scale-invariant feature transform", "paper_id": "WOS:000355036900022"}