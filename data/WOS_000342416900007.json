{"auto_keywords": [{"score": 0.039306566027447205, "phrase": "awgn-good_lattice"}, {"score": 0.03479053433256308, "phrase": "erez"}, {"score": 0.034367457885539014, "phrase": "zamir"}, {"score": 0.00481495049065317, "phrase": "awgn_channel_capacity_with"}, {"score": 0.0047846807459660376, "phrase": "lattice_gaussian_coding"}, {"score": 0.0046361494357125355, "phrase": "new_coding_scheme"}, {"score": 0.004380265418103948, "phrase": "additive_white_gaussian_noise"}, {"score": 0.004217537792708984, "phrase": "lattice_decoding"}, {"score": 0.00406083086983316, "phrase": "signal-to-noise_ratio"}, {"score": 0.0038124354878360032, "phrase": "discrete_gaussian_distribution"}, {"score": 0.00355665081072721, "phrase": "shaping_lattice"}, {"score": 0.003338992028053874, "phrase": "default_lattice_coding_scheme"}, {"score": 0.003174464741377186, "phrase": "quantization-good_lattice"}, {"score": 0.002999012736727594, "phrase": "flatness_factor"}, {"score": 0.002887450071878095, "phrase": "error_probability"}, {"score": 0.0028332303659245085, "phrase": "proposed_scheme"}, {"score": 0.0027976491158911514, "phrase": "minimum_mean-square_error_lattice_decoding"}, {"score": 0.0024968185204913935, "phrase": "awgn_channel_capacity"}, {"score": 0.0023887436047824386, "phrase": "good_constellations"}, {"score": 0.0023290951071300433, "phrase": "almost_the_same_mutual_information"}, {"score": 0.0022709326810964386, "phrase": "continuous_gaussian_inputs"}, {"score": 0.00216052800952708, "phrase": "gaussian"}, {"score": 0.0021049977753042253, "phrase": "proposed_lattice_gaussian_coding_scheme"}], "paper_keywords": ["Channel capacity", " flatness factor", " lattice coding", " lattice Gaussian distribution", " MMSE"], "paper_abstract": "We propose a new coding scheme using only one lattice that achieves the 1/2 log(1 + SNR) capacity of the additive white Gaussian noise (AWGN) channel with lattice decoding, which is provable for signal-to-noise ratio SNR > e at present. The scheme applies a discrete Gaussian distribution over an AWGN-good lattice, but otherwise does not require a shaping lattice or dither. Thus, it significantly simplifies the default lattice coding scheme of Erez and Zamir which involves a quantization-good lattice as well as an AWGN-good lattice. Using the flatness factor, we show that the error probability of the proposed scheme under minimum mean-square error lattice decoding is almost the same as that of Erez and Zamir, for any rate up to the AWGN channel capacity. We introduce the notion of good constellations, which carry almost the same mutual information as that of continuous Gaussian inputs. We also address the implementation of Gaussian shaping for the proposed lattice Gaussian coding scheme.", "paper_title": "Achieving AWGN Channel Capacity With Lattice Gaussian Coding", "paper_id": "WOS:000342416900007"}