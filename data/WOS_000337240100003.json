{"auto_keywords": [{"score": 0.004521179256835894, "phrase": "embodied_conversational_agents"}, {"score": 0.004346704947011699, "phrase": "novel_concepts"}, {"score": 0.0042119653427658025, "phrase": "interaction_management_tactics"}, {"score": 0.00414616342377235, "phrase": "responsive_human-machine_interfaces"}, {"score": 0.0038624981944755813, "phrase": "natural_visualized_speech"}, {"score": 0.003802135020791801, "phrase": "facial_expression"}, {"score": 0.0037133478610481994, "phrase": "different_body_motions"}, {"score": 0.003541923233726252, "phrase": "reactive_humanlike_communicative_behavior"}, {"score": 0.00327356326590461, "phrase": "different_behavioral_analyses"}, {"score": 0.0032223742018434856, "phrase": "realization_tactics"}, {"score": 0.0030254743224136247, "phrase": "novel_environment"}, {"score": 0.0029781530607129653, "phrase": "\"online\"_visual_modeling"}, {"score": 0.0026045914281028473, "phrase": "visual_speech"}, {"score": 0.0025638362414466278, "phrase": "nonverbal_behavior_synthesis"}, {"score": 0.0025038930574283174, "phrase": "hierarchical_xml-based_behavioral_events"}, {"score": 0.0023507916951658455, "phrase": "main_goal"}, {"score": 0.0022958180852458215, "phrase": "presented_abstract_motion_notation_scheme"}, {"score": 0.002242127152093798, "phrase": "eva-script"}, {"score": 0.0021049977753042253, "phrase": "unique_and_responsive_behavior"}], "paper_keywords": [""], "paper_abstract": "Multimodal interfaces incorporating embodied conversational agents enable the development of novel concepts with regard to interaction management tactics in responsive human-machine interfaces. Such interfaces provide several additional nonverbal communication channels, such as natural visualized speech, facial expression, and different body motions. In order to simulate reactive humanlike communicative behavior and attitude, the realization of motion relies on different behavioral analyses and realization tactics and approaches. This article proposes a novel environment for \"online\" visual modeling of humanlike communicative behavior, named EVA-framework. In this study we focus on visual speech and nonverbal behavior synthesis by using hierarchical XML-based behavioral events and expressively adjustable motion templates. The main goal of the presented abstract motion notation scheme, named EVA-Script, is to enable the synthesis of unique and responsive behavior.", "paper_title": "DESCRIBING AND ANIMATING COMPLEX COMMUNICATIVE VERBAL AND NONVERBAL BEHAVIOR USING EVA-FRAMEWORK", "paper_id": "WOS:000337240100003"}