{"auto_keywords": [{"score": 0.040980305034149664, "phrase": "mirex"}, {"score": 0.00481495049065317, "phrase": "audio_beat_tracking"}, {"score": 0.004720043307726269, "phrase": "music_tempo_extraction_algorithms"}, {"score": 0.004490842671590769, "phrase": "extended_analysis"}, {"score": 0.004402295697276237, "phrase": "eight_different_algorithms"}, {"score": 0.004315487055548749, "phrase": "musical_tempo_extraction"}, {"score": 0.0032004205378150354, "phrase": "performance_metrics"}, {"score": 0.003014576010931602, "phrase": "algorithms'_abilities"}, {"score": 0.002701361707441567, "phrase": "detailed_results"}, {"score": 0.0024941578231560055, "phrase": "algorithm_performance"}, {"score": 0.0023259039577313294, "phrase": "musical_genre"}, {"score": 0.002168975681697056, "phrase": "musical_meter"}], "paper_keywords": [""], "paper_abstract": "This is an extended analysis of eight different algorithms for musical tempo extraction and beat tracking. The algorithms participated in the 2006 Music Information Retrieval Evaluation eXchange (MIREX), where they were evaluated using a set of 140 musical excerpts, each with beats annotated by 40 different listeners. Performance metrics were constructed to measure the algorithms' abilities to predict the most perceptually salient musical beats and tempi of the excerpts. Detailed results of the evaluation are presented here and algorithm performance is evaluated as a function of musical genre, the presence of percussion, musical meter and the most salient perceptual tempo of each excerpt.", "paper_title": "Evaluation of audio beat tracking and music tempo extraction algorithms", "paper_id": "WOS:000251512100001"}