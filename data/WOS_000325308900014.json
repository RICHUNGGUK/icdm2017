{"auto_keywords": [{"score": 0.049435104149514096, "phrase": "density_power_divergence"}, {"score": 0.015719716506582538, "phrase": "noisy_oracle"}, {"score": 0.014216125793867168, "phrase": "noisy_labels"}, {"score": 0.004592016716046632, "phrase": "active_learning"}, {"score": 0.003983016985197904, "phrase": "novel_pool-based_active_learning_framework"}, {"score": 0.002724428781940696, "phrase": "evaluation_scheme"}, {"score": 0.0026157259734105, "phrase": "asymptotic_statistical_analyses"}, {"score": 0.0024111277643627154, "phrase": "estimation_error"}, {"score": 0.002330664671716791, "phrase": "benchmark_datasets"}, {"score": 0.0022992346264367374, "phrase": "real-world_image_datasets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Noisy oracle", " Active learning", " Density power divergence"], "paper_abstract": "The accuracy of active learning is critically influenced by the existence of noisy labels given by a noisy oracle. In this paper, we propose a novel pool-based active learning framework through robust measures based on density power divergence. By minimizing density power divergence, such as a-divergence and gamma-divergence, one can estimate the model accurately even under the existence of noisy labels within data. Accordingly, we develop query selecting measures for pool-based active learning using these divergences. In addition, we propose an evaluation scheme for these measures based on asymptotic statistical analyses, which enables us to perform active learning by evaluating an estimation error directly. Experiments with benchmark datasets and real-world image datasets show that our active learning scheme performs better than several baseline methods. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Active learning for noisy oracle via density power divergence", "paper_id": "WOS:000325308900014"}