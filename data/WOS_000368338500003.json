{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "test_sets"}, {"score": 0.038246058185547986, "phrase": "behavioural_coverage"}, {"score": 0.004740476936977635, "phrase": "behavioural_adequacy"}, {"score": 0.004667149874736771, "phrase": "finite_test"}, {"score": 0.004559270778306828, "phrase": "essential_behaviour"}, {"score": 0.0043509032299218955, "phrase": "well-established_problem"}, {"score": 0.004233762728640565, "phrase": "syntactic_adequacy_metrics"}, {"score": 0.0037516215763875225, "phrase": "theoretical_terms"}, {"score": 0.0035108659422301985, "phrase": "accurate_model"}, {"score": 0.003389704997952315, "phrase": "test_set"}, {"score": 0.0031597433845085092, "phrase": "theoretical_domain"}, {"score": 0.0031351720217878917, "phrase": "inferred_models"}, {"score": 0.0029110398328258194, "phrase": "pragmatic_interim_measures"}, {"score": 0.002854761308379149, "phrase": "test_set_generation"}, {"score": 0.0027886573969044042, "phrase": "practical_approach"}, {"score": 0.002599365215003002, "phrase": "standard_syntactic_testing_approaches"}, {"score": 0.0025292620341476283, "phrase": "search-based_testing_techniques"}, {"score": 0.0023946630984825207, "phrase": "empirical_study"}, {"score": 0.00234834406550549, "phrase": "java_units"}, {"score": 0.002311933249234786, "phrase": "higher_behavioural_coverage"}, {"score": 0.00228499525153, "phrase": "current_baseline_test_criteria"}, {"score": 0.0022495644368875686, "phrase": "detected_faults"}], "paper_keywords": ["test generation", " test adequacy", " search-based software testing"], "paper_abstract": "Identifying a finite test set that adequately captures the essential behaviour of a program such that all faults are identified is a well-established problem. This is traditionally addressed with syntactic adequacy metrics (e.g. branch coverage), but these can be impractical and may be misleading even if they are satisfied. One intuitive notion of adequacy, which has been discussed in theoretical terms over the past three decades, is the idea of behavioural coverage: If it is possible to infer an accurate model of a system from its test executions, then the test set can be deemed to be adequate. Despite its intuitive basis, it has remained almost entirely in the theoretical domain because inferred models have been expected to be exact (generally an infeasible task) and have not allowed for any pragmatic interim measures of adequacy to guide test set generation. This paper presents a practical approach to incorporate behavioural coverage. Our BESTEST approach (1) enables the use of machine learning algorithms to augment standard syntactic testing approaches and (2) shows how search-based testing techniques can be applied to generate test sets with respect to this criterion. An empirical study on a selection of Java units demonstrates that test sets with higher behavioural coverage significantly outperform current baseline test criteria in terms of detected faults. (c) 2015 The Authors. Software Testing, Verification and Reliability published by John Wiley & Sons, Ltd.", "paper_title": "Assessing and generating test sets in terms of behavioural adequacy", "paper_id": "WOS:000368338500003"}