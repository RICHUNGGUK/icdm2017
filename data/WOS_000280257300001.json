{"auto_keywords": [{"score": 0.04710443424650763, "phrase": "dec-pomdps"}, {"score": 0.00481495049065317, "phrase": "fixed-size_stochastic_controllers"}, {"score": 0.004693167092003573, "phrase": "decentralized_pomdps"}, {"score": 0.004401955895933783, "phrase": "rich_framework"}, {"score": 0.004345909305473054, "phrase": "sequential_decision"}, {"score": 0.004050116768809519, "phrase": "important_research_challenge"}, {"score": 0.0038973170902076707, "phrase": "intractable_memory_requirements"}, {"score": 0.0038476708316022823, "phrase": "current_algorithms"}, {"score": 0.0037262941538784094, "phrase": "agent_policies"}, {"score": 0.0036788184374592706, "phrase": "finite-state_controllers"}, {"score": 0.0034725269588525534, "phrase": "new_approach"}, {"score": 0.0033200826267264383, "phrase": "nonlinear_program"}, {"score": 0.003215295260684715, "phrase": "optimal_policy"}, {"score": 0.003154012038613403, "phrase": "desired_size"}, {"score": 0.003034916887102753, "phrase": "new_formulation"}, {"score": 0.002977061391551631, "phrase": "wide_range"}, {"score": 0.0029391032882625473, "phrase": "powerful_nonlinear_programming_algorithms"}, {"score": 0.00270389431876454, "phrase": "nlp"}, {"score": 0.0025034338848015166, "phrase": "off-the-shelf_optimization_method"}, {"score": 0.0024399717841513354, "phrase": "state-of-the-art_pomdp_algorithms"}, {"score": 0.0023934306706217797, "phrase": "state-of-the-art_dec-pomdp_algorithms"}, {"score": 0.00220177373403577, "phrase": "research_directions"}, {"score": 0.0021049977753042253, "phrase": "nonlinear_programming_methods"}], "paper_keywords": ["Decision theory", " Multiagent systems", " Planning under uncertainty", " POMDPs", " DEC-POMDPs"], "paper_abstract": "POMDPs and their decentralized multiagent counterparts, DEC-POMDPs, offer a rich framework for sequential decision making under uncertainty. Their high computational complexity, however, presents an important research challenge. One way to address the intractable memory requirements of current algorithms is based on representing agent policies as finite-state controllers. Using this representation, we propose a new approach that formulates the problem as a nonlinear program, which defines an optimal policy of a desired size for each agent. This new formulation allows a wide range of powerful nonlinear programming algorithms to be used to solve POMDPs and DEC-POMDPs. Although solving the NLP optimally is often intractable, the results we obtain using an off-the-shelf optimization method are competitive with state-of-the-art POMDP algorithms and outperform state-of-the-art DEC-POMDP algorithms. Our approach is easy to implement and it opens up promising research directions for solving POMDPs and DEC-POMDPs using nonlinear programming methods.", "paper_title": "Optimizing fixed-size stochastic controllers for POMDPs and decentralized POMDPs", "paper_id": "WOS:000280257300001"}