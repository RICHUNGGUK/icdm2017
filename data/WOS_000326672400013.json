{"auto_keywords": [{"score": 0.04893638421315736, "phrase": "hybrid_infill_strategy"}, {"score": 0.0450260882774516, "phrase": "surrogate-based_optimization"}, {"score": 0.0404616772403515, "phrase": "surrogate_accuracy"}, {"score": 0.00481495049065317, "phrase": "rbf_neural_network"}, {"score": 0.004745665541429529, "phrase": "linear_interpolation"}, {"score": 0.004435230698216773, "phrase": "costly_models"}, {"score": 0.004185289462328125, "phrase": "accurate_models"}, {"score": 0.0041450181887917135, "phrase": "cheap_surrogates"}, {"score": 0.0037267132967205136, "phrase": "available_training_samples"}, {"score": 0.0033021988455635403, "phrase": "real_global_optimum"}, {"score": 0.0032546105164772995, "phrase": "accurate_model"}, {"score": 0.0028421434495262796, "phrase": "rbfnn_accuracy"}, {"score": 0.0027876387169652717, "phrase": "gradient_match"}, {"score": 0.002655894070657161, "phrase": "training_samples"}, {"score": 0.0025059724686541263, "phrase": "surrogate_prediction_error"}, {"score": 0.0024224481033945943, "phrase": "optimization_objective"}, {"score": 0.0023759728305710365, "phrase": "promising_region"}, {"score": 0.002319127685733821, "phrase": "linear_interpolation-based_sequential_sampling_approach"}, {"score": 0.0022094759531152072, "phrase": "extensive_tests"}, {"score": 0.0021049977753042253, "phrase": "proposed_methods"}], "paper_keywords": ["RBF neural network", " width optimization", " linear interpolation", " infill strategy", " sequential sampling", " surrogate-based optimization"], "paper_abstract": "In engineering, it is computationally prohibitive to directly employ costly models in optimization. Therefore, surrogate-based optimization is developed to replace the accurate models with cheap surrogates during optimization for efficiency. The two key issues of surrogate-based optimization are how to improve the surrogate accuracy by making the most of the available training samples, and how to sequentially augment the training set with certain infill strategy so as to gradually improve the surrogate accuracy and guarantee the convergence to the real global optimum of the accurate model. To address these two issues, a radial basis function neural network (RBFNN) based optimization method is proposed in this paper. First, a linear interpolation (LI) based RBFNN modelling method, LI-RBFNN, is developed, which can enhance the RBFNN accuracy by enforcing the gradient match between the surrogate and the trend observed from the training samples. Second, a hybrid infill strategy is proposed, which uses the surrogate prediction error based surrogate lower bound as the optimization objective to locate the promising region and meanwhile employs a linear interpolation-based sequential sampling approach to improve the surrogate accuracy globally. Finally, extensive tests are investigated and the effectiveness and efficiency of the proposed methods are demonstrated.", "paper_title": "A surrogate-based optimization method with RBF neural network enhanced by linear interpolation and hybrid infill strategy", "paper_id": "WOS:000326672400013"}