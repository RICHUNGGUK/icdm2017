{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "coupled_recurrent_networks"}, {"score": 0.0047515546458205046, "phrase": "conditional_branching"}, {"score": 0.00470975295439431, "phrase": "possible_behavioral_states"}, {"score": 0.004606843145343611, "phrase": "intelligent_behavior"}, {"score": 0.004446823283475876, "phrase": "neuronal_mechanisms"}, {"score": 0.004124920849728372, "phrase": "theoretical_analysis"}, {"score": 0.004016938499717623, "phrase": "richly_interconnected_neurons"}, {"score": 0.003877329308854808, "phrase": "superficial_layers"}, {"score": 0.003660700128133065, "phrase": "multistable_neuronal_network"}, {"score": 0.003149471116658739, "phrase": "recurrent_cross-connections"}, {"score": 0.003013129637451091, "phrase": "required_states"}, {"score": 0.0028195727965553367, "phrase": "current_state"}, {"score": 0.0026267609106294817, "phrase": "small_number"}, {"score": 0.0026036031415940563, "phrase": "transition_neurons"}, {"score": 0.0025692477422626678, "phrase": "necessary_input-driven_transitions"}, {"score": 0.0024798279465139688, "phrase": "simple_rules"}, {"score": 0.0024148064819862337, "phrase": "neuronal_state_machines"}, {"score": 0.0021809311689473493, "phrase": "broad_range"}, {"score": 0.002161695357601592, "phrase": "sophisticated_processing"}], "paper_keywords": [""], "paper_abstract": "Although conditional branching between possible behavioral states is a hallmark of intelligent behavior, very little is known about the neuronal mechanisms that support this processing. In a step toward solving this problem, we demonstrate by theoretical analysis and simulation how networks of richly interconnected neurons, such as those observed in the superficial layers of the neocortex, can embed reliable, robust finite state machines. We show how a multistable neuronal network containing a number of states can be created very simply by coupling two recurrent networks whose synaptic weights have been configured for soft winner-take-all (sWTA) performance. These two sWTAs have simple, homogeneous, locally recurrent connectivity except for a small fraction of recurrent cross-connections between them, which are used to embed the required states. This coupling between the maps allows the network to continue to express the current state even after the input that elicited that state is withdrawn. In addition, a small number of transition neurons implement the necessary input-driven transitions between the embedded states. We provide simple rules to systematically design and construct neuronal state machines of this kind. The significance of our finding is that it offers a method whereby the cortex could construct networks supporting a broad range of sophisticated processing by applying only small specializations to the same generic neuronal circuit.", "paper_title": "State-Dependent Computation Using Coupled Recurrent Networks", "paper_id": "WOS:000263387000008"}