{"auto_keywords": [{"score": 0.04900275767994014, "phrase": "personal_highlights"}, {"score": 0.008336235433368016, "phrase": "motion_vectors"}, {"score": 0.00481495049065317, "phrase": "facial_activity"}, {"score": 0.004635881163634672, "phrase": "multimedia_contents"}, {"score": 0.004075198669927074, "phrase": "facial_activities"}, {"score": 0.0036924762294207633, "phrase": "twelve_key_points"}, {"score": 0.0036093693971289754, "phrase": "human_face"}, {"score": 0.0032209766681045365, "phrase": "viewer's_affective_reaction"}, {"score": 0.002985484575498061, "phrase": "ten_participants"}, {"score": 0.002896167001212006, "phrase": "eight_video_clips"}, {"score": 0.002788257824525862, "phrase": "experimental_results"}, {"score": 0.0027254466299651936, "phrase": "useful_motion_vectors"}, {"score": 0.0023591417077156555, "phrase": "upper_part"}, {"score": 0.0021049977753042253, "phrase": "lower_part"}], "paper_keywords": ["Facial activity", " Facial expression", " Affective summarization"], "paper_abstract": "This paper presents an approach to detect personal highlights in videos based on the analysis of facial activities of the viewer. Our facial activity analysis was based on the motion vectors tracked on twelve key points in the human face. In our approach, the magnitude of the motion vectors represented a degree of a viewer's affective reaction to video contents. We examined 80 facial activity videos recorded for ten participants, each watching eight video clips in various genres. The experimental results suggest that useful motion vectors to detect personal highlights varied significantly across viewers. However, it was suggested that the activity in the upper part of face tended to be more indicative of personal highlights than the activity in the lower part.", "paper_title": "Looking at the viewer: analysing facial activity to detect personal highlights of multimedia contents", "paper_id": "WOS:000286472300005"}