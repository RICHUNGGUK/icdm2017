{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "robust_visual_tracking"}, {"score": 0.004769444094319619, "phrase": "visual_tracking"}, {"score": 0.004613516457919661, "phrase": "non-stationary_image_streams"}, {"score": 0.004296264970612285, "phrase": "controlled_environments"}, {"score": 0.004116440453049531, "phrase": "significant_variation"}, {"score": 0.004058180509184539, "phrase": "object's_appearance"}, {"score": 0.004019797503157808, "phrase": "surrounding_illumination"}, {"score": 0.0038515000499988673, "phrase": "fixed_appearance_models"}, {"score": 0.0033395980635636644, "phrase": "large_volume"}, {"score": 0.0032456625605347417, "phrase": "shape_changes"}, {"score": 0.0032149396890830575, "phrase": "specific_lighting_conditions"}, {"score": 0.0029935730127943496, "phrase": "tracking_method"}, {"score": 0.002923214590192792, "phrase": "low-dimensional_subspace_representation"}, {"score": 0.0027218799769229596, "phrase": "model_update"}, {"score": 0.0026705669656375197, "phrase": "incremental_algorithms"}, {"score": 0.0026452734009203764, "phrase": "principal_component_analysis"}, {"score": 0.0024513404432665153, "phrase": "forgetting_factor"}, {"score": 0.002371018116266096, "phrase": "older_observations"}, {"score": 0.0022608057001451414, "phrase": "overall_tracking_performance"}, {"score": 0.0022393843660697484, "phrase": "numerous_experiments"}, {"score": 0.0021763278640166707, "phrase": "proposed_tracking_algorithm"}, {"score": 0.0021557052355026048, "phrase": "indoor_and_outdoor_environments"}, {"score": 0.0021251363422701446, "phrase": "target_objects"}, {"score": 0.0021049977753042253, "phrase": "large_changes"}], "paper_keywords": ["visual tracking", " subspace update", " online algorithms", " adaptive methods", " particle filter", " illumination"], "paper_abstract": "Visual tracking, in essence, deals with non-stationary image streams that change over time. While most existing algorithms are able to track objects well in controlled environments, they usually fail in the presence of significant variation of the object's appearance or surrounding illumination. One reason for such failures is that many algorithms employ fixed appearance models of the target. Such models are trained using only appearance data available before tracking begins, which in practice limits the range of appearances that are modeled, and ignores the large volume of information (such as shape changes or specific lighting conditions) that becomes available during tracking. In this paper, we present a tracking method that incrementally learns a low-dimensional subspace representation, efficiently adapting online to changes in the appearance of the target. The model update, based on incremental algorithms for principal component analysis, includes two important features: a method for correctly updating the sample mean, and a forgetting factor to ensure less modeling power is expended fitting older observations. Both of these features contribute measurably to improving overall tracking performance. Numerous experiments demonstrate the effectiveness of the proposed tracking algorithm in indoor and outdoor environments where the target objects undergo large changes in pose, scale, and illumination.", "paper_title": "Incremental learning for robust visual tracking", "paper_id": "WOS:000253526100008"}