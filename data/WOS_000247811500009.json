{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "simple_models"}, {"score": 0.004624751696958501, "phrase": "behavioral_research"}, {"score": 0.0043533862892678864, "phrase": "human_learning"}, {"score": 0.0040978781692373005, "phrase": "multi-agent_systems"}, {"score": 0.003704797078215222, "phrase": "surprisingly_simple_\"foresight-free\"_models"}, {"score": 0.0025761937402886954, "phrase": "social_interactions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["reinforcement learning", " fictitious play", " Equivalent Number of Observations (ENO)", " reciprocation"], "paper_abstract": "Behavioral research suggests that human learning in some multi-agent systems can be predicted with surprisingly simple \"foresight-free\" models. The current note discusses the implications of this research, and its relationship to the observation that social interactions tend to complicate learning. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Multi-agent learning and the descriptive value of simple models", "paper_id": "WOS:000247811500009"}