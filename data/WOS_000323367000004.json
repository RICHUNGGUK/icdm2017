{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "random_designs"}, {"score": 0.049378038061471535, "phrase": "orthogonal_matching_pursuit"}, {"score": 0.004406994912939125, "phrase": "variable_selection"}, {"score": 0.004093453936415085, "phrase": "deterministic_case"}, {"score": 0.003664315990489347, "phrase": "design_matrix"}, {"score": 0.003531474887552889, "phrase": "far_less_stringent_sparsity_constraints"}, {"score": 0.0032800186243040663, "phrase": "exact_sparse_vectors"}, {"score": 0.0031378436120100286, "phrase": "omp"}, {"score": 0.0029576827451501956, "phrase": "lasso_algorithm"}, {"score": 0.0029142984967017657, "phrase": "wainwright"}, {"score": 0.00266693888510356, "phrase": "coefficient_vector"}, {"score": 0.002422552850701705, "phrase": "smaller_coefficients"}, {"score": 0.0021363670305843403, "phrase": "coefficient_estimate"}, {"score": 0.0021049977753042253, "phrase": "strong_oracle_type_inequalities"}], "paper_keywords": ["high dimensional regression", " greedy algorithms", " Lasso", " compressed sensing"], "paper_abstract": "The performance of orthogonal matching pursuit (OMP) for variable selection is analyzed for random designs. When contrasted with the deterministic case, since the performance is here measured after averaging over the distribution of the design matrix, one can have far less stringent sparsity constraints on the coefficient vector. We demonstrate that for exact sparse vectors, the performance of the OMP is similar to known results on the Lasso algorithm (Wainwright, 2009). Moreover, variable selection under a more relaxed sparsity assumption on the coefficient vector, whereby one has only control on the l(1) norm of the smaller coefficients, is also analyzed. As consequence of these results, we also show that the coefficient estimate satisfies strong oracle type inequalities.", "paper_title": "Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit", "paper_id": "WOS:000323367000004"}