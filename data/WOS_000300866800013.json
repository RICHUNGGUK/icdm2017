{"auto_keywords": [{"score": 0.035489007303453515, "phrase": "good_grasping_points"}, {"score": 0.03167536669791014, "phrase": "different_objects"}, {"score": 0.00481495049065317, "phrase": "active_learning"}, {"score": 0.004782848614014638, "phrase": "visual_descriptors"}, {"score": 0.004687815426832587, "phrase": "beta_distributions"}, {"score": 0.004610058444728656, "phrase": "basic_skills"}, {"score": 0.004458375125223899, "phrase": "appropriate_grasping_point"}, {"score": 0.0042543303585113965, "phrase": "grasping_points"}, {"score": 0.004225950334493496, "phrase": "different_types"}, {"score": 0.004141936429360251, "phrase": "single_image"}, {"score": 0.003822191555851545, "phrase": "full_reconstruction"}, {"score": 0.0037336520904376687, "phrase": "kinematic_constraints"}, {"score": 0.0036963349119571104, "phrase": "hand_morphology"}, {"score": 0.003659389341948856, "phrase": "learning_strategies"}, {"score": 0.0036107002958650344, "phrase": "large_set"}, {"score": 0.0035865983700531278, "phrase": "labeled_examples"}, {"score": 0.003222065787177288, "phrase": "proposed_algorithm"}, {"score": 0.00306414423737093, "phrase": "feature_vector"}, {"score": 0.003013237619840709, "phrase": "different_feature_values"}, {"score": 0.0028368567593956054, "phrase": "beta-binomial_distributions"}, {"score": 0.002808477620731167, "phrase": "non-parametric_kernel_approach"}, {"score": 0.0027710786693798534, "phrase": "full_distribution"}, {"score": 0.00265292826903791, "phrase": "active_exploration"}, {"score": 0.0025313026089662165, "phrase": "real_humanoid_robot"}, {"score": 0.0022585847551229274, "phrase": "smooth_generalization"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Active Learning", " Learning through experience", " Grasping points"], "paper_abstract": "One of the basic skills for a robot autonomous grasping is to select the appropriate grasping point for an object. Several recent works have shown that it is possible to learn grasping points from different types of features extracted from a single image or from more complex 3D reconstructions. In the context of learning through experience, this is very convenient, since it does not require a full reconstruction of the object and implicitly incorporates kinematic constraints as the hand morphology. These learning strategies usually require a large set of labeled examples which can be expensive to obtain. In this paper, we address the problem of actively learning good grasping points to reduce the number of examples needed by the robot. The proposed algorithm computes the probability of successfully grasping an object at a given location represented by a feature vector. By autonomously exploring different feature values on different objects, the systems learn where to grasp each of the objects. The algorithm combines beta-binomial distributions and a non-parametric kernel approach to provide the full distribution for the probability of grasping. This information allows to perform an active exploration that efficiently learns good grasping points even among different objects. We tested our algorithm using a real humanoid robot that acquired the examples by experimenting directly on the objects and, therefore, it deals better with complex (anthropomorphic) hand-object interactions whose results are difficult to model, or predict. The results show a smooth generalization even in the presence of very few data as is often the case in learning through experience. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Active learning of visual descriptors for grasping using non-parametric smoothed beta distributions", "paper_id": "WOS:000300866800013"}