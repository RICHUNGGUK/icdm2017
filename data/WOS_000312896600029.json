{"auto_keywords": [{"score": 0.04432720202656295, "phrase": "coefficient_vector"}, {"score": 0.033172228999680184, "phrase": "sparse_logistic_regression"}, {"score": 0.004678384952779725, "phrase": "convex_programming_approach"}, {"score": 0.004583205112737672, "phrase": "theoretical_results"}, {"score": 0.0045084510240032535, "phrase": "sparse_binomial_regression"}, {"score": 0.004398589723893764, "phrase": "single_convex_program"}, {"score": 0.004344662696228875, "phrase": "accurate_estimate"}, {"score": 0.004034649282040889, "phrase": "s-sparse_signal"}, {"score": 0.003746673633703251, "phrase": "single-bit_measurements"}, {"score": 0.003700709435644458, "phrase": "simple_convex_program"}, {"score": 0.0035808664384880213, "phrase": "measurement_bit"}, {"score": 0.0033388871136347704, "phrase": "uniform_results"}, {"score": 0.00327086925741257, "phrase": "sparse_inputs"}, {"score": 0.0030247625535682987, "phrase": "bernoulli_trials"}, {"score": 0.002762774046280398, "phrase": "virtually_all_generalized_linear_models"}, {"score": 0.0027064605585684696, "phrase": "link_function"}, {"score": 0.0025865679621853667, "phrase": "first_results"}, {"score": 0.0024215727801940434, "phrase": "general_signal_structures"}, {"score": 0.0021845387990972543, "phrase": "mean_width"}, {"score": 0.0021488235554917128, "phrase": "computable_quantity"}, {"score": 0.0021049977753042253, "phrase": "robust_extension"}], "paper_keywords": ["Compressed sensing", " data compression", " parameter estimation", " quantization", " regression analysis", " signal reconstruction"], "paper_abstract": "This paper develops theoretical results regarding noisy 1-bit compressed sensing and sparse binomial regression. We demonstrate that a single convex program gives an accurate estimate of the signal, or coefficient vector, for both of these models. We show that an s-sparse signal in R-n can be accurately estimated from m = O(s log (n/s)) single-bit measurements using a simple convex program. This remains true even if each measurement bit is flipped with probability nearly 1/2. Worst-case (adversarial) noise can also be accounted for, and uniform results that hold for all sparse inputs are derived as well. In the terminology of sparse logistic regression, we show that O(s log (n/s)) Bernoulli trials are sufficient to estimate a coefficient vector in R-n which is approximately s-sparse. Moreover, the same convex program works for virtually all generalized linear models, in which the link function may be unknown. To our knowledge, these are the first results that tie together the theory of sparse logistic regression to 1-bit compressed sensing. Our results apply to general signal structures aside from sparsity; one only needs to know the size of the set where signals reside. The size is given by the mean width of, a computable quantity whose square serves as a robust extension of the dimension.", "paper_title": "Robust 1-bit Compressed Sensing and Sparse Logistic Regression: A Convex Programming Approach", "paper_id": "WOS:000312896600029"}