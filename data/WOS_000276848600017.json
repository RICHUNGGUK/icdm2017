{"auto_keywords": [{"score": 0.049435104149514096, "phrase": "new_perceptual_model"}, {"score": 0.00842967721407604, "phrase": "intensity_values"}, {"score": 0.00481495049065317, "phrase": "adaptive_spread-transform_dither_modulation"}, {"score": 0.004707479285061122, "phrase": "color_image_watermarking"}, {"score": 0.004665162327051461, "phrase": "major_challenges"}, {"score": 0.004602395776895036, "phrase": "conventional_spread-transform_dither_modulation"}, {"score": 0.004561019456344306, "phrase": "stdm"}, {"score": 0.004320421465896323, "phrase": "fixed_watermarking_strength"}, {"score": 0.004074016501033133, "phrase": "whole_cover_image"}, {"score": 0.0035898158129721003, "phrase": "robust_color_image_watermark_nit"}, {"score": 0.0034780071331554003, "phrase": "conventional_stdm_framework"}, {"score": 0.0034467039994594065, "phrase": "proposed_approach"}, {"score": 0.0033393377529146893, "phrase": "quantization_index_step_sizes"}, {"score": 0.0032794890195334513, "phrase": "local_perceptual_characteristics"}, {"score": 0.003235305151177897, "phrase": "cover_image"}, {"score": 0.003134503353065008, "phrase": "conventional_watson's_model"}, {"score": 0.0030644247579222333, "phrase": "amplitude_chancres"}, {"score": 0.002889444701599236, "phrase": "amplitude_change"}, {"score": 0.0027491902732542013, "phrase": "human_visual_system"}, {"score": 0.002627587221594597, "phrase": "watermark_embedding_procedure"}, {"score": 0.002433048706565187, "phrase": "color_artifact_suppression_algorithm"}, {"score": 0.0023571835517819124, "phrase": "upper_bound"}, {"score": 0.0022836785412390544, "phrase": "inherent_relationship"}, {"score": 0.002252880693912436, "phrase": "saturation_and_the_intensity_components_extensive_experiments"}, {"score": 0.0021727640931660038, "phrase": "corel_database"}, {"score": 0.0021337783230121286, "phrase": "superior_performance"}, {"score": 0.0021049977753042253, "phrase": "proposed_astdm_approach"}], "paper_keywords": ["Color image watermarking", " perceptual model", " spread-transform dither modulation", " amplitude scaling", " requantization"], "paper_abstract": "Major challenges of the conventional spread-transform dither modulation (STDM) watermarking approach are two-fold (i) it exploits a fixed watermarking strength (more particularly, the quantization index step size) to the whole cover image, and (ii) it is fairly vulnerable to the amplitude chancres To tackle the above challenges, an adaptive spread-tranform dither modulation (ASTDM) approach is proposed in tins paper for conducting robust color image watermark nit by Incorporating a new perceptual model into the conventional STDM framework The proposed approach exploits a new perceptual model to adjust the quantization index step sizes according to the local perceptual characteristics of a cover image Furthermore. in contrast to the conventional Watson's model is vulnerable to the amplitude chancres. our proposed new perceptual model makes the luminance masking, thresholds be consistent with any amplitude change. while keeping the consistence to the properties of the human visual system In addition. certain color artifacts could be incurred during the watermark embedding procedure. Since. some intensity values are perceptibly changed to label the watermark For that, a color artifact suppression algorithm is proposed by mathematically deriving an upper bound for the intensity values according to the inherent relationship between the saturation and the intensity components Extensive experiments are conducted using 500 images selected from Corel database to demonstrate the superior performance of the proposed ASTDM approach.", "paper_title": "Adaptive Spread-Transform Dither Modulation Using a New Perceptual Model for Color Image Watermarking", "paper_id": "WOS:000276848600017"}