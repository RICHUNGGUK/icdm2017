{"auto_keywords": [{"score": 0.049522654987196275, "phrase": "image_parameters"}, {"score": 0.02515155543881951, "phrase": "background_model"}, {"score": 0.013419459729776737, "phrase": "foreground_detection"}, {"score": 0.008713836369066502, "phrase": "hri"}, {"score": 0.006510693886361178, "phrase": "proposed_method"}, {"score": 0.004786687731085711, "phrase": "background_subtraction"}, {"score": 0.004722038375317162, "phrase": "purpose_-_background_subtraction"}, {"score": 0.004667149874736771, "phrase": "particularly_popular_foreground_detection_method"}, {"score": 0.004488734023485018, "phrase": "input_images"}, {"score": 0.0044192837023190445, "phrase": "foreground_object"}, {"score": 0.004071846628708832, "phrase": "human-robot_interaction"}, {"score": 0.0038554737609608255, "phrase": "new_background_subtraction_method"}, {"score": 0.0036648265911110164, "phrase": "existing_background_subtraction_method"}, {"score": 0.0035245918797629804, "phrase": "foreground_results"}, {"score": 0.0034296217420566304, "phrase": "change_features"}, {"score": 0.0032472646337850073, "phrase": "first_image"}, {"score": 0.0032094634756436595, "phrase": "previous_image"}, {"score": 0.0031845067058084583, "phrase": "image_sequence"}, {"score": 0.0030269369940823902, "phrase": "abnormal_background_model"}, {"score": 0.0028436364707396613, "phrase": "findings_-_experimental_results"}, {"score": 0.002821516317503421, "phrase": "typical_interaction_scenes"}, {"score": 0.0027240799841720957, "phrase": "broken_probability"}, {"score": 0.0025892330566358503, "phrase": "different_threshold_values"}, {"score": 0.0025095811903520274, "phrase": "different_environments"}, {"score": 0.00243237365704391, "phrase": "automatic_selection"}, {"score": 0.0024134449026937586, "phrase": "parameters'_threshold_values"}, {"score": 0.002376027109070317, "phrase": "interaction_scene"}, {"score": 0.0021049987157850925, "phrase": "hri."}], "paper_keywords": ["Image processing", " Robotics", " Human-robot interaction", " Background subtraction", " Foreground detection", " Image parameters"], "paper_abstract": "Purpose - Background subtraction is a particularly popular foreground detection method, whose background model can be updated by using input images. However, foreground object cannot be detected accurately if the background model is broken. In order to improve the performance of foreground detection in human-robot interaction (HRI), the purpose of this paper is to propose a new background subtraction method based on image parameters, which helps to improve the robustness of the existing background subtraction method. Design/methodology/approach - The proposed method evaluates the image and foreground results according to the image parameters representing the change features of the image. It ignores the image that is similar to the first image and the previous image in image sequence, filters the image that may break the background model and detects the abnormal background model. The method also helps to rebuild the background model when the model is broken. Findings - Experimental results of typical interaction scenes validate that the proposed method helps to reduce the broken probability of background model and improve the robustness of background subtraction. Research limitations/implications - Different threshold values of image parameters may affect the results in different environments. Future researches should focus on the automatic selection of parameters' threshold values according to the interaction scene. Practical implications - A useful method for foreground detection in HRI. Originality/value - This paper proposes a method which employs image parameters to improve the robustness of the background subtraction for foreground detection in HRI.", "paper_title": "An improved background subtraction method for HRI based on image parameters", "paper_id": "WOS:000341938400004"}