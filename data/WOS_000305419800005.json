{"auto_keywords": [{"score": 0.04167518006179967, "phrase": "hpa"}, {"score": 0.00481495049065317, "phrase": "location_pattern_classification"}, {"score": 0.004786211598268987, "phrase": "cellular_images"}, {"score": 0.004757643419056999, "phrase": "latent_discriminative_models"}, {"score": 0.0046589847106386605, "phrase": "subcellular_location"}, {"score": 0.004508048086020253, "phrase": "subcellular_pattern"}, {"score": 0.0043619799095455415, "phrase": "cellular_components"}, {"score": 0.0042459818200777846, "phrase": "important_task"}, {"score": 0.004157889052612049, "phrase": "microscope_images"}, {"score": 0.004047296286849109, "phrase": "classification_problem"}, {"score": 0.004023120753104693, "phrase": "confocal_immunofluorescence_images"}, {"score": 0.0035473867669654174, "phrase": "pattern_type"}, {"score": 0.0035156341294017685, "phrase": "stained_protein"}, {"score": 0.0034529760173586583, "phrase": "local_image_regions"}, {"score": 0.003311067956326299, "phrase": "region-based_approach"}, {"score": 0.0032036590920314725, "phrase": "different_cell_components"}, {"score": 0.0030081570462991776, "phrase": "logistic_regression"}, {"score": 0.0029901699209266435, "phrase": "structured_latent_variables"}, {"score": 0.002963390095037466, "phrase": "first_model"}, {"score": 0.002867227226349298, "phrase": "underlying_components"}, {"score": 0.0028500803748621175, "phrase": "different_regions"}, {"score": 0.0028245516301681713, "phrase": "second_model"}, {"score": 0.002790867657645595, "phrase": "spatial_dependencies"}, {"score": 0.002597012212823168, "phrase": "fast_approximate_algorithm"}, {"score": 0.002543043781904587, "phrase": "gradient-based_methods"}, {"score": 0.0025127084501976745, "phrase": "data_likelihood"}, {"score": 0.00242385118139873, "phrase": "proposed_models"}, {"score": 0.0023949342544966916, "phrase": "classification_accuracies"}, {"score": 0.002380605108907738, "phrase": "synthetic_data"}, {"score": 0.002366361492754389, "phrase": "real_cellular_images"}, {"score": 0.0023451553255837317, "phrase": "best_overall_accuracy"}, {"score": 0.0021176715289546798, "phrase": "prior_knowledge"}, {"score": 0.0021049977753042253, "phrase": "cell_organization"}], "paper_keywords": [""], "paper_abstract": "Motivation: Knowledge of the subcellular location of a protein is crucial for understanding its functions. The subcellular pattern of a protein is typically represented as the set of cellular components in which it is located, and an important task is to determine this set from microscope images. In this article, we address this classification problem using confocal immunofluorescence images from the Human Protein Atlas (HPA) project. The HPA contains images of cells stained for many proteins; each is also stained for three reference components, but there are many other components that are invisible. Given one such cell, the task is to classify the pattern type of the stained protein. We first randomly select local image regions within the cells, and then extract various carefully designed features from these regions. This region-based approach enables us to explicitly study the relationship between proteins and different cell components, as well as the interactions between these components. To achieve these two goals, we propose two discriminative models that extend logistic regression with structured latent variables. The first model allows the same protein pattern class to be expressed differently according to the underlying components in different regions. The second model further captures the spatial dependencies between the components within the same cell so that we can better infer these components. To learn these models, we propose a fast approximate algorithm for inference, and then use gradient-based methods to maximize the data likelihood. Results: In the experiments, we show that the proposed models help improve the classification accuracies on synthetic data and real cellular images. The best overall accuracy we report in this article for classifying 942 proteins into 13 classes of patterns is about 84.6%, which to our knowledge is the best so far. In addition, the dependencies learned are consistent with prior knowledge of cell organization.", "paper_title": "Protein subcellular location pattern classification in cellular images using latent discriminative models", "paper_id": "WOS:000305419800005"}