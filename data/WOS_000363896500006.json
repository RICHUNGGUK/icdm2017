{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "social_events"}, {"score": 0.047186684081144986, "phrase": "meaningful_groups"}, {"score": 0.004748832495727873, "phrase": "social_multimedia"}, {"score": 0.004667454318370122, "phrase": "social_media_streams"}, {"score": 0.004603352344461032, "phrase": "flickr_photos"}, {"score": 0.004571630734130793, "phrase": "twitter_tweets"}, {"score": 0.004236733825313407, "phrase": "social_web"}, {"score": 0.004008624230034271, "phrase": "inherently_multimodal_nature"}, {"score": 0.003858936100805083, "phrase": "social_media_items"}, {"score": 0.0037535816047183845, "phrase": "ill-posed_and_application_specific_unsupervised_clustering_problem"}, {"score": 0.0033951334049808733, "phrase": "social_event_detection"}, {"score": 0.003360057874429478, "phrase": "streaming_multi-modal_clustering_task"}, {"score": 0.0032682787834955856, "phrase": "temporal_nature"}, {"score": 0.003201088113538101, "phrase": "side_benefit"}, {"score": 0.0031352744329834676, "phrase": "real-world_datasets"}, {"score": 0.0030708096989903945, "phrase": "social_event_detection_task"}, {"score": 0.0028161281608563267, "phrase": "relative_importance"}, {"score": 0.002739165532192527, "phrase": "single_sparse_affinity_matrix"}, {"score": 0.0026735459686033627, "phrase": "meaningful_item_groups"}, {"score": 0.00246877952076635, "phrase": "reseed_dataset"}, {"score": 0.002451730979693715, "phrase": "standardised_evaluation_measures"}, {"score": 0.002426378123762607, "phrase": "automatically_learned_feature_weights"}, {"score": 0.0023275553629639395, "phrase": "good_compromise"}, {"score": 0.0021049977753042253, "phrase": "best_results"}], "paper_keywords": ["Social event detection", " Clustering methods", " Scalability", " User-generated content"], "paper_abstract": "Combining items from social media streams, such as Flickr photos and Twitter tweets, into meaningful groups can help users contextualise and consume more effectively the torrents of information continuously being made available on the social web. This task is made challenging due to the scale of the streams and the inherently multimodal nature of the information being contextualised. The problem of grouping social media items into meaningful groups can be seen as an ill-posed and application specific unsupervised clustering problem. A fundamental question in multimodal contexts is determining which features best signify that two items should belong to the same grouping. This paper presents a methodology which approaches social event detection as a streaming multi-modal clustering task. The methodology takes advantage of the temporal nature of social events and as a side benefit, allows for scaling to real-world datasets. Specific challenges of the social event detection task are addressed: the engineering and selection of the features used to compare items to one another; a feature fusion strategy that incorporates relative importance of features; the construction of a single sparse affinity matrix; and clustering techniques which produce meaningful item groups whilst scaling to cluster very large numbers of items. The state-of-the-art approach presented here is evaluated using the ReSEED dataset with standardised evaluation measures. With automatically learned feature weights, we achieve an F-1 score of 0.94, showing that a good compromise between precision and recall of clusters can be achieved. In a comparison with other state-of-the-art algorithms our approach is shown to give the best results.", "paper_title": "Detection of social events in streams of social multimedia", "paper_id": "WOS:000363896500006"}