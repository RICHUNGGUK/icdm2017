{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "human_action_recognition"}, {"score": 0.004570759604335229, "phrase": "important_and_challenging_task"}, {"score": 0.004310752197635499, "phrase": "discriminative_action"}, {"score": 0.004227398267369744, "phrase": "simple_features"}, {"score": 0.004145649381700967, "phrase": "relevant_task"}, {"score": 0.0038092152998069786, "phrase": "simple_filter_outputs"}, {"score": 0.0037599278182081056, "phrase": "multilevel_architectures"}, {"score": 0.0037112756920669593, "phrase": "non-linear_transformations"}, {"score": 0.0035458802311188497, "phrase": "new_multiscale_descriptor"}, {"score": 0.0034999891150193, "phrase": "har"}, {"score": 0.003432279984002843, "phrase": "pyramid"}, {"score": 0.0033878306639271963, "phrase": "accumulated_histograms"}, {"score": 0.0033439771810057717, "phrase": "optical_flow"}, {"score": 0.0031127040190005216, "phrase": "space-time_gradients"}, {"score": 0.0029933487820771217, "phrase": "recognition_task"}, {"score": 0.0028412769256691, "phrase": "human_actions"}, {"score": 0.002804484195217693, "phrase": "kth"}, {"score": 0.002768155873129179, "phrase": "weizmann"}, {"score": 0.0027323009127771525, "phrase": "ixmas."}, {"score": 0.002543224008253855, "phrase": "current_results"}, {"score": 0.0021049977753042253, "phrase": "correct_recognition"}], "paper_keywords": ["Human motion", " Action description and recognition", " Feature pooling", " Optical Flow"], "paper_abstract": "Human action recognition (HAR) from images is an important and challenging task for many current applications. In this context, designing discriminative action descriptors from simple features is a relevant task. In this paper we show that very good descriptors can be build from simple filter outputs when multilevel architectures and non-linear transformations are used. We propose a new multiscale descriptor for HAR from a Pyramid of Accumulated Histograms of Optical Flow. We also show that, in this case, space-time gradients provide sufficient information for the recognition task. Our descriptor is evaluated on three standard databases of human actions: KTH, Weizmann and IXMAS. We compare very favorably the results of our descriptor with the current results for these three databases from other algorithms. In particular, our descriptor is directly comparable to the state-of-the-art on KTH database with an average of 96 % of correct recognition.", "paper_title": "Human action recognition from simple feature pooling", "paper_id": "WOS:000330839400002"}