{"auto_keywords": [{"score": 0.04656949560443595, "phrase": "wasserstein_distance"}, {"score": 0.004815077777076625, "phrase": "quantitative"}, {"score": 0.00459165923324494, "phrase": "geometrically_ergodic_markov_chain"}, {"score": 0.0038332390893263844, "phrase": "explicit_convergence_rates"}, {"score": 0.0037610536973798113, "phrase": "markov_chains"}, {"score": 0.0032302647179383915, "phrase": "useful_insights"}, {"score": 0.0030802351224657673, "phrase": "mcmc_algorithms"}, {"score": 0.0028274743316389437, "phrase": "good_mixing_rate"}, {"score": 0.0026452734009203764, "phrase": "underlying_sampling_space"}, {"score": 0.002382329940096419, "phrase": "exponential_integrator_version"}, {"score": 0.0021049977753042253, "phrase": "bayesian_linear_inverse_problem"}], "paper_keywords": ["Explicit rate of convergence", " Wasserstein distance", " Metropolis adjusted Langevin algorithm"], "paper_abstract": "In this paper, we establish explicit convergence rates for Markov chains in Wasserstein distance. Compared to the more classical total variation bounds, the proposed rate of convergence leads to useful insights for the analysis of MCMC algorithms, and suggests ways to construct sampler with good mixing rate even if the dimension of the underlying sampling space is large. We illustrate these results by analyzing the Exponential Integrator version of the Metropolis Adjusted Langevin Algorithm. We illustrate our findings using a Bayesian linear inverse problem.", "paper_title": "Quantitative bounds of convergence for geometrically ergodic Markov chain in the Wasserstein distance with application to the Metropolis Adjusted Langevin Algorithm", "paper_id": "WOS:000349028500003"}