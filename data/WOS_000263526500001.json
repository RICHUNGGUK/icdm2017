{"auto_keywords": [{"score": 0.03737634241271663, "phrase": "nic"}, {"score": 0.010617411201552088, "phrase": "read_requests"}, {"score": 0.009447133978453742, "phrase": "nic_cache"}, {"score": 0.00481495049065317, "phrase": "iscsi_storage_server"}, {"score": 0.004690952711665194, "phrase": "data-intensive_applications"}, {"score": 0.004550300345169981, "phrase": "fast-growing_volume"}, {"score": 0.004262881313926916, "phrase": "storage_servers"}, {"score": 0.004010960493946656, "phrase": "hierarchical_data_cache_architecture"}, {"score": 0.003907586297783078, "phrase": "local_interconnect_traffic"}, {"score": 0.0038234714417849495, "phrase": "storage_server_performance"}, {"score": 0.003773870856027139, "phrase": "popular_iscsi_storage_server_architecture"}, {"score": 0.003660636957101787, "phrase": "dca"}, {"score": 0.003581797255879607, "phrase": "read_cache"}, {"score": 0.003399466007862412, "phrase": "host_memory"}, {"score": 0.0033700043473143897, "phrase": "helper"}, {"score": 0.0031568884810273226, "phrase": "pci_bus"}, {"score": 0.0031023662967184216, "phrase": "helper_cache"}, {"score": 0.0029830992938695007, "phrase": "partial_nic_cache"}, {"score": 0.002906138793910919, "phrase": "cache_placement"}, {"score": 0.0027104531025934865, "phrase": "novel_state-locality-aware_cache_placement_algorithm"}, {"score": 0.002686936713144626, "phrase": "slap"}, {"score": 0.002594880866651459, "phrase": "mixed_read"}, {"score": 0.0024306740161601625, "phrase": "dca_prototype_system"}, {"score": 0.0023679315987170857, "phrase": "open_source"}, {"score": 0.0023270035715132866, "phrase": "representative_storage_server_workloads"}, {"score": 0.002237477619351199, "phrase": "iscsi_storage_server_throughput"}, {"score": 0.0021797112385590913, "phrase": "pci_traffic"}, {"score": 0.002123433075137768, "phrase": "iscsi_target"}, {"score": 0.0021049999697546184, "phrase": "dca."}], "paper_keywords": ["NIC", " cache", " PCI", " iSCSI", " storage server"], "paper_abstract": "With the emergence of data-intensive applications, recent years have seen a fast-growing volume of I/O traffic propagated through the local I/O interconnect bus. This raises up a question for storage servers on how to resolve such a potential bottleneck. In this paper, we present a hierarchical Data Cache Architecture called DCA to effectively slash local interconnect traffic and thus boost the storage server performance. A popular iSCSI storage server architecture is chosen as an example. DCA is composed of a read cache in NIC called NIC cache and a read/write unified cache in host memory called Helper cache. The NIC cache services most portions of read requests without fetching data via the PCI bus, while the Helper cache 1) supplies some portions of read requests per partial NIC cache hit, 2) directs cache placement for NIC cache, and 3) absorbs most transient writes locally. We develop a novel State-Locality-Aware cache Placement algorithm called SLAP to improve the NIC cache hit ratio for mixed read and write workloads. To demonstrate the effectiveness of DCA, we develop a DCA prototype system and evaluate it with an open source iSCSI implementation under representative storage server workloads. Experimental results showed that DCA can boost iSCSI storage server throughput by up to 121 percent and reduce the PCI traffic by up to 74 percent compared with an iSCSI target without DCA.", "paper_title": "A New Hierarchical Data Cache Architecture for iSCSI Storage Server", "paper_id": "WOS:000263526500001"}