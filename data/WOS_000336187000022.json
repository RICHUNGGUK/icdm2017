{"auto_keywords": [{"score": 0.04066301332698914, "phrase": "key_frames"}, {"score": 0.00481495049065317, "phrase": "based_visual_attention_model"}, {"score": 0.004671932143798307, "phrase": "video_summarization"}, {"score": 0.004588158931776543, "phrase": "integral_component"}, {"score": 0.004533142516832776, "phrase": "video_archiving_systems"}, {"score": 0.004425072111844721, "phrase": "small_versions"}, {"score": 0.004191200981137508, "phrase": "browsing_and_navigation_capabilities"}, {"score": 0.004116012194714212, "phrase": "popular_method"}, {"score": 0.003692271726952282, "phrase": "overall_message"}, {"score": 0.003496994062890991, "phrase": "novel_feature_aggregation_based_visual_saliency_detection_mechanism"}, {"score": 0.0032920678776655783, "phrase": "saliency_maps"}, {"score": 0.003174903873774882, "phrase": "aggregated_features"}, {"score": 0.0031367803372203498, "phrase": "motion_intensity"}, {"score": 0.003080449000295983, "phrase": "non-linear_weighted_fusion_mechanism"}, {"score": 0.00291743479583421, "phrase": "resultant_map"}, {"score": 0.0028650312174624635, "phrase": "gaussian_weighting_scheme"}, {"score": 0.0025388705701873075, "phrase": "final_attention_value"}, {"score": 0.002361236012575149, "phrase": "experimental_results"}, {"score": 0.002304824112812496, "phrase": "different_evaluation_standards"}, {"score": 0.0022361964497681934, "phrase": "proposed_scheme"}, {"score": 0.002209319719984651, "phrase": "semantically_significant_key_frames"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": [""], "paper_abstract": "Video summarization is an integral component of video archiving systems. It provides small versions of the videos that are suitable for enhancing browsing and navigation capabilities. A popular method to generate summaries is to extract a set of key frames from the video, which conveys the overall message of the video. This paper introduces a novel feature aggregation based visual saliency detection mechanism and its usage for extracting key frames. The saliency maps are computed based on the aggregated features and motion intensity. A non-linear weighted fusion mechanism combines the two saliency maps. On the resultant map, a Gaussian weighting scheme is used to assign more weight to the pixels close to the center of the frame. Based on the final attention value of each frame, the key frames are extracted adaptively. The experimental results, based on different evaluation standards, demonstrate that the proposed scheme extracts semantically significant key frames. (C) 2014 Published by Elsevier Ltd.", "paper_title": "Feature aggregation based visual attention model for video summarization", "paper_id": "WOS:000336187000022"}