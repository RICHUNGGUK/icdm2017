{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "corresponding_feature_points"}, {"score": 0.004678785623021003, "phrase": "relative_pose"}, {"score": 0.004520438007604407, "phrase": "single_camera"}, {"score": 0.004342430078306461, "phrase": "iterative_methods"}, {"score": 0.004268293864953256, "phrase": "inverse_projection_ray_approach"}, {"score": 0.004147523799581407, "phrase": "iterative_algorithm"}, {"score": 0.004030157055463817, "phrase": "depth_recovery_stage"}, {"score": 0.003984141889010296, "phrase": "absolute_orientation_stage"}, {"score": 0.0038271712887391015, "phrase": "first_stage"}, {"score": 0.0037617986040878342, "phrase": "optimal_translation_vector"}, {"score": 0.003613556291453534, "phrase": "rotation_matrix"}, {"score": 0.0035722806911457545, "phrase": "least_square_method"}, {"score": 0.003431481042678356, "phrase": "observed_points"}, {"score": 0.0033152062780180073, "phrase": "estimated_point"}, {"score": 0.0032398798149196432, "phrase": "inverse_projection_ray"}, {"score": 0.003166259444961177, "phrase": "image_point"}, {"score": 0.003006654007926993, "phrase": "estimated_depths"}, {"score": 0.0029722900280316216, "phrase": "previous_step"}, {"score": 0.00290473242917264, "phrase": "second_stage"}, {"score": 0.0028550709503536494, "phrase": "optimal_rotation_matrix"}, {"score": 0.0027741761880779535, "phrase": "umeyama_algorithm"}, {"score": 0.002487083025913648, "phrase": "global_convergence"}, {"score": 0.002444544487772349, "phrase": "two-stage_iterative_algorithm"}, {"score": 0.002361632539339945, "phrase": "global_convergence_theorem"}, {"score": 0.002294686545883412, "phrase": "spacecraft_docking_application"}, {"score": 0.0021539955106204354, "phrase": "proposed_algorithm"}, {"score": 0.002129356014992349, "phrase": "mathematical_simulation"}, {"score": 0.0021049977753042253, "phrase": "physical_simulation"}], "paper_keywords": ["monocular vision", " feature point", " relative pose", " two-stage iterative algorithm", " global convergence"], "paper_abstract": "To determine the relative pose between an object and a single camera using 2D-to-3D point correspondences, a kind of iterative methods based on inverse projection ray approach is proposed. An iterative algorithm which is divided into depth recovery stage and absolute orientation stage is also proposed. In the first stage, the optimal translation vector is first computed in terms of rotation matrix via least square method, then the depths of the observed points are estimated by projecting the estimated point orthogonally to the inverse projection ray defined by the image point, and finally 3D points are reconstructed using the estimated depths from previous step. In the second stage, the optimal rotation matrix is estimated by applying Umeyama algorithm to fitting of the 3D model points and 3D estimated points. The above two stages are repeated until the result converges. The global convergence of the two-stage iterative algorithm is proven based on the global convergence theorem. Finally, a spacecraft docking application is implemented to test the effectiveness and convergence of the proposed algorithm by mathematical simulation and physical simulation.", "paper_title": "Monocular vision-based iterative pose estimation algorithm from corresponding feature points", "paper_id": "WOS:000279689900021"}