{"auto_keywords": [{"score": 0.04117729234560256, "phrase": "la"}, {"score": 0.01222307643277979, "phrase": "vehicular_environment"}, {"score": 0.007636076170369294, "phrase": "proposed_scheme"}, {"score": 0.00481495049065317, "phrase": "learning_automata"}, {"score": 0.004696608876994947, "phrase": "performance_analysis"}, {"score": 0.004581162468419365, "phrase": "stringent_constraints"}, {"score": 0.0045357787854931894, "phrase": "constant_topological_changes"}, {"score": 0.004490842671590769, "phrase": "low_end-to-end_delay"}, {"score": 0.004358676214574977, "phrase": "vehicular_enviornment"}, {"score": 0.004272724011826495, "phrase": "challenging_task"}, {"score": 0.0037913267098534887, "phrase": "bayesian_coalition_game"}, {"score": 0.003380791705551809, "phrase": "pre-defined_strategy"}, {"score": 0.0033306180744375616, "phrase": "strategy_space"}, {"score": 0.002634830238219976, "phrase": "bayesian_conditional_probability"}, {"score": 0.0022799458141165587, "phrase": "different_network_conditions"}, {"score": 0.0022460727898764216, "phrase": "real_environment"}, {"score": 0.0022016885701010088, "phrase": "learning_rates"}, {"score": 0.0021049977753042253, "phrase": "successful_packet_delivery_ratio"}], "paper_keywords": [""], "paper_abstract": "Due to the stringent constraints of constant topological changes and low end-to-end delay, data forwarding in the vehicular enviornment is always a challenging task. In this article, we have analyzed the performance of networks of learning automata (LA) using the concepts of the Bayesian coalition game in the vehicular environment. LA are assumed to be the players in the game, which form a coalition based on some pre-defined strategy from the strategy space. Each action taken by the players in the game may be rewarded or penalized by the environment in which they operate. The environment provides a feedback for each action taken by the LA. The probability of selection of an action is estimated using the Bayesian conditional probability on the payoff corresponding to each player. After fetching input from the environment, the LA update their action probability vector. The performance of the proposed scheme is evaluated in different network conditions in a real environment by varying the learning rates of the automaton. A 20-30 percent enhancement of the successful packet delivery ratio has been observed using the proposed scheme in the vehicular environment.", "paper_title": "NETWORKS OF LEARNING AUTOMATA FOR THE VEHICULAR ENVIRONMENT: A PERFORMANCE ANALYSIS STUDY", "paper_id": "WOS:000347382300008"}