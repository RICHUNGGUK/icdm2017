{"auto_keywords": [{"score": 0.04774633807425784, "phrase": "imbalanced_problems"}, {"score": 0.00481495049065317, "phrase": "imbalanced_classification_problems"}, {"score": 0.004709333998298903, "phrase": "overall_prediction_error"}, {"score": 0.004031865694174726, "phrase": "sensitive_learning"}, {"score": 0.0036892809673917592, "phrase": "training_process"}, {"score": 0.0035290250358997904, "phrase": "traditional_error"}, {"score": 0.003509487090932835, "phrase": "based_objective_functions"}, {"score": 0.002873524721802591, "phrase": "appropriate_measure"}, {"score": 0.002794802975530612, "phrase": "hypothesis_space"}, {"score": 0.0026732973536990373, "phrase": "case_studies"}, {"score": 0.00262910358108176, "phrase": "standard_threelayer_neural_network"}, {"score": 0.002473203873496859, "phrase": "genetic_algorithms"}, {"score": 0.0023656467839555458, "phrase": "objective_function"}, {"score": 0.0023394947463129642, "phrase": "experimental_results"}, {"score": 0.0023136311468961125, "phrase": "eight_benchmark_problems"}, {"score": 0.002262756631083292, "phrase": "proposed_method"}, {"score": 0.0022253345930383257, "phrase": "consistently_favorable_outcomes"}, {"score": 0.002164331818029166, "phrase": "commonly_used_sampling_technique"}, {"score": 0.0021049977753042253, "phrase": "multi-objective_optimization"}], "paper_keywords": ["imbalanced datasets", " genetic algorithms (GAs)", " neural networks", " G-mean", " synthetic minority over-sampling technique (SMOTE)"], "paper_abstract": "Since the overall prediction error of a classifier on imbalanced problems can be potentially misleading and biased, alternative performance measures such as G-mean and F-measure have been widely adopted. Various techniques including sampling and cost sensitive learning are often employed to improve the performance of classifiers in such situations. However, the training process of classifiers is still largely driven by traditional error based objective functions. As a result, there is clearly a gap between themeasure according to which the classifier is evaluated and how the classifier is trained. This paper investigates the prospect of explicitly using the appropriate measure itself to search the hypothesis space to bridge this gap. In the case studies, a standard threelayer neural network is used as the classifier, which is evolved by genetic algorithms (GAs) with G-mean as the objective function. Experimental results on eight benchmark problems show that the proposed method can achieve consistently favorable outcomes in comparison with a commonly used sampling technique. The effectiveness of multi-objective optimization in handling imbalanced problems is also demonstrated.", "paper_title": "Measure oriented training: a targeted approach to imbalanced classification problems", "paper_id": "WOS:000309721200001"}