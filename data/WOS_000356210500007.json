{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "verifiable_conditions"}, {"score": 0.004508661664944657, "phrase": "borel_spaces."}, {"score": 0.00422177384286051, "phrase": "new_set"}, {"score": 0.003953068310598579, "phrase": "average_optimal_stationary_policies"}, {"score": 0.003772684543694116, "phrase": "markov"}, {"score": 0.0036324746826127997, "phrase": "borel_spaces"}, {"score": 0.003038237581227068, "phrase": "lyapunov-type_condition"}, {"score": 0.002953711377604328, "phrase": "common_continuity-compactness_conditions"}, {"score": 0.0027395968397212053, "phrase": "primitive_data"}, {"score": 0.002613709503583786, "phrase": "markov_decision_processes"}, {"score": 0.0021049977753042253, "phrase": "related_literature"}], "paper_keywords": ["discrete-time Markov decision processes", " average reward criterion", " optimal stationary policy", " Lyapunov-type condition", " unbounded reward/cost function"], "paper_abstract": "In this paper we give a new set of verifiable conditions for the existence of average optimal stationary policies in discrete-time Markov decision processes with Borel spaces and unbounded reward/cost functions. More precisely, we provide another set of conditions, which only consists of a Lyapunov-type condition and the common continuity-compactness conditions. These conditions are imposed on the primitive data of the model of Markov decision processes and thus easy to verify. We also give two examples for which all our conditions are satisfied, but some of conditions in the related literature fail to hold.", "paper_title": "ANOTHER SET OF VERIFIABLE CONDITIONS FOR AVERAGE MARKOV DECISION PROCESSES WITH BOREL SPACES", "paper_id": "WOS:000356210500007"}