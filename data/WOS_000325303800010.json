{"auto_keywords": [{"score": 0.035050648308006416, "phrase": "bci"}, {"score": 0.00481495049065317, "phrase": "virtual_and_real_environments"}, {"score": 0.004542441734438654, "phrase": "navigation_paradigm"}, {"score": 0.004285289574869884, "phrase": "brain-computer_interface"}, {"score": 0.003916098498242888, "phrase": "graphical_interface"}, {"score": 0.0037139103792217143, "phrase": "gaze_control"}, {"score": 0.0036167509502276294, "phrase": "audio-cued_paradigm"}, {"score": 0.003150900886669123, "phrase": "right_hand_movements"}, {"score": 0.0030684249587688826, "phrase": "motor_imagery"}, {"score": 0.003036040409062437, "phrase": "navigation_control"}, {"score": 0.0029253546782349875, "phrase": "auditory_bcis"}, {"score": 0.002658863179011018, "phrase": "audio-cued_interface"}, {"score": 0.0026168641536413978, "phrase": "virtual_wheelchair"}, {"score": 0.002561892963059385, "phrase": "second_one"}, {"score": 0.002468450551616404, "phrase": "real_environments"}, {"score": 0.002429451930463481, "phrase": "obtained_results"}, {"score": 0.0023532890136269986, "phrase": "proposed_interface"}, {"score": 0.0023038418282549274, "phrase": "real_wheelchair"}, {"score": 0.002196342933346204, "phrase": "visual_stimuli"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Brain-computer interface (BCI)", " Navigation", " Asynchronous", " Motor imagery (MI)", " Mental tasks", " Auditory"], "paper_abstract": "The aim of this work is to provide a navigation paradigm that could be used to control a wheelchair through a brain-computer interface (BCI). In such a case, it is desirable to control the system without a graphical interface so that it will be useful for people without gaze control. Thus, an audio-cued paradigm with several navigation commands is proposed. In order to reduce the probability of misclassification, the BCI operates with only two mental tasks: relaxed state versus imagination of right hand movements; the use of motor imagery for navigation control is not yet extended among the auditory BCIs. Two experiments are described: in the first one, users practice the switch from a graphical to an audio-cued interface with a virtual wheelchair; in the second one, they change from virtual to real environments. The obtained results support the use of the proposed interface to control a real wheelchair without the need of a screen to provide visual stimuli or feedback. (c) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Audio-cued motor imagery-based brain-computer interface: Navigation through virtual and real environments", "paper_id": "WOS:000325303800010"}