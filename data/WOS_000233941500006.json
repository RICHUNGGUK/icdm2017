{"auto_keywords": [{"score": 0.04930986456658363, "phrase": "k-nearest_neighbor_classifier"}, {"score": 0.00481495049065317, "phrase": "distance_estimation_-_application"}, {"score": 0.004537254814246843, "phrase": "new_distance_estimation_technique"}, {"score": 0.004028796143006953, "phrase": "typical_classification_problem"}, {"score": 0.00385832528624328, "phrase": "distance_function"}, {"score": 0.003796267885124202, "phrase": "resulting_distance"}, {"score": 0.0037150693245941112, "phrase": "k-nn."}, {"score": 0.003675120438902734, "phrase": "proposed_method"}, {"score": 0.0035771121569391916, "phrase": "nearest_neighbor"}, {"score": 0.0035005841368145525, "phrase": "adaboost_classifier"}, {"score": 0.0032806521851034766, "phrase": "k-nn_classifier"}, {"score": 0.003074495313651187, "phrase": "relevant_component_analysis"}, {"score": 0.003041425386418528, "phrase": "rca"}, {"score": 0.002992456867123044, "phrase": "duda"}, {"score": 0.0029602552900111407, "phrase": "r.o."}, {"score": 0.002928410979091104, "phrase": "hart"}, {"score": 0.002789226820897593, "phrase": "john_wiley"}, {"score": 0.0025167026017217926, "phrase": "classification_accuracy"}, {"score": 0.0024896081630179194, "phrase": "classical_techniques"}, {"score": 0.0024497801690348854, "phrase": "pca"}, {"score": 0.0024233889520188854, "phrase": "lda"}, {"score": 0.0023841095772440643, "phrase": "nda."}, {"score": 0.002246292543825748, "phrase": "uci_repository"}, {"score": 0.0022101055924375725, "phrase": "standard_gender_recognition_database"}, {"score": 0.0021745003291048356, "phrase": "mnist_database"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["distance estimation", " AdaBoost", " dimension reduction"], "paper_abstract": "In this work we introduce a new distance estimation technique by boosting and we apply it to the K-Nearest Neighbor Classifier (K-NN). Instead of applying AdaBoost to a typical classification problem, we use it for learning a distance function and the resulting distance is used into K-NN. The proposed method (Boosted Distance with Nearest Neighbor) outperforms the AdaBoost classifier when the training set is small. It also outperforms the K-NN classifier used with several different distances and the distances obtained with other estimation methods such as Relevant Component Analysis (RCA) [Duda, R.O., Hart, P.E., Stock, D.G., 2001. Pattern Classification, John Wiley and Sons Inc.]. Furthermore, our distance estimation performs dimension-reduction, being much more efficient in terms of classification accuracy than classical techniques such as PCA, LDA, and NDA. The method has been thoroughly tested on 13 standard databases from the UCI repository, a standard gender recognition database and the MNIST database. (c) 2005 Elsevier B.V. All rights reserved.", "paper_title": "Boosting the distance estimation - Application to the K-Nearest Neighbor Classifier", "paper_id": "WOS:000233941500006"}