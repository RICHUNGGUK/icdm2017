{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "phoneme-level_controls"}, {"score": 0.004643839937761046, "phrase": "novel_data-driven_expressive_speech_animation_synthesis_system"}, {"score": 0.004293584349522444, "phrase": "pre-recorded_facial_motion_capture_database"}, {"score": 0.004042166795461166, "phrase": "pre-designed_corpus"}, {"score": 0.003714629047818465, "phrase": "new_phoneme-aligned_expressive_speech"}, {"score": 0.0035181731203867456, "phrase": "constrained_dynamic_programming_algorithm"}, {"score": 0.0033929894721242367, "phrase": "best-matched_captured_motion_clips"}, {"score": 0.003332072426367186, "phrase": "processed_facial_motion_database"}, {"score": 0.003252542052430782, "phrase": "cost_function"}, {"score": 0.002813566267090177, "phrase": "phoneme-isomap_interface"}, {"score": 0.0027298319171606498, "phrase": "phoneme_clusters"}, {"score": 0.002600995957987461, "phrase": "facial_motion_capture_frames"}, {"score": 0.002508365161206412, "phrase": "novel_visualization_interface"}, {"score": 0.002419025278429845, "phrase": "contaminated_motion_subsequences"}, {"score": 0.0023755529073496394, "phrase": "large_facial_motion_dataset"}, {"score": 0.0023470051993423483, "phrase": "facial_animation_synthesis_experiments"}, {"score": 0.0022633993976138387, "phrase": "facial_motion"}, {"score": 0.0021049977753042253, "phrase": "realistic_expressive_speech_animations"}], "paper_keywords": ["Facial animation", " speech animation", " data-driven", " facial expression", " phoneme-isomap", " motion capture"], "paper_abstract": "This paper presents a novel data-driven expressive speech animation synthesis system with phoneme-level controls. This system is based on a pre-recorded facial motion capture database, where an actress was directed to recite a pre-designed corpus with four facial expressions (neutral, happiness, anger and sadness). Given new phoneme-aligned expressive speech and its emotion modifiers as inputs, a constrained dynamic programming algorithm is used to search for best-matched captured motion clips from the processed facial motion database by minimizing a cost function. Users optionally specify 'hard constraints' (motion-node constraints for expressing phoneme utterances) and 'soft constraints' (emotion modifiers) to guide this search process. We also introduce a phoneme-Isomap interface for visualizing and interacting phoneme clusters that are typically composed of thousands of facial motion capture frames. On top of this novel visualization interface, users can conveniently remove contaminated motion subsequences from a large facial motion dataset. Facial animation synthesis experiments and objective comparisons between synthesized facial motion and captured motion showed that this system is effective for producing realistic expressive speech animations.", "paper_title": "Expressive Speech Animation Synthesis with Phoneme-Level Controls", "paper_id": "WOS:000261137800009"}