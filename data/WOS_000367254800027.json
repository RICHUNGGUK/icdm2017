{"auto_keywords": [{"score": 0.04712665802421912, "phrase": "multiple_gpus"}, {"score": 0.011654822810129329, "phrase": "redundant_communication"}, {"score": 0.00481495049065317, "phrase": "semcache"}, {"score": 0.004714023408114857, "phrase": "semantics-aware"}, {"score": 0.004639712384096822, "phrase": "efficient_multi-gpu_offloading"}, {"score": 0.0044237033788643715, "phrase": "easy_task"}, {"score": 0.004330941610682453, "phrase": "decomposing_data"}, {"score": 0.004129248271757936, "phrase": "gpu_libraries"}, {"score": 0.003813669883040509, "phrase": "library_calls"}, {"score": 0.0036167509502276294, "phrase": "successive_kernel_invocations"}, {"score": 0.0033050912164615726, "phrase": "gpu"}, {"score": 0.0030039966201398966, "phrase": "redundant_transfers"}, {"score": 0.0027741761880779535, "phrase": "replacement_library"}, {"score": 0.00267301171407926, "phrase": "virtual_memory"}, {"score": 0.0025892330566358503, "phrase": "multi-gpu_communication"}, {"score": 0.002255431275670053, "phrase": "experimental_results"}, {"score": 0.0021501863832966966, "phrase": "significant_performance_improvements"}, {"score": 0.0021274723597955567, "phrase": "multi-gpu_libraries"}, {"score": 0.0021049977753042253, "phrase": "cublasxt."}], "paper_keywords": ["Multi-GPU offloading", " GPGPU", " Communication optimization"], "paper_abstract": "Offloading computations to multiple GPUs is not an easy task. It requires decomposing data, distributing computations and handling communication manually. GPU libraries have made it easy to offload computations to multiple GPUs by hiding this complexity inside library calls. Such encapsulation prevents the reuse of the data between successive kernel invocations resulting in redundant communication. In this work, we introduce SemCache++, a semantics-aware GPU cache that automatically manages communication between the CPU and multiple GPUs in addition to optimizing communication by eliminating redundant transfers using caching. SemCache++ is used to build the first multi-GPU drop-in replacement library that (a) uses the virtual memory to automatically manage and optimize multi-GPU communication and (b) requires no program rewriting or annotations. Our caching technique is efficient; it uses a two level caching directory to track matrices and submatrices. Experimental results show that our system can eliminate redundant communication and deliver significant performance improvements over multi-GPU libraries like CUBLASXT.", "paper_title": "SemCache plus plus : Semantics-Aware Caching for Efficient Multi-GPU Offloading", "paper_id": "WOS:000367254800027"}