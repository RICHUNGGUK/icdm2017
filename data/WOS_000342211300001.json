{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "wide_spread"}, {"score": 0.0046993598473345395, "phrase": "large_number"}, {"score": 0.004653900688892822, "phrase": "user-generated_videos"}, {"score": 0.004520132822496416, "phrase": "embedded_sensors"}, {"score": 0.00436890075128947, "phrase": "digital_compass"}, {"score": 0.0037392451233558234, "phrase": "smartphone_applications"}, {"score": 0.0036493838225192883, "phrase": "continuous_stream"}, {"score": 0.0035616743422949766, "phrase": "direction_information"}, {"score": 0.0035100601949451028, "phrase": "collected_videos"}, {"score": 0.0033271045779740683, "phrase": "spatio-temporal_objects"}, {"score": 0.003278878522165818, "phrase": "sensor_meta-data"}, {"score": 0.0031383410838018984, "phrase": "visual_content"}, {"score": 0.0029892206557359836, "phrase": "geo-tagged_videos"}, {"score": 0.0029602552900111433, "phrase": "large-scale_repositories"}, {"score": 0.0028333356794133053, "phrase": "novel_three-level_grid-based_index_structure"}, {"score": 0.002685558057339722, "phrase": "typical_spatial_queries"}, {"score": 0.0026209522797963447, "phrase": "bounded_radius"}, {"score": 0.0025829353063908256, "phrase": "direction_restriction"}, {"score": 0.002400944221804575, "phrase": "real-world_dataset"}, {"score": 0.0023546121947302877, "phrase": "experimental_results"}, {"score": 0.002320449502337321, "phrase": "large-scale_synthetic_dataset_show"}, {"score": 0.002242647404307089, "phrase": "significant_speed_improvements"}, {"score": 0.0021049977753042253, "phrase": "multi-dimensional_r-tree_implementation"}], "paper_keywords": ["Geo-taggeed video search", " Grid-based index", " Meta-data generation", " Query processing"], "paper_abstract": "With the wide spread of smartphones, a large number of user-generated videos are produced everyday. The embedded sensors, e.g., GPS and the digital compass, make it possible that videos are accessed based on their geo-properties. In our previous work, we have created a framework for integrated, sensor-rich video acquisition (with one instantiation implemented in the form of smartphone applications) which associates a continuous stream of location and viewing direction information with the collected videos, hence allowing them to be expressed and manipulated as spatio-temporal objects. These sensor meta-data are considerably smaller in size compared to the visual content and are helpful in effectively and efficiently searching for geo-tagged videos in large-scale repositories. In this study, we propose a novel three-level grid-based index structure and introduce a number of related query types, including typical spatial queries and ones based on bounded radius and viewing direction restriction. These two criteria are important in many video applications and we demonstrate the importance with a real-world dataset. Moreover, experimental results on a large-scale synthetic dataset show that our approach can provide a significant speed improvements of at least 30 %, considering a mix of queries, compared to a multi-dimensional R-tree implementation.", "paper_title": "Large-scale geo-tagged video indexing and queries", "paper_id": "WOS:000342211300001"}