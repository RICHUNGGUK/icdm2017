{"auto_keywords": [{"score": 0.04181790450128157, "phrase": "second_stage"}, {"score": 0.00481495049065317, "phrase": "two-class_classification"}, {"score": 0.004733347359490221, "phrase": "two-stage_linear-in-the-parameter_model_construction_algorithm"}, {"score": 0.0043208252177835815, "phrase": "first_stage"}, {"score": 0.004199406257273994, "phrase": "prefiltered_signal"}, {"score": 0.004058180509184539, "phrase": "desired_output"}, {"score": 0.003683213029483699, "phrase": "prefiltering_stage"}, {"score": 0.0036207206487324506, "phrase": "two-level_process"}, {"score": 0.0035189057079817285, "phrase": "model's_generalization_capability"}, {"score": 0.003419943984098415, "phrase": "new_elastic-net_model_identification_algorithm"}, {"score": 0.0032487508969192293, "phrase": "lower_level"}, {"score": 0.003068537223324389, "phrase": "particle-swarm-optimization_algorithm"}, {"score": 0.0027218799769229596, "phrase": "resultant_prefiltered_signal"}, {"score": 0.002527150892127982, "phrase": "associated_computational_cost"}, {"score": 0.0024984517279573906, "phrase": "minimal_due_to_orthogonality"}, {"score": 0.0024281181691350085, "phrase": "sparse_classifier_construction"}, {"score": 0.002373276186210053, "phrase": "orthogonal_forward_regression"}, {"score": 0.0023329572140896237, "phrase": "d-optimality_algorithm"}, {"score": 0.0022287497627555895, "phrase": "noisy_data_sets"}, {"score": 0.0021049977753042253, "phrase": "noisy_data_problems"}], "paper_keywords": ["Cross-validation (CV)", " elastic net (EN)", " forward regression", " leave-one-out (LOO) errors", " linear-in-the-parameter model", " regularization"], "paper_abstract": "A two-stage linear-in-the-parameter model construction algorithm is proposed aimed at noisy two-class classification problems. The purpose of the first stage is to produce a prefiltered signal that is used as the desired output for the second stage which constructs a sparse linear-in-the-parameter classifier. The prefiltering stage is a two-level process aimed at maximizing a model's generalization capability, in which a new elastic-net model identification algorithm using singular value decomposition is employed at the lower level, and then, two regularization parameters are optimized using a particle-swarm-optimization algorithm at the upper level by minimizing the leave-one-out (LOO) misclassification rate. It is shown that the LOO misclassification rate based on the resultant prefiltered signal can be analytically computed without splitting the data set, and the associated computational cost is minimal due to orthogonality. The second stage of sparse classifier construction is based on orthogonal forward regression with the D-optimality algorithm. Extensive simulations of this approach for noisy data sets illustrate the competitiveness of this approach to classification of noisy data problems.", "paper_title": "Elastic-Net Prefiltering for Two-Class Classification", "paper_id": "WOS:000317643500023"}