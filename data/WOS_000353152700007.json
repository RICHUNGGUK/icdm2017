{"auto_keywords": [{"score": 0.04137933977553009, "phrase": "minority_samples"}, {"score": 0.033851541801474476, "phrase": "imbalanced_graph_streams"}, {"score": 0.00481495049065317, "phrase": "graph_ensemble"}, {"score": 0.004752873752686246, "phrase": "imbalanced_noisy_graph_stream_classification"}, {"score": 0.004651177631663439, "phrase": "stream_data"}, {"score": 0.0040672766251859975, "phrase": "significant_challenges"}, {"score": 0.0035564156572789473, "phrase": "class_imbalance"}, {"score": 0.0032471982781283374, "phrase": "classification_model"}, {"score": 0.0030428787018636147, "phrase": "ensemble-based_framework"}, {"score": 0.0030166226457616616, "phrase": "partition_graph_stream"}, {"score": 0.002913837945508097, "phrase": "noisy_graphs"}, {"score": 0.002888692115811987, "phrase": "imbalanced_class_distributions"}, {"score": 0.0028390477456009568, "phrase": "individual_chunk"}, {"score": 0.0027781870000242004, "phrase": "boosting_algorithm"}, {"score": 0.0027422968723193057, "phrase": "discriminative_subgraph_pattern_selection"}, {"score": 0.0026718978608934077, "phrase": "unified_framework"}, {"score": 0.0026488343783448273, "phrase": "graph_classification"}, {"score": 0.0025696647013416863, "phrase": "graph_streams"}, {"score": 0.0025364615261136655, "phrase": "instance_level_weighting_mechanism"}, {"score": 0.0024606422183102382, "phrase": "instance_weight"}, {"score": 0.0024078737745407614, "phrase": "boosting_framework"}, {"score": 0.0023664730217196252, "phrase": "difficult_graph_samples"}, {"score": 0.0023056996845692355, "phrase": "different_graph_chunks"}, {"score": 0.0022562464662197867, "phrase": "graph_stream_classification"}, {"score": 0.002169882514603539, "phrase": "clear_benefits"}, {"score": 0.0021049977753042253, "phrase": "imbalanced_noisy_graph_stream"}], "paper_keywords": ["Data streams", " graph ensemble boosting (gEBoost)", " graphs", " imbalanced class distributions", " noise"], "paper_abstract": "Many applications involve stream data with structural dependency, graph representations, and continuously increasing volumes. For these applications, it is very common that their class distributions are imbalanced with minority (or positive) samples being only a small portion of the population, which imposes significant challenges for learning models to accurately identify minority samples. This problem is further complicated with the presence of noise, because they are similar to minority samples and any treatment for the class imbalance may falsely focus on the noise and result in deterioration of accuracy. In this paper, we propose a classification model to tackle imbalanced graph streams with noise. Our method, graph ensemble boosting, employs an ensemble-based framework to partition graph stream into chunks each containing a number of noisy graphs with imbalanced class distributions. For each individual chunk, we propose a boosting algorithm to combine discriminative subgraph pattern selection and model learning as a unified framework for graph classification. To tackle concept drifting in graph streams, an instance level weighting mechanism is used to dynamically adjust the instance weight, through which the boosting framework can emphasize on difficult graph samples. The classifiers built from different graph chunks form an ensemble for graph stream classification. Experiments on real-life imbalanced graph streams demonstrate clear benefits of our boosting design for handling imbalanced noisy graph stream.", "paper_title": "Graph Ensemble Boosting for Imbalanced Noisy Graph Stream Classification", "paper_id": "WOS:000353152700007"}