{"auto_keywords": [{"score": 0.029749626569268276, "phrase": "snr"}, {"score": 0.006492869075996293, "phrase": "rv"}, {"score": 0.00481495049065317, "phrase": "lower_bounds"}, {"score": 0.00473320761888448, "phrase": "provable_lower_bounds"}, {"score": 0.004270960586542813, "phrase": "finite-size_alphabet"}, {"score": 0.00418046991987597, "phrase": "discrete-valued_random_variable"}, {"score": 0.004039639718055365, "phrase": "gaussian_rv."}, {"score": 0.0038702288460744274, "phrase": "precursor_intersymbol_interference"}, {"score": 0.0037719988989298983, "phrase": "decision_feedback_equalizer"}, {"score": 0.003432604816716035, "phrase": "symmetric_information_rate"}, {"score": 0.003288567185099276, "phrase": "isi_channel"}, {"score": 0.0032465423581390625, "phrase": "gaussian_noise"}, {"score": 0.003137074867443131, "phrase": "well-known_finite-isi_channels"}, {"score": 0.0029579636865134885, "phrase": "shamai"}, {"score": 0.002877776711145848, "phrase": "laroia"}, {"score": 0.0028302635493019867, "phrase": "signal-to-noise_ratio"}, {"score": 0.0026538960171433985, "phrase": "high_snrs"}, {"score": 0.0026199603775129516, "phrase": "new_lower_bounds"}, {"score": 0.0025207284405252914, "phrase": "\"mismatched\"_mutual_information_function"}, {"score": 0.0021049977753042253, "phrase": "small_computational_load"}], "paper_keywords": ["Channel capacity", " decision feedback equalizer", " information rate", " intersymbol interference", " lower bounds", " mutual information"], "paper_abstract": "Provable lower bounds are presented for the information rate I(X; X + S + N) where X is the symbol drawn independently and uniformly from a finite-size alphabet, S is a discrete-valued random variable (RV) and N is a Gaussian RV. It is well known that with S representing the precursor intersymbol interference (ISI) at the decision feedback equalizer (DFE) output, I(X; X + S + N) serves as a tight lower bound for the symmetric information rate (SIR) as well as capacity of the ISI channel corrupted by Gaussian noise. When evaluated on a number of well-known finite-ISI channels, these new bounds provide a very similar level of tightness against the SIR to the conjectured lower bound by Shamai and Laroia at all signal-to-noise ratio (SNR) ranges, while being actually tighter when viewed closed up at high SNRs. The new lower bounds are obtained in two steps: First, a \"mismatched\" mutual information function is introduced which can be proved as a lower bound to I(X; X + S + N) Secondly, this function is further bounded from below by an expression that can be computed easily via a few single-dimensional integrations with a small computational load.", "paper_title": "Easily Computed Lower Bounds on the Information Rate of Intersymbol Interference Channels", "paper_id": "WOS:000300246900025"}