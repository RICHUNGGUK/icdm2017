{"auto_keywords": [{"score": 0.03622410301658812, "phrase": "direct_similarities"}, {"score": 0.00481495049065317, "phrase": "distances_and_means_of_direct_similarities"}, {"score": 0.0047587234712024775, "phrase": "non-euclidean_nature"}, {"score": 0.004648222388468414, "phrase": "euclidean_space"}, {"score": 0.004005339423663657, "phrase": "direct_isometry"}, {"score": 0.003958529104387973, "phrase": "positive_uniform_scaling"}, {"score": 0.003279559293934528, "phrase": "squared_divergences"}, {"score": 0.003191572682819548, "phrase": "euclidean"}, {"score": 0.003141093559655865, "phrase": "matrix_representation"}, {"score": 0.003056029284235528, "phrase": "lie_group_theory"}, {"score": 0.002973261772253616, "phrase": "left-invariant_distances"}, {"score": 0.0029384777371425862, "phrase": "riemannian_geometry"}, {"score": 0.002727409429089543, "phrase": "novel_family"}, {"score": 0.0027060907634889734, "phrase": "left-invariant_divergences"}, {"score": 0.0026744402846872093, "phrase": "srt"}, {"score": 0.0025816239578784067, "phrase": "standard_divergences"}, {"score": 0.002501835053002899, "phrase": "derived_properties"}, {"score": 0.0023773911659018825, "phrase": "synthetic_data"}, {"score": 0.002285883886723896, "phrase": "real-world_application"}, {"score": 0.0021467260992026295, "phrase": "new_divergences"}], "paper_keywords": ["Direct similarity", " Distance", " Mean", " Registration", " Object recognition"], "paper_abstract": "The non-Euclidean nature of direct isometries in a Euclidean space, i.e. transformations consisting of a rotation and a translation, creates difficulties when computing distances, means and distributions over them, which have been well studied in the literature. Direct similarities, transformations consisting of a direct isometry and a positive uniform scaling, present even more of a challenge-one which we demonstrate and address here. In this article, we investigate divergences (a superset of distances without constraints on symmetry and sub-additivity) for comparing direct similarities, and means induced by them via minimizing a sum of squared divergences. We analyze several standard divergences: the Euclidean distance using the matrix representation of direct similarities, a divergence from Lie group theory, and the family of all left-invariant distances derived from Riemannian geometry. We derive their properties and those of their induced means, highlighting several shortcomings. In addition, we introduce a novel family of left-invariant divergences, called SRT divergences, which resolve several issues associated with the standard divergences. In our evaluation we empirically demonstrate the derived properties of the divergences and means, both qualitatively and quantitatively, on synthetic data. Finally, we compare the divergences in a real-world application: vote-based, scale-invariant object recognition. Our results show that the new divergences presented here, and their means, are both more effective and faster to compute for this task.", "paper_title": "Distances and Means of Direct Similarities", "paper_id": "WOS:000353159600002"}