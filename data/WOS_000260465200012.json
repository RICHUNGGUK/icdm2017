{"auto_keywords": [{"score": 0.04645434007699365, "phrase": "coding_efficiency"}, {"score": 0.028003757414044973, "phrase": "model-based_estimation"}, {"score": 0.00481495049065317, "phrase": "-based_correlation_estimation"}, {"score": 0.004788936788674301, "phrase": "distributed_source_coding_under_rate"}, {"score": 0.004686367933224672, "phrase": "dsc"}, {"score": 0.004635765943321778, "phrase": "correlation_information"}, {"score": 0.004475329531698828, "phrase": "encoding_rate"}, {"score": 0.004355688788648902, "phrase": "correlation_estimation"}, {"score": 0.004216316375000129, "phrase": "estimation_error"}, {"score": 0.0041935232812319295, "phrase": "compression_efficiency"}, {"score": 0.004103571390356404, "phrase": "dsc_problem"}, {"score": 0.0039507551536392595, "phrase": "complexity_constraints"}, {"score": 0.0038555230685370034, "phrase": "dsc_framework"}, {"score": 0.003834672885739794, "phrase": "practical_distributed_image"}, {"score": 0.003813935026397848, "phrase": "video_applications"}, {"score": 0.0037320948619083702, "phrase": "binary_correlation_models"}, {"score": 0.0036918332580584768, "phrase": "slepian-wolf_coding"}, {"score": 0.003671865026158296, "phrase": "sampling_techniques"}, {"score": 0.0034780071331554003, "phrase": "first_part"}, {"score": 0.00338493754743055, "phrase": "binary_data"}, {"score": 0.003197492724448062, "phrase": "coding_rate_penalty"}, {"score": 0.0031203609829058587, "phrase": "single_binary_source"}, {"score": 0.003036832649117453, "phrase": "multiple_binary_sources"}, {"score": 0.002868609051439957, "phrase": "different_sources"}, {"score": 0.0028376361457661415, "phrase": "overall_rate_penalty"}, {"score": 0.0027541694378728004, "phrase": "total_number"}, {"score": 0.002687702958515561, "phrase": "paper_studies_compression"}, {"score": 0.0026731512522544312, "phrase": "continuous-valued_data"}, {"score": 0.0026157259734105, "phrase": "particular_but_important_situations"}, {"score": 0.0026015629469149384, "phrase": "binary_bit-planes"}, {"score": 0.0025664891161790437, "phrase": "continuous-valued_input_source"}, {"score": 0.002511352026257741, "phrase": "dsc."}, {"score": 0.002497750121448195, "phrase": "proposed_model-based_method"}, {"score": 0.0024573914320899968, "phrase": "correlation_noise_models"}, {"score": 0.0024440836179156593, "phrase": "continuous-valued_samples"}, {"score": 0.00237861522566195, "phrase": "bit-plane_statistics"}, {"score": 0.002198485165633691, "phrase": "wavelet-based_applications"}, {"score": 0.00214540018664566, "phrase": "hyper-spectral_image_compression"}, {"score": 0.0021049977753042253, "phrase": "proposed_algorithms"}], "paper_keywords": [""], "paper_abstract": "In many practical distributed source coding (DSC) applications, correlation information has to be estimated at the encoder in order to determine the encoding rate. Coding efficiency depends strongly on the accuracy of this correlation estimation. While error in estimation is inevitable, the impact of estimation error on compression efficiency has not been sufficiently studied for the DSC problem. In this paper, we study correlation estimation subject to rate and complexity constraints, and its impact on coding efficiency in a DSC framework for practical distributed image and video applications. We focus on, in particular, applications where binary correlation models are exploited for Slepian-Wolf coding and sampling techniques are used to estimate the correlation, while extensions to other correlation models would also be briefly discussed. In the first part of this paper, we investigate the compression of binary data. We first propose a model to characterize the relationship between the number of samples used in estimation and the coding rate penalty, in the case of encoding of a single binary source. The model is then extended to scenarios where multiple binary sources are compressed, and based on the model we propose an algorithm to determine the number of samples allocated to different sources so that the overall rate penalty can be minimized, subject to a constraint on the total number of samples. The second part of this paper studies compression of continuous-valued data. We propose a model-based estimation for the particular but important situations where binary bit-planes are extracted from a continuous-valued input source, and each bit-plane is compressed using DSC. The proposed model-based method first estimates the source and correlation noise models using continuous-valued samples, and then uses the models to derive the bit-plane statistics analytically. We also extend the model-based estimation to the cases when bit-planes are extracted based on the significance of the data, similar to those commonly used in wavelet-based applications. Experimental results, including some based on hyper-spectral image compression, demonstrate the effectiveness of the proposed algorithms.", "paper_title": "Sampling-Based Correlation Estimation for Distributed Source Coding Under Rate and Complexity Constraints", "paper_id": "WOS:000260465200012"}