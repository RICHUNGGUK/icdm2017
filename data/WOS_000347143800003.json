{"auto_keywords": [{"score": 0.03185149409800905, "phrase": "text_components"}, {"score": 0.015719716506582538, "phrase": "video_script_identification"}, {"score": 0.004783232571029632, "phrase": "multi-script_identification"}, {"score": 0.004689321062844586, "phrase": "appropriate_ocr"}, {"score": 0.004551883842967241, "phrase": "video_frames"}, {"score": 0.004492094831481931, "phrase": "low_resolution"}, {"score": 0.004462494148878735, "phrase": "complex_background"}, {"score": 0.004317378385832431, "phrase": "text_information"}, {"score": 0.0042325743185503825, "phrase": "novel_idea"}, {"score": 0.0039748192550806815, "phrase": "block_level"}, {"score": 0.003922580121023413, "phrase": "error_factor"}, {"score": 0.003807529003314843, "phrase": "six_video_scripts"}, {"score": 0.0037575016983755886, "phrase": "arabic"}, {"score": 0.0037327520505380457, "phrase": "chinese"}, {"score": 0.0037082177266380867, "phrase": "english"}, {"score": 0.0036836597948039494, "phrase": "japanese"}, {"score": 0.003659349577753594, "phrase": "korean"}, {"score": 0.003635211101377326, "phrase": "tamil"}, {"score": 0.0036112323484812675, "phrase": "horizontal_and_vertical_gradient_values"}, {"score": 0.0035402494307399733, "phrase": "text_block"}, {"score": 0.0034706569037527774, "phrase": "text_pixels"}, {"score": 0.0032483801419536675, "phrase": "horizontal_direction"}, {"score": 0.0032269483581856737, "phrase": "histogram_operation"}, {"score": 0.0031426214970263137, "phrase": "dominant_text_pixels"}, {"score": 0.0031218852898830755, "phrase": "respective_subparts"}, {"score": 0.003060491505805715, "phrase": "vertical_gradient_blocks"}, {"score": 0.0028173769301594745, "phrase": "structural_features"}, {"score": 0.002789528662623221, "phrase": "end_points"}, {"score": 0.002771115819151223, "phrase": "intersection_points"}, {"score": 0.002752824177838148, "phrase": "junction_points"}, {"score": 0.002663156413861478, "phrase": "novel_way"}, {"score": 0.0025509294021449254, "phrase": "six_scripts"}, {"score": 0.0025090323307618632, "phrase": "font_size"}, {"score": 0.002427286272201272, "phrase": "existing_method"}, {"score": 0.002395336706478158, "phrase": "classification_rate"}, {"score": 0.0023795195973873636, "phrase": "experimental_results"}, {"score": 0.0023481972886024347, "phrase": "proposed_method"}, {"score": 0.002241773449372999, "phrase": "noisy_images"}, {"score": 0.0022196020509093694, "phrase": "low_resolution_documents"}, {"score": 0.002147265537489893, "phrase": "proposed_gradient-spatial-structural_features"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Video text blocks", " Gradient blocks", " Dominant video text pixels", " Gradient-Spatial-Structural-Features", " Video script identification"], "paper_abstract": "Multi-script identification helps in automatically selecting an appropriate OCR when video has several scripts; however, script identification in video frames is challenging because low resolution and complex background of video often cause disconnections or the loss of text information. This paper presents a novel idea that integrates the Gradient-Spatial-Features (GSpF) and the Gradient-Structural-Features (GStF) at block level based on an error factor and the weights of the features to identify six video scripts, namely, Arabic, Chinese, English, Japanese, Korean and Tamil. Horizontal and vertical gradient values are first computed for each text block to increase the contrast of text pixels. Then the method divides the horizontal and the vertical gradient blocks into two equal parts at the centroid in the horizontal direction. Histogram operation on each part is performed to select dominant text pixels from respective subparts of the horizontal and the vertical gradient blocks, which results in text components. After extracting GSpF and GStF from the text components, we finally propose to integrate the spatial and the structural features based on end points, intersection points, junction points and straightness of the skeleton of text components in a novel way to identify the scripts. The method is evaluated on 970 video frames of six scripts which involves font, font size or contrast variations, and is compared with an existing method in terms of classification rate. Experimental results show that the proposed method achieves 83.0% average classification rate for video script identification. The method is also evaluated by testing on noisy images and scanned low resolution documents, illustrating the robustness and the extensibility of the proposed Gradient-Spatial-Structural Features. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "New Gradient-Spatial-Structural Features for video script identification", "paper_id": "WOS:000347143800003"}