{"auto_keywords": [{"score": 0.04916809664432026, "phrase": "chunks"}, {"score": 0.04526127683762939, "phrase": "application_programmer"}, {"score": 0.04145983454477273, "phrase": "chunks_and_tasks_library"}, {"score": 0.03814164409668085, "phrase": "high_performance"}, {"score": 0.00481495049065317, "phrase": "dynamic_algorithms"}, {"score": 0.0041287394089001405, "phrase": "smaller_pieces"}, {"score": 0.0038230844545071303, "phrase": "physical_resources"}, {"score": 0.0036611708297251645, "phrase": "user_friendliness"}, {"score": 0.0035060903664150115, "phrase": "parallel_algorithm"}, {"score": 0.0033737457695128233, "phrase": "work_objects"}, {"score": 0.003293570937654716, "phrase": "explicit_communication_calls"}, {"score": 0.0030203487665054806, "phrase": "efficient_implementation"}, {"score": 0.0029914213495838998, "phrase": "complex_applications"}, {"score": 0.002948547333717581, "phrase": "dynamic_distribution"}, {"score": 0.0027704360092064783, "phrase": "tasks"}, {"score": 0.0024914105981393127, "phrase": "fundamental_abstractions"}, {"score": 0.0024556852466581527, "phrase": "programming_model"}, {"score": 0.002329009499335603, "phrase": "resilience_considerations"}, {"score": 0.002219516542316085, "phrase": "multicore_machines"}, {"score": 0.002166711569953301, "phrase": "irregular_block-sparse_matrix-matrix_multiplication"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Distributed memory parallelization", " Dynamic data distribution", " Dynamic load balancing", " Fault tolerance", " Parallel programming model", " Determinism"], "paper_abstract": "We propose Chunks and Tasks, a parallel programming model built on abstractions for both data and work. The application programmer specifies how data and work can be split into smaller pieces, chunks and tasks, respectively. The Chunks and Tasks library maps the chunks and tasks to physical resources. In this way we seek to combine user friendliness with high performance. An application programmer can express a parallel algorithm using a few simple building blocks, defining data and work objects and their relationships. No explicit communication calls are needed; the distribution of both work and data is handled by the Chunks and Tasks library. This makes efficient implementation of complex applications that require dynamic distribution of work and data easier. At the same time, Chunks and Tasks imposes restrictions on data access and task dependencies that facilitate the development of high performance parallel back ends. We discuss the fundamental abstractions underlying the programming model, as well as performance, determinism, and fault resilience considerations. We also present a pilot C++ library implementation for clusters of multicore machines and demonstrate its performance for irregular block-sparse matrix-matrix multiplication. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Chunks and Tasks: A programming model for parallelization of dynamic algorithms", "paper_id": "WOS:000339598400013"}