{"auto_keywords": [{"score": 0.03317679677856877, "phrase": "scene_changes"}, {"score": 0.00481495049065317, "phrase": "optical_flow"}, {"score": 0.004769444094319619, "phrase": "scene_change_detection"}, {"score": 0.004569905085027681, "phrase": "optical_flow_information"}, {"score": 0.004195418010131832, "phrase": "mobile_camera"}, {"score": 0.004038943596016986, "phrase": "optical_flow_signal"}, {"score": 0.003962899903266524, "phrase": "robust_flow_vectors"}, {"score": 0.0037789720824759503, "phrase": "depth_discontinuities"}, {"score": 0.0037432199549135826, "phrase": "appearance_changes"}, {"score": 0.00370780481244907, "phrase": "key_locations"}, {"score": 0.0035525230119401153, "phrase": "full_discussion"}, {"score": 0.0035189057079817285, "phrase": "camera_positioning"}, {"score": 0.003485605409687907, "phrase": "distortion_compensation"}, {"score": 0.0034526191487098093, "phrase": "noise_filtering"}, {"score": 0.0034037221513153566, "phrase": "parameter_estimation"}, {"score": 0.0032922964156452696, "phrase": "statistical_attributes"}, {"score": 0.0032456625605347417, "phrase": "flow_signal"}, {"score": 0.003036595866130994, "phrase": "dominant_shape"}, {"score": 0.0027741761880779535, "phrase": "detected_scene_change"}, {"score": 0.002546466113418944, "phrase": "topological_localization"}, {"score": 0.0024051153560799335, "phrase": "mahalanobis_and_chi-square_distances"}, {"score": 0.0021557052355026048, "phrase": "diverse_lighting_conditions"}, {"score": 0.0021251363422701446, "phrase": "indoor_and_outdoor_environments"}, {"score": 0.0021049977753042253, "phrase": "different_robot_platforms"}], "paper_keywords": ["Scene change detection", " Optical flow descriptor", " Mapping and localization", " Computer vision", " Mobile robots"], "paper_abstract": "We propose the use of optical flow information as a method for detecting and describing changes in the environment, from the perspective of a mobile camera. We analyze the characteristics of the optical flow signal and demonstrate how robust flow vectors can be generated and used for the detection of depth discontinuities and appearance changes at key locations. To successfully achieve this task, a full discussion on camera positioning, distortion compensation, noise filtering, and parameter estimation is presented. We then extract statistical attributes from the flow signal to describe the location of the scene changes. We also employ clustering and dominant shape of vectors to increase the descriptiveness. Once a database of nodes (where a node is a detected scene change) and their corresponding flow features is created, matching can be performed whenever nodes are encountered, such that topological localization can be achieved. We retrieve the most likely node according to the Mahalanobis and Chi-square distances between the current frame and the database. The results illustrate the applicability of the technique for detecting and describing scene changes in diverse lighting conditions, considering indoor and outdoor environments and different robot platforms.", "paper_title": "On the Use of Optical Flow for Scene Change Detection and Description", "paper_id": "WOS:000336449900016"}