{"auto_keywords": [{"score": 0.03549931087351772, "phrase": "run_time"}, {"score": 0.00481495049065317, "phrase": "channel-level_acceleration_of"}, {"score": 0.004785356349906913, "phrase": "deep_face_representations"}, {"score": 0.004697655699119423, "phrase": "major_challenge"}, {"score": 0.004444037594955185, "phrase": "client_side"}, {"score": 0.004362564831572539, "phrase": "hardware_resources"}, {"score": 0.004230068512904886, "phrase": "deep_learning_approaches"}, {"score": 0.004152502093643003, "phrase": "unique_challenge"}, {"score": 0.0033251716926666437, "phrase": "network_size"}, {"score": 0.0031260524791486347, "phrase": "compression_methods"}, {"score": 0.0030497740719977835, "phrase": "deep_face_nets"}, {"score": 0.002831894638104635, "phrase": "object_recognition_networks"}, {"score": 0.0025027144548626975, "phrase": "lowly_active_channels"}, {"score": 0.0023819914954155905, "phrase": "repeated_use"}, {"score": 0.0023527296826339225, "phrase": "already_computed_elements"}, {"score": 0.002295277579105177, "phrase": "entire_channels"}, {"score": 0.0022531089868518235, "phrase": "appealing_idea"}, {"score": 0.0021049977753042253, "phrase": "almost_every_reasonable_architecture"}], "paper_keywords": ["Face recognition", " neural network compression"], "paper_abstract": "A major challenge in biometrics is performing the test at the client side, where hardware resources are often limited. Deep learning approaches pose a unique challenge: while such architectures dominate the field of face recognition with regard to accuracy, they require elaborate, multi-stage computations. Recently, there has been some work on compressing networks for the purpose of reducing run time and network size. However, it is not clear that these compression methods would work in deep face nets, which are, generally speaking, less redundant than the object recognition networks, i.e., they are already relatively lean. We propose two novel methods for compression: one based on eliminating lowly active channels and the other on coupling pruning with repeated use of already computed elements. Pruning of entire channels is an appealing idea, since it leads to direct saving in run time in almost every reasonable architecture.", "paper_title": "Channel-Level Acceleration of Deep Face Representations", "paper_id": "WOS:000371388200166"}