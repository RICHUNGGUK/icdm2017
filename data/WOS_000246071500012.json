{"auto_keywords": [{"score": 0.04521793700326864, "phrase": "feature_selection"}, {"score": 0.00481495049065317, "phrase": "gene_selection"}, {"score": 0.004762550320451225, "phrase": "gene_expression_data"}, {"score": 0.00471071771178029, "phrase": "high_dimensionality"}, {"score": 0.004685012337701536, "phrase": "machine_learning_algorithms"}, {"score": 0.0046340196745259694, "phrase": "feature_selection_techniques"}, {"score": 0.004571055044692412, "phrase": "effective_classification"}, {"score": 0.00454610829874136, "phrase": "microarray_gene_expression_data_sets"}, {"score": 0.004484332781147261, "phrase": "large_number"}, {"score": 0.0041421659519564865, "phrase": "stochastic_optimization"}, {"score": 0.004030310299445338, "phrase": "exponential_number"}, {"score": 0.0040083028097631975, "phrase": "alternative_gene"}, {"score": 0.003921463318953744, "phrase": "highest_generalization"}, {"score": 0.0038470175104007524, "phrase": "experimental_design_strategy"}, {"score": 0.0038155447176837, "phrase": "similar_experimental_conditions"}, {"score": 0.003784328428527216, "phrase": "alternative_stochastic_configurations"}, {"score": 0.0036419834462626125, "phrase": "actual_differences"}, {"score": 0.0035826234811610316, "phrase": "noise_effects"}, {"score": 0.0035338939519719784, "phrase": "original_blocking_strategy"}, {"score": 0.0034572968057822633, "phrase": "paired_way"}, {"score": 0.0034384074513828613, "phrase": "validation_outcomes"}, {"score": 0.003382354267177914, "phrase": "gene_subset"}, {"score": 0.0032550798703544145, "phrase": "conventional_wrappers"}, {"score": 0.003202005703957046, "phrase": "sole_learning_algorithm"}, {"score": 0.002998197231744409, "phrase": "experimental_conditions"}, {"score": 0.0029492991503845003, "phrase": "feature_subset"}, {"score": 0.0027996401456881806, "phrase": "better_selection"}, {"score": 0.0027464325217130283, "phrase": "blocking_strategy"}, {"score": 0.0026942333853202556, "phrase": "conventional_forward_selection"}, {"score": 0.0026213749921120623, "phrase": "six_different_classifiers"}, {"score": 0.002550481822137976, "phrase": "classification_algorithm"}, {"score": 0.002522662955545598, "phrase": "selection_step"}, {"score": 0.002474706265455793, "phrase": "available_biological_annotation_support"}, {"score": 0.002342640118816734, "phrase": "first_validation"}, {"score": 0.0023107372754933887, "phrase": "pubmed_abstracts"}, {"score": 0.002285527382381719, "phrase": "selected_genes"}, {"score": 0.002254400561534981, "phrase": "regular_expressions"}, {"score": 0.0022359278646792153, "phrase": "biological_phenomenon"}, {"score": 0.0022176061978080837, "phrase": "expression_data_sets"}, {"score": 0.0021994343316143125, "phrase": "biological_validation"}, {"score": 0.0021399277552314067, "phrase": "bioconductor_package"}, {"score": 0.0021049977753042253, "phrase": "gene_ontology_statistical_analysis"}], "paper_keywords": ["bioinformatics (genome or protein) databases", " data mining", " machine learning", " feature evaluation and selection"], "paper_abstract": "Because of high dimensionality, machine learning algorithms typically rely on feature selection techniques in order to perform effective classification in microarray gene expression data sets. However, the large number of features compared to the number of samples makes the task of feature selection computationally hard and prone to errors. This paper interprets feature selection as a task of stochastic optimization, where the goal is to select among an exponential number of alternative gene subsets the one expected to return the highest generalization in classification. Blocking is an experimental design strategy which produces similar experimental conditions to compare alternative stochastic configurations in order to be confident that observed differences in accuracy are due to actual differences rather than to fluctuations and noise effects. We propose an original blocking strategy for improving feature selection which aggregates in a paired way the validation outcomes of several learning algorithms to assess a gene subset and compare it to others. This is a novelty with respect to conventional wrappers, which commonly adopt a sole learning algorithm to evaluate the relevance of a given set of variables. The rationale of the approach is that, by increasing the amount of experimental conditions under which we validate a feature subset, we can lessen the problems related to the scarcity of samples and consequently come up with a better selection. The paper shows that the blocking strategy significantly improves the performance of a conventional forward selection for a set of 16 publicly available cancer expression data sets. The experiments involve six different classifiers and show that improvements take place independent of the classification algorithm used after the selection step. Two further validations based on available biological annotation support the claim that blocking strategies in feature selection may improve the accuracy and the quality of the solution. The first validation is based on retrieving PubMEd abstracts associated to the selected genes and matching them to regular expressions describing the biological phenomenon underlying the expression data sets. The biological validation that follows is based on the use of the Bioconductor package GoStats in order to perform Gene Ontology statistical analysis.", "paper_title": "A blocking strategy to improve gene selection for classification of gene expression data", "paper_id": "WOS:000246071500012"}