{"auto_keywords": [{"score": 0.04371077897994308, "phrase": "interest_points"}, {"score": 0.01395236448966716, "phrase": "image_matching"}, {"score": 0.00481495049065317, "phrase": "sparse_color_interest_points_for_image_retrieval"}, {"score": 0.004712463245074863, "phrase": "interest_point_detection"}, {"score": 0.004652016085325825, "phrase": "important_research_area"}, {"score": 0.004552981066668676, "phrase": "image_processing_and_computer_vision"}, {"score": 0.004342430078306461, "phrase": "local_image_descriptors"}, {"score": 0.0036395944934310524, "phrase": "selective_search"}, {"score": 0.003592859432554987, "phrase": "total_number"}, {"score": 0.003441352119167824, "phrase": "color_interest_points"}, {"score": 0.0034118234596993836, "phrase": "sparse_image_representation"}, {"score": 0.003310447652300423, "phrase": "varying_imaging_conditions"}, {"score": 0.0032820385246266773, "phrase": "light-invariant_interest_points"}, {"score": 0.0032259472087775138, "phrase": "color_statistics"}, {"score": 0.0031845067058084583, "phrase": "occurrence_probability_lead"}, {"score": 0.003050166508545763, "phrase": "saliency-based_feature_selection"}, {"score": 0.002985130390111069, "phrase": "principal_component_analysis-based_scale_selection_method"}, {"score": 0.0028963961037320805, "phrase": "robust_scale_estimation"}, {"score": 0.0028715299874549245, "phrase": "interest_point"}, {"score": 0.0028346293790895024, "phrase": "large-scale_experiments"}, {"score": 0.0027503564589458837, "phrase": "proposed_color_interest_point_detector"}, {"score": 0.002680114113899346, "phrase": "luminance-based_one"}, {"score": 0.0025892330566358503, "phrase": "image_retrieval"}, {"score": 0.002555950807368337, "phrase": "reduced_and_predictable_number"}, {"score": 0.002437525632451029, "phrase": "state-of-the-art_interest_points"}, {"score": 0.0023548511815224098, "phrase": "object_recognition"}, {"score": 0.0022651818270925704, "phrase": "comparable_performance"}, {"score": 0.0021049977753042253, "phrase": "computing_time"}], "paper_keywords": ["ARS-IIU", " color invariance", " ELI-COL", " image retrieval", " local features", " object categorization", " SMR-REP"], "paper_abstract": "Interest point detection is an important research area in the field of image processing and computer vision. In particular, image retrieval and object categorization heavily rely on interest point detection from which local image descriptors are computed for image matching. In general, interest points are based on luminance, and color has been largely ignored. However, the use of color increases the distinctiveness of interest points. The use of color may therefore provide selective search reducing the total number of interest points used for image matching. This paper proposes color interest points for sparse image representation. To reduce the sensitivity to varying imaging conditions, light-invariant interest points are introduced. Color statistics based on occurrence probability lead to color boosted points, which are obtained through saliency-based feature selection. Furthermore, a principal component analysis-based scale selection method is proposed, which gives a robust scale estimation per interest point. From large-scale experiments, it is shown that the proposed color interest point detector has higher repeatability than a luminance-based one. Furthermore, in the context of image retrieval, a reduced and predictable number of color features show an increase in performance compared to state-of-the-art interest points. Finally, in the context of object recognition, for the Pascal VOC 2007 challenge, our method gives comparable performance to state-of-the-art methods using only a small fraction of the features, reducing the computing time considerably.", "paper_title": "Sparse Color Interest Points for Image Retrieval and Object Categorization", "paper_id": "WOS:000304160800027"}