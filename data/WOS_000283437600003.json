{"auto_keywords": [{"score": 0.004734987730139094, "phrase": "artificial_organisms"}, {"score": 0.004579005794486596, "phrase": "motor_system"}, {"score": 0.004378958522416482, "phrase": "neural_network"}, {"score": 0.003960101604693806, "phrase": "right_handle"}, {"score": 0.0036621225944272256, "phrase": "handle's_position"}, {"score": 0.002677638852123641, "phrase": "tucker"}, {"score": 0.002647872917979199, "phrase": "ellis"}, {"score": 0.0024075916292945715, "phrase": "compatible_condition"}, {"score": 0.002176887956041267, "phrase": "incompatible_condition"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Affordances", " Spatial compatibility", " Neural networks", " Embodied cognition", " Genetic algorithm", " Motor system"], "paper_abstract": "In two Artificial Life simulations we evolved artificial organisms possessing a visual and a motor system, and whose nervous system was simulated with a neural network. Each organism could see four objects, either upright or reversed, with a left or a right handle. In Task 1 they learned to reach the object handle independently of the handle's position. In Task 2 they learned to reach one of two buttons located below the handle either to decide where the handle was (Simulation 1) or whether the object was upright or reversed (Simulation 2). Task 1 simulated real life experience, Task 2 replicated either a classic spatial compatibility task (Simulation 1) or an experiment by Tucker and Ellis (1998) (Simulation 2). In both simulations learning occurred earlier in the Compatible condition, when the button to reach and the handle were on the same side, than in the Incompatible condition. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Objects, spatial compatibility, and affordances: A connectionist study", "paper_id": "WOS:000283437600003"}