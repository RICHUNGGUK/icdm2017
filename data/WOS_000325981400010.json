{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "fixed_expansion_layer_networks"}, {"score": 0.004539005582217309, "phrase": "well-studied_attribute"}, {"score": 0.004406994912939125, "phrase": "learning_systems"}, {"score": 0.004105558123159003, "phrase": "feedforward_neural_networks"}, {"score": 0.0040097139701644165, "phrase": "nonstationary_inputs"}, {"score": 0.0038930368103015467, "phrase": "previously_learned_mappings"}, {"score": 0.0036052633308076933, "phrase": "catastrophic_forgetting"}, {"score": 0.0033190180867511605, "phrase": "fixed_expansion_layer"}, {"score": 0.0031100973266506163, "phrase": "sparsely_encoding_hidden_layer"}, {"score": 0.0030017207229983385, "phrase": "prior_learned_representations"}, {"score": 0.0028630535573013686, "phrase": "novel_framework"}, {"score": 0.0028293966058473476, "phrase": "training_ensembles"}, {"score": 0.0027961342030212353, "phrase": "fel_networks"}, {"score": 0.0026986685585382347, "phrase": "information-theoretic_measure"}, {"score": 0.0026355812883224203, "phrase": "fel_learners"}, {"score": 0.0025587867729949037, "phrase": "undesired_plasticity"}, {"score": 0.0025137856138000014, "phrase": "proposed_methodology"}, {"score": 0.0024405312482831646, "phrase": "basic_classification_task"}, {"score": 0.0023554316787703137, "phrase": "existing_techniques"}, {"score": 0.002181069180139225, "phrase": "computational_intelligence_tasks"}, {"score": 0.002130056082139311, "phrase": "regression_problems"}, {"score": 0.0021049977753042253, "phrase": "system_control"}], "paper_keywords": ["Catastrophic forgetting", " nonstationary inputs", " sparse encoding neural networks"], "paper_abstract": "Catastrophic forgetting is a well-studied attribute of most parameterized supervised learning systems. A variation of this phenomenon, in the context of feedforward neural networks, arises when nonstationary inputs lead to loss of previously learned mappings. The majority of the schemes proposed in the literature for mitigating catastrophic forgetting were not data driven and did not scale well. We introduce the fixed expansion layer (FEL) feedforward neural network, which embeds a sparsely encoding hidden layer to help mitigate forgetting of prior learned representations. In addition, we investigate a novel framework for training ensembles of FEL networks, based on exploiting an information-theoretic measure of diversity between FEL learners, to further control undesired plasticity. The proposed methodology is demonstrated on a basic classification task, clearly emphasizing its advantages over existing techniques. The architecture proposed can be enhanced to address a range of computational intelligence tasks, such as regression problems and system control.", "paper_title": "Ensemble Learning in Fixed Expansion Layer Networks for Mitigating Catastrophic Forgetting", "paper_id": "WOS:000325981400010"}