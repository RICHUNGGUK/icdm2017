{"auto_keywords": [{"score": 0.048835745230446134, "phrase": "semantic-visual_knowledge_base"}, {"score": 0.00481495049065317, "phrase": "enhancing_video_event"}, {"score": 0.004155113657645735, "phrase": "complex_nature"}, {"score": 0.004111584914709491, "phrase": "user-defined_events"}, {"score": 0.0040047396607954325, "phrase": "purely_audio-visual_content_analysis"}, {"score": 0.0035106041824568618, "phrase": "rich_event-centric_concepts"}, {"score": 0.0034013521529056715, "phrase": "well-established_lexical_databases"}, {"score": 0.0033480084982607868, "phrase": "framenet"}, {"score": 0.0032437952431945724, "phrase": "concept-specific_visual_knowledge"}, {"score": 0.0032098198946008123, "phrase": "imagenet"}, {"score": 0.0031262984171100856, "phrase": "semantic-visual_knowledge_bases"}, {"score": 0.0030449789178940787, "phrase": "effective_system"}, {"score": 0.0030130446986008277, "phrase": "video_event_recognition"}, {"score": 0.0028734230458881903, "phrase": "semantic_gap"}, {"score": 0.002828331235643921, "phrase": "high-level_complex_events"}, {"score": 0.002798662730881037, "phrase": "low-level_visual_representations"}, {"score": 0.0027258422018680453, "phrase": "event-centric_semantic_concepts"}, {"score": 0.0026689487424251907, "phrase": "knowledge_base"}, {"score": 0.0026270572353632297, "phrase": "intermediate-level_event_representation"}, {"score": 0.0025052769325080255, "phrase": "machine-interpretable_semantic_clues"}, {"score": 0.002339246282204109, "phrase": "abundant_imagenet_images"}, {"score": 0.0022783523466965187, "phrase": "robust_transfer_learning_model"}, {"score": 0.0022307779508260205, "phrase": "noise-resistant_concept_classifiers"}, {"score": 0.00218419478369074, "phrase": "extensive_experiments"}], "paper_keywords": ["Concept detection", " event recognition", " knowledge base"], "paper_abstract": "The task of recognizing events from video has attracted a lot of attention in recent years. However, due to the complex nature of user-defined events, the use of purely audio-visual content analysis without domain knowledge has been found to be grossly inadequate. In this paper, we propose to construct a semantic-visual knowledge base to encode the rich event-centric concepts and their relationships from the well-established lexical databases, including FrameNet, as well as the concept-specific visual knowledge from ImageNet. Based on this semantic-visual knowledge bases, we design an effective system for video event recognition. Specifically, in order to narrow the semantic gap between the high-level complex events and low-level visual representations, we utilize the event-centric semantic concepts encoded in the knowledge base as the intermediate-level event representation, which offers both human-perceivable and machine-interpretable semantic clues for event recognition. In addition, in order to leverage the abundant ImageNet images, we propose a robust transfer learning model to learn the noise-resistant concept classifiers for videos. Extensive experiments on various real-world video datasets demonstrate the superiority of our proposed system as compared to the state-of-the-art approaches.", "paper_title": "Enhancing Video Event Recognition Using Automatically Constructed Semantic-Visual Knowledge Base", "paper_id": "WOS:000359583000016"}