{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "statistical_correlations"}, {"score": 0.0496463517482477, "phrase": "image_retrieval"}, {"score": 0.004685575787741084, "phrase": "cognitive_gap"}, {"score": 0.004559661374976129, "phrase": "active_research_direction"}, {"score": 0.004417012437860011, "phrase": "key_challenge"}, {"score": 0.004259418153299952, "phrase": "mapping_functions"}, {"score": 0.0042209023469249205, "phrase": "low-level_feature_spaces"}, {"score": 0.0041827333568982055, "phrase": "high-level_semantics"}, {"score": 0.004070276454809864, "phrase": "image_regions"}, {"score": 0.0038895008852940323, "phrase": "main_semantic_contents"}, {"score": 0.00385431710959668, "phrase": "environmental_regions"}, {"score": 0.0034717929086014636, "phrase": "context_expansion_approach"}, {"score": 0.00330246222643051, "phrase": "key_regions"}, {"score": 0.0032282396745967504, "phrase": "highly_correlated_environmental_regions"}, {"score": 0.003170060683860338, "phrase": "image_thesaurus"}, {"score": 0.003056819704624705, "phrase": "image_low-level_features"}, {"score": 0.0029209233709517634, "phrase": "different_concepts"}, {"score": 0.0028293966058473476, "phrase": "data-driven_approach"}, {"score": 0.0027910516355928983, "phrase": "web_data"}, {"score": 0.00266693888510356, "phrase": "training_data_source"}, {"score": 0.0026188490199688013, "phrase": "region_concepts"}, {"score": 0.002536763634539386, "phrase": "experimental_results"}, {"score": 0.0023802126605244438, "phrase": "search_precision"}, {"score": 0.0022537212268979507, "phrase": "relevant_images"}], "paper_keywords": ["query expansion", " image thesaurus", " content-based image retrieval", " region-based image retrieval"], "paper_abstract": "Bridging the cognitive gap in image retrieval has been an active research direction in recent years, of which a key challenge is to get enough training data to learn the mapping functions from low-level feature spaces to high-level semantics. In this paper, image regions are classified into two types: key regions representing the main semantic contents and environmental regions representing the contexts. We attempt to leverage the correlations between types of regions to improve the performance of image retrieval. A Context Expansion approach is explored to take advantages of such correlations by expanding the key regions of the queries using highly correlated environmental regions according to an image thesaurus. The thesaurus serves as both a mapping function between image low-level features and concepts and a store of the statistical correlations between different concepts. It is constructed through a data-driven approach which uses Web data (images, their surrounding textual annotations) as training data source to learn the region concepts and to explore the statistical correlations. Experimental results on a database of 10,000 general-purpose images show the effectiveness of our proposed approach in both improving search precision (i.e. filter irrelevant images) and recall (i.e. retrieval relevant images whose context may be varied). Several major factors which have impact on the performance of our approach are also studied.", "paper_title": "Exploring statistical correlations for image retrieval", "paper_id": "WOS:000236982300004"}