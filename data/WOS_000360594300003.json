{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "randomization_mechanisms"}, {"score": 0.024510259704186278, "phrase": "utility_rate"}, {"score": 0.004598027492787762, "phrase": "effective_technique"}, {"score": 0.004549366134876482, "phrase": "sensitive_information"}, {"score": 0.004469400468609653, "phrase": "information-theoretic_channels"}, {"score": 0.004375286710337962, "phrase": "semantic_notion"}, {"score": 0.004237803085579238, "phrase": "privacy_breach"}, {"score": 0.004032441847334232, "phrase": "background_information"}, {"score": 0.003961526165403768, "phrase": "prior_probability"}, {"score": 0.0039195744361570075, "phrase": "secret_inputs"}, {"score": 0.0037428381813152532, "phrase": "average_case"}, {"score": 0.0036900720643677034, "phrase": "repeated_observations"}, {"score": 0.0035740424892197155, "phrase": "security_level"}, {"score": 0.003486316700608598, "phrase": "simple_fashion"}, {"score": 0.003412833120814178, "phrase": "channel_matrix"}, {"score": 0.0032358074601765555, "phrase": "chernoff_information"}, {"score": 0.003089970256435066, "phrase": "dp"}, {"score": 0.0027577972695911825, "phrase": "independent_priors"}, {"score": 0.0026710032893246154, "phrase": "expected_utility"}, {"score": 0.0026146595609362715, "phrase": "ghosh_et_al"}, {"score": 0.0025504217985882725, "phrase": "repeated_independent_observations"}, {"score": 0.0025055037815033725, "phrase": "exponential_growth_rate"}, {"score": 0.0024789326485851666, "phrase": "reasonable_utility_function"}, {"score": 0.0024439412207268355, "phrase": "particular_case"}, {"score": 0.002188947861949892, "phrase": "practically_interesting_cases"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Foundations of security", " Quantitative information flow", " Differential privacy", " Utility", " Information theory"], "paper_abstract": "In a variety of contexts, randomization is regarded as an effective technique to conceal sensitive information. Viewing randomization mechanisms as information-theoretic channels, we start from a semantic notion of security, which expresses absence of any privacy breach above a given level of seriousness is an element of, irrespective of any background information, represented as a prior probability on the secret inputs. We first examine this notion according to two dimensions: worst vs. average case, single vs. repeated observations. In each case, we characterize the security level achievable by a mechanism in a simple fashion that only depends on the channel matrix, and specifically on certain measures of \"distance\" between its rows, like norm-1 distance and Chernoff Information. We next clarify the relation between our worst-case security notion and differential privacy (DP): we show that, while the former is in general stronger, the two coincide if one confines to background information that can be factorized into the product of independent priors over individuals. We finally turn our attention to expected utility, in the sense of Ghosh et al., in the case of repeated independent observations. We characterize the exponential growth rate of any reasonable utility function. In the particular case the mechanism provides is an element of-DP, we study the relation of the utility rate with 6: we offer either exact expressions or upper-bounds for utility rate that apply to practically interesting cases, such as the (truncated) geometric mechanism. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Worst- and average-case privacy breaches in randomization mechanisms", "paper_id": "WOS:000360594300003"}