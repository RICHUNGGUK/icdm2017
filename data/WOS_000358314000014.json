{"auto_keywords": [{"score": 0.029872613721291786, "phrase": "resulting_networks"}, {"score": 0.028974696779470278, "phrase": "power-law_distribution"}, {"score": 0.00481495049065317, "phrase": "scesn"}, {"score": 0.004784909348794283, "phrase": "spesn"}, {"score": 0.004622986791421418, "phrase": "clustered_reservoirs"}, {"score": 0.004565468027464384, "phrase": "nonlinear_and_chaotic_time_series"}, {"score": 0.0043560464825349275, "phrase": "recurrent_neural_network_training"}, {"score": 0.004117329555194574, "phrase": "previous_studies"}, {"score": 0.004078829832634839, "phrase": "largest_eigenvalue"}, {"score": 0.004040688646993605, "phrase": "reservoir_connectivity_matrix"}, {"score": 0.00389164348807591, "phrase": "stable_network_dynamics"}, {"score": 0.0038552459083505985, "phrase": "recent_evidences"}, {"score": 0.003771631577951067, "phrase": "reservoir_substructures"}, {"score": 0.0037246656582642272, "phrase": "stability_criteria"}, {"score": 0.003553674679835236, "phrase": "network_approximation_ability"}, {"score": 0.003531474887552889, "phrase": "esn_networks"}, {"score": 0.0033066374949683014, "phrase": "k-means"}, {"score": 0.0032146290579476923, "phrase": "pam"}, {"score": 0.003125175084962886, "phrase": "internal_neurons"}, {"score": 0.0029909851863915283, "phrase": "backbone_units"}, {"score": 0.0028986672783671147, "phrase": "local_neurons"}, {"score": 0.0028003960243011975, "phrase": "small-world_topology"}, {"score": 0.002756832447586547, "phrase": "new_networks"}, {"score": 0.0026633568650501873, "phrase": "resulting_clustered_networks"}, {"score": 0.00262191949451482, "phrase": "biological_neural_system"}, {"score": 0.0025892330566358503, "phrase": "small-word_feature"}, {"score": 0.0025409639091476363, "phrase": "distributed_architecture"}, {"score": 0.0025014259919355453, "phrase": "prediction_power"}, {"score": 0.0024625017739528096, "phrase": "spectral_radius"}, {"score": 0.00241658945942583, "phrase": "new_esns"}, {"score": 0.0023939545398857518, "phrase": "mackey-glass_dynamic_system"}, {"score": 0.002371531125700046, "phrase": "laser_time_series_prediction_problem"}, {"score": 0.0023200213317312577, "phrase": "previous_works"}, {"score": 0.002283913454238574, "phrase": "echo_state_property"}, {"score": 0.002248366278757655, "phrase": "highly_complex_nonlinear_dynamic_systems"}, {"score": 0.0022064376000055764, "phrase": "previous_approaches"}, {"score": 0.0021652891317252994, "phrase": "proposed_methods"}, {"score": 0.0021450029487459403, "phrase": "previous_ones"}, {"score": 0.0021182494144182805, "phrase": "prediction_accuracy"}, {"score": 0.0021049977753042253, "phrase": "chaotic_time_series"}], "paper_keywords": ["Complex network", " Small-world network", " Power-law network", " Echo state network", " Classic clustering algorithms"], "paper_abstract": "Echo state networks (ESNs) with very simple and linear learning algorithm are a new approach to recurrent neural network training. Recently, these networks have aroused a lot of interest in their nonlinear dynamic system modeling capacities. In previous studies, the largest eigenvalue of the reservoir connectivity matrix (spectral radius) is used as a predictor for the stable network dynamics, but recent evidences show that in the presence of reservoir substructures like clusters, stability criteria in these kind of networks are altered. Some researchers have also demonstrated that network approximation ability in ESN networks is improved by the characteristics of small-world and scale-free. In this paper, we used three classic clustering algorithms called K-Means (C- Centeriod), partitioning Around Medoids (PAM) and ward algorithm, for clustering the internal neurons. After that, we refer to mean nodes in each cluster as backbone units and refer to the other neurons in a cluster as local neurons. Connections between neurons are such that the resulting networks have small-world topology and neurons in the new networks follow a power-law distribution. At first, we demonstrate that resulting clustered networks have some characteristics of biological neural system like power-law distribution, small-word feature, community structure, and distributed architecture. For investigating the prediction power and the range of spectral radius of resulting networks, we use new ESNs on the Mackey-Glass dynamic system and the laser time series prediction problem and compared the results with the previous works. Then we evaluate echo state property and performance of approximating highly complex nonlinear dynamic systems of proposed networks rather than previous approaches. Results show that the proposed methods outperform the previous ones in terms of prediction accuracy of chaotic time series.", "paper_title": "SCESN, SPESN, SWESN: Three recurrent neural echo state networks with clustered reservoirs for prediction of nonlinear and chaotic time series", "paper_id": "WOS:000358314000014"}