{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "visual-context-aware_object_detection"}, {"score": 0.03812983798224722, "phrase": "object_detection"}, {"score": 0.03296414213809495, "phrase": "individual_contextual_cues"}, {"score": 0.004598933498016774, "phrase": "object's_presence"}, {"score": 0.004466519142879166, "phrase": "observed_scene"}, {"score": 0.004266067096140677, "phrase": "object_detection_techniques"}, {"score": 0.00417793854311445, "phrase": "computer_vision"}, {"score": 0.004143196873246147, "phrase": "object_detectors"}, {"score": 0.003859273279966873, "phrase": "visual_contextual_information"}, {"score": 0.0038271712887391015, "phrase": "still_images"}, {"score": 0.003505749731180509, "phrase": "sparse_coding"}, {"score": 0.00347657813672945, "phrase": "contextual_features"}, {"score": 0.003292770855568091, "phrase": "bottom-up_saliency_and_object_co-occurrences"}, {"score": 0.0030797912111959137, "phrase": "local_appearance-based_object_detector"}, {"score": 0.0028327783069076883, "phrase": "underlying_conditional_probabilities"}, {"score": 0.0027974705482714884, "phrase": "different_cues"}, {"score": 0.002728166176898539, "phrase": "kernel_density_estimation"}, {"score": 0.002660574167091781, "phrase": "crucial_part"}, {"score": 0.0025623050508233078, "phrase": "detailed_evaluation"}, {"score": 0.00246765655376112, "phrase": "image_data"}, {"score": 0.002327310963701377, "phrase": "context-aware_object_detection"}, {"score": 0.002298288831092204, "phrase": "in-depth_analysis"}, {"score": 0.0021766418372878835, "phrase": "visual_context"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Visual context", " Object detection", " Context integration"], "paper_abstract": "Visual context provides cues about an object's presence, position and size within the observed scene, which should be used to increase the performance of object detection techniques. However, in computer vision, object detectors typically ignore this information. We therefore present a framework for visual-context-aware object detection. Methods for extracting visual contextual information from still images are proposed, which are then used to calculate a prior for object detection. The concept is based on a sparse coding of contextual features, which are based on geometry and texture. In addition, bottom-up saliency and object co-occurrences are exploited, to define auxiliary visual context. To integrate the individual contextual cues with a local appearance-based object detector, a fully probabilistic framework is established. In contrast to other methods, our integration is based on modeling the underlying conditional probabilities between the different cues, which is done via kernel density estimation. This integration is a crucial part of the framework which is demonstrated within the detailed evaluation. Our method is evaluated using a novel demanding image data set and compared to a state-of-the-art method for context-aware object detection. An in-depth analysis is given discussing the contributions of the individual contextual cues and the limitations of visual context for object detection. (C) 2010 Elsevier Inc. All rights reserved.", "paper_title": "A framework for visual-context-aware object detection in still images", "paper_id": "WOS:000278443300008"}