{"auto_keywords": [{"score": 0.048364759730099696, "phrase": "bayesian_networks"}, {"score": 0.04670675420350503, "phrase": "bayesian_score_metrics"}, {"score": 0.00481495049065317, "phrase": "bayesian_dirichlet_metrics"}, {"score": 0.004586531354697466, "phrase": "marginal_likelihood"}, {"score": 0.004212453011596424, "phrase": "common_formulations"}, {"score": 0.0041112665381266315, "phrase": "free_parameters"}, {"score": 0.003996271202811961, "phrase": "recent_theoretical_and_experimental_works"}, {"score": 0.00374531366198605, "phrase": "particular_assignments"}, {"score": 0.0036553070575015344, "phrase": "equivalent_sample_size"}, {"score": 0.003567455727660992, "phrase": "poor_choices"}, {"score": 0.0034817084307034955, "phrase": "inferred_bn_models"}, {"score": 0.0032629585038738856, "phrase": "large_sample_sizes"}, {"score": 0.0030953529970646626, "phrase": "bde_metric"}, {"score": 0.0030086877092638945, "phrase": "bn_model_parameters_distribution"}, {"score": 0.002831037222426215, "phrase": "real_settings"}, {"score": 0.002578745296475411, "phrase": "wider_set"}, {"score": 0.00241658945942583, "phrase": "robust_performance"}, {"score": 0.00233936726307301, "phrase": "standard_bde_metric"}, {"score": 0.002311047934798247, "phrase": "optimum_selection"}, {"score": 0.002183347623351868, "phrase": "wrong_settings"}, {"score": 0.0021569129153653777, "phrase": "widely_applied_bayesian_score_metric"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Probabilistic graphical models", " Bayesian networks", " Structure learning", " Parameter estimation", " Bayesian metrics"], "paper_abstract": "The marginal likelihood of the data computed using Bayesian score metrics is at the core of score+search methods when learning Bayesian networks from data. However, common formulations of those Bayesian score metrics rely on free parameters which are hard to assess. Recent theoretical and experimental works have also shown that the commonly employed BDe score metric is strongly biased by the particular assignments of its free parameter known as the equivalent sample size. This sensitivity means that poor choices of this parameter lead to inferred BN models whose structure and parameters do not properly represent the distribution generating the data even for large sample sizes. In this paper we argue that the problem is that the BDe metric is based on assumptions about the BN model parameters distribution assumed to generate the data which are too strict and do not hold in real settings. To overcome this issue we introduce here an approach that tries to marginalize the meta-parameter locally, aiming to embrace a wider set of assumptions about these parameters. It is shown experimentally that this approach offers a robust performance, as good as that of the standard BDe metric with an optimum selection of its free parameter and, in consequence, this method prevents the choice of wrong settings for this widely applied Bayesian score metric. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Locally averaged Bayesian Dirichlet metrics for learning the structure and the parameters of Bayesian networks", "paper_id": "WOS:000317379500008"}