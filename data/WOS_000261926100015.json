{"auto_keywords": [{"score": 0.04590884875550197, "phrase": "asc"}, {"score": 0.00481495049065317, "phrase": "self-organizing_incremental_neural_network"}, {"score": 0.0046970764288494764, "phrase": "fast_prototype-based_nearest_neighbor_classifier"}, {"score": 0.00446987606516801, "phrase": "adjusted_soinn_classifier"}, {"score": 0.0035461111918923117, "phrase": "decision_boundary"}, {"score": 0.0034306925765832633, "phrase": "new_information"}, {"score": 0.0033465923623290034, "phrase": "old_learned_information"}, {"score": 0.0031845067058084583, "phrase": "noisy_training_data"}, {"score": 0.002836096284133166, "phrase": "artificial_datasets"}, {"score": 0.002789528662623221, "phrase": "real-world_datasets"}, {"score": 0.0027211032672460984, "phrase": "asc."}, {"score": 0.0024637379406427856, "phrase": "compression_ratio"}, {"score": 0.0021940118003312397, "phrase": "best_performance"}], "paper_keywords": ["Self-organizing incremental neural network", " Nearest neighbor", " Fast", " Prototype-based classifier"], "paper_abstract": "A fast prototype-based nearest neighbor classifier is introduced. The proposed Adjusted SOINN Classifier (ASC) is based on SOINN (self-organizing incremental neural network), it automatically learns the number of prototypes needed to determine the decision boundary, and learns new information without destroying old learned information. It is robust to noisy training data, and it realizes very fast classification. In the experiment, we use some artificial datasets and real-world datasets to illustrate ASC. We also compare ASC with other prototype-based classifiers with regard to its classification error, compression ratio, and speed up ratio. The results show that ASC has the best performance and it is a very efficient classifier. (C) 2008 Elsevier Ltd. All rights reserved.", "paper_title": "A fast nearest neighbor classifier based on self-organizing incremental neural network", "paper_id": "WOS:000261926100015"}