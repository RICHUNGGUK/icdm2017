{"auto_keywords": [{"score": 0.04459796331314663, "phrase": "transition_region"}, {"score": 0.00481495049065317, "phrase": "transition_regions"}, {"score": 0.004713162564945179, "phrase": "new_thresholding_framework"}, {"score": 0.003544088803300751, "phrase": "background_pixel"}, {"score": 0.0033001333942688778, "phrase": "sample_statistics"}, {"score": 0.0031845067058084583, "phrase": "background_proportions"}, {"score": 0.0028207566216121856, "phrase": "proposed_approach"}, {"score": 0.0025525322651112365, "phrase": "conventional_transition-region-based_thresholding_methods"}, {"score": 0.002342972434255588, "phrase": "wider_applicability"}, {"score": 0.002309754152767196, "phrase": "existing_supervised_thresholding_methods"}, {"score": 0.0021659920594094407, "phrase": "difficult_images"}, {"score": 0.0021352776064254195, "phrase": "multiple_objects"}, {"score": 0.0021049977753042253, "phrase": "serious_imaging_artifacts"}], "paper_keywords": ["Grayscale thresholding", " Transition region", " Supervision", " Prior knowledge"], "paper_abstract": "A new thresholding framework is proposed which is transition region based, and consists of deriving the transition region with the help of supervision and calculating the threshold from the transition region. Four ways of supervision are studied: picking up an object and a background pixel, from other clustering or segmentation results, based on sample statistics, and exploration of background proportions. The approach has been validated both quantitatively and qualitatively. It is found that the proposed approach: (I) is more robust, consistent and reliable than the conventional transition-region-based thresholding methods; and (2) is easier to implement and has wider applicability than existing supervised thresholding methods. The approach is especially useful for segmenting difficult images with multiple objects and/or serious imaging artifacts. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Supervised grayscale thresholding based on transition regions", "paper_id": "WOS:000260711500011"}