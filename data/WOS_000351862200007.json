{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "lowest-timestamp-first"}, {"score": 0.0047323590206695305, "phrase": "high-performance_optimistic_simulation_platforms"}, {"score": 0.004631099806015235, "phrase": "high-performance_discrete_event_simulation"}, {"score": 0.004396790930873782, "phrase": "simulation_model"}, {"score": 0.0042656009036320585, "phrase": "logical_processes"}, {"score": 0.004084920064588169, "phrase": "different_cpus"}, {"score": 0.004049709080817396, "phrase": "multiple_cpu-cores"}, {"score": 0.003911862375084159, "phrase": "high_degree"}, {"score": 0.0038781372962808894, "phrase": "hardware_parallelism"}, {"score": 0.003828091961373454, "phrase": "relatively_large_models"}, {"score": 0.003795086335272422, "phrase": "multiprogramming_schemes"}, {"score": 0.0036500346000495317, "phrase": "single_cpu-core"}, {"score": 0.0035410467987580484, "phrase": "priority_management"}, {"score": 0.003450213580299164, "phrase": "central_issues"}, {"score": 0.003361702510958392, "phrase": "parallel_simulation_environment"}, {"score": 0.003261295948815592, "phrase": "optimistic_approach"}, {"score": 0.0031502008922533894, "phrase": "speculative_processing"}, {"score": 0.0030560920414081645, "phrase": "concurrent_lps"}, {"score": 0.003029722317983915, "phrase": "rollback_techniques"}, {"score": 0.0029264925857346497, "phrase": "low-overhead_constant-time_implementation"}, {"score": 0.0027781870000242004, "phrase": "next_lp"}, {"score": 0.0026033013834547507, "phrase": "optimistic_simulation_system"}, {"score": 0.002525489173110693, "phrase": "separate_event_lists"}, {"score": 0.0024928553725344933, "phrase": "hosted_lps"}, {"score": 0.0022758994740331258, "phrase": "extended_performance_study"}, {"score": 0.0021511430180912164, "phrase": "test-bed_application"}], "paper_keywords": ["Parallel discrete event simulation", " Optimistic synchronization", " CPU-scheduling", " Performance optimization"], "paper_abstract": "An approach to high-performance discrete event simulation consists of exploiting parallelization techniques. These rely on partitioning the simulation model into multiple, interacting simulation objects, also known as Logical Processes (LPs), which concurrently execute events on different CPUs and/or multiple CPU-cores. However, despite the tendency towards high degree of hardware parallelism, for relatively large models, multiprogramming schemes are still needed in order to share a single CPU-core across multiple LPs. Consequently, priority management and CPU-scheduling remain central issues for the effectiveness of any parallel simulation environment. This article focuses on the optimistic approach to parallelism, which is based on speculative processing and maintains event-causality across concurrent LPs via rollback techniques. Specifically, the article presents a low-overhead constant-time implementation of the well known Lowest-Timestamp-First algorithm for the identification of the next LP to be CPU-dispatched. This proposal is suited for contexts where the optimistic simulation system conforms to the best-practice of keeping separate event lists for the hosted LPs. The implementation has been integrated in the open source ROOT-Sim (ROme OpTimistic Simulator) package. The effectiveness of the presented proposal is assessed via an extended performance study, carried out by relying on the game of life as the test-bed application. (C) 2015 Elsevier B. V. All rights reserved.", "paper_title": "A low-overhead constant-time Lowest-Timestamp-First CPU scheduler for high-performance optimistic simulation platforms", "paper_id": "WOS:000351862200007"}