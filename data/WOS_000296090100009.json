{"auto_keywords": [{"score": 0.04415257445690235, "phrase": "parallel_streams"}, {"score": 0.03679418729719719, "phrase": "optimal_number"}, {"score": 0.00481495049065317, "phrase": "optimal_parallelism_level"}, {"score": 0.004775531918452571, "phrase": "wide_area_data_transfers"}, {"score": 0.004736434518535051, "phrase": "wide_area_data_transfer"}, {"score": 0.004659192888931046, "phrase": "major_bottleneck"}, {"score": 0.004602085616330634, "phrase": "end-to-end_performance"}, {"score": 0.004489952932659799, "phrase": "practical_way"}, {"score": 0.004416713079266374, "phrase": "wide_area_throughput"}, {"score": 0.004362564831572539, "phrase": "application_layer"}, {"score": 0.00430907756010007, "phrase": "multiple_parallel_streams"}, {"score": 0.004256243266481051, "phrase": "increased_number"}, {"score": 0.004101579688745222, "phrase": "single_stream"}, {"score": 0.003920128102807887, "phrase": "inverse_effect"}, {"score": 0.003824547895167011, "phrase": "excess_number"}, {"score": 0.003352658916650986, "phrase": "\"optimum\"_number"}, {"score": 0.003177958355586418, "phrase": "individual_transfer"}, {"score": 0.0031518989079229714, "phrase": "generic_models"}, {"score": 0.002999955539996569, "phrase": "historical_information"}, {"score": 0.002938821840519756, "phrase": "accurate_predictions"}, {"score": 0.0028086649378423357, "phrase": "new_models"}, {"score": 0.0027176309244222, "phrase": "least_history_information"}, {"score": 0.0026953359825383624, "phrase": "lowest_prediction_overhead"}, {"score": 0.0025972447844047515, "phrase": "best_combination"}, {"score": 0.002575934917174136, "phrase": "historic_information"}, {"score": 0.0025130460190930554, "phrase": "evaluation_purposes"}, {"score": 0.002471973283582411, "phrase": "optimizing_prediction"}, {"score": 0.0024416087858984644, "phrase": "error_rate"}, {"score": 0.0023430556582539805, "phrase": "proposed_prediction_models"}, {"score": 0.002304754792740636, "phrase": "actual_gridftp_data_transfer"}, {"score": 0.0021049977753042253, "phrase": "optimal_stream_number"}], "paper_keywords": ["Distributed applications", " modeling and prediction", " parallelism and concurrency", " network protocols"], "paper_abstract": "Wide area data transfer may be a major bottleneck for the end-to-end performance of distributed applications. A practical way of increasing the wide area throughput at the application layer is using multiple parallel streams. Although increased number of parallel streams may yield much better performance than using a single stream, overwhelming the network by opening too many streams may have an inverse effect. The congestion created by excess number of streams may cause a drop down in the throughput achieved. Hence, it is important to decide on the optimal number of streams without congesting the network. Predicting this \"optimum\" number is not straightforward, since it depends on many parameters specific to each individual transfer. Generic models that try to predict this number either rely too much on historical information or fail to achieve accurate predictions. In this paper, we present a set of new models which aim to approximate the optimal number with least history information and lowest prediction overhead. An algorithm is introduced to select the best combination of historic information to do the prediction for evaluation purposes as well as optimizing prediction by reducing error rate. We measure the feasibility and accuracy of the proposed prediction models by comparing to actual GridFTP data transfer by using little historical information and have seen that we could predict the throughput of parallel streams accurately and find a very close approximation of the optimal stream number.", "paper_title": "Prediction of Optimal Parallelism Level in Wide Area Data Transfers", "paper_id": "WOS:000296090100009"}