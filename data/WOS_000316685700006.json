{"auto_keywords": [{"score": 0.0265498627596169, "phrase": "variance_functions"}, {"score": 0.00481495049065317, "phrase": "weighted_least_squares"}, {"score": 0.00469500313566324, "phrase": "estimated_weights"}, {"score": 0.0036018503805251424, "phrase": "random_error"}, {"score": 0.0032556926399045635, "phrase": "support_points"}, {"score": 0.003075765038696993, "phrase": "optimal_proportions"}, {"score": 0.002887450071878095, "phrase": "specific_examples"}, {"score": 0.002815383690003621, "phrase": "i-optimal_design"}, {"score": 0.002285335999629823, "phrase": "homoscedastic_case"}, {"score": 0.0022142194702079866, "phrase": "minimax_designs"}, {"score": 0.0021049977753042253, "phrase": "finite_classes"}], "paper_keywords": ["Linear programming", " Minimax", " Optimal design", " Polynomial regression"], "paper_abstract": "We study designs, optimal up to and including terms that are O(n (-1)), for weighted least squares regression, when the weights are intended to be inversely proportional to the variances but are estimated with random error. We take a finite, but arbitrarily large, design space from which the support points are to be chosen, and obtain the optimal proportions of observations to be assigned to each point. Specific examples of D- and I-optimal design for polynomial responses are studied. In some cases the same designs that are optimal under homoscedasticity remain so for a range of variance functions; in others there tend to be more support points than are required in the homoscedastic case. We also exhibit minimax designs, that minimize the maximum, over finite classes of variance functions, value of the loss. These also tend to have more support points, often resulting from the breaking down of replicates into clusters.", "paper_title": "Designs for weighted least squares regression, with estimated weights", "paper_id": "WOS:000316685700006"}