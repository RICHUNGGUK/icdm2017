{"auto_keywords": [{"score": 0.02890432233657509, "phrase": "storm"}, {"score": 0.00481495049065317, "phrase": "distributed_stream_processors"}, {"score": 0.004744018246633455, "phrase": "generation_real-time_applications"}, {"score": 0.004697308822154191, "phrase": "big-data_infrastructures"}, {"score": 0.004628101576367193, "phrase": "huge_and_continuous_data_volumes"}, {"score": 0.004382913938427474, "phrase": "new_issues"}, {"score": 0.004339744430169516, "phrase": "current_big-data_processing_infrastructures"}, {"score": 0.004089475312474684, "phrase": "current_infrastructures"}, {"score": 0.0040491842732233154, "phrase": "big-data_processing"}, {"score": 0.003969784439380027, "phrase": "general_purpose_applications"}, {"score": 0.003834548373258131, "phrase": "real-time_performance"}, {"score": 0.003685604033479918, "phrase": "implicit_requirement"}, {"score": 0.0036312482387007815, "phrase": "second_important_limitation"}, {"score": 0.0035424245257172234, "phrase": "clear_computational_models"}, {"score": 0.0034386894664467003, "phrase": "current_big-data_frameworks"}, {"score": 0.003023047748772801, "phrase": "computational_model"}, {"score": 0.0028484940955893134, "phrase": "real-time_infrastructure"}, {"score": 0.0025415366388578465, "phrase": "extra_control"}, {"score": 0.002301572462091142, "phrase": "empirical_evidences"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Real-time", " Distributed stream processing", " Predictable infrastructure"], "paper_abstract": "Next generation real-time applications demand big-data infrastructures to process huge and continuous data volumes under complex computational constraints. This type of application raises new issues on current big-data processing infrastructures. The first issue to be considered is that most of current infrastructures for big-data processing were defined for general purpose applications. Thus, they set aside real-time performance, which is in some cases an implicit requirement. A second important limitation is the lack of clear computational models that could be supported by current big-data frameworks. In an effort to reduce this gap, this article contributes along several lines. First, it provides a set of improvements to a computational model called distributed stream processing in order to formalize it as a real-time infrastructure. Second, it proposes some extensions to Storm, one of the most popular stream processors. These extensions are designed to gain an extra control over the resources used by the application in order to improve its predictability. Lastly, the article presents some empirical evidences on the performance that can be expected from this type of infrastructure. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Improving the predictability of distributed stream processors", "paper_id": "WOS:000358807200003"}