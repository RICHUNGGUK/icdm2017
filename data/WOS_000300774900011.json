{"auto_keywords": [{"score": 0.034726425619790245, "phrase": "motion_similarity"}, {"score": 0.01518519373804938, "phrase": "single_video_scene"}, {"score": 0.013163244267581344, "phrase": "multiple_video_sequences"}, {"score": 0.010412755200503391, "phrase": "position_similarity"}, {"score": 0.010233267899119278, "phrase": "corresponding_motion_parts"}, {"score": 0.00481495049065317, "phrase": "position_similarities"}, {"score": 0.004710854091689325, "phrase": "multiple_videos"}, {"score": 0.004588891098290524, "phrase": "challenging_task"}, {"score": 0.004548939310612501, "phrase": "current_video_fusion"}, {"score": 0.00450933377534525, "phrase": "mosaicing_research_and_film_production"}, {"score": 0.00433531459712787, "phrase": "novel_method"}, {"score": 0.004297560964892607, "phrase": "video_motion"}, {"score": 0.004095692768056685, "phrase": "foreground_objects"}, {"score": 0.003937573222812911, "phrase": "common_reference_frame"}, {"score": 0.0038355531523269217, "phrase": "static_and_dynamic_backgrounds"}, {"score": 0.0035918768194006735, "phrase": "static_region"}, {"score": 0.003545024951402821, "phrase": "dynamic_region"}, {"score": 0.003408091901859624, "phrase": "warped_input_video_sequences"}, {"score": 0.0033636292024305406, "phrase": "panoramic_video"}, {"score": 0.0029238768315330305, "phrase": "different_videos"}, {"score": 0.002898378776839434, "phrase": "dynamic_backgrounds"}, {"score": 0.0028108690791085536, "phrase": "poisson_editing"}, {"score": 0.002475532161577715, "phrase": "trajectory_similarity"}, {"score": 0.0024007585788965655, "phrase": "everyday_videos"}, {"score": 0.0022777800735119405, "phrase": "real_motion_similarity"}, {"score": 0.0022480304016499605, "phrase": "decisive_role"}, {"score": 0.0021422271362195734, "phrase": "satisfactory_results"}, {"score": 0.002123531043641047, "phrase": "motion_stitching"}, {"score": 0.0021049977753042253, "phrase": "video_mosaicing"}], "paper_keywords": ["video fusion", " video mosaicing", " video registration", " background estimation", " motion stitching"], "paper_abstract": "Stitching motions in multiple videos into a single video scene is a challenging task in current video fusion and mosaicing research and film production. In this paper, we present a novel method of video motion stitching based on the similarities of trajectory and position of foreground objects. First, multiple video sequences are registered in a common reference frame, whereby we estimate the static and dynamic backgrounds, with the former responsible for distinguishing the foreground from the background and the static region from the dynamic region, and the latter functioning in mosaicing the warped input video sequences into a panoramic video. Accordingly, the motion similarity is calculated by reference to trajectory and position similarity, whereby the corresponding motion parts are extracted from multiple video sequences. Finally, using the corresponding motion parts, the foregrounds of different videos and dynamic backgrounds are fused into a single video scene through Poisson editing, with the motions involved being stitched together. Our major contributions are a framework of multiple video mosaicing based on motion similarity and a method of calculating motion similarity from the trajectory similarity and the position similarity. Experiments on everyday videos show that the agreement of trajectory and position similarities with the real motion similarity plays a decisive role in determining whether two motions can be stitched. We acquire satisfactory results for motion stitching and video mosaicing.", "paper_title": "Video motion stitching using trajectory and position similarities", "paper_id": "WOS:000300774900011"}