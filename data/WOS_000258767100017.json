{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "lost_speech_segments"}, {"score": 0.04710047763260585, "phrase": "interpolation_method"}, {"score": 0.04164228196739029, "phrase": "spectral_envelope"}, {"score": 0.0047787596516662, "phrase": "lp-hnm_model"}, {"score": 0.00474283953918251, "phrase": "codebook_post-processing"}, {"score": 0.00443141503046841, "phrase": "packet_loss_concealment"}, {"score": 0.004398094237005956, "phrase": "voice_communication"}, {"score": 0.004365022891478405, "phrase": "mobile_phones"}, {"score": 0.004203343568960231, "phrase": "lost_segments"}, {"score": 0.004171730509424374, "phrase": "speech_recordings"}, {"score": 0.0040323765107766335, "phrase": "linear_prediction"}, {"score": 0.003927203683176278, "phrase": "harmonic_noise_model"}, {"score": 0.0038976604827586294, "phrase": "hnm"}, {"score": 0.0037674258625824113, "phrase": "speech_interpolation_problem"}, {"score": 0.0036005006349430586, "phrase": "lp_parameters"}, {"score": 0.003480161521018509, "phrase": "hnm_tracks"}, {"score": 0.0034539685987677376, "phrase": "speech_excitation"}, {"score": 0.0033511469200347907, "phrase": "harmonicity_results"}, {"score": 0.003313380246267812, "phrase": "smooth_transition"}, {"score": 0.003263683763829895, "phrase": "unvoiced_speech"}, {"score": 0.003239114833599948, "phrase": "vice_versa"}, {"score": 0.0031784960695034645, "phrase": "proposed_interpolation_method"}, {"score": 0.0029807267909921628, "phrase": "different_combinations"}, {"score": 0.0029360049890445944, "phrase": "autoregressive_interpolation_methods"}, {"score": 0.0028485585670146025, "phrase": "time-varying_parameters"}, {"score": 0.002827105825163379, "phrase": "lp-hnm_tracks"}, {"score": 0.0025819015229390663, "phrase": "improved_output_quality"}, {"score": 0.002562451837774567, "phrase": "longer_length_speech_gaps"}, {"score": 0.0025335509856200433, "phrase": "different_packet_loss_rates"}, {"score": 0.002476721068743341, "phrase": "missing_speech_gaps"}, {"score": 0.0024487847651989128, "phrase": "proposed_interpolation_methods"}, {"score": 0.0023938516706864775, "phrase": "popular_ar-based_interpolation_methods"}, {"score": 0.002366847878952636, "phrase": "speech_packet_recovery_method"}, {"score": 0.00227040825063645, "phrase": "evaluation_results"}, {"score": 0.0022363199197710385, "phrase": "proposed_methods"}, {"score": 0.002169667676959813, "phrase": "harmonic_tracks"}, {"score": 0.002129020447793464, "phrase": "significant_performance_gain"}, {"score": 0.0021049977753042253, "phrase": "perceptual_quality"}], "paper_keywords": [""], "paper_abstract": "This paper presents a method for interpolation of lost speech segments. The interpolation method can be used for packet loss concealment in voice communication over mobile phones, for voice over IP or for restoration of lost segments in speech recordings. The interpolation method employs a combination of a linear prediction (LP) model of the spectral envelope and a harmonic noise model (HNM) of the excitation of speech. The speech interpolation problem is transformed to the modeling and interpolation of the trajectories of LP parameters and the amplitude, phase and harmonicity of HNM tracks of speech excitation. In particular, the interpolation of harmonicity results in a smooth transition from voiced to unvoiced speech and vice versa. Crucially, the proposed interpolation method does not suffer from the consequences of zero-excitation of conventional autoregressive (AR) interpolation. Different combinations of linear and autoregressive interpolation methods are evaluated for the estimation of the time-varying parameters of LP-HNM tracks. Furthermore, a post-processing codebook mapping, employed to enhance the interpolation of the spectral envelope of speech, results in improved output quality for longer length speech gaps. For different packet loss rates and patterns or distributions of missing speech gaps, the proposed interpolation methods are evaluated and compared with popular AR-based interpolation methods and the speech packet recovery method specified in the ITU G.711 standard, as a reference. The evaluation results show that the proposed methods substantially improve the restoration of formants and harmonic tracks and consistently results in significant performance gain and improved perceptual quality of speech.", "paper_title": "Interpolation of lost speech segments using LP-HNM model with codebook post-processing", "paper_id": "WOS:000258767100017"}