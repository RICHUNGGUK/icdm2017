{"auto_keywords": [{"score": 0.04967913398382337, "phrase": "ant_colony_optimization"}, {"score": 0.043335277289837486, "phrase": "cpu_implementation"}, {"score": 0.040460720519068925, "phrase": "tour_construction"}, {"score": 0.00481495049065317, "phrase": "data_parallelism"}, {"score": 0.004695303774351139, "phrase": "graphics_processing_units"}, {"score": 0.004559451202070545, "phrase": "highly_parallel_and_fully_programmable_architecture"}, {"score": 0.004409058820370728, "phrase": "cuda"}, {"score": 0.0038227112550093863, "phrase": "pheromone_update"}, {"score": 0.0035444736871640147, "phrase": "significant_challenges"}, {"score": 0.0035001037990786727, "phrase": "irregular_memory_access_patterns"}, {"score": 0.003059925849144792, "phrase": "pheromone_update_stage"}, {"score": 0.002885135695263876, "phrase": "classic_roulette_wheel"}, {"score": 0.00284899583294417, "phrase": "cpu_parallelism"}, {"score": 0.002789763110395331, "phrase": "factor_gains"}, {"score": 0.00267495669519805, "phrase": "aco_algorithm"}, {"score": 0.002619390960685417, "phrase": "tsp"}, {"score": 0.002532724486603177, "phrase": "similar_single-threaded_high-end_cpu."}, {"score": 0.0024489727828322693, "phrase": "different_implementation_paths"}, {"score": 0.002358050109031317, "phrase": "parallel_graph_connected_components"}, {"score": 0.002270495425498003, "phrase": "broader_area"}, {"score": 0.0022232633360792222, "phrase": "algorithm_designers"}, {"score": 0.0021770116505684394, "phrase": "similar_optimization_methods"}, {"score": 0.002158780936704905, "phrase": "cpu_architecture"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Metaheuristics", " GPU programming", " Ant Colony Optimization", " TSP", " Performance analysis"], "paper_abstract": "Graphics Processing Units (GPUs) have evolved into highly parallel and fully programmable architecture over the past five years, and the advent of CUDA has facilitated their application to many real-world applications. In this paper, we deal with a CPU implementation of Ant Colony Optimization (ACO), a population-based optimization method which comprises two major stages: tour construction and pheromone update. Because of its inherently parallel nature, ACO is well-suited to CPU implementation, but it also poses significant challenges due to irregular memory access patterns. Our contribution within this context is threefold: (1) a data parallelism scheme for tour construction tailored to CPUs, (2) novel CPU programming strategies for the pheromone update stage, and (3) a new mechanism called 1-Roulette to replicate the classic roulette wheel while improving CPU parallelism. Our implementation leads to factor gains exceeding 20x for any of the two stages of the ACO algorithm as applied to the TSP when compared to its sequential counterpart version running on a similar single-threaded high-end CPU. Moreover, an extensive discussion focused on different implementation paths on CPUs shows the way to deal with parallel graph connected components. This, in turn, suggests a broader area of inquiry, where algorithm designers may learn to adapt similar optimization methods to CPU architecture. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Enhancing data parallelism for Ant Colony Optimization on GPUs", "paper_id": "WOS:000311921300005"}