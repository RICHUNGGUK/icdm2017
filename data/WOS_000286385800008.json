{"auto_keywords": [{"score": 0.025951032365095553, "phrase": "recognition_performance"}, {"score": 0.00481495049065317, "phrase": "sparsity_promotion"}, {"score": 0.004776853267973129, "phrase": "perceptual_wavelet_domain"}, {"score": 0.004739056045644449, "phrase": "speech_enhancement"}, {"score": 0.004627441072541506, "phrase": "speech_recognition_accuracy"}, {"score": 0.00435971969507033, "phrase": "estimated_signal_components"}, {"score": 0.004140203942496321, "phrase": "wavelet-based_techniques"}, {"score": 0.004074901471704325, "phrase": "automatic_speech_recognition_performance"}, {"score": 0.003994714109598034, "phrase": "background_noise"}, {"score": 0.003947358102140903, "phrase": "proposed_robust_speech_recognition_system"}, {"score": 0.0038696708318671446, "phrase": "speech_enhancement_preprocessing"}, {"score": 0.0038390240716280302, "phrase": "feature_extraction"}, {"score": 0.0037040785566765954, "phrase": "time-frequency_space"}, {"score": 0.0036601552758254757, "phrase": "perceptual_wavelet_filterbank"}, {"score": 0.0036167509502276294, "phrase": "fixed_base"}, {"score": 0.003559675269411366, "phrase": "human_perceptual_modus"}, {"score": 0.0034073030552032304, "phrase": "time-frequency_plane"}, {"score": 0.0031845067058084583, "phrase": "bayesian_scheme"}, {"score": 0.0031217859267564344, "phrase": "wavelet_domain"}, {"score": 0.0030481444896915504, "phrase": "noise_components"}, {"score": 0.0030119758165837625, "phrase": "proposed_iterative_speech_enhancement_algorithm"}, {"score": 0.002826181226538412, "phrase": "wavelet_coefficients"}, {"score": 0.0027926389474730927, "phrase": "denoised_wavelet_features"}, {"score": 0.002737615043512257, "phrase": "hybrid_classifier"}, {"score": 0.002694375425481759, "phrase": "hidden_markov_model"}, {"score": 0.0026307897899760383, "phrase": "intrinsic_limitation"}, {"score": 0.0025996382241790634, "phrase": "hmm"}, {"score": 0.0025180781216911246, "phrase": "wavelet_support_vector_machine"}, {"score": 0.002468450551616404, "phrase": "hierarchical_design_paradigm"}, {"score": 0.002381566880282456, "phrase": "different_methods"}, {"score": 0.0023532890136269986, "phrase": "integral_system"}, {"score": 0.0023253461255420436, "phrase": "continuous_digit_speech_recognition_experiments"}, {"score": 0.0022886031992739126, "phrase": "proposed_framework"}, {"score": 0.002270449532546444, "phrase": "promising_results"}, {"score": 0.002190519728921395, "phrase": "low_signal-to-noise_ratio"}, {"score": 0.002130298466581199, "phrase": "poorer_performance"}, {"score": 0.0021049977753042253, "phrase": "high_snr."}], "paper_keywords": ["Bayesian theory", " hidden Markov model (HMM)", " speech enhancement", " speech recognition", " support vector machine (SVM)", " wavelet transform"], "paper_abstract": "Speech recognition accuracy can be improved by the removal of noise. However, errors in the estimated signal components can also obscure the recognition. This paper presents a framework of wavelet-based techniques to harness the automatic speech recognition performance in the presence of background noise. The proposed robust speech recognition system is realized by implementing speech enhancement preprocessing, feature extraction, and a hybrid speech recognizer in the time-frequency space. A perceptual wavelet filterbank using a fixed base to imitate the human perceptual modus of speech is developed to capture the most discriminative information in the time-frequency plane. To minimize the mismatch between the training and testing conditions of the classifier, a Bayesian scheme is applied in a wavelet domain to separate the speech and noise components in the proposed iterative speech enhancement algorithm. The nonphonetic information is discarded while the more critical speech features are extracted and represented by the wavelet coefficients. The denoised wavelet features are fed to the hybrid classifier founded on a hidden Markov model (HMM). The intrinsic limitation of the HMM is overcome by augmenting it with a wavelet support vector machine. This hybrid and hierarchical design paradigm improves the recognition performance by combining the advantages of different methods into an integral system. The continuous digit speech recognition experiments conducted with the proposed framework show promising results. It significantly improves the recognition performance at a low signal-to-noise ratio (SNR) without causing a poorer performance at a high SNR.", "paper_title": "Bayesian Separation With Sparsity Promotion in Perceptual Wavelet Domain for Speech Enhancement and Hybrid Speech Recognition", "paper_id": "WOS:000286385800008"}