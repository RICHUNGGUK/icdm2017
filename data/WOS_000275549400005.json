{"auto_keywords": [{"score": 0.04209445471630583, "phrase": "recognition_rate"}, {"score": 0.004816265469549792, "phrase": "bayesian"}, {"score": 0.004543708337879809, "phrase": "symbol_recognition"}, {"score": 0.004256703909255889, "phrase": "descriptor_combination_method"}, {"score": 0.0039019217388438134, "phrase": "recognition_rates"}, {"score": 0.0035766032751309677, "phrase": "probabilistic_graphical_model"}, {"score": 0.003350480663660326, "phrase": "discrete_and_continuous-valued_variables"}, {"score": 0.002469830206270585, "phrase": "dimensionality_problem"}, {"score": 0.0023990982005125763, "phrase": "large_dimension"}, {"score": 0.0023644936731468252, "phrase": "visual_features"}, {"score": 0.002263639474937039, "phrase": "variable_selection_method"}, {"score": 0.002230984431056064, "phrase": "experimental_results"}, {"score": 0.002151388538895855, "phrase": "supervised_learning_context"}, {"score": 0.0021049977753042253, "phrase": "noisy_and_occluded_symbols"}], "paper_keywords": ["Symbol recognition", " Descriptor combination", " Variable selection", " Probabilistic graphical models", " Bayesian networks"], "paper_abstract": "In this paper, we propose a descriptor combination method, which enables to improve significantly the recognition rate compared to the recognition rates obtained by each descriptor. This approach is based on a probabilistic graphical model. This model also enables to handle both discrete and continuous-valued variables. In fact, in order to improve the recognition rate, we have combined two kinds of features: discrete features (corresponding to shape measures) and continuous features (corresponding to shape descriptors). In order to solve the dimensionality problem due to the large dimension of visual features, we have adapted a variable selection method. Experimental results, obtained in a supervised learning context, on noisy and occluded symbols, show the feasibility of the approach.", "paper_title": "A Bayesian network for combining descriptors: application to symbol recognition", "paper_id": "WOS:000275549400005"}