{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "weakly_supervised_photo_cropping"}, {"score": 0.04970018005584556, "phrase": "photo_cropping"}, {"score": 0.004664352260912174, "phrase": "printing_industry"}, {"score": 0.00453643016617164, "phrase": "conventional_photo_cropping_methods"}, {"score": 0.004325208730208653, "phrase": "photo_aesthetics"}, {"score": 0.004206548500039536, "phrase": "model_designers"}, {"score": 0.004173244935967375, "phrase": "specific_data_sets"}, {"score": 0.004026598712747509, "phrase": "photos_aesthetics"}, {"score": 0.0039005612858880115, "phrase": "cropped_photo"}, {"score": 0.0037935066882208235, "phrase": "visual_features"}, {"score": 0.0037485269508155516, "phrase": "image_region"}, {"score": 0.0036893794227117194, "phrase": "human_aesthetics"}, {"score": 0.0036456298076415652, "phrase": "state-of-the-art_photo_cropping_methods"}, {"score": 0.003248483521309273, "phrase": "manifold_embedding_algorithm"}, {"score": 0.0031845067058084583, "phrase": "image-level_semantics"}, {"score": 0.0031467250930224126, "phrase": "global_configurations"}, {"score": 0.0030000149283621255, "phrase": "bayesian_network"}, {"score": 0.002882980094838904, "phrase": "testing_photo"}, {"score": 0.0028037753646260937, "phrase": "multi-channel_post-embedding_graphlets"}, {"score": 0.0026204665739240716, "phrase": "bn"}, {"score": 0.002439143581855858, "phrase": "training_photos"}, {"score": 0.0024006068621542642, "phrase": "optimal_cropping_parameter"}, {"score": 0.0023626775529531486, "phrase": "gibbs_sampling"}, {"score": 0.0023439376937579204, "phrase": "subjective_evaluations"}, {"score": 0.0021992603252793995, "phrase": "semantics-free_graphlets"}, {"score": 0.002147333949483224, "phrase": "visualized_graphlets"}, {"score": 0.0021218313648947926, "phrase": "photo_semantics"}, {"score": 0.0021049977753042253, "phrase": "global_spatial_configurations"}], "paper_keywords": ["Bayesian network", " image-level semantics", " photo cropping", " weakly supervised"], "paper_abstract": "Photo cropping is widely used in the printing industry, photography, and cinematography. Conventional photo cropping methods suffer from three drawbacks: 1) the semantics used to describe photo aesthetics are determined by the experience of model designers and specific data sets, 2) image global configurations, an essential cue to capture photos aesthetics, are not well preserved in the cropped photo, and 3) multi-channel visual features from an image region contribute differently to human aesthetics, but state-of-the-art photo cropping methods cannot automatically weight them. Owing to the recent progress in image retrieval community, image-level semantics, i.e., photo labels obtained without much human supervision, can be efficiently and effectively acquired. Thus, we propose weakly supervised photo cropping, where a manifold embedding algorithm is developed to incorporate image-level semantics and image global configurations with graphlets, or, small-sized connected subgraph. After manifold embedding, a Bayesian Network (BN) is proposed. It incorporates the testing photo into the framework derived from the multi-channel post-embedding graphlets of the training data, the importance of which is determined automatically. Based on the BN, photo cropping can be casted as searching the candidate cropped photo that maximally preserves graphlets from the training photos, and the optimal cropping parameter is inferred by Gibbs sampling. Subjective evaluations demonstrate that: 1) our approach outperforms several representative photo cropping methods, including our previous cropping model that is guided by semantics-free graphlets, and 2) the visualized graphlets explicitly capture photo semantics and global spatial configurations.", "paper_title": "Weakly Supervised Photo Cropping", "paper_id": "WOS:000328948100009"}