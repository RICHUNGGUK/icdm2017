{"auto_keywords": [{"score": 0.04907561130245922, "phrase": "multi-label_classification"}, {"score": 0.032953862995656065, "phrase": "bayesian_network"}, {"score": 0.030450421996722158, "phrase": "class_variables"}, {"score": 0.004814957642010738, "phrase": "multi-label"}, {"score": 0.004764220976404241, "phrase": "bayesian_network-based_chain_classifiers"}, {"score": 0.004518442937844318, "phrase": "different_classes"}, {"score": 0.004346266306175988, "phrase": "compound_class_variable"}, {"score": 0.004121960535174029, "phrase": "independent_classifiers"}, {"score": 0.004049783994776266, "phrase": "binary_relevance_methods"}, {"score": 0.003992950134435965, "phrase": "first_approach"}, {"score": 0.003950846696972114, "phrase": "high_computationally_complexity"}, {"score": 0.0038953958723049287, "phrase": "second_approach"}, {"score": 0.0038679618585498597, "phrase": "possible_dependencies"}, {"score": 0.003813669883040509, "phrase": "chain_classifiers"}, {"score": 0.0034299649219748513, "phrase": "previous_classifiers"}, {"score": 0.003264316172836322, "phrase": "bayesian_classifiers"}, {"score": 0.003195787852087248, "phrase": "classifier_chains"}, {"score": 0.0031732652552570644, "phrase": "bayesian_networks"}, {"score": 0.002988101395789399, "phrase": "probabilistic_dependency_relationships"}, {"score": 0.002793874145713024, "phrase": "conditional_independence_conditions"}, {"score": 0.0026967596578196325, "phrase": "possible_chain_orders"}, {"score": 0.002640114583897493, "phrase": "bayesian_chain"}, {"score": 0.0026307897899760383, "phrase": "classifier_performance"}, {"score": 0.002603012037901889, "phrase": "different_chain_orders"}, {"score": 0.0025846562485378247, "phrase": "training_strategies"}, {"score": 0.0025125151618810523, "phrase": "base_classifiers"}, {"score": 0.002485983124803852, "phrase": "different_base_classifiers"}, {"score": 0.002365815362517737, "phrase": "random_chain_order"}, {"score": 0.0022835460368487233, "phrase": "simple_tree-based_structure"}, {"score": 0.0022276618873985445, "phrase": "predictive_performance"}, {"score": 0.002211947103318718, "phrase": "time_complexity"}], "paper_keywords": ["Multi-label classification", " Chain classifier", " Bayesian networks"], "paper_abstract": "In multi-label classification the goal is to assign an instance to a set of different classes. This task is normally addressed either by defining a compound class variable with all the possible combinations of labels (label power-set methods) or by building independent classifiers for each class (binary relevance methods). The first approach suffers from high computationally complexity, while the second approach ignores possible dependencies among classes. Chain classifiers have been recently proposed to address these problems, where each classifier in the chain learns and predicts the label of one class given the attributes and all the predictions of the previous classifiers in the chain. In this paper we introduce a method for chaining Bayesian classifiers that combines the strengths of classifier chains and Bayesian networks for multi-label classification. A Bayesian network is induced from data to: (i) represent the probabilistic dependency relationships between classes, (ii) constrain the number of class variables used in the chain classifier by considering conditional independence conditions, and (iii) reduce the number of possible chain orders. The effects in the Bayesian chain classifier performance of considering different chain orders, training strategies, number of class variables added in the base classifiers, and different base classifiers, are experimentally assessed. In particular, it is shown that a random chain order considering the constraints imposed by a Bayesian network with a simple tree-based structure can have very competitive results in terms of predictive performance and time complexity against related state-of-the-art approaches. (C) 2013 Elsevier B. V. All rights reserved.", "paper_title": "Multi-label classification with Bayesian network-based chain classifiers", "paper_id": "WOS:000333105900003"}