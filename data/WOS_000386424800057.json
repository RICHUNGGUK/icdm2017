{"auto_keywords": [{"score": 0.050077294365016824, "phrase": "distributed_geo-textual_image_retrieval"}, {"score": 0.04542490996391519, "phrase": "flickr"}, {"score": 0.0046875099587735825, "phrase": "massive_amounts"}, {"score": 0.004514714250357749, "phrase": "annotated_images"}, {"score": 0.00441883624011048, "phrase": "online_photo_services"}, {"score": 0.004301834610818624, "phrase": "zommr"}, {"score": 0.0038431888954930083, "phrase": "geo-textual_images"}, {"score": 0.0038023057163825416, "phrase": "google"}, {"score": 0.0037213333316218522, "phrase": "hot_topics"}, {"score": 0.00366185681714204, "phrase": "specific_geographic_region"}, {"score": 0.0036227329311981195, "phrase": "time_period"}, {"score": 0.0034890505116128606, "phrase": "query_image"}, {"score": 0.0034148795808317555, "phrase": "recommended_images"}, {"score": 0.0030834712590249863, "phrase": "index_geotextual_images"}, {"score": 0.0030017207229983385, "phrase": "metric_similarity_queries"}, {"score": 0.002953711377604328, "phrase": "top-m_spatio-temporal_range"}, {"score": 0.0028142286985235977, "phrase": "geo-textual_image_retrieval"}, {"score": 0.002695768552609587, "phrase": "browser-server_model"}, {"score": 0.002568435291444709, "phrase": "distributed_environment"}, {"score": 0.002473560912156024, "phrase": "huge_amounts"}, {"score": 0.002382182688788248, "phrase": "rich_set"}, {"score": 0.0021975548867457606, "phrase": "high-quality_answers"}, {"score": 0.002162379426839795, "phrase": "interactive_way"}, {"score": 0.002127765807039172, "phrase": "efficient_updates"}, {"score": 0.0021049977753042253, "phrase": "high_image_arrival_rates"}], "paper_keywords": [""], "paper_abstract": "Massive amounts of geo-tagged and textually annotated images are provided by online photo services such as Flickr and Zommr. However, most existing image retrieval engines only consider text annotations. We present I2RS, a system that allows users to view geo-textual images on Google Maps, find hot topics within a specific geographic region and time period, retrieve images similar to a query image, and receive recommended images that they might be interested in. I2RS is a distributed geo-textual image retrieval and recommendation system that employs SPB-trees to index geotextual images, and that utilizes metric similarity queries, including top-m spatio-temporal range and k nearest neighbor queries, to support geo-textual image retrieval and recommendation. The system adopts the browser-server model, whereas the server is deployed in a distributed environment that enables efficiency and scalability to huge amounts of data and requests. A rich set of 100 million geo-textual images crawled from Flickr is used to demonstrate that, I2RS can return high-quality answers in an interactive way and support efficient updates for high image arrival rates.", "paper_title": "I2RS: A Distributed Geo-Textual Image Retrieval and Recommendation System", "paper_id": "WOS:000386424800057"}