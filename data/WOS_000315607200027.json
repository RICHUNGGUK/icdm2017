{"auto_keywords": [{"score": 0.03380191138272064, "phrase": "hessian_matrix"}, {"score": 0.00481495049065317, "phrase": "online_time_series_data_prediction"}, {"score": 0.004581162468419365, "phrase": "signal_analysis"}, {"score": 0.004337028108577593, "phrase": "sparse_kernel"}, {"score": 0.004251500979153001, "phrase": "online_time_series_prediction"}, {"score": 0.004188459638572375, "phrase": "classical_kernel_methods"}, {"score": 0.004126349202545883, "phrase": "kernel_function_number"}, {"score": 0.003945467978172845, "phrase": "high_computational_cost"}, {"score": 0.003848413823574867, "phrase": "off-line_or_batch_learning"}, {"score": 0.0036980501827538455, "phrase": "learning_system"}, {"score": 0.0036070601923916196, "phrase": "training_sample"}, {"score": 0.0034834098902271626, "phrase": "higher_computational_speed"}, {"score": 0.003397683082821229, "phrase": "kernel_methods"}, {"score": 0.003347259612209552, "phrase": "online_learning"}, {"score": 0.003264872488939969, "phrase": "sparsification_method"}, {"score": 0.003152915289414825, "phrase": "system_loss_function"}, {"score": 0.0030296432347510687, "phrase": "new_training_sample"}, {"score": 0.0029403531729828574, "phrase": "sparse_dictionary"}, {"score": 0.0027557911038816256, "phrase": "correlation_matrix"}, {"score": 0.0027284410545226306, "phrase": "sample_inputs"}, {"score": 0.002687922713487696, "phrase": "kernel_weight_updating"}, {"score": 0.002408565679880478, "phrase": "affordable_computational_cost"}, {"score": 0.0023846534541336326, "phrase": "real-time_applications"}, {"score": 0.0022799458141165587, "phrase": "proposed_algorithm"}, {"score": 0.002223770196464436, "phrase": "artificial_time"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Kernel methods", " Recursive least square (RLS)", " Sparsification", " Online learning", " Time series"], "paper_abstract": "Kernel based methods have been widely applied for signal analysis and processing. In this paper, we propose a sparse kernel based algorithm for online time series prediction. In classical kernel methods, the kernel function number is very large which makes them of a high computational cost and only applicable for off-line or batch learning. In online learning settings, the learning system is updated when each training sample is obtained and it requires a higher computational speed. To make the kernel methods suitable for online learning, we propose a sparsification method based on the Hessian matrix of the system loss function to continuously examine the significance of the new training sample in order to select a sparse dictionary (support vector set). The Hessian matrix is equivalent to the correlation matrix of sample inputs in the kernel weight updating using the recursive least square (RLS) algorithm. This makes the algorithm able to be easily implemented with an affordable computational cost for real-time applications. Experimental results show the ability of the proposed algorithm for both real-world and artificial time series data forecasting and prediction. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "A sparse kernel algorithm for online time series data prediction", "paper_id": "WOS:000315607200027"}