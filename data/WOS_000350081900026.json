{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multiple_graph"}, {"score": 0.04968114352851346, "phrase": "sparse_coding"}, {"score": 0.0487007149356068, "phrase": "image_representation"}, {"score": 0.043193449009403535, "phrase": "manifold_learning"}, {"score": 0.004735254735115024, "phrase": "multiple_hypergraph"}, {"score": 0.0047155367844327, "phrase": "regularized_sparse_coding"}, {"score": 0.004641016648774612, "phrase": "manifold"}, {"score": 0.004598933498016774, "phrase": "sparse_coding_shows"}, {"score": 0.004466519142879166, "phrase": "key_issue"}, {"score": 0.00421297029755273, "phrase": "suitable_graph"}, {"score": 0.004074574278425223, "phrase": "sparse_coding_task"}, {"score": 0.004007083686875716, "phrase": "cross_validation"}, {"score": 0.003670608022642996, "phrase": "multiple_graph_sparse_coding"}, {"score": 0.0036400696415545813, "phrase": "mgrsc"}, {"score": 0.0035947360742084253, "phrase": "multiple_hypergraph_sparse_coding"}, {"score": 0.0033482708495261864, "phrase": "multiple_hypergraph_regularizers"}, {"score": 0.003265365666305185, "phrase": "sparse_codes"}, {"score": 0.0031845067058084583, "phrase": "data_manifold"}, {"score": 0.0030797912111959137, "phrase": "multiple_previously_given_graph_laplacians"}, {"score": 0.0030541531847589833, "phrase": "hypergraph_laplacians"}, {"score": 0.0029909851863915283, "phrase": "proposed_regularziers"}, {"score": 0.0028926147550022607, "phrase": "traditional_sparse_coding_framework"}, {"score": 0.0026941587813581252, "phrase": "objective_functions"}, {"score": 0.002627407106087633, "phrase": "sparse_coding_algorithms"}, {"score": 0.0025730425700096365, "phrase": "proposed_two_sparse_coding_methods"}, {"score": 0.0024065032567542107, "phrase": "graph_hyper-parameters"}, {"score": 0.0022601535748259785, "phrase": "proposed_sparse_coding_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Sparse coding", " Graph", " Hypergraph", " Alternating optimization"], "paper_abstract": "Manifold regularized sparse coding shows promising performance for various applications. The key issue that must be considered in the application is how to adaptively select the suitable graph hyper-parameters in manifold learning for the sparse coding task. Usually, cross validation is applied, but it does not necessarily scale up and easily leads to overfitting. In this article, multiple graph sparse coding (MGrSc) and multiple Hypergraph sparse coding (MHGrSc) for image representation are proposed. Inspired by the Ensemble Manifold Regularizer, we formulate multiple graph and multiple Hypergraph regularizers to guarantee the smoothness of sparse codes along the geodesics of a data manifold, which is characterized by fusing the multiple previously given graph Laplacians or Hypergraph Laplacians. Then, the proposed regularziers, respectively, are incorporated into the traditional sparse coding framework, which results in two unified objective functions of sparse coding. Alternating optimization is used to optimize the objective functions, and two, novel manifold regularized sparse coding algorithms are presented. The proposed two sparse coding methods learn both the composite manifold and the sparse coding jointly, and it is fully automatic for learning the graph hyper-parameters in the manifold learning. Image clustering tests on real world datasets demonstrated that the proposed sparse coding methods are superior to the state-of-the-art methods. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Multiple graph regularized sparse coding and multiple hypergraph regularized sparse coding for image representation", "paper_id": "WOS:000350081900026"}