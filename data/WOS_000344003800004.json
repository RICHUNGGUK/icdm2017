{"auto_keywords": [{"score": 0.049250789168149005, "phrase": "unsafe_actions"}, {"score": 0.012127661761832498, "phrase": "motion_data"}, {"score": 0.00481495049065317, "phrase": "motion_features"}, {"score": 0.00478701880312723, "phrase": "similarity-based_modeling"}, {"score": 0.004676895436217523, "phrase": "rapid_development"}, {"score": 0.00464976086880886, "phrase": "motion_sensors"}, {"score": 0.004622783000449884, "phrase": "video_processing"}, {"score": 0.004582608049002167, "phrase": "growing_attention"}, {"score": 0.004490212943845175, "phrase": "health_analysis"}, {"score": 0.004425354103924516, "phrase": "operation_analysis"}, {"score": 0.004336115760817672, "phrase": "occupational_safety"}, {"score": 0.0042859292226559535, "phrase": "worker_behavior_monitoring"}, {"score": 0.004236321075918639, "phrase": "automatic_detection"}, {"score": 0.004211731831120046, "phrase": "workers'_unsafe_actions"}, {"score": 0.004067152645111547, "phrase": "proactive_prevention"}, {"score": 0.003916098498242888, "phrase": "previous_studies"}, {"score": 0.003859500298805362, "phrase": "human_movements"}, {"score": 0.0036411406244705557, "phrase": "classification_performances"}, {"score": 0.0035469375686704207, "phrase": "capture_data"}, {"score": 0.0032596049901888724, "phrase": "classification_methodology"}, {"score": 0.0028094389072212352, "phrase": "actions'_mean_trajectory"}, {"score": 0.002658068304632523, "phrase": "spatial-temporal_similarity"}, {"score": 0.0026119782818898193, "phrase": "motion_analysis"}, {"score": 0.0025148328760856505, "phrase": "ladder_climbing"}, {"score": 0.002421291757425244, "phrase": "experimental_study"}, {"score": 0.0023792975669318615, "phrase": "proposed_approach"}, {"score": 0.002331221840164716, "phrase": "lab_experiments"}, {"score": 0.0022974765563692776, "phrase": "rotation_angle"}, {"score": 0.0022774637727808237, "phrase": "joint_angle"}, {"score": 0.0022576249214220187, "phrase": "position_vector"}, {"score": 0.002231441081806766, "phrase": "movement_direction"}, {"score": 0.0021927323694667694, "phrase": "motion_classification"}, {"score": 0.0021049977753042253, "phrase": "american_society_of_civil_engineers"}], "paper_keywords": ["Safety", " Motion capture", " Action recognition", " Dimension reduction", " Machine learning", " Classification"], "paper_abstract": "Rapid development of motion sensors and video processing has triggered growing attention to action recognition for safety and health analysis, as well as operation analysis, in construction. Specifically for occupational safety and health, worker behavior monitoring allows for the automatic detection of workers' unsafe actions and for feedback on their behavior, both of which enable the proactive prevention of an accident by reducing the number of unsafe actions that occur. Previous studies provide insight into tracking human movements and recognizing actions, but further research efforts are needed to understand the following characteristics of motion data, which can significantly affect classification performances: (1) various motion data types extracted from motion capture data, (2) variations of postures and actions, and (3) temporal and sequential relations of motion data. This paper thus presents a modeling and classification methodology for the recognition of unsafe actions, particularly focusing on (1) the description and comparison of four motion data types (i.e., rotation angles, joint angles, position vectors, and movement direction) that will be used as a feature for classification, (2) the estimation of actions' mean trajectory in order to model various patterns of action, and (3) the classification of actions based on spatial-temporal similarity. With a concentration on motion analysis, experiments were undertaken for the modeling and detection of actions during ladder climbing using an red, green, blue plus depth (RGB-D) sensor. Through the experimental study, we found that the proposed approach performs well (i.e., an accuracy of up to 99.5% in lab experiments), that a rotation angle outperforms a joint angle and a position vector, and that movement direction explicitly improves the accuracy of motion classification as combined with each of the other three. (C) 2014 American Society of Civil Engineers.", "paper_title": "Comparative Study of Motion Features for Similarity-Based Modeling and Classification of Unsafe Actions in Construction", "paper_id": "WOS:000344003800004"}