{"auto_keywords": [{"score": 0.04920822493417558, "phrase": "semantic_attributes"}, {"score": 0.03830243085167389, "phrase": "multiple_relative_attributes"}, {"score": 0.004815666084861762, "phrase": "humans"}, {"score": 0.004766808844197446, "phrase": "loop"}, {"score": 0.00454019648854141, "phrase": "image_content"}, {"score": 0.004424953471635011, "phrase": "image_annotation"}, {"score": 0.004344424495876066, "phrase": "significant_improvement"}, {"score": 0.004296809240805996, "phrase": "traditional_binary"}, {"score": 0.004081385289516914, "phrase": "abundant_supervision"}, {"score": 0.004051501401100304, "phrase": "high-quality_training_data"}, {"score": 0.00391969808162005, "phrase": "small_amounts"}, {"score": 0.0038624981944755813, "phrase": "low-quality_training_data"}, {"score": 0.0038061298318563925, "phrase": "active_learning"}, {"score": 0.0037231102027070724, "phrase": "relative_attributes"}, {"score": 0.003536346954940087, "phrase": "additional_information"}, {"score": 0.003433847524648519, "phrase": "existing_work"}, {"score": 0.003309877074892399, "phrase": "learning_loop"}, {"score": 0.00327356326590461, "phrase": "minimal_additional_guidance"}, {"score": 0.002985988377995789, "phrase": "joint_active_learning"}, {"score": 0.002931569771634119, "phrase": "pairwise_supervision"}, {"score": 0.0026641365405034355, "phrase": "ranking_functions"}, {"score": 0.0024842242921857705, "phrase": "proposed_pairwise_queries"}, {"score": 0.0022825763382627443, "phrase": "extensive_empirical_study"}, {"score": 0.00226583335721762, "phrase": "real_image_data_sets"}, {"score": 0.002128376306688074, "phrase": "superior_retrieval_performance"}, {"score": 0.0021049977753042253, "phrase": "significantly_less_human_inputs"}], "paper_keywords": ["Active learning", " learning to rank", " humans-in-the-loop", " image recognition", " relative attributes"], "paper_abstract": "Semantic attributes have been recognized as a more spontaneous manner to describe and annotate image content. It is widely accepted that image annotation using semantic attributes is a significant improvement to the traditional binary or multiclass annotation due to its naturally continuous and relative properties. Though useful, existing approaches rely on an abundant supervision and high-quality training data, which limit their applicability. Two standard methods to overcome small amounts of guidance and low-quality training data are transfer and active learning. In the context of relative attributes, this would entail learning multiple relative attributes simultaneously and actively querying a human for additional information. This paper addresses the two main limitations in existing work: 1) it actively adds humans to the learning loop so that minimal additional guidance can be given and 2) it learns multiple relative attributes simultaneously and thereby leverages dependence amongst them. In this paper, we formulate a joint active learning to rank framework with pairwise supervision to achieve these two aims, which also has other benefits such as the ability to be kernelized. The proposed framework optimizes over a set of ranking functions (measuring the strength of the presence of attributes) simultaneously and dependently on each other. The proposed pairwise queries take the form of which one of these two pictures is more natural? These queries can be easily answered by humans. Extensive empirical study on real image data sets shows that our proposed method, compared with several state-of-the-art methods, achieves superior retrieval performance while requires significantly less human inputs.", "paper_title": "Learning Multiple Relative Attributes With Humans in the Loop", "paper_id": "WOS:000345514300002"}