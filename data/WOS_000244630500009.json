{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "new_method"}, {"score": 0.01504624499318245, "phrase": "additive_models"}, {"score": 0.004767826806287385, "phrase": "function_estimation"}, {"score": 0.004721162131188487, "phrase": "variable_selection"}, {"score": 0.004539005582217309, "phrase": "cubic_splines"}, {"score": 0.004133940019630129, "phrase": "nonparametric_setting"}, {"score": 0.0040334640350288, "phrase": "linear_case"}, {"score": 0.003728000957725218, "phrase": "parsimonious_models"}, {"score": 0.0036733470451885465, "phrase": "significant_variables"}, {"score": 0.0034118234596993836, "phrase": "parsimonious_additive_model_solution"}, {"score": 0.003247868216333148, "phrase": "fixed_point_algorithm"}, {"score": 0.003168859801438632, "phrase": "singular_value_decomposition"}, {"score": 0.0030614565460256897, "phrase": "empirical_behavior"}, {"score": 0.0030314419455512013, "phrase": "parsimonious_additive_models"}, {"score": 0.0029576827451501956, "phrase": "adaptive_backfitting_bruto_algorithm"}, {"score": 0.0026538282523433684, "phrase": "model_estimation"}, {"score": 0.0025014259919355453, "phrase": "real_data"}, {"score": 0.002346160830406661, "phrase": "indinavir_plasma_concentration"}, {"score": 0.002323142666222693, "phrase": "hiv_patients"}, {"score": 0.0022223176391038785, "phrase": "promising_technique"}, {"score": 0.0021682027434117095, "phrase": "application_areas"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["model selection", " supervised learning", " nonparametric regression", " function estimation", " splines", " smoothing", " variable selection", " lasso", " penalization", " interpretable models"], "paper_abstract": "A new method for function estimation and variable selection, specifically designed for additive models fitted by cubic splines is proposed. This new method involves regularizing additive models using the l(1)-norm, which generalizes the lasso to the nonparametric setting. As in the linear case, it shrinks coefficients and produces some coefficients that are exactly zero. It gives parsimonious models, selects significant variables, and reveals nonlinearities in the effects of predictors. Two strategies for finding a parsimonious additive model solution are proposed. Both algorithms are based on a fixed point algorithm, combined with a singular value decomposition that considerably reduces computation. The empirical behavior of parsimonious additive models is compared to the adaptive backfitting BRUTO algorithm. The results allow to characterize the domains in which our approach is effective: it performs significantly better than BRUTO when model estimation is challenging. An implementation of this method is illustrated using real data from the Cophar 1 ANRS 102 trial. Parsimonious additive models are applied to predict the indinavir plasma concentration in HIV patients. Results suggest that this new method is a promising technique for the research and application areas. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Parsimonious additive models", "paper_id": "WOS:000244630500009"}