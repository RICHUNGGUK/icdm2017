{"auto_keywords": [{"score": 0.04301297368556487, "phrase": "fixed_camera"}, {"score": 0.03152580954847, "phrase": "developed_controller"}, {"score": 0.00481495049065317, "phrase": "robotic_manipulator"}, {"score": 0.004780334370089564, "phrase": "citrus_harvesting"}, {"score": 0.004728874038094706, "phrase": "main_contribution"}, {"score": 0.004577777897335174, "phrase": "vision-based_estimation_and_control_system"}, {"score": 0.004479726755921316, "phrase": "rigorous_stability_analysis"}, {"score": 0.004383766516923386, "phrase": "closed-loop_system"}, {"score": 0.004213123914295882, "phrase": "large_field"}, {"score": 0.003891430578662587, "phrase": "computationally_inexpensive_perspective_transformation-based_range_estimation_method"}, {"score": 0.0037398806676032068, "phrase": "real-time_manipulator_control"}, {"score": 0.0035554741718298085, "phrase": "target_fruit"}, {"score": 0.0034293295415901807, "phrase": "cih"}, {"score": 0.0032484270911235526, "phrase": "target_fruit_location"}, {"score": 0.0032134045046357876, "phrase": "presented_pursuit_guidance"}, {"score": 0.0031444844772458504, "phrase": "lyapunov-based_stability_analysis"}, {"score": 0.0030438576446554138, "phrase": "numerical_simulations"}, {"score": 0.0028936710552719806, "phrase": "seven_degrees-of-freedom_kinematically_redundant_manipulator"}, {"score": 0.0027113815712365924, "phrase": "closed-loop_visual_servo_control_experiment"}, {"score": 0.0025405463228033486, "phrase": "expected_position"}, {"score": 0.002441477009112022, "phrase": "confidence_ellipsoid"}, {"score": 0.0022547515816852266, "phrase": "large_varieties"}, {"score": 0.002238500096284007, "phrase": "citrus_fruit"}, {"score": 0.0021904435447196884, "phrase": "small_varieties"}, {"score": 0.002151183757599893, "phrase": "blood_oranges"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual servo control", " Robotic harvesting", " Agricultural robotics"], "paper_abstract": "The main contribution of this paper is in the development of vision-based estimation and control system for robotic fruit harvesting and rigorous stability analysis to guarantee performance of the closed-loop system. The presented cooperative visual servo controller benefits from the large field-of-view of a fixed camera and the accuracy of a camera-in-hand (CiH). Computationally inexpensive perspective transformation-based range estimation method obtains 3D fruit position using a monocular camera to enable real-time manipulator control. A rotation controller is developed to orient the robot such that the target fruit selected by the fixed camera can be viewed by the CiH attached to the end-effector. Subsequently, the end-effector can be servoed to the target fruit location using the presented pursuit guidance based hybrid translation controller. Lyapunov-based stability analysis guarantees global exponential regulation of the end-effector. Numerical simulations verify the feasibility of the developed controller while the performance is evaluated on a seven degrees-of-freedom kinematically redundant manipulator using an artificial citrus tree. The position of the fruit was randomly selected, and the closed-loop visual servo control experiment was performed 21 times to analyze the repeatability and accuracy of the developed controller. With 95% confidence level the expected position of the robot end-effector is observed to lie within the confidence ellipsoid. The accuracy of the controller was observed to be about 15 mm, thus making the system suitable for harvesting medium and large varieties of citrus fruit but may limit operation for small varieties such as page and blood oranges. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Vision-based control of robotic manipulator for citrus harvesting", "paper_id": "WOS:000334010400016"}