{"auto_keywords": [{"score": 0.0399982426143156, "phrase": "sparse_representation_structure"}, {"score": 0.015518719646278559, "phrase": "high-dimensional_data"}, {"score": 0.007975895388566252, "phrase": "proposed_methods"}, {"score": 0.00481495049065317, "phrase": "underlying_sparse_representation_structure"}, {"score": 0.00466085208934021, "phrase": "face_images"}, {"score": 0.004367228576339114, "phrase": "fast_sparsity_preserving_projections"}, {"score": 0.003663250792230243, "phrase": "existing_sparsity_preserving_projections"}, {"score": 0.003322263555678713, "phrase": "fspp"}, {"score": 0.003195073461466748, "phrase": "pca"}, {"score": 0.0030326180561817497, "phrase": "constructed_dictionary"}, {"score": 0.0029933487820771217, "phrase": "matrix-vector_multiplications"}, {"score": 0.0028228178454284825, "phrase": "ffspp"}, {"score": 0.0026104197983396367, "phrase": "fisher_constraint"}, {"score": 0.002559859451119449, "phrase": "fspp_formulation"}, {"score": 0.0025102759256260703, "phrase": "fspp's_discriminating_ability"}, {"score": 0.002336527289457915, "phrase": "generalized_eigenvalue_problem"}, {"score": 0.0023062508214156123, "phrase": "experimental_results"}, {"score": 0.0022468721386440316, "phrase": "yale"}, {"score": 0.002203332747526648, "phrase": "yale_b"}, {"score": 0.0021747828098044515, "phrase": "orl"}, {"score": 0.0021049977753042253, "phrase": "standard_document_collection"}], "paper_keywords": ["Dimensionality reduction", " Sparse representation", " Classwise PCA decomposition", " Fisher constraint", " Face recognition"], "paper_abstract": "Recently, there has been a lot of interest in the underlying sparse representation structure in high-dimensional data such as face images. In this paper, we propose two novel efficient dimensionality reduction methods named Fast Sparsity Preserving Projections (FSPP) and Fast Fisher Sparsity Preserving Projections (FFSPP), respectively, which aim to preserve the sparse representation structure in high-dimensional data. Unlike the existing Sparsity Preserving Projections (SPP), where the sparse representation structure is learned through resolving n (the number of samples) time-consuming norm optimization problems, FSPP constructs a dictionary through classwise PCA decompositions and learns the sparse representation structure under the constructed dictionary through matrix-vector multiplications, which is much more computationally tractable. FFSPP takes into consideration both the sparse representation structure and the discriminating efficiency by adding the Fisher constraint to the FSPP formulation to improve FSPP's discriminating ability. Both of the proposed methods can boil down to a generalized eigenvalue problem. Experimental results on three publicly available face data sets (Yale, Extended Yale B and ORL), and a standard document collection (Reuters-21578) validate the feasibility and effectiveness of the proposed methods.", "paper_title": "Fast Fisher Sparsity Preserving Projections", "paper_id": "WOS:000324794200015"}