{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "bayesian_multinets"}, {"score": 0.004754600386388821, "phrase": "binary_classification"}, {"score": 0.0046069985410261746, "phrase": "scoring_criterion"}, {"score": 0.00452063603944825, "phrase": "mixture-based_factorized_conditional_log-likelihood"}, {"score": 0.004298134888203576, "phrase": "efficient_hybrid_learning"}, {"score": 0.004191007935893067, "phrase": "bayesian_networks"}, {"score": 0.0041384457437123635, "phrase": "binary_classification_tasks"}, {"score": 0.00406083086983316, "phrase": "learning_procedure"}, {"score": 0.003909923690310641, "phrase": "background_learning"}, {"score": 0.003764603272900618, "phrase": "single_concept"}, {"score": 0.00353426342004404, "phrase": "highly_complex_background"}, {"score": 0.003467940281748612, "phrase": "overall_procedure"}, {"score": 0.003095257144856771, "phrase": "learning_algorithm"}, {"score": 0.002980124909321296, "phrase": "polynomial_time"}, {"score": 0.0029427043216782604, "phrase": "network_structures"}, {"score": 0.0028511898481970595, "phrase": "consistent_kappa-graphs"}, {"score": 0.0027106334164712057, "phrase": "mfcll_scoring_criterion"}, {"score": 0.0023887436047824386, "phrase": "large_suite"}, {"score": 0.0023587312574818208, "phrase": "benchmark_datasets"}, {"score": 0.0023144166368024603, "phrase": "mfcll-trained_classifiers"}, {"score": 0.0022709326810964386, "phrase": "competitive_alternative"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Conditional log-likelihood", " Approximation", " Hybrid learning", " Discriminative learning", " Bayesian networks", " Mixtures", " Multinets"], "paper_abstract": "We propose a scoring criterion, named mixture-based factorized conditional log-likelihood (mfCLL), which allows for efficient hybrid learning of mixtures of Bayesian networks in binary classification tasks. The learning procedure is decoupled in foreground and background learning, being the foreground the single concept of interest that we want to distinguish from a highly complex background. The overall procedure is hybrid as the foreground is discriminatively learned, whereas the background is generatively learned. The learning algorithm is shown to run in polynomial time for network structures such as trees and consistent kappa-graphs. To gauge the performance of the mfCLL scoring criterion, we carry out a comparison with state-of-the-art classifiers. Results obtained with a large suite of benchmark datasets show that mfCLL-trained classifiers are a competitive alternative and should be taken into consideration. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Hybrid learning of Bayesian multinets for binary classification", "paper_id": "WOS:000338392400019"}