{"auto_keywords": [{"score": 0.04201777933896293, "phrase": "bbn"}, {"score": 0.010319034482322215, "phrase": "statistical_feature_models"}, {"score": 0.006167812476432796, "phrase": "average_recognition_rate"}, {"score": 0.004725385523804256, "phrase": "bayesian_belief_inference"}, {"score": 0.004594137808658537, "phrase": "precise_facial_surfaces"}, {"score": 0.004508661664944657, "phrase": "associated_textures"}, {"score": 0.004362870617347183, "phrase": "accurate_description"}, {"score": 0.00432208488976429, "phrase": "facial_activities"}, {"score": 0.004143196873246147, "phrase": "unified_probabilistic_framework"}, {"score": 0.004047020753789236, "phrase": "bayesian_belief_network"}, {"score": 0.003807242767474929, "phrase": "bayesian_inference"}, {"score": 0.0036667768092524576, "phrase": "gibbs-boltzmann_distribution"}, {"score": 0.003598492288058048, "phrase": "hybrid_approach"}, {"score": 0.0034332736827447654, "phrase": "morphological_ones"}, {"score": 0.003154701855951328, "phrase": "fully_automatic_facial_expression_analysis"}, {"score": 0.003095923814666088, "phrase": "extensive_experiments"}, {"score": 0.0029398538512108597, "phrase": "bosphorus"}, {"score": 0.0028715299874549245, "phrase": "manually_labeled_landmarks"}, {"score": 0.0028312983170567948, "phrase": "proposed_framework"}, {"score": 0.002626034130205569, "phrase": "bosphorus_dataset"}, {"score": 0.0025409639091476363, "phrase": "six_universal_expressions"}, {"score": 0.0024128022009415476, "phrase": "sfam"}, {"score": 0.002248366278757655, "phrase": "experimental_results"}, {"score": 0.0021857667493036786, "phrase": "proposed_approach"}, {"score": 0.0021450029487459403, "phrase": "landmark_localization_errors"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Bayesian Belief Network", " Statistical feature model", " 3D face", " Facial expression recognition", " Action units recognition", " Automatic landmarking"], "paper_abstract": "Textured 3D face models capture precise facial surfaces along with the associated textures, making it possible for an accurate description of facial activities. In this paper, we present a unified probabilistic framework based on a novel Bayesian Belief Network (BBN) for 3D facial expression and Action Unit (AU) recognition. The proposed BBN performs Bayesian inference based on Statistical Feature Models (SFM) and Gibbs-Boltzmann distribution and feature a hybrid approach in fusing both geometric and appearance features along with morphological ones. When combined with our previously developed morphable partial face model (SFAM), the proposed BBN has the capacity of conducting fully automatic facial expression analysis. We conducted extensive experiments on the two public databases, namely the BU-3DFE dataset and the Bosphorus dataset. When using manually labeled landmarks, the proposed framework achieved an average recognition rate of 94.2% and 85.6% for the 7 and 16 AU on face data from the Bosphorus dataset respectively, and 89.2% for the six universal expressions on the BU-3DFE dataset. Using the landmarks automatically located by SFAM, the proposed BBN still achieved an average recognition rate of 84.9% for the six prototypical facial expressions. These experimental results demonstrate the effectiveness of the proposed approach and its robustness in landmark localization errors. Published by Elsevier B.V.", "paper_title": "A unified probabilistic framework for automatic 3D facial expression analysis based on a Bayesian belief inference and statistical feature models", "paper_id": "WOS:000317324600002"}