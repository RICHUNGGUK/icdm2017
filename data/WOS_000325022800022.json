{"auto_keywords": [{"score": 0.03826109052676288, "phrase": "mpi"}, {"score": 0.004385555408850022, "phrase": "program_development_toolkit"}, {"score": 0.004322967486451877, "phrase": "ompicuda"}, {"score": 0.0038256426589560774, "phrase": "familiar_programming_model"}, {"score": 0.003434397017127762, "phrase": "sdsm"}, {"score": 0.002952745241052452, "phrase": "different_parallel_regions"}, {"score": 0.00278752137116301, "phrase": "extended_device_directive"}, {"score": 0.0026505322540093783, "phrase": "parallel_region"}, {"score": 0.0025202582748972122, "phrase": "programming_toolkit"}, {"score": 0.0024311346712789553, "phrase": "data-partition_interfaces"}, {"score": 0.0023451553255837317, "phrase": "load_balance"}, {"score": 0.0022950308685133224, "phrase": "application_level"}], "paper_keywords": ["Hybrid CPU/GPU clusters", " Compound OpenMP/MPI", " CUDA", " Load balance", " Device directive"], "paper_abstract": "In this paper, we propose a program development toolkit called OMPICUDA for hybrid CPU/GPU clusters. With the support of this toolkit, users can make use of a familiar programming model, i.e., compound OpenMP and MPI instead of mixed CUDA and MPI or SDSM to develop their applications on a hybrid CPU/GPU cluster. In addition, they can adapt the types of resources used for executing different parallel regions in the same program by means of an extended device directive according to the property of each parallel region. On the other hand, this programming toolkit supports a set of data-partition interfaces for users to achieve load balance at the application level no matter what type of resources are used for the execution of their programs.", "paper_title": "A compound OpenMP/MPI program development toolkit for hybrid CPU/GPU clusters", "paper_id": "WOS:000325022800022"}