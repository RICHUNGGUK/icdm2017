{"auto_keywords": [{"score": 0.014601277902302912, "phrase": "network_latency"}, {"score": 0.00481495049065317, "phrase": "distributed_transactional_memory"}, {"score": 0.004678785623021003, "phrase": "distributed_transactional_memory_system"}, {"score": 0.0045726187330434025, "phrase": "new_opportunity"}, {"score": 0.003916098498242888, "phrase": "symbolic_prefetches"}, {"score": 0.0037402558657576124, "phrase": "first_prefetching_approach"}, {"score": 0.003431481042678356, "phrase": "aggressive_use"}, {"score": 0.003296212583539166, "phrase": "remote_objects"}, {"score": 0.0030414140732789186, "phrase": "simple_transactional_consistency_model"}, {"score": 0.0027741761880779535, "phrase": "five_scientific_benchmarks"}, {"score": 0.0025449518236394103, "phrase": "multiple_machines"}, {"score": 0.002294686545883412, "phrase": "distributed_applications"}, {"score": 0.0021049977753042253, "phrase": "parallel_applications"}], "paper_keywords": ["Distributed shared memory", " software transactional memory", " prefetching"], "paper_abstract": "We present a distributed transactional memory system that exploits a new opportunity to automatically hide network latency by speculatively prefetching and caching objects. The system includes an object caching framework, language extensions to support our approach, and symbolic prefetches. To our knowledge, this is the first prefetching approach that can prefetch objects whose addresses have not been computed or predicted. Our approach makes aggressive use of both prefetching and caching of remote objects to hide network latency while relying on the transaction commit mechanism to preserve the simple transactional consistency model that we present to the developer. We have evaluated this approach on three distributed benchmarks, five scientific benchmarks, and several microbenchmarks. We have found that our approach enables our benchmark applications to effectively utilize multiple machines and benefit from prefetching and caching. We have observed a speedup of up to 7.26x for distributed applications on our system using prefetching and caching and a speedup of up to 5.55x for parallel applications on our system.", "paper_title": "Integrating Caching and Prefetching Mechanisms in a Distributed Transactional Memory", "paper_id": "WOS:000292047500005"}