{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "singer's_method"}, {"score": 0.011664178563080422, "phrase": "crammer"}, {"score": 0.004304574865291508, "phrase": "complicated_optimization_problem"}, {"score": 0.004215189457411489, "phrase": "svm"}, {"score": 0.003985305257857655, "phrase": "common_alternative"}, {"score": 0.0032522091171602557, "phrase": "thorough_investigation"}, {"score": 0.0029688173975648173, "phrase": "subtle_differences"}, {"score": 0.0027100527874262446, "phrase": "useful_reference"}, {"score": 0.002388487669097511, "phrase": "tedious_process"}, {"score": 0.002195552442011313, "phrase": "new_results"}], "paper_keywords": [""], "paper_abstract": "Crammer and Singer's method is one of the most popular multiclass support vector machines (SVMs). It considers L1 loss (hinge loss) in a complicated optimization problem. In SVM, squared hinge loss (L2 loss) is a common alternative to L1 loss, but surprisingly we have not seen any paper studying the details of Crammer and Singer's method using L2 loss. In this letter, we conduct a thorough investigation. We show that the derivation is not trivial and has some subtle differences from the L1 case. Details provided in this work can be a useful reference for those who intend to use Crammer and Singer's method with L2 loss. They do not need a tedious process to derive everything by themselves. Furthermore, we present some new results on and discussion of both L1- and L2-loss formulations.", "paper_title": "A Study on L2-Loss (Squared Hinge-Loss) Multiclass SVM", "paper_id": "WOS:000316992800007"}