{"auto_keywords": [{"score": 0.04922237591220716, "phrase": "cooperative_multiagent_systems"}, {"score": 0.032981674375017964, "phrase": "repeated_interactions"}, {"score": 0.02634923946581221, "phrase": "learning_performance"}, {"score": 0.00481495049065317, "phrase": "multiagent_reinforcement_social_learning"}, {"score": 0.00418595288276353, "phrase": "cooperative_games"}, {"score": 0.004092463367307375, "phrase": "practical_complex_environments"}, {"score": 0.0038764861784138117, "phrase": "agent's_interacting_partners"}, {"score": 0.003638823482920949, "phrase": "multiagent_coordination_problems"}, {"score": 0.0036060781902674207, "phrase": "cooperative_environments"}, {"score": 0.003557509959237602, "phrase": "social_learning_framework"}, {"score": 0.0034780071331554003, "phrase": "large_population"}, {"score": 0.0030094882299407256, "phrase": "social_learning"}, {"score": 0.002824829396721492, "phrase": "consistent_optimal_coordination_policy"}, {"score": 0.00233594452829104, "phrase": "deterministic_and_stochastic_cooperative_games"}, {"score": 0.0022631003204259224, "phrase": "information_sharing_degree"}, {"score": 0.0021727640931660038, "phrase": "key_difference"}, {"score": 0.0021434588322608653, "phrase": "learning_framework"}, {"score": 0.0021049977753042253, "phrase": "fixed_agents"}], "paper_keywords": ["Algorithms", " Experimentation", " Multiagent social learning", " multiagent coordination", " cooperative games"], "paper_abstract": "Most previous works on coordination in cooperative multiagent systems study the problem of how two (or more) players can coordinate on Pareto-optimal Nash equilibrium(s) through fixed and repeated interactions in the context of cooperative games. However, in practical complex environments, the interactions between agents can be sparse, and each agent's interacting partners may change frequently and randomly. To this end, we investigate the multiagent coordination problems in cooperative environments under a social learning framework. We consider a large population of agents where each agent interacts with another agent randomly chosen from the population in each round. Each agent learns its policy through repeated interactions with the rest of the agents via social learning. It is not clear a priori if all agents can learn a consistent optimal coordination policy in such a situation. We distinguish two different types of learners depending on the amount of information each agent can perceive: individual action learner and joint action learner. The learning performance of both types of learners is evaluated under a number of challenging deterministic and stochastic cooperative games, and the influence of the information sharing degree on the learning performance also is investigated-a key difference from the learning framework involving repeated interactions among fixed agents.", "paper_title": "Multiagent Reinforcement Social Learning toward Coordination in Cooperative Multiagent Systems", "paper_id": "WOS:000348362200004"}