{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "big_data"}, {"score": 0.04971245563968756, "phrase": "small_nodes"}, {"score": 0.023420467715420917, "phrase": "arm_servers"}, {"score": 0.004723322467153553, "phrase": "continuous_increase"}, {"score": 0.004545240514015278, "phrase": "datacenter_resource"}, {"score": 0.004475893575036647, "phrase": "energy_utilization_problem"}, {"score": 0.004257708925521277, "phrase": "power_usage"}, {"score": 0.004192770270215872, "phrase": "watts"}, {"score": 0.003988293689448734, "phrase": "significant_improvements"}, {"score": 0.0037072310568610723, "phrase": "major_industry_players"}, {"score": 0.0035673211706948576, "phrase": "performance_study"}, {"score": 0.0035399770257915466, "phrase": "big_data_execution"}, {"score": 0.003459191419478298, "phrase": "traditional_big_nodes"}, {"score": 0.003328611206488653, "phrase": "future_development"}, {"score": 0.0032777653153451265, "phrase": "hadoop_mapreduce"}, {"score": 0.0032029462986637577, "phrase": "shark"}, {"score": 0.003070166825722112, "phrase": "intel_xeon"}, {"score": 0.003000070450638437, "phrase": "execution_time"}, {"score": 0.002977061391551631, "phrase": "energy_usage"}, {"score": 0.0029542282776915747, "phrase": "total_cost"}, {"score": 0.0028867712833776046, "phrase": "self-hosted_arm"}, {"score": 0.002662541169311738, "phrase": "big_data_workloads"}, {"score": 0.0026421139329830755, "phrase": "small_and_big_nodes"}, {"score": 0.0026117657828249137, "phrase": "small_memory_size"}, {"score": 0.002465161736207254, "phrase": "lower-power_advantage"}, {"score": 0.0024464591964712184, "phrase": "arm"}, {"score": 0.002308910575113746, "phrase": "xeon_nodes"}, {"score": 0.0022648637058989463, "phrase": "database_query_processing"}, {"score": 0.002145942273032774, "phrase": "slightly_lower_throughput"}, {"score": 0.002121281184742656, "phrase": "minor_software_modifications"}, {"score": 0.0021049977753042253, "phrase": "cpu-intensive_mapreduce_workloads"}], "paper_keywords": [""], "paper_abstract": "The continuous increase in volume, variety and velocity of Big Data exposes datacenter resource scaling to an energy utilization problem. Traditionally, datacenters employ x86-64 (big) server nodes with power usage of tens to hundreds of Watts. But lately, low-power (small) systems originally developed for mobile devices have seen significant improvements in performance. These improvements could lead to the adoption of such small systems in servers, as announced by major industry players. In this context, we systematically conduct a performance study of Big Data execution on small nodes in comparison with traditional big nodes, and present insights that would be useful for future development. We run Hadoop MapReduce, MySQL and in-memory Shark workloads on clusters of ARM big. LITTLE boards and Intel Xeon server systems. We evaluate execution time, energy usage and total cost of running the workloads on self-hosted ARM and Xeon nodes. Our study shows that there is no one size fits all rule for judging the efficiency of executing Big Data workloads on small and big nodes. But small memory size, low memory and I/O bandwidths, and software immaturity concur in canceling the lower-power advantage of ARM servers. We show that I/O-intensive MapReduce workloads are more energy-efficient to run on Xeon nodes. In contrast, database query processing is always more energy-efficient on ARM servers, at the cost of slightly lower throughput. With minor software modifications, CPU-intensive MapReduce workloads are almost four times cheaper to execute on ARM servers.", "paper_title": "A Performance Study of Big Data on Small Nodes", "paper_id": "WOS:000362281700006"}