{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "ever-smaller_transistors"}, {"score": 0.004716520738331953, "phrase": "dramatic_variations"}, {"score": 0.004652016085325825, "phrase": "critical_process_parameters"}, {"score": 0.00443308765153716, "phrase": "large_variations"}, {"score": 0.004312622975366676, "phrase": "different_hardware_components"}, {"score": 0.004053362743156545, "phrase": "memory_components"}, {"score": 0.003970439654470374, "phrase": "minimum-sized_transistors"}, {"score": 0.003835972725191194, "phrase": "current_design_methodologies"}, {"score": 0.003680587852807675, "phrase": "worst_case_scenarios"}, {"score": 0.0035072146967082083, "phrase": "performance_angle"}, {"score": 0.003296212583539166, "phrase": "viable_option"}, {"score": 0.0032065418360603293, "phrase": "future_designs"}, {"score": 0.0030135741897058844, "phrase": "chip_data_caches"}, {"score": 0.0028715299874549245, "phrase": "adaptive_cache_management_policy"}, {"score": 0.0028127163745564777, "phrase": "nonuniform_cache_access"}, {"score": 0.002680114113899346, "phrase": "latency_compensation_approach"}, {"score": 0.0025537472239953807, "phrase": "access_latency"}, {"score": 0.002518746501941657, "phrase": "select_cache_lines"}, {"score": 0.0023999697562763433, "phrase": "load_instructions"}, {"score": 0.0021940118003312397, "phrase": "significant_amount"}, {"score": 0.0021490449563443025, "phrase": "lost_performance"}, {"score": 0.0021049977753042253, "phrase": "worst_case_designs"}], "paper_keywords": ["Process variation", " cache", " address prediction", " superscalar processors"], "paper_abstract": "Fabricating circuits that employ ever-smaller transistors leads to dramatic variations in critical process parameters. This in turn results in large variations in execution/access latencies of different hardware components. This situation is even more severe for memory components due to minimum-sized transistors used in their design. Current design methodologies that are tuned for the worst case scenarios are becoming increasingly pessimistic from the performance angle, and thus, may not be a viable option at all for future designs. This paper makes two contributions targeting on-chip data caches. First, it presents an adaptive cache management policy based on nonuniform cache access. Second, it proposes a latency compensation approach that employs several circuit-level techniques to change the access latency of select cache lines based on the criticalities of the load instructions that access them. Our experiments reveal that both these techniques can recover significant amount of the lost performance due to worst case designs.", "paper_title": "Process Variation-Aware Adaptive Cache Architecture and Management", "paper_id": "WOS:000266273200001"}