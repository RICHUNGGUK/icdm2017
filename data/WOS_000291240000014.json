{"auto_keywords": [{"score": 0.046720801569906774, "phrase": "previous_version"}, {"score": 0.015587509184417645, "phrase": "multiple_helper_servers"}, {"score": 0.008713768692145006, "phrase": "parallel_programming_interface"}, {"score": 0.007969037126772036, "phrase": "global_data_structures"}, {"score": 0.00785120607077978, "phrase": "heavy_use"}, {"score": 0.007210305333743777, "phrase": "distributed_program"}, {"score": 0.0071643864674607125, "phrase": "test_data"}, {"score": 0.005990177239396912, "phrase": "new_version"}, {"score": 0.004794437032071519, "phrase": "distributed_data"}, {"score": 0.0047777308010243935, "phrase": "global_data_structure"}, {"score": 0.004723322467153553, "phrase": "improved_version"}, {"score": 0.004623547657702614, "phrase": "common_application_programming_interface"}, {"score": 0.0043181530164057135, "phrase": "large_global_data_structures"}, {"score": 0.004272882932156908, "phrase": "program"}, {"score": 0.004146416483297736, "phrase": "cpc_program_library"}, {"score": 0.0041287394089001405, "phrase": "queen's_university"}, {"score": 0.00411113753736038, "phrase": "belfast"}, {"score": 0.004093610094414265, "phrase": "n._ireland"}, {"score": 0.004058778458962374, "phrase": "standard_cpc"}, {"score": 0.0037663231691533244, "phrase": "tar.gz_programming_language"}, {"score": 0.0037502873149511252, "phrase": "fortran"}, {"score": 0.003555191623558018, "phrase": "ram"}, {"score": 0.003517360835220474, "phrase": "external"}, {"score": 0.0033991222157268752, "phrase": "comput"}, {"score": 0.0033860869117176605, "phrase": "phys"}, {"score": 0.0033701693046163422, "phrase": "comm"}, {"score": 0.0031071534787335577, "phrase": "required_one-sided_remote_memory_access"}, {"score": 0.003015508235745547, "phrase": "parallel_scientific_applications"}, {"score": 0.002977061391551628, "phrase": "global_data_management"}, {"score": 0.0029079265023919275, "phrase": "ga"}, {"score": 0.0028040060413773507, "phrase": "portable_parallel_codes"}, {"score": 0.002703869368554536, "phrase": "particular_computing_platform"}, {"score": 0.002601727192945944, "phrase": "passive_one-sided_operations"}, {"score": 0.002434756284438473, "phrase": "mutual_exclusion"}, {"score": 0.0023883144155067253, "phrase": "data_server"}, {"score": 0.0023227875748290257, "phrase": "flexible_options"}, {"score": 0.0022980652695552698, "phrase": "different_settings"}, {"score": 0.0022882500116799777, "phrase": "helper_servers"}, {"score": 0.0022784765799773463, "phrase": "significant_improvement"}, {"score": 0.0022542248277445495, "phrase": "performance_tests"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["MPI", " Parallel"], "paper_abstract": "We present an improved version of the Parallel Programming Interface for Distributed Data with Multiple Helper Servers (PPIDDv2) library, which provides a common application programming interface that is based on the most frequently used functionality of both MPI-2 and GA. Compared with the previous version, the PPIDDv2 library introduces multiple helper servers to facilitate global data structures, and allows programmers to make heavy use of large global data structures efficiently. Program summary Program title: PPIDDv2 Catalogue identifier: AEEF_v2_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEEF_v2_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk//licence/licence.html No. of lines in distributed program, including test data, etc.: 22 997 No. of bytes in distributed program, including test data, etc.: 184477 Distribution format: tar.gz Programming language: Fortran, C Computer: Many parallel systems Operating system: Various Has the code been vectorised or parallelised?: Yes. 2-1024 processors used RAM: 50 Mbytes Classification: 6.5 External routines: Global Arrays or MPI-2 Catalogue identifier of previous version: AEEF_v1_0 Journal reference of previous version: Comput. Phys. Comm. 180 (2009) 2673 Does the new version supersede the previous version?: Yes Nature of problem: Many scientific applications require management and communication of data that is global, and the standard MPI-2 protocol provides only low-level methods for the required one-sided remote memory access. Solution method: The Parallel Programming Interface for Distributed Data (PPIDD) library provides an interface, suitable for use in parallel scientific applications, that delivers communications and global data management. The library can be built either using the Global Arrays (GA) toolkit, or a standard MPI-2 library. This abstraction allows the programmer to write portable parallel codes that can utilise the best, or only, communications library that is available on a particular computing platform. Reasons for new version: In the previous version, functionality in global data structure was mainly implemented by MPI-2 passive one-sided operations. In real applications which make heavy use of global data structures, very poor performance was observed. Summary of revisions: Multiple helper servers are introduced to facilitate the manipulation and management of global data structure. Mutual exclusion is also implemented by the help of a data server, and becomes much more robust and efficient. In addition, flexible options are provided to choose different settings for helper servers. Significant improvement has been seen in performance tests. M. Wang et al./Computer Physics Communications 182 (2011) 1502-1506 Running time: Problem-dependent. The test provided with the distribution takes only a few seconds to run. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Improved version of parallel programming interface for distributed data with multiple helper servers", "paper_id": "WOS:000291240000014"}