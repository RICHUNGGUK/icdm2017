{"auto_keywords": [{"score": 0.04811643643051334, "phrase": "subspace_learning"}, {"score": 0.00481495049065317, "phrase": "based_feature_extraction"}, {"score": 0.0047152877145889656, "phrase": "face_representation_and_recognition"}, {"score": 0.004291617358806677, "phrase": "proper_feature_subspace"}, {"score": 0.004115697805448384, "phrase": "high-dimensional_data"}, {"score": 0.003988487841970088, "phrase": "learned_low-dimensional_subspace"}, {"score": 0.003480993634130542, "phrase": "projection_process"}, {"score": 0.002974974236093886, "phrase": "haar"}, {"score": 0.002882837875681877, "phrase": "fht"}, {"score": 0.002678944072162297, "phrase": "fht_based_spectral_regression_discriminant_analysis"}, {"score": 0.002289180040240783, "phrase": "integral_vector"}, {"score": 0.002241679436497569, "phrase": "feature_extraction"}, {"score": 0.0021951623041245897, "phrase": "experimental_results"}], "paper_keywords": ["Face representation and recognition", " fast algorithm", " feature extraction", " Haar transform", " subspace analysis"], "paper_abstract": "Subspace learning is the process of finding a proper feature subspace and then projecting high-dimensional data onto the learned low-dimensional subspace. The projection operation requires many floating-point multiplications and additions, which makes the projection process computationally expensive. To tackle this problem, this paper proposes two simple-but-effective fast subspace learning and image projection methods, fast Haar transform (FHT) based principal component analysis and FHT based spectral regression discriminant analysis. The advantages of these two methods result from employing both the FHT for subspace learning and the integral vector for feature extraction. Experimental results on three face databases demonstrated their effectiveness and efficiency.", "paper_title": "Fast Haar Transform Based Feature Extraction for Face Representation and Recognition", "paper_id": "WOS:000269155900015"}