{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "scene_enhancement"}, {"score": 0.004770211811866158, "phrase": "object_tracking"}, {"score": 0.004703878334423852, "phrase": "important_challenge"}, {"score": 0.004638462976078815, "phrase": "vision_system"}, {"score": 0.004552648949390462, "phrase": "varying_illumination_conditions"}, {"score": 0.004447600571127578, "phrase": "automatic_correction_scheme"}, {"score": 0.004324723240308028, "phrase": "unknown_illumination"}, {"score": 0.0042446888127531945, "phrase": "illumination_model_learnt"}, {"score": 0.004185632403886255, "phrase": "known_illumination"}, {"score": 0.003994624397219346, "phrase": "gray_level_imaging_scenarios"}, {"score": 0.003957477564354679, "phrase": "skin_color_based_hand_tracking"}, {"score": 0.0037768417338850274, "phrase": "color_imaging_scenario"}, {"score": 0.0037242701420971062, "phrase": "automatically_extracted_palm_region"}, {"score": 0.0035542408902458677, "phrase": "observed_skin_color_palette"}, {"score": 0.003504756881063581, "phrase": "training_phase"}, {"score": 0.003472149546470424, "phrase": "feed-forward_neural_network"}, {"score": 0.0033603864623013733, "phrase": "observed_palette"}, {"score": 0.0031919592786945126, "phrase": "ideal_illumination_conditions"}, {"score": 0.0031182092708983184, "phrase": "reliable_results"}, {"score": 0.00297576670831646, "phrase": "skin_regions"}, {"score": 0.002948066398723126, "phrase": "successive_frames"}, {"score": 0.0029069972482610403, "phrase": "image_sequence"}, {"score": 0.002722758109991685, "phrase": "reliable_tracking"}, {"score": 0.0026722904884984348, "phrase": "image_sequences"}, {"score": 0.0026474076254702525, "phrase": "wide_variations"}, {"score": 0.002410942838102255, "phrase": "clustering_scheme"}, {"score": 0.0023662411481713704, "phrase": "segment_images"}, {"score": 0.002289993730291138, "phrase": "matching_clusters"}, {"score": 0.0022058510091498666, "phrase": "poorly_illuminated_images"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["illumination correction", " skin color", " contrast transfer", " neural network", " condensation tracker", " fuzzy c-means clustering"], "paper_abstract": "An important challenge for any vision system is to accommodate varying illumination conditions. We device an automatic correction scheme that transforms images under some unknown illumination to match an illumination model learnt for a known illumination. We test the scheme on both color and gray level imaging scenarios. Skin color based hand tracking is our reference problem for testing the scheme in color imaging scenario. An automatically extracted palm region from initial frames in the sequence serves as an observed skin color palette. During training phase a feed-forward neural network learns the weights that map the observed palette to a pre-stored (target) skin color palette. The pre-stored palette represents ideal illumination conditions where the tracker gives reliable results. The look up table so generated then enhances skin regions in successive frames of the image sequence, thus improving the performance of the tracker. This approach enables a reliable tracking of hand in image sequences with wide variations in illumination. In order to defining correspondence between source and target palettes, a fuzzy c-means clustering scheme is used to segment images into regions. The histograms of matching clusters are used to transfer the contrast in poorly illuminated images to enhance the contrast. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Automatic illumination correction for scene enhancement and object tracking", "paper_id": "WOS:000240577200004"}