{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "facial_expression_analysis"}, {"score": 0.004520132822496416, "phrase": "human-computer_interaction"}, {"score": 0.004390192910013225, "phrase": "facial_animation"}, {"score": 0.0043477114072437316, "phrase": "three-dimensional_facial_data"}, {"score": 0.004181839414007266, "phrase": "illumination_condition"}, {"score": 0.0037942165191367366, "phrase": "discrete_expression_classification"}, {"score": 0.0037030390595465673, "phrase": "human_face"}, {"score": 0.0035100601949451028, "phrase": "first_part"}, {"score": 0.0033433365160336842, "phrase": "annotated_face_model"}, {"score": 0.003231349231968127, "phrase": "dense_point_correspondence"}, {"score": 0.002917331114260319, "phrase": "expression_recognition_framework"}, {"score": 0.0027651847105654363, "phrase": "point_distribution_model"}, {"score": 0.0026466064623118105, "phrase": "different_features"}, {"score": 0.00259554612218815, "phrase": "second_part"}, {"score": 0.0025207920578878894, "phrase": "systematic_pipeline"}, {"score": 0.0023431692392929353, "phrase": "alternative_modules"}, {"score": 0.002286781334850213, "phrase": "comparative_study"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Expression recognition", " 3D face models", " 40 face videos", " Mesh registration"], "paper_abstract": "Facial expression analysis has interested many researchers in the past decade due to its potential applications in various fields such as human-computer interaction, psychological studies, and facial animation. Three-dimensional facial data has been proven to be insensitive to illumination condition and head pose, and has hence gathered attention in recent years. In this paper, we focus on discrete expression classification using 3D data from the human face. The paper is divided in two parts. In the first part, we present improvement to the fitting of the Annotated Face Model (AFM) so that a dense point correspondence can be found in terms of both position and semantics among static 3D face scans or frames in 3D face sequences. Then, an expression recognition framework on static 3D images is presented. It is based on a Point Distribution Model (PDM) which can be built on different features. In the second part of this article, a systematic pipeline that operates on dynamic 3D sequences (4D datasets or 3D videos) is proposed and alternative modules are investigated as a comparative study. We evaluated both 3D and 4D Facial Expression Recognition pipelines on two publicly available facial expression databases and obtained promising results. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "3D/4D facial expression analysis: An advanced annotated face model approach", "paper_id": "WOS:000310389100006"}