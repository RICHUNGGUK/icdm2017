{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multilayer_perceptrons"}, {"score": 0.013776968085917133, "phrase": "cross-entropy"}, {"score": 0.01157120019101811, "phrase": "exp"}, {"score": 0.004763895422211728, "phrase": "different_risk"}, {"score": 0.004663396040465122, "phrase": "present_paper"}, {"score": 0.004492573860101133, "phrase": "information-theoretic_inspired_risk_functionals"}, {"score": 0.004259293347851015, "phrase": "mean_square_error"}, {"score": 0.0038283058265876713, "phrase": "shannon_and_quadratic_renyi_entropies"}, {"score": 0.003727527379253624, "phrase": "zed"}, {"score": 0.0036100762867678415, "phrase": "error_density"}, {"score": 0.003571751184289622, "phrase": "zero_errors"}, {"score": 0.0034777028461723198, "phrase": "generalized_exponential_risk"}, {"score": 0.0033680968918579717, "phrase": "wide_variety"}, {"score": 0.003332332086930163, "phrase": "risk_functionals"}, {"score": 0.003261934055562238, "phrase": "information-thoeretic_ones"}, {"score": 0.002900426826591772, "phrase": "statistical_tests"}, {"score": 0.0028391271282216758, "phrase": "experimental_results"}, {"score": 0.0027791193706247267, "phrase": "ubiquitous_mean_square_error"}, {"score": 0.0025514745448798385, "phrase": "square_error"}, {"score": 0.002497531381123025, "phrase": "significantly_better_classification_performance"}, {"score": 0.0022087165619569006, "phrase": "significantly_better_and_worse_risks"}, {"score": 0.002127655517353705, "phrase": "hs"}], "paper_keywords": ["Risk functionals", " classification", " multilayer perceptrons"], "paper_abstract": "In the present paper, we assess the performance of information-theoretic inspired risk functionals in multilayer perceptrons with reference to the two most popular ones, Mean Square Error and Cross-Entropy. The information-theoretic inspired risks, recently proposed: HS and HR2 are, respectively, the Shannon and quadratic Renyi entropies of the error; ZED is a risk reflecting the error density at zero errors; EXP is a generalized exponential risk, able to mimic a wide variety of risk functionals, including the information-thoeretic ones. The experiments were carried out with multilayer perceptrons on 35 public real-world datasets. All experiments were performed according to the same protocol. The statistical tests applied to the experimental results showed that the ubiquitous mean square error was the less interesting risk functional to be used by multilayer perceptrons. Namely, mean square error never achieved a significantly better classification performance than competing risks. Cross-entropy and EXP were the risks found by several tests to be significantly better than their competitors. Counts of significantly better and worse risks have also shown the usefulness of HS and HR2 for some datasets.", "paper_title": "CLASSIFICATION PERFORMANCE OF MULTILAYER PERCEPTRONS WITH DIFFERENT RISK FUNCTIONALS", "paper_id": "WOS:000343997500001"}