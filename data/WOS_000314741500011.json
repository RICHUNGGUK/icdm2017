{"auto_keywords": [{"score": 0.03464034545023033, "phrase": "sparse_imputation"}, {"score": 0.00481495049065317, "phrase": "data_speech_recognition"}, {"score": 0.004718897469501381, "phrase": "multisource_reverberant_environment"}, {"score": 0.004563028873351776, "phrase": "automatic_speech_recognition_system"}, {"score": 0.004442032546224076, "phrase": "missing_data_approach"}, {"score": 0.004295269532032448, "phrase": "environmental_noise"}, {"score": 0.0037549546301384336, "phrase": "diverse_range"}, {"score": 0.003704797078215222, "phrase": "acoustic_features"}, {"score": 0.0036064757492752703, "phrase": "speech_recognition"}, {"score": 0.0035344448639851827, "phrase": "partially_observed_data"}, {"score": 0.0034638476252104706, "phrase": "missing_components"}, {"score": 0.0033718991936259038, "phrase": "clean_speech_estimates"}, {"score": 0.003238517900104576, "phrase": "cluster-based_gmm_imputation"}, {"score": 0.0030895394261534776, "phrase": "estimation_techniques"}, {"score": 0.0030278017562213265, "phrase": "interaural_level"}, {"score": 0.0029873281676201565, "phrase": "time_difference-pairs"}, {"score": 0.002927626967420519, "phrase": "proposed_missing_data_approach"}, {"score": 0.0028498718992429825, "phrase": "keyword_accuracy_rates"}, {"score": 0.00279291004189267, "phrase": "signal-to-noise_ratio_conditions"}, {"score": 0.002700485592691974, "phrase": "chime_reverberant_multisource_environment_corpus"}, {"score": 0.002628747284714371, "phrase": "imputation_methods"}, {"score": 0.0025935941070969575, "phrase": "cluster-based_imputation"}, {"score": 0.0024576084154573396, "phrase": "highest_keyword_accuracy"}, {"score": 0.0023131084326717755, "phrase": "imputed_data"}, {"score": 0.0021917966722180132, "phrase": "possible_imputation_errors"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Noise robust", " Speech recognition", " Missing data", " Binaural", " Multicondition", " Imputation"], "paper_abstract": "We present an automatic speech recognition system that uses a missing data approach to compensate for challenging environmental noise containing both additive and convolutive components. The unreliable and noise-corrupted (\"missing\") components are identified using a Gaussian mixture model (GMM) classifier based on a diverse range of acoustic features. To perform speech recognition using the partially observed data, the missing components are substituted with clean speech estimates computed using both sparse imputation and cluster-based GMM imputation. Compared to two reference mask estimation techniques based on interaural level and time difference-pairs, the proposed missing data approach significantly improved the keyword accuracy rates in all signal-to-noise ratio conditions when evaluated on the CHIME reverberant multisource environment corpus. Of the imputation methods, cluster-based imputation was found to outperform sparse imputation. The highest keyword accuracy was achieved when the system was trained on imputed data, which made it more robust to possible imputation errors. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Mask estimation and imputation methods for missing data speech recognition in a multisource reverberant environment", "paper_id": "WOS:000314741500011"}