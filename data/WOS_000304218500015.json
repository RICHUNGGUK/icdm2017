{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "cognitive_radio_networks"}, {"score": 0.03022084635258387, "phrase": "local_game"}, {"score": 0.004749106104067268, "phrase": "game_learning_approach"}, {"score": 0.004684157900507474, "phrase": "aggregate_system_capacity"}, {"score": 0.004556901872357751, "phrase": "game_theoretic_solution"}, {"score": 0.004515252649226697, "phrase": "joint_channel_allocation"}, {"score": 0.004473982381245469, "phrase": "power_control"}, {"score": 0.004352411290383643, "phrase": "physical_interference_model"}, {"score": 0.004195418010131832, "phrase": "distributed_solution"}, {"score": 0.004119049028319832, "phrase": "network_utility"}, {"score": 0.004044064541716598, "phrase": "different_criteria"}, {"score": 0.003988719758707836, "phrase": "limited_information"}, {"score": 0.0038447943243941685, "phrase": "noncooperative_game"}, {"score": 0.0037921662574137535, "phrase": "local_information"}, {"score": 0.0036721416244816455, "phrase": "pure_nash_equilibrium"}, {"score": 0.0035233696341819437, "phrase": "simulation_results"}, {"score": 0.003427540517249369, "phrase": "high_probability"}, {"score": 0.00327356326590461, "phrase": "potential_game"}, {"score": 0.0031845067058084583, "phrase": "overall_network_information"}, {"score": 0.003140888248194296, "phrase": "obtained_results"}, {"score": 0.0030695103543472908, "phrase": "centralized_heuristic_genetic_algorithm"}, {"score": 0.0028914057633212045, "phrase": "utility_functions"}, {"score": 0.0027741761880779535, "phrase": "transmitted_power"}, {"score": 0.0026252106881752067, "phrase": "convergence_limitations"}, {"score": 0.0025655216052760093, "phrase": "no-regret_learning_algorithms"}, {"score": 0.0024956789310376635, "phrase": "joint_channel"}, {"score": 0.002472822097373027, "phrase": "power_allocation"}, {"score": 0.00241658945942583, "phrase": "stable_mixed_strategies"}, {"score": 0.002361632539339945, "phrase": "even_better_global_performance"}, {"score": 0.0023079225317714815, "phrase": "interesting_perspective"}, {"score": 0.002276283303864666, "phrase": "realistic_protocols"}, {"score": 0.0022347698358650514, "phrase": "modeled_interactions"}, {"score": 0.002163930783583212, "phrase": "efficient_opportunistic_spectrum_access"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Cognitive radio networks", " Game theory", " No-regret learning", " Channel allocation", " Power control"], "paper_abstract": "This paper presents a game theoretic solution for joint channel allocation and power control in cognitive radio networks analyzed under the physical interference model. The objective is to find a distributed solution that maximizes the network utility, defined with different criteria, with limited information. The problem is addressed through a noncooperative game based on local information. Although the existence of a pure Nash Equilibrium cannot be assured for this game, simulation results show that it exists with high probability and with a performance similar to that of a potential game, where each player requires overall network information. The obtained results are compared with a centralized heuristic genetic algorithm to show the correctness of the proposals. From this point, utility functions for the local game are modified to restrict the transmitted power to drive the solution to a more cooperative approach. To overcome the convergence limitations of the local game, no-regret learning algorithms are used to perform the joint channel and power allocation. These algorithms provide stable mixed strategies in any scenario with even better global performance. This opens an interesting perspective to develop realistic protocols based on the modeled interactions and increases the adaptability to perform efficient opportunistic spectrum access. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Distributed resource allocation in cognitive radio networks with a game learning approach to improve aggregate system capacity", "paper_id": "WOS:000304218500015"}