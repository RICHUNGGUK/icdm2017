{"auto_keywords": [{"score": 0.03913046358139019, "phrase": "data_dependencies"}, {"score": 0.00481495049065317, "phrase": "task_scheduling_strategies"}, {"score": 0.004624751696958501, "phrase": "multiple_data_centers"}, {"score": 0.004555371402128666, "phrase": "intensive_applications"}, {"score": 0.004509694461067052, "phrase": "remote_sensing_data_processing"}, {"score": 0.004266501496765747, "phrase": "computer_and_network_technologies"}, {"score": 0.0038964032225585117, "phrase": "input_files"}, {"score": 0.0038379074449947067, "phrase": "acyclic_graph"}, {"score": 0.0036676174658755683, "phrase": "widely_distributed_computing_environment"}, {"score": 0.0032006150973842846, "phrase": "sharing_files"}, {"score": 0.0031366648074858555, "phrase": "pgh_algorithm"}, {"score": 0.003105168935158648, "phrase": "bots_applications"}, {"score": 0.0028355237433457313, "phrase": "scheduling_policy"}, {"score": 0.002628747284714371, "phrase": "dag_workflow"}, {"score": 0.0026023381988430666, "phrase": "massive_remote_sensing_data"}, {"score": 0.002524688179363081, "phrase": "scheduling_queue"}, {"score": 0.0024993218789131437, "phrase": "dag_tasks"}, {"score": 0.0023287359930308864, "phrase": "gridsim_simulation_environment"}, {"score": 0.0022706700510423954, "phrase": "gridlets"}, {"score": 0.002158836285985314, "phrase": "ott._copyright"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["multi-datacenter infrastructure", " data intensive computing", " task scheduling", " big data computing"], "paper_abstract": "Data intensive applications of remote sensing data processing are more and more widespread resulting from the evolutions in computer and network technologies. Especially, bags-of-tasks (BoTs) applications with a mass of sharing input files and directed acyclic graph (DAG) applications with data dependencies in a widely distributed computing environment bring new challenges. In this article, a strategy of partitioning group based on hypergraph (PGH) is introduced to formulate the model of sharing files. Within the PGH algorithm, BoTs applications would be partitioned into several groups to minimize the time of data transferring. We also adopted another scheduling policy, which is called optimized task tree (OTT) strategy to handle the DAG workflow of massive remote sensing data processing with data dependencies. A scheduling queue of DAG tasks would be updated according to the priorities changing. With the help of GridSim simulation environment, we designed the Gridlets within scheduler to test the performance of PGH and OTT. Copyright (c) 2013 John Wiley & Sons, Ltd.", "paper_title": "Design and implementation of task scheduling strategies for massive remote sensing data processing across multiple data centers", "paper_id": "WOS:000337731000008"}