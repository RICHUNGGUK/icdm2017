{"auto_keywords": [{"score": 0.04976849859687578, "phrase": "expression_variations"}, {"score": 0.0047527118741586055, "phrase": "partial_data"}, {"score": 0.004630626571109149, "phrase": "challenging_task"}, {"score": 0.004367228576339114, "phrase": "meshsift_algorithm"}, {"score": 0.004078729256705429, "phrase": "mean_curvature_extrema"}, {"score": 0.004052263422466088, "phrase": "scale_space"}, {"score": 0.0039097293657870584, "phrase": "salient_points"}, {"score": 0.0038092152998069786, "phrase": "salient_point"}, {"score": 0.003747705541406206, "phrase": "feature_vector"}, {"score": 0.0037112756920669593, "phrase": "concatenated_histograms"}, {"score": 0.0036871853429163953, "phrase": "shape_indices"}, {"score": 0.003663250792230243, "phrase": "slant_angles"}, {"score": 0.0036040894858791793, "phrase": "feature_vectors"}, {"score": 0.003477264432055326, "phrase": "feature_space"}, {"score": 0.003257960296952439, "phrase": "first_contribution"}, {"score": 0.0031638248208086263, "phrase": "meshsift_features"}, {"score": 0.003133052778244851, "phrase": "reliable_measure"}, {"score": 0.0031127040190005216, "phrase": "expression-invariant_face_recognition"}, {"score": 0.0029836116021984605, "phrase": "bosphorus"}, {"score": 0.002964230998380698, "phrase": "frgc"}, {"score": 0.0028412769256691, "phrase": "feature_descriptors"}, {"score": 0.002585016334273749, "phrase": "recognition_rate"}, {"score": 0.0023441581629788347, "phrase": "symmetry_plane_estimation"}, {"score": 0.002261570820039492, "phrase": "ransac"}, {"score": 0.002232261129770455, "phrase": "correct_solution"}, {"score": 0.0021961592899628615, "phrase": "bosphorus_database"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["meshSIFT", " 3D face recognition", " Local features", " Expressions", " Missing data", " Partial data", " Pose normalisation", " Symmetry plane"], "paper_abstract": "Matching 3D faces for recognition is a challenging task caused by the presence of expression variations, missing data, and outliers. In this paper the meshSIFT algorithm and its use for 3D face recognition is presented. This algorithm consists of four major components. First, salient points on the 3D facial surface are detected as mean curvature extrema in scale space. Second, orientations are assigned to each of these salient points. Third, the neighbourhood of each salient point is described in a feature vector consisting of concatenated histograms of shape indices and slant angles. Fourth, the feature vectors of two 3D facial surfaces are reliably matched by comparing the angles in feature space. This results in an algorithm which is robust to expression variations, missing data and outliers. As a first contribution, we demonstrate that the number of matching meshSIFT features is a reliable measure for expression-invariant face recognition, as shown by the rank 1 recognition rate of 93.7% and 89.6% for the Bosphorus and FRGC v2 database, respectively. Next, we demonstrate that symmetrising the feature descriptors allows comparing two 3D facial surfaces with limited or no overlap. Validation on the data of the \"SHRE'11: Face Scans\" contest, containing many partial scans, resulted in a recognition rate of 98.6%, clearly outperforming all other participants in the challenge. Finally, we also demonstrate the use of meshSIFT for two other problems related with 3D face recognition: pose normalisation and symmetry plane estimation. For both problems, applying meshSIFT in combination with RANSAC resulted in a correct solution for +/- 90% of all Bosphorus database meshes (except +/- 90 degrees and +/- 45 degrees rotations). (c) 2012 Elsevier Inc. All rights reserved.", "paper_title": "meshSIFT: Local surface features for 3D face recognition under expression variations and partial data", "paper_id": "WOS:000314136600005"}