{"auto_keywords": [{"score": 0.046363267640327735, "phrase": "optical_flow"}, {"score": 0.044605401042099674, "phrase": "human_actions"}, {"score": 0.03156429996966141, "phrase": "hidden_layer"}, {"score": 0.026057046832530392, "phrase": "flfcn_classifier"}, {"score": 0.00481495049065317, "phrase": "human_action_recognition"}, {"score": 0.004742730438544081, "phrase": "fast_learning"}, {"score": 0.004419703921314433, "phrase": "based_complex-valued_features"}, {"score": 0.003995876175614403, "phrase": "complex_plane"}, {"score": 0.0038573081851680656, "phrase": "motion_information"}, {"score": 0.00363080961099728, "phrase": "complex-valued_features"}, {"score": 0.003558294449586273, "phrase": "fast_learning_fully_complex-valued_neural_classifier"}, {"score": 0.0032989853590079153, "phrase": "fast_learning_fully_complex-valued_neural"}, {"score": 0.0031684791285366315, "phrase": "single_hidden_layer"}, {"score": 0.0029374939071038146, "phrase": "fully_complex-valued_activation_function"}, {"score": 0.0028498718992429825, "phrase": "hyperbolic_secant_function"}, {"score": 0.0026823700218343506, "phrase": "output_weights"}, {"score": 0.0026155094974689595, "phrase": "minimum_norm_least_square_solution"}, {"score": 0.0025503112711036994, "phrase": "linear_equations"}, {"score": 0.0024742098091226203, "phrase": "superior_performance"}, {"score": 0.0023642842046859274, "phrase": "real-valued_support_vector_machines"}, {"score": 0.0021917966722180132, "phrase": "orthogonal_decision_boundaries"}, {"score": 0.002158836285985314, "phrase": "classification_performance"}], "paper_keywords": ["Action recognition", " Complex-valued neural networks", " Optical flow", " Human Action", " Orthogonal decision boundaries"], "paper_abstract": "In this paper, we use optical flow based complex-valued features extracted from video sequences to recognize human actions. The optical flow features between two image planes can be appropriately represented in the Complex plane. Therefore, we argue that motion information that is used to model the human actions should be represented as complex-valued features and propose a fast learning fully complex-valued neural classifier to solve the action recognition task. The classifier, termed as, \"fast learning fully complex-valued neural (FLFCN) classifier\" is a single hidden layer fully complex-valued neural network. The neurons in the hidden layer employ the fully complex-valued activation function of the type of a hyperbolic secant function. The parameters of the hidden layer are chosen randomly and the output weights are estimated as the minimum norm least square solution to a set of linear equations. The results indicate the superior performance of FLFCN classifier in recognizing the actions compared to real-valued support vector machines and other existing results in the literature. Complex valued representation of 2D motion and orthogonal decision boundaries boost the classification performance of FLFCN classifier. (c) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Human action recognition using a fast learning fully complex-valued classifier", "paper_id": "WOS:000304638500021"}