{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "distribution-free_estimator"}, {"score": 0.0046781613377273774, "phrase": "conditional_support"}, {"score": 0.004589124394375718, "phrase": "tolerance_intervals"}, {"score": 0.0037864980290391354, "phrase": "key_ingredients"}, {"score": 0.0035741900278634616, "phrase": "appropriate_notion"}, {"score": 0.0033737457695128233, "phrase": "probability_mass"}, {"score": 0.0028923335491735564, "phrase": "compression_argument"}, {"score": 0.0025521085778978042, "phrase": "mutual_information"}, {"score": 0.002166711569953301, "phrase": "fano's_inequality"}, {"score": 0.0021049977753042253, "phrase": "bivariate_case"}], "paper_keywords": ["Fano's inequality", " mutual information", " statistical learning theory"], "paper_abstract": "This(1) paper studies a distribution-free estimator of the conditional support and tolerance intervals of a distributions underlying a set of paired independent and identically distributed (i.i.d.) observations. The key ingredients are (a) an appropriate notion of risk which measures what probability mass is not captured by the estimate, (b) a uniform concentration inequality for the empirical risk based on a compression argument, and (c) the derivation of a lower bound to the mutual information, dictating how to maximize the informativeness of the estimator. For this result we extend Fano's inequality to the bivariate case.", "paper_title": "Least Conservative Support and Tolerance Tubes", "paper_id": "WOS:000268107200028"}