{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "shift-invariant_sparse_image_representations"}, {"score": 0.0046069985410261746, "phrase": "sparse_coding"}, {"score": 0.00452063603944825, "phrase": "generative_signal_model"}, {"score": 0.0043527164193299574, "phrase": "linear_combinations"}, {"score": 0.004112411350177274, "phrase": "sparsity_penalty"}, {"score": 0.004009894739765119, "phrase": "signal_approximation"}, {"score": 0.003959594975607075, "phrase": "dictionary_learning"}, {"score": 0.0038124354878360032, "phrase": "primal_structures"}, {"score": 0.0036476222647061243, "phrase": "shift-invariance_constraint"}, {"score": 0.003194580334752371, "phrase": "dictionary_increase"}, {"score": 0.0031148723927633955, "phrase": "increasing_number"}, {"score": 0.0028692628457408025, "phrase": "shift-invariant_sparse_image_representation"}, {"score": 0.0027106334164712057, "phrase": "tree-structured_approach"}, {"score": 0.002626317051411829, "phrase": "tree-structured_dictionary"}, {"score": 0.0025285834281312705, "phrase": "computational_cost"}, {"score": 0.002481085648977411, "phrase": "image_decomposition"}, {"score": 0.002434477906829832, "phrase": "logarithmic_order"}, {"score": 0.0022002633747977593, "phrase": "se_learning"}, {"score": 0.0021049977753042253, "phrase": "image_recovery_applications"}], "paper_keywords": ["image decomposition", " image representation", " sparse coding", " shape vector quantization", " image restoration"], "paper_abstract": "In this study, we introduce shift-invariant sparse image representations using tree-structured dictionaries. Sparse coding is a generative signal model that approximates signals by the linear combinations of atoms in a dictionary. Since a sparsity penalty is introduced during signal approximation and dictionary learning, the dictionary represents the primal structures of the signals. Under the shift-invariance constraint, the dictionary comprises translated structuring elements (SEs). The computational cost and number of atoms in the dictionary increase along with the increasing number of SEs. In this paper, we propose an algorithm for shift-invariant sparse image representation, in which SEs are learnt with a tree-structured approach. By using a tree-structured dictionary, we can reduce the computational cost of the image decomposition to the logarithmic order of the number of SEs. We also present the results of our experiments on the SE learning and the use Of Our algorithm in image recovery applications.", "paper_title": "Shift-Invariant Sparse Image Representations Using Tree-Structured Dictionaries", "paper_id": "WOS:000272773700022"}