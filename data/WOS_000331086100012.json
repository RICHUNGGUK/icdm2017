{"auto_keywords": [{"score": 0.027432916894526822, "phrase": "hct"}, {"score": 0.025422965336947427, "phrase": "pam"}, {"score": 0.00481495049065317, "phrase": "discrete_k-median_clustering"}, {"score": 0.004779406424192843, "phrase": "time-series_data"}, {"score": 0.004571559854487074, "phrase": "time-series_data_sets"}, {"score": 0.00450429688285697, "phrase": "nondiscrete_clustering_methods"}, {"score": 0.004421601997620278, "phrase": "problem_domain"}, {"score": 0.004276541976450121, "phrase": "mathematical_programming_formulations"}, {"score": 0.004244955499652296, "phrase": "solution_methods"}, {"score": 0.004167001961564886, "phrase": "dkm_clustering_problem"}, {"score": 0.004105666842002734, "phrase": "approximation_algorithms"}, {"score": 0.004060256280654948, "phrase": "bilinear_formulation"}, {"score": 0.004015345955907906, "phrase": "discrete_k-median_problem"}, {"score": 0.003970930401776528, "phrase": "uncoupled_bilinear_program_algorithm"}, {"score": 0.003927004211021119, "phrase": "approximation_algorithm"}, {"score": 0.0036462799422150834, "phrase": "linear_time"}, {"score": 0.003566028957296066, "phrase": "minimum_cost_assignment_problem"}, {"score": 0.003436169600453596, "phrase": "assignment_problem"}, {"score": 0.0033981387193790353, "phrase": "efficient_sequential_algorithm"}, {"score": 0.003360527337581911, "phrase": "faster_approximation"}, {"score": 0.0032987614613108345, "phrase": "dkm-s."}, {"score": 0.0032381271420557052, "phrase": "compact_exact_integer_formulation"}, {"score": 0.0032141856243404618, "phrase": "dkm"}, {"score": 0.003120171161064748, "phrase": "dkm-m."}, {"score": 0.0030514638431036714, "phrase": "arbitrary_pairwise_distance_matrices"}, {"score": 0.0029621948240346092, "phrase": "simulated_single-variate"}, {"score": 0.002929394386754424, "phrase": "random_walk_time-series_data"}, {"score": 0.0028862231180242053, "phrase": "comparative_clustering_performances"}, {"score": 0.0028648759706752162, "phrase": "normalized_mutual_information"}, {"score": 0.0028436917627268758, "phrase": "nmi"}, {"score": 0.0028121943702224326, "phrase": "solution_speeds"}, {"score": 0.0027810502577708105, "phrase": "dkm_methods"}, {"score": 0.0026401983633087267, "phrase": "distance_matrices"}, {"score": 0.0026012779346272848, "phrase": "hierarchical_cluster_trees"}, {"score": 0.002469508424323385, "phrase": "nmi_scores"}, {"score": 0.0024512358145634336, "phrase": "classification_accuracies"}, {"score": 0.002370663905320869, "phrase": "five_different_distance_measures"}, {"score": 0.002301265368019983, "phrase": "public_benchmark"}, {"score": 0.002284234786840546, "phrase": "real-life_neural_time-series_data_sets"}, {"score": 0.002242206465278159, "phrase": "dkm-s"}, {"score": 0.002128587147609537, "phrase": "consistently_good_clustering_results"}, {"score": 0.0021049977753042253, "phrase": "data_sets"}], "paper_keywords": ["clustering", " optimization", " discrete k-median", " mixed-integer programming", " uncoupled bilinear program algorithm", " sequential optimization", " time series"], "paper_abstract": "Discrete k-median (DKM) clustering problems arise in many real-life applications that involve time-series data sets, in which nondiscrete clustering methods may not represent the problem domain adequately. In this study, we propose mathematical programming formulations and solution methods to efficiently solve the DKM clustering problem. We develop approximation algorithms from a bilinear formulation of the discrete k-median problem using an uncoupled bilinear program algorithm. This approximation algorithm, which we refer to as DKM-L, is composed of two alternating linear programs, where one can be solved in linear time and the other is a minimum cost assignment problem. We then modify this algorithm by replacing the assignment problem with an efficient sequential algorithm for a faster approximation, which we call DKM-S. We also propose a compact exact integer formulation, DKM-I, and a more efficient network design-based exact mixed-integer formulation, DKM-M. All of our methods use arbitrary pairwise distance matrices as input. We apply our methods to simulated single-variate and multivariate random walk time-series data. We report comparative clustering performances using normalized mutual information (NMI) and solution speeds among the DKM methods we propose. We also compare our methods to other clustering algorithms that can operate with distance matrices, such as hierarchical cluster trees (HCT) and partition around medoids (PAM). We present NMI scores and classification accuracies of our DKM algorithms compared to HCT and PAM using five different distance measures on simluated data, as well as public benchmark and real-life neural time-series data sets. We show that DKM-S is much faster than HCT, PAM, and all other DKM methods and produces consistently good clustering results on all data sets.", "paper_title": "Mathematical Programming Formulations and Algorithms for Discrete k-Median Clustering of Time-Series Data", "paper_id": "WOS:000331086100012"}