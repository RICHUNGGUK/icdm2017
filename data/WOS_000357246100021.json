{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "facial_expression_recognition"}, {"score": 0.043683483035953596, "phrase": "joint_representation"}, {"score": 0.04173052379689658, "phrase": "facial_images"}, {"score": 0.004510203697930847, "phrase": "fer"}, {"score": 0.004352123742308589, "phrase": "multimodal_learning_method"}, {"score": 0.004275173711009189, "phrase": "first_attempt"}, {"score": 0.004028326293950714, "phrase": "landmark_modality"}, {"score": 0.003450966222451678, "phrase": "different_modalities"}, {"score": 0.0031561961485589633, "phrase": "modality-specific_sparsity"}, {"score": 0.002852356597632014, "phrase": "facial_expression"}, {"score": 0.002639845784408318, "phrase": "subtle_expression"}, {"score": 0.0025471636425006155, "phrase": "different_input"}, {"score": 0.0024577274522206436, "phrase": "proposed_multimodal_learning_network"}, {"score": 0.002371424085814217, "phrase": "multimodal_inputs"}, {"score": 0.0022881443200668886, "phrase": "fer._experimental_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Multimodal learning", " Facial expression recognition", " Texture", " Landmark"], "paper_abstract": "In this paper, multimodal learning for facial expression recognition (FER) is proposed. The multimodal learning method makes the first attempt to learn the joint representation by considering the texture and landmark modality of facial images, which are complementary with each other. In order to learn the representation of each modality and the correlation and interaction between different modalities, the structured regularization (SR) is employed to enforce and learn the modality-specific sparsity and density of each modality, respectively. By introducing SR, the comprehensiveness of the facial expression is fully taken into consideration, which can not only handle the subtle expression but also perform robustly to different input of facial images. With the proposed multimodal learning network, the joint representation learning from multimodal inputs will be more suitable for FER. Experimental results on the CK+ and NVIE databases demonstrate the superiority of our proposed method. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Multimodal learning for facial expression recognition", "paper_id": "WOS:000357246100021"}