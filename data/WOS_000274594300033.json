{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "classifier_performances"}, {"score": 0.04506785476449152, "phrase": "new_measure"}, {"score": 0.03125119819092013, "phrase": "proposed_measure"}, {"score": 0.02902782548552576, "phrase": "theoretical_analysis"}, {"score": 0.004716520738331953, "phrase": "crucial_problem"}, {"score": 0.004652016085325825, "phrase": "pattern_recognition"}, {"score": 0.004588389551682397, "phrase": "machine_learning"}, {"score": 0.0028914057633212045, "phrase": "class_distribution_information"}, {"score": 0.0026986685585382347, "phrase": "statistical_experiments"}, {"score": 0.002518746501941657, "phrase": "rci._experimental_results"}, {"score": 0.002467140591777737, "phrase": "benchmark_data"}, {"score": 0.0023507916951658455, "phrase": "statistical_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Performance evaluation", " Entropy", " Accuracy", " Classification"], "paper_abstract": "Evaluating classifier performances is a crucial problem in pattern recognition and machine learning. In this paper, we propose a new measure, i.e. confusion entropy, for evaluating classifiers. For each class cl(i) of an (N + 1)-class problem, the misclassification information involves both the information of how the samples with true class label cl(i) have been misclassified to the other N classes and the information of how the samples of the other N classes have been misclassified to class cl(i). The proposed measure exploits the class distribution information of such misclassifications of all classes. Both theoretical analysis and statistical experiments show the proposed measure is more precise than accuracy and RCI. Experimental results on some benchmark data sets further confirm the theoretical analysis and statistical results and show that the new measure is feasible for evaluating classifier performances. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "A novel measure for evaluating classifiers", "paper_id": "WOS:000274594300033"}