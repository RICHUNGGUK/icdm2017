{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-class_object_layout"}, {"score": 0.004637478829869904, "phrase": "object_recognition"}, {"score": 0.004436116555817464, "phrase": "sophisticated_machine_learning_techniques"}, {"score": 0.0043610084347896596, "phrase": "labeled_examples"}, {"score": 0.004157374465795314, "phrase": "positive_and_negative_examples"}, {"score": 0.0040040425282442125, "phrase": "non-maxima_suppression"}, {"score": 0.0038960785110831162, "phrase": "multiple_detections"}, {"score": 0.0038431888954930083, "phrase": "different_classes"}, {"score": 0.0037395458116642306, "phrase": "good_performance"}, {"score": 0.0035648266669315943, "phrase": "unified_model"}, {"score": 0.003540539868937462, "phrase": "multi-class_object_recognition"}, {"score": 0.003456827226847432, "phrase": "structured_prediction_task"}, {"score": 0.003386645324034521, "phrase": "binary_label"}, {"score": 0.003352088714126572, "phrase": "image_window"}, {"score": 0.0032728171827367068, "phrase": "structured_labeling"}, {"score": 0.003239418275717787, "phrase": "entire_image"}, {"score": 0.0030985717040741875, "phrase": "spatial_arrangements"}, {"score": 0.003056475095474338, "phrase": "real_images"}, {"score": 0.0029537168715385643, "phrase": "nms"}, {"score": 0.0028937142757436683, "phrase": "spatial_co-occurrence_statistics"}, {"score": 0.002854392852477005, "phrase": "parameter_estimation"}, {"score": 0.002805989498127897, "phrase": "max-margin_learning_problem"}, {"score": 0.002748984715897838, "phrase": "ground-truth_object_locations"}, {"score": 0.0026565317818265394, "phrase": "convex_optimization_problem"}, {"score": 0.0026114748685439116, "phrase": "cutting_plane_algorithm"}, {"score": 0.0025936662520897992, "phrase": "joachims_et_al"}, {"score": 0.0025672524051949933, "phrase": "mach"}, {"score": 0.002447101794397243, "phrase": "training_images"}, {"score": 0.002340623433237658, "phrase": "pascal_voc_benchmark"}, {"score": 0.0022774088820755366, "phrase": "global_model"}, {"score": 0.002254145085288829, "phrase": "spatial_layout"}, {"score": 0.002238767763626708, "phrase": "multiple_object_classes"}, {"score": 0.002215897810312801, "phrase": "preliminary_version"}, {"score": 0.0021560445153869985, "phrase": "desai_et_al"}, {"score": 0.0021049977753042253, "phrase": "computer_vision"}], "paper_keywords": ["Object recognition", " Context", " Structured prediction", " Cutting plane"], "paper_abstract": "Many state-of-the-art approaches for object recognition reduce the problem to a 0-1 classification task. This allows one to leverage sophisticated machine learning techniques for training classifiers from labeled examples. However, these models are typically trained independently for each class using positive and negative examples cropped from images. At test-time, various post-processing heuristics such as non-maxima suppression (NMS) are required to reconcile multiple detections within and between different classes for each image. Though crucial to good performance on benchmarks, this post-processing is usually defined heuristically. We introduce a unified model for multi-class object recognition that casts the problem as a structured prediction task. Rather than predicting a binary label for each image window independently, our model simultaneously predicts a structured labeling of the entire image (Fig. 1). Our model learns statistics that capture the spatial arrangements of various object classes in real images, both in terms of which arrangements to suppress through NMS and which arrangements to favor through spatial co-occurrence statistics. We formulate parameter estimation in our model as a max-margin learning problem. Given training images with ground-truth object locations, we show how to formulate learning as a convex optimization problem. We employ the cutting plane algorithm of Joachims et al. (Mach. Learn. 2009) to efficiently learn a model from thousands of training images. We show state-of-the-art results on the PASCAL VOC benchmark that indicate the benefits of learning a global model encapsulating the spatial layout of multiple object classes (a preliminary version of this work appeared in ICCV 2009, Desai et al., IEEE international conference on computer vision, 2009).", "paper_title": "Discriminative Models for Multi-Class Object Layout", "paper_id": "WOS:000294569300001"}