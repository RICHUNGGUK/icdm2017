{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "genetic_network_programming"}, {"score": 0.0046993598473345395, "phrase": "dynamically_changing_environments"}, {"score": 0.004411588377842043, "phrase": "evolutionary_algorithms"}, {"score": 0.004326624385772596, "phrase": "reinforcement_learning"}, {"score": 0.0039447744176901054, "phrase": "fitness_improvement"}, {"score": 0.0037942165191367366, "phrase": "tileworld_problems"}, {"score": 0.003757480190200645, "phrase": "elevator_group_supervisory_control_systems"}, {"score": 0.003579046565851265, "phrase": "khepera_robot"}, {"score": 0.0034760655218366, "phrase": "testing_environments"}, {"score": 0.0031383410838018984, "phrase": "adaptation_mechanism"}, {"score": 0.003092842645798083, "phrase": "testing_environment"}, {"score": 0.002903161412792026, "phrase": "environmental_changes"}, {"score": 0.002861062731782219, "phrase": "robot_simulator"}, {"score": 0.0028471655497661528, "phrase": "webots"}, {"score": 0.0027922467043592597, "phrase": "unexperienced_sensor_troubles"}, {"score": 0.002725081358527507, "phrase": "simulation_results"}, {"score": 0.0025829353063908256, "phrase": "wrong_sensor_information"}, {"score": 0.002424450174817922, "phrase": "alternative_actions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Evolutionary computation", " Genetic network programming", " Reinforcement learning", " Adaptability", " Khepera robot"], "paper_abstract": "Genetic network programming (GNP) has been proposed as one of the evolutionary algorithms and extended with reinforcement learning (GNP-RL). The combination of evolution and learning can efficiently evolve programs and the fitness improvement has been confirmed in the simulations of tileworld problems, elevator group supervisory control systems, stock trading models and wall following behavior of Khepera robot. However, its adaptability in testing environments, where the situations dynamically change, has not been analyzed in detail yet. In this paper, the adaptation mechanism in the testing environment is introduced and it is confirmed that GNP-RL can adapt to the environmental changes using a robot simulator WEBOTS, especially when unexperienced sensor troubles suddenly occur. The simulation results show that GNP-RL works well in the testing even if wrong sensor information is given because GNP-RL has a function to automatically change programs using alternative actions. In addition, the analysis on the effects of the parameters of GNP-RL is carried out in both training and testing simulations. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Adaptability analysis of genetic network programming with reinforcement learning in dynamically changing environments", "paper_id": "WOS:000307796300007"}