{"auto_keywords": [{"score": 0.04480024954324633, "phrase": "feature_selection"}, {"score": 0.015361973151232501, "phrase": "class_imbalance_problem"}, {"score": 0.00481495049065317, "phrase": "small_sample_class_imbalance_problem"}, {"score": 0.004631758267671427, "phrase": "real-world_applications"}, {"score": 0.004490212943845175, "phrase": "classifier's_suboptimal_performance"}, {"score": 0.004171065188039856, "phrase": "systematic_studies"}, {"score": 0.003844545552246988, "phrase": "different_challenges"}, {"score": 0.003800026771283179, "phrase": "imbalanced_data_sets"}, {"score": 0.003627028894710926, "phrase": "text_classification_problems"}, {"score": 0.003488874535154583, "phrase": "additional_problem"}, {"score": 0.003435092524339692, "phrase": "small_samples"}, {"score": 0.0033559647822437298, "phrase": "first_systematic_comparison"}, {"score": 0.003253279945540651, "phrase": "imbalanced_data_classification_problems"}, {"score": 0.0032155857567170696, "phrase": "seven_feature_selection_metrics"}, {"score": 0.003178326919668771, "phrase": "small_sample_data_sets"}, {"score": 0.0029867619862229853, "phrase": "receiver_operating_characteristic"}, {"score": 0.002895341091441627, "phrase": "precision-recall_curve"}, {"score": 0.0027741761880779535, "phrase": "average_performance"}, {"score": 0.0026374845514245547, "phrase": "best_performance"}, {"score": 0.002606906626639414, "phrase": "specific_problem"}, {"score": 0.0024977819584875573, "phrase": "problem_domain"}, {"score": 0.002293014162421338, "phrase": "signal-to-noise_correlation_coefficient"}, {"score": 0.0022227806435520764, "phrase": "sliding_thresholds"}, {"score": 0.0021799789348982534, "phrase": "great_candidates"}], "paper_keywords": ["Class imbalance problem", " feature evaluation and selection", " machine learning", " pattern recognition", " bioinformatics", " text mining"], "paper_abstract": "The class imbalance problem is encountered in real-world applications of machine learning and results in a classifier's suboptimal performance. Researchers have rigorously studied the resampling, algorithms, and feature selection approaches to this problem. No systematic studies have been conducted to understand how well these methods combat the class imbalance problem and which of these methods best manage the different challenges posed by imbalanced data sets. In particular, feature selection has rarely been studied outside of text classification problems. Additionally, no studies have looked at the additional problem of learning from small samples. This paper presents a first systematic comparison of the three types of methods developed for imbalanced data classification problems and of seven feature selection metrics evaluated on small sample data sets from different applications. We evaluated the performance of these metrics using area under the receiver operating characteristic (AUC) and area under the precision-recall curve (PRC). We compared each metric on the average performance across all problems and on the likelihood of a metric yielding the best performance on a specific problem. We examined the performance of these metrics inside each problem domain. Finally, we evaluated the efficacy of these metrics to see which perform best across algorithms. Our results showed that signal-to-noise correlation coefficient (S2N) and Feature Assessment by Sliding Thresholds (FAST) are great candidates for feature selection in most applications, especially when selecting very small numbers of features.", "paper_title": "Combating the Small Sample Class Imbalance Problem Using Feature Selection", "paper_id": "WOS:000281000500004"}