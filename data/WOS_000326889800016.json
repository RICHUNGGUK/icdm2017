{"auto_keywords": [{"score": 0.031325598349779195, "phrase": "proposed_algorithm"}, {"score": 0.00481495049065317, "phrase": "kernelized_lars-lasso"}, {"score": 0.004719664411221952, "phrase": "radial_basis_function_neural_networks"}, {"score": 0.00450456611645112, "phrase": "crucial_importance"}, {"score": 0.004444921827311577, "phrase": "radial_basis_function"}, {"score": 0.004299228562179176, "phrase": "existing_model_structure_selection_algorithms"}, {"score": 0.004130660282810338, "phrase": "backward_elimination_methods"}, {"score": 0.003995226376780718, "phrase": "sub-optimal_models"}, {"score": 0.0038385317554884713, "phrase": "alternative_selection_procedure"}, {"score": 0.003737485125097945, "phrase": "kernelized_least_angle_regression"}, {"score": 0.003520007298940198, "phrase": "lasso"}, {"score": 0.003359119985242403, "phrase": "rbf_neural_network"}, {"score": 0.0032925489316383955, "phrase": "linear-in-the-parameters_model"}, {"score": 0.0028052155436760528, "phrase": "previously_selected_regressor_term"}, {"score": 0.002589241150493978, "phrase": "lars"}, {"score": 0.0025042115651986332, "phrase": "output_weights"}, {"score": 0.0023113506171584157, "phrase": "model_structure_selection"}, {"score": 0.0021910825909008946, "phrase": "better_generalization_performance"}, {"score": 0.0021333110194180997, "phrase": "computational_experiments"}, {"score": 0.0021049977753042253, "phrase": "artificial_and_real_world_data"}], "paper_keywords": ["Kernelized LARS-LASSO", " Radial basis function (RBF)", " Mode structure selection"], "paper_abstract": "Model structure selection is of crucial importance in radial basis function (RBF) neural networks. Existing model structure selection algorithms are essentially forward selection or backward elimination methods that may lead to sub-optimal models. This paper proposes an alternative selection procedure based on the kernelized least angle regression (LARS)-least absolute shrinkage and selection operator (LASSO) method. By formulating the RBF neural network as a linear-in-the-parameters model, we derive a l (1)-constrained objective function for training the network. The proposed algorithm makes it possible to dynamically drop a previously selected regressor term that is insignificant. Furthermore, inspired by the idea of LARS, the computing of output weights in our algorithm is greatly simplified. Since our proposed algorithm can simultaneously conduct model structure selection and parameter optimization, a network with better generalization performance is built. Computational experiments with artificial and real world data confirm the efficacy of the proposed algorithm.", "paper_title": "Kernelized LARS-LASSO for constructing radial basis function neural networks", "paper_id": "WOS:000326889800016"}