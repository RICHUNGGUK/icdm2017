{"auto_keywords": [{"score": 0.037059837378086914, "phrase": "gpu"}, {"score": 0.006433369381671689, "phrase": "cpu_cores"}, {"score": 0.00481495049065317, "phrase": "synergistic_execution_of_stream_programs"}, {"score": 0.004715465748738294, "phrase": "streamit_programming_model"}, {"score": 0.004563250218021092, "phrase": "general_purpose_multicore_architectures"}, {"score": 0.0045225925147033205, "phrase": "streamit_graphs"}, {"score": 0.004311765153841034, "phrase": "graphics_processing_units"}, {"score": 0.004247910547470913, "phrase": "cellbe"}, {"score": 0.004210050422187886, "phrase": "abundant_parallelism"}, {"score": 0.0040740829470571425, "phrase": "novel_method"}, {"score": 0.003989844368560806, "phrase": "streamit_program"}, {"score": 0.0039542753090237755, "phrase": "multicore_platform"}, {"score": 0.0038725043244407353, "phrase": "proposed_approach"}, {"score": 0.003792417854654894, "phrase": "relative_benefits"}, {"score": 0.0037139814615660943, "phrase": "superscalar_cpu_cores"}, {"score": 0.003436537775827008, "phrase": "data_transfers"}, {"score": 0.0034058845212645915, "phrase": "required_buffer_layout_transformations"}, {"score": 0.0033254681817919403, "phrase": "integrated_integer_linear_program"}, {"score": 0.0033056700315316056, "phrase": "ilp"}, {"score": 0.0032179767877362512, "phrase": "ilp_solver"}, {"score": 0.003160812175253167, "phrase": "efficient_heuristic_algorithm"}, {"score": 0.002968591879288644, "phrase": "optimal_solution"}, {"score": 0.002915844417747579, "phrase": "benchmark_suite"}, {"score": 0.00288982217955743, "phrase": "partitioned_tasks"}, {"score": 0.0028131366865158302, "phrase": "multiple_cpu_cores"}, {"score": 0.0027303200550412962, "phrase": "gpu."}, {"score": 0.0027140368858793174, "phrase": "software_pipelining_algorithm"}, {"score": 0.002518621016346282, "phrase": "required_data_transfers"}, {"score": 0.0024298722543554443, "phrase": "gts"}, {"score": 0.0023938189911418373, "phrase": "geometric_mean_speedup"}, {"score": 0.002323308052177842, "phrase": "single_threaded_cpu_execution"}, {"score": 0.002302561649365666, "phrase": "streamit_benchmarks"}, {"score": 0.002248137100864451, "phrase": "partitioning_strategy"}, {"score": 0.0021753930127723386, "phrase": "gpu_-_the_filters"}, {"score": 0.002105001693755694, "phrase": "cpu."}], "paper_keywords": ["Algorithms", " Experimentation", " Languages", " Performance", " CUDA", " GPU Programming", " Software Pipelining", " Stream Programming", " Partitioning"], "paper_abstract": "The StreamIt programming model has been proposed to exploit parallelism in streaming applications on general purpose multicore architectures. The StreamIt graphs describe task, data and pipeline parallelism which can be exploited on accelerators such as Graphics Processing Units (GPUs) or CellBE which support abundant parallelism in hardware. In this paper, we describe a novel method to orchestrate the execution of a StreamIt program on a multicore platform equipped with an accelerator. The proposed approach identifies, using profiling, the relative benefits of executing a task on the superscalar CPU cores and the accelerator. We formulate the problem of partitioning the work between the CPU cores and the GPU, taking into account the latencies for data transfers and the required buffer layout transformations associated with the partitioning, as an integrated Integer Linear Program (ILP) which can then be solved by an ILP solver. We also propose an efficient heuristic algorithm for the work partitioning between the CPU and the GPU, which provides solutions which are within 9.05% of the optimal solution on an average across the benchmark suite. The partitioned tasks are then software pipelined to execute on the multiple CPU cores and the Streaming Multiprocessors (SMs) of the GPU. The software pipelining algorithm orchestrates the execution between CPU cores and the GPU by emitting the code for the CPU and the GPU, and the code for the required data transfers. Our experiments on a platform with 8 CPU cores and a GeForce 8800 GTS 512 GPU show a geometric mean speedup of 6.84X with a maximum of 51.96X over a single threaded CPU execution across the StreamIt benchmarks. This is a 18.9% improvement over a partitioning strategy that maps only the filters that cannot be executed on the GPU - the filters with state that is persistent across firings - onto the CPU.", "paper_title": "Synergistic Execution of Stream Programs on Multicores with Accelerators", "paper_id": "WOS:000268471100012"}