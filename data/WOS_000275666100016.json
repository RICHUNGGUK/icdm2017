{"auto_keywords": [{"score": 0.03899661662596745, "phrase": "iaps"}, {"score": 0.00481495049065317, "phrase": "emotional_biosignals"}, {"score": 0.004737201825299411, "phrase": "affective_pictures"}, {"score": 0.004529776351030488, "phrase": "healthcare_applications"}, {"score": 0.004493045859210086, "phrase": "recent_neuroscience_findings"}, {"score": 0.0044385053213394175, "phrase": "fundamental_role"}, {"score": 0.004313793774439379, "phrase": "physical_and_mental_health"}, {"score": 0.004244102948402086, "phrase": "present_study"}, {"score": 0.004192571571622019, "phrase": "novel_architecture"}, {"score": 0.004108066884382925, "phrase": "robust_discrimination"}, {"score": 0.00407474190126995, "phrase": "emotional_physiological_signals"}, {"score": 0.003848886045448135, "phrase": "multichannel_recordings"}, {"score": 0.003740679163860117, "phrase": "bidirectional_emotion_theory_model"}, {"score": 0.0032567057896906314, "phrase": "data_mining_approach"}, {"score": 0.003088617973198433, "phrase": "gender_information"}, {"score": 0.0030017207229983385, "phrase": "distance_classifier"}, {"score": 0.0029172611440429963, "phrase": "high_and_low_arousing"}, {"score": 0.0028467558213723697, "phrase": "extensible_markup_language"}, {"score": 0.0024781515864648242, "phrase": "valence_dimension"}, {"score": 0.002379092507901856, "phrase": "proposed_approach"}, {"score": 0.0023310544011985253, "phrase": "efficient_discrimination"}, {"score": 0.0023121112251855667, "phrase": "negative_and_positive_emotions"}, {"score": 0.0022378620428620782, "phrase": "future_developments"}, {"score": 0.0021748483128942687, "phrase": "affective_healthcare_applications"}, {"score": 0.0021049977753042253, "phrase": "elderly_or_chronically_ill_people"}], "paper_keywords": ["Affective computing", " data mining", " decision tree", " EEG", " emotion theory", " evoked potential response", " healthcare remote monitoring", " International Affective Picture System (IAPS)", " Mahalanobis distance"], "paper_abstract": "Recent neuroscience findings demonstrate the fundamental role of emotion in the maintenance of physical and mental health. In the present study, a novel architecture is proposed for the robust discrimination of emotional physiological signals evoked upon viewing pictures selected from the International Affective Picture System (IAPS). Biosignals are multichannel recordings from both the central and the autonomic nervous systems. Following the bidirectional emotion theory model, IAPS pictures are rated along two dimensions, namely, their valence and arousal. Following this model, biosignals in this paper are initially differentiated according to their valence dimension by means of a data mining approach, which is the C4.5 decision tree algorithm. Then, the valence and the gender information serve as an input to aMahalanobis distance classifier, which dissects the data into high and low arousing. Results are described in Extensible Markup Language (XML) format, thereby accounting for platform independency, easy interconnectivity, and information exchange. The average recognition (success) rate was 77.68% for the discrimination of four emotional states, differing both in their arousal and valence dimension. It is, therefore, envisaged that the proposed approach holds promise for the efficient discrimination of negative and positive emotions, and it is hereby discussed how future developments may be steered to serve for affective healthcare applications, such as the monitoring of the elderly or chronically ill people.", "paper_title": "On the Classification of Emotional Biosignals Evoked While Viewing Affective Pictures: An Integrated Data-Mining-Based Approach for Healthcare Applications", "paper_id": "WOS:000275666100016"}