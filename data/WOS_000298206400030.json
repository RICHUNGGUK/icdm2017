{"auto_keywords": [{"score": 0.03739663127905036, "phrase": "objective_function"}, {"score": 0.00481495049065317, "phrase": "discriminative_visual_dictionary_learning_method"}, {"score": 0.004713379149462482, "phrase": "classification_performance"}, {"score": 0.004601548128751513, "phrase": "k"}, {"score": 0.004421284843189731, "phrase": "popular_algorithms"}, {"score": 0.004374385639298755, "phrase": "visual_dictionary_learning"}, {"score": 0.004191690483929023, "phrase": "normalized_visual_word_frequency"}, {"score": 0.0041251561573501455, "phrase": "distinctive_classes"}, {"score": 0.004081385289516914, "phrase": "large_label_distances"}, {"score": 0.003869373085652601, "phrase": "sample_label_information"}, {"score": 0.0038079353103469865, "phrase": "visual_dictionary"}, {"score": 0.0037474693720823643, "phrase": "supervised_manner"}, {"score": 0.0034777028461723198, "phrase": "sample_element"}, {"score": 0.0034042817048307336, "phrase": "sift"}, {"score": 0.0031255543155487234, "phrase": "normalized_aggregative_visual_word"}, {"score": 0.0029630461161780203, "phrase": "kindred_samples"}, {"score": 0.0028391271282216758, "phrase": "inhomogeneous_samples"}, {"score": 0.0027058852678238632, "phrase": "hard_binary_constraints"}, {"score": 0.0026771333996253783, "phrase": "soft_nonnegative_ones"}, {"score": 0.0026345758986796703, "phrase": "multiplicative_nonnegative_update_procedure"}, {"score": 0.0025109095718850376, "phrase": "theoretic_convergence_proof"}, {"score": 0.0024842242921857705, "phrase": "extensive_experiments"}, {"score": 0.0024578219177450876, "phrase": "classification_tasks"}, {"score": 0.0022444104439449737, "phrase": "proposed_framework"}, {"score": 0.002220551141101661, "phrase": "conventional_clustering"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Visual dictionary", " Bag-of-words", " K-means", " Supervised learning"], "paper_abstract": "In this paper, we investigate a discriminative visual dictionary learning method for boosting the classification performance. Tied to the K-means clustering philosophy, those popular algorithms for visual dictionary learning cannot guarantee the well-separation of the normalized visual word frequency vectors from distinctive classes or large label distances. The rationale of this work is to harness sample label information for learning visual dictionary in a supervised manner, and this target is then formulated as an objective function, where each sample element, e.g., SIFT descriptor, is expected to be close to its assigned visual word, and at the same time the normalized aggregative visual word frequency vectors are expected to possess the property that kindred samples shall be close to each other while inhomogeneous samples shall be far away. By relaxing the hard binary constraints to soft nonnegative ones, a multiplicative nonnegative update procedure is proposed to optimize the objective function along with theoretic convergence proof. Extensive experiments on classification tasks (i.e., natural scene and sports event classifications) all demonstrate the superiority of this proposed framework over conventional clustering based visual dictionary learning. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "A unified supervised codebook learning framework for classification", "paper_id": "WOS:000298206400030"}