{"auto_keywords": [{"score": 0.04966229511350132, "phrase": "wireless_multimedia_sensor_networks"}, {"score": 0.04454153022265074, "phrase": "object_localization"}, {"score": 0.038764567724346874, "phrase": "detected_object"}, {"score": 0.027244860483140693, "phrase": "camera_sensors"}, {"score": 0.00481495049065317, "phrase": "multiple_objects"}, {"score": 0.004588891098290524, "phrase": "large_number"}, {"score": 0.004548939310612501, "phrase": "resource_constrained_camera_sensors"}, {"score": 0.0044896599221451216, "phrase": "remote_surveillance_applications"}, {"score": 0.004354315061804687, "phrase": "lightweight_solutions"}, {"score": 0.004316396683332752, "phrase": "traditional_problems"}, {"score": 0.004223032986655664, "phrase": "real-time_tracking"}, {"score": 0.00406001734835979, "phrase": "energy-efficient_object_localization"}, {"score": 0.004024651422626329, "phrase": "multiple_object_tracking_scheme"}, {"score": 0.003989596478992267, "phrase": "wmsns"}, {"score": 0.0038692638652494697, "phrase": "individual_camera_sensors"}, {"score": 0.0036393456309815166, "phrase": "video_frame"}, {"score": 0.0035605741849764187, "phrase": "frame_differencing"}, {"score": 0.003334309053314909, "phrase": "camera_sensor's_location"}, {"score": 0.0030148941188459987, "phrase": "fuzzy_object_classification"}, {"score": 0.0029755458462182565, "phrase": "camera_sensor"}, {"score": 0.0029238768315330305, "phrase": "limited_information"}, {"score": 0.0027620516806198354, "phrase": "sink_node"}, {"score": 0.00270221723573854, "phrase": "real-time_object_tracking"}, {"score": 0.0025977542995083624, "phrase": "raw_video_data"}, {"score": 0.0024864020775253767, "phrase": "specific_object"}, {"score": 0.0023902621773166963, "phrase": "different_times"}, {"score": 0.0022480304016499605, "phrase": "proposed_approach"}, {"score": 0.0021896891011033105, "phrase": "higher_localization"}, {"score": 0.0021705796895687864, "phrase": "identification_accuracies"}, {"score": 0.0021049977753042253, "phrase": "low_camera_coverage"}], "paper_keywords": [""], "paper_abstract": "Wireless Multimedia Sensor Networks (WMSNs) are characterized by large number of resource constrained camera sensors. In remote surveillance applications, such resource constraints necessitate the design of lightweight solutions for traditional problems such as object localization and real-time tracking. In this paper, we propose an energy-efficient object localization and multiple object tracking scheme for WMSNs. The object localization is performed by individual camera sensors. For that purpose, the approach first extracts the detected object from the video frame and finds its boundary using frame differencing. The location of the object is then estimated with the help of the camera sensor's location, distance of the object to the camera and camera/frame size properties. After localizing a detected object, its boundary information is used to perform a fuzzy object classification at the camera sensor. Finally, limited information containing the location and classification of the object are transmitted to the sink node to be used in real-time object tracking. In this way, without receiving the raw video data from the camera sensors, the sink can identify a specific object even though its information may come from several camera sensors at different times, and determine its path for the purpose of tracking. Via extensive simulations, the proposed approach has been shown to provide higher localization and identification accuracies with little cost on camera sensors even under low camera coverage.", "paper_title": "Efficient Tracking of Multiple Objects in Wireless Multimedia Sensor Networks", "paper_id": "WOS:000321021300004"}