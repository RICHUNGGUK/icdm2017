{"auto_keywords": [{"score": 0.031491438136414286, "phrase": "execution_time"}, {"score": 0.014370404299070817, "phrase": "code_size"}, {"score": 0.01428666079501351, "phrase": "compilation_time"}, {"score": 0.007749918868191222, "phrase": "program_features"}, {"score": 0.007503118943125207, "phrase": "milepost_gcc"}, {"score": 0.004814958118695131, "phrase": "gcc"}, {"score": 0.004786620949516712, "phrase": "machine_learning_enabled_self-tuning"}, {"score": 0.004772556958364792, "phrase": "compiler"}, {"score": 0.004730458558634266, "phrase": "compiler_optimizations"}, {"score": 0.004592905436175987, "phrase": "optimizing_compiler"}, {"score": 0.004552421225766146, "phrase": "new_platform"}, {"score": 0.004498994325265174, "phrase": "iterative_optimization"}, {"score": 0.004459334186889869, "phrase": "popular_approach"}, {"score": 0.00438105507792004, "phrase": "new_architecture"}, {"score": 0.004342430078306461, "phrase": "feedback-directed_compilation"}, {"score": 0.004278807087784626, "phrase": "large_number"}, {"score": 0.0041666157975446564, "phrase": "iterative_compilation"}, {"score": 0.004081385289516914, "phrase": "production_compilers"}, {"score": 0.00405735420159564, "phrase": "machine_learning"}, {"score": 0.00384731849108269, "phrase": "long_training_phases"}, {"score": 0.0036697319652557363, "phrase": "self-tuning_optimization_infrastructure"}, {"score": 0.0036159291978698016, "phrase": "best_optimizations"}, {"score": 0.0035946288112367578, "phrase": "multiple_programs"}, {"score": 0.003489987735217367, "phrase": "run-time_behavior"}, {"score": 0.0032033846797483475, "phrase": "interactive_compilation"}, {"score": 0.0031751172182793953, "phrase": "ici"}, {"score": 0.0031009188628557957, "phrase": "exchange_optimization_data"}, {"score": 0.0030735451757603555, "phrase": "ctuning.org_open_public_repository"}, {"score": 0.0030195184114140063, "phrase": "internal_optimization_heuristic"}, {"score": 0.0030017207229983385, "phrase": "function-level_granularity"}, {"score": 0.002914288956035066, "phrase": "new_program"}, {"score": 0.002846175473457555, "phrase": "milepost_technology"}, {"score": 0.002821044196775531, "phrase": "low-level_ici-inspired_plugin_framework"}, {"score": 0.0026827569390113822, "phrase": "transductive_approaches"}, {"score": 0.002659064774118166, "phrase": "good_combinations"}, {"score": 0.0025361866386341796, "phrase": "individual_mibench_programs"}, {"score": 0.0023277282036119106, "phrase": "mibench_benchmark_suite"}, {"score": 0.0022935555629405003, "phrase": "arc_reconfigurable_processor"}, {"score": 0.002253208464566164, "phrase": "realistic_multi-objective_optimization_scenario"}, {"score": 0.0022399174232611853, "phrase": "berkeley_db"}, {"score": 0.0021049977753042253, "phrase": "intel_xeon_processor"}], "paper_keywords": ["Machine learning compiler", " Self-tuning compiler", " Adaptive compiler", " Automatic performance tuning", " Machine learning", " Program characterization", " Program features", " Collective optimization", " Continuous optimization", " Multi-objective optimization", " Empirical performance tuning", " Optimization repository", " Iterative compilation", " Feedback-directed compilation", " Adaptive compilation", " Optimization prediction", " Portable optimization"], "paper_abstract": "Tuning compiler optimizations for rapidly evolving hardware makes porting and extending an optimizing compiler for each new platform extremely challenging. Iterative optimization is a popular approach to adapting programs to a new architecture automatically using feedback-directed compilation. However, the large number of evaluations required for each program has prevented iterative compilation from widespread take-up in production compilers. Machine learning has been proposed to tune optimizations across programs systematically but is currently limited to a few transformations, long training phases and critically lacks publicly released, stable tools. Our approach is to develop a modular, extensible, self-tuning optimization infrastructure to automatically learn the best optimizations across multiple programs and architectures based on the correlation between program features, run-time behavior and optimizations. In this paper we describe Milepost GCC, the first publicly-available open-source machine learning-based compiler. It consists of an Interactive Compilation Interface (ICI) and plugins to extract program features and exchange optimization data with the cTuning.org open public repository. It automatically adapts the internal optimization heuristic at function-level granularity to improve execution time, code size and compilation time of a new program on a given architecture. Part of the MILEPOST technology together with low-level ICI-inspired plugin framework is now included in the mainline GCC. We developed machine learning plugins based on probabilistic and transductive approaches to predict good combinations of optimizations. Our preliminary experimental results show that it is possible to automatically reduce the execution time of individual MiBench programs, some by more than a factor of 2, while also improving compilation time and code size. On average we are able to reduce the execution time of the MiBench benchmark suite by 11% for the ARC reconfigurable processor. We also present a realistic multi-objective optimization scenario for Berkeley DB library using Milepost GCC and improve execution time by approximately 17%, while reducing compilation time and code size by 12% and 7% respectively on Intel Xeon processor.", "paper_title": "Milepost GCC: Machine Learning Enabled Self-tuning Compiler", "paper_id": "WOS:000289615900002"}