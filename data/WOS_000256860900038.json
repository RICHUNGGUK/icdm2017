{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "spoken_language_understanding"}, {"score": 0.0040978781692373005, "phrase": "user's_speech"}, {"score": 0.003975781274672803, "phrase": "semantic_frame"}, {"score": 0.0037423521744765075, "phrase": "previous_works"}, {"score": 0.00363080961099728, "phrase": "semantic_structures"}, {"score": 0.0035582949787475045, "phrase": "slu"}, {"score": 0.0031845067058084583, "phrase": "noisy_input"}, {"score": 0.0030278017562213265, "phrase": "structured_prediction_method"}, {"score": 0.0029672941061574375, "phrase": "slu_problem"}, {"score": 0.0027929100418926725, "phrase": "unstructured_one"}, {"score": 0.0025761937402886954, "phrase": "combined_method"}, {"score": 0.0024993218789131437, "phrase": "long-distance_dependency"}, {"score": 0.0023762535034673017, "phrase": "cascaded_manner"}, {"score": 0.0023053339328456234, "phrase": "air_travel_data"}, {"score": 0.0021049977753042253, "phrase": "baseline_models"}], "paper_keywords": ["spoken language understanding", " named entity recognition from speech", " structured prediction", " long-distance dependency", " two-step cascaded approach"], "paper_abstract": "Spoken language understanding (SLU) aims to map a user's speech into a semantic frame. Since most of the previous works use the semantic structures for SLU, we verify that the structure is useful even for noisy input. We apply a structured prediction method to SLU problem and compare it to an unstructured one. In addition, we present a combined method to embed long-distance dependency between entities in a cascaded manner. On air travel data, we show that our approach improves performance over baseline models.", "paper_title": "On the use of structures for spoken language understanding: A two-step approach", "paper_id": "WOS:000256860900038"}