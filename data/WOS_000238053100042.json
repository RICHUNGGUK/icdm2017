{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "fujisaki's_intonation_model_parameters"}, {"score": 0.003916098498242888, "phrase": "fujisaki's_parameterization"}, {"score": 0.003822003373331997, "phrase": "pitch_contour"}, {"score": 0.0035965032173588753, "phrase": "emotion_recognition"}, {"score": 0.0033029038236817372, "phrase": "proposed_features"}, {"score": 0.003107935254560724, "phrase": "decision_tree_inducer"}, {"score": 0.0028890603352364273, "phrase": "based_learning_algorithm"}, {"score": 0.0026209522797963447, "phrase": "classification_models"}, {"score": 0.002406799309495983, "phrase": "fujisaki's_parameters"}, {"score": 0.002320449502337321, "phrase": "prediction_models"}, {"score": 0.0022371907579775796, "phrase": "average_raise"}, {"score": 0.0021049977753042253, "phrase": "total_accuracy"}], "paper_keywords": [""], "paper_abstract": "In this paper we are introducing the employment of features extracted from Fujisaki's parameterization of pitch contour for the task of emotion recognition from speech. In evaluating the proposed features we have trained a decision tree inducer as well as the instance based learning algorithm. The datasets utilized for training the classification models, were extracted from two emotional speech databases. Fujisaki's parameters benefited all prediction models with an average raise of 9,52% in the total accuracy.", "paper_title": "Employing Fujisaki's intonation model parameters for emotion recognition", "paper_id": "WOS:000238053100042"}