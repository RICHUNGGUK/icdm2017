{"auto_keywords": [{"score": 0.0496578611773389, "phrase": "drift_correction"}, {"score": 0.015719716506582538, "phrase": "active_feature_selection"}, {"score": 0.004586531354697466, "phrase": "discriminative_multi-task_objects"}, {"score": 0.004407690586271672, "phrase": "developed_method"}, {"score": 0.004292337783332826, "phrase": "particle_filter_framework"}, {"score": 0.004254558771304349, "phrase": "multi-task_discriminative_tracking"}, {"score": 0.004161553532799662, "phrase": "generative_methods"}, {"score": 0.0040347380310668994, "phrase": "proposed_method"}, {"score": 0.003877329308854808, "phrase": "corresponding_coefficients"}, {"score": 0.0037925389501636975, "phrase": "tracking_algorithm"}, {"score": 0.0037260386566859197, "phrase": "active_feature_selection_scheme"}, {"score": 0.0036445446531633368, "phrase": "suitable_number"}, {"score": 0.0036124465071873998, "phrase": "discriminative_features"}, {"score": 0.0035648266669315943, "phrase": "tracked_target"}, {"score": 0.0034868462688262864, "phrase": "dynamic_environment"}, {"score": 0.003410565849262162, "phrase": "selected_feature_space"}, {"score": 0.003365598242636633, "phrase": "discriminative_dictionary"}, {"score": 0.00289546142998427, "phrase": "discriminative_multi-task_learning"}, {"score": 0.002807118943000936, "phrase": "highest_similarity"}, {"score": 0.002697474061842142, "phrase": "next_tracked_target_state"}, {"score": 0.002661883310629088, "phrase": "jointly_sparsity_and_discriminative_learning"}, {"score": 0.0025578967205807843, "phrase": "tracking_performance"}, {"score": 0.0025018875576502606, "phrase": "visual_drift_problem"}, {"score": 0.0024688710065898646, "phrase": "object_tracking"}, {"score": 0.002436289099444074, "phrase": "two-stage_particle_filtering_algorithm"}, {"score": 0.0022396694076443446, "phrase": "current_frame"}, {"score": 0.002219916677664081, "phrase": "experimental_evaluations"}, {"score": 0.002200337772403983, "phrase": "challenging_sequences"}, {"score": 0.0021049977753042253, "phrase": "proposed_tracker"}], "paper_keywords": ["Discriminative multi-task objects tracking", " Active feature selection", " Drift correction", " Jointly sparsity"], "paper_abstract": "In this paper, we propose a discriminative multi-task objects tracking method with active feature selection and drift correction. The developed method formulates object tracking in a particle filter framework as multi-Task discriminative tracking. As opposed to generative methods that handle particles separately, the proposed method learns the representation of all the particles jointly and the corresponding coefficients are similar. The tracking algorithm starts from the active feature selection scheme, which adaptively chooses suitable number of discriminative features from the tracked target and background in the dynamic environment. Based on the selected feature space, the discriminative dictionary is constructed and updated dynamically. Only a few of them are used to represent all the particles at each frame. In other words, all the particles share the same dictionary templates and their representations are obtained jointly by discriminative multi-task learning. The particle that has the highest similarity with the dictionary templates is selected as the next tracked target state. This jointly sparsity and discriminative learning can exploit the relationship between particles and improve tracking performance. To alleviate the visual drift problem encountered in object tracking, a two-stage particle filtering algorithm is proposed to complete drift correction and exploit both the ground truth information of the first frame and observations obtained online from the current frame. Experimental evaluations on challenging sequences demonstrate the effectiveness, accuracy and robustness of the proposed tracker in comparison with state-of-the-art algorithms. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Discriminative multi-task objects tracking with active feature selection and drift correction", "paper_id": "WOS:000342870900008"}