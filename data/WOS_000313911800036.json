{"auto_keywords": [{"score": 0.03932122714942605, "phrase": "multiple_gpus"}, {"score": 0.00481495049065317, "phrase": "stencil_computation"}, {"score": 0.004718897469501381, "phrase": "multi-gpu_systems"}, {"score": 0.0044870272550540415, "phrase": "powerful_and_energy-efficient_solution"}, {"score": 0.004223708778943785, "phrase": "higher_performance"}, {"score": 0.004139401327448807, "phrase": "larger_problems"}, {"score": 0.003594369823549604, "phrase": "already_high_programming_complexity"}, {"score": 0.003152531962718477, "phrase": "multi-gpu_programming"}, {"score": 0.002878785759716458, "phrase": "best_strategy"}, {"score": 0.002709589081384597, "phrase": "stencil_operator"}, {"score": 0.0026554236621262515, "phrase": "problem_size"}, {"score": 0.002576390050186916, "phrase": "gpu"}, {"score": 0.002424745104046415, "phrase": "pci"}, {"score": 0.002282166507956957, "phrase": "nonuniform_characteristics"}, {"score": 0.002214048743052355, "phrase": "seemingly_homogeneous_setup"}], "paper_keywords": ["Experimentation", " Performance", " GPGPU", " multi GPU", " optimization", " stencil computation"], "paper_abstract": "GPGPUs are a powerful and energy-efficient solution for many problems. For higher performance or larger problems, it is necessary to distribute the problem across multiple GPUs, increasing the already high programming complexity. In this article, we focus on abstracting the complexity of multi-GPU programming for stencil computation. We show that the best strategy depends not only on the stencil operator, problem size, and GPU, but also on the PCI express layout. This adds nonuniform characteristics to a seemingly homogeneous setup, causing up to 23% performance loss. We address this issue with an autotuner that optimizes the distribution across multiple GPUs.", "paper_title": "PARTANS: An Autotuning Framework for Stencil Computation on Multi-GPU Systems", "paper_id": "WOS:000313911800036"}