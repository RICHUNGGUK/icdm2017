{"auto_keywords": [{"score": 0.043088061205824785, "phrase": "conventional_mil_model"}, {"score": 0.00481495049065317, "phrase": "kernels_for_generalized_multiple-instance_learning"}, {"score": 0.004748740786945996, "phrase": "multiple-instance_learning"}, {"score": 0.004705134519368131, "phrase": "mil"}, {"score": 0.004555499634179394, "phrase": "numerous_application_areas"}, {"score": 0.004172874316207784, "phrase": "significant_advantages"}, {"score": 0.0038935506745975835, "phrase": "high_dimensions"}, {"score": 0.0037006243674469657, "phrase": "support_vector_machine"}, {"score": 0.0035498822293046884, "phrase": "time_complexity"}, {"score": 0.0032215231177304513, "phrase": "discrete_bounded_space"}, {"score": 0.0029234476524900794, "phrase": "fully_polynomial_randomized_approximation_scheme"}, {"score": 0.0028965528631286932, "phrase": "fpras"}, {"score": 0.0026284507395498897, "phrase": "normalized_version"}, {"score": 0.0023851187337905412, "phrase": "positive_semidefinite_gram_matrices"}, {"score": 0.0022355167967736326, "phrase": "content-based_image_retrieval"}, {"score": 0.002154272413276506, "phrase": "musk_data_sets"}], "paper_keywords": ["Kernels", " support vector machines", " generalized multiple-instance learning", " content-based image retrieval", " biological sequence analysis", " fully polynomial randomized approximation schemes"], "paper_abstract": "The multiple-instance learning (MIL) model has been successful in numerous application areas. Recently, a generalization of this model and an algorithm for it have been introduced, showing significant advantages over the conventional MIL model on certain application areas. Unfortunately, that algorithm is not scalable to high dimensions. We adapt that algorithm to one that uses a support vector machine with our new kernel k(A). This reduces the time complexity from exponential in the dimension to polynomial. Computing our new kernel is equivalent to counting the number of boxes in a discrete bounded space that contain at least one point from each of two multisets. We first show that this problem is #P-complete and then present a fully polynomial randomized approximation scheme (FPRAS) for it. We then extend k(A) by enriching its representation into a new kernel k(min) and also consider a normalized version of k(A) that we call k(A/V) (which may or may not be a kernel but whose approximation yielded positive semidefinite Gram matrices in practice). We then empirically evaluate all three measures on data from content-based image retrieval, biological sequence analysis, and the Musk data sets. We found that our kernels performed well on all data sets relative to algorithms in the conventional MIL model.", "paper_title": "Kernels for Generalized Multiple-Instance Learning", "paper_id": "WOS:000260033900002"}