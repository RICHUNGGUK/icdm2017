{"auto_keywords": [{"score": 0.050078245640192025, "phrase": "music_similarity"}, {"score": 0.042495190264088885, "phrase": "relative_ratings"}, {"score": 0.03496926672800003, "phrase": "rdnn"}, {"score": 0.029166348627855717, "phrase": "feature_sets"}, {"score": 0.02873633795308799, "phrase": "mlr"}, {"score": 0.0047784273577245505, "phrase": "relative_user_ratings"}, {"score": 0.004742179945772899, "phrase": "computational_modelling"}, {"score": 0.004652754203582873, "phrase": "increasingly_important_part"}, {"score": 0.004547656324173302, "phrase": "music_information_retrieval"}, {"score": 0.004478907336898875, "phrase": "music_perception"}, {"score": 0.004361077072629878, "phrase": "relative_similarity_ratings"}, {"score": 0.004311527998148399, "phrase": "new_and_promising_approach"}, {"score": 0.00421410521089045, "phrase": "well_known_problems"}, {"score": 0.0041821205529541045, "phrase": "absolute_ratings"}, {"score": 0.004010477922833839, "phrase": "magnatagatune_dataset"}, {"score": 0.003980032599437366, "phrase": "new_and_existing_variants"}, {"score": 0.003802135020791801, "phrase": "first_comprehensive_and_rigorous_evaluation"}, {"score": 0.00364603066037512, "phrase": "support_vector_machines"}, {"score": 0.0034303002275695446, "phrase": "diagonal_and_a_novel_weighted_variant"}, {"score": 0.0033399639721674954, "phrase": "neural_networks"}, {"score": 0.0032027739752274, "phrase": "different_high_and_low_level_audio_features"}, {"score": 0.003106541164572609, "phrase": "dimensionality_reduction_methods"}, {"score": 0.0030595112110658675, "phrase": "similarity_ratings"}, {"score": 0.003024705160129876, "phrase": "different_sampling_methods"}, {"score": 0.0029675701595142656, "phrase": "music_similarity_measures"}, {"score": 0.0028565082986974602, "phrase": "standard_euclidian_metric"}, {"score": 0.0027286918886186245, "phrase": "application_scenario"}, {"score": 0.002687535149311768, "phrase": "svm"}, {"score": 0.00266693888510356, "phrase": "dmlr"}, {"score": 0.002596653214530156, "phrase": "weighted_ratings"}, {"score": 0.002537880772794665, "phrase": "timbral_and_music-structural_features"}, {"score": 0.002360381056508366, "phrase": "audio_clips"}, {"score": 0.0022981559278396845, "phrase": "training_sets"}, {"score": 0.002229043128610864, "phrase": "svm-based_methods"}, {"score": 0.0021702728407945976, "phrase": "applications_scenarios"}, {"score": 0.0021455612994325424, "phrase": "testing_framework"}, {"score": 0.0021051052905516586, "phrase": "matlab"}], "paper_keywords": ["Music similarity", " Relative similarity ratings", " Metric learning", " Support vector machines", " Metric learning to rank", " Neural networks"], "paper_abstract": "Computational modelling of music similarity is an increasingly important part of personalisation and optimisation in music information retrieval and research in music perception and cognition. The use of relative similarity ratings is a new and promising approach to modelling similarity that avoids well known problems with absolute ratings. In this article, we use relative ratings from the MagnaTagATune dataset with new and existing variants of state-of-the-art algorithms and provide the first comprehensive and rigorous evaluation of this approach. We compare metric learning based on support vector machines (SVMs) and metric-learning-to-rank (MLR), including a diagonal and a novel weighted variant, and relative distance learning with neural networks (RDNN). We further evaluate the effectiveness of different high and low level audio features and genre data, as well as dimensionality reduction methods, weighting of similarity ratings, and different sampling methods. Our results show that music similarity measures learnt on relative ratings can be significantly better than a standard Euclidian metric, depending on the choice of learning algorithm, feature sets and application scenario. MLR and SVM outperform DMLR and RDNN, while MLR with weighted ratings leads to no further performance gain. Timbral and music-structural features are most effective, and all features jointly are significantly better than any other combination of feature sets. Sharing audio clips (but not the similarity ratings) between test and training sets improves performance, in particular for the SVM-based methods, which is useful for some applications scenarios. A testing framework has been implemented in Matlab and made publicly available http://mi.soi.city.ac.uk/datasets/ir2012framework so that these results are reproducible.", "paper_title": "Learning music similarity from relative user ratings", "paper_id": "WOS:000332963700001"}