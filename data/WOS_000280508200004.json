{"auto_keywords": [{"score": 0.037922755717671494, "phrase": "batched_evaluation"}, {"score": 0.007256853225524547, "phrase": "local_evaluation"}, {"score": 0.00481495049065317, "phrase": "demand_tabling"}, {"score": 0.004617187934074393, "phrase": "suspension-based_tabled_evaluation"}, {"score": 0.00444612502361583, "phrase": "local_and_batched_evaluation"}, {"score": 0.004299374036140852, "phrase": "tabled_predicate"}, {"score": 0.004122699822340296, "phrase": "tabled_computation"}, {"score": 0.0035444736871640147, "phrase": "sld_evaluation"}, {"score": 0.0033141428467975795, "phrase": "arbitrarily_more_memory"}, {"score": 0.0030216031606457214, "phrase": "local_strategy"}, {"score": 0.00284899583294417, "phrase": "general_adoption"}, {"score": 0.002630364569659529, "phrase": "high_memory_consumption"}, {"score": 0.002564862727498502, "phrase": "new_scheduling_strategy"}, {"score": 0.0024800509241747013, "phrase": "swapping_evaluation"}, {"score": 0.0023779596230982234, "phrase": "tabled_call"}, {"score": 0.0022420373745572837, "phrase": "experimental_implementation"}, {"score": 0.0022139352210982398, "phrase": "xsb_system"}, {"score": 0.002149722786728988, "phrase": "feasible_memory-scalable_strategy"}, {"score": 0.0021049977753042253, "phrase": "execution_speed"}], "paper_keywords": ["Logic programming", " tabling", " implementation", " on-demand answers", " performance"], "paper_abstract": "One of the differences among the various approaches to suspension-based tabled evaluation is the scheduling strategy. The two most popular strategies are local and batched evaluation. The former collects all the solutions to a tabled predicate before making any one of them available outside the tabled computation. The latter returns answers one by one before computing them all, which in principle is better if only one answer (or a subset of the answers) is desired. Batched evaluation is closer to SLD evaluation in that it computes solutions lazily as they are demanded, but it may need arbitrarily more memory than local evaluation, which is able to reclaim memory sooner. Some programs which in practice can be executed under the local strategy quickly run out of memory under batched evaluation. This has led to the general adoption of local evaluation at the expense of the more depth-first batched strategy. In this paper we study the reasons for the high memory consumption of batched evaluation and propose a new scheduling strategy which we have termed swapping evaluation. Swapping evaluation also returns answers one by one before completing a tabled call, but its memory usage can be orders of magnitude less than batched evaluation. An experimental implementation in the XSB system shows that swapping evaluation is a feasible memory-scalable strategy that need not compromise execution speed.", "paper_title": "Swapping evaluation: A memory-scalable solution for answer-on-demand tabling", "paper_id": "WOS:000280508200004"}