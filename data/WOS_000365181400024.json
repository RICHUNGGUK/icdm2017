{"auto_keywords": [{"score": 0.03423057083405171, "phrase": "camera_movement"}, {"score": 0.00481495049065317, "phrase": "stochastic_approximation"}, {"score": 0.0040438338011467845, "phrase": "novel_approach"}, {"score": 0.003982011128052839, "phrase": "stochastic_approximation_learning"}, {"score": 0.003941319912895672, "phrase": "probabilistic_mixtures"}, {"score": 0.0035201528214608914, "phrase": "egomotion_sequences"}, {"score": 0.0034841647157189985, "phrase": "abrupt_changes"}, {"score": 0.003361069456060196, "phrase": "non_panoramic_model"}, {"score": 0.0031277316566463978, "phrase": "previous_frame"}, {"score": 0.0028807718824400697, "phrase": "foreground_objects"}, {"score": 0.0027223626424366207, "phrase": "covariance_matrices"}, {"score": 0.0026806884201358515, "phrase": "gaussian_mixture_components"}, {"score": 0.002533253511622532, "phrase": "background_extrapolation_method"}, {"score": 0.002443671484766342, "phrase": "new_mixture_models"}, {"score": 0.0024186620196958867, "phrase": "previously_unseen_regions"}, {"score": 0.0022161333611134806, "phrase": "competitive_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Background modeling", " Moving camera", " Covariance matrix interpolation", " Stochastic approximation"], "paper_abstract": "Most foreground detection algorithms do not perform well with pan-tilt-zoom (PTZ) cameras for video surveillance and static cameras that experience vibration, since they rely on the assumption that the background does not move. Here a novel approach based on stochastic approximation learning of probabilistic mixtures is proposed. It assumes that the camera can zoom and move in both horizontal and vertical planes, and it is also adequate for egomotion sequences without abrupt changes. In other words it is a non panoramic model for moving cameras, where the camera movement allows to reuse enough background information from the previous frame. Two pixel models are used, one to follow the camera movement and the other to detect foreground objects. A procedure is developed to transform and interpolate the covariance matrices of the Gaussian mixture components as the camera moves and zooms. Moreover, a background extrapolation method is presented in order to generate new mixture models for previously unseen regions. The proposal is compared with some state-of-the-art alternatives, with competitive results both quantitatively and qualitatively. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Foreground detection for moving cameras with stochastic approximation", "paper_id": "WOS:000365181400024"}