{"auto_keywords": [{"score": 0.048839643896770986, "phrase": "variation_distance"}, {"score": 0.007706973484887397, "phrase": "recent_work"}, {"score": 0.00481495049065317, "phrase": "probabilistic_deterministic_finite_state_automata"}, {"score": 0.004479855062309818, "phrase": "pac-learning_distributions"}, {"score": 0.004306968571854912, "phrase": "probabilistic_deterministic_finite_automata"}, {"score": 0.004086744751579196, "phrase": "probabilistic_model"}, {"score": 0.003607630811220324, "phrase": "handwriting_recognition"}, {"score": 0.003378385493203297, "phrase": "random_examples"}, {"score": 0.0032266093099550955, "phrase": "error_measure"}, {"score": 0.0029625516571745764, "phrase": "clark"}, {"score": 0.0029238768315330305, "phrase": "thollard"}, {"score": 0.0023079225317714815, "phrase": "polynomial_sample_size_bounds"}, {"score": 0.002218668420806254, "phrase": "expected_length"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["computational complexity", " machine learning"], "paper_abstract": "We consider the problem of PAC-learning distributions over strings, represented by probabilistic deterministic finite automata (PDFAs). PDFAs are a probabilistic model for the generation of strings of symbols, that have been used in the context of speech and handwriting recognition, and bioinformatics. Recent work on learning PDFAs from random examples has used the KL-divergence as the error measure; here we use the variation distance. We build on recent work by Clark and Thollard, and show that the use of the variation distance allows simplifications to be made to the algorithms, and also a strengthening of the results; in particular that using the variation distance, we obtain polynomial sample size bounds that are independent of the expected length of strings. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "PAC-learnability of probabilistic deterministic finite state automata in terms of variation distance", "paper_id": "WOS:000250935400003"}