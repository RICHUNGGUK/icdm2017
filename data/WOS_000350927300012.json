{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "concept-drift_problems"}, {"score": 0.004655285779819366, "phrase": "incrementally_optimized_stream_mining_model"}, {"score": 0.004551781491498328, "phrase": "potential_value"}, {"score": 0.004475659507646842, "phrase": "big_data"}, {"score": 0.004376131419366239, "phrase": "popular_research_topic"}, {"score": 0.004207230913063179, "phrase": "infinite_big_data_scenario"}, {"score": 0.00413684709497912, "phrase": "underlying_data_distribution"}, {"score": 0.004090577229368418, "phrase": "newly_arrived_data"}, {"score": 0.003845154818609644, "phrase": "real_world"}, {"score": 0.0034359094594153304, "phrase": "big_data_mining"}, {"score": 0.0033405704229694656, "phrase": "decision_tree_inductions"}, {"score": 0.003303177222901723, "phrase": "multi-tree_learning"}, {"score": 0.00319348234663792, "phrase": "alternative_trees"}, {"score": 0.003070086433952691, "phrase": "multi-tree_algorithms"}, {"score": 0.0028373742057129126, "phrase": "optimized_node-splitting_mechanism"}, {"score": 0.002727700630869639, "phrase": "test-then-training_tree-building_process"}, {"score": 0.0025494354909453847, "phrase": "new_method"}, {"score": 0.002506715532901322, "phrase": "state-of-art_singletree"}, {"score": 0.0023560952790080943, "phrase": "new_algorithm"}, {"score": 0.0023166075278110237, "phrase": "good_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Concept drift", " Data stream mining", " Very fast decision tree"], "paper_abstract": "Mining the potential value hidden behind big data has been a popular research topic around the world. For an infinite big data scenario, the underlying data distribution of newly arrived data may be appeared differently from the old one in the real world. This phenomenon is so-called the concept-drift problem that exists commonly in the scenario of big data mining. In the past decade, decision tree inductions use multi-tree learning to detect the drift using alternative trees as a solution. However, multi-tree algorithms consume more computing resources than the singletree. This paper proposes a singletree with an optimized node-splitting mechanism to detect the drift in a test-then-training tree-building process. In the experiment, we compare the performance of the new method to some state-of-art singletree and multi-tree algorithms. Result shows that the new algorithm performs with good accuracy while a more compact model size and less use of memory than the others. (C) 2014 Elsevier Inc. All rights reserved.", "paper_title": "Countering the concept-drift problems in big data by an incrementally optimized stream mining model", "paper_id": "WOS:000350927300012"}