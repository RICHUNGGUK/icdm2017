{"auto_keywords": [{"score": 0.042948433778622036, "phrase": "model_parameters"}, {"score": 0.00481495049065317, "phrase": "pseudo-marginal_bayesian_inference"}, {"score": 0.0047559432344272, "phrase": "gaussian_processes"}, {"score": 0.00466877910546307, "phrase": "main_challenges"}, {"score": 0.004527024978801684, "phrase": "gaussian_process_priors"}, {"score": 0.004471530397729526, "phrase": "probabilistic_modeling"}, {"score": 0.00430907756010007, "phrase": "exact_bayesian_inference"}, {"score": 0.004026359831748917, "phrase": "model-based_predictions"}, {"score": 0.003976978140059542, "phrase": "out-of-sample_data"}, {"score": 0.003808845109556467, "phrase": "illustrative_working_example"}, {"score": 0.0036703791815812328, "phrase": "general_and_effective_methodology"}, {"score": 0.0035808664384880213, "phrase": "pseudo-marginal_approach"}, {"score": 0.0035379168158686455, "phrase": "markov"}, {"score": 0.0034935290662899488, "phrase": "monte_carlo"}, {"score": 0.003204232566468624, "phrase": "paper_show"}, {"score": 0.003145417398038261, "phrase": "existing_sampling_methods"}, {"score": 0.0030497740719977835, "phrase": "posterior_distribution"}, {"score": 0.002938821840519756, "phrase": "covariance_function"}, {"score": 0.0027120400060701034, "phrase": "powerful_tool"}, {"score": 0.0026458370516131255, "phrase": "full_bayesian_inference"}, {"score": 0.0026133424923929227, "phrase": "gaussian_process"}, {"score": 0.0025812459787060097, "phrase": "hierarchic_statistical_models"}, {"score": 0.0024416087858984644, "phrase": "monte_carlo_based_integration"}, {"score": 0.002239225269052105, "phrase": "superior_quantification"}, {"score": 0.002157697367447098, "phrase": "extensive_comparisons"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_probabilistic_classifiers"}], "paper_keywords": ["Hierarchic Bayesian models", " Gaussian processes", " Markov chain Monte Carlo", " pseudo-marginal Monte Carlo", " Kernel methods", " approximate Bayesian inference"], "paper_abstract": "The main challenges that arise when adopting Gaussian process priors in probabilistic modeling are how to carry out exact Bayesian inference and how to account for uncertainty on model parameters when making model-based predictions on out-of-sample data. Using probit regression as an illustrative working example, this paper presents a general and effective methodology based on the pseudo-marginal approach to Markov chain Monte Carlo that efficiently addresses both of these issues. The results presented in this paper show improvements over existing sampling methods to simulate from the posterior distribution over the parameters defining the covariance function of the Gaussian Process prior. This is particularly important as it offers a powerful tool to carry out full Bayesian inference of Gaussian Process based hierarchic statistical models in general. The results also demonstrate that Monte Carlo based integration of all model parameters is actually feasible in this class of models providing a superior quantification of uncertainty in predictions. Extensive comparisons with respect to state-of-the-art probabilistic classifiers confirm this assertion.", "paper_title": "Pseudo-Marginal Bayesian Inference for Gaussian Processes", "paper_id": "WOS:000343702400008"}