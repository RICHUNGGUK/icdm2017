{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "object_recognition"}, {"score": 0.004734448316824488, "phrase": "single_or_multiple_model_views"}, {"score": 0.004635701867952543, "phrase": "novel_object_recognition_approach"}, {"score": 0.004577440795549049, "phrase": "affine_invariant_regions"}, {"score": 0.004388450908826472, "phrase": "limited_repeatability"}, {"score": 0.004333283735537634, "phrase": "region_detectors"}, {"score": 0.0041194351307673556, "phrase": "large_amounts"}, {"score": 0.004084829853870028, "phrase": "background_clutter"}, {"score": 0.003916098498242888, "phrase": "initial_set"}, {"score": 0.0037701851296383405, "phrase": "surrounding_image_areas"}, {"score": 0.0036144035798673967, "phrase": "initial_ones"}, {"score": 0.003407026489727146, "phrase": "correct_matches"}, {"score": 0.0033641551050434663, "phrase": "wrong_ones"}, {"score": 0.00305285084207725, "phrase": "multiple_model_views"}, {"score": 0.0029020077365708966, "phrase": "recognition_time"}, {"score": 0.0028174721236762317, "phrase": "efficient_algorithm"}, {"score": 0.0027469703311742647, "phrase": "region_matches"}, {"score": 0.002689564715486338, "phrase": "smooth_surfaces"}, {"score": 0.002524428047147766, "phrase": "different_model_views"}, {"score": 0.002503187934017557, "phrase": "experimental_results"}, {"score": 0.002471661547432869, "phrase": "stronger_power"}, {"score": 0.0023996317685956213, "phrase": "extensive_clutter"}, {"score": 0.0023794391656001466, "phrase": "dominant_occlusion"}, {"score": 0.002349467661235186, "phrase": "large_scale"}, {"score": 0.0023003498123420237, "phrase": "non-rigid_deformations"}, {"score": 0.0022145052062614514, "phrase": "approximative_contours"}, {"score": 0.0021408862709571615, "phrase": "presented_techniques"}, {"score": 0.0021049977753042253, "phrase": "view-point_invariant_feature_extractor"}], "paper_keywords": [""], "paper_abstract": "We present a novel Object Recognition approach based on affine invariant regions. It actively counters the problems related to the limited repeatability of the region detectors, and the difficulty of matching, in the presence of large amounts of background clutter and particularly challenging viewing conditions. After producing an initial set of matches, the method gradually explores the surrounding image areas, recursively constructing more and more matching regions, increasingly farther from the initial ones. This process covers the object with matches, and simultaneously separates the correct matches from the wrong ones. Hence, recognition and segmentation are achieved at the same time. The approach includes a mechanism for capturing the relationships between multiple model views and exploiting these for integrating the contributions of the views at recognition time. This is based on an efficient algorithm for partitioning a set of region matches into groups lying on smooth surfaces. Integration is achieved by measuring the consistency of configurations of groups arising from different model views. Experimental results demonstrate the stronger power of the approach in dealing with extensive clutter, dominant occlusion, and large scale and viewpoint changes. Non-rigid deformations are explicitly taken into account, and the approximative contours of the object are produced. All presented techniques can extend any view-point invariant feature extractor.", "paper_title": "Simultaneous object recognition and segmentation from single or multiple model views", "paper_id": "WOS:000237985300003"}