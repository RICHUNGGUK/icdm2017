{"auto_keywords": [{"score": 0.043612899193540264, "phrase": "head_rotation"}, {"score": 0.004815721818315065, "phrase": "environments"}, {"score": 0.004767261858417823, "phrase": "gaze_estimation"}, {"score": 0.004315487055548749, "phrase": "new_method"}, {"score": 0.004251500979153001, "phrase": "visual_focus"}, {"score": 0.004065156038847781, "phrase": "fuzzy_fusion"}, {"score": 0.003984968827278219, "phrase": "eye_gaze_estimates"}, {"score": 0.003906357144047631, "phrase": "fully_automatic_manner"}, {"score": 0.0037724857647796813, "phrase": "special_hardware"}, {"score": 0.003716520760680603, "phrase": "priori_knowledge"}, {"score": 0.003347259612209552, "phrase": "unpretending_conditions"}, {"score": 0.0032324864013225166, "phrase": "simple_hardware"}, {"score": 0.0031686717525002935, "phrase": "normal_web-camera"}, {"score": 0.003014576010931602, "phrase": "human-computer_interaction_environment"}, {"score": 0.0026086775334428617, "phrase": "local_and_appearance_information"}, {"score": 0.002457110101089137, "phrase": "common_framework"}, {"score": 0.0023609780669713288, "phrase": "head_rotational_movement"}, {"score": 0.0023259039577313294, "phrase": "translational_movements"}, {"score": 0.002136747803494932, "phrase": "user's_distance"}, {"score": 0.0021049977753042253, "phrase": "camera_or_camera_intrinsic_parameters"}], "paper_keywords": ["Head pose estimation", " User attention estimation", " Facial feature tracking", " Facial feature detection", " Face tracking", " Eye Gaze estimation", " Human computer interaction"], "paper_abstract": "Estimating the focus of attention of a person highly depends on her/his gaze directionality. Here, we propose a new method for estimating visual focus of attention using head rotation, as well as fuzzy fusion of head rotation and eye gaze estimates, in a fully automatic manner, without the need for any special hardware or a priori knowledge regarding the user, the environment or the setup. Instead, we propose a system aimed at functioning under unpretending conditions, only with the usage of simple hardware, like a normal web-camera. Our system is aimed at functioning in a human-computer interaction environment, considering a person is facing a monitor with a camera adjusted on top. To this aim, we propose in this paper two novel techniques, based on local and appearance information, estimating head rotation, and we adaptively fuse them in a common framework. The system is able to recognize head rotational movement, under translational movements of the user towards any direction, without any knowledge or a-priori estimate of the user's distance from the camera or camera intrinsic parameters.", "paper_title": "Visual Focus of Attention in Non-calibrated Environments using Gaze Estimation", "paper_id": "WOS:000333362600005"}