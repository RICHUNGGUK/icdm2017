{"auto_keywords": [{"score": 0.038944728793694525, "phrase": "dslpso"}, {"score": 0.010146632223769153, "phrase": "pso"}, {"score": 0.009921228267407201, "phrase": "premature_convergence"}, {"score": 0.00481495049065317, "phrase": "shrunk_search_space"}, {"score": 0.004644146045859622, "phrase": "standard_particle_swarm_optimization"}, {"score": 0.004459190343665408, "phrase": "slow_convergence_speed"}, {"score": 0.004339979174946844, "phrase": "stochastic_or_aimless_strategies"}, {"score": 0.004262273304740847, "phrase": "convergence_problem"}, {"score": 0.004167086373747367, "phrase": "mutual_learning"}, {"score": 0.004129607015893271, "phrase": "elites_particles"}, {"score": 0.003929391999210588, "phrase": "convergence_speed"}, {"score": 0.0033544692489307676, "phrase": "aforementioned_shortcomings"}, {"score": 0.003134503353065008, "phrase": "tabu_detecting_strategy"}, {"score": 0.0030783143919343972, "phrase": "good_ergodicity"}, {"score": 0.0030505976034245234, "phrase": "search_space"}, {"score": 0.0029959082125682918, "phrase": "global_historical_best_particle"}, {"score": 0.0027616550517346066, "phrase": "shrinking_strategy"}, {"score": 0.0026634937939104177, "phrase": "smaller_search_space"}, {"score": 0.0026157259734105, "phrase": "higher_convergence_speed"}, {"score": 0.002568812627436125, "phrase": "local_learning_strategy"}, {"score": 0.002455168454109375, "phrase": "solution_accuracy"}, {"score": 0.0024220634963019114, "phrase": "experimental_results"}, {"score": 0.0023571835517819124, "phrase": "superior_performance"}, {"score": 0.0022631003204259224, "phrase": "tested_functions"}, {"score": 0.002202469129781332, "phrase": "faster_convergence_speed"}, {"score": 0.0021826210858934933, "phrase": "higher_solution_accuracy"}, {"score": 0.002162951519368368, "phrase": "stronger_reliability"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Particle swarm optimization", " Detecting strategy", " Shrink search space", " Local learning", " Subregions", " Premature convergence"], "paper_abstract": "To improve the performance of the standard particle swarm optimization (PSO) which suffers from premature convergence and slow convergence speed, many PSO variants introduce lots of stochastic or aimless strategies to overcome the convergence problem. However, the mutual learning between elites particles is omitted, although which might be benefit to the convergence speed and, prevent the premature convergence. In this paper, we introduce DSLPSO, which integrates three novel strategies, specifically, tabu detecting, shrinking and local learning strategies, into PSO to overcome the aforementioned shortcomings. In DSLPSO, search space of each dimension is divided into many equal subregions. Then the tabu detecting strategy, which has good ergodicity for search space, helps the global historical best particle to detect a more suitable subregion, and thus help it jump out of a local optimum. The shrinking strategy enables DSLPSO to take optimization in a smaller search space and obtain a higher convergence speed. In the local learning strategy, a differential between two elites particles is used to increase solution accuracy. The experimental results show that DSLPSO has a superior performance in comparison with several other participant PSOs on most of the tested functions, as well as offering faster convergence speed, higher solution accuracy and stronger reliability. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "An improved particle swarm optimizer based on tabu detecting and local learning strategy in a shrunk search space", "paper_id": "WOS:000341680000008"}