{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "flexible_initial_framework"}, {"score": 0.004658426838467567, "phrase": "self-aware_agents"}, {"score": 0.004422632150619634, "phrase": "long-term_rewards"}, {"score": 0.0043194180167921165, "phrase": "reasoned_exploration"}, {"score": 0.004278807087784626, "phrase": "feasible_sequences"}, {"score": 0.0041987222897385676, "phrase": "corresponding_states"}, {"score": 0.003475582268210954, "phrase": "realistic_agents"}, {"score": 0.0033150974333333214, "phrase": "proposed_agents"}, {"score": 0.00326840809777013, "phrase": "weakened_closed-world_assumption"}, {"score": 0.003176986603753607, "phrase": "epistemic_reasoning"}, {"score": 0.003102752392819577, "phrase": "planning_operators"}, {"score": 0.0028093921138602606, "phrase": "language_production"}, {"score": 0.0027567336518542858, "phrase": "uniform_procedural_attachment_method"}, {"score": 0.002641823250595624, "phrase": "experimental_runs"}, {"score": 0.0025436978068459565, "phrase": "simple_world"}, {"score": 0.0022706045233150795, "phrase": "aforementioned_features"}, {"score": 0.00218623706110975, "phrase": "single_or_multiple_goal-seeking_agents"}, {"score": 0.0021049977753042253, "phrase": "recent_experimental_agents"}], "paper_keywords": ["communicative agents", " continual planning", " deliberate and opportunistic behavior", " incomplete knowledge", " introspection", " self-aware agents", " self-motivated cognitive agents"], "paper_abstract": "We present a flexible initial framework for defining self-motivated, self-aware agents in simulated worlds, planning continuously so as to maximize long-term rewards. While such agents employ reasoned exploration of feasible sequences of actions and corresponding states, they also behave opportunistically and recover from failure, thanks to their continual plan updates and quest for rewards. Our framework allows for both specific and general (quantified) knowledge and for epistemic predicates such as knowing-that and knowing-whether. Because realistic agents have only partial knowledge of their world, the reasoning of the proposed agents uses a weakened closed-world assumption; this has consequences for epistemic reasoning, in particular introspection. The planning operators allow for quantitative, gradual change and side effects such as the passage of time, changes in distances and rewards, and language production, using a uniform procedural attachment method. Question answering (involving introspection) and experimental runs are shown for our particular agent ME in a simple world, demonstrating the value of continual deliberate, reward-driven planning. Though the primary merit of agents definable in our framework is that they combine all of the aforementioned features, they can also be configured as single or multiple goal-seeking agents and as such perform comparably with some recent experimental agents.", "paper_title": "Toward Self-Motivated, Cognitive, Continually Planning Agents", "paper_id": "WOS:000358608900001"}