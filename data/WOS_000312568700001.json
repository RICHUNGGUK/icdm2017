{"auto_keywords": [{"score": 0.04248340330135682, "phrase": "decomposable_model"}, {"score": 0.00481495049065317, "phrase": "decomposable_models._decomposable"}, {"score": 0.004719816332271661, "phrase": "log-linear_models"}, {"score": 0.004663636232080366, "phrase": "acyclic_hypergraphs"}, {"score": 0.004553265070135597, "phrase": "nice_properties"}, {"score": 0.004271490815763164, "phrase": "probability_distribution_p"}, {"score": 0.004220624516321415, "phrase": "finite_set_v"}, {"score": 0.0041703614123283165, "phrase": "discrete_variables"}, {"score": 0.004120694410890683, "phrase": "positive_integer_k"}, {"score": 0.0038348235692738783, "phrase": "generating_hypergraph"}, {"score": 0.0034289106230496816, "phrase": "information_divergence"}, {"score": 0.0030781126453776723, "phrase": "tree-width_k"}, {"score": 0.0028540944960340434, "phrase": "np"}, {"score": 0.0026976874091004495, "phrase": "chow"}, {"score": 0.002676220870081979, "phrase": "liu"}, {"score": 0.002571171956724731, "phrase": "optimal_chow-liu_solution"}, {"score": 0.0024408799645640323, "phrase": "'good'_solution"}, {"score": 0.0024117603727471654, "phrase": "arbitrary_k."}, {"score": 0.002373472641477602, "phrase": "backward-selection_procedure"}, {"score": 0.0021909411820497707, "phrase": "study_case"}, {"score": 0.0021049977753042253, "phrase": "optimal_solution"}], "paper_keywords": ["backward selection", " information divergence", " decomposable model", " acyclic hypergraph", " k-hypertree"], "paper_abstract": "Decomposable (probabilistic) models are log-linear models generated by acyclic hypergraphs, and a number of nice properties enjoyed by them are known. In many applications the following selection problem naturally arises: given a probability distribution p over a finite set V of n discrete variables and a positive integer k, find a decomposable model with tree-width k that best fits p. If H is the generating hypergraph of a decomposable model and p(H) is the estimate of p under the model, we can measure the closeness of p(H) to p by the information divergence D(p : p(H)), so that the problem above reads: given p and k, find an acyclic, connected hypergraph H of tree-width k such that D(p : pH) is minimum. It is well-known that this problem is NP-hard. However, for k = 1 it was solved by Chow and Liu in a very efficient way; thus, starting from an optimal Chow-Liu solution, a few forward-selection procedures have been proposed with the aim at finding a 'good' solution for an arbitrary k. We propose a backward-selection procedure which starts from the (trivial) optimal solution for k = n - 1, and we show that, in a study case taken from literature, our procedure succeeds in finding an optimal solution for every k.", "paper_title": "A BACKWARD SELECTION PROCEDURE FOR APPROXIMATING A DISCRETE PROBABILITY DISTRIBUTION BY DECOMPOSABLE MODELS", "paper_id": "WOS:000312568700001"}