{"auto_keywords": [{"score": 0.04584591872891792, "phrase": "robotic_manipulator"}, {"score": 0.014216658520745116, "phrase": "visual_servoing"}, {"score": 0.008663947132282569, "phrase": "proposed_control_scheme"}, {"score": 0.00481495049065317, "phrase": "non-cooperative_target"}, {"score": 0.0047707093928203, "phrase": "visual_servoing_and_motion_predictive_control"}, {"score": 0.004597754207658615, "phrase": "autonomous_capture_operation"}, {"score": 0.004534517530868195, "phrase": "non-cooperative_mobile_target"}, {"score": 0.004153647187175639, "phrase": "hand_configuration"}, {"score": 0.004058826900076531, "phrase": "predictive_control"}, {"score": 0.004021570650533213, "phrase": "kalman"}, {"score": 0.003947884118204803, "phrase": "on-line_state_and_parameter_estimation"}, {"score": 0.003839962121679795, "phrase": "transitional_decision_making_process"}, {"score": 0.003683565150278339, "phrase": "different_phases"}, {"score": 0.0036328561748082138, "phrase": "capture_operation"}, {"score": 0.0035663245542174224, "phrase": "custom_metric"}, {"score": 0.003517223847512266, "phrase": "visual_misalignments"}, {"score": 0.0033739270918502285, "phrase": "guidance_measurement"}, {"score": 0.003281643474564305, "phrase": "target_acquisition"}, {"score": 0.0032514447965530323, "phrase": "approach_stage"}, {"score": 0.0027784560880013886, "phrase": "proposed_motion_predictive_control_scheme"}, {"score": 0.00274017282519193, "phrase": "autonomous_capturing_task"}, {"score": 0.0025565050791036973, "phrase": "unexpected_disturbances"}, {"score": 0.0025329623864528317, "phrase": "vision_system"}, {"score": 0.0025096359514694523, "phrase": "sensory-motor_coordination"}, {"score": 0.002429668083484833, "phrase": "real_environments"}, {"score": 0.002407290605654707, "phrase": "experimental_results"}, {"score": 0.0023741093119014436, "phrase": "visual_servoing_control_scheme"}, {"score": 0.0023198180380964305, "phrase": "predictive_kalman_filter"}, {"score": 0.002164264600379492, "phrase": "target_motion"}, {"score": 0.0021049977753042253, "phrase": "tracking_and_capture_performance"}], "paper_keywords": ["Autonomy", " Robotic manipulator", " Visual servoing", " Trajectory tracking", " Capture", " Non-cooperative target", " Kalman filter", " Motion predictive control"], "paper_abstract": "This paper presents a framework for autonomous capture operation of a non-cooperative mobile target in a 3-dimensional workspace using a robotic manipulator with visual servoing. The visual servoing with an eye-in-hand configuration is based on motion predictive control using Kalman filter for the on-line state and parameter estimation of the target. A transitional decision making process is developed to guide the robotic manipulator between the different phases of the capture operation by employing a custom metric that translates visual misalignments between the end-effector and the target into a guidance measurement. These phases include the target acquisition and approach stage and the alignment and capture phase. Experiments have been carried out on a custom designed and built robotic manipulator with 6 degrees of freedom. The objective is to evaluate the performance of the proposed motion predictive control scheme for the autonomous capturing task and to demonstrate the robustness of the proposed control scheme in the presence of noise and unexpected disturbances in vision system, sensory-motor coordination and constraints for the execution in real environments. Experimental results of the visual servoing control scheme integrated with the motion predictive Kalman filter indicate the feasibility and applicability of the proposed control scheme. It shows that when the target motion is properly predicted, the tracking and capture performance has been improved significantly.", "paper_title": "Autonomous robotic capture of non-cooperative target using visual servoing and motion predictive control", "paper_id": "WOS:000336975800003"}