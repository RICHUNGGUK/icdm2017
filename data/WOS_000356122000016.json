{"auto_keywords": [{"score": 0.015468621765144918, "phrase": "subject_matter_experts"}, {"score": 0.00481495049065317, "phrase": "flawed_expert_knowledge"}, {"score": 0.004775918707955445, "phrase": "reinforcement_learning"}, {"score": 0.004548253531664032, "phrase": "intelligent_systems"}, {"score": 0.0044025116437190785, "phrase": "correct_knowledge"}, {"score": 0.004278807087784626, "phrase": "knowledge_engineer"}, {"score": 0.004058180509184539, "phrase": "outdated_knowledge"}, {"score": 0.003848886045448135, "phrase": "flawed_tactical_agent"}, {"score": 0.003725470458263889, "phrase": "simulated_version"}, {"score": 0.0036207206487324506, "phrase": "theory_revision_repairs_agents"}, {"score": 0.00332375606483146, "phrase": "human_expertise"}, {"score": 0.0032833625797814474, "phrase": "correct_and_complete_domain_knowledge"}, {"score": 0.0026560841114619147, "phrase": "context-based_tactical_agent"}, {"score": 0.002438043578514396, "phrase": "original_hand-built_agent"}, {"score": 0.0023694065215394593, "phrase": "known_errors"}, {"score": 0.002283984048569816, "phrase": "improved_agent"}, {"score": 0.0022287497627555895, "phrase": "seeded_errors"}, {"score": 0.0021837406983565098, "phrase": "missing_knowledge"}], "paper_keywords": ["Knowledge acquisition", " Context-based reasoning", " Reinforcement learning", " Theory revision"], "paper_abstract": "Subject matter experts can sometimes provide incorrect and/or incomplete knowledge in the process of building intelligent systems. Other times, the expert articulates correct knowledge only to be misinterpreted by the knowledge engineer. In yet other cases, changes in the domain can lead to outdated knowledge in the system. This paper describes a technique that improves a flawed tactical agent by revising its knowledge through practice in a simulated version of its operational environment. This form of theory revision repairs agents originally built through interaction with subject matter experts. It is advantageous because such systems can now cease to be completely dependent on human expertise to provide correct and complete domain knowledge. After an agent has been built in consultation with experts, and before it is allowed to become operational, our method permits its improvement by subjecting it to several practice sessions in a simulation of its mission environment. Our method uses reinforcement learning to correct such errors and fill in gaps in the knowledge of a context-based tactical agent. The method was implemented and evaluated by comparing the performance of an agent improved by our method, to the original hand-built agent whose knowledge was purposely seeded with known errors and/or gaps. The results show that the improved agent did in fact correct the seeded errors and did gain the missing knowledge to permit it to perform better than the original, flawed agent. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Correcting flawed expert knowledge through reinforcement learning", "paper_id": "WOS:000356122000016"}