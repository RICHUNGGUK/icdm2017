{"auto_keywords": [{"score": 0.04776974719693073, "phrase": "fortran"}, {"score": 0.009290923381555384, "phrase": "mpi_code"}, {"score": 0.00481495049065317, "phrase": "modern_fortran"}, {"score": 0.004645057834614705, "phrase": "coordinate-free_numerics"}, {"score": 0.004521566043596533, "phrase": "code_flexibility"}, {"score": 0.004461051281091779, "phrase": "partial_differential_equation"}, {"score": 0.003987126862293129, "phrase": "state-of-the-art_software_development"}, {"score": 0.003951453722517865, "phrase": "fortran's_new_coarray_distributed_data_structure"}, {"score": 0.003677280504320636, "phrase": "pure_procedure_capability"}, {"score": 0.0035473867669654174, "phrase": "hpc_software"}, {"score": 0.0034220655476652683, "phrase": "parallel_computations"}, {"score": 0.0033914308417007316, "phrase": "efficient_communication"}, {"score": 0.0033160345607565565, "phrase": "programming_patterns"}, {"score": 0.0032716011062067286, "phrase": "asynchronous_evaluation"}, {"score": 0.003198860258228543, "phrase": "parallel_operations"}, {"score": 0.0031702173541386888, "phrase": "distributed_data"}, {"score": 0.002897482096228207, "phrase": "codes'_complexity"}, {"score": 0.0027328817607818207, "phrase": "external_libraries"}, {"score": 0.0026720866990543744, "phrase": "cray_hardware"}, {"score": 0.0026362590493392785, "phrase": "cray_compiler"}, {"score": 0.0025316254589087973, "phrase": "coarray_code"}, {"score": 0.0024641814990854463, "phrase": "intel_compiler_implements"}, {"score": 0.0024311346712789553, "phrase": "intel's_mpi_library"}, {"score": 0.0023033498726884385, "phrase": "mpi"}, {"score": 0.002272415777234064, "phrase": "nearly_linear_scaling_efficiency"}, {"score": 0.0021049977753042253, "phrase": "performance_gap"}], "paper_keywords": [""], "paper_abstract": "This paper presents ideas for using coordinate-free numerics in modern Fortran to achieve code flexibility in the partial differential equation (PDE) domain. We also show how Fortran, over the last few decades, has changed to become a language well-suited for state-of-the-art software development. Fortran's new coarray distributed data structure, the language's class mechanism, and its side-effect-free, pure procedure capability provide the scaffolding on which we implement HPC software. These features empower compilers to organize parallel computations with efficient communication. We present some programming patterns that support asynchronous evaluation of expressions comprised of parallel operations on distributed data. We implemented these patterns using coarrays and the message passing interface (MPI). We compared the codes' complexity and performance. The MPI code is much more complex and depends on external libraries. The MPI code on Cray hardware using the Cray compiler is 1.5-2 times faster than the coarray code on the same hardware. The Intel compiler implements coarrays atop Intel's MPI library with the result apparently being 2-2.5 times slower than manually coded MPI despite exhibiting nearly linear scaling efficiency. As compilers mature and further improvements to coarrays comes in Fortran 2015, we expect this performance gap to narrow.", "paper_title": "High-Performance Design Patterns for Modern Fortran", "paper_id": "WOS:000355855600001"}