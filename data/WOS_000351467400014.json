{"auto_keywords": [{"score": 0.03891431677282442, "phrase": "visual_features"}, {"score": 0.015719716506582538, "phrase": "user_clicks"}, {"score": 0.0047013405841819025, "phrase": "image_retrieval"}, {"score": 0.00459039896577789, "phrase": "textual_features"}, {"score": 0.004546755482549647, "phrase": "visual_contents"}, {"score": 0.004482063543727601, "phrase": "poor_image_search_results"}, {"score": 0.004172094622123562, "phrase": "textual_information"}, {"score": 0.003996458454723708, "phrase": "clicked_images"}, {"score": 0.003773680962197766, "phrase": "existing_ranking_model"}, {"score": 0.0035632774896594524, "phrase": "click-based_search_results"}, {"score": 0.003413183361838603, "phrase": "novel_ranking_model"}, {"score": 0.0032382660477699695, "phrase": "click_features"}, {"score": 0.003131637033429892, "phrase": "ranking_model"}, {"score": 0.00305762327908599, "phrase": "proposed_approach"}, {"score": 0.0029996699429582835, "phrase": "large_margin_structured_output_learning"}, {"score": 0.0028187792953857957, "phrase": "hypergraph_regularizer_term"}, {"score": 0.002739001004969201, "phrase": "fast_alternating_linearization_method"}, {"score": 0.0026742419973883134, "phrase": "novel_algorithm"}, {"score": 0.002623536040408411, "phrase": "objective_function"}, {"score": 0.002512926336312949, "phrase": "original_objective_function"}, {"score": 0.0023388183537341213, "phrase": "large-scale_dataset"}, {"score": 0.0022944576894161485, "phrase": "image_search_engine"}, {"score": 0.00220823903315848, "phrase": "proposed_learning"}, {"score": 0.0021049977753042253, "phrase": "state-of-the-art_algorithms"}], "paper_keywords": ["Click", " hypergraph", " learning to rank"], "paper_abstract": "The inconsistency between textual features and visual contents can cause poor image search results. To solve this problem, click features, which are more reliable than textual information in justifying the relevance between a query and clicked images, are adopted in image ranking model. However, the existing ranking model cannot integrate visual features, which are efficient in refining the click-based search results. In this paper, we propose a novel ranking model based on the learning to rank framework. Visual features and click features are simultaneously utilized to obtain the ranking model. Specifically, the proposed approach is based on large margin structured output learning and the visual consistency is integrated with the click features through a hypergraph regularizer term. In accordance with the fast alternating linearization method, we design a novel algorithm to optimize the objective function. This algorithm alternately minimizes two different approximations of the original objective function by keeping one function unchanged and linearizing the other. We conduct experiments on a large-scale dataset collected from the Microsoft Bing image search engine, and the results demonstrate that the proposed learning to rank models based on visual features and user clicks outperforms state-of-the-art algorithms.", "paper_title": "Learning to Rank Using User Clicks and Visual Features for Image Retrieval", "paper_id": "WOS:000351467400014"}