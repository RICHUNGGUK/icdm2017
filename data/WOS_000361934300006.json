{"auto_keywords": [{"score": 0.050077294365016824, "phrase": "tag_refinement"}, {"score": 0.0494997538357069, "phrase": "web_videos"}, {"score": 0.046299628841683614, "phrase": "user-generated_tags"}, {"score": 0.038854320683450905, "phrase": "flickr"}, {"score": 0.0046993598473345395, "phrase": "visual_content"}, {"score": 0.004586531354697466, "phrase": "web-based_services"}, {"score": 0.00450368324850566, "phrase": "tagging_functionalities"}, {"score": 0.0043161190928529755, "phrase": "media_collections"}, {"score": 0.004263972370406983, "phrase": "tag_clouds"}, {"score": 0.004199670318539555, "phrase": "multimedia_content"}, {"score": 0.004012500850311087, "phrase": "current_systems"}, {"score": 0.003939980614608309, "phrase": "single_photo"}, {"score": 0.003674034647773692, "phrase": "facebook"}, {"score": 0.0035855828944304506, "phrase": "video_sequence"}, {"score": 0.0034361227353612456, "phrase": "overall_content"}, {"score": 0.0033029038236817372, "phrase": "automatic_video_annotation"}, {"score": 0.003070340620983981, "phrase": "collective_knowledge"}, {"score": 0.0029874020705125356, "phrase": "visual_similarity"}, {"score": 0.0029244418026475832, "phrase": "social_sites"}, {"score": 0.0029067445366205064, "phrase": "youtube"}, {"score": 0.0028454331415283213, "phrase": "web_sources"}, {"score": 0.002828293859357491, "phrase": "google"}, {"score": 0.002661146838358236, "phrase": "visual_sources"}, {"score": 0.002644995764097807, "phrase": "training_exemplars"}, {"score": 0.0025735173163957993, "phrase": "test_sample"}, {"score": 0.002511600086227215, "phrase": "similar_images"}, {"score": 0.002481200970201421, "phrase": "existing_video_tagging_approaches"}, {"score": 0.0024586427394152196, "phrase": "training_classifiers"}, {"score": 0.0023275257102180554, "phrase": "open_vocabulary_scenario"}, {"score": 0.0022508576173469515, "phrase": "dut-webv"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Video tagging", " Web video", " Tag refinement", " Tag localization", " Social media", " Data-driven", " Lazy learning"], "paper_abstract": "Tagging of visual content is becoming more and more widespread as web-based services and social networks have popularized tagging functionalities among their users. These user-generated tags are used to ease browsing and exploration of media collections, e.g. using tag clouds, or to retrieve multimedia content. However, not all media are equally tagged by users. Using the current systems is easy to tag a single photo, and even tagging a part of a photo, like a face, has become common in sites like Flickr and Facebook. On the other hand, tagging a video sequence is more complicated and time consuming, so that users just tag the overall content of a video. In this paper we present a method for automatic video annotation that increases the number of tags originally provided by users, and localizes them temporally, associating tags to keyframes. Our approach exploits collective knowledge embedded in user-generated tags and web sources, and visual similarity of keyframes and images uploaded to social sites like YouTube and Flickr, as well as web sources like Google and Bing. Given a keyframe, our method is able to select \"on the fly\" from these visual sources the training exemplars that should be the most relevant for this test sample, and proceeds to transfer labels across similar images. Compared to existing video tagging approaches that require training classifiers for each tag, our system has few parameters, is easy to implement and can deal with an open vocabulary scenario. We demonstrate the approach on tag refinement and localization on DUT-WEBV, a large dataset of web videos, and show state-of-the-art results. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "A data-driven approach for tag refinement and localization in web videos", "paper_id": "WOS:000361934300006"}