{"auto_keywords": [{"score": 0.04832675252243851, "phrase": "multiple_organs"}, {"score": 0.040287025689518835, "phrase": "supervised_intensity_information"}, {"score": 0.015719716506582538, "phrase": "ct_images"}, {"score": 0.01424698826013824, "phrase": "conditional_priors"}, {"score": 0.0047851345246117455, "phrase": "conditional_shape-location"}, {"score": 0.0047555023078686386, "phrase": "unsupervised_intensity_priors"}, {"score": 0.0046676969718111765, "phrase": "automated_segmentation"}, {"score": 0.004610058444728656, "phrase": "upper_abdominal_computed_tomography"}, {"score": 0.004239103253656808, "phrase": "easy_adaptation"}, {"score": 0.004122179528285764, "phrase": "clinical_practice"}, {"score": 0.004058615475230867, "phrase": "general_framework"}, {"score": 0.0040334640350288, "phrase": "multi-organ_segmentation"}, {"score": 0.0036288825833675127, "phrase": "conditional_shape"}, {"score": 0.003388909415044492, "phrase": "accurate_priors"}, {"score": 0.0032749212355657215, "phrase": "intensity_priors"}, {"score": 0.003086961663712383, "phrase": "segmentation_processes"}, {"score": 0.002918826667294298, "phrase": "conventional_single-organ_segmentation_methods"}, {"score": 0.0028382152567141784, "phrase": "remaining_organs"}, {"score": 0.0027943943921568456, "phrase": "conditional_shape-location_priors"}, {"score": 0.002700348931172875, "phrase": "eight_abdominal_organs"}, {"score": 0.002474961375646351, "phrase": "six_imaging_conditions"}, {"score": 0.002436735294813786, "phrase": "experimental_results"}, {"score": 0.0023916406628316593, "phrase": "proposed_prediction-based_priors"}, {"score": 0.0023039337947957077, "phrase": "average_dice_coefficients"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Subject-specific priors", " Partial least squares regression", " Computational anatomy", " Statistical shape model", " Probabilistic atlas"], "paper_abstract": "This paper addresses the automated segmentation of multiple organs in upper abdominal computed tomography (CT) data. The aim of our study is to develop methods to effectively construct the conditional priors and use their prediction power for more accurate segmentation as well as easy adaptation to various imaging conditions in CT images, as observed in clinical practice. We propose a general framework of multi-organ segmentation which effectively incorporates interrelations among multiple organs and easily adapts to various imaging conditions without the need for supervised intensity information. The features of the framework are as follows: (1) A method for modeling conditional shape and location (shape-location) priors, which we call prediction-based priors, is developed to derive accurate priors specific to each subject, which enables the estimation of intensity priors without the need for supervised intensity information. (2) Organ correlation graph is introduced, which defines how the conditional priors are constructed and segmentation processes of multiple organs are executed. In our framework, predictor organs, whose segmentation is sufficiently accurate by using conventional single-organ segmentation methods, are pre-segmented, and the remaining organs are hierarchically segmented using conditional shape-location priors. The proposed framework was evaluated through the segmentation of eight abdominal organs (liver, spleen, left and right kidneys, pancreas, gallbladder, aorta, and inferior vena cava) from 134 CT data from 86 patients obtained under six imaging conditions at two hospitals. The experimental results show the effectiveness of the proposed prediction-based priors and the applicability to various imaging conditions without the need for supervised intensity information. Average Dice coefficients for the liver, spleen, and kidneys were more than 92%, and were around 73% and 67% for the pancreas and gallbladder, respectively. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Abdominal multi-organ segmentation from CT images using conditional shape-location and unsupervised intensity priors", "paper_id": "WOS:000367490800001"}