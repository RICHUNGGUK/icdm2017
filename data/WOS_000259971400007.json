{"auto_keywords": [{"score": 0.04886626441968086, "phrase": "configurable_architectures"}, {"score": 0.00481495049065317, "phrase": "managing_storage"}, {"score": 0.004574085781766281, "phrase": "unique_opportunity"}, {"score": 0.004504193207111593, "phrase": "hardware_designs"}, {"score": 0.004412654209742722, "phrase": "specific_data"}, {"score": 0.004367581653370531, "phrase": "computational_patterns"}, {"score": 0.004300830853119242, "phrase": "application_code"}, {"score": 0.00421340730888561, "phrase": "storage_structures"}, {"score": 0.0040438338011467845, "phrase": "continuing_gap"}, {"score": 0.004002513373645485, "phrase": "memory_latencies"}, {"score": 0.003961613484271729, "phrase": "internal_computing_speeds"}, {"score": 0.0037632749713937637, "phrase": "compiler_algorithm"}, {"score": 0.0036303546926971966, "phrase": "loop-based_computation"}, {"score": 0.0035932440062595252, "phrase": "internal_storage_structures"}, {"score": 0.003538481782046042, "phrase": "ram"}, {"score": 0.003343841875107018, "phrase": "overall_execution_time"}, {"score": 0.0032423089921154503, "phrase": "bandwidth_constraints"}, {"score": 0.003192700856094016, "phrase": "storage_resources"}, {"score": 0.0030327408069772293, "phrase": "single_framework"}, {"score": 0.002986329509791943, "phrase": "high-level_compiler_techniques"}, {"score": 0.002955782731675529, "phrase": "lower-level_scheduling_information"}, {"score": 0.0026806884201358537, "phrase": "xilinx_virtextm_field-programmable_gate_array"}, {"score": 0.002494466951433885, "phrase": "state-of-the-art_custom_data_layout_mapping_technique"}, {"score": 0.0023451553255837317, "phrase": "hand-coded_designs"}, {"score": 0.0022390533383717715, "phrase": "execution_time"}, {"score": 0.0021377414429251647, "phrase": "minute_fraction"}, {"score": 0.0021049977753042253, "phrase": "design_time"}], "paper_keywords": [""], "paper_abstract": "Configurable architectures offer the unique opportunity of realizing hardware designs tailored to the specific data and computational patterns of an application code. Customizing the storage structures is becoming increasingly important in mitigating the continuing gap between memory latencies and internal computing speeds. In this article we describe and evaluate a compiler algorithm that maps the arrays of a loop-based computation to internal storage structures, either RAM blocks or discrete registers. Our objective is to minimize the overall execution time while considering the capacity and bandwidth constraints of the storage resources. The novelty of our approach lies in creating a single framework that combines high-level compiler techniques with lower-level scheduling information for mapping the data. We illustrate the benefits of our approach for a set of image/signal processing kernels using a Xilinx VirtexTM Field-Programmable Gate Array (FPGA). Our algorithm leads to faster designs compared to the state-of-the-art custom data layout mapping technique, in some instances using less storage. When compared to hand-coded designs, our results are comparable in terms of execution time and resources, but are derived in a minute fraction of the design time.", "paper_title": "A Compiler Approach to Managing Storage and Memory Bandwidth in Configurable Architectures", "paper_id": "WOS:000259971400007"}