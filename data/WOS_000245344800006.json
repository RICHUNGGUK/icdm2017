{"auto_keywords": [{"score": 0.0390108089770287, "phrase": "regularization_error"}, {"score": 0.00481495049065317, "phrase": "classification_algorithms"}, {"score": 0.004741845603430361, "phrase": "tikhonov_regularization_schemes"}, {"score": 0.004598933498016774, "phrase": "mufti-kernel_spaces"}, {"score": 0.004552255360140208, "phrase": "general_convex_loss_functions"}, {"score": 0.0044150318724093226, "phrase": "satisfactory_estimates"}, {"score": 0.004347972379250724, "phrase": "excess_misclassification_error"}, {"score": 0.0042819270655224916, "phrase": "mufti-kernel_regularized_classifiers"}, {"score": 0.0041316803676012155, "phrase": "zero_value"}, {"score": 0.004068907083697369, "phrase": "error_analysis"}, {"score": 0.0036740168936985314, "phrase": "approximation_error"}, {"score": 0.003545024951402821, "phrase": "mufti-kernel_setting"}, {"score": 0.0034733518170738517, "phrase": "general_loss_function"}, {"score": 0.0032336801561165113, "phrase": "weighted_l-q_spaces"}, {"score": 0.0031682817605340028, "phrase": "sample_error"}, {"score": 0.003088384809415812, "phrase": "projection_operator"}, {"score": 0.0028459677232555176, "phrase": "convergence_rates"}, {"score": 0.0027459678326877744, "phrase": "one-kernel_schemes"}, {"score": 0.002718045523483502, "phrase": "special_loss_functions"}, {"score": 0.002690406375639144, "phrase": "least-square_loss"}, {"score": 0.002622528664187849, "phrase": "support_vector_machine_soft_margin_classifiers"}, {"score": 0.002556359086441866, "phrase": "optimization_problem"}, {"score": 0.0025174594088331853, "phrase": "regularization_scheme"}, {"score": 0.002416589459425828, "phrase": "kernel_functions"}, {"score": 0.0022961534630650347, "phrase": "concrete_examples"}, {"score": 0.002261204313587616, "phrase": "gaussian_kernels"}, {"score": 0.0022382002476510573, "phrase": "flexible_variances"}, {"score": 0.0022154296909169826, "phrase": "probability_distributions"}, {"score": 0.0021817065300196634, "phrase": "noise_conditions"}, {"score": 0.0021049977753042253, "phrase": "general_theory"}], "paper_keywords": ["classification algorithm", " multi-kernel regularization scheme", " convex loss function", " misclassification error", " regularization error and sample error"], "paper_abstract": "A family of classification algorithms generated from Tikhonov regularization schemes are considered. They involve mufti-kernel spaces and general convex loss functions. Our main purpose is to provide satisfactory estimates for the excess misclassification error of these mufti-kernel regularized classifiers when the loss functions achieve the zero value. The error analysis consists of two parts: regularization error and sample error. Allowing mufti-kernels in the algorithm improves the regularization error and approximation error, which is one advantage of the mufti-kernel setting. For a general loss function, we show how to bound the regularization error by the approximation in some weighted L-q spaces. For the sample error, we use a projection operator. The projection in connection with the decay of the regularization error enables us to improve convergence rates in the literature even for the one-kernel schemes and special loss functions: least-square loss and hinge loss for support vector machine soft margin classifiers. Existence of the optimization problem for the regularization scheme associated with multi-kernels is verified when the kernel functions are continuous with respect to the index set. Concrete examples, including Gaussian kernels with flexible variances and probability distributions with some noise conditions, are used to illustrate the general theory. (c) 2006 Elsevier Inc. All rights reserved.", "paper_title": "Multi-kernel regularized classifiers", "paper_id": "WOS:000245344800006"}