{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "full-information_and_bandit_online_learning"}, {"score": 0.004312622975366672, "phrase": "individual_sequences"}, {"score": 0.004195418010131832, "phrase": "linear_loss"}, {"score": 0.0037060428445111664, "phrase": "first_efficient_algorithm"}, {"score": 0.003459191419478298, "phrase": "online_linear_optimization"}, {"score": 0.0028127163745564777, "phrase": "full-information_setting"}, {"score": 0.0026252106881752067, "phrase": "novel_regret_minimization_algorithm"}, {"score": 0.002255431275670053, "phrase": "interior-point_methods"}, {"score": 0.0021049977753042253, "phrase": "online_learning"}], "paper_keywords": ["Bandit feedback", " interior-point methods", " online convex optimization", " online learning"], "paper_abstract": "We study the problem of predicting individual sequences with linear loss with full and partial (or bandit) feedback. Our main contribution is the first efficient algorithm for the problem of online linear optimization in the bandit setting which achieves the optimal (O) over tilde(root T) regret. In addition, for the full-information setting, we give a novel regret minimization algorithm. These results are made possible by the introduction of interior-point methods for convex optimization to online learning.", "paper_title": "Interior-Point Methods for Full-Information and Bandit Online Learning", "paper_id": "WOS:000305575000007"}