{"auto_keywords": [{"score": 0.032262692011100026, "phrase": "inference_algorithm"}, {"score": 0.004779085953614184, "phrase": "attribute_grammar"}, {"score": 0.004673079747693193, "phrase": "simple_attribute_graph_grammar"}, {"score": 0.004620957579769604, "phrase": "generative_representation"}, {"score": 0.004586531354697466, "phrase": "man-made_scenes"}, {"score": 0.004177149334239669, "phrase": "bayesian_posterior_probability"}, {"score": 0.0040997480534580065, "phrase": "description_length"}, {"score": 0.004008749730113699, "phrase": "simple_grammar"}, {"score": 0.003890540531028228, "phrase": "i._e."}, {"score": 0.0038184296585478724, "phrase": "planar_rectangles"}, {"score": 0.0037476503270386903, "phrase": "image_plane"}, {"score": 0.003637112258469488, "phrase": "spatial_layout"}, {"score": 0.0035965032173588753, "phrase": "rectangular_surfaces"}, {"score": 0.003503497128638099, "phrase": "nonterminal_nodes"}, {"score": 0.003362163770566293, "phrase": "image_appearance"}, {"score": 0.003324614337607016, "phrase": "production_rule"}, {"score": 0.003178550413662537, "phrase": "parent_node"}, {"score": 0.0030847461428168614, "phrase": "input_image"}, {"score": 0.0029053368919259985, "phrase": "parse_tree"}, {"score": 0.0028728747019026485, "phrase": "hierarchical_decomposition"}, {"score": 0.0028195727965553367, "phrase": "spatial_constraints"}, {"score": 0.0027466028572379455, "phrase": "bottom-up_step"}, {"score": 0.0027159094186967247, "phrase": "excessive_number"}, {"score": 0.002675516297446243, "phrase": "weighted_candidates"}, {"score": 0.0025771355599741915, "phrase": "top-down_predictions"}, {"score": 0.0025578967205807843, "phrase": "occluded_or_missing_components"}, {"score": 0.00252930673503721, "phrase": "grammar_rules"}, {"score": 0.00250103550267459, "phrase": "whole_procedure"}, {"score": 0.002418099158357658, "phrase": "data-driven_markov_chain"}, {"score": 0.0024090550572099688, "phrase": "monte_carlo"}, {"score": 0.002294507393862231, "phrase": "greedy_algorithm"}, {"score": 0.0021609589091422608, "phrase": "top-down_inference"}, {"score": 0.0021049977753042253, "phrase": "bottom-up_detection"}], "paper_keywords": ["Attribute graph grammar", " bottom-up/top-down", " image parsing", " primal sketch", " generative model"], "paper_abstract": "This paper presents a simple attribute graph grammar as a generative representation for man-made scenes such as buildings, hallways, kitchens, and living rooms and studies an effective top-down/bottom-up inference algorithm for parsing images in the process of maximizing a Bayesian posterior probability or equivalently minimizing a description length (MDL). This simple grammar has one class of primitives as its terminal nodes, i. e., the projection of planar rectangles in 3-space into the image plane, and six production rules for the spatial layout of the rectangular surfaces. All of the terminal and nonterminal nodes in the grammar are described by attributes for their geometric properties and image appearance. Each production rule is associated with some equations that constrain the attributes of a parent node and those of its children. Given an input image, the inference algorithm computes (or constructs) a parse graph, which includes a parse tree for the hierarchical decomposition and a number of spatial constraints. In the inference algorithm, the bottom-up step detects an excessive number of rectangles as weighted candidates, which are sorted in a certain order and activate top-down predictions of occluded or missing components through the grammar rules. The whole procedure is, in spirit, similar to the data-driven Markov chain Monte Carlo paradigm [ 39], [ 33], except that a greedy algorithm is adopted for simplicity. In the experiment, we show that the grammar and top-down inference can largely improve the performance of bottom-up detection.", "paper_title": "Bottom-Up/Top-Down Image Parsing with Attribute Grammar", "paper_id": "WOS:000260889700006"}