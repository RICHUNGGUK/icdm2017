{"auto_keywords": [{"score": 0.02491223260151097, "phrase": "average_number"}, {"score": 0.024656637385868797, "phrase": "recognition_errors"}, {"score": 0.00481495049065317, "phrase": "rule-based_hand_trajectory_segmentation"}, {"score": 0.0047395356621991935, "phrase": "common_approach"}, {"score": 0.0046164478775379105, "phrase": "sign_language"}, {"score": 0.004496542293425754, "phrase": "unsupervised_clustering_algorithm"}, {"score": 0.004402854153653114, "phrase": "sign_segments"}, {"score": 0.004311109608629196, "phrase": "simple_clustering_algorithms"}, {"score": 0.004243552607799184, "phrase": "distance_measures"}, {"score": 0.004089991141220082, "phrase": "temporal_data"}, {"score": 0.004025885154716127, "phrase": "complex_algorithms"}, {"score": 0.003839510177926892, "phrase": "simple_and_effective_approach"}, {"score": 0.0037397086147485897, "phrase": "american_sign_language_sentences"}, {"score": 0.003623352647973122, "phrase": "rule-based_segmentation_algorithm"}, {"score": 0.0035477930970463432, "phrase": "hand_motion_trajectories"}, {"score": 0.0035106041824568618, "phrase": "signed_sentences"}, {"score": 0.0034193226278107346, "phrase": "feature_descriptors"}, {"score": 0.0033656930865509547, "phrase": "principal_component_analysis"}, {"score": 0.0030772505522663612, "phrase": "high_level_features"}, {"score": 0.0028886123801902517, "phrase": "deaf_signer"}, {"score": 0.0027547408718334603, "phrase": "phoneme_transcription"}, {"score": 0.002697245874076643, "phrase": "hidden_markov_models"}, {"score": 0.002219040041886641, "phrase": "completely_manual_trajectory_segmentation"}, {"score": 0.0021498955164659145, "phrase": "considerable_labor"}], "paper_keywords": ["American sign language (ASL)", " Phoneme transcription", " Trajectory segmentation", " Principal component analysis (PCA)", " Hidden Markov models (HMM)"], "paper_abstract": "A common approach to extract phonemes of sign language is to use an unsupervised clustering algorithm to group the sign segments. However, simple clustering algorithms based on distance measures usually do not work well on temporal data and require complex algorithms. In this paper, we present a simple and effective approach to extract phonemes from American sign language sentences. We first apply a rule-based segmentation algorithm to segment the hand motion trajectories of signed sentences. We then extract feature descriptors based on principal component analysis to represent the segments efficiently. The segments are clustered by k-means using these high level features to derive phonemes. 25 different continuously signed sentences from a deaf signer were used to perform the analysis. After phoneme transcription, we trained Hidden Markov Models to recognize the sequence of phonemes in the sentences. Overall, our automatic approach yielded 165 segments, and 58 phonemes were obtained based on these segments. The average number of recognition errors was 18.8 (11.4%). In comparison, completely manual trajectory segmentation and phoneme transcription, involving considerable labor yielded 173 segments, 57 phonemes, and the average number of recognition errors was 33.8 (19.5%).", "paper_title": "Sign Language Phoneme Transcription with Rule-based Hand Trajectory Segmentation", "paper_id": "WOS:000275990900007"}