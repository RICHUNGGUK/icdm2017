{"auto_keywords": [{"score": 0.027606723564008742, "phrase": "harp"}, {"score": 0.00481495049065317, "phrase": "energy_analysis_of_hardware_and_software_range_partitioning"}, {"score": 0.004675768396728975, "phrase": "critical_operation"}, {"score": 0.004607686390487483, "phrase": "large_datasets"}, {"score": 0.004345085569121329, "phrase": "efficient_processing"}, {"score": 0.004219427915728972, "phrase": "limiting_factor"}, {"score": 0.004178351419209898, "phrase": "database_performance"}, {"score": 0.004097389262726735, "phrase": "significant_fraction"}, {"score": 0.004037694641919865, "phrase": "overall_runtime"}, {"score": 0.003998380230709541, "phrase": "large_data_queries"}, {"score": 0.0038074544783102226, "phrase": "state-of-the-art_software_partitioners"}, {"score": 0.003520687960750365, "phrase": "software_implementation"}, {"score": 0.0034020946201397057, "phrase": "separate_analysis"}, {"score": 0.0033524956061690868, "phrase": "partition_function_computation_and_data_shuffling_costs"}, {"score": 0.0031457622320220364, "phrase": "simpler_strategies"}, {"score": 0.003099888654615187, "phrase": "hash_partitioning"}, {"score": 0.003024909947609294, "phrase": "careful_data_movement"}, {"score": 0.002951739421935396, "phrase": "partition_function"}, {"score": 0.0026372419109713923, "phrase": "hardware_range_partitioner"}, {"score": 0.002498873893632726, "phrase": "seamless_execution_environment"}, {"score": 0.0021361800485636823, "phrase": "xeon_core"}], "paper_keywords": ["Design", " Measurement", " Performance", " Accelerator", " specialized functional unit", " streaming data", " microarchitecture", " data partitioning"], "paper_abstract": "Data partitioning is a critical operation for manipulating large datasets because it subdivides tasks into pieces that are more amenable to efficient processing. It is often the limiting factor in database performance and represents a significant fraction of the overall runtime of large data queries. This article measures the performance and energy of state-of-the-art software partitioners, and describes and evaluates a hardware range partitioner that further improves efficiency. The software implementation is broken into two phases, allowing separate analysis of the partition function computation and data shuffling costs. Although range partitioning is commonly thought to be more expensive than simpler strategies such as hash partitioning, our measurements indicate that careful data movement and optimization of the partition function can allow it to approach the throughput and energy consumption of hash or radix partitioning. For further acceleration, we describe a hardware range partitioner, or HARP, a streaming framework that offers a seamless execution environment for this and other streaming accelerators, and a detailed analysis of a 32nm physical design that matches the throughput of four to eight software threads while consuming just 6.9% of the area and 4.3% of the power of a Xeon core in the same technology generation.", "paper_title": "Energy Analysis of Hardware and Software Range Partitioning", "paper_id": "WOS:000344319900002"}