{"auto_keywords": [{"score": 0.026315199353167427, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "coupled_compressive_pruning"}, {"score": 0.004687305496643216, "phrase": "support_vector_machines"}, {"score": 0.004624751696958501, "phrase": "least_square_support_vector_machine"}, {"score": 0.004266501496765747, "phrase": "inequality_constraints"}, {"score": 0.004209539728590977, "phrase": "linear_equations"}, {"score": 0.00398916666053909, "phrase": "reduced_support_vectors"}, {"score": 0.0038833278847237858, "phrase": "generalization_performance"}, {"score": 0.0038314621564116192, "phrase": "lssvm."}, {"score": 0.003558294449586273, "phrase": "support_vectors"}, {"score": 0.00344062888674746, "phrase": "high_computation_complexity"}, {"score": 0.003238517900104576, "phrase": "recently_developed_compressive_sampling_theory"}, {"score": 0.0031738126998349775, "phrase": "one-step_compressive_pruning_strategy"}, {"score": 0.0030482430937467013, "phrase": "sparse_lssvm"}, {"score": 0.0029873281676201565, "phrase": "remarkable_reduction"}, {"score": 0.002700485592691974, "phrase": "iterative_retraining"}, {"score": 0.0026111116934081284, "phrase": "pattern_recognition"}, {"score": 0.0025761937402886954, "phrase": "function_approximation"}, {"score": 0.0024247382451294255, "phrase": "available_pruning_approaches"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v._all_rights"}], "paper_keywords": ["Least square support vector machine", " Compressive pruning", " Sparse representation", " Random measurement"], "paper_abstract": "Among the support vector machines, Least Square Support Vector Machine (LSSVM) is computationally attractive for reducing a set of inequality constraints to linear equations. Several pruning algorithms have been developed to obtain reduced support vectors to improve the generalization performance of LSSVM. However, most of the pruning algorithms iteratively select the support vectors, which is of high computation complexity. In this paper, inspired by the recently developed compressive sampling theory, a one-step compressive pruning strategy is proposed to construct a sparse LSSVM without the remarkable reduction of accuracy. It is a fast, universal and information-preserved pruning approach that can avoid the intensive computations in iterative retraining. Some experiments on pattern recognition and function approximation are taken to compare the proposed method with the available pruning approaches, and the results show the feasibility of the proposed method and the superiority to its counterparts. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Sparse least square support vector machine via coupled compressive pruning", "paper_id": "WOS:000332805700009"}