{"auto_keywords": [{"score": 0.04909435677365324, "phrase": "indoor_scene_recognition"}, {"score": 0.004815047029611802, "phrase": "nearest-neighbor"}, {"score": 0.004765173195920904, "phrase": "metric_functions"}, {"score": 0.004594951819987416, "phrase": "challenging_problem"}, {"score": 0.004523865550323285, "phrase": "classical_scene_recognition_domain"}, {"score": 0.004430784015995566, "phrase": "severe_intra-class_variations"}, {"score": 0.004384960761826366, "phrase": "inter-class_similarities"}, {"score": 0.004339609346924681, "phrase": "man-made_indoor_structures"}, {"score": 0.004294724955301414, "phrase": "state-of-the-art_scene_recognition_techniques"}, {"score": 0.0040771431404398855, "phrase": "low_performance"}, {"score": 0.004034962424068988, "phrase": "indoor_scenes"}, {"score": 0.003931402465972151, "phrase": "intermediate_steps"}, {"score": 0.0035063024767122684, "phrase": "highly_cluttered_and_sophisticated_environment"}, {"score": 0.0034162643819889054, "phrase": "classification_method"}, {"score": 0.0032940691998512963, "phrase": "problem_domain"}, {"score": 0.003226209534553224, "phrase": "metric_function"}, {"score": 0.0031597433845085092, "phrase": "nearest-neighbor_classification_procedure"}, {"score": 0.0031107911390188055, "phrase": "bag-of-visual_words_scheme"}, {"score": 0.0029530125680590413, "phrase": "codebook_construction"}, {"score": 0.0029072537537959374, "phrase": "voronoi_tessellation"}, {"score": 0.0028622019660721363, "phrase": "feature_space"}, {"score": 0.0026888503045081505, "phrase": "learned_weighted_distance"}, {"score": 0.0026471739851621143, "phrase": "extracted_feature_vectors"}, {"score": 0.0025657442830956017, "phrase": "voronoi_cells"}, {"score": 0.0025259712348798323, "phrase": "strong_indication"}, {"score": 0.0024868131939261716, "phrase": "image's_category"}, {"score": 0.002324007171619245, "phrase": "indoor_scene_recognition_benchmark"}, {"score": 0.0022879728308318205, "phrase": "competitive_results"}, {"score": 0.0022524959504997303, "phrase": "general_scene"}, {"score": 0.0021945833590668973, "phrase": "single_type"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Scene classification", " Indoor scene recognition", " Nearest Neighbor classifier", " Bag-of-visual words"], "paper_abstract": "Indoor scene recognition is a challenging problem in the classical scene recognition domain due to the severe intra-class variations and inter-class similarities of man-made indoor structures. State-of-the-art scene recognition techniques such as capturing holistic representations of an image demonstrate low performance on indoor scenes. Other methods that introduce intermediate steps such as identifying objects and associating them with scenes have the handicap of successfully localizing and recognizing the objects in a highly cluttered and sophisticated environment. We propose a classification method that can handle such difficulties of the problem domain by employing a metric function based on the Nearest-Neighbor classification procedure using the bag-of-visual words scheme, the so-called codebooks. Considering the codebook construction as a Voronoi tessellation of the feature space, we have observed that, given an image, a learned weighted distance of the extracted feature vectors to the center of the Voronoi cells gives a strong indication of the image's category. Our method outperforms state-of-the-art approaches on an indoor scene recognition benchmark and achieves competitive results on a general scene dataset, using a single type of descriptor. (C) 2011 Elsevier Inc. All rights reserved.", "paper_title": "Nearest-Neighbor based Metric Functions for indoor scene recognition", "paper_id": "WOS:000295424200002"}