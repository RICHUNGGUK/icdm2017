{"auto_keywords": [{"score": 0.04484681558552234, "phrase": "based_algorithms"}, {"score": 0.00481495049065317, "phrase": "artificial_neural_network_training"}, {"score": 0.004753670676591174, "phrase": "artificial_neural_network"}, {"score": 0.004693728122870604, "phrase": "ann"}, {"score": 0.0045162169185355, "phrase": "major_challenges"}, {"score": 0.004401955895933783, "phrase": "prediction_model"}, {"score": 0.0043181530164057135, "phrase": "ann._gradient"}, {"score": 0.003774386964733469, "phrase": "ann."}, {"score": 0.003631945391344252, "phrase": "greedy_gradient"}, {"score": 0.003450329424861292, "phrase": "improved_opposition"}, {"score": 0.003194736764837261, "phrase": "momentum_term"}, {"score": 0.002864628676257225, "phrase": "time-varying_parameter"}, {"score": 0.0028100102841877835, "phrase": "search_ability"}, {"score": 0.0027741761880779535, "phrase": "standard_pso"}, {"score": 0.0027212777001495154, "phrase": "constriction_factor"}, {"score": 0.0026865721000905235, "phrase": "particles_convergence"}, {"score": 0.0025521085778978042, "phrase": "weight_space"}, {"score": 0.0025034338848015187, "phrase": "new_cross_validation_method"}, {"score": 0.0023178219772486868, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Artificial Neural Networks", " Hybrid training algorithm", " Particle swarm optimization", " Backpropagation algorithm", " Cross validation", " Time-varying parameter"], "paper_abstract": "Artificial neural network (ANN) training is one of the major challenges in using a prediction model based on ANN. Gradient based algorithms are the most frequent training algorithms with several drawbacks. The aim of this paper is to present a method for training ANN. The ability of metaheuristics and greedy gradient based algorithms are combined to obtain a hybrid improved opposition based particle swarm optimization and a back propagation algorithm with the momentum term. Opposition based learning and random perturbation help population diversification during the iteration. Use of time-varying parameter improves the search ability of standard PSO, and constriction factor guarantees particles convergence. Since several contingent local minima conditions may happen in the weight space, a new cross validation method is proposed to prevent overfitting. Effectiveness and efficiency of the proposed method are compared with several other famous ANN training algorithms on the various benchmark problems. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "A hybrid algorithm for artificial neural network training", "paper_id": "WOS:000313855000024"}