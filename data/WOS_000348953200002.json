{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "input_modality_choice"}, {"score": 0.037045008134528865, "phrase": "modality_efficiency"}, {"score": 0.03661511892018969, "phrase": "input_performance"}, {"score": 0.004671932143798307, "phrase": "speech_interfaces"}, {"score": 0.004372002674739612, "phrase": "mobile_application"}, {"score": 0.004293584349522444, "phrase": "graphical_input"}, {"score": 0.004140924670517666, "phrase": "speech_interface"}, {"score": 0.003945754887845885, "phrase": "multimodal_interaction"}, {"score": 0.0037371212381934853, "phrase": "multimodal_human-computer_interaction"}, {"score": 0.0035824802350703376, "phrase": "experimental_results"}, {"score": 0.0034342161742428635, "phrase": "important_moderators"}, {"score": 0.0033929894721242367, "phrase": "modality_choice"}, {"score": 0.003252542052430779, "phrase": "utility-driven_model"}, {"score": 0.0031941384895530426, "phrase": "probability_estimations"}, {"score": 0.003155784719225786, "phrase": "modality_usage"}, {"score": 0.002830617996609902, "phrase": "training_data"}, {"score": 0.0027298319171606498, "phrase": "sequential_least_squares_programming"}, {"score": 0.0026326249204932733, "phrase": "considerable_fit"}, {"score": 0.002600995957987461, "phrase": "averaged_modality_usage"}, {"score": 0.0025235718883452585, "phrase": "individual_modality_usage_profiles"}, {"score": 0.002389956401870098, "phrase": "application_example"}, {"score": 0.002304824112812496, "phrase": "modality_choice_mechanism"}, {"score": 0.002156529381840657, "phrase": "automatic_usability_evaluation"}, {"score": 0.0021049977753042253, "phrase": "possible_limitations"}], "paper_keywords": ["Multimodal human-computer interaction", " Modality choice", " User modeling", " Simulation", " Automatic usability evaluation"], "paper_abstract": "In this paper, we review three experiments with a mobile application that integrates graphical input with a touch-screen and a speech interface and develop a model for input modality choice in multimodal interaction. The model aims to enable simulation of multimodal human-computer interaction for automatic usability evaluation. The experimental results indicate that modality efficiency and input performance are important moderators of modality choice. Accordingly, we establish a utility-driven model that provides probability estimations of modality usage, based on the parameters of modality efficiency and input performance. Four variants of the model that differ in training data are fitted by means of Sequential Least Squares Programming. The analysis reveals a considerable fit regarding averaged modality usage. When applied to individual modality usage profiles, the accuracy decreases significantly. In an application example it is shown how the modality choice mechanism can be deployed for simulating interaction in the field of automatic usability evaluation. Results and possible limitations are discussed. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Modeling input modality choice in mobile graphical and speech interfaces", "paper_id": "WOS:000348953200002"}