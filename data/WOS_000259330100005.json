{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "agents_epistemic_state"}, {"score": 0.004334280585565239, "phrase": "belief_revision"}, {"score": 0.003113441660343867, "phrase": "reverse_engineering_approach"}, {"score": 0.0029095936591723645, "phrase": "iterated_belief_revision"}, {"score": 0.002447101794397243, "phrase": "best-explaining_model"}, {"score": 0.0023214774334744713, "phrase": "epistemic_behaviour"}, {"score": 0.0021049977753042253, "phrase": "best_explanation"}], "paper_keywords": ["belief revision", " non-monotonic reasoning", " iterated revision", " non-prioritised revision", " rational closure", " rational explanation", " multi-agent systems"], "paper_abstract": "We look at the problem in belief revision of trying to make inferences about what an agent believed - or will believe - at a given moment, based on an observation of how the agent has responded to some sequence of previous belief revision inputs over time. We adopt a reverse engineering approach to this problem. Assuming a framework for iterated belief revision which is based on sequences, we construct a model of the agent that best explains the observation. Further considerations on this best-explaining model then allow inferences about the agents epistemic behaviour to be made. We also provide an algorithm which computes this best explanation.", "paper_title": "Reconstructing an agents epistemic state from observations about its beliefs and non-beliefs", "paper_id": "WOS:000259330100005"}