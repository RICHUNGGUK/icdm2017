{"auto_keywords": [{"score": 0.03466947857283771, "phrase": "accuracy_measures"}, {"score": 0.00481495049065317, "phrase": "recommendation_biases"}, {"score": 0.004772367030970874, "phrase": "possible_countermeasures"}, {"score": 0.004626255242038005, "phrase": "commercial_context"}, {"score": 0.00450456611645112, "phrase": "value-adding_service"}, {"score": 0.00436661740263741, "phrase": "social_web_platforms"}, {"score": 0.004308791766002289, "phrase": "typical_success_indicators"}, {"score": 0.004232875294230749, "phrase": "conversion_rates"}, {"score": 0.004195418010131832, "phrase": "customer_loyalty"}, {"score": 0.004158290806404304, "phrase": "sales_numbers"}, {"score": 0.004103212598803194, "phrase": "academic_research"}, {"score": 0.0039248128268720645, "phrase": "different_recommendation_algorithms"}, {"score": 0.0038385317554884713, "phrase": "offline_experimental_designs"}, {"score": 0.003606866938661143, "phrase": "algorithm's_recommendation_quality"}, {"score": 0.003465350958971198, "phrase": "popular_recommendation_techniques"}, {"score": 0.003005539334280134, "phrase": "in-depth_analysis"}, {"score": 0.0029133627624098064, "phrase": "different_perspectives"}, {"score": 0.0028492532869274743, "phrase": "catalog_coverage"}, {"score": 0.0027865506182608263, "phrase": "popular_items"}, {"score": 0.0027131212233443137, "phrase": "recent_techniques"}, {"score": 0.002572001496778222, "phrase": "tiny_fraction"}, {"score": 0.002537880772794665, "phrase": "item_spectrum"}, {"score": 0.0025042115651986332, "phrase": "mostly_top_sellers"}, {"score": 0.002352886041381761, "phrase": "algorithmic_design"}, {"score": 0.002200861826643147, "phrase": "hyperparameter_tuning"}, {"score": 0.0021049977753042253, "phrase": "popularity_biases"}], "paper_keywords": ["Recommender systems", " Bias", " Evaluation"], "paper_abstract": "Most real-world recommender systems are deployed in a commercial context or designed to represent a value-adding service, e.g., on shopping or Social Web platforms, and typical success indicators for such systems include conversion rates, customer loyalty or sales numbers. In academic research, in contrast, the evaluation and comparison of different recommendation algorithms is mostly based on offline experimental designs and accuracy or rank measures which are used as proxies to assess an algorithm's recommendation quality. In this paper, we show that popular recommendation techniques-despite often being similar when compared with the help of accuracy measures-can be quite different with respect to which items they recommend. We report the results of an in-depth analysis in which we compare several recommendations strategies from different perspectives, including accuracy, catalog coverage and their bias to recommend popular items. Our analyses reveal that some recent techniques that perform well with respect to accuracy measures focus their recommendations on a tiny fraction of the item spectrum or recommend mostly top sellers. We analyze the reasons for some of these biases in terms of algorithmic design and parameterization and show how the characteristics of the recommendations can be altered by hyperparameter tuning. Finally, we propose two novel algorithmic schemes to counter these popularity biases.", "paper_title": "What recommenders recommend: an analysis of recommendation biases and possible countermeasures", "paper_id": "WOS:000369848700001"}