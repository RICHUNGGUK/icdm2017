{"auto_keywords": [{"score": 0.040150760158608925, "phrase": "bomi_system"}, {"score": 0.004561019117546361, "phrase": "elbow_movements"}, {"score": 0.004349791059765796, "phrase": "system_users"}, {"score": 0.004120289747942224, "phrase": "engineering_design"}, {"score": 0.003983016985197904, "phrase": "embedded_part"}, {"score": 0.0039028497942174777, "phrase": "functional_design"}, {"score": 0.003772793879444995, "phrase": "real-time_controllability"}, {"score": 0.0036224139706218916, "phrase": "user-specific_dynamic_body_response_signatures"}, {"score": 0.0033167679667625667, "phrase": "user's_body_signals"}, {"score": 0.003141598480804135, "phrase": "user's_body"}, {"score": 0.0030783143919343972, "phrase": "virtual_reality_device-control_space"}, {"score": 0.002598034157587518, "phrase": "human_body_signals"}, {"score": 0.0025630077791393125, "phrase": "multiple_degrees"}, {"score": 0.0024607296642187824, "phrase": "robotic_wheelchair_navigation_task"}, {"score": 0.0022992346264367374, "phrase": "machine_learning"}, {"score": 0.0021049977753042253, "phrase": "human_body"}], "paper_keywords": ["Wearable sensors", " Robotics", " Virtual reality"], "paper_abstract": "This paper presents the design and performance of a body-machine-interface (BoMI) system, where a user controls a robotic 3D virtual wheelchair with the signals derived from his/her shoulder and elbow movements. BoMI promotes the perspective that system users should no longer be operators of the engineering design but should be an embedded part of the functional design. This BoMI system has real-time controllability of robotic devices based on user-specific dynamic body response signatures in high-density 52-channel sensor shirt. The BoMI system not only gives access to the user's body signals, but also translates these signals from user's body to the virtual reality device-control space. We have explored the efficiency of this BoMI system in a semi-cylinderic 3D virtual reality system. Experimental studies are conducted to demonstrate, how this transformation of human body signals of multiple degrees of freedom, controls a robotic wheelchair navigation task in a 3D virtual reality environment. We have also presented how machine learning can enhance the interface to adapt towards the degree of freedoms of human body by correcting the errors performed by the user.", "paper_title": "A Sensorized Garment Controlled Virtual Robotic Wheelchair", "paper_id": "WOS:000336449900017"}