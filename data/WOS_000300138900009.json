{"auto_keywords": [{"score": 0.048989156600390535, "phrase": "slr"}, {"score": 0.01321060560169491, "phrase": "pattern_recognition"}, {"score": 0.00972841819005929, "phrase": "extended_him"}, {"score": 0.00481495049065317, "phrase": "bioinspired_hierarchical_temporal_memory_paradigm"}, {"score": 0.0047325016751114165, "phrase": "sign_language_recognition"}, {"score": 0.0046648687677450455, "phrase": "spatial_positions"}, {"score": 0.0045324756541157574, "phrase": "challenging_multi-variable_time_series_recognition_problem"}, {"score": 0.004391159805197013, "phrase": "slr_purposes"}, {"score": 0.0043533862892678864, "phrase": "hierarchically_connected_network"}, {"score": 0.004278807087784626, "phrase": "bayesian-like_paradigm"}, {"score": 0.004241995931481941, "phrase": "hierarchical_temporal_memory"}, {"score": 0.0041693170015901235, "phrase": "neocortical_principles"}, {"score": 0.0041215546273657795, "phrase": "information_coding"}, {"score": 0.004062617218035532, "phrase": "broad_paradigm"}, {"score": 0.003970058383807247, "phrase": "forward_prediction"}, {"score": 0.0038351438570038195, "phrase": "physical_world"}, {"score": 0.003694136180797615, "phrase": "htm_capabilities"}, {"score": 0.003620360845720931, "phrase": "traditional_him_paradigm"}, {"score": 0.003589193972443107, "phrase": "original_top_node"}, {"score": 0.00353784217050407, "phrase": "htms_performance"}, {"score": 0.00335896380465609, "phrase": "spatio-temporally_codified_inputs"}, {"score": 0.0033204536265162114, "phrase": "temporal_evolution"}, {"score": 0.003282383509542342, "phrase": "sign_language"}, {"score": 0.003263511910710557, "phrase": "sequence_comparison"}, {"score": 0.0032075435331011173, "phrase": "needleman-wunsch_algorithm"}, {"score": 0.003152531962718477, "phrase": "dynamic_programming"}, {"score": 0.00308064351528802, "phrase": "extended_htm"}, {"score": 0.0030629282276491403, "phrase": "traditional_htms"}, {"score": 0.00304531450085166, "phrase": "machine_learning_algorithms"}, {"score": 0.0029844581454509297, "phrase": "slr."}, {"score": 0.0029332611651817528, "phrase": "traditional_him"}, {"score": 0.0028663584600000023, "phrase": "data_set"}, {"score": 0.002833479895505502, "phrase": "australian_sign_language"}, {"score": 0.0028090680055739203, "phrase": "sufficient_training_instances"}, {"score": 0.0027688467116177614, "phrase": "extended_htm_matches"}, {"score": 0.002721338551347818, "phrase": "art_methods"}, {"score": 0.002682370021834353, "phrase": "hidden_markov_models"}, {"score": 0.00266693888510356, "phrase": "metafeatures_t-classes"}, {"score": 0.0026211746739675927, "phrase": "language_model"}, {"score": 0.002583636737108568, "phrase": "sensor_data"}, {"score": 0.0025466350097711407, "phrase": "relatively_small_feature_vectors"}, {"score": 0.00245997322259401, "phrase": "spatio-temporal_data_structures"}, {"score": 0.002383120224166142, "phrase": "manually_predefined_features"}, {"score": 0.00232202561027509, "phrase": "real_time"}, {"score": 0.0022755900116918923, "phrase": "extended_him_approach"}, {"score": 0.002255973756526505, "phrase": "valid_bioinspired_alternative"}, {"score": 0.0022429900751970797, "phrase": "existing_slr_engines"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Encoding", " Motion analysis", " Multidimensional sequences", " Multidimensional signal processing", " Neural network architecture", " Pattern recognition", " Hierarchical temporal memory"], "paper_abstract": "Sign language recognition, SLR, using spatial positions and arrangements of the hands over time is a challenging multi-variable time series recognition problem with several potential applications. Here we explore, for SLR purposes, a hierarchically connected network of nodes based on a Bayesian-like paradigm known as hierarchical temporal memory, HIM, that models neocortical principles of organization and information coding. HIM is a broad paradigm for pattern recognition, control, attention and forward prediction that exploits the hierarchy in time and space existing in the physical world during both learning and inference. In this work we focus on HTM capabilities for pattern recognition. We extend the traditional HIM paradigm with an original top node in order to improve HTMs performance in problems where instances unfold over time. The extended top node stores and compares sequences of spatio-temporally codified inputs to handle the temporal evolution of instances in sign language. Sequence comparison is carried out using the Needleman-Wunsch algorithm for sequence alignment that employs dynamic programming. We compare the performance of the extended HTM with traditional HTMs and machine learning algorithms routinely used in the literature for SLR. The extended HIM improves performance of traditional HIM for SLR, reaching 91% recognition accuracy for a data set of 95 categories of Australian sign language. When sufficient training instances are available, the extended HTM matches or outperforms state of the art methods for SLR such as Hidden Markov Models or Metafeatures T-Classes without the usage of a language model, nor preprocessing of sensor data. The extended HIM employs relatively small feature vectors in comparison to methods in the literature. Our method learns the spatio-temporal data structures and transitions that occur in the data without depending on manually predefined features to be searched for and works well in real time. These results suggest that the extended HIM approach is a valid bioinspired alternative to existing SLR engines and that it can be successfully applied to other machine learning tasks whose input instances also unfold over time. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Extending the bioinspired hierarchical temporal memory paradigm for sign language recognition", "paper_id": "WOS:000300138900009"}