{"auto_keywords": [{"score": 0.028490167836718976, "phrase": "high-fuzziness_samples"}, {"score": 0.00481495049065317, "phrase": "classifier_performance_improvement"}, {"score": 0.004208002469225673, "phrase": "misclassification_rate"}, {"score": 0.0036443694410100507, "phrase": "membership_vector"}, {"score": 0.0033914308417007316, "phrase": "higher_fuzziness"}, {"score": 0.0031845067058084583, "phrase": "bigger_risk"}, {"score": 0.002963390095037466, "phrase": "fuzziness_category"}, {"score": 0.0026126405272417783, "phrase": "low_fuzziness_samples"}, {"score": 0.002543043781904587, "phrase": "particular_technique"}, {"score": 0.0023241387549221408, "phrase": "classifier_performance"}], "paper_keywords": ["Fuzziness", " misclassification", " generalization", " boundary point", " Divide-and-Conquer strategy"], "paper_abstract": "This paper investigates a relationship between the fuzziness of a classifier and the misclassification rate of the classifier on a group of samples. For a given trained classifier that outputs a membership vector, we demonstrate experimentally that samples with higher fuzziness outputted by the classifier mean a bigger risk of misclassification. We then propose a fuzziness category based divide-and-conquer strategy which separates the high-fuzziness samples from the low fuzziness samples. A particular technique is used to handle the high-fuzziness samples for promoting the classifier performance. The reasonability of the approach is theoretically explained and its effectiveness is experimentally demonstrated.", "paper_title": "Fuzziness based sample categorization for classifier performance improvement", "paper_id": "WOS:000362970400016"}