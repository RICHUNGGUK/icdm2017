{"auto_keywords": [{"score": 0.046133894713162954, "phrase": "multi-view_videos"}, {"score": 0.040855906235626405, "phrase": "spatio-temporal_shot_graph"}, {"score": 0.00481495049065317, "phrase": "multi-view_video_summarization"}, {"score": 0.004771672073078768, "phrase": "previous_video_summarization_studies"}, {"score": 0.004707479285061122, "phrase": "monocular_videos"}, {"score": 0.004204904449336037, "phrase": "multiple_views"}, {"score": 0.0038242899532391914, "phrase": "summarization_problem"}, {"score": 0.003772793879444995, "phrase": "graph_labeling_task"}, {"score": 0.003525493807130663, "phrase": "different_attributes"}, {"score": 0.0034937647771945803, "phrase": "multi-view_video_shots"}, {"score": 0.003369669078274226, "phrase": "shot_graph"}, {"score": 0.003294350220187021, "phrase": "event-centered_shots"}, {"score": 0.003220709449062307, "phrase": "random_walks"}, {"score": 0.0031773149810690494, "phrase": "summarization_result"}, {"score": 0.0030922667860233603, "phrase": "multi-objective_optimization_problem"}, {"score": 0.00298238929037041, "phrase": "gaussian_entropy_fusion_scheme"}, {"score": 0.002955533639862811, "phrase": "different_summarization_objectives"}, {"score": 0.0029025435402480326, "phrase": "minimum_summary_length"}, {"score": 0.0028764048059439205, "phrase": "maximum_information_coverage"}, {"score": 0.002627587221594597, "phrase": "optimization_parameters"}, {"score": 0.0025572160146590623, "phrase": "multi-view_storyboard"}, {"score": 0.002488724764295623, "phrase": "multi-view_summaries"}, {"score": 0.002400241288973103, "phrase": "multi-view_summarized_shots"}, {"score": 0.0022940375532231145, "phrase": "event-centered_multi-view_shots"}, {"score": 0.0022427071130840647, "phrase": "single_video_summary"}, {"score": 0.002212460584002629, "phrase": "quick_browsing"}, {"score": 0.0021826210858934933, "phrase": "summarized_multi-view_video"}, {"score": 0.0021049977753042253, "phrase": "event_board_representation"}], "paper_keywords": ["Multi-objective optimization", " multi-view video", " random walks", " spatio-temporal graph", " video summarization"], "paper_abstract": "Previous video summarization studies focused on monocular videos, and the results would not be good if they were applied to multi-view videos directly, due to problems such as the redundancy in multiple views. In this paper, we present a method for summarizing multi-view videos. We construct a spatio-temporal shot graph and formulate the summarization problem as a graph labeling task. The spatio-temporal shot graph is derived from a hypergraph, which encodes the correlations with different attributes among multi-view video shots in hyperedges. We then partition the shot graph and identify clusters of event-centered shots with similar contents via random walks. The summarization result is generated through solving a multi-objective optimization problem based on shot importance evaluated using a Gaussian entropy fusion scheme. Different summarization objectives, such as minimum summary length and maximum information coverage, can be accomplished in the framework. Moreover, multi-level summarization can be achieved easily by configuring the optimization parameters. We also propose the multi-view storyboard and event board for presenting multi-view summaries. The storyboard naturally reflects correlations among multi-view summarized shots that describe the same important event. The event-board serially assembles event-centered multi-view shots in temporal order. Single video summary which facilitates quick browsing of the summarized multi-view video can be easily generated based on the event board representation.", "paper_title": "Multi-View Video Summarization", "paper_id": "WOS:000283448500009"}