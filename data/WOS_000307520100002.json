{"auto_keywords": [{"score": 0.0383084906782155, "phrase": "uncertain_data"}, {"score": 0.015556930206334117, "phrase": "positive_and_unlabelled_examples"}, {"score": 0.00481495049065317, "phrase": "naive_bayes_classifiers"}, {"score": 0.004665296491645837, "phrase": "traditional_classification_algorithms"}, {"score": 0.004592214823540993, "phrase": "large_number"}, {"score": 0.004544127927346964, "phrase": "labelled_examples"}, {"score": 0.004155113657645735, "phrase": "data_uncertainty"}, {"score": 0.00398370478688858, "phrase": "sensor_network"}, {"score": 0.003941964605885606, "phrase": "market_analysis"}, {"score": 0.0039006600544599537, "phrase": "medical_diagnosis"}, {"score": 0.0034193226278107346, "phrase": "naive_bayes_classifier"}, {"score": 0.003209782650616367, "phrase": "prior_probability"}, {"score": 0.0031761255583359726, "phrase": "positive_class"}, {"score": 0.002813457986293993, "phrase": "user-specified_parameter"}, {"score": 0.002613239644974825, "phrase": "appropriate_value"}, {"score": 0.002326938965568362, "phrase": "satisfactory_classification_performance"}, {"score": 0.0021385822825864425, "phrase": "better_classification_performance"}, {"score": 0.0021049977753042253, "phrase": "traditional_naive_bayes"}], "paper_keywords": ["positive unlabelled learning", " uncertain data", " naive Bayes", " positive naive Bayes"], "paper_abstract": "Traditional classification algorithms require a large number of labelled examples from all the predefined classes, which is generally difficult and time-consuming to obtain. Furthermore, data uncertainty is prevalent in many real-world applications, such as sensor network, market analysis and medical diagnosis. In this article, we explore the issue of classification on uncertain data when only positive and unlabelled examples are available. We propose an algorithm to build naive Bayes classifier from positive and unlabelled examples with uncertainty. However, the algorithm requires the prior probability of positive class, and it is generally difficult for the user to provide this parameter in practice. Two approaches are proposed to avoid this user-specified parameter. One approach is to use a validation set to search for an appropriate value for this parameter, and the other is to estimate it directly. Our extensive experiments show that the two approaches can basically achieve satisfactory classification performance on uncertain data. In addition, our algorithm exploiting uncertainty in the dataset can potentially achieve better classification performance comparing to traditional naive Bayes which ignores uncertainty when handling uncertain data.", "paper_title": "Learning naive Bayes classifiers from positive and unlabelled examples with uncertainty", "paper_id": "WOS:000307520100002"}