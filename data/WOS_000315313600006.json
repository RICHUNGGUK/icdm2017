{"auto_keywords": [{"score": 0.035620716932052585, "phrase": "optimal_bayesian_classifiers"}, {"score": 0.00481495049065317, "phrase": "minimum_expected_error"}, {"score": 0.004734448316824488, "phrase": "bayesian_framework_-_part_ii"}, {"score": 0.004425616928975799, "phrase": "two-part_study"}, {"score": 0.0043029342321223825, "phrase": "new_optimal_bayesian_classification_methodology"}, {"score": 0.00413684709497912, "phrase": "bayesian_minimum-mean-square_error"}, {"score": 0.00409062485091255, "phrase": "mmse"}, {"score": 0.00397714507836836, "phrase": "optimal_bayesian_classification"}, {"score": 0.003888659470009222, "phrase": "bayesian_theory"}, {"score": 0.00345530020388352, "phrase": "assumed_model"}, {"score": 0.0033405704229694656, "phrase": "discrete_and_gaussian_models"}, {"score": 0.003035711716881469, "phrase": "invertible_transformations"}, {"score": 0.002951444412262927, "phrase": "bayes_classifier"}, {"score": 0.002853396755102163, "phrase": "bayesian_robust_classifiers"}, {"score": 0.002727700630869639, "phrase": "non-informative_priors"}, {"score": 0.002607527117561699, "phrase": "quadratic_discriminant_analysis"}, {"score": 0.002578407015048409, "phrase": "lda"}, {"score": 0.0025494365029840554, "phrase": "qda"}, {"score": 0.0024370965602952496, "phrase": "plug-in_rules"}, {"score": 0.0024097920845706795, "phrase": "gaussian_modeling_assumptions"}, {"score": 0.0022396019251440724, "phrase": "false_modeling_assumptions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Bayesian estimation", " Classification", " Error estimation", " Genomics", " Minimum mean-square estimation", " Small samples"], "paper_abstract": "In part I of this two-part study, we introduced a new optimal Bayesian classification methodology that utilizes the same modeling framework proposed in Bayesian minimum-mean-square error (MMSE) error estimation. Optimal Bayesian classification thus completes a Bayesian theory of classification, where both the classifier error and our estimate of the error may be simultaneously optimized and studied probabilistically within the assumed model. Having developed optimal Bayesian classifiers in discrete and Gaussian models in part I, here we explore properties of optimal Bayesian classifiers, in particular, invariance to invertible transformations, convergence to the Bayes classifier, and a connection to Bayesian robust classifiers. We also explicitly derive optimal Bayesian classifiers with non-informative priors, and explore relationships to linear and quadratic discriminant analysis (LDA and QDA), which may be viewed as plug-in rules under Gaussian modeling assumptions. Finally, we present several simulations addressing the robustness of optimal Bayesian classifiers to false modeling assumptions. Companion website: http://gsp.tamu.edu/Publications/supplementary/dalton12a. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Optimal classifiers with minimum expected error within a Bayesian framework - Part II: Properties and performance analysis", "paper_id": "WOS:000315313600006"}