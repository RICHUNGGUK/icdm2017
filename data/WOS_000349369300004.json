{"auto_keywords": [{"score": 0.044079538984485474, "phrase": "mts"}, {"score": 0.019899787089915418, "phrase": "time_index"}, {"score": 0.007045265850138568, "phrase": "smts"}, {"score": 0.00481495049065317, "phrase": "symbolic_representation"}, {"score": 0.004786519708868553, "phrase": "multivariate_time_series_classification"}, {"score": 0.004758255999331728, "phrase": "multivariate_time_series"}, {"score": 0.004592128194844475, "phrase": "temporal_datasets"}, {"score": 0.004565007074039171, "phrase": "different_domains"}, {"score": 0.004379572106088617, "phrase": "similarity-based_approaches"}, {"score": 0.004327981760540394, "phrase": "nearest-neighbor_classifiers"}, {"score": 0.004251728624599691, "phrase": "univariate_time_series"}, {"score": 0.004139850082354509, "phrase": "individual_attributes"}, {"score": 0.003959863717046575, "phrase": "new_symbolic_representation"}, {"score": 0.0035590664550919854, "phrase": "supervised_algorithm"}, {"score": 0.0035066948004186076, "phrase": "pre-defined_intervals"}, {"score": 0.003444861556939966, "phrase": "elementary_representation"}, {"score": 0.0032755054812060444, "phrase": "numerical_attributes"}, {"score": 0.0032368785020224725, "phrase": "individual_time_series"}, {"score": 0.003151619859498847, "phrase": "essentially_no_feature_extraction"}, {"score": 0.003114449258490062, "phrase": "first_differences"}, {"score": 0.0030777156987044385, "phrase": "local_series_values"}, {"score": 0.0030414140732789186, "phrase": "time_position"}, {"score": 0.0029877604856619806, "phrase": "initial_representation"}, {"score": 0.0029700864920418554, "phrase": "raw_data"}, {"score": 0.002874726518572154, "phrase": "tree-based_ensemble"}, {"score": 0.0027824197043924527, "phrase": "time_values"}, {"score": 0.002717149533691728, "phrase": "high-dimensional_codebook"}, {"score": 0.002693068835869533, "phrase": "terminal_nodes"}, {"score": 0.0023987234349331383, "phrase": "second_ensemble"}, {"score": 0.0023774580561555913, "phrase": "implicit_feature_selection"}, {"score": 0.002335489878370869, "phrase": "high-dimensional_input"}, {"score": 0.002314783782656802, "phrase": "constituent_properties"}, {"score": 0.0022942608418577313, "phrase": "distinctly_different_algorithm"}, {"score": 0.002253757988526137, "phrase": "nominal_and_missing_values"}, {"score": 0.002220551141101661, "phrase": "tree_learners"}, {"score": 0.002168432656901106, "phrase": "proposed_approach"}], "paper_keywords": ["Supervised learning", " Codebook", " Decision trees"], "paper_abstract": "Multivariate time series (MTS) classification has gained importance with the increase in the number of temporal datasets in different domains (such as medicine, finance, multimedia, etc.). Similarity-based approaches, such as nearest-neighbor classifiers, are often used for univariate time series, but MTS are characterized not only by individual attributes, but also by their relationships. Here we provide a classifier based on a new symbolic representation for MTS (denoted as SMTS) with several important elements. SMTS considers all attributes of MTS simultaneously, rather than separately, to extract information contained in the relationships. Symbols are learned from a supervised algorithm that does not require pre-defined intervals, nor features. An elementary representation is used that consists of the time index, and the values (and first differences for numerical attributes) of the individual time series as columns. That is, there is essentially no feature extraction (aside from first differences) and the local series values are fused to time position through the time index. The initial representation of raw data is quite simple conceptually and operationally. Still, a tree-based ensemble can detect interactions in the space of the time index and time values and this is exploited to generate a high-dimensional codebook from the terminal nodes of the trees. Because the time index is included as an attribute, each MTS is learned to be segmented by time, or by the value of one of its attributes. The codebook is processed with a second ensemble where now implicit feature selection is exploited to handle the high-dimensional input. The constituent properties produce a distinctly different algorithm. Moreover, MTS with nominal and missing values are handled efficiently with tree learners. Experiments demonstrate the effectiveness of the proposed approach in terms of accuracy and computation times in a large collection multivariate (and univariate) datasets.", "paper_title": "Learning a symbolic representation for multivariate time series classification", "paper_id": "WOS:000349369300004"}