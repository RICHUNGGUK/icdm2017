{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "based_semi-supervised_learning"}, {"score": 0.003703282519292336, "phrase": "reverse_direction"}, {"score": 0.003501991125315889, "phrase": "oppositely_labelled_points"}, {"score": 0.003348838095597268, "phrase": "undesirable_edges"}, {"score": 0.003202361402737197, "phrase": "informative_point"}, {"score": 0.002677616534005393, "phrase": "optimization_criterion"}, {"score": 0.0025892330566358503, "phrase": "labelled_points"}, {"score": 0.0024620842899061614, "phrase": "wide_variety"}, {"score": 0.0023807981747706376, "phrase": "current_paper"}, {"score": 0.0021049977753042253, "phrase": "publicly_available_benchmark_data_sets"}], "paper_keywords": [""], "paper_abstract": "In many graph-based semi-supervised learning algorithms, edge weights are assumed to be fixed and determined by the data points' (often symmetric) relationships in input space, without considering directionality. However, relationships may be more informative in one direction (e.g. from labelled to unlabelled) than in the reverse direction, and some relationships (e.g. strong weights between oppositely labelled points) are unhelpful in either direction. Undesirable edges may reduce the amount of influence an informative point can propagate to its neighbours-the point and its outgoing edges have been \"blunted.\" We present an approach to \"sharpening\" in which weights are adjusted to meet an optimization criterion wherever they are directed towards labelled points. This principle can be applied to a wide variety of algorithms. In the current paper, we present one ad hoc solution satisfying the principle, in order to show that it can improve performance on a number of publicly available benchmark data sets.", "paper_title": "Graph based semi-supervised learning with sharper edges", "paper_id": "WOS:000242308000034"}