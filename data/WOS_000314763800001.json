{"auto_keywords": [{"score": 0.0365481469656163, "phrase": "point-based_value_iteration"}, {"score": 0.00481495049065317, "phrase": "point-based_pomdp_solvers"}, {"score": 0.004675768396728975, "phrase": "significant_breakthrough"}, {"score": 0.004519703452803668, "phrase": "markov"}, {"score": 0.004240116703465252, "phrase": "perhaps_a_dozen_states"}, {"score": 0.0041174821422410544, "phrase": "complex_domains"}, {"score": 0.0038074544783102226, "phrase": "value_function_computations"}, {"score": 0.0037519679864796906, "phrase": "finite_subset"}, {"score": 0.003697287104870263, "phrase": "belief_space"}, {"score": 0.0034020946201397057, "phrase": "exponential_growth"}, {"score": 0.0033524956061690868, "phrase": "value_function"}, {"score": 0.0032079813320482304, "phrase": "longer_horizons"}, {"score": 0.0031457622320220364, "phrase": "relatively_large_state_spaces"}, {"score": 0.003024909947609294, "phrase": "basic_idea"}, {"score": 0.0029229677574293725, "phrase": "algorithm-mainly_the_selection"}, {"score": 0.002880333728285514, "phrase": "belief_space_subset"}, {"score": 0.002535876002754739, "phrase": "main_concepts"}, {"score": 0.0024264776194357993, "phrase": "major_extensions"}, {"score": 0.002391067964886602, "phrase": "basic_algorithm"}, {"score": 0.002276717177453959, "phrase": "extensive_empirical_analysis"}, {"score": 0.002254510319372956, "phrase": "well_known_benchmarks"}], "paper_keywords": ["Partially observable Markov decision processes", " Decision-theoretic planning", " Reinforcement learning"], "paper_abstract": "The past decade has seen a significant breakthrough in research on solving partially observable Markov decision processes (POMDPs). Where past solvers could not scale beyond perhaps a dozen states, modern solvers can handle complex domains with many thousands of states. This breakthrough was mainly due to the idea of restricting value function computations to a finite subset of the belief space, permitting only local value updates for this subset. This approach, known as point-based value iteration, avoids the exponential growth of the value function, and is thus applicable for domains with longer horizons, even with relatively large state spaces. Many extensions were suggested to this basic idea, focusing on various aspects of the algorithm-mainly the selection of the belief space subset, and the order of value function updates. In this survey, we walk the reader through the fundamentals of point-based value iteration, explaining the main concepts and ideas. Then, we survey the major extensions to the basic algorithm, discussing their merits. Finally, we include an extensive empirical analysis using well known benchmarks, in order to shed light on the strengths and limitations of the various approaches.", "paper_title": "A survey of point-based POMDP solvers", "paper_id": "WOS:000314763800001"}