{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "data_fusion"}, {"score": 0.004535481695403089, "phrase": "diverse_modalities"}, {"score": 0.004366106816225457, "phrase": "sensor_networks"}, {"score": 0.004272164161788242, "phrase": "single_event"}, {"score": 0.004203030435498069, "phrase": "large_number"}, {"score": 0.004157561334726201, "phrase": "vantage_points"}, {"score": 0.004090274535243564, "phrase": "multiple_modalities"}, {"score": 0.003916098498242888, "phrase": "large_amounts"}, {"score": 0.0037697665240643066, "phrase": "even_a_relatively_small_network"}, {"score": 0.003668591097652231, "phrase": "massive_amounts"}, {"score": 0.0036288825833675127, "phrase": "high-dimensional_image_and_video_data"}, {"score": 0.0034742854447532678, "phrase": "data_deluge"}, {"score": 0.003399466007862412, "phrase": "low-dimensional_data_models"}, {"score": 0.003290237137651949, "phrase": "particularly_powerful_theoretical_and_algorithmic_framework"}, {"score": 0.003115908199991072, "phrase": "small_number"}, {"score": 0.002934764205541183, "phrase": "sensor_network"}, {"score": 0.0027641218567092665, "phrase": "account_dependencies"}, {"score": 0.0027341763737751467, "phrase": "multiple_sensors"}, {"score": 0.002646267286675984, "phrase": "new_joint_manifold_framework"}, {"score": 0.0024923577071656014, "phrase": "joint_manifold_structure"}, {"score": 0.0024386325347607674, "phrase": "improved_performance"}, {"score": 0.0023730978395564116, "phrase": "signal_processing_algorithms"}, {"score": 0.0022967713922705, "phrase": "manifold_learning"}, {"score": 0.0022472527731744974, "phrase": "recent_results"}, {"score": 0.0022228943786652914, "phrase": "random_projections"}, {"score": 0.0021049977753042253, "phrase": "universal_dimensionality_reduction_scheme"}], "paper_keywords": ["Camera networks", " classification", " data fusion", " manifold learning", " random projections", " sensor networks"], "paper_abstract": "The emergence of low-cost sensing architectures for diverse modalities has made it possible to deploy sensor networks that capture a single event from a large number of vantage points and using multiple modalities. In many scenarios, these networks acquire large amounts of very high-dimensional data. For example, even a relatively small network of cameras can generate massive amounts of high-dimensional image and video data. One way to cope with this data deluge is to exploit low-dimensional data models. Manifold models provide a particularly powerful theoretical and algorithmic framework for capturing the structure of data governed by a small number of parameters, as is often the case in a sensor network. However, these models do not typically take into account dependencies among multiple sensors. We thus propose a new joint manifold framework for data ensembles that exploits such dependencies. We show that joint manifold structure can lead to improved performance for a variety of signal processing algorithms for applications including classification and manifold learning. Additionally, recent results concerning random projections of manifolds enable us to formulate a scalable and universal dimensionality reduction scheme that efficiently fuses the data from all sensors.", "paper_title": "Joint Manifolds for Data Fusion", "paper_id": "WOS:000283593800007"}