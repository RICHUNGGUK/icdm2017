{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "fixed_effects"}, {"score": 0.004764859786310636, "phrase": "high_dimensional_linear_mixed_models"}, {"score": 0.004690694501758065, "phrase": "multicycle_ecm_algorithm"}, {"score": 0.004641890423057823, "phrase": "linear_mixed_models"}, {"score": 0.004382364826200616, "phrase": "high_dimensional_setting"}, {"score": 0.0042692243768616455, "phrase": "fixed_effect"}, {"score": 0.0040942189695983185, "phrase": "classical_tools"}, {"score": 0.003905864553426306, "phrase": "random_effects"}, {"score": 0.003785115566529808, "phrase": "linear_mixed_model_framework"}, {"score": 0.0036680857629458816, "phrase": "fixed_effects_coefficients"}, {"score": 0.003610929883213109, "phrase": "resulting_log-likelihood"}, {"score": 0.0035176353680157367, "phrase": "optimization_problem"}, {"score": 0.0034267429854665035, "phrase": "multicycle_expectation_conditional_maximization"}, {"score": 0.003118486096035156, "phrase": "total_number"}, {"score": 0.002867771524071872, "phrase": "covariance_matrix"}, {"score": 0.002823050755743821, "phrase": "proposed_algorithm"}, {"score": 0.0027356847952125433, "phrase": "variable_selection_method"}, {"score": 0.002693018258362651, "phrase": "linear_models"}, {"score": 0.0026096659285441384, "phrase": "proposed_approach"}, {"score": 0.0025288869172313674, "phrase": "multiple_testing_procedure"}, {"score": 0.0024894376091589244, "phrase": "variable_selection_aspect"}, {"score": 0.002387214876538434, "phrase": "false_discovery_rate"}, {"score": 0.002289180040240783, "phrase": "mms_r-package"}, {"score": 0.002172266188075892, "phrase": "high-dimensional_simulated_setting"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Linear mixed model", " LmmLasso", " Multiple hypothesis testing", " High-dimension"], "paper_abstract": "Linear mixed models are especially useful when observations are grouped. In a high dimensional setting however, selecting the fixed effect coefficients in these models is mandatory as classical tools are not performing well. By considering the random effects as missing values in the linear mixed model framework, a l(1)-penalization on the fixed effects coefficients of the resulting log-likelihood is proposed. The optimization problem is solved via a multicycle Expectation Conditional Maximization (ECM) algorithm which allows for the number of parameters p to be larger than the total number of observations n and does not require the inversion of the sample n x n covariance matrix. The proposed algorithm can be combined with any variable selection method developed for linear models. A variant of the proposed approach replaces the l(1)-penalization with a multiple testing procedure for the variable selection aspect and is shown to greatly improve the False Discovery Rate. Both methods are implemented in the MMS R-package, and are shown to give very satisfying results in a high-dimensional simulated setting. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Selection of fixed effects in high dimensional linear mixed models using a multicycle ECM algorithm", "paper_id": "WOS:000341346300018"}