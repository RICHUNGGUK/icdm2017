{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "consumer_depth_camera"}, {"score": 0.04593811340084708, "phrase": "head_movement"}, {"score": 0.039510674444560676, "phrase": "proposed_system"}, {"score": 0.004769444094319619, "phrase": "existing_eye-gaze-tracking_systems"}, {"score": 0.004548253531664032, "phrase": "high-quality_cameras"}, {"score": 0.004483909657713567, "phrase": "good_performance"}, {"score": 0.004275904315753662, "phrase": "systems'_potential"}, {"score": 0.0042354707960660706, "phrase": "broader_applications"}, {"score": 0.003419943984098415, "phrase": "simple_procedure"}, {"score": 0.003355515315708125, "phrase": "geometric_relationship"}, {"score": 0.0032149396890830575, "phrase": "subject-specific_parameters"}, {"score": 0.0031693980719538287, "phrase": "parameterized_iris_model"}, {"score": 0.0029935730127943466, "phrase": "gaze_feature_extraction"}, {"score": 0.002923214590192792, "phrase": "low-quality_eye_images"}, {"score": 0.002854505078275351, "phrase": "gaze_direction"}, {"score": 0.002657890175649468, "phrase": "visual_axis"}, {"score": 0.0026202187680903063, "phrase": "optical_axis"}, {"score": 0.002546466113418944, "phrase": "experimental_results"}, {"score": 0.0023485549678832628, "phrase": "large_head_movements"}, {"score": 0.0021659920594094407, "phrase": "wide_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Gaze estimation", " Eye tracking", " Gaze direction", " System calibration", " Human-computer interaction"], "paper_abstract": "Existing eye-gaze-tracking systems typically require multiple infrared (IR) lights and high-quality cameras to achieve good performance and robustness against head movement. This requirement limits the systems' potential for broader applications. In this paper, we present a low-cost, non-intrusive, simple-setup gaze estimation system that can estimate the gaze direction under free head movement. In particular, the proposed system only uses a consumer depth camera (Kinect sensor) positioned at a distance from the subject. We develop a simple procedure to calibrate the geometric relationship between the screen and the camera, and subject-specific parameters. A parameterized iris model is then used to locate the center of the iris for gaze feature extraction, which can handle low-quality eye images. Finally, the gaze direction is determined based on a 3D geometric eye model, where the head movement and deviation of the visual axis from the optical axis are taken into consideration. Experimental results indicate that the system can estimate gaze with an accuracy of 1.4-2.7 degrees and is robust against large head movements. Two real-time human-computer interaction (HCI) applications are presented to demonstrate the potential of the proposed system for wide applications. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Real time gaze estimation with a consumer depth camera", "paper_id": "WOS:000359029900020"}