{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "prediction_error"}, {"score": 0.004497410940849537, "phrase": "covariance_penalty_methods"}, {"score": 0.004075198669927074, "phrase": "non-linear_regression_model"}, {"score": 0.003923532450854754, "phrase": "extensive_simulation_approach"}, {"score": 0.0036093693971289754, "phrase": "different_non-parametric_methods"}, {"score": 0.003501452436803395, "phrase": "varying_signal-to-noise_ratio"}, {"score": 0.0032951702142329357, "phrase": "resampling_methods"}, {"score": 0.0028309318332306703, "phrase": "cross_validation"}, {"score": 0.0025453546203590364, "phrase": "regression_trees"}, {"score": 0.002254003531073337, "phrase": "best_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Prediction error", " Extra-sample error", " In-sample error", " Optimism", " Cross-validation", " Leave-one-out", " Bootstrap", " Covariance penalty", " Regression trees", " Projection pursuit regression", " Neural networks"], "paper_abstract": "The estimators most widely used to evaluate the prediction error of a non-linear regression model are examined. An extensive simulation approach allowed the comparison of the performance of these estimators for different non-parametric methods, and with varying signal-to-noise ratio and sample size. Estimators based on resampling methods such as Leave-one-out, parametric and non-parametric Bootstrap, as well as repeated Cross Validation methods and Hold-out, were considered. The methods used are Regression Trees, Projection Pursuit Regression and Neural Networks. The repeated-corrected 10-fold Cross-Validation estimator and the Parametric Bootstrap estimator obtained the best performance in the simulations. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Measuring the prediction error. A comparison of cross-validation, bootstrap and covariance penalty methods", "paper_id": "WOS:000281333900008"}