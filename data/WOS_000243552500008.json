{"auto_keywords": [{"score": 0.04025111049892481, "phrase": "human_head"}, {"score": 0.03816675918099568, "phrase": "face_region"}, {"score": 0.03789679908476813, "phrase": "hair_region"}, {"score": 0.00481495049065317, "phrase": "based_multi-camera_integration"}, {"score": 0.004641351004344458, "phrase": "human-computer_interfaces"}, {"score": 0.004523552067565685, "phrase": "color-based_particle_trackers"}, {"score": 0.0043764594918057915, "phrase": "modest_computational_cost"}, {"score": 0.0042497136254424995, "phrase": "multi-camera_information"}, {"score": 0.0033465923623290034, "phrase": "illumination_variety"}, {"score": 0.003309877074892399, "phrase": "fisher_criterion"}, {"score": 0.003132236287543072, "phrase": "color_histogram"}, {"score": 0.0030751605843937673, "phrase": "color_distribution_template"}, {"score": 0.00300803677566719, "phrase": "proper_time"}, {"score": 0.0028887477548568685, "phrase": "distributed_framework"}, {"score": 0.0027844017803674444, "phrase": "client_processors"}, {"score": 0.0027036380093304747, "phrase": "proposed_algorithm"}, {"score": 0.0026641365405034355, "phrase": "visual_tracking"}, {"score": 0.0026155681847364483, "phrase": "office_environment"}, {"score": 0.0025490525773769063, "phrase": "accurate_tracking_results"}, {"score": 0.0024842242921857705, "phrase": "difficult_scenarios"}, {"score": 0.0024389277933858054, "phrase": "complete_occlusion"}, {"score": 0.0023768935613577985, "phrase": "skin_color"}, {"score": 0.0023335495163073544, "phrase": "additional_information"}, {"score": 0.0022825763382627443, "phrase": "head_posture"}, {"score": 0.0022575078732617678, "phrase": "face_orientation_schemes"}, {"score": 0.002183938718432764, "phrase": "face_recognition"}, {"score": 0.0021679176844660074, "phrase": "eye_gaze_estimation"}, {"score": 0.0021049977753042253, "phrase": "designed_experiments"}], "paper_keywords": ["multi-camera tracking", " particle filter", " face tracking"], "paper_abstract": "Face tracking has many visual applications such as human-computer interfaces, video communications and surveillance. Color-based particle trackers have been proved robust and versatile for a modest computational cost. In this paper, a probabilistic method for integrating multi-camera information is introduced to track human face 3D-pose variations. The proposed method fuses information coming from several calibrated cameras via one color-based particle filter. The algorithm relies on the following novelties. First, the human head other than face is defined as the target of our algorithm. To distinguish the face region and hair region, a dual-color-ball is utilized to model the human head in 3D space. Second, to enhance the robustness to illumination variety, the Fisher criterion is applied to measure the separability of the face region and the hair region on the color histogram. Consequently, the color distribution template can be adapted at the proper time. Finally, the algorithm is performed based on the distributed framework, therefore the computation is implemented equally by all client processors. To demonstrate the performance of the proposed algorithm, several scenarios of visual tracking are tested in an office environment with three to four calibrated cameras. Experiments show that accurate tracking results are achieved, even in some difficult scenarios, such as the complete occlusion and the temptation of anything with skin color. Furthermore, the additional information of our track results, including the head posture and the face orientation schemes, can be used for further work such as face recognition and eye gaze estimation, which is also explained by elaborated designed experiments.", "paper_title": "Particle filter based multi-camera integration for face 3D-pose tracking", "paper_id": "WOS:000243552500008"}