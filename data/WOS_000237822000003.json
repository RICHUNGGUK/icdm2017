{"auto_keywords": [{"score": 0.04456084724287016, "phrase": "motion_vectors"}, {"score": 0.03791367979358708, "phrase": "temporary_motion_vector"}, {"score": 0.034803109985566766, "phrase": "proposed_scheme"}, {"score": 0.015158760173688089, "phrase": "temporary_predictive_motion_vector"}, {"score": 0.013638660546743392, "phrase": "vector_map"}, {"score": 0.009867606079533166, "phrase": "multiple_frames"}, {"score": 0.007417092521931778, "phrase": "optimal_motion_vector"}, {"score": 0.007349743014044062, "phrase": "reference_frame"}, {"score": 0.007173097590088379, "phrase": "conventional_schemes"}, {"score": 0.006958207318081819, "phrase": "narrow_search_range"}, {"score": 0.00481495049065317, "phrase": "motion_estimation"}, {"score": 0.004785682967399109, "phrase": "multireference_frames"}, {"score": 0.004641981839313141, "phrase": "mrmc"}, {"score": 0.00442093689661089, "phrase": "coding_efficiency"}, {"score": 0.004340774889203221, "phrase": "single_reference_frame_motion_compensation"}, {"score": 0.004314377131918679, "phrase": "srmc"}, {"score": 0.004197551473726497, "phrase": "single_reference_frame"}, {"score": 0.00410886951639144, "phrase": "multiple_reference_frames"}, {"score": 0.00405903443476192, "phrase": "channel_errors"}, {"score": 0.0039011907503957075, "phrase": "huge_computing_time"}, {"score": 0.003830416706816913, "phrase": "novel_motion_estimation_procedure"}, {"score": 0.0037724164140125137, "phrase": "lower_search_complexity"}, {"score": 0.0037380370652211315, "phrase": "image_quality"}, {"score": 0.0036590276279709955, "phrase": "motion_estimation_procedure"}, {"score": 0.003484627161645746, "phrase": "motion_vector_map"}, {"score": 0.0034318447871577503, "phrase": "successive_frames"}, {"score": 0.0032682370318207503, "phrase": "lower_complexity"}, {"score": 0.002991262005863753, "phrase": "encoded_image_quality"}, {"score": 0.002910159235873015, "phrase": "full_search_algorithm"}, {"score": 0.0028836151926021234, "phrase": "proposed_motion_estimation_process"}, {"score": 0.002663449329156526, "phrase": "first_reference_frame"}, {"score": 0.0025991404592599437, "phrase": "element_vectors"}, {"score": 0.0024301658667103565, "phrase": "experimental_results"}, {"score": 0.0023787343905076024, "phrase": "proposed_method"}, {"score": 0.0023426638248794643, "phrase": "proposed_motion_estimation_algorithm"}, {"score": 0.0022860825534337255, "phrase": "cpu_times"}, {"score": 0.002190326602897302, "phrase": "cpu_time"}, {"score": 0.0021243898166922177, "phrase": "additional_distortion"}, {"score": 0.0021049977753042253, "phrase": "encoded_video_quality"}], "paper_keywords": ["h.264", " motion estimation"], "paper_abstract": "The multiple reference frame motion compensation (MRMC) supported by H.264 makes use of the redundancy which is between multiple frames to enhance the coding efficiency over a scheme using the single reference frame motion compensation (SRMC) in which motion vectors are searched over a single reference frame. And, the technique using multiple reference frames can combat the channel errors efficiently. However, searching the motion vectors in multiple frames may require a huge computing time. This paper proposes a novel motion estimation procedure, which has a lower search complexity without sacrificing image quality. To reduce the complexity of motion estimation procedure, we use a temporary motion vector generated with little computation. The temporary motion vector is calculated from the motion vector map composed of motion vectors between successive frames, and used to predict the optimal motion vector for a reference frame. The proposed scheme requires the lower complexity than conventional schemes by using the temporary motion vector and refinement process over a narrow search range around the temporary predictive motion vector. Since the temporary predictive motion vector effectively chases the optimal motion vector for each reference frame, the encoded image quality by proposed scheme is very similar to that of full search algorithm. The proposed motion estimation process consists of three phases: 1) making a vector map between two consecutive frames, where the vector map is constructed by copying motion vectors which have been estimated in first reference frame, 2) composing a temporary motion vector with element vectors which are in the vector map, and 3) finally, the temporary predictive motion vector is refined over a narrow search range. We show experimental results which demonstrate the effectiveness of the proposed method. To compare the proposed motion estimation algorithm with the conventional schemes, we check the CPU times consumed by ME module in H.264 encoder using the proposed scheme. In the results, CPU time consumed by the proposed scheme has been reduced significantly without additional distortion of the encoded video quality.", "paper_title": "An efficient scheme for motion estimation using multireference frames in H.264/AVC", "paper_id": "WOS:000237822000003"}