{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "character_animation"}, {"score": 0.04601284855430019, "phrase": "skeletal_control"}, {"score": 0.033961708538626435, "phrase": "target_skeletal_motion"}, {"score": 0.004652016085325825, "phrase": "novel_hybrid_representation"}, {"score": 0.004363846362238565, "phrase": "surface_motion_graphs"}, {"score": 0.004174824849669107, "phrase": "dynamic_surface_shape"}, {"score": 0.004133940019630129, "phrase": "associated_appearance"}, {"score": 0.004093453936415085, "phrase": "multiple-view_video"}, {"score": 0.0040334640350288, "phrase": "hybrid_representation"}, {"score": 0.003935420482629049, "phrase": "novel_surface_sequences"}, {"score": 0.0038397509389856625, "phrase": "user-specified_key-frames"}, {"score": 0.003709693561373114, "phrase": "motion_graph_path_optimisation"}, {"score": 0.0035141291835319682, "phrase": "plausible_surface_motion"}, {"score": 0.0034118234596993836, "phrase": "space-time_editing"}, {"score": 0.0033617891884360606, "phrase": "mesh_sequence"}, {"score": 0.003312486229143855, "phrase": "learned_part-based_laplacian_surface_deformation_model"}, {"score": 0.0029576827451501956, "phrase": "clothing_styles"}, {"score": 0.002899965889623787, "phrase": "key-frame_animation"}, {"score": 0.002843372121209168, "phrase": "novel_sequences"}, {"score": 0.002680114113899346, "phrase": "sequence_duration"}, {"score": 0.0026538282523433684, "phrase": "path_length"}, {"score": 0.0026020254041372723, "phrase": "motion-capture-driven_animation"}, {"score": 0.0024891269874339553, "phrase": "synthesised_motion"}, {"score": 0.002346160830406661, "phrase": "surface_motion_graph"}, {"score": 0.0021789194955896102, "phrase": "natural_dynamics"}, {"score": 0.0021049977753042253, "phrase": "captured_performance"}], "paper_keywords": ["Algorithms", " Human motion synthesis", " motion graphs", " surface motion capture", " 3D video", " 4D performance capture", " example-based animation", " video-based rendering"], "paper_abstract": "We present a novel hybrid representation for character animation from 4D Performance Capture (4DPC) data which combines skeletal control with surface motion graphs. 4DPC data are temporally aligned 3D mesh sequence reconstructions of the dynamic surface shape and associated appearance from multiple-view video. The hybrid representation supports the production of novel surface sequences which satisfy constraints from user-specified key-frames or a target skeletal motion. Motion graph path optimisation concatenates fragments of 4DPC data to satisfy the constraints while maintaining plausible surface motion at transitions between sequences. Space-time editing of the mesh sequence using a learned part-based Laplacian surface deformation model is performed to match the target skeletal motion and transition between sequences. The approach is quantitatively evaluated for three 4DPC datasets with a variety of clothing styles. Results for key-frame animation demonstrate production of novel sequences that satisfy constraints on timing and position of less than 1% of the sequence duration and path length. Evaluation of motion-capture-driven animation over a corpus of 130 sequences shows that the synthesised motion accurately matches the target skeletal motion. The combination of skeletal control with the surface motion graph extends the range and style of motion which can be produced while maintaining the natural dynamics of shape and appearance from the captured performance.", "paper_title": "Hybrid Skeletal-Surface Motion Graphs for Character Animation from 4D Performance Capture", "paper_id": "WOS:000350565200004"}