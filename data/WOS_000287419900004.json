{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "support_vector_machines"}, {"score": 0.004588158931776543, "phrase": "classification_approaches"}, {"score": 0.004478782833067256, "phrase": "poor_generalization_performance"}, {"score": 0.004398457709182882, "phrase": "apparent_class_imbalance_problem"}, {"score": 0.004116012194714212, "phrase": "possible_models"}, {"score": 0.004042166795461166, "phrase": "remaining_uncertainty"}, {"score": 0.003969640975997097, "phrase": "class_imbalance"}, {"score": 0.003692271726952282, "phrase": "attractive_pragmatic_expansion_scheme"}, {"score": 0.003626000977962191, "phrase": "bayesian_approach"}, {"score": 0.0034135407979996673, "phrase": "class_imbalance_problem"}, {"score": 0.003213489259323921, "phrase": "model_assessment"}, {"score": 0.0030434561939032597, "phrase": "corresponding_decision_costs"}, {"score": 0.0029887957779347394, "phrase": "quadratic_program"}, {"score": 0.002952900365829518, "phrase": "optimal_margin_classifier"}, {"score": 0.002899861600151726, "phrase": "bayesian_support_vector_machines"}, {"score": 0.0025697460140513932, "phrase": "primal_problem"}, {"score": 0.002508365161206412, "phrase": "appropriate_learning_rule"}, {"score": 0.0024632912250657636, "phrase": "observation_sample"}, {"score": 0.0022771244331421586, "phrase": "true_relationship"}, {"score": 0.0021827653135510225, "phrase": "experimental_evidence"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Class imbalance problem", " Bayesian approach", " Support vector machines"], "paper_abstract": "Classification approaches usually present the poor generalization performance with an apparent class imbalance problem. Surely, a measures of the quality of the possible models reflected the remaining uncertainty in the class imbalance on learning. The purpose of our learning method is to lead an attractive pragmatic expansion scheme of the Bayesian approach to assess how well it is aligned with the class imbalance problem. Thus, we propose a method with a model assessment of the interplay between various classification decisions using probability, corresponding decision costs, and quadratic program of optimal margin classifier called: Bayesian Support Vector Machines (BSVMs) learning strategy. In the framework, we did modify in the objects and conditions of primal problem to reproduce an appropriate learning rule for an observation sample. The experiments on several existing data sets showed that BSVMs may appropriately capture the true relationship between the inputs and outputs by experimental evidence. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Bayesian decision theory for support vector machines: Imbalance measurement and feature optimization", "paper_id": "WOS:000287419900004"}