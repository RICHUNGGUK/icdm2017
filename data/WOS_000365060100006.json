{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "conceptual_spaces"}, {"score": 0.01550881895316471, "phrase": "language_games"}, {"score": 0.012280255417597608, "phrase": "lexicon_formation"}, {"score": 0.012156057191113909, "phrase": "language_game"}, {"score": 0.00478218760286811, "phrase": "symbol_grounding"}, {"score": 0.004701247803858319, "phrase": "standard_approach"}, {"score": 0.004621671570727774, "phrase": "language_evolution"}, {"score": 0.004497129150551236, "phrase": "communicative_interactions"}, {"score": 0.004466519142879166, "phrase": "intelligent_agents"}, {"score": 0.004185874747231179, "phrase": "world_objects"}, {"score": 0.003949693102823493, "phrase": "categorization_process"}, {"score": 0.0038431888954930083, "phrase": "meaningful_experiences"}, {"score": 0.0034924598001567944, "phrase": "dynamic_and_continuously_changing_environment"}, {"score": 0.003317883538640966, "phrase": "barsalou's_notion"}, {"score": 0.0032952735750239924, "phrase": "mental_simulation"}, {"score": 0.0032728171827367068, "phrase": "gardenfors'_notion"}, {"score": 0.0031845067058084583, "phrase": "esom_neural_networks"}, {"score": 0.003152006152091526, "phrase": "cognitive_architecture"}, {"score": 0.0030879936732269293, "phrase": "mental_concepts"}, {"score": 0.0026565317818265394, "phrase": "linguistic_symbols"}, {"score": 0.002629405440065951, "phrase": "naming_game"}, {"score": 0.002567180189640976, "phrase": "priori\"_categorization_scheme"}, {"score": 0.002532284627202572, "phrase": "external_expert"}, {"score": 0.002455489835065937, "phrase": "neural_network"}, {"score": 0.002430411367515404, "phrase": "previous_discrimination_game"}, {"score": 0.0023566987138026285, "phrase": "potential_ways"}, {"score": 0.002293051006249274, "phrase": "biologically_realistic_way"}, {"score": 0.002148677187261496, "phrase": "grammatical_language"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Intelligent agents", " Symbol grounding problem", " Mental simulation", " Simulator", " Conceptual spaces", " Language games"], "paper_abstract": "A standard approach in the simulation of language evolution is the use of Language Games to model communicative interactions between intelligent agents. Usually, in such language games, an agent uses the results from its perceptual layer to categorize and to conceptualize world objects, a process named categorization. In this paper, we develop an approach to the categorization process, where the decomposition of reality in meaningful experiences is co-evolved with the lexicon formation in the language game. This approach brings some insights on how meaning might be assigned to symbols, in a dynamic and continuously changing environment being experienced by an agent. In order to do that, we use Barsalou's notion of mental simulation and Gardenfors' notion of conceptual spaces such that, together with ESOM neural networks, a cognitive architecture can be developed, where mental concepts formation and lexicon formation are able to co-evolve during a language game. The performance of our cognitive architecture is evaluated and the results show that the architecture is able to fulfill its semantics function, by allowing a population of agents to exchange the meaning of linguistic symbols during a naming game, without relying on \"a priori\" categorization scheme provided by an external expert or a set of examples for training a neural network in a previous discrimination game. These results, beyond bringing evidence on potential ways for symbols to get meaning on a biologically realistic way, open a set of possibilities for further uses of conceptual spaces on a much more complex problem: the grounding of a grammatical language. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Evolving conceptual spaces for symbol grounding in language games", "paper_id": "WOS:000365060100006"}