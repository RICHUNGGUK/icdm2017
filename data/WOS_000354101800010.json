{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "monocular_video_guided_garment_simulation"}, {"score": 0.0045879792359519375, "phrase": "garment-shape_sequence"}, {"score": 0.004490552331642995, "phrase": "monocular_video_sequence"}, {"score": 0.004301834610818624, "phrase": "physically-based_simulation"}, {"score": 0.004233119608341877, "phrase": "boundary-based_modification"}, {"score": 0.0038638811223100184, "phrase": "garment_initial_shape"}, {"score": 0.0032712190037495975, "phrase": "matching_correspondences"}, {"score": 0.0029221312451219203, "phrase": "matched_vertices"}, {"score": 0.0028446460307503343, "phrase": "best-matching_correspondences"}, {"score": 0.002681315076008658, "phrase": "candidate_vertices"}, {"score": 0.0025822818714499795, "phrase": "garment_shape"}, {"score": 0.0025273383208209922, "phrase": "inter-frame_oscillations"}, {"score": 0.0023566987138026285, "phrase": "next_frame"}, {"score": 0.0021857667493036786, "phrase": "garment_video_sequence"}], "paper_keywords": ["garment simulation", " monocular video", " shape correspondence"], "paper_abstract": "We present a prototype to generate a garment-shape sequence guided by a monocular video sequence. It is a combination of a physically-based simulation and a boundary-based modification. Given a garment in the video worn on a mannequin, the simulation generates a garment initial shape by exploiting the mannequin shapes estimated from the video. The modification then deforms the simulated 3D shape into such a shape that matches the garment 2D boundary extracted from the video. According to the matching correspondences between the vertices on the shape and the points on the boundary, the modification is implemented by attracting the matched vertices and their neighboring vertices. For best-matching correspondences and efficient performance, three criteria are introduced to select the candidate vertices for matching. Since modifying each garment shape independently may cause inter-frame oscillations, changes by the modification are also propagated from one frame to the next frame. As a result, the generated garment 3D shape sequence is stable and similar to the garment video sequence. We demonstrate the effectiveness of our prototype with a number of examples.", "paper_title": "Monocular Video Guided Garment Simulation", "paper_id": "WOS:000354101800010"}