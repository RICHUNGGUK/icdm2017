{"auto_keywords": [{"score": 0.04961597900198376, "phrase": "gpgpu"}, {"score": 0.015346323866691032, "phrase": "new_pdom_stack"}, {"score": 0.011831326493398993, "phrase": "branch_divergence"}, {"score": 0.00481495049065317, "phrase": "branch_divergence_performance"}, {"score": 0.004653900688892822, "phrase": "multi-level_warp_scheduling"}, {"score": 0.004608879242346434, "phrase": "general-purpose_graphics_processing_unit"}, {"score": 0.004476399615305783, "phrase": "important_role"}, {"score": 0.00443308765153716, "phrase": "massive_parallel_computing"}, {"score": 0.0043477114072437316, "phrase": "gpgpu_core"}, {"score": 0.004181839414007266, "phrase": "hardware_threads"}, {"score": 0.0040222701316738295, "phrase": "single_instruction_multiple_thread"}, {"score": 0.0039833354612163275, "phrase": "simt"}, {"score": 0.0038499929374478125, "phrase": "high_performance"}, {"score": 0.003757480190200645, "phrase": "different_branches"}, {"score": 0.0036671822784770463, "phrase": "simd_style"}, {"score": 0.003493021648360933, "phrase": "hardware_stack"}, {"score": 0.003278878522165815, "phrase": "performance_degradation"}, {"score": 0.0031845067058084583, "phrase": "pdom"}, {"score": 0.0030628762739398855, "phrase": "binary_tree"}, {"score": 0.0029458777184930896, "phrase": "branch_target"}, {"score": 0.0028471655497661528, "phrase": "pdom-asi"}, {"score": 0.0027383842769094354, "phrase": "new_stack"}, {"score": 0.0025207920578878894, "phrase": "multi-level_warp_scheduling_policy"}, {"score": 0.0022756672722130424, "phrase": "simulation_results"}, {"score": 0.002199363362666037, "phrase": "baseline_policies"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["PDOM stack", " Warp scheduling", " Branch divergence", " GPGPU", " Performance", " Architecture"], "paper_abstract": "General-purpose graphics processing unit (GPGPU) plays an important role in massive parallel computing nowadays. A GPGPU core typically holds thousands of threads, where hardware threads are organized into warps. With the single instruction multiple thread (SIMT) pipeline, GPGPU can achieve high performance. But threads taking different branches in the same warp violate SIMD style and cause branch divergence. To support this, a hardware stack is used to sequentially execute all branches. Hence branch divergence leads to performance degradation. This article represents the PDOM (post dominator) stack as a binary tree, and each leaf corresponds to a branch target. We propose a new PDOM stack called PDOM-ASI, which can schedule all the tree leaves. The new stack can hide more long operation latencies with more schedulable warps without the problem of warp over-subdivision. Besides, a multi-level warp scheduling policy is proposed, which lets part of the warps run ahead and creates more opportunities to hide the latencies. The simulation results show that our policies achieve 10.5% performance improvements over baseline policies with only 1.33% hardware area overhead. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Improving branch divergence performance on GPGPU with a new PDOM stack and multi-level warp scheduling", "paper_id": "WOS:000337212500002"}