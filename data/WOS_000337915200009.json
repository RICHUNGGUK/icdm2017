{"auto_keywords": [{"score": 0.047358918256261234, "phrase": "massive_datasets"}, {"score": 0.00481495049065317, "phrase": "balanced_iterative_reducing_and_clustering_hierarchies"}, {"score": 0.004429388453288922, "phrase": "balanced_iterative"}, {"score": 0.004007083686875716, "phrase": "data_file"}, {"score": 0.003279082159362209, "phrase": "birch"}, {"score": 0.002941389980674657, "phrase": "computer_main_memory"}, {"score": 0.0027974705482714884, "phrase": "spearman's_rho"}, {"score": 0.002751075263422475, "phrase": "kendall's_tau"}, {"score": 0.0026164433143193015, "phrase": "birch_output"}, {"score": 0.002509284173541882, "phrase": "monte_carlo_studies"}, {"score": 0.002447101794397243, "phrase": "numerical_results"}, {"score": 0.0023665766694993535, "phrase": "birch-based_estimates"}, {"score": 0.00223196703759329, "phrase": "usual_estimates"}], "paper_keywords": ["correlation", " rank statistics", " massive dataset", " Kendall's tau", " Spearman's rho", " BIRCH"], "paper_abstract": "The balanced iterative reducing and clustering hierarchies (BIRCH) algorithm handles massive datasets by reading the data file only once, clustering the data as it is read, and retaining only a few clustering features to summarize the data read so far. Using BIRCH allows to analyse datasets that are too large to fit in the computer main memory. We propose estimates of Spearman's rho and Kendall's tau that are calculated from a BIRCH output and assess their performance through Monte Carlo studies. The numerical results show that the BIRCH-based estimates can achieve the same efficiency as the usual estimates of rho and tau while using only a fraction of the memory otherwise required.", "paper_title": "Using balanced iterative reducing and clustering hierarchies to compute approximate rank statistics on massive datasets", "paper_id": "WOS:000337915200009"}