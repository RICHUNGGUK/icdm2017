{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "write_operation"}, {"score": 0.008649693619854423, "phrase": "multi-dimensional_dsp_applications"}, {"score": 0.005977247102518044, "phrase": "full_parallelism"}, {"score": 0.005289939752290683, "phrase": "tlp_algorithm"}, {"score": 0.004726579360618152, "phrase": "two-level_partition_technique"}, {"score": 0.004691684576246597, "phrase": "complete_memory_latency_hiding"}, {"score": 0.004438019162720755, "phrase": "chip_multiprocessor"}, {"score": 0.004229249483672165, "phrase": "digital_signal_processing_applications"}, {"score": 0.00407533728096378, "phrase": "inefficient_scheduling_scheme"}, {"score": 0.00403026082093352, "phrase": "huge_amount"}, {"score": 0.0038548668648948044, "phrase": "significant_amount"}, {"score": 0.0037560869590718966, "phrase": "cpu_speed"}, {"score": 0.0036598289615980837, "phrase": "memory_speed"}, {"score": 0.0035528259557800683, "phrase": "overall_system_performance"}, {"score": 0.003436169600453596, "phrase": "two-level_partition"}, {"score": 0.0032022811145186974, "phrase": "scratchpad_memory"}, {"score": 0.0031434146012468307, "phrase": "on-chip_memory"}, {"score": 0.00308563971642571, "phrase": "ibm"}, {"score": 0.003006499028632742, "phrase": "dsp_benchmarks"}, {"score": 0.002822652835367827, "phrase": "memory_latencies"}, {"score": 0.0027502501046865525, "phrase": "least_amount"}, {"score": 0.0027097117582440687, "phrase": "main_memory"}, {"score": 0.00267969955652659, "phrase": "previous_approaches"}, {"score": 0.00265987582861194, "phrase": "experimental_results"}, {"score": 0.002582032847722892, "phrase": "known_methods"}, {"score": 0.002543967677678384, "phrase": "list_scheduling"}, {"score": 0.0025251455169484557, "phrase": "rotation_scheduling"}, {"score": 0.0024240794798626674, "phrase": "iterational_retiming"}, {"score": 0.002361876178411006, "phrase": "tlp_scheduling_algorithm"}, {"score": 0.002258924405138231, "phrase": "schedule_length"}, {"score": 0.0021927897271015657, "phrase": "irp_scheduling_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Chip multiprocessor (CMP)", " Memory latency", " Multi-dimensional DSP application", " Partition technique", " Schedule length", " Scratchpad memory (SPM)", " Write operation"], "paper_abstract": "Most scientific and digital signal processing (DSP) applications are recursive or iterative. The execution of these applications on a chip multiprocessor (CMP) encounters two challenges. First, as most of the digital signal processing applications are both computation intensive and data intensive, an inefficient scheduling scheme may generate huge amount of write operation, cost a lot of time, and consume significant amount of energy. Second, because CPU speed has been increased dramatically compared with memory speed, the slowness of memory hinders the overall system performance. In this paper, we develop a Two-Level Partition (TLP) algorithm that can minimize write operation while achieving full parallelism for multi-dimensional DSP applications running on CMPs which employ scratchpad memory (SPM) as on-chip memory (e.g., the IBM Cell processor). Experiments on DSP benchmarks demonstrate the effectiveness and efficiency of the TLP algorithm, namely, the TLP algorithm can completely hide memory latencies to achieve full parallelism and generate the least amount of write operation to main memory compared with previous approaches. Experimental results show that our proposed algorithm is superior to all known methods, including the list scheduling, rotation scheduling, Partition Scheduling with Prefetching (PSP), and Iterational Retiming with Partitioning (IRP) algorithms. Furthermore, the TLP scheduling algorithm can reduce write operation to main memory by 45.35% and reduce the schedule length by 23.7% on average compared with the IRP scheduling algorithm, the best known algorithm. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Minimizing write operation for multi-dimensional DSP applications via a two-level partition technique with complete memory latency hiding", "paper_id": "WOS:000351966500003"}