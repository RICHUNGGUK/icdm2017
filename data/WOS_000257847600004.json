{"auto_keywords": [{"score": 0.03852759913182569, "phrase": "contextual_equivalence"}, {"score": 0.010612387000973441, "phrase": "lambda_calculus"}, {"score": 0.006429800335662771, "phrase": "fair_normal-order_reduction"}, {"score": 0.0047804843375940835, "phrase": "locally_bottom-avoiding_choice"}, {"score": 0.004578783486828809, "phrase": "higher-order_call"}, {"score": 0.00441718685609235, "phrase": "case_expressions"}, {"score": 0.004385555408850022, "phrase": "recursive_letrec_expressions"}, {"score": 0.004338530593157634, "phrase": "seq_operator"}, {"score": 0.004307459965946991, "phrase": "sequential_evaluation"}, {"score": 0.004261268957001927, "phrase": "non-deterministic_operator_amb"}, {"score": 0.004096082254543022, "phrase": "small-step_operational_semantics"}, {"score": 0.0037171648669537287, "phrase": "equational_theory"}, {"score": 0.0034841647157189985, "phrase": "program_context"}, {"score": 0.0031845067058084613, "phrase": "non-deterministic_computations"}, {"score": 0.0030830390264125923, "phrase": "fairness_condition"}, {"score": 0.0030609320300175953, "phrase": "equational_reasoning"}, {"score": 0.0030171910207671205, "phrase": "valid_equations"}, {"score": 0.0029740732099993706, "phrase": "normal-order_reduction"}, {"score": 0.0028381384547894865, "phrase": "proof_tools"}, {"score": 0.00278752137116301, "phrase": "program_transformations"}, {"score": 0.002708399936381754, "phrase": "context_lemma"}, {"score": 0.0026600905156986317, "phrase": "must-_convergence"}, {"score": 0.0024842242921857705, "phrase": "so-called_complete_sets"}, {"score": 0.0022950308685133224, "phrase": "standardisation_theorem"}, {"score": 0.002135690395965095, "phrase": "omega"}, {"score": 0.0021049977753042253, "phrase": "least_element"}], "paper_keywords": [""], "paper_abstract": "We present a higher-order call-by-need lambda calculus enriched with constructors, case expressions, recursive letrec expressions, a seq operator for sequential evaluation and a non-deterministic operator amb that is locally bottom-avoiding. We use a small-step operational semantics in the form of a single-step rewriting system that defines a (non-deterministic) normal-order reduction. This strategy can be made fair by adding resources for book-keeping. As equational theory, we use contextual equivalence (that is, terms are equal if, when plugged into any program context, their termination behaviour is the same), in which we use a combination of may- and must-convergence, which is appropriate for non-deterministic computations. We show that we can drop the fairness condition for equational reasoning, since the valid equations with respect to normal-order reduction are the same as for fair normal-order reduction. We develop a number of proof tools for proving correctness of program transformations. In particular, we prove a context lemma for both may- and must- convergence that restricts the number of contexts that need to be examined for proving contextual equivalence. Combining this with so-called complete sets of commuting and forking diagrams, we show that all the deterministic reduction rules and some additional transformations preserve contextual equivalence. We also prove a standardisation theorem for fair normal-order reduction. The structure of the ordering <=(c) is also analysed, and we show that Omega is not a least element and <=(c) already implies contextual equivalence with respect to may-convergence.", "paper_title": "A call-by-need lambda calculus with locally bottom-avoiding choice: context lemma and correctness of transformations", "paper_id": "WOS:000257847600004"}