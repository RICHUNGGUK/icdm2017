{"auto_keywords": [{"score": 0.0444846753840644, "phrase": "dynamic_environments"}, {"score": 0.015719716506582538, "phrase": "genetic_network_programming"}, {"score": 0.015230954706398833, "phrase": "reinforcement_learning"}, {"score": 0.01049771081723231, "phrase": "node_transition"}, {"score": 0.004553265070135597, "phrase": "graph-based_evolutionary_algorithm"}, {"score": 0.004120694410890683, "phrase": "distinguished_expression_ability"}, {"score": 0.0038810583785936505, "phrase": "gnp_programs"}, {"score": 0.003583002730249742, "phrase": "directed_links"}, {"score": 0.0034702685641070283, "phrase": "graph_structure"}, {"score": 0.0030781126453776723, "phrase": "terminal_nodes"}, {"score": 0.002957471572421436, "phrase": "current_node"}, {"score": 0.002841545331522694, "phrase": "implicit_memory_function"}, {"score": 0.0028076592725295646, "phrase": "structural_characteristics"}, {"score": 0.0026654155072292707, "phrase": "extended_algorithm"}, {"score": 0.0024604876113911173, "phrase": "effective_graph_structures"}, {"score": 0.0024311346712789553, "phrase": "better_results"}, {"score": 0.0022803854904010347, "phrase": "agents'_behavior"}, {"score": 0.0021909411820497707, "phrase": "simulation_environment"}, {"score": 0.0021049977753042253, "phrase": "conventional_methods"}], "paper_keywords": ["evolutionary computation", " graph structure", " reinforcement learning", " agent", " tileworld"], "paper_abstract": "This paper proposes a graph-based evolutionary algorithm called Genetic Network Programming (GNP). Our goal is to develop GNP, which can deal with dynamic environments efficiently and effectively, based on the distinguished expression ability of the graph (network) structure. The characteristics of GNP are as follows. 1) GNP programs are composed of a number of nodes which execute simple judgment /processing, and these nodes are connected by directed links to each other. 2) The graph structure enables GNP to re-use nodes, thus the structure can be very compact. 3) The node transition of GNP is executed according to its node connections without any terminal nodes, thus the past history of the node transition affects the current node to be used and this characteristic works as an implicit memory function. These structural characteristics are useful for dealing with dynamic environments. Furthermore, we propose an extended algorithm, \"GNP with Reinforcement Learning (GNPRL)\" which combines evolution and reinforcement learning in order to create effective graph structures and obtain better results in dynamic environments. In this paper, we applied GNP to the problem of determining agents' behavior to evaluate its effectiveness. Tileworld was used as the simulation environment. The results show some advantages for GNP over conventional methods.", "paper_title": "A graph-based evolutionary algorithm: Genetic Network Programming (GNP) and its extension using reinforcement learning", "paper_id": "WOS:000249149400006"}