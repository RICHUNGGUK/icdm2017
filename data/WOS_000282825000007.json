{"auto_keywords": [{"score": 0.04960770684597511, "phrase": "microcoded_ips"}, {"score": 0.00481495049065317, "phrase": "code_size"}, {"score": 0.004697308822154191, "phrase": "high_decompression_speed"}, {"score": 0.004628101576367193, "phrase": "customized_ips"}, {"score": 0.004582528208024817, "phrase": "superior_performance"}, {"score": 0.004537401559396022, "phrase": "direct_programmability"}, {"score": 0.004492717291734985, "phrase": "micro-architectural_structures"}, {"score": 0.00442651096522781, "phrase": "instruction-based_processors"}, {"score": 0.00427578268550103, "phrase": "drastically_enlarged_code_sizes"}, {"score": 0.004150661689086371, "phrase": "size_reductions"}, {"score": 0.0040491842732233154, "phrase": "performance_issues"}, {"score": 0.00395017798595193, "phrase": "performance_benefits"}, {"score": 0.0035600143547053287, "phrase": "fast_code_compression_technique"}, {"score": 0.0033879628186273625, "phrase": "sizable_amount"}, {"score": 0.0033545600622020464, "phrase": "unspecified_bits"}, {"score": 0.003192406091820197, "phrase": "specified_bits"}, {"score": 0.0030988889679192965, "phrase": "proposed_technique"}, {"score": 0.0029637093924781825, "phrase": "fully_specified_bits"}, {"score": 0.0029055323737809825, "phrase": "linear_network"}, {"score": 0.002862648127577722, "phrase": "linear_property"}, {"score": 0.002806449337145999, "phrase": "compression_strategy"}, {"score": 0.0026973310437053573, "phrase": "extremely_low-overhead_decompression_engine"}, {"score": 0.002618278365749875, "phrase": "decompressed_code"}, {"score": 0.0024306105794630246, "phrase": "fixed-bandwidth_xor_network"}, {"score": 0.0023593563827190626, "phrase": "proposed_flexible_xor-based_network"}, {"score": 0.0023245146355917626, "phrase": "minimum_two-level_storage"}, {"score": 0.002234092591045251, "phrase": "immediate_values"}, {"score": 0.0022010965931147735, "phrase": "utmost_code_compression"}, {"score": 0.002147180332779021, "phrase": "negligible_amount"}, {"score": 0.0021049977753042253, "phrase": "hardware_overhead"}], "paper_keywords": ["Microcode compression", " Linear compression network", " Microcoded processors"], "paper_abstract": "Microcoded customized IPs offer superior performance and direct programmability of micro-architectural structures compared to instruction-based processors, yet at the cost of drastically enlarged code sizes. Code compression can deliver size reductions but necessitates attention to performance issues, so that the performance benefits of microcoded IPs are not squandered in the process. To attain this goal, we propose in this paper a fast code compression technique through exploiting the fact that the microcodes contain a sizable amount of unspecified bits. Although the values and the positions of the specified bits are highly irregular, the proposed technique can still flexibly and precisely fill in these fully specified bits through utilizing a linear network. The linear property inherent in the compression strategy in turn enables the development of an extremely low-overhead decompression engine. At runtime, the decompressed code can be generated in such a way that all the specified bits can be filled as required by a fixed-bandwidth XOR network. The combination of the proposed flexible XOR-based network with a minimum two-level storage for highly specified fields, such as immediate values, offers utmost code compression, attained within a negligible amount of performance and hardware overhead.", "paper_title": "Squashing code size in microcoded IPs while delivering high decompression speed", "paper_id": "WOS:000282825000007"}