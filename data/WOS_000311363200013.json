{"auto_keywords": [{"score": 0.04765243024404618, "phrase": "pca"}, {"score": 0.04020498078350934, "phrase": "original_input_variables"}, {"score": 0.00481495049065317, "phrase": "original_variables"}, {"score": 0.004765173195920904, "phrase": "bayesian_pca"}, {"score": 0.004667149874736771, "phrase": "image_analysis"}, {"score": 0.004618893461411858, "phrase": "principal_component_analysis"}, {"score": 0.004477083974172596, "phrase": "succinct_data_representation"}, {"score": 0.004250302819248558, "phrase": "maximum_variation"}, {"score": 0.004141238989360548, "phrase": "new_variables"}, {"score": 0.003771185758226876, "phrase": "obscure_semantics"}, {"score": 0.0036553070575015344, "phrase": "bayesian_data_analysis"}, {"score": 0.0034162643819889054, "phrase": "input_variables"}, {"score": 0.0032769720645483102, "phrase": "pair-wise_products"}, {"score": 0.0031270239691197515, "phrase": "sparse_model"}, {"score": 0.0029376803941247084, "phrase": "sparsity_pattern"}, {"score": 0.0028921584725218642, "phrase": "resultant_coefficients"}, {"score": 0.002803213985198645, "phrase": "intrinsic_groups"}, {"score": 0.002579140290642792, "phrase": "robust_estimation"}, {"score": 0.00253916011199984, "phrase": "covariance_matrix"}, {"score": 0.0025128735071736725, "phrase": "pca."}, {"score": 0.0024868131939261716, "phrase": "proposed_model"}, {"score": 0.002422890839801611, "phrase": "visual_data"}, {"score": 0.00234834406550549, "phrase": "output_variables"}, {"score": 0.002299921909935613, "phrase": "meaningful_parts"}, {"score": 0.0021493248730171132, "phrase": "proposed_technique"}], "paper_keywords": ["Feature extraction", " principal component analysis (PCA)", " sparse learning"], "paper_abstract": "Principal component analysis (PCA) computes a succinct data representation by converting the data to a few new variables while retaining maximum variation. However, the new variables are difficult to interpret, because each one is combined with all of the original input variables and has obscure semantics. Under the umbrella of Bayesian data analysis, this paper presents a new prior to explicitly regularize combinations of input variables. In particular, the prior penalizes pair-wise products of the coefficients of PCA and encourages a sparse model. Compared to the commonly used l(1)-regularizer, the proposed prior encourages the sparsity pattern in the resultant coefficients to be consistent with the intrinsic groups in the original input variables. Moreover, the proposed prior can be explained as recovering a robust estimation of the covariance matrix for PCA. The proposed model is suited for analyzing visual data, where it encourages the output variables to correspond to meaningful parts in the data. We demonstrate the characteristics and effectiveness of the proposed technique through experiments on both synthetic and real data.", "paper_title": "On Preserving Original Variables in Bayesian PCA With Application to Image Analysis", "paper_id": "WOS:000311363200013"}