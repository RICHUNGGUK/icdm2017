{"auto_keywords": [{"score": 0.00476527679607755, "phrase": "natural_environments"}, {"score": 0.004683618147754759, "phrase": "new_dataset"}, {"score": 0.004325568312096711, "phrase": "realistic_human_sensing_systems"}, {"score": 0.00425141240073214, "phrase": "next_generation"}, {"score": 0.004222105714769577, "phrase": "human_pose_estimation_models"}, {"score": 0.004036455094603843, "phrase": "current_state-of-the-art"}, {"score": 0.0038323244983352587, "phrase": "diverse_set"}, {"score": 0.0037148167062767096, "phrase": "typical_human_activities"}, {"score": 0.0034544053534458093, "phrase": "additional_synchronized_image"}, {"score": 0.0034305738274625634, "phrase": "human_motion_capture"}, {"score": 0.003190024306903021, "phrase": "controlled_mixed_reality_evaluation_scenarios"}, {"score": 0.003102875178186416, "phrase": "motion_capture"}, {"score": 0.0030285690317007805, "phrase": "complex_real_environments"}, {"score": 0.002845541839157798, "phrase": "large-scale_statistical_models"}, {"score": 0.002692132776447632, "phrase": "future_work"}, {"score": 0.0026643006135750025, "phrase": "research_community"}, {"score": 0.002503232182798796, "phrase": "training_set"}, {"score": 0.002451730979693715, "phrase": "largest_existing_public_dataset"}, {"score": 0.0022560827223539934, "phrase": "future_research"}, {"score": 0.0021867999937268084, "phrase": "associated_large-scale_learning_models"}, {"score": 0.0021049977753042253, "phrase": "evaluation_server"}], "paper_keywords": ["3D human pose estimation", " human motion capture data", " articulated body modeling", " optimization", " large-scale learning", " structured prediction", " Fourier kernel approximations"], "paper_abstract": "We introduce a new dataset, Human3.6M, of 3.6 Million accurate 3D Human poses, acquired by recording the performance of 5 female and 6 male subjects, under 4 different viewpoints, for training realistic human sensing systems and for evaluating the next generation of human pose estimation models and algorithms. Besides increasing the size of the datasets in the current state-of-the-art by several orders of magnitude, we also aim to complement such datasets with a diverse set of motions and poses encountered as part of typical human activities (taking photos, talking on the phone, posing, greeting, eating, etc.), with additional synchronized image, human motion capture, and time of flight (depth) data, and with accurate 3D body scans of all the subject actors involved. We also provide controlled mixed reality evaluation scenarios where 3D human models are animated using motion capture and inserted using correct 3D geometry, in complex real environments, viewed with moving cameras, and under occlusion. Finally, we provide a set of large-scale statistical models and detailed evaluation baselines for the dataset illustrating its diversity and the scope for improvement by future work in the research community. Our experiments show that our best large-scale model can leverage our full training set to obtain a 20% improvement in performance compared to a training set of the scale of the largest existing public dataset for this problem. Yet the potential for improvement by leveraging higher capacity, more complex models with our large dataset, is substantially vaster and should stimulate future research. The dataset together with code for the associated large-scale learning models, features, visualization tools, as well as the evaluation server, is available online at http://vision.imar.ro/human3.6m.", "paper_title": "Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments", "paper_id": "WOS:000338209900004"}