{"auto_keywords": [{"score": 0.04137518569891578, "phrase": "whole_kernel_matrix"}, {"score": 0.030982333237418662, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "spectral_kernel_learning"}, {"score": 0.004767261858417823, "phrase": "kernel_learning"}, {"score": 0.004337028108577593, "phrase": "side_information"}, {"score": 0.004230382915464492, "phrase": "pairwise_constraints"}, {"score": 0.004024863549087511, "phrase": "existing_methods"}, {"score": 0.0038676325043529524, "phrase": "limited_number"}, {"score": 0.003753738096719609, "phrase": "non-parametric_methods"}, {"score": 0.003553540530701019, "phrase": "arbitrary_structures"}, {"score": 0.0033140589981208693, "phrase": "small_data_sets"}, {"score": 0.0031686717525002935, "phrase": "kernel_learning_method"}, {"score": 0.002969821115740559, "phrase": "freedom_degree"}, {"score": 0.0028822890425197582, "phrase": "spectral_embedding"}, {"score": 0.0028253682745674608, "phrase": "square_matrix"}, {"score": 0.0026745503978347143, "phrase": "embedded_space"}, {"score": 0.0024941578231560055, "phrase": "kernel_matrix"}, {"score": 0.0024693979425773993, "phrase": "experimental_results"}, {"score": 0.002444883254621769, "phrase": "synthetic_and_real-world_data_sets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Kernel learning", " Spectral", " Scalable", " Semi-supervised clustering", " Laplacian", " Constraint"], "paper_abstract": "Kernel learning is one of the most important and recent approaches to constrained clustering. Until now many kernel learning methods have been introduced for clustering when side information in the form of pairwise constraints is available. However, almost all of the existing methods either learn a whole kernel matrix or learn a limited number of parameters. Although the non-parametric methods that learn whole kernel matrix can provide capability of finding clusters of arbitrary structures, they are very computationally expensive and these methods are feasible only on small data sets. In this paper, we propose a kernel learning method that shows flexibility in the number of variables between the two extremes of freedom degree. The proposed method uses a spectral embedding to learn a square matrix whose number of rows is the number of dimensions in the embedded space. Therefore, the proposed method shows much higher scalability compared to other methods that learn a kernel matrix. Experimental results on synthetic and real-world data sets show that the performance of the proposed method is generally near to the learning a whole kernel matrix while its time cost is very low compared to these methods. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Scalable semi-supervised clustering by spectral kernel learning", "paper_id": "WOS:000337219200022"}