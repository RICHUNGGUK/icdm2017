{"auto_keywords": [{"score": 0.026597672683514845, "phrase": "graph_weights"}, {"score": 0.00481495049065317, "phrase": "multitask_linear_discriminant_analysis_for_view_invariant_action_recognition"}, {"score": 0.004749106104067268, "phrase": "robust_action_recognition"}, {"score": 0.004684157900507474, "phrase": "viewpoint_changes"}, {"score": 0.004588389551682397, "phrase": "considerable_attention"}, {"score": 0.004372442291178139, "phrase": "self-similarity_matrices"}, {"score": 0.004109600767747015, "phrase": "effective_view-invariant_action_descriptors"}, {"score": 0.003916098498242888, "phrase": "ssm-based_methods"}, {"score": 0.003809628721278519, "phrase": "multitask_linear_discriminant_analysis"}, {"score": 0.003531474887552889, "phrase": "multiview_action_recognition"}, {"score": 0.0033651019362620866, "phrase": "discriminative_ssm_features"}, {"score": 0.0033190180867511605, "phrase": "different_views"}, {"score": 0.003097865379563127, "phrase": "mathematical_connection"}, {"score": 0.0030554300179552415, "phrase": "multivariate_linear_regression"}, {"score": 0.003013885749330024, "phrase": "lda"}, {"score": 0.002931569771634119, "phrase": "multitask_multiclass"}, {"score": 0.002851790448644913, "phrase": "single_optimization_problem"}, {"score": 0.0027741761880779535, "phrase": "appropriate_class_indicator_matrix"}, {"score": 0.0026071599759743833, "phrase": "graph-guided_multitask_lda"}, {"score": 0.002467140591777737, "phrase": "view_dependencies"}, {"score": 0.002224510044064184, "phrase": "training_data"}, {"score": 0.0021490449563443025, "phrase": "proposed_methods"}], "paper_keywords": ["Multi-view action recognition", " self-similarity matrix", " multi-task learning", " linear discriminant analysis"], "paper_abstract": "Robust action recognition under viewpoint changes has received considerable attention recently. To this end, self-similarity matrices (SSMs) have been found to be effective view-invariant action descriptors. To enhance the performance of SSM-based methods, we propose multitask linear discriminant analysis (LDA), a novel multitask learning framework for multiview action recognition that allows for the sharing of discriminative SSM features among different views (i.e., tasks). Inspired by the mathematical connection between multivariate linear regression and LDA, we model multitask multiclass LDA as a single optimization problem by choosing an appropriate class indicator matrix. In particular, we propose two variants of graph-guided multitask LDA: 1) where the graph weights specifying view dependencies are fixed a priori and 2) where graph weights are flexibly learnt from the training data. We evaluate the proposed methods extensively on multiview RGB and RGBD video data sets, and experimental results confirm that the proposed approaches compare favorably with the state-of-the-art.", "paper_title": "Multitask Linear Discriminant Analysis for View Invariant Action Recognition", "paper_id": "WOS:000345514300004"}