{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "fast_sparse_superposition_codes"}, {"score": 0.0045726187330434025, "phrase": "additive_white_gaussian_noise_channel"}, {"score": 0.004479120557712926, "phrase": "average_codeword_power_constraint"}, {"score": 0.0043875257506180865, "phrase": "sparse_superposition_codes"}, {"score": 0.003956784357357341, "phrase": "statistical_high-dimensional_regression_framework"}, {"score": 0.0034951469511975346, "phrase": "optimal_maximum-likelihood_decoding_scheme"}, {"score": 0.0033190180867511605, "phrase": "fast_decoding_algorithm"}, {"score": 0.0027837615811247963, "phrase": "capacity_c"}, {"score": 0.0025361866386341796, "phrase": "nearly_exponentially_small_error_probability"}, {"score": 0.0022168460543913787, "phrase": "error_probability"}], "paper_keywords": ["Gaussian channel", " subset selection", " compressed sensing", " multiuser detection", " orthogonal matching pursuit", " greedy algorithms", " successive cancelation decoding", " error exponents", " achieving channel capacity"], "paper_abstract": "For the additive white Gaussian noise channel with average codeword power constraint, sparse superposition codes are developed. These codes are based on the statistical high-dimensional regression framework. In a previous paper, we investigated decoding using the optimal maximum-likelihood decoding scheme. Here, a fast decoding algorithm, called the adaptive successive decoder, is developed. For any rate less than the capacity C, communication is shown to be reliable with nearly exponentially small error probability. Specifically, for blocklength n, it is shown that the error probability is exponentially small in n/log n.", "paper_title": "Fast Sparse Superposition Codes Have Near Exponential Error Probability for R < C", "paper_id": "WOS:000330286100011"}