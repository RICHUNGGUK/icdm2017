{"auto_keywords": [{"score": 0.03652446068505374, "phrase": "input_image"}, {"score": 0.015719716506582538, "phrase": "appearance-space_clustering"}, {"score": 0.010977299115485057, "phrase": "texture_exemplars"}, {"score": 0.008829923134443375, "phrase": "randomized_search_strategy"}, {"score": 0.008314635152768186, "phrase": "flow_field"}, {"score": 0.004671803485255806, "phrase": "texture_flow_estimation_method"}, {"score": 0.004550029253278477, "phrase": "correspondence_search"}, {"score": 0.004464987136420614, "phrase": "deformed_exemplars"}, {"score": 0.004381527499253281, "phrase": "underlying_texture_flow"}, {"score": 0.0042351951710402425, "phrase": "texture_label"}, {"score": 0.004124754315882517, "phrase": "user_interactions"}, {"score": 0.00409372989087314, "phrase": "strict_assumptions"}, {"score": 0.004047628461126961, "phrase": "geometric_model"}, {"score": 0.0039869632444468036, "phrase": "flow_estimation"}, {"score": 0.0039124037252916055, "phrase": "gradient-like_pattern"}, {"score": 0.0037959868107895053, "phrase": "distinct_texture_exemplars"}, {"score": 0.0037532257703888315, "phrase": "unsupervised_way"}, {"score": 0.0036969566358089644, "phrase": "efficient_search_strategy"}, {"score": 0.0036553070575015344, "phrase": "deformation_parameter_space"}, {"score": 0.0035734052458933547, "phrase": "coherent_flow"}, {"score": 0.0035331426502479687, "phrase": "fully_automatic_manner"}, {"score": 0.003440945901489461, "phrase": "multiple_textures"}, {"score": 0.003415047118340286, "phrase": "different_categories"}, {"score": 0.0033008858616145205, "phrase": "input_texture_image"}, {"score": 0.003226899588787952, "phrase": "medoid-based_clustering"}, {"score": 0.003049086085585051, "phrase": "deformation_parameters"}, {"score": 0.002958281631770322, "phrase": "distance_function"}, {"score": 0.0028810424107858436, "phrase": "texture_exemplar"}, {"score": 0.0028485585670146025, "phrase": "deformed_target_patch"}, {"score": 0.0026113524778702602, "phrase": "deformation_flow_field"}, {"score": 0.002486103638234488, "phrase": "matching_confidence_score"}, {"score": 0.00243033541656411, "phrase": "local_visual_similarity"}, {"score": 0.0023848164282879885, "phrase": "appearance_space"}, {"score": 0.0023579143175099324, "phrase": "local_behaviors"}, {"score": 0.0022110892229209407, "phrase": "matching_criterion"}, {"score": 0.002169667676959813, "phrase": "experimental_results"}, {"score": 0.002153316680437517, "phrase": "synthetic_and_natural_images"}, {"score": 0.002120982646893519, "phrase": "proposed_method"}, {"score": 0.0021049977753042253, "phrase": "existing_methods"}], "paper_keywords": ["Texture analysis", " texture flow", " texture exemplar", " randomized search", " medoid-based clustering"], "paper_abstract": "This paper presents a texture flow estimation method that uses an appearance-space clustering and a correspondence search in the space of deformed exemplars. To estimate the underlying texture flow, such as scale, orientation, and texture label, most existing approaches require a certain amount of user interactions. Strict assumptions on a geometric model further limit the flow estimation to such a near-regular texture as a gradient-like pattern. We address these problems by extracting distinct texture exemplars in an unsupervised way and using an efficient search strategy on a deformation parameter space. This enables estimating a coherent flow in a fully automatic manner, even when an input image contains multiple textures of different categories. A set of texture exemplars that describes the input texture image is first extracted via a medoid-based clustering in appearance space. The texture exemplars are then matched with the input image to infer deformation parameters. In particular, we define a distance function for measuring a similarity between the texture exemplar and a deformed target patch centered at each pixel from the input image, and then propose to use a randomized search strategy to estimate these parameters efficiently. The deformation flow field is further refined by adaptively smoothing the flow field under guidance of a matching confidence score. We show that a local visual similarity, directly measured from appearance space, explains local behaviors of the flow very well, and the flow field can be estimated very efficiently when the matching criterion meets the randomized search strategy. Experimental results on synthetic and natural images show that the proposed method outperforms existing methods.", "paper_title": "Unsupervised Texture Flow Estimation Using Appearance-Space Clustering and Correspondence", "paper_id": "WOS:000358514100004"}