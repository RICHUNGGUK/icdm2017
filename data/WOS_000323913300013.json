{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "continuous_visual_event_recognition"}, {"score": 0.04963913874714364, "phrase": "max-margin_hough_transformation_framework"}, {"score": 0.004597754207658615, "phrase": "novel_method"}, {"score": 0.004192190072470619, "phrase": "diverse_real_environmental_state_and_wide_scene_variability_direct_application"}, {"score": 0.004058826900076531, "phrase": "spatio-temporal_interest_point"}, {"score": 0.003966162568548304, "phrase": "whole_dataset"}, {"score": 0.003734979290204709, "phrase": "motion_region_extraction_technique"}, {"score": 0.0036496814103475174, "phrase": "motion_segmentation"}, {"score": 0.0035498822293046884, "phrase": "possible_candidate_\"event"}, {"score": 0.0034528025626422154, "phrase": "preprocessing_step"}, {"score": 0.003389557201018519, "phrase": "candidate_regions"}, {"score": 0.003358368814209542, "phrase": "stip_detector"}, {"score": 0.0032968474833776906, "phrase": "local_motion_features"}, {"score": 0.0032215231177304513, "phrase": "activity_representation"}, {"score": 0.0031625195022965415, "phrase": "hough"}, {"score": 0.00309023627455429, "phrase": "feature_point"}, {"score": 0.0030476702431093687, "phrase": "weighted_vote"}, {"score": 0.0030196181347744372, "phrase": "possible_activity_class_centre"}, {"score": 0.0029780219173522115, "phrase": "max-margin_frame_work"}, {"score": 0.0028303313661029597, "phrase": "activity_detection"}, {"score": 0.002765636101369536, "phrase": "hough_voting_space"}, {"score": 0.0026899455459275575, "phrase": "initial_event_hypothesis"}, {"score": 0.0026284507395498897, "phrase": "spatio-temporal_information"}, {"score": 0.0025922289692173997, "phrase": "participating_stips"}, {"score": 0.0025565050791036973, "phrase": "event_recognition"}, {"score": 0.0025329623864528317, "phrase": "verification_support_vector_machine"}, {"score": 0.0024750474634399797, "phrase": "extensive_evaluation"}, {"score": 0.0024522530645471065, "phrase": "benchmark_large_scale_video_surveillance_dataset"}, {"score": 0.002429668806944879, "phrase": "virat"}, {"score": 0.0023522423291484212, "phrase": "small_scale_benchmark_dataset"}, {"score": 0.002330602309206224, "phrase": "msr"}, {"score": 0.0022772782536385717, "phrase": "proposed_method"}, {"score": 0.002225196379204285, "phrase": "wide_range"}, {"score": 0.002204697943520258, "phrase": "continuous_visual_event_recognition_applications"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Continuous visual event", " Large scale", " Max-margin Hough transform", " Event detection"], "paper_abstract": "In this paper we propose a novel method for continuous visual event recognition (CVER) on a large scale video dataset using max-margin Hough transformation framework. Due to high scalability, diverse real environmental state and wide scene variability direct application of action recognition/detection methods such as spatio-temporal interest point (STIP)-local feature based technique, on the whole dataset is practically infeasible. To address this problem, we apply a motion region extraction technique which is based on motion segmentation and region clustering to identify possible candidate \"event of interest\" as a preprocessing step. On these candidate regions a STIP detector is applied and local motion features are computed. For activity representation we use generalized Hough transform framework where each feature point casts a weighted vote for possible activity class centre. A max-margin frame work is applied to learn the feature codebook weight. For activity detection, peaks in the Hough voting space are taken into account and initial event hypothesis is generated using the spatio-temporal information of the participating STIPs. For event recognition a verification Support Vector Machine is used. An extensive evaluation on benchmark large scale video surveillance dataset (VIRAT) and as well on a small scale benchmark dataset (MSR) shows that the proposed method is applicable on a wide range of continuous visual event recognition applications having extremely challenging conditions. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Large scale continuous visual event recognition using max-margin Hough transformation framework", "paper_id": "WOS:000323913300013"}