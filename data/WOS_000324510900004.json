{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "motion_retrieval"}, {"score": 0.004634459424542272, "phrase": "new_examplar-based_method"}, {"score": 0.00459039896577789, "phrase": "real-time_human_motion_recognition"}, {"score": 0.004546755482549647, "phrase": "motion_capture"}, {"score": 0.004334657104697421, "phrase": "recognizable_actions"}, {"score": 0.004232331639807526, "phrase": "online_mocap_engine"}, {"score": 0.0041522059428827345, "phrase": "motion_graph"}, {"score": 0.004034841146538891, "phrase": "animation_motion_graph"}, {"score": 0.003828187766572941, "phrase": "known_actions"}, {"score": 0.0037199473428123175, "phrase": "new_ones"}, {"score": 0.003580355398511932, "phrase": "spatio-temporal_metric"}, {"score": 0.0033969001271637934, "phrase": "proposed_method"}, {"score": 0.0032074366230426727, "phrase": "recognition_process"}, {"score": 0.003087017178815267, "phrase": "new_action"}, {"score": 0.002739001004969201, "phrase": "skeleton-centric_coordinate_system"}, {"score": 0.002327648608736437, "phrase": "human_action_recognition"}, {"score": 0.002166349705365602, "phrase": "better_recognition_rates"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Motion retrieval", " Motion interpretation", " Human action recognition", " Motion Capture", " Automaton", " Examplar-based"], "paper_abstract": "This paper proposes a new examplar-based method for real-time human motion recognition using Motion Capture (MoCap) data. We have formalized streamed recognizable actions, coming from an online MoCap engine, into a motion graph that is similar to an animation motion graph. This graph is used as an automaton to recognize known actions as well as to add new ones. We have defined and used a spatio-temporal metric for similarity measurements to achieve more accurate feedbacks on classification. The proposed method has the advantage of being linear and incremental, making the recognition process very fast and the addition of a new action straightforward. Furthermore, actions can be recognized with a score even before they are fully completed. Thanks to the use of a skeleton-centric coordinate system, our recognition method has become view-invariant. We have successfully tested our action recognition method on both synthetic and real data. We have also compared our results with four state-of-the-art methods using three well known datasets for human action recognition. In particular, the comparisons have clearly shown the advantage of our method through better recognition rates. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "A real-time system for motion retrieval and interpretation", "paper_id": "WOS:000324510900004"}