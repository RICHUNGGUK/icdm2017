{"auto_keywords": [{"score": 0.04233528418394491, "phrase": "pawlak's_rough_set_model"}, {"score": 0.04093030702492042, "phrase": "mlrs"}, {"score": 0.035918128081770216, "phrase": "cut_reduction"}, {"score": 0.01571970438343417, "phrase": "decision_rule_mining"}, {"score": 0.015183987813384554, "phrase": "attribute_reduction"}, {"score": 0.004719473826242326, "phrase": "rough_sets"}, {"score": 0.004534136929881113, "phrase": "single_concept_level"}, {"score": 0.004444203710097833, "phrase": "attribute_value_taxonomies"}, {"score": 0.004205940624913343, "phrase": "real-world_applications"}, {"score": 0.003940706575253453, "phrase": "novel_multi-level_rough_set_model"}, {"score": 0.003766908559075843, "phrase": "full-subtree_generalization_scheme"}, {"score": 0.003441891354624516, "phrase": "novel_concept"}, {"score": 0.0030823667846259836, "phrase": "raw_decision_table"}, {"score": 0.0025989960809479104, "phrase": "cut_reduction_generation"}, {"score": 0.002573567309049561, "phrase": "np"}, {"score": 0.0024842242921857705, "phrase": "heuristic_algorithm"}, {"score": 0.002459414063407306, "phrase": "crtdr"}, {"score": 0.002327310963701377, "phrase": "rmtdr"}, {"score": 0.0022925278792429553, "phrase": "multi-level_decision_rule"}, {"score": 0.0022133711375320266, "phrase": "decision_rules"}, {"score": 0.0021912600076114033, "phrase": "different_concept_levels"}, {"score": 0.0021693692831601745, "phrase": "example_analysis"}, {"score": 0.0021476967767071233, "phrase": "comparative_experiments"}, {"score": 0.0021049977753042253, "phrase": "proposed_methods"}], "paper_keywords": ["Rough set theory", " Multi-level data mining", " Attribute value taxonomy", " Data generalization", " Concept level"], "paper_abstract": "Most previous studies on rough sets focused on attribute reduction and decision rule mining on a single concept level. Data with attribute value taxonomies (AVTs) are, however, commonly seen in real-world applications. In this paper, we extend Pawlak's rough set model, and propose a novel multi-level rough set model (MLRS) based on AVTs and a full-subtree generalization scheme. Paralleling with Pawlak's rough set model, some conclusions related to the MLRS are given. Meanwhile, a novel concept of cut reduction based on MLRS is presented. A cut reduction can induce the most abstract multi-level decision table with the same classification ability on the raw decision table, and no other multi-level decision table exists that is more abstract. Furthermore, the relationships between attribute reduction in Pawlak's rough set model and cut reduction in MLRS are discussed. We also prove that the problem of cut reduction generation is NP-hard, and develop a heuristic algorithm named CRTDR for computing the cut reduction. Finally, an approach named RMTDR for mining multi-level decision rule is provided. It can mine decision rules from different concept levels. Example analysis and comparative experiments show that the proposed methods are efficient and effective in handling the problems where data is associated with AVTs.", "paper_title": "Multi-level rough set reduction for decision rule mining", "paper_id": "WOS:000324107400013"}