{"auto_keywords": [{"score": 0.048902368426216106, "phrase": "gpu."}, {"score": 0.00481495049065317, "phrase": "optimized_approach"}, {"score": 0.004581162468419365, "phrase": "compact_representation"}, {"score": 0.004337028108577593, "phrase": "full_range"}, {"score": 0.004251500979153001, "phrase": "diverse_fields"}, {"score": 0.004209369306023422, "phrase": "histogram_generation"}, {"score": 0.0041469500929423595, "phrase": "inherently_sequential_operation"}, {"score": 0.0040048667115255, "phrase": "reduced_set"}, {"score": 0.0038676325043529524, "phrase": "efficient_parallel_implementations"}, {"score": 0.003716520760680603, "phrase": "graphics_processing_units"}, {"score": 0.003553540530701019, "phrase": "short_number"}, {"score": 0.0035183010916001664, "phrase": "histogram_bins"}, {"score": 0.0032324864013225166, "phrase": "thread_execution"}, {"score": 0.003029643234751066, "phrase": "highly_optimized_approach"}, {"score": 0.00299958349498286, "phrase": "histogram_calculation"}, {"score": 0.0028822890425197582, "phrase": "histogram_replication"}, {"score": 0.0028394925080958205, "phrase": "position_conflicts"}, {"score": 0.002769568481822277, "phrase": "bank_conflicts"}, {"score": 0.0026745503978347143, "phrase": "input_data"}, {"score": 0.0021474369836979048, "phrase": "previous_implementation"}], "paper_keywords": ["Histogram", " GPU", " CUDA", " Replication", " Padding"], "paper_abstract": "A histogram is a compact representation of the distribution of data in an image with a full range of applications in diverse fields. Histogram generation is an inherently sequential operation where every pixel votes in a reduced set of bins. This makes finding efficient parallel implementations very desirable but challenging, because on graphics processing units thousands of threads may be atomically updating a short number of histogram bins. Under these circumstances, collisions among threads will be very frequent and such collisions will serialize thread execution, seriously damaging the performance. In this paper we propose a highly optimized approach to histogram calculation, which tackles such performance bottlenecks. It uses histogram replication for eliminating position conflicts, padding to reduce bank conflicts, and an improved access to input data called interleaved read access. Our so-called -per-block approach to histogram calculation has been successfully compared to the main state-of-the-art works using four histogram-based image processing kernels and two real image databases. Results show that our proposal is between 1.4 and 15.7 faster than every previous implementation for histograms of up to 4,096 bins.", "paper_title": "An optimized approach to histogram computation on GPU", "paper_id": "WOS:000320512000002"}