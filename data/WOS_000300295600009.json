{"auto_keywords": [{"score": 0.004120694410890683, "phrase": "test_queries"}, {"score": 0.0038119123317396954, "phrase": "relevant_documents"}, {"score": 0.00374399358035391, "phrase": "evaluation_framework"}, {"score": 0.003677280504320636, "phrase": "performance_measures"}, {"score": 0.0034220655476652683, "phrase": "search_parameters"}, {"score": 0.003361069456060196, "phrase": "program_trec_eval"}, {"score": 0.0033011569787033297, "phrase": "large_number"}, {"score": 0.003109031770476385, "phrase": "mean_average_precision_or_recall-precision_curves"}, {"score": 0.0027575842698911173, "phrase": "small_number"}, {"score": 0.0026760974046034854, "phrase": "different_information_retrieval_systems"}, {"score": 0.002445767214680791, "phrase": "massive_data_analysis"}, {"score": 0.00241658945942583, "phrase": "trec_results"}, {"score": 0.0022758279600841014, "phrase": "individual_queries"}, {"score": 0.0021049977753042253, "phrase": "homogeneous_clusters"}], "paper_keywords": ["Information retrieval", " Performance measures", " Evaluation", " Statistical data analysis"], "paper_abstract": "Evaluating effectiveness of information retrieval systems is achieved by performing on a collection of documents, a search, in which a set of test queries are performed and, for each query, the list of the relevant documents. This evaluation framework also includes performance measures making it possible to control the impact of a modification of search parameters. The program trec_eval calculates a large number of measures, some being more used like the mean average precision or recall-precision curves. The motivation of our work is to compare all measures and to help the user to choose a small number of them when evaluating different information retrieval systems. In this paper, we present the study we carried out from a massive data analysis of TREC results. Relationships between the 130 measures calculated by trec_eval for individual queries are investigated, and we show that they can be clustered into homogeneous clusters.", "paper_title": "How many performance measures to evaluate information retrieval systems?", "paper_id": "WOS:000300295600009"}