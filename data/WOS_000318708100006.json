{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "situation-aware_and_user-adaptive_music_recommendation_service"}, {"score": 0.004732100994830163, "phrase": "real-time_multimedia_computing_environment"}, {"score": 0.0046184900568047565, "phrase": "ubiquitous_era"}, {"score": 0.0044608829094248985, "phrase": "semantic_web_environment"}, {"score": 0.004323620278409076, "phrase": "situation-aware_personalized_music_recommendation_service"}, {"score": 0.004176033420846065, "phrase": "situation-aware_music_recommendation"}, {"score": 0.004104132253183181, "phrase": "low-level_feature_extraction"}, {"score": 0.004047500054405469, "phrase": "music_mood_classification"}, {"score": 0.0040194764936614565, "phrase": "human_emotion_prediction"}, {"score": 0.0038957429132649175, "phrase": "new_scheme"}, {"score": 0.0035965032173588753, "phrase": "music_contents"}, {"score": 0.003449585750738867, "phrase": "semantic_web_technologies"}, {"score": 0.003378385493203297, "phrase": "domain_knowledge"}, {"score": 0.003140524241432171, "phrase": "user's_musical_preferences"}, {"score": 0.0030437652050982643, "phrase": "user's_desired_emotions"}, {"score": 0.002980916123365584, "phrase": "comus"}, {"score": 0.0029499784768149146, "phrase": "upper_music_ontology"}, {"score": 0.0028890603352364273, "phrase": "general_properties"}, {"score": 0.002704306866425829, "phrase": "domain-specific_ontologies"}, {"score": 0.00266693888510356, "phrase": "music_features"}, {"score": 0.0025937408242280757, "phrase": "hierarchical_manner"}, {"score": 0.0025313382638451776, "phrase": "context_ontology"}, {"score": 0.0024876840172100567, "phrase": "logical_reasoning_rules"}, {"score": 0.002320449502337321, "phrase": "detailed_and_complicated_relations"}, {"score": 0.0022101055924375725, "phrase": "appropriate_music"}, {"score": 0.0021049977753042253, "phrase": "music_recommendation"}], "paper_keywords": ["Customization", " Ontology", " Reasoning", " Semantic web", " User profiles"], "paper_abstract": "With the advent of the ubiquitous era, many studies have been devoted to various situation-aware services in the semantic web environment. One of the most challenging studies involves implementing a situation-aware personalized music recommendation service which considers the user's situation and preferences. Situation-aware music recommendation requires multidisciplinary efforts including low-level feature extraction and analysis, music mood classification and human emotion prediction. In this paper, we propose a new scheme for a situation-aware/user-adaptive music recommendation service in the semantic web environment. To do this, we first discuss utilizing knowledge for analyzing and retrieving music contents semantically, and a user adaptive music recommendation scheme based on semantic web technologies that facilitates the development of domain knowledge and a rule set. Based on this discussion, we describe our Context-based Music Recommendation (COMUS) ontology for modeling the user's musical preferences and contexts, and supporting reasoning about the user's desired emotions and preferences. Basically, COMUS defines an upper music ontology that captures concepts on the general properties of music such as titles, artists and genres. In addition, it provides functionality for adding domain-specific ontologies, such as music features, moods and situations, in a hierarchical manner, for extensibility. Using this context ontology, we believe that logical reasoning rules can be inferred based on high-level (implicit) knowledge such as situations from low-level (explicit) knowledge. As an innovation, our ontology can express detailed and complicated relations among music clips, moods and situations, which enables users to find appropriate music. We present some of the experiments we performed as a case-study for music recommendation.", "paper_title": "Implementing situation-aware and user-adaptive music recommendation service in semantic web and real-time multimedia computing environment", "paper_id": "WOS:000318708100006"}