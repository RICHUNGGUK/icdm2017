{"auto_keywords": [{"score": 0.04962396550254858, "phrase": "image_collections"}, {"score": 0.045915154498909476, "phrase": "visual_summaries"}, {"score": 0.00481495049065317, "phrase": "visual_summarization"}, {"score": 0.00459039896577789, "phrase": "novel_approach"}, {"score": 0.004054169947971483, "phrase": "amazon_mechanical_turk_crowdsourcing_platform"}, {"score": 0.003977403701783668, "phrase": "large_number"}, {"score": 0.003939565240409143, "phrase": "manually_created_visual_summaries"}, {"score": 0.003791763445590174, "phrase": "image_inclusion"}, {"score": 0.0036494864560524735, "phrase": "large-scale_user_tests"}, {"score": 0.0035632774896594524, "phrase": "automatic_image_selection_approach"}, {"score": 0.003429544382524185, "phrase": "image_content"}, {"score": 0.003332537728389913, "phrase": "visual_aesthetic_appeal"}, {"score": 0.002845883666777154, "phrase": "semantically_related_images"}, {"score": 0.002687070469080394, "phrase": "aesthetic_appeal"}, {"score": 0.0025861368747446324, "phrase": "particular_group"}, {"score": 0.0024652715040303416, "phrase": "low_inter-user_agreement"}, {"score": 0.002406968743305622, "phrase": "automatic_evaluation"}, {"score": 0.0023613185213421173, "phrase": "challenging_task"}, {"score": 0.0022725931637071852, "phrase": "text_summarization"}, {"score": 0.0022509365210787993, "phrase": "machine_translation_communities"}, {"score": 0.0021560018573288666, "phrase": "geo-referenced_flickr_images"}], "paper_keywords": ["Crowdsourcing", " image aesthetic appeal", " image content and context", " image set evaluation", " learning to rank", " sentiment analysis", " social media", " user-informed visual summarization"], "paper_abstract": "In this paper we propose a novel approach to selecting images suitable for inclusion in the visual summaries. The approach is grounded in insights about how people summarize image collections. We utilize the Amazon Mechanical Turk crowdsourcing platform to obtain a large number of manually created visual summaries as well as information about criteria for image inclusion in the summary. Based on these large-scale user tests, we propose an automatic image selection approach, which jointly utilizes the analysis of image content, context, popularity, visual aesthetic appeal as well as the sentiment derived from the comments posted on the images. In our approach we do not describe images based on their properties only, but also in the context of semantically related images, which improves robustness and effectively enables propagation of sentiment, aesthetic appeal as well as various inherent attributes associated with a particular group of images. We discuss the phenomenon of a low inter-user agreement, which makes an automatic evaluation of visual summaries a challenging task and propose a solution inspired by the text summarization and machine translation communities. The experiments performed on a collection of geo-referenced Flickr images demonstrate the effectiveness of our image selection approach.", "paper_title": "Learning Crowdsourced User Preferences for Visual Summarization of Image Collections", "paper_id": "WOS:000324765400002"}