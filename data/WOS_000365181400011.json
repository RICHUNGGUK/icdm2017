{"auto_keywords": [{"score": 0.0234353818740969, "phrase": "uiuc"}, {"score": 0.004712726613162057, "phrase": "top-down_semantic_segmentation"}, {"score": 0.003802135020791801, "phrase": "novel_detector-based_semantic_segmentation_feature"}, {"score": 0.0036815763368083197, "phrase": "carefully-modified_orientation_map"}, {"score": 0.003034158379493625, "phrase": "single_image"}, {"score": 0.0027543636132088332, "phrase": "conditional_random_field_formulation"}, {"score": 0.0023950275815082297, "phrase": "existing_bottom-up_geometric_features"}, {"score": 0.0022941723937662927, "phrase": "state-of-the-art_layout_accuracy"}], "paper_keywords": ["3D Layout estimation", " Semantic segmentation"], "paper_abstract": "In this paper, we propose a framework to recover a 3D cuboidal indoor scene with a novel detector-based semantic segmentation feature and a carefully-modified orientation map. We use those features to mimic the ability of humans to recognize a 3D layout from a single image. We define all the potentials in our model under a conditional random field formulation. Our experimental results show the effectiveness of our new features which complement the limitations of existing bottom-up geometric features while achieving the state-of-the-art layout accuracy on the indoor UIUC dataset. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Recovering an indoor 3D layout with top-down semantic segmentation from a single image", "paper_id": "WOS:000365181400011"}