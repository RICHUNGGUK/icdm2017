{"auto_keywords": [{"score": 0.041726498903390224, "phrase": "sist"}, {"score": 0.04025991931734957, "phrase": "sist_coefficients"}, {"score": 0.03425068632088303, "phrase": "standard_deviation"}, {"score": 0.00481495049065317, "phrase": "image_shift-invariant_shearlet_coefficients"}, {"score": 0.00466102244911872, "phrase": "fused_outcome"}, {"score": 0.004408456735066782, "phrase": "source_images"}, {"score": 0.004307286039184164, "phrase": "multi-modal_medical_image_fusion_method"}, {"score": 0.004208427318712072, "phrase": "shift-invariant_shearlet_transform"}, {"score": 0.003888905257972882, "phrase": "dependent_relationships"}, {"score": 0.0035603115570447467, "phrase": "conventional_average-maximum_fusion_scheme"}, {"score": 0.003446353878654566, "phrase": "medical_image_fusion"}, {"score": 0.003367188029221534, "phrase": "new_scheme"}, {"score": 0.0032745778756077693, "phrase": "probability_density_function"}, {"score": 0.003111336942540226, "phrase": "fused_coefficients"}, {"score": 0.0030398432591176357, "phrase": "fused_image"}, {"score": 0.002942495422585405, "phrase": "inverse_sist."}, {"score": 0.0028615323526689582, "phrase": "hmt_model"}, {"score": 0.0026687115458522326, "phrase": "fused_results"}, {"score": 0.0026440008776012665, "phrase": "visual_and_statistical_analyses"}, {"score": 0.0025952620596908747, "phrase": "fusion_quality"}, {"score": 0.002500456462028735, "phrase": "five_typical_methods"}, {"score": 0.002431626477893495, "phrase": "mutual_information"}, {"score": 0.0024091057723923857, "phrase": "edge_information"}, {"score": 0.0023103100997344072, "phrase": "structural_similarity"}, {"score": 0.002267708463966758, "phrase": "color_distortion"}, {"score": 0.0022052711621931144, "phrase": "great_extent"}, {"score": 0.002164602220179823, "phrase": "better_visual_sense"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Medical image", " Image fusion", " Hidden Markov Tree model", " Shift-invariance", " Shearlet transform"], "paper_abstract": "For the quality of the fused outcome is determined by the amount of the information captured from the source images, thus, a multi-modal medical image fusion method is developed in the shift-invariant shearlet transform (SIST) domain. The two-state Hidden Markov Tree (HMT) model is extended into the SIST domain to describe the dependent relationships of the SIST coefficients of the cross-scale and inter-subbands. Base on the model, we explain why the conventional Average-Maximum fusion scheme is not the best rule for medical image fusion, and therefore a new scheme is developed, where the probability density function and standard deviation of the SIST coefficients are employed to calculate the fused coefficients. Finally, the fused image is obtained by directly applying the inverse SIST. Integrating the SIST and the HMT model, more spatial feature information of the singularities and more functional information contents can be preserved and transferred into the fused results. Visual and statistical analyses demonstrate that the fusion quality can be significantly improved over that of five typical methods in terms of entropy and mutual information, edge information, standard deviation, peak signal to noise and structural similarity. Besides, color distortion can be suppressed to a great extent, providing a better visual sense. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Multi-modal medical image fusion using the inter-scale and intra-scale dependencies between image shift-invariant shearlet coefficients", "paper_id": "WOS:000334133100004"}