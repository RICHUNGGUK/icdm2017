{"auto_keywords": [{"score": 0.048231156244864744, "phrase": "false_reject_rate"}, {"score": 0.046448599314105624, "phrase": "false_accept_rate"}, {"score": 0.00481495049065317, "phrase": "different_requirements"}, {"score": 0.004278807087784626, "phrase": "classification_applications"}, {"score": 0.0040334640350288, "phrase": "classifier_learning"}, {"score": 0.003728000957725218, "phrase": "asymmetric_factor"}, {"score": 0.0031223774204093713, "phrase": "novel_adaboost_algorithm"}, {"score": 0.0028293966058473476, "phrase": "asymmetric_weight"}, {"score": 0.0025137856138000014, "phrase": "theoretical_analysis"}, {"score": 0.002233301265743633, "phrase": "upper_bound"}, {"score": 0.0021049977753042253, "phrase": "classification_error"}], "paper_keywords": ["AdaBoost", " adaptive weight", " asymmetric error"], "paper_abstract": "There should be different requirements for False Reject rate and False Accept rate in classification applications, and classifier learning should use an asymmetric factor to balance between False Reject rate and False Accept rate. A novel AdaBoost algorithm was developed with the asymmetric weight. Moreover we provide the theoretical analysis of its performance and derive the upper bound of the classification error.", "paper_title": "AN ASYMMETRIC ADAPTIVE CLASSIFICATION METHOD", "paper_id": "WOS:000286754500008"}