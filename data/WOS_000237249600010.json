{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "weighted_nearest_neighbor"}, {"score": 0.004659951478263083, "phrase": "unlabeled_data"}, {"score": 0.004436716583179764, "phrase": "data-mining_applications"}, {"score": 0.004258843584164121, "phrase": "molecular_profiling"}, {"score": 0.004054745478848129, "phrase": "machine_learning_algorithms"}, {"score": 0.0038603905208013482, "phrase": "labeled_and_unlabeled_data"}, {"score": 0.0037055370870874484, "phrase": "unlabeled_examples"}, {"score": 0.0035861227263414537, "phrase": "labeled_examples"}, {"score": 0.00335867620389808, "phrase": "two-stage_classifier"}, {"score": 0.0031199418866663543, "phrase": "available_unlabeled_data"}, {"score": 0.002994701080666466, "phrase": "weighted_nearest_neighbor_classification_algorithm"}, {"score": 0.002921975748248106, "phrase": "combined_example-sets"}, {"score": 0.0028510114763213596, "phrase": "knowledge_base"}, {"score": 0.0027141975147496264, "phrase": "unlabeled_set"}, {"score": 0.0025211567863488962, "phrase": "initial_classifier"}, {"score": 0.0024001337476063094, "phrase": "limited_available_training_data"}, {"score": 0.002322689143237591, "phrase": "appropriate_weights"}, {"score": 0.002266246304762945, "phrase": "prelabeled_data"}, {"score": 0.0022111720236287547, "phrase": "nearest_neighbor"}, {"score": 0.0021049977753042253, "phrase": "original_classifier"}], "paper_keywords": [""], "paper_abstract": "The development of, data-mining applications such as text-classification and molecular profiling has shown the need for machine learning algorithms that can benefit from both labeled and unlabeled data, where often the unlabeled examples greatly outnumber the labeled examples. In this paper we present a two-stage classifier that improves its predictive accuracy by making use of the available unlabeled data. It uses a weighted nearest neighbor classification algorithm using the combined example-sets as a knowledge base. The examples from the unlabeled set are \"pre-labeled\" by an initial classifier that is build using the limited available training data. By choosing appropriate weights for this prelabeled data, the nearest neighbor classifier consistently improves on the original classifier.", "paper_title": "Using weighted nearest neighbor to benefit from unlabeled data", "paper_id": "WOS:000237249600010"}