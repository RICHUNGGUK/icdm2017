{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "svm_classification_learning"}, {"score": 0.004771196027464407, "phrase": "support_vector_machines"}, {"score": 0.004600100053651545, "phrase": "popular_classification_algorithms"}, {"score": 0.004276016541197123, "phrase": "large_set"}, {"score": 0.004237138632255772, "phrase": "learning_samples"}, {"score": 0.004179480763003705, "phrase": "learning_efficiency"}, {"score": 0.0037454814403672697, "phrase": "optimal_classification"}, {"score": 0.0036275736378775757, "phrase": "training_svms"}, {"score": 0.0035294580355761506, "phrase": "training_time"}, {"score": 0.00349734405943853, "phrase": "space_complexity"}, {"score": 0.003356396922662246, "phrase": "neighborhood_based_rough_set_model"}, {"score": 0.0031627430133087616, "phrase": "sample_spaces"}, {"score": 0.0029396242707327986, "phrase": "input_features"}, {"score": 0.0028340217672278975, "phrase": "weakly_relevant_and_indispensable_features"}, {"score": 0.0025981315738078793, "phrase": "boundary_samples"}, {"score": 0.0025627194819793347, "phrase": "relevant_and_indispensable_feature_subspaces"}, {"score": 0.0025047659706737215, "phrase": "sample_selection"}, {"score": 0.00243694486220507, "phrase": "proposed_model"}, {"score": 0.0023818288346547692, "phrase": "experimental_results"}, {"score": 0.002234031373581961, "phrase": "mean_time"}, {"score": 0.0022136780933978612, "phrase": "classification_performances"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Support vector machine", " Rough set", " Neighborhood relation", " Sample selection", " Feature selection"], "paper_abstract": "Support vector machines (SVMs) are a class of popular classification algorithms for their high generalization ability. However, it is time-consuming to train SVMs with a large set of learning samples. Improving learning efficiency is one of most important research tasks on SVMs. It is known that although there are many candidate training samples in some learning tasks, only the samples near decision boundary which are called support vectors have impact on the optimal classification hyper-planes. Finding these samples and training SVMs with them will greatly decrease training time and space complexity. Based on the observation, we introduce neighborhood based rough set model to search boundary samples. Using the model, we firstly divide sample spaces into three subsets: positive region, boundary and noise. Furthermore, we partition the input features into four subsets: strongly relevant features, weakly relevant and indispensable features, weakly relevant and superfluous features, and irrelevant features. Then we train SVMs only with the boundary samples in the relevant and indispensable feature subspaces, thus feature and sample selection is simultaneously conducted with the proposed model. A set of experimental results show the model can select very few features and samples for training; in the mean time the classification performances are preserved or even improved. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Neighborhood based sample and feature selection for SVM classification learning", "paper_id": "WOS:000290838600011"}