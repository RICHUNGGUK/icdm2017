{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "labeled_and_unlabeled_examples"}, {"score": 0.004444921827311577, "phrase": "new_form"}, {"score": 0.004103212598803194, "phrase": "marginal_distribution"}, {"score": 0.003942299471749811, "phrase": "semi-supervised_framework"}, {"score": 0.0038642157757169315, "phrase": "labeled_and_unlabeled_data"}, {"score": 0.00378767277402891, "phrase": "general-purpose_learner"}, {"score": 0.003712640297460159, "phrase": "transductive_graph"}, {"score": 0.003614895644619489, "phrase": "standard_methods"}, {"score": 0.0035669891404642015, "phrase": "support_vector_machines"}, {"score": 0.0035197152758635344, "phrase": "regularized_least_squares"}, {"score": 0.003404244237372396, "phrase": "special_cases"}, {"score": 0.0032489004068215407, "phrase": "kernel_hilbert_spaces"}, {"score": 0.0030799988391729464, "phrase": "theoretical_basis"}, {"score": 0.002842920225545139, "phrase": "purely_graph-based_approaches"}, {"score": 0.0027495914857929584, "phrase": "natural_out-of-sample_extension"}, {"score": 0.002520990102833368, "phrase": "truly_semi-supervised_settings"}, {"score": 0.0024545413637350765, "phrase": "experimental_evidence"}, {"score": 0.0023268399760599336, "phrase": "unlabeled_data"}, {"score": 0.002220551141101661, "phrase": "brief_discussion"}], "paper_keywords": ["semi-supervised learning", " graph transduction", " regularization", " kernel methods", " manifold learning", " spectral graph theory", " unlabeled data", " support vector machines"], "paper_abstract": "We propose a family of learning algorithms based on a new form of regularization that allows us to exploit the geometry of the marginal distribution. We focus on a semi-supervised framework that incorporates labeled and unlabeled data in a general-purpose learner. Some transductive graph learning algorithms and standard methods including support vector machines and regularized least squares can be obtained as special cases. We use properties of reproducing kernel Hilbert spaces to prove new Representer theorems that provide theoretical basis for the algorithms. As a result ( in contrast to purely graph-based approaches) we obtain a natural out-of-sample extension to novel examples and so are able to handle both transductive and truly semi-supervised settings. We present experimental evidence suggesting that our semi-supervised algorithms are able to use unlabeled data effectively. Finally we have a brief discussion of unsupervised and fully supervised learning within our general framework.", "paper_title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples", "paper_id": "WOS:000245390700005"}