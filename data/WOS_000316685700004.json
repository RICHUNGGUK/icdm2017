{"auto_keywords": [{"score": 0.04980781719029459, "phrase": "tensor_product_smooths"}, {"score": 0.04940434737342581, "phrase": "natural_way"}, {"score": 0.030245937979909057, "phrase": "marginal_smooths"}, {"score": 0.00481495049065317, "phrase": "mixed_models"}, {"score": 0.004706821999798591, "phrase": "smooth_interaction_terms"}, {"score": 0.004680169643744616, "phrase": "regression_models"}, {"score": 0.004421770937919324, "phrase": "arbitrary_decisions"}, {"score": 0.004396725551762061, "phrase": "relative_scaling"}, {"score": 0.0042493917291653105, "phrase": "smooth_interactions"}, {"score": 0.004225318573570145, "phrase": "mixed_regression_models"}, {"score": 0.004130376386308024, "phrase": "tensor_product_constructions"}, {"score": 0.003935620172060555, "phrase": "new_approach"}, {"score": 0.0037287578312533596, "phrase": "fixed_effects"}, {"score": 0.0036037265181631324, "phrase": "previously_published_construction"}, {"score": 0.003502731108174352, "phrase": "random_effects_structure"}, {"score": 0.0034434928798003956, "phrase": "almost_any_flexible_mixed_modelling_software"}, {"score": 0.0033279950116371208, "phrase": "generalized_linear_mixed_model"}, {"score": 0.0032810180076973806, "phrase": "computationally_convenient_separation"}, {"score": 0.0032624127956206316, "phrase": "smoothing_penalties"}, {"score": 0.002970177327299509, "phrase": "function_shape"}, {"score": 0.002936577024096783, "phrase": "tensor_product_smoothing_methods"}, {"score": 0.002886885861509621, "phrase": "smooth_functions"}, {"score": 0.002838033152426417, "phrase": "lower_dimension"}, {"score": 0.002782079283183827, "phrase": "previous_literature"}, {"score": 0.0027506009796522245, "phrase": "general_case"}, {"score": 0.0026887059722856695, "phrase": "quadratically_penalized_basis_expansion"}, {"score": 0.0025472157850600563, "phrase": "identifiability_constraints"}, {"score": 0.0024969812322112174, "phrase": "mixed_model"}, {"score": 0.002447734941784553, "phrase": "simple_additive_model"}, {"score": 0.00235883374582576, "phrase": "interesting_side_effect"}, {"score": 0.0021534846185436497, "phrase": "applied_problems"}, {"score": 0.002123051344001408, "phrase": "abundance_survey_data"}], "paper_keywords": ["Tensor product", " Smooth", " Smoothing spline ANOVA", " Low rank", " Space-time", " Spatio-temporal", " Identifiability constraint", " Mixed model"], "paper_abstract": "Tensor product smooths provide the natural way of representing smooth interaction terms in regression models because they are invariant to the units in which the covariates are measured, hence avoiding the need for arbitrary decisions about relative scaling of variables. They would also be the natural way to represent smooth interactions in mixed regression models, but for the fact that the tensor product constructions proposed to date are difficult or impossible to estimate using most standard mixed modelling software. This paper proposes a new approach to the construction of tensor product smooths, which allows the smooth to be written as the sum of some fixed effects and some sets of i.i.d. Gaussian random effects: no previously published construction achieves this. Because of the simplicity of this random effects structure, our construction is useable with almost any flexible mixed modelling software, allowing smooth interaction terms to be readily incorporated into any Generalized Linear Mixed Model. To achieve the computationally convenient separation of smoothing penalties, the construction differs from previous tensor product approaches in the penalties used to control smoothness, but the penalties have the advantage over several alternative approaches of being explicitly interpretable in terms of function shape. Like all tensor product smoothing methods, our approach builds up smooth functions of several variables from marginal smooths of lower dimension, but unlike much of the previous literature we treat the general case in which the marginal smooths can be any quadratically penalized basis expansion, and there can be any number of them. We also point out that the imposition of identifiability constraints on smoothers requires more care in the mixed model setting than it would in a simple additive model setting, and show how to deal with the issue. An interesting side effect of our construction is that an ANOVA-decomposition of the smooth can be read off from the estimates, although this is not our primary focus. We were motivated to undertake this work by applied problems in the analysis of abundance survey data, and two examples of this are presented.", "paper_title": "Straightforward intermediate rank tensor product smoothing in mixed models", "paper_id": "WOS:000316685700004"}