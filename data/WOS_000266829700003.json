{"auto_keywords": [{"score": 0.04926219622874721, "phrase": "adg"}, {"score": 0.00481495049065317, "phrase": "adjoint_code_generator"}, {"score": 0.004456044928556639, "phrase": "adjoint_codes"}, {"score": 0.004053362743156545, "phrase": "hessian-vector_products"}, {"score": 0.0037188360359702182, "phrase": "independent_variables"}, {"score": 0.003267925215811654, "phrase": "least_program_behavior_decomposition_method"}, {"score": 0.0029722900280316216, "phrase": "concerned_concepts"}, {"score": 0.00265710026740799, "phrase": "adg."}, {"score": 0.0024799423362011582, "phrase": "design_architecture"}, {"score": 0.0023958326775913165, "phrase": "implementation_details"}, {"score": 0.002197801146305747, "phrase": "code_optimization"}, {"score": 0.0021416404045850224, "phrase": "experimental_results"}], "paper_keywords": ["gradient", " Hessian", " adjoint model", " automatic differentiation"], "paper_abstract": "The adjoint code generator (ADG) is developed to produce the adjoint codes, which are used to analytically calculate gradients and the Hessian-vector products with the costs independent of the number of the independent variables. Different from other automatic differentiation tools, the implementation of ADG has advantages of using the least program behavior decomposition method and several static dependence analysis techniques. In this paper we first address the concerned concepts and fundamentals, and then introduce the functionality and the features of ADG. In particular, we also discuss the design architecture of ADG and implementation details including the recomputation and storing strategy and several techniques for code optimization. Some experimental results in several applications are presented at the end.", "paper_title": "Adjoint code generator", "paper_id": "WOS:000266829700003"}