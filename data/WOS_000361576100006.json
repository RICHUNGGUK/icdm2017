{"auto_keywords": [{"score": 0.04665550215861355, "phrase": "speech_recognition"}, {"score": 0.046308404263363405, "phrase": "background_noise"}, {"score": 0.044111484437312234, "phrase": "iterative_channel_estimation_method"}, {"score": 0.004818528277835571, "phrase": "gaussian"}, {"score": 0.004667149874736771, "phrase": "iterative_channel_estimation"}, {"score": 0.004559270778306828, "phrase": "effective_feature_compensation_scheme"}, {"score": 0.004506265705673849, "phrase": "severely_adverse_environments"}, {"score": 0.004266907250334316, "phrase": "proposed_scheme"}, {"score": 0.004040211152784802, "phrase": "based_feature_compensation_algorithm"}, {"score": 0.003993216345115755, "phrase": "new_speech_corpus"}, {"score": 0.003870541730075597, "phrase": "convolutional_noise_corruption"}, {"score": 0.0038255128976509545, "phrase": "channel_distortion_effects"}, {"score": 0.0037516215763875225, "phrase": "ntimit_and_ctimit_corpora"}, {"score": 0.0036791522245326514, "phrase": "objective_measures"}, {"score": 0.003650557076320074, "phrase": "stnr"}, {"score": 0.003622183906271663, "phrase": "pesq"}, {"score": 0.0035245918797629804, "phrase": "highly_challenging_acoustic_conditions"}, {"score": 0.003443031148055198, "phrase": "proposed_feature_compensation_method"}, {"score": 0.00337650257503995, "phrase": "developed_speech_corpus"}, {"score": 0.0033372020049592726, "phrase": "experimental_results"}, {"score": 0.0032855095476183372, "phrase": "proposed_feature_compensation_scheme"}, {"score": 0.0032220148724914867, "phrase": "speech_recognition_performance"}, {"score": 0.0030269369940823902, "phrase": "proposed_pcgmm-based_feature_compensation_scheme"}, {"score": 0.002865929543375884, "phrase": "averaged_wer"}, {"score": 0.002821516317503421, "phrase": "etsi_afe_algorithm"}, {"score": 0.0027886573969044042, "phrase": "developed_speech_corpora"}, {"score": 0.0027669641413939593, "phrase": "ntimit"}, {"score": 0.002745438358145758, "phrase": "ctimit_channel_effects"}, {"score": 0.002702887319160534, "phrase": "real-fife_application"}, {"score": 0.002671406231520296, "phrase": "voice_activity_detection_technique"}, {"score": 0.0026095369186867707, "phrase": "noise_model"}, {"score": 0.0025892330566358503, "phrase": "pcgmm-based_method"}, {"score": 0.002559072326933071, "phrase": "priori_knowledge"}, {"score": 0.0025292620341476283, "phrase": "non-speech_locations"}, {"score": 0.002470676601347937, "phrase": "proposed_method"}, {"score": 0.0024134449026937586, "phrase": "cu-move_corpus"}, {"score": 0.002366763442497185, "phrase": "-vehicle_conditions"}, {"score": 0.0022939396079753463, "phrase": "etsi_afe."}, {"score": 0.0022407927161620855, "phrase": "proposed_pcgmm-based_feature_compensation_method"}, {"score": 0.002171836484200008, "phrase": "increasing_speech_recognition_accuracy"}, {"score": 0.002154930852763048, "phrase": "real-life_severely_adverse_conditions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Robust speech recognition", " Feature compensation", " Channel estimation", " Model combination", " PCGMM"], "paper_abstract": "This study proposes an effective feature compensation scheme to address severely adverse environments for speech recognition where background noise and channel distortion are simultaneously involved. In the proposed scheme, an iterative channel estimation method is integrated into the framework of our previously proposed Parallel Combined Gaussian Mixture Model (PCGMM) based feature compensation algorithm. A new speech corpus is developed which reflects both additive and convolutional noise corruption. The channel distortion effects are obtained from the NTIMIT and CTIMIT corpora. Evaluation based on objective measures including STNR, PESQ, and speech recognition shows that generated speech corpus includes highly challenging acoustic conditions for speech recognition. The proposed feature compensation method is evaluated over the developed speech corpus. The experimental results demonstrate that the proposed feature compensation scheme is effective at improving speech recognition performance in the presence of both background noise and channel distortion, employing the iterative channel estimation method. The proposed PCGMM-based feature compensation scheme employing the channel estimation method shows +3.58% and +11.61% relative improvements in averaged WER compared to the ETSI AFE algorithm for the developed speech corpora including NTIMIT and CTIMIT channel effects respectively. For real-fife application, a voice activity detection technique is employed to estimate the noise model for PCGMM-based method without a priori knowledge of the non-speech locations of input speech. The proposed method is also evaluated on the CU-Move corpus which represents actual in-vehicle conditions, showing a +12.99% relative improvement compared to the ETSI AFE. This study confirms that the proposed PCGMM-based feature compensation method integrated with channel estimation is effective at increasing speech recognition accuracy in real-life severely adverse conditions. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Advanced parallel combined Gaussian mixture model based feature compensation integrated with iterative channel estimation", "paper_id": "WOS:000361576100006"}