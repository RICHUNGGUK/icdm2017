{"auto_keywords": [{"score": 0.027740271023772693, "phrase": "update_overhead"}, {"score": 0.00481495049065317, "phrase": "hybrid_hardware_architecture"}, {"score": 0.004773692073488661, "phrase": "high-speed_ip_lookups"}, {"score": 0.004632039024076267, "phrase": "network_link_rates"}, {"score": 0.0044369056710423065, "phrase": "high-speed_routers"}, {"score": 0.004305203085016233, "phrase": "ternary_content"}, {"score": 0.004286708921931472, "phrase": "addressable_memory"}, {"score": 0.003967021436047945, "phrase": "high_throughput"}, {"score": 0.003899269293218826, "phrase": "route_updates"}, {"score": 0.003816197777388722, "phrase": "lookup_performance"}, {"score": 0.0037348894128879082, "phrase": "packet_drops"}, {"score": 0.003623949225126944, "phrase": "growing_interest"}, {"score": 0.003592859432554987, "phrase": "virtual_ip_routers"}, {"score": 0.003441352119167824, "phrase": "fast_lookup"}, {"score": 0.0034118234596993836, "phrase": "low_update_overhead"}, {"score": 0.0032538723984338615, "phrase": "hybrid_ip_lookup_architecture"}, {"score": 0.0030898642396380662, "phrase": "efficient_trie_partitioning_scheme"}, {"score": 0.003037047249598515, "phrase": "forwarding_information_base"}, {"score": 0.002934098412396701, "phrase": "large_disjoint_leaf_prefix"}, {"score": 0.0028715299874549245, "phrase": "external_tcam-based_lookup_engine"}, {"score": 0.0027503564589458837, "phrase": "on-chip_sram-based_lookup_pipeline"}, {"score": 0.0026570998719084153, "phrase": "ip_lookup_engines"}, {"score": 0.0025230952890994236, "phrase": "proposed_hybrid_architecture"}, {"score": 0.0024906610581090223, "phrase": "virtual_routers"}, {"score": 0.002226430168622392, "phrase": "previous_work"}, {"score": 0.002197801146305747, "phrase": "memory_consumption"}, {"score": 0.0021416404045850224, "phrase": "utilization_ratio"}], "paper_keywords": ["IP lookup", " route updates", " ternary content addressable memory (TCAM)", " static random access memory (SRAM)-based pipeline"], "paper_abstract": "As network link rates are being pushed beyond 40 Gb/s, IP lookup in high-speed routers is moving to hardware. The ternary content addressable memory (TCAM)-based IP lookup engine and the static random access memory (SRAM)-based IP lookup pipeline are the two most common ways to achieve high throughput. However, route updates in both engines degrade lookup performance and may lead to packet drops. Moreover, there is a growing interest in virtual IP routers where more frequent updates happen. Finding solutions that achieve both fast lookup and low update overhead becomes critical. In this paper, we propose a hybrid IP lookup architecture to address this challenge. The architecture is based on an efficient trie partitioning scheme that divides the forwarding information base (FIB) into two prefix sets: a large disjoint leaf prefix set mapped into an external TCAM-based lookup engine and a small overlapping prefix set mapped into an on-chip SRAM-based lookup pipeline. Critical optimizations are developed on both IP lookup engines to reduce the update overhead. We show how to extend the proposed hybrid architecture to support virtual routers. Our implementation shows a throughput of 250 million lookups per second (equivalent to 128 Gb/s with 64-B packets). The update overhead is significantly lower than that of previous work, the memory consumption is reasonable, and the utilization ratio of most external TCAMs is up to 100%.", "paper_title": "A Hybrid Hardware Architecture for High-Speed IP Lookups and Fast Route Updates", "paper_id": "WOS:000338124100021"}