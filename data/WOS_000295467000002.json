{"auto_keywords": [{"score": 0.04980874191704607, "phrase": "quickbird"}, {"score": 0.03943135149133939, "phrase": "spectral_information"}, {"score": 0.03363894006158369, "phrase": "object_size"}, {"score": 0.00481495049065317, "phrase": "lidar-measured_forest_canopy_height"}, {"score": 0.004747355713871062, "phrase": "lidar"}, {"score": 0.004575854901681043, "phrase": "highly_accurate_information"}, {"score": 0.004550029253278477, "phrase": "forest_vertical_structure"}, {"score": 0.0044105602025248936, "phrase": "optical_remotely_sensed_data"}, {"score": 0.004360906420260988, "phrase": "promising_results"}, {"score": 0.004074457750151711, "phrase": "forest_canopy_heights"}, {"score": 0.004039995317682942, "phrase": "small-footprint_lidar_data"}, {"score": 0.003938340235432683, "phrase": "multiscale_geographic_object-based_image_analysis"}, {"score": 0.003916098498242888, "phrase": "geobia"}, {"score": 0.0038719896823446592, "phrase": "qb_data"}, {"score": 0.003817548980308163, "phrase": "conifer_stands"}, {"score": 0.003437697879833853, "phrase": "forest_variability"}, {"score": 0.0034182738124051777, "phrase": "neighboring_objects"}, {"score": 0.003322781957744817, "phrase": "vertical_forest_structure"}, {"score": 0.0032946562900625187, "phrase": "novel_object_area-weighted_error_calculation_approach"}, {"score": 0.0031397016413607795, "phrase": "best_object_scale"}, {"score": 0.003009022147559257, "phrase": "canopy_height"}, {"score": 0.002958281631770322, "phrase": "new_perspective"}, {"score": 0.0029249294679606656, "phrase": "height_variability"}, {"score": 0.0027170943110836425, "phrase": "traditional_pixel-based_approach"}, {"score": 0.0026113524778702624, "phrase": "shadow_fraction_variables"}, {"score": 0.0025892330566358503, "phrase": "model_performance"}, {"score": 0.0025311573083044545, "phrase": "deciduous_trees"}, {"score": 0.0025026085288350004, "phrase": "average_increase"}, {"score": 0.002432633980666185, "phrase": "root_mean_squared_error"}, {"score": 0.0023713273141757326, "phrase": "geobia_approach"}, {"score": 0.002234206434819338, "phrase": "geobia_models"}, {"score": 0.0022089995300212588, "phrase": "pixel-based_models"}, {"score": 0.0021655683497137234, "phrase": "inappropriately_selected_object_scales"}, {"score": 0.002141134176057931, "phrase": "poorer_height_accuracies"}, {"score": 0.0021049977753042253, "phrase": "applied_pixel-based_approach"}], "paper_keywords": ["geographic object-based image analysis", " multiscale", " geographic object-based texture", " shadow fraction", " Quickbird", " lidar", " forests"], "paper_abstract": "Lidar (light detection and ranging) has demonstrated the ability to provide highly accurate information on forest vertical structure; however, lidar data collection and processing are still expensive. Very high spatial resolution optical remotely sensed data have also shown promising results to delineate various forest biophysical properties. In this study, our main objective is to examine the potential of Quickbird (QB) imagery to accurately estimate forest canopy heights measured from small-footprint lidar data. To achieve this, we have developed multiscale geographic object-based image analysis (GEOBIA) models from QB data for both deciduous and conifer stands. In addition to the spectral information, these models also included (1) image-texture [i.e., an internal-object variability measure and a new dynamic geographic object-based texture (GEOTEX) measure that quantifies forest variability within neighboring objects] and (2) a canopy shadow fraction measure that acts as a proxy of vertical forest structure. A novel object area-weighted error calculation approach was used to evaluate model performance by considering the importance of object size. To determine the best object scale [i.e., mean object size (MOS)] for defining the most accurate canopy height estimates, we introduce a new perspective, which considers height variability both between-and within-objects at all scales. To better evaluate the improvements resulting from our GEOBIA models, we compared their performance with a traditional pixel-based approach. Our results show that (1) the addition of image-texture and shadow fraction variables increases the model performance versus using spectral information only, especially for deciduous trees, where the average increase of R(2) is approximately 23% with a further 1.47 m decrease of Root Mean Squared Error (RMSE) at all scales using the GEOBIA approach; (2) the best object scale for our study site corresponds to an MOS of 4.00 ha; (3) at most scales, GEOBIA models achieve more accurate results than pixel-based models; however, we note that inappropriately selected object scales may result in poorer height accuracies than those derived from the applied pixel-based approach.", "paper_title": "A multiscale geographic object-based image analysis to estimate lidar-measured forest canopy height using Quickbird imagery", "paper_id": "WOS:000295467000002"}