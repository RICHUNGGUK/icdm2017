{"auto_keywords": [{"score": 0.049315802984675514, "phrase": "petra"}, {"score": 0.04782295087603994, "phrase": "automatic_parallelization"}, {"score": 0.03687774525172631, "phrase": "automatic_tuning"}, {"score": 0.00481495049065317, "phrase": "modern_parallelizing_compilers"}, {"score": 0.004692699265201631, "phrase": "portable_performance_evaluation_tool"}, {"score": 0.004558855900816642, "phrase": "sequential_programs"}, {"score": 0.004515091332353969, "phrase": "performance_tuning"}, {"score": 0.00447174501210281, "phrase": "important_alternative"}, {"score": 0.004443077867798955, "phrase": "manual_parallelization"}, {"score": 0.004386291308906104, "phrase": "performance_potential"}, {"score": 0.004358169586895055, "phrase": "today's_multicores"}, {"score": 0.004302463542835521, "phrase": "renewed_interest"}, {"score": 0.004179703591623336, "phrase": "comprehensive_evaluation"}, {"score": 0.004073515217375164, "phrase": "underlying_techniques"}, {"score": 0.003970013879881066, "phrase": "informed_decisions"}, {"score": 0.0038941106036522216, "phrase": "industrial_products"}, {"score": 0.003869132124880576, "phrase": "direct_researchers"}, {"score": 0.0038443132503234428, "phrase": "potential_improvements"}, {"score": 0.003782957707237928, "phrase": "experimental_methodology"}, {"score": 0.003746613650522989, "phrase": "fully_automated_implementation"}, {"score": 0.003663157964665246, "phrase": "parallelizing_compilers"}, {"score": 0.0034237422623525937, "phrase": "performance_contributions"}, {"score": 0.0034017706220810223, "phrase": "individual_techniques"}, {"score": 0.003379939505148494, "phrase": "multiple_optimization_levels"}, {"score": 0.0032728607237892038, "phrase": "compiler_optimizations"}, {"score": 0.0031589756301986763, "phrase": "research_compilers"}, {"score": 0.0031386977609818736, "phrase": "industrial_compilers"}, {"score": 0.0030294669203999565, "phrase": "proposed_methodology"}, {"score": 0.0029906933149249533, "phrase": "five_modern_parallelizing_compilers"}, {"score": 0.002895910285227502, "phrase": "evaluation_tool"}, {"score": 0.002840484388249037, "phrase": "parallel_coverage"}, {"score": 0.0027861163438498374, "phrase": "parallel_loops"}, {"score": 0.0027504487463153532, "phrase": "nas_benchmarks"}, {"score": 0.0027239972021363863, "phrase": "program_suite"}, {"score": 0.00242569125010088, "phrase": "significant_additional_performance"}, {"score": 0.002379243574322898, "phrase": "hand-parallelized_programs"}, {"score": 0.002364019570476563, "phrase": "advanced"}, {"score": 0.0022742871983734737, "phrase": "previous_generations"}, {"score": 0.0021254512976941644, "phrase": "specific_reasons"}, {"score": 0.0021049977753042253, "phrase": "measured_performance"}], "paper_keywords": ["Automatic parallelization", " Optimization techniques", " Performance evaluation", " Evaluation methodology", " NPB benchmarks"], "paper_abstract": "This paper describes PETRA: a portable performance evaluation tool for parallelizing compilers and their individual techniques. Automatic parallelization of sequential programs combined with performance tuning is an important alternative to manual parallelization for exploiting the performance potential of today's multicores. Given the renewed interest in autoparallelization, this paper aims at a comprehensive evaluation, identifying strengths and weaknesses in the underlying techniques. The findings allow engineers to make informed decisions about techniques to include in industrial products and direct researchers to potential improvements. We present an experimental methodology and a fully automated implementation for comprehensively evaluating the effectiveness of parallelizing compilers and their underlying optimization techniques. The methodology is the first to (1) include automatic tuning, (2) measure the performance contributions of individual techniques at multiple optimization levels, and (3) quantify the interactions of compiler optimizations. The results will also help close the gap between research compilers and industrial compilers, which are still far behind. We applied the proposed methodology using PETRA on five modern parallelizing compilers and their tuning capabilities, illustrating several use cases and applications for the evaluation tool. We report speedups, parallel coverage, and the number of parallel loops, using the NAS Benchmarks as a program suite. We found parallelizers to be reasonably successful in about half of the given science-engineering programs. An important finding is also that some techniques substitute each other. Furthermore, we found that automatic tuning can lead to significant additional performance and sometimes matches or outperforms hand-parallelized programs. Advanced versions of some of the techniques identified as most successful in previous generations of compilers are also most important today, while other techniques have risen significantly in impact. Finally, we analyze specific reasons for the measured performance and the potential for improvement of automatic parallelization.", "paper_title": "PETRA: Performance Evaluation Tool for Modern Parallelizing Compilers", "paper_id": "WOS:000352287300001"}