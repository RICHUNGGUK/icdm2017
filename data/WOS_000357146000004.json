{"auto_keywords": [{"score": 0.036166955150614445, "phrase": "proposed_network"}, {"score": 0.00481495049065317, "phrase": "disparity-vergence_behavior"}, {"score": 0.004747544039399003, "phrase": "population_reward"}, {"score": 0.0046025376320049955, "phrase": "robot_stereo_head"}, {"score": 0.00456376131573829, "phrase": "robotic_system_implementation"}, {"score": 0.004525310204193961, "phrase": "autonomous_learning_capabilities"}, {"score": 0.0044998554636609955, "phrase": "effective_control"}, {"score": 0.004474543261728526, "phrase": "vergence_eye_movements"}, {"score": 0.004253018585673207, "phrase": "large_tolerance"}, {"score": 0.004193445699579727, "phrase": "real_stereo_heads"}, {"score": 0.004146386253535282, "phrase": "changeable_environment"}, {"score": 0.004111437132764509, "phrase": "proposed_approach"}, {"score": 0.004088300855497412, "phrase": "early_binocular_vision_mechanisms"}, {"score": 0.004065294241465876, "phrase": "basic_learning_processes"}, {"score": 0.004019667124208171, "phrase": "synaptic_plasticity"}, {"score": 0.00399704519135802, "phrase": "reward_modulation"}, {"score": 0.003963349828993976, "phrase": "computational_substrate"}, {"score": 0.003853062158993238, "phrase": "oriented_binocular_disparity_detectors"}, {"score": 0.0038205759273939903, "phrase": "resulting_population_response"}, {"score": 0.003788362554541234, "phrase": "implicit_binocular_depth_cues"}, {"score": 0.0037037769661437563, "phrase": "global_signal"}, {"score": 0.003461145312315784, "phrase": "desired_vergence_position"}, {"score": 0.0032343566763490916, "phrase": "differential_hebbian_rule"}, {"score": 0.0032070701272953563, "phrase": "overall_activity"}, {"score": 0.003126579632610959, "phrase": "intrinsic_signal"}, {"score": 0.0029968794886425227, "phrase": "population_activity"}, {"score": 0.0029465141526991323, "phrase": "highly_effective_reward"}, {"score": 0.0028969927933916676, "phrase": "stable_and_accurate_vergence_behavior"}, {"score": 0.0028483013501083144, "phrase": "different_orientations"}, {"score": 0.002824262516441788, "phrase": "learning_process"}, {"score": 0.0027767900889698713, "phrase": "whole_population"}, {"score": 0.0027147290829871245, "phrase": "differently_oriented_channels"}, {"score": 0.002691814517164577, "phrase": "faster_learning_capability"}, {"score": 0.0026242217741112256, "phrase": "proposed_intrinsic_reward_signal"}, {"score": 0.002572822239596127, "phrase": "ground-truth_signal"}, {"score": 0.002522426900157144, "phrase": "equivalent_results"}, {"score": 0.0024452162861064524, "phrase": "simulated_environment"}, {"score": 0.0023770727209879885, "phrase": "vergent_geometry"}, {"score": 0.002343714737395609, "phrase": "effective_vergence_movements"}, {"score": 0.0023108237893935766, "phrase": "visual_targets"}, {"score": 0.0022977967191969515, "phrase": "experimental_tests"}, {"score": 0.0022848429198019885, "phrase": "real_robot_stereo_pairs"}, {"score": 0.002141009796880959, "phrase": "stimulus_characteristics"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Vergence control", " Stereo vision", " Neural models", " Binocular disparity", " Energy model", " Hebbian learning", " Active vision"], "paper_abstract": "A robotic system implementation that exhibits autonomous learning capabilities of effective control for vergence eye movements is presented. The system, directly relying on a distributed (i.e. neural) representation of binocular disparity, shows a large tolerance to the inaccuracies of real stereo heads and to the changeable environment. The proposed approach combines early binocular vision mechanisms with basic learning processes, such as synaptic plasticity and reward modulation. The computational substrate consists of a network of modeled V1 complex cells that act as oriented binocular disparity detectors. The resulting population response, besides implicit binocular depth cues about the environment, also provides a global signal (i.e. the overall activity of the population itself) to describe the state of the system and thus its deviation from the desired vergence position. The proposed network, by taking into account the modification of its internal state as a consequence of the action performed, evolves following a differential Hebbian rule. The overall activity of the population is exploited to derive an intrinsic signal that drives the weights update. Exploiting this signal implies a maximization of the population activity itself, thus providing an highly effective reward for the developing of a stable and accurate vergence behavior. The role of the different orientations in the learning process is evaluated separately against the whole population, evidencing that the interplay among the differently oriented channels allows a faster learning capability and a more accurate control. The efficacy of the proposed intrinsic reward signal is thus comparatively assessed against the ground-truth signal (the actual disparity) providing equivalent results, and thus validating the approach. Trained in a simulated environment, the proposed network, is able to cope with vergent geometry and thus to learn effective vergence movements for static and moving visual targets. Experimental tests with real robot stereo pairs demonstrate the capability of the architecture not just to directly learn from the environment, but to adapt the control to the stimulus characteristics. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Autonomous learning of disparity-vergence behavior through distributed coding and population reward: Basic mechanisms and real-world conditioning on a robot stereo head", "paper_id": "WOS:000357146000004"}