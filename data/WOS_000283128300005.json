{"auto_keywords": [{"score": 0.03784144720028532, "phrase": "agent's_market_power"}, {"score": 0.00481495049065317, "phrase": "adaptive_q-learning_algorithm"}, {"score": 0.0047515546458205046, "phrase": "agent-based_computational_modeling"}, {"score": 0.004292337783332826, "phrase": "dynamic_uncertain_environment"}, {"score": 0.004198510172614725, "phrase": "significant_subject"}, {"score": 0.004070573090297285, "phrase": "reinforcement_learning"}, {"score": 0.003964007795174772, "phrase": "electricity_market"}, {"score": 0.003709595902020469, "phrase": "learning_methods"}, {"score": 0.0036445446531633368, "phrase": "economic_system"}, {"score": 0.00354909279546064, "phrase": "vital_role"}, {"score": 0.003502305158321511, "phrase": "decision-making_problem"}, {"score": 0.0033955105098235345, "phrase": "ql_method"}, {"score": 0.003350740737336966, "phrase": "main_idea"}, {"score": 0.0032485526269852606, "phrase": "market_power"}, {"score": 0.003163439005885435, "phrase": "good_balance"}, {"score": 0.0030399188412691914, "phrase": "adaptation_process"}, {"score": 0.0029733865110222785, "phrase": "fuzzy_nature"}, {"score": 0.0029471818883482688, "phrase": "human's_decision-making_process"}, {"score": 0.00278237555651743, "phrase": "ql_parameters"}, {"score": 0.002721464488351771, "phrase": "fuzzy_ql_method"}, {"score": 0.0026501241093379786, "phrase": "power_supplier's_strategic_bidding_behavior"}, {"score": 0.0025465957200502404, "phrase": "simulation_framework"}, {"score": 0.002512990657100351, "phrase": "ql_algorithm"}, {"score": 0.0024798279465139688, "phrase": "power_supplier's_bidding_strategy"}, {"score": 0.002320449502337321, "phrase": "human's_risk_characteristic"}, {"score": 0.0022595974985992664, "phrase": "proposed_methodology"}, {"score": 0.0022297712188622293, "phrase": "power_supplier"}, {"score": 0.002200337772403983, "phrase": "multiarea_power_system"}, {"score": 0.0021712920081029194, "phrase": "performance_improvement"}, {"score": 0.0021049977753042253, "phrase": "fixed_parameters"}], "paper_keywords": ["Agent-based computational modeling", " electricity market", " Q-learning (QL)", " risk strategy"], "paper_abstract": "Balancing between exploration and exploitation with adaptation of the Q-learning (QL) parameters to the condition of dynamic uncertain environment has always been a significant subject of interest in the context of reinforcement learning. The peculiarities of the electricity market have provided such complex dynamic economic environment, and consequently have increased the requirement for advancement of the learning methods. In this economic system, the agent's market power plays a vital role in bidding decision-making problem. In order to improve the QL method, as main idea, adaptation of its parameters to the market power is proposed for making a good balance between exploration and exploitation. To implement this adaptation process, due to the fuzzy nature of human's decision-making process, a fuzzy system is designed to map each agent's market power into the QL parameters. Therefore, a fuzzy QL method is developed to model the power supplier's strategic bidding behavior in a computational electricity market. In the simulation framework, the QL algorithm selects the power supplier's bidding strategy according to the past experiences and the values of the parameters, which show the human's risk characteristic. The application of the proposed methodology for the power supplier in a multiarea power system shows the performance improvement in comparison to the QL with fixed parameters.", "paper_title": "An Adaptive Q-Learning Algorithm Developed for Agent-Based Computational Modeling of Electricity Market", "paper_id": "WOS:000283128300005"}