{"auto_keywords": [{"score": 0.03303103209185277, "phrase": "mean-squared_error"}, {"score": 0.00481495049065317, "phrase": "textnn-a_matlab"}, {"score": 0.004769958800452922, "phrase": "textural_classification"}, {"score": 0.004740197030914445, "phrase": "neural_networks"}, {"score": 0.004695900553353526, "phrase": "new_matlab_code"}, {"score": 0.004579780586951551, "phrase": "textural_images"}, {"score": 0.004328856052035968, "phrase": "textural_neural_network"}, {"score": 0.004301834610818624, "phrase": "textnn"}, {"score": 0.0042085753823566125, "phrase": "variogram_maps"}, {"score": 0.004169226023596022, "phrase": "frequency_domain"}, {"score": 0.004143196873246147, "phrase": "specific_lag_distances"}, {"score": 0.003953068310598579, "phrase": "spatial_domain"}, {"score": 0.003916098498242888, "phrase": "directional_or_omni-directional_semivariograms"}, {"score": 0.003807242767474929, "phrase": "textural_information"}, {"score": 0.003771631577951067, "phrase": "semivariance_values"}, {"score": 0.0037363522297378777, "phrase": "lag_distances"}, {"score": 0.003666776809252461, "phrase": "histogram_measures"}, {"score": 0.003621111838638197, "phrase": "standard_deviation"}, {"score": 0.003487489029588045, "phrase": "selected_group"}, {"score": 0.003358780420024205, "phrase": "moving_window"}, {"score": 0.003327349929456035, "phrase": "feed-forward_back-propagation_neural_network"}, {"score": 0.0032449610741097992, "phrase": "feature_vectors"}, {"score": 0.0032246835734680377, "phrase": "predefined_classes"}, {"score": 0.003154701855951328, "phrase": "training_phase"}, {"score": 0.0029260602766930065, "phrase": "test_set"}, {"score": 0.00285357934700279, "phrase": "contingency_matrices"}, {"score": 0.002835740601294821, "phrase": "global_accuracy"}, {"score": 0.002818013056816282, "phrase": "kappa_coefficient"}, {"score": 0.0027139447110929586, "phrase": "quantitative_appraisal"}, {"score": 0.002688532127821979, "phrase": "predictive_power"}, {"score": 0.0026633568650501873, "phrase": "neural_network_models"}, {"score": 0.0025892330566358503, "phrase": "best_model"}, {"score": 0.0025569530630374995, "phrase": "k-fold_cross-validation"}, {"score": 0.0025171669791790438, "phrase": "unique_split-sample_dataset"}, {"score": 0.0023864566654035924, "phrase": "end-user_program"}, {"score": 0.0023566987138026285, "phrase": "synthetic_images"}, {"score": 0.0023419588513908783, "phrase": "orbital_synthetic_aperture_radar"}, {"score": 0.0022767594422780026, "phrase": "oil-seepage_detection"}, {"score": 0.0022203512113953025, "phrase": "sar"}, {"score": 0.0021995257343837547, "phrase": "geologic_mapping"}, {"score": 0.002172093645267283, "phrase": "overall_results"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Semivariograms", " Supervised classification", " Feed-forward neural networks", " Textural images", " RADAR images"], "paper_abstract": "A new MATLAB code that provides tools to perform classification of textural images for applications in the geosciences is presented in this paper. The program, here coined as textural neural network (TEXTNN), comprises the computation of variogram maps in the frequency domain for specific lag distances in the neighborhood of a pixel. The result is then converted back to spatial domain, where directional or omni-directional semivariograms are extracted. Feature vectors are built with textural information composed of semivariance values at these lag distances and, moreover, with histogram measures of mean, standard deviation and weighted-rank fill ratio. This procedure is applied to a selected group of pixels or to all pixels in an image using a moving window. A feed-forward back-propagation neural network can then be designed and trained on feature vectors of predefined classes (training set). The training phase minimizes the mean-squared error on the training set. Additionally, at each iteration, the mean-squared error for every validation is assessed and a test set is evaluated. The program also calculates contingency matrices, global accuracy and kappa coefficient for the training, validation and test sets, allowing a quantitative appraisal of the predictive power of the neural network models. The interpreter is able to select the best model obtained from a k-fold cross-validation or to use a unique split-sample dataset for classification of all pixels in a given textural image. The performance of the algorithms and the end-user program were tested using synthetic images, orbital synthetic aperture radar (SAR) (RADARSAT) imagery for oil-seepage detection, and airborne, multi-polarized SAR imagery for geologic mapping, and the overall results are considered quite positive. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "TEXTNN-A MATLAB program for textural classification using neural networks", "paper_id": "WOS:000271368500014"}