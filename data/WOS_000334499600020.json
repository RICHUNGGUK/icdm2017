{"auto_keywords": [{"score": 0.047917862153602386, "phrase": "depth_estimation"}, {"score": 0.010507489578808505, "phrase": "single_image"}, {"score": 0.00481495049065317, "phrase": "gpu-accelerated_single_image_depth"}, {"score": 0.004748740786945996, "phrase": "color-filtered_aperture"}, {"score": 0.004555499634179394, "phrase": "multiple_image_depth_estimation"}, {"score": 0.004513631630494221, "phrase": "single_image_depth_estimation"}, {"score": 0.004349955692802962, "phrase": "high_hardware_cost"}, {"score": 0.004270347498153512, "phrase": "multiple_cameras"}, {"score": 0.004172874316207784, "phrase": "simple_software_algorithm"}, {"score": 0.0040215052006051235, "phrase": "low_hardware_cost"}, {"score": 0.003966162568548304, "phrase": "software_algorithm"}, {"score": 0.003839962121679795, "phrase": "recent_trends"}, {"score": 0.003517223847512266, "phrase": "optical_elements"}, {"score": 0.0034210342328868017, "phrase": "conventional_camera"}, {"score": 0.0031625006830124512, "phrase": "graphics_processing_unit"}, {"score": 0.003133514262134615, "phrase": "gpu"}, {"score": 0.0030759821501544224, "phrase": "desktop_pc"}, {"score": 0.0030196181347744372, "phrase": "real-time_application"}, {"score": 0.0029642838574678526, "phrase": "parallel_processing_technique"}, {"score": 0.002909960617042717, "phrase": "compute_shader"}, {"score": 0.0028172726995962173, "phrase": "compute-intensive_implementation"}, {"score": 0.00274017282519193, "phrase": "single_view_image"}, {"score": 0.0026163878528969917, "phrase": "matlab"}, {"score": 0.0025329623864528317, "phrase": "almost_twice_the_real-time_standard"}, {"score": 0.0024522530645471065, "phrase": "previous_literature"}, {"score": 0.002225196379204285, "phrase": "frame_rate"}, {"score": 0.0021443262599352996, "phrase": "previous_studies"}, {"score": 0.0021245712108461227, "phrase": "multiple_images"}], "paper_keywords": ["Real time", " graphics processing unit", " parallel processing technique", " compute shade"], "paper_abstract": "There are two major ways to implement depth estimation, multiple image depth estimation and single image depth estimation, respectively. The former has a high hardware cost because it uses multiple cameras but it has a simple software algorithm. Conversely, the latter has a low hardware cost but the software algorithm is complex. One of the recent trends in this field is to make a system compact, or even portable, and to simplify the optical elements to be attached to the conventional camera. In this paper, we present an implementation of depth estimation with a single image using a graphics processing unit (GPU) in a desktop PC, and achieve real-time application via our evolutional algorithm and parallel processing technique, employing a compute shader. The methods greatly accelerate the compute-intensive implementation of depth estimation with a single view image from 0.003 frames per second (fps) (implemented in MATLAB) to 53 fps, which is almost twice the real-time standard of 30 fps. In the previous literature, to the best of our knowledge, no paper discusses the optimization of depth estimation using a single image, and the frame rate of our final result is better than that of previous studies using multiple images, whose frame rate is about 20fps.", "paper_title": "GPU-Accelerated Single Image Depth Estimation with Color-Filtered Aperture", "paper_id": "WOS:000334499600020"}