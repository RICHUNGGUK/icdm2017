{"auto_keywords": [{"score": 0.048877326221094704, "phrase": "human_motion"}, {"score": 0.040454428776653985, "phrase": "mocap_data"}, {"score": 0.039717311925460824, "phrase": "training_data"}, {"score": 0.00481495049065317, "phrase": "human_motion_segmentation"}, {"score": 0.004784448637292493, "phrase": "motion_regularities"}, {"score": 0.004576253356889219, "phrase": "important_role"}, {"score": 0.004489810932879285, "phrase": "medical_rehabilitation"}, {"score": 0.0043080553835735825, "phrase": "fundamental_functions"}, {"score": 0.004253618550301311, "phrase": "segmentation_methods"}, {"score": 0.0040298010803060495, "phrase": "better_performance"}, {"score": 0.0038789122930433305, "phrase": "intrinsic_regularities"}, {"score": 0.003805591825381666, "phrase": "small_set"}, {"score": 0.0037336520904376687, "phrase": "daily-life_motions"}, {"score": 0.0036747384051186937, "phrase": "learnt_motion_regularities"}, {"score": 0.0036052633308076933, "phrase": "long_motion_sequences"}, {"score": 0.003582397044768098, "phrase": "motion_types"}, {"score": 0.0033402088717816416, "phrase": "small_number"}, {"score": 0.0033190180867511605, "phrase": "typical_poses"}, {"score": 0.003287482882222731, "phrase": "motion_vocabulary"}, {"score": 0.0031845067058084583, "phrase": "key_pose_extraction"}, {"score": 0.0030847461428168614, "phrase": "low-level_motion_regularity"}, {"score": 0.002912963877144772, "phrase": "text-like_documents"}, {"score": 0.0028578496983461136, "phrase": "latent_dirichlet_allocation"}, {"score": 0.0028037753646260937, "phrase": "pose_combinations"}, {"score": 0.0027594936602962075, "phrase": "human_motions"}, {"score": 0.0026140878612307536, "phrase": "high-level_motion_regularities"}, {"score": 0.0025727942759279513, "phrase": "target_motion"}, {"score": 0.0025240999184904366, "phrase": "learnt_mo-topics"}, {"score": 0.0025000985765154028, "phrase": "segmentation_task"}, {"score": 0.002421726275597666, "phrase": "notable_changes"}, {"score": 0.0023532890136269986, "phrase": "local_semantic_coherence_curve"}, {"score": 0.002338344706059989, "phrase": "segment_motion_sequences"}, {"score": 0.0022434880661725493, "phrase": "motion_representation"}, {"score": 0.0022292394795878643, "phrase": "logically_correct_results"}, {"score": 0.0021593396036472777, "phrase": "proposed_approach"}, {"score": 0.002138799283553239, "phrase": "available_methods"}, {"score": 0.0021252179662468794, "phrase": "cmu"}, {"score": 0.0021117617021565458, "phrase": "bonn"}, {"score": 0.0021049977753042253, "phrase": "mocap_database"}], "paper_keywords": ["Motion capture", " Motion representation", " Motion segmentation", " Hierarchical clustering", " Latent Dirichlet allocation", " Topic mining"], "paper_abstract": "Analysis and reuse of human motion capture (mocap) data play an important role in animation, games and medical rehabilitation. In various mocap-based animation techniques, motion segmentation is regarded as one of the fundamental functions. Many proposed segmentation methods utilize little or no prior knowledge. However, human motion has its own regularities, so reasonable prior assumptions on these regularities will lead to better performance. In this paper, we focus on the learning of intrinsic regularities of mocap data based on a small set of training data which only contain daily-life motions. By utilizing these learnt motion regularities, we can successfully segment long motion sequences containing motion types that not even include in the training data. First, by assuming that most types of motions can be composed of a small number of typical poses, the motion vocabulary (mo-vocabulary) can be obtained using key pose extraction and clustering analysis, which are regarded as the low-level motion regularity. By replacing each frame with the most similar pose in the mo-vocabulary, mocap data can be transformed into text-like documents. Second, we use latent Dirichlet allocation to capture the patterns of pose combinations that frequently occur in human motions, namely the motion topics (mo-topics), which are regarded as the high-level motion regularities. By representing the target motion as the distribution over the learnt mo-topics, the segmentation task can be naturally turned into a problem of detecting notable changes of this distribution. Finally, we propose local semantic coherence curve to segment motion sequences. Since mo-topics are semantically meaningful and significantly increase the abstraction-level of motion representation, logically correct results can be obtained. The experiments demonstrate that the proposed approach outperforms the available methods on CMU and Bonn mocap database.", "paper_title": "Automated human motion segmentation via motion regularities", "paper_id": "WOS:000347839600004"}