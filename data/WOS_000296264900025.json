{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "csx"}, {"score": 0.00461302961851157, "phrase": "spmv_on_shared_memory_systems"}, {"score": 0.004312622975366676, "phrase": "shared_memory_systems"}, {"score": 0.004260134699483774, "phrase": "multiple_processing_units"}, {"score": 0.004157058883925715, "phrase": "streaming_nature"}, {"score": 0.003910106508089187, "phrase": "effective_strategy"}, {"score": 0.0038154673253945003, "phrase": "kernel's_performance"}, {"score": 0.0036777702949712457, "phrase": "data_volume"}, {"score": 0.003501846136829077, "phrase": "storage_formats"}, {"score": 0.003459191419478298, "phrase": "sparse_matrices"}, {"score": 0.0033139366449568565, "phrase": "non-zero_elements"}, {"score": 0.0031553611552558986, "phrase": "generalized_approach"}, {"score": 0.0028958411976400646, "phrase": "proposed_storage_format"}, {"score": 0.002690406375639144, "phrase": "runtime_code_generation"}, {"score": 0.002641360377825228, "phrase": "specialized_spmv_routines"}, {"score": 0.0025615908073796027, "phrase": "experimental_evaluation"}, {"score": 0.002469032978674379, "phrase": "significant_performance_gains"}, {"score": 0.0023944552329463035, "phrase": "participating_cores_increases"}, {"score": 0.0023079225317714815, "phrase": "csx_construction"}, {"score": 0.002183938718432764, "phrase": "preprocessing_cost"}, {"score": 0.0021049977753042253, "phrase": "online_and_offline_preprocessing"}], "paper_keywords": ["Sparse Matrix-Vector Multiplication", " Shared Memory", " compression", " SpMV", " SMP", " Algorithms", " Performance"], "paper_abstract": "The Sparse Matrix-Vector multiplication (SpMV) kernel scales poorly on shared memory systems with multiple processing units due to the streaming nature of its data access pattern. Previous research has demonstrated that an effective strategy to improve the kernel's performance is to drastically reduce the data volume involved in the computations. Since the storage formats for sparse matrices include metadata describing the structure of non-zero elements within the matrix, we propose a generalized approach to compress metadata by exploiting substructures within the matrix. We call the proposed storage format Compressed Sparse eXtended (CSX). In our implementation we employ runtime code generation to construct specialized SpMV routines for each matrix. Experimental evaluation on two shared memory systems for 15 sparse matrices demonstrates significant performance gains as the number of participating cores increases. Regarding the cost of CSX construction, we propose several strategies which trade performance for preprocessing cost making CSX applicable both to online and offline preprocessing.", "paper_title": "CSX: An Extended Compression Format for SpMV on Shared Memory Systems", "paper_id": "WOS:000296264900025"}