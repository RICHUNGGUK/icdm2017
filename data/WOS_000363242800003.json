{"auto_keywords": [{"score": 0.04749848892978978, "phrase": "lsm"}, {"score": 0.015355106984099667, "phrase": "speech_recognition"}, {"score": 0.00481495049065317, "phrase": "digital_liquid_state_machine"}, {"score": 0.004777034835192062, "phrase": "biologically_inspired_learning"}, {"score": 0.00459186790405058, "phrase": "bioinspired_digital_liquid-state_machine"}, {"score": 0.00450198136261303, "phrase": "low-power_very-large-scale-integration"}, {"score": 0.004293336465549723, "phrase": "authors'_knowledge"}, {"score": 0.004209269012699911, "phrase": "first_work"}, {"score": 0.004143196873246147, "phrase": "bioinspired_spike-based_learning_algorithm"}, {"score": 0.004046020290832207, "phrase": "proposed_online_learning"}, {"score": 0.003935513160201076, "phrase": "input_patterns"}, {"score": 0.0038431888954930083, "phrase": "intermediate_data_storage"}, {"score": 0.0037828412206668206, "phrase": "offline_learning_methods"}, {"score": 0.003738200814271716, "phrase": "ridge_regression"}, {"score": 0.0036940852452587093, "phrase": "proposed_learning_rule"}, {"score": 0.003607404191062938, "phrase": "synaptic_weight_update"}, {"score": 0.003522749900725601, "phrase": "firing_activities"}, {"score": 0.0034811680446852054, "phrase": "corresponding_presynaptic_and_postsynaptic_neurons"}, {"score": 0.0033860360186761533, "phrase": "neural_network"}, {"score": 0.003319675107116333, "phrase": "backpropagation-based_learning"}, {"score": 0.0032161835102640372, "phrase": "proposed_approach"}, {"score": 0.00316565009987584, "phrase": "efficient_parallel_vlsi_implementation"}, {"score": 0.00303072749758085, "phrase": "bioinspired_digital_lsm."}, {"score": 0.002947868524740683, "phrase": "spiking_neural_network_model"}, {"score": 0.0028110458014332187, "phrase": "synaptic_models"}, {"score": 0.0027778413437997635, "phrase": "fading_memory"}, {"score": 0.002627985415362773, "phrase": "synaptic_weight_resolution"}, {"score": 0.002607246047604476, "phrase": "reservoir_size"}, {"score": 0.002576442680766742, "phrase": "recognition_performance"}, {"score": 0.002556109032208553, "phrase": "present_techniques"}, {"score": 0.002486193594641237, "phrase": "hardware_implementation"}, {"score": 0.002408623172021922, "phrase": "isolated_word_recognition"}, {"score": 0.0023427323356117365, "phrase": "proposed_digital_lsm_rivals"}, {"score": 0.0021049977753042253, "phrase": "neural_networks"}], "paper_keywords": ["Hardware implementation", " liquid-state machine (LSM)", " speech recognition", " spike-based learning"], "paper_abstract": "This paper presents a bioinspired digital liquid-state machine (LSM) for low-power very-large-scale-integration (VLSI)-based machine learning applications. To the best of the authors' knowledge, this is the first work that employs a bioinspired spike-based learning algorithm for the LSM. With the proposed online learning, the LSM extracts information from input patterns on the fly without needing intermediate data storage as required in offline learning methods such as ridge regression. The proposed learning rule is local such that each synaptic weight update is based only upon the firing activities of the corresponding presynaptic and postsynaptic neurons without incurring global communications across the neural network. Compared with the backpropagation-based learning, the locality of computation in the proposed approach lends itself to efficient parallel VLSI implementation. We use subsets of the TI46 speech corpus to benchmark the bioinspired digital LSM. To reduce the complexity of the spiking neural network model without performance degradation for speech recognition, we study the impacts of synaptic models on the fading memory of the reservoir and hence the network performance. Moreover, we examine the tradeoffs between synaptic weight resolution, reservoir size, and recognition performance and present techniques to further reduce the overhead of hardware implementation. Our simulation results show that in terms of isolated word recognition evaluated using the TI46 speech corpus, the proposed digital LSM rivals the state-of-the-art hidden Markov-model-based recognizer Sphinx-4 and outperforms all other reported recognizers including the ones that are based upon the LSM or neural networks.", "paper_title": "A Digital Liquid State Machine With Biologically Inspired Learning and Its Application to Speech Recognition", "paper_id": "WOS:000363242800003"}