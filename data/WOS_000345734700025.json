{"auto_keywords": [{"score": 0.04248340330135682, "phrase": "nmf"}, {"score": 0.013106112868675404, "phrase": "nearest_neighbor_graph"}, {"score": 0.012647394963521531, "phrase": "gnmf"}, {"score": 0.011409385098249814, "phrase": "data_samples"}, {"score": 0.00481495049065317, "phrase": "adaptive_graph"}, {"score": 0.004701015188740582, "phrase": "nonnegative_matrix_factorization"}, {"score": 0.004392565073466714, "phrase": "intrinsic_local_geometric_structure"}, {"score": 0.004340263267055143, "phrase": "data_space"}, {"score": 0.003943569631183138, "phrase": "input_data"}, {"score": 0.00374399358035391, "phrase": "original_feature_space"}, {"score": 0.0035544816252832375, "phrase": "noisy_and_irrelevant_features"}, {"score": 0.0033745298175222056, "phrase": "nonlinear_distribution"}, {"score": 0.0033077610063168093, "phrase": "kernel_embedding"}, {"score": 0.0029339151044984134, "phrase": "feature_selection"}, {"score": 0.002910545717767559, "phrase": "multiple-kernel_learning"}, {"score": 0.0027631038845413393, "phrase": "fixed_graph"}, {"score": 0.0026022112631368223, "phrase": "selected_features"}, {"score": 0.002571171956724731, "phrase": "multiple_kernels"}, {"score": 0.0024604876113911173, "phrase": "unified_objective_function"}, {"score": 0.0023925401023682717, "phrase": "adaptive_graph_regularization"}, {"score": 0.0022803854904010347, "phrase": "experimental_results"}, {"score": 0.0022262909736042212, "phrase": "proposed_methods"}, {"score": 0.002199725773957207, "phrase": "state-of-the-art_data_representation_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Data representation", " Nonnegative matrix factorization", " Graph regularization", " Feature selection", " Multi-kernel learning"], "paper_abstract": "Nonnegative matrix factorization (NMF), a popular part-based representation technique, does not capture the intrinsic local geometric structure of the data space. Graph regularized NMF (GNMF) was recently proposed to avoid this limitation by regularizing NMF with a nearest neighbor graph constructed from the input data set. However, GNMF has two main bottlenecks. First, using the original feature space directly to construct the graph is not necessarily optimal because of the noisy and irrelevant features and nonlinear distributions of data samples. Second, one possible way to handle the nonlinear distribution of data samples is by kernel embedding. However, it is often difficult to choose the most suitable kernel. To solve these bottlenecks, we propose two novel graph-regularized NMF methods, AGNMF(FS) and AGNMF(MK), by introducing feature selection and multiple-kernel learning to the graph regularized NMF, respectively. Instead of using a fixed graph as in GNMF, the two proposed methods learn the nearest neighbor graph that is adaptive to the selected features and learned multiple kernels, respectively. For each method, we propose a unified objective function to conduct feature selection/multi-kernel learning, NMF and adaptive graph regularization simultaneously. We further develop two iterative algorithms to solve the two optimization problems. Experimental results on two challenging pattern classification tasks demonstrate that the proposed methods significantly outperform state-of-the-art data representation methods. (C) 2014 The Authors. Published by Elsevier Ltd.", "paper_title": "Feature selection and multi-kernel learning for adaptive graph regularized nonnegative matrix factorization", "paper_id": "WOS:000345734700025"}