{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "distributed_data"}, {"score": 0.004598933498016774, "phrase": "data_holders"}, {"score": 0.0043258453436258405, "phrase": "separate_disclosures"}, {"score": 0.003334309053314909, "phrase": "seemingly_anonymous_data"}, {"score": 0.0031121406603482112, "phrase": "formal_model"}, {"score": 0.003064809736127888, "phrase": "privacy_protection"}, {"score": 0.002629238854352447, "phrase": "sensitive_data_trails"}, {"score": 0.002435190484324197, "phrase": "graph-based_model"}, {"score": 0.002255431275670053, "phrase": "privacy_problem"}, {"score": 0.0022041312401435346, "phrase": "alternative_privacy_protection_models"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["security & privacy", " knowledge discovery", " distributed databases"], "paper_abstract": "In the past, data holders protected the privacy of their constituents by issuing separate disclosures of sensitive (e.g., DNA) and identifying data (e.g., names). However, individuals visit many places and their location-visit patterns, or '' trails '', can re-identify seemingly anonymous data. In this paper, we introduce a formal model of privacy protection, called k-unlinkability, to prevent trail re-identification in distributed data. The model guarantees that sensitive data trails are linkable to no less than k identities. We develop a graph-based model and illustrate how k-unlinkability is a more appropriate solution to this privacy problem compared to alternative privacy protection models. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "k-Unlinkability: A privacy protection model for distributed data", "paper_id": "WOS:000251639400015"}