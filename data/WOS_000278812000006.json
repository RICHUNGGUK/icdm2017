{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "aep"}, {"score": 0.007432631378032911, "phrase": "entropy_rate"}, {"score": 0.004425072111844721, "phrase": "discrete_random_process"}, {"score": 0.004140924670517666, "phrase": "random_process"}, {"score": 0.003714629047818465, "phrase": "information_theory"}, {"score": 0.0035181731203867456, "phrase": "source-coding_algorithms"}, {"score": 0.003117890043128058, "phrase": "ergodic_theorem"}, {"score": 0.0030434561939032597, "phrase": "asymptotic_equipartition_property"}, {"score": 0.002648619227468846, "phrase": "ams"}, {"score": 0.0025388705701873075, "phrase": "pointwise_ergodic_theorem"}, {"score": 0.0021049977753042253, "phrase": "average_codeword_length"}], "paper_keywords": ["Asymptotic equipartition property (AEP)", " asymptotically mean stationary (AMS)", " ergodic theorem"], "paper_abstract": "A word-valued source Y = Y(1),Y(2),... is discrete random process that is formed by sequentially encoding the symbols of a random process X = X(1),X(2),... with codewords from a codebook. These processes appear frequently in information theory (in particular, in the analysis of source-coding algorithms), so it is of interest to give conditions on X and C for which will satisfy an ergodic theorem and possess an asymptotic equipartition property (AEP). In this paper, we prove the following: 1) if X is asymptotically mean stationary (AMS), then will satisfy a pointwise ergodic theorem and possess an AEP; and 2) if the codebook is prefix-free, then the entropy rate of is equal to the entropy rate of X normalized by the average codeword length.", "paper_title": "Word-Valued Sources: An Ergodic Theorem, an AEP, and the Conservation of Entropy", "paper_id": "WOS:000278812000006"}