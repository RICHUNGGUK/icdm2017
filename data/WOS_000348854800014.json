{"auto_keywords": [{"score": 0.04124584638960657, "phrase": "optimal_control_signal"}, {"score": 0.03433421203524884, "phrase": "optimal_weight_vectors"}, {"score": 0.00481495049065317, "phrase": "learning_design-based_adaptive_tracking_control"}, {"score": 0.004734448316824488, "phrase": "nonlinear_discrete-time_mimo_systems"}, {"score": 0.004635701867952543, "phrase": "neural_network"}, {"score": 0.004500891637057374, "phrase": "online_reinforcement"}, {"score": 0.004481954307639453, "phrase": "learning_algorithm"}, {"score": 0.003999578057088828, "phrase": "action_network"}, {"score": 0.0038343546245999285, "phrase": "critic_network"}, {"score": 0.0037701851296383405, "phrase": "cost_function"}, {"score": 0.0035240305920962766, "phrase": "previous_approaches"}, {"score": 0.0033218213825698417, "phrase": "gradient_descent_rule"}, {"score": 0.003078740573398959, "phrase": "existing_results"}, {"score": 0.0030399874838260886, "phrase": "main_contributions"}, {"score": 0.0027819985260847577, "phrase": "adaptation_laws"}, {"score": 0.002723862897844177, "phrase": "previous_results"}, {"score": 0.00266693888510356, "phrase": "updating_parameters"}, {"score": 0.0025458479274370832, "phrase": "mimo_systems"}, {"score": 0.0025137856138000014, "phrase": "tuning_rules"}, {"score": 0.0023794391656001466, "phrase": "critic_networks"}, {"score": 0.0023100907305651872, "phrase": "tracking_errors"}, {"score": 0.002261794227418188, "phrase": "control_inputs"}, {"score": 0.0022145052062614514, "phrase": "lyapunov_analysis_method"}, {"score": 0.0021866066626507028, "phrase": "simulation_examples"}, {"score": 0.0021049977753042253, "phrase": "proposed_algorithm"}], "paper_keywords": ["Adaptive control", " discrete-time systems", " online approximators", " reinforcement learning (RL)", " uncertain nonlinear systems"], "paper_abstract": "Based on the neural network (NN) approximator, an online reinforcement learning algorithm is proposed for a class of affine multiple input and multiple output (MIMO) nonlinear discrete-time systems with unknown functions and disturbances. In the design procedure, two networks are provided where one is an action network to generate an optimal control signal and the other is a critic network to approximate the cost function. An optimal control signal and adaptation laws can be generated based on two NNs. In the previous approaches, the weights of critic and action networks are updated based on the gradient descent rule and the estimations of optimal weight vectors are directly adjusted in the design. Consequently, compared with the existing results, the main contributions of this paper are: 1) only two parameters are needed to be adjusted, and thus the number of the adaptation laws is smaller than the previous results and 2) the updating parameters do not depend on the number of the subsystems for MIMO systems and the tuning rules are replaced by adjusting the norms on optimal weight vectors in both action and critic networks. It is proven that the tracking errors, the adaptation laws, and the control inputs are uniformly bounded using Lyapunov analysis method. The simulation examples are employed to illustrate the effectiveness of the proposed algorithm.", "paper_title": "Reinforcement Learning Design-Based Adaptive Tracking Control With Less Learning Parameters for Nonlinear Discrete-Time MIMO Systems", "paper_id": "WOS:000348854800014"}