{"auto_keywords": [{"score": 0.04573228268553137, "phrase": "var"}, {"score": 0.00481495049065317, "phrase": "still_human_body_segmentation"}, {"score": 0.004761494044422926, "phrase": "depth_images_for_video"}, {"score": 0.004734987730139094, "phrase": "-based_activity_recognition"}, {"score": 0.0046046429665581555, "phrase": "essential_part"}, {"score": 0.004553510708976456, "phrase": "ubiquitous_computing"}, {"score": 0.004428139418750855, "phrase": "video_based_activity_recognition"}, {"score": 0.00423465514675998, "phrase": "important_component"}, {"score": 0.0041642891310893, "phrase": "user's_context"}, {"score": 0.004118026552723285, "phrase": "automatic_service_delivery"}, {"score": 0.004072275820209647, "phrase": "context-aware_applications"}, {"score": 0.0037869901077566526, "phrase": "employed_human_body_segmentation_algorithm"}, {"score": 0.0037449033166879874, "phrase": "previous_human_body_segmentation_algorithms"}, {"score": 0.0036214184763804034, "phrase": "human_body"}, {"score": 0.003541357671562449, "phrase": "bulky_amount"}, {"score": 0.003501991125315889, "phrase": "training_data"}, {"score": 0.0032747835779400212, "phrase": "active_contours"}, {"score": 0.0031845067058084583, "phrase": "successful_segmentation_technique"}, {"score": 0.003149094460617212, "phrase": "still_images"}, {"score": 0.0030282147475402736, "phrase": "active_contour_model"}, {"score": 0.0029447150254434842, "phrase": "chan_vese"}, {"score": 0.0028795712616923462, "phrase": "energy_and_bhattacharya_distance_functions"}, {"score": 0.002815864555488112, "phrase": "automatic_human_body_segmentation"}, {"score": 0.0027382065219709287, "phrase": "var."}, {"score": 0.002707741309851526, "phrase": "proposed_technique"}, {"score": 0.0026478260192958924, "phrase": "existing_segmentation_methods"}, {"score": 0.002618366076489732, "phrase": "normal_scenarios"}, {"score": 0.002354302193867031, "phrase": "prior_human_body_model"}, {"score": 0.002251227801482381, "phrase": "proposed_segmentation_technique"}], "paper_keywords": ["Human body segmentation", " active contour", " Bhattacharyya distance", " activity recognition", " depth camera"], "paper_abstract": "Context-awareness is an essential part of ubiquitous computing, and over the past decade video based activity recognition (VAR) has emerged as an important component to identify user's context for automatic service delivery in context-aware applications. The accuracy of VAR significantly depends on the performance of the employed human body segmentation algorithm. Previous human body segmentation algorithms often engage modeling of the human body that normally requires bulky amount of training data and cannot competently handle changes over time. Recently, active contours have emerged as a successful segmentation technique in still images. In this paper, an active contour model with the integration of Chan Vese (CV) energy and Bhattacharya distance functions are adapted for automatic human body segmentation using depth cameras for VAR. The proposed technique not only outperforms existing segmentation methods in normal scenarios but it is also more robust to noise. Moreover, it is unsupervised, i.e., no prior human body model is needed. The performance of the proposed segmentation technique is compared against conventional CV Active Contour (AC) model using a depth-camera and obtained much better performance over it.", "paper_title": "Active Contours Level Set Based Still Human Body Segmentation from Depth Images For Video-based Activity Recognition", "paper_id": "WOS:000331613500017"}