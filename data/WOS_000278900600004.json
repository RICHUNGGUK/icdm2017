{"auto_keywords": [{"score": 0.03801816490579767, "phrase": "regularization_parameter"}, {"score": 0.00481495049065317, "phrase": "adaptive_kernel_methods"}, {"score": 0.004717325943509345, "phrase": "balancing_principle"}, {"score": 0.004621671570727774, "phrase": "regularization_parameter_choice"}, {"score": 0.004527947981009528, "phrase": "fundamental_problem"}, {"score": 0.004466519142879166, "phrase": "learning_theory"}, {"score": 0.0038695436922618876, "phrase": "main_theoretical_issue"}, {"score": 0.0037395458116642306, "phrase": "prior_knowledge"}, {"score": 0.0034924598001567944, "phrase": "good_learning_rates"}, {"score": 0.003306559295382181, "phrase": "parameter_choice_strategy"}, {"score": 0.0029235593748707495, "phrase": "target_function"}, {"score": 0.002805989498127897, "phrase": "best_error_rate"}, {"score": 0.0027116246112603875, "phrase": "regularization_algorithms"}, {"score": 0.0026565317818265394, "phrase": "kernel_hilbert_space"}, {"score": 0.002602555367635598, "phrase": "square_loss"}, {"score": 0.002463906556781983, "phrase": "similar_principle"}, {"score": 0.0023167153974120083, "phrase": "straightforward_corollary"}, {"score": 0.002238767763626708, "phrase": "adaptive_parameter_choices"}, {"score": 0.002148677187261496, "phrase": "numerical_experiments"}, {"score": 0.0021049977753042253, "phrase": "proposed_parameter_choice_rules"}], "paper_keywords": ["Learning Theory", " Model Selection", " Adaptive Regularization", " Inverse Problems"], "paper_abstract": "The regularization parameter choice is a fundamental problem in Learning Theory since the performance of most supervised algorithms crucially depends on the choice of one or more of such parameters. In particular a main theoretical issue regards the amount of prior knowledge needed to choose the regularization parameter in order to obtain good learning rates. In this paper we present a parameter choice strategy, called the balancing principle, to choose the regularization parameter without knowledge of the regularity of the target function. Such a choice adaptively achieves the best error rate. Our main result applies to regularization algorithms in reproducing kernel Hilbert space with the square loss, though we also study how a similar principle can be used in other situations. As a straightforward corollary we can immediately derive adaptive parameter choices for various kernel methods recently studied. Numerical experiments with the proposed parameter choice rules are also presented.", "paper_title": "Adaptive Kernel Methods Using the Balancing Principle", "paper_id": "WOS:000278900600004"}