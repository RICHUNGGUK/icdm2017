{"auto_keywords": [{"score": 0.035620716932052585, "phrase": "proposed_algorithms"}, {"score": 0.0048149540663384284, "phrase": "semi-supervised"}, {"score": 0.004765788394931875, "phrase": "unsupervised_extreme_learning_machines"}, {"score": 0.004481132747216135, "phrase": "efficient_and_effective_learning_mechanisms"}, {"score": 0.0041703614123283165, "phrase": "supervised_learning_problems"}, {"score": 0.004002513373645485, "phrase": "unlabeled_data"}, {"score": 0.0037057255600764475, "phrase": "unsupervised_tasks"}, {"score": 0.0036303546926971966, "phrase": "manifold_regularization"}, {"score": 0.0034308688638878286, "phrase": "key_advantages"}, {"score": 0.0032256881625734777, "phrase": "semi-supervised_elm"}, {"score": 0.002910545717767559, "phrase": "multiclass_classification"}, {"score": 0.0028807718824400697, "phrase": "multi-cluster_clustering"}, {"score": 0.002708399936381754, "phrase": "unseen_data"}, {"score": 0.0026806884201358515, "phrase": "test_time"}, {"score": 0.0023816257768353344, "phrase": "unified_framework"}, {"score": 0.0023331227492950422, "phrase": "new_perspectives"}, {"score": 0.002262209824105154, "phrase": "random_feature_mapping"}, {"score": 0.0022047613106966745, "phrase": "key_concept"}, {"score": 0.0021821915946356168, "phrase": "elm_theory"}, {"score": 0.002159852420283463, "phrase": "empirical_study"}, {"score": 0.0021267708018655493, "phrase": "wide_range"}, {"score": 0.0021049977753042253, "phrase": "data_sets"}], "paper_keywords": ["Clustering", " embedding", " extreme learning machine (ELM)", " manifold regularization", " semi-supervised learning", " unsupervised learning"], "paper_abstract": "Extreme learning machines (ELMs) have proven to be efficient and effective learning mechanisms for pattern classification and regression. However, ELMs are primarily applied to supervised learning problems. Only a few existing research papers have used ELMs to explore unlabeled data. In this paper, we extend ELMs for both semi-supervised and unsupervised tasks based on the manifold regularization, thus greatly expanding the applicability of ELMs. The key advantages of the proposed algorithms are as follows: 1) both the semi-supervised ELM (SS-ELM) and the unsupervised ELM (US-ELM) exhibit learning capability and computational efficiency of ELMs; 2) both algorithms naturally handle multiclass classification or multi-cluster clustering; and 3) both algorithms are inductive and can handle unseen data at test time directly. Moreover, it is shown in this paper that all the supervised, semi-supervised, and unsupervised ELMs can actually be put into a unified framework. This provides new perspectives for understanding the mechanism of random feature mapping, which is the key concept in ELM theory. Empirical study on a wide range of data sets demonstrates that the proposed algorithms are competitive with the state-of-the-art semi-supervised or unsupervised learning algorithms in terms of accuracy and efficiency.", "paper_title": "Semi-Supervised and Unsupervised Extreme Learning Machines", "paper_id": "WOS:000345629000014"}