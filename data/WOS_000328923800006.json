{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "arbitrary_loss"}, {"score": 0.004600596158672458, "phrase": "general_framework"}, {"score": 0.00445332728705756, "phrase": "fully_corrective_boosting-based_classifiers"}, {"score": 0.004282787299993434, "phrase": "convex_objective_function"}, {"score": 0.0037112756920669593, "phrase": "wide_variety"}, {"score": 0.003663250792230243, "phrase": "existing_fully_corrective_boosting-based_classifiers"}, {"score": 0.003454687811707182, "phrase": "primal_and_dual_problems"}, {"score": 0.0033006894756949776, "phrase": "direct_comparison"}, {"score": 0.003257960296952439, "phrase": "apparently_disparate_methods"}, {"score": 0.002935393439834135, "phrase": "efficient_fully-corrective_boosting_algorithms"}, {"score": 0.002859856368059419, "phrase": "sophisticated_convex_optimization_processes"}, {"score": 0.0027145478956494356, "phrase": "additional_boosting-based_algorithms"}, {"score": 0.002413964586947992, "phrase": "empirical_analysis"}, {"score": 0.002189009136006588, "phrase": "benchmark_datasets"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Boosting", " Ensemble learning", " Convex optimization", " Column generation"], "paper_abstract": "We propose a general framework for analyzing and developing fully corrective boosting-based classifiers. The framework accepts any convex objective function, and allows any convex (for example, l(p)-norm, p >= 1) regularization term. By placing the wide variety of existing fully corrective boosting-based classifiers on a common footing, and considering the primal and dual problems together, the framework allows a direct comparison between apparently disparate methods. By solving the primal rather than the dual the framework is capable of generating efficient fully-corrective boosting algorithms without recourse to sophisticated convex optimization processes. We show that a range of additional boosting-based algorithms can be incorporated into the framework despite not being fully corrective. Finally, we provide an empirical analysis of the performance of a variety of the most significant boosting-based classifiers on a few machine learning benchmark datasets. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Fully corrective boosting with arbitrary loss and regularization", "paper_id": "WOS:000328923800006"}