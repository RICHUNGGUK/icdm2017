{"auto_keywords": [{"score": 0.04237520470574669, "phrase": "web_images"}, {"score": 0.00481495049065317, "phrase": "image_groups"}, {"score": 0.004722613498487908, "phrase": "desirable_events"}, {"score": 0.004692227830462433, "phrase": "uncontrolled_videos"}, {"score": 0.004647013794908825, "phrase": "challenging_task"}, {"score": 0.004587402291248795, "phrase": "mainly_focus"}, {"score": 0.004513957235071457, "phrase": "numerous_labeled_videos"}, {"score": 0.004328432545135587, "phrase": "large_amount"}, {"score": 0.004300572109650207, "phrase": "required_labeled_videos"}, {"score": 0.004272890231368899, "phrase": "training_event_models"}, {"score": 0.00409723267214392, "phrase": "abundant_web_images"}, {"score": 0.004005645977640982, "phrase": "rich_source"}, {"score": 0.003694884775158077, "phrase": "video_annotation_performance"}, {"score": 0.003612259264584205, "phrase": "novel_group-based_domain_adaptation"}, {"score": 0.0035889948769324714, "phrase": "gda"}, {"score": 0.003520082172409082, "phrase": "different_groups"}, {"score": 0.0034081501761600067, "phrase": "web_image_search_engine"}, {"score": 0.003289117944111902, "phrase": "traditional_methods"}, {"score": 0.003267925215811654, "phrase": "multiple_source_domains"}, {"score": 0.002825478348161608, "phrase": "target-domain_videos"}, {"score": 0.0027533227351039277, "phrase": "different_weights"}, {"score": 0.002735572813553256, "phrase": "different_image_groups"}, {"score": 0.0026743419827100225, "phrase": "source_groups"}, {"score": 0.002648520437064087, "phrase": "target_domain"}, {"score": 0.0026144780997686464, "phrase": "group_weight"}, {"score": 0.0025725382476862305, "phrase": "corresponding_source_image_group"}, {"score": 0.00250682585023182, "phrase": "target_video"}, {"score": 0.002450702522633428, "phrase": "group_weights"}, {"score": 0.0024348987477622983, "phrase": "group_classifiers"}, {"score": 0.002380381895973937, "phrase": "joint_optimization_algorithm"}, {"score": 0.002224031430284778, "phrase": "ccv"}, {"score": 0.0022096849931961247, "phrase": "kodak"}, {"score": 0.002188357760829972, "phrase": "youtube"}, {"score": 0.0021393317071153844, "phrase": "grouped_knowledge"}, {"score": 0.0021049977753042253, "phrase": "video_annotation"}], "paper_keywords": ["Concept-specific group", " domain adaptation", " event-specific group", " video annotation"], "paper_abstract": "Searching desirable events in uncontrolled videos is a challenging task. Current researches mainly focus on obtaining concepts from numerous labeled videos. But it is time consuming and labor expensive to collect a large amount of required labeled videos for training event models under various circumstances. To alleviate this problem, we propose to leverage abundant Web images for videos since Web images contain a rich source of information with many events roughly annotated and taken under various conditions. However, knowledge from the Web is noisy and diverse, brute force knowledge transfer of images may hurt the video annotation performance. Therefore, we propose a novel Group-based Domain Adaptation (GDA) learning framework to leverage different groups of knowledge (source domain) queried from the Web image search engine to consumer videos (target domain). Different from traditional methods using multiple source domains of images, our method organizes the Web images according to their intrinsic semantic relationships instead of their sources. Specifically, two different types of groups (i.e., event-specific groups and concept-specific groups) are exploited to respectively describe the event-level and concept-level semantic meanings of target-domain videos. Under this framework, we assign different weights to different image groups according to the relevances between the source groups and the target domain, and each group weight represents how contributive the corresponding source image group is to the knowledge transferred to the target video. In order to make the group weights and group classifiers mutually beneficial and reciprocal, a joint optimization algorithm is presented for simultaneously learning the weights and classifiers, using two novel data-dependent regularizers. Experimental results on three challenging video datasets (i.e., CCV, Kodak, and YouTube) demonstrate the effectiveness of leveraging grouped knowledge gained from Web images for video annotation.", "paper_title": "Video Annotation via Image Groups from the Web", "paper_id": "WOS:000340295600010"}