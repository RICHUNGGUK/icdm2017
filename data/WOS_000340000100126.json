{"auto_keywords": [{"score": 0.04614766352910894, "phrase": "real-world_scenes"}, {"score": 0.043692086897500614, "phrase": "ground_truth_data"}, {"score": 0.00481495049065317, "phrase": "intrinsic_image_decomposition"}, {"score": 0.0046797114400479135, "phrase": "reflectance_layer"}, {"score": 0.004613516457919661, "phrase": "shading_layer"}, {"score": 0.004569905085027681, "phrase": "automatic_intrinsic_image_decomposition"}, {"score": 0.0045052562941109734, "phrase": "significant_challenge"}, {"score": 0.004316722156877335, "phrase": "longstanding_problem"}, {"score": 0.004215397034321004, "phrase": "public_datasets"}, {"score": 0.004077508669922702, "phrase": "mit_intrinsic_images_dataset"}, {"score": 0.0037969755088553326, "phrase": "small_range"}, {"score": 0.0035864603175592854, "phrase": "rich_range"}, {"score": 0.0034526191487098093, "phrase": "complex_illumination"}, {"score": 0.0033395980635636644, "phrase": "intrinsic_images"}, {"score": 0.0031244995579170435, "phrase": "intrinsic_image_decompositions"}, {"score": 0.0030949200330108156, "phrase": "indoor_scenes"}, {"score": 0.0029652292779277782, "phrase": "crowdsourced_annotations"}, {"score": 0.002937153116494391, "phrase": "relative_comparisons"}, {"score": 0.002909342017421165, "phrase": "material_properties"}, {"score": 0.0027479040199262393, "phrase": "scalable_approach"}, {"score": 0.002696101728474703, "phrase": "large_database"}, {"score": 0.002570817338292482, "phrase": "material_comparisons"}, {"score": 0.00241658945942583, "phrase": "dense_crf-based_intrinsic_image_algorithm"}, {"score": 0.0022933216359142736, "phrase": "state-of-the-art_intrinsic_image_algorithms"}, {"score": 0.0021049977753042253, "phrase": "future_research"}], "paper_keywords": ["intrinsic images", " crowdsourcing", " reflectance", " shading"], "paper_abstract": "Intrinsic image decomposition separates an image into a reflectance layer and a shading layer. Automatic intrinsic image decomposition remains a significant challenge, particularly for real-world scenes. Advances on this longstanding problem have been spurred by public datasets of ground truth data, such as the MIT Intrinsic Images dataset. However, the difficulty of acquiring ground truth data has meant that such datasets cover a small range of materials and objects. In contrast, real-world scenes contain a rich range of shapes and materials, lit by complex illumination. In this paper we introduce Intrinsic Images in the Wild, a large-scale, public dataset for evaluating intrinsic image decompositions of indoor scenes. We create this benchmark through millions of crowdsourced annotations of relative comparisons of material properties at pairs of points in each scene. Crowdsourcing enables a scalable approach to acquiring a large database, and uses the ability of humans to judge material comparisons, despite variations in illumination. Given our database, we develop a dense CRF-based intrinsic image algorithm for images in the wild that outperforms a range of state-of-the-art intrinsic image algorithms. Intrinsic image decomposition remains a challenging problem; we release our code and database publicly to support future research on this problem,", "paper_title": "Intrinsic Images in the Wild", "paper_id": "WOS:000340000100126"}