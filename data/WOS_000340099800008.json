{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "rgb-d_data"}, {"score": 0.004725385523804256, "phrase": "adaptive_autoregressive_model"}, {"score": 0.004551199992546761, "phrase": "adaptive_color-guided_autoregressive"}, {"score": 0.004383406949799696, "phrase": "high_quality_depth_recovery"}, {"score": 0.004328856052035968, "phrase": "low_quality_measurements"}, {"score": 0.004248294537944227, "phrase": "depth_cameras"}, {"score": 0.004040688646993609, "phrase": "ar_model"}, {"score": 0.003965468669507077, "phrase": "depth_maps"}, {"score": 0.003916098498242888, "phrase": "generic_scenes"}, {"score": 0.0038431888954930083, "phrase": "depth_recovery_task"}, {"score": 0.0036782824183282823, "phrase": "ar_prediction_errors"}, {"score": 0.0036097844103129073, "phrase": "measurement_consistency"}, {"score": 0.003542557455905503, "phrase": "ar_predictor"}, {"score": 0.003306559295382181, "phrase": "initial_depth_map"}, {"score": 0.0032449610741097992, "phrase": "nonlocal_similarity"}, {"score": 0.0031845067058084613, "phrase": "accompanied_high_quality_color_image"}, {"score": 0.0029909851863915283, "phrase": "linear_system_point"}, {"score": 0.0028625406368744995, "phrase": "parameter_adaptation_scheme"}, {"score": 0.0028091907694771613, "phrase": "stable_and_accurate_depth_recovery"}, {"score": 0.0027741761880779535, "phrase": "quantitative_and_qualitative_evaluation"}, {"score": 0.002371531125700046, "phrase": "depth_degradations"}, {"score": 0.002327310963701377, "phrase": "proposed_method"}, {"score": 0.0022696277881969896, "phrase": "mainstream_depth_sensors"}, {"score": 0.0022413233627905696, "phrase": "time-of-flight_camera"}, {"score": 0.0021995352330055006, "phrase": "kinect"}, {"score": 0.0021049977753042253, "phrase": "real_systems"}], "paper_keywords": ["Depth recovery (upsampling, inpainting, denoising)", " autoregressive model", " RGB-D camera"], "paper_abstract": "This paper proposes an adaptive color-guided autoregressive (AR) model for high quality depth recovery from low quality measurements captured by depth cameras. We observe and verify that the AR model tightly fits depth maps of generic scenes. The depth recovery task is formulated into a minimization of AR prediction errors subject to measurement consistency. The AR predictor for each pixel is constructed according to both the local correlation in the initial depth map and the nonlocal similarity in the accompanied high quality color image. We analyze the stability of our method from a linear system point of view, and design a parameter adaptation scheme to achieve stable and accurate depth recovery. Quantitative and qualitative evaluation compared with ten state-of-the-art schemes show the effectiveness and superiority of our method. Being able to handle various types of depth degradations, the proposed method is versatile for mainstream depth sensors, time-of-flight camera, and Kinect, as demonstrated by experiments on real systems.", "paper_title": "Color-Guided Depth Recovery From RGB-D Data Using an Adaptive Autoregressive Model", "paper_id": "WOS:000340099800008"}