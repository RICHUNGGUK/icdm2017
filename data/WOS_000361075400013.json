{"auto_keywords": [{"score": 0.050078515420936276, "phrase": "ompss"}, {"score": 0.03696700047294347, "phrase": "picos"}, {"score": 0.034280562433132836, "phrase": "picas"}, {"score": 0.004752873752686246, "phrase": "programming_model"}, {"score": 0.004671342094877447, "phrase": "simple_and_powerful_way"}, {"score": 0.004611108249179507, "phrase": "sequential_programs"}, {"score": 0.0045124316982387315, "phrase": "task_parallelism"}, {"score": 0.004454237726525018, "phrase": "runtime_data_dependency_analysis"}, {"score": 0.004084920064588169, "phrase": "openmp_standard"}, {"score": 0.00403221710768334, "phrase": "current_implementation"}, {"score": 0.003894963476923956, "phrase": "pure-software_runtime_library"}, {"score": 0.0034204548167213545, "phrase": "task_superscalar"}, {"score": 0.0033182992967343916, "phrase": "hardware_support"}, {"score": 0.003275454623236867, "phrase": "ompss_programming_model"}, {"score": 0.003205268682789165, "phrase": "novel_hardware_dataflow-based_task_scheduler"}, {"score": 0.0031502008922533894, "phrase": "inter-task_dependencies"}, {"score": 0.003109519872758431, "phrase": "task-level_parallelism"}, {"score": 0.002901237866824737, "phrase": "main_functionality"}, {"score": 0.002718627370925435, "phrase": "full_cycle-accurate_simulator"}, {"score": 0.0026259694526633037, "phrase": "design_exploration"}, {"score": 0.0025145641652082164, "phrase": "reasonable_amount"}, {"score": 0.002315719347244451, "phrase": "real_benchmarks"}, {"score": 0.002227083991228041, "phrase": "ideal_scalability"}, {"score": 0.002207851585508636, "phrase": "aggressive_parallel_strategies"}, {"score": 0.002179313258573375, "phrase": "large_number"}, {"score": 0.0021604924928015283, "phrase": "fine_granularity_tasks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Hardware implementation", " Task scheduling", " Dataflow execution", " Parallel programming model", " OmpSs", " OpenMP"], "paper_abstract": "OmpSs is a programming model that provides a simple and powerful way of annotating sequential programs to exploit heterogeneity and task parallelism based on runtime data dependency analysis, dataflow scheduling and out-of-order task execution; it has greatly influenced Version 4.0 of the OpenMP standard. The current implementation of OmpSs achieves those capabilities with a pure-software runtime library: Nanos++. Therefore, although powerful and easy to use, the performance benefits of exploiting fine-grained (pico) task parallelism are limited by the software runtime overheads. To overcome this handicap we propose Picos, an implementation of the Task Superscalar (TSS) architecture that provides hardware support to the OmpSs programming model. Picas is a novel hardware dataflow-based task scheduler that dynamically analyzes inter-task dependencies and identifies task-level parallelism at run-time. In this paper, we describe the Picos Hardware Design and the latencies of the main functionality of its components, based on the synthesis of their VHDL design. We have implemented a full cycle-accurate simulator based on those latencies to perform a design exploration of the characteristics and number of its components in a reasonable amount of time. Finally, we present a comparison of the Picas and Nanos++ runtime performance scalability with a set of real benchmarks. With Picos, a programmer can achieve ideal scalability using aggressive parallel strategies with a large number of fine granularity tasks. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Picos. A hardware runtime architecture support for OmpSs", "paper_id": "WOS:000361075400013"}