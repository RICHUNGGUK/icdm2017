{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "autoregressive_parameter_space"}, {"score": 0.004586531354697466, "phrase": "new_no-reference"}, {"score": 0.0041840994704406866, "phrase": "ar_model_parameters"}, {"score": 0.00394264312173188, "phrase": "locally_estimated_ar_coefficients"}, {"score": 0.003879234831701853, "phrase": "pointwise_way"}, {"score": 0.0037554497046697432, "phrase": "image_sharpness"}, {"score": 0.0036159990127332315, "phrase": "overall_score"}, {"score": 0.0035005841368145525, "phrase": "luminance_domain"}, {"score": 0.0033888405252810927, "phrase": "inevitable_effect"}, {"score": 0.003352388337911934, "phrase": "color_information"}, {"score": 0.0033163269450817716, "phrase": "visual_perception"}, {"score": 0.0031417377608722, "phrase": "widely_used_yiq_color_space"}, {"score": 0.0028195727965553367, "phrase": "csiq"}, {"score": 0.0027295084882654917, "phrase": "experimental_results"}, {"score": 0.002599763359352916, "phrase": "existing_nr_algorithms"}, {"score": 0.0022830706430588482, "phrase": "proposed_metric"}, {"score": 0.0022101055924375725, "phrase": "stereoscopic_images"}, {"score": 0.0021745003291048356, "phrase": "binocular_rivalry"}, {"score": 0.002127915423138391, "phrase": "remarkably_high_performance"}], "paper_keywords": ["Image sharpness/blurriness", " image quality assessment (IQA)", " no-reference (NR)/blind", " autoregressive (AR) parameters", " YIQ color space", " stereoscopic image", " binocular rivalry"], "paper_abstract": "In this paper, we propose a new no-reference (NR)/blind sharpness metric in the autoregressive (AR) parameter space. Our model is established via the analysis of AR model parameters, first calculating the energy-and contrast-differences in the locally estimated AR coefficients in a pointwise way, and then quantifying the image sharpness with percentile pooling to predict the overall score. In addition to the luminance domain, we further consider the inevitable effect of color information on visual perception to sharpness and thereby extend the above model to the widely used YIQ color space. Validation of our technique is conducted on the subsets with blurring artifacts from four large-scale image databases (LIVE, TID2008, CSIQ, and TID2013). Experimental results confirm the superiority and efficiency of our method over existing NR algorithms, the state-of-the-art blind sharpness/blurriness estimators, and classical full-reference quality evaluators. Furthermore, the proposed metric can be also extended to stereoscopic images based on binocular rivalry, and attains remarkably high performance on LIVE3D-I and LIVE3D-II databases.", "paper_title": "No-Reference Image Sharpness Assessment in Autoregressive Parameter Space", "paper_id": "WOS:000356505500004"}