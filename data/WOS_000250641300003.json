{"auto_keywords": [{"score": 0.0447080647651602, "phrase": "target_speech"}, {"score": 0.03810463830315169, "phrase": "target_talker"}, {"score": 0.03265769574929044, "phrase": "chinese_listeners"}, {"score": 0.00481495049065317, "phrase": "chinese_speech"}, {"score": 0.004782455247247007, "phrase": "informational_masking"}, {"score": 0.00471811808206897, "phrase": "cocktail-party_environment"}, {"score": 0.004592016716046632, "phrase": "perceptual-level_and_cognitive-level_cues"}, {"score": 0.004409127897028587, "phrase": "cognitive_level"}, {"score": 0.004134273515080792, "phrase": "remaining_parts"}, {"score": 0.0040648241451154525, "phrase": "competing_speech"}, {"score": 0.003837273003552065, "phrase": "speech_recognition"}, {"score": 0.0036594395622282358, "phrase": "voice_characteristics"}, {"score": 0.0034311578789991363, "phrase": "present_study"}, {"score": 0.003350679980619693, "phrase": "cognitive-level_cue"}, {"score": 0.003272083495778595, "phrase": "perceptual-level_cue"}, {"score": 0.003195324728141602, "phrase": "word_identification"}, {"score": 0.002799388549023265, "phrase": "priming_sentence"}, {"score": 0.002724428781940696, "phrase": "target_sentence"}, {"score": 0.0025456716198597627, "phrase": "speech-masking_conditions"}, {"score": 0.002452392552332778, "phrase": "last_key_word"}, {"score": 0.002427549902743566, "phrase": "full-length_target_sentence"}, {"score": 0.0024029583021102255, "phrase": "noise-masking_conditions"}, {"score": 0.0023867021254922755, "phrase": "same-sentence_primes"}, {"score": 0.0023625233416109917, "phrase": "weak_but_significant_releasing_effect"}, {"score": 0.002338588929719847, "phrase": "different-sentence_primes"}, {"score": 0.002252880693912436, "phrase": "content_cues"}, {"score": 0.002237637525225501, "phrase": "voice_cues"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["speech", " informational masking", " energetic masking", " cuing effect", " voice"], "paper_abstract": "In a cocktail-party environment, human listeners are able to use perceptual-level and cognitive-level cues to segregate the attended target speech from other background conversations. At the cognitive level, priming the listener with part of the target speech in quiet can markedly improve the recognition of the remaining parts when the target speech and competing speech are presented at the same time. Hence, knowledge of content (content cuing) improves speech recognition when other people are talking. In addition, familiarity or knowledge of the voice characteristics of the target talker could also help the listener attend to the target talker when other talkers are present. The present study investigated the extent to which a cognitive-level cue (content cuing) and a perceptual-level cue (voice cuing) can improve word identification for speech masked by noise or by other speech in Chinese listeners. Specifically, listeners were primed with part of a sentence in quiet before a sentence was repeated in the presence of either noise or speech. The priming sentence was always in the same voice as the target sentence. Two kinds of primes were investigated: same-sentence primes, and different-sentence primes. Under speech-masking conditions, each of the two prime types significantly improved recognition of the last key word in the full-length target sentence. Under noise-masking conditions, same-sentence primes had a weak but significant releasing effect, but different-sentence primes had only a negligible releasing effect. These results suggest that in addition to content cues, voice cues can be used by Chinese listeners to release speech from masking by other talkers. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "The effect of voice cuing on releasing Chinese speech from informational masking", "paper_id": "WOS:000250641300003"}