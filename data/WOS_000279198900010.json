{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "implicit_user_interaction"}, {"score": 0.004562362497952548, "phrase": "integrated_framework"}, {"score": 0.004441059405327222, "phrase": "human_actions"}, {"score": 0.0043619799095455415, "phrase": "video_streams"}, {"score": 0.004023120753104693, "phrase": "automatic_spatiotemporal_analysis"}, {"score": 0.00384633057714983, "phrase": "proposed_method"}, {"score": 0.0034529760173586583, "phrase": "dynamically_mining_semantics"}, {"score": 0.0033914308417007316, "phrase": "annotating_video_streams"}, {"score": 0.0032132782979796895, "phrase": "new_and_ambitious_goal"}, {"score": 0.002963390095037466, "phrase": "\"average_user's\"_selections"}, {"score": 0.0027328817607818207, "phrase": "content_semantics"}, {"score": 0.0026600905156986317, "phrase": "proposed_approach"}, {"score": 0.002543043781904587, "phrase": "significant_value"}, {"score": 0.00247529638625566, "phrase": "-annotated_or_inadequately_annotated_video_streams"}, {"score": 0.0023451553255837317, "phrase": "file_servers"}, {"score": 0.0022218413146898887, "phrase": "expert_annotators"}, {"score": 0.00216263228969761, "phrase": "important_knowledge"}, {"score": 0.0021049977753042253, "phrase": "user_preferences"}], "paper_keywords": ["Human action analysis", " User transparent interaction", " Human object detection", " Action modeling", " Video annotation"], "paper_abstract": "This paper proposes an integrated framework for analyzing human actions in video streams. Despite most current approaches that are just based on automatic spatiotemporal analysis of sequences, the proposed method introduces the implicit user-in-the-loop concept for dynamically mining semantics and annotating video streams. This work sets a new and ambitious goal: to recognize, model and properly use \"average user's\" selections, preferences and perception, for dynamically extracting content semantics. The proposed approach is expected to add significant value to hundreds of billions of non-annotated or inadequately annotated video streams existing in the Web, file servers, databases etc. Furthermore expert annotators can gain important knowledge relevant to user preferences, selections, styles of searching and perception.", "paper_title": "Human action annotation, modeling and analysis based on implicit user interaction", "paper_id": "WOS:000279198900010"}