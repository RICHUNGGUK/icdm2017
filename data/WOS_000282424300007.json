{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "minimal_agents"}, {"score": 0.004648609688625397, "phrase": "minimal_reactive_agent"}, {"score": 0.0045143706249204905, "phrase": "condition-action_rules"}, {"score": 0.004358368398332723, "phrase": "perceived_environmental_stimuli"}, {"score": 0.004257360656055417, "phrase": "policy_pre"}, {"score": 0.0040622852274783275, "phrase": "stipulated_goal"}, {"score": 0.003633927813203731, "phrase": "teleo-reactive_policies"}, {"score": 0.0035082436540296406, "phrase": "discounted-reward_evaluation"}, {"score": 0.0034673190692473903, "phrase": "policy-restricted_subgraphs"}, {"score": 0.0034268702387746106, "phrase": "complete_situation_graphs"}, {"score": 0.003367077034382727, "phrase": "main_feature"}, {"score": 0.003212663446866794, "phrase": "explicit_associations"}, {"score": 0.0031565959573536194, "phrase": "agent's_perceptions"}, {"score": 0.0028736379396305596, "phrase": "cooperating_agents"}, {"score": 0.0027417911324611917, "phrase": "single_representative"}, {"score": 0.002615977783510631, "phrase": "potential_combinatorial_burden"}, {"score": 0.002540285736232124, "phrase": "varied_behaviours"}, {"score": 0.0023953929817357882, "phrase": "simulation_results"}, {"score": 0.002272053079580848, "phrase": "good_degree"}, {"score": 0.00224551648748308, "phrase": "predictive_power"}, {"score": 0.0021550502873107654, "phrase": "bound_algorithms"}, {"score": 0.0021049977753042253, "phrase": "policy_evaluation"}], "paper_keywords": ["minimal agent", " multi-agent policies", " policy evaluation"], "paper_abstract": "A policy for a minimal reactive agent is a set of condition-action rules used to determine its response to perceived environmental stimuli. When the policy pre-disposes the agent to achieving a stipulated goal we call it a teleo-reactive policy. This paper presents a framework for constructing and evaluating teleo-reactive policies for one or more minimal agents, based upon discounted-reward evaluation of policy-restricted subgraphs of complete situation graphs. The main feature of the method is that it exploits explicit associations of the agent's perceptions with states. The framework allows to construct and evaluate policies for a number of cooperating agents by focusing upon the behaviour of a single representative of them. This abstraction ameliorates the potential combinatorial burden. Within the framework varied behaviours can be modelled, including communication between agents. Simulation results presented here indicate that the method affords a good degree of predictive power. The paper presents two different branch and bound algorithms used to optimize policy evaluation.", "paper_title": "Designing Effective Policies for Minimal Agents", "paper_id": "WOS:000282424300007"}