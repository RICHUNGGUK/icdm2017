{"auto_keywords": [{"score": 0.04942981937458461, "phrase": "sampled-data_nonlinear_systems"}, {"score": 0.03981403818161384, "phrase": "sampling_period"}, {"score": 0.00481495049065317, "phrase": "deterministic_learning"}, {"score": 0.004466519142879166, "phrase": "deterministic_learning_theory"}, {"score": 0.004287166497171827, "phrase": "euler_approximate_model"}, {"score": 0.004200197763119297, "phrase": "adaptive_neural_network_identifier"}, {"score": 0.0041149859710361125, "phrase": "normalized_learning_algorithm"}, {"score": 0.0037140731069193896, "phrase": "overall_system"}, {"score": 0.0034924598001567944, "phrase": "neural_network_weights"}, {"score": 0.003239418275717787, "phrase": "partial_persistent_excitation"}, {"score": 0.003195506976310118, "phrase": "pe"}, {"score": 0.003066945490483524, "phrase": "locally_accurate_learning"}, {"score": 0.003004655258223784, "phrase": "nonlinear_dynamics"}, {"score": 0.002748984715897838, "phrase": "constant-weight_neural_networks"}, {"score": 0.002620424858132324, "phrase": "performance_analysis"}, {"score": 0.002567180189640976, "phrase": "learning_algorithm"}, {"score": 0.002515014676664348, "phrase": "explicit_bounds"}, {"score": 0.002463906556781983, "phrase": "learning_rate"}, {"score": 0.002285216591220303, "phrase": "pe_level"}, {"score": 0.002238767763626708, "phrase": "learning_gain"}, {"score": 0.0021049977753042253, "phrase": "simulation_studies"}], "paper_keywords": ["neural network identification", " deterministic learning", " persistent excitation", " sampled-data systems", " radial basis function networks (RBFNs)"], "paper_abstract": "In this paper, we extend the deterministic learning theory to sampled-data nonlinear systems Based on the Euler approximate model, the adaptive neural network identifier with a normalized learning algorithm is proposed. It is proven that by properly setting the sampling period, the overall system can be guaranteed to be stable and partial neural network weights can exponentially converge to their optimal values under the satisfaction of the partial persistent excitation (PE) condition. Consequently, locally accurate learning of the nonlinear dynamics can be achieved, and the knowledge can be represented by using constant-weight neural networks. Furthermore, we present a performance analysis for the learning algorithm by developing explicit bounds on the learning rate and accuracy. Several factors that influence learning, including the PE level, the learning gain, and the sampling period, are investigated. Simulation studies are included to demonstrate the effectiveness of the approach.", "paper_title": "Design and performance analysis of deterministic learning of sampled-data nonlinear systems", "paper_id": "WOS:000332351000017"}