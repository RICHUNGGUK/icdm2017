{"auto_keywords": [{"score": 0.04812854551814997, "phrase": "gaussian"}, {"score": 0.006208684102128744, "phrase": "discrete"}, {"score": 0.00481495049065317, "phrase": "minimum_expected_error"}, {"score": 0.004740476936977635, "phrase": "bayesian_framework-part"}, {"score": 0.004339609346924681, "phrase": "difficult_small-sample_phenotype_discrimination_problems"}, {"score": 0.0038106195546165574, "phrase": "classification_rules"}, {"score": 0.003771185758226876, "phrase": "heuristic_algorithms"}, {"score": 0.003580032420161922, "phrase": "concrete_mathematical_structure"}, {"score": 0.0034881076466982226, "phrase": "recent_work"}, {"score": 0.0034162643819889054, "phrase": "bayesian_modeling_framework"}, {"score": 0.003345895878114341, "phrase": "uncertainty_class"}, {"score": 0.00331125524068286, "phrase": "feature-label_distributions"}, {"score": 0.0032094634756436595, "phrase": "error_estimator_performance"}, {"score": 0.0031597433845085092, "phrase": "current_study"}, {"score": 0.0030466955629231047, "phrase": "classifier_design"}, {"score": 0.002968424524565369, "phrase": "bayesian_theory"}, {"score": 0.002674885993329912, "phrase": "model_framework"}, {"score": 0.0025524176761139413, "phrase": "two-part_study"}, {"score": 0.002512850690695835, "phrase": "optimal_classifiers"}, {"score": 0.0024868131939261716, "phrase": "discrete_and_gaussian_models"}, {"score": 0.002422890839801611, "phrase": "popular_classifiers"}, {"score": 0.002385326947545194, "phrase": "assumed_model"}, {"score": 0.002299921909935613, "phrase": "real_genomic_data"}, {"score": 0.0022642601698943687, "phrase": "second_part"}, {"score": 0.002171836484200008, "phrase": "optimal_bayesian_classifiers"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Bayesian estimation", " Classification", " Error estimation", " Genomics", " Minimum mean-square estimation", " Small samples"], "paper_abstract": "In recent years, biomedicine has faced a flood of difficult small-sample phenotype discrimination problems. A host of classification rules have been proposed to discriminate types of pathology, stages of disease and other diagnoses. Typically, these classification rules are heuristic algorithms, with very little understood about their performance. To give a concrete mathematical structure to the problem, recent work has utilized a Bayesian modeling framework based on an uncertainty class of feature-label distributions to both optimize and analyze error estimator performance. The current study uses the same Bayesian framework to also optimize classifier design. This completes a Bayesian theory of classification, where both the classifier error and the estimate of the error may be optimized and studied probabilistically within the model framework. This paper, the first of a two-part study, derives optimal classifiers in discrete and Gaussian models, demonstrates their superior performance over popular classifiers within the assumed model, and applies the method to real genomic data. The second part of the study discusses properties of these optimal Bayesian classifiers. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Optimal classifiers with minimum expected error within a Bayesian framework-Part I: Discrete and Gaussian models", "paper_id": "WOS:000315313600007"}