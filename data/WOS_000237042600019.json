{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "real_time_synthesis"}, {"score": 0.0046993598473345395, "phrase": "sign_language"}, {"score": 0.003964007795174772, "phrase": "virtual_humanoid"}, {"score": 0.003775803846431323, "phrase": "expressive_gestures"}, {"score": 0.003685067218455088, "phrase": "real_time"}, {"score": 0.0034676182423067307, "phrase": "gesture_motion_data_acquisition_protocol"}, {"score": 0.0032629585038738856, "phrase": "main_articulators"}, {"score": 0.0031459887611258765, "phrase": "human_expressive_gesture"}, {"score": 0.0024963543716522087, "phrase": "captured_data"}, {"score": 0.0023776656246300063, "phrase": "motion_database"}, {"score": 0.0021049977753042253, "phrase": "animation_techniques"}], "paper_keywords": [""], "paper_abstract": "This study proposes a roadmap for the creation and specification of a virtual humanoid capable of performing expressive gestures in real time. We present a gesture motion data acquisition protocol capable of handling the main articulators involved in human expressive gesture (whole body, fingers and face). The focus is then shifted to the postprocessing of captured data leading to a motion database complying with our motion specification language and capable of feeding data driven animation techniques.", "paper_title": "Captured motion data processing for real time synthesis of sign language", "paper_id": "WOS:000237042600019"}