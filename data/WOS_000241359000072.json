{"auto_keywords": [{"score": 0.031763843900136826, "phrase": "automatic_annotation_task"}, {"score": 0.00481495049065317, "phrase": "content-based_image_retrieval"}, {"score": 0.004033464035028803, "phrase": "medical_retrieval_task"}, {"score": 0.0036759314172445934, "phrase": "textual_information_retrieval"}, {"score": 0.0034944094552943, "phrase": "clear_improvements"}, {"score": 0.0028776033221807598, "phrase": "fire"}, {"score": 0.002689564715486338, "phrase": "second_subimage_based_method"}], "paper_keywords": [""], "paper_abstract": "In this paper the methods we used in the 2005 ImageCLEF content-based image retrieval evaluation are described. For the medical retrieval task, we combined several low-level image features with textual information retrieval. Combining these two information sources, clear improvements over the use of one of these sources alone are possible. Additionally we participated in the automatic annotation task, where our content-based image retrieval system, FIRE, was used as well as a second subimage based method for object classification. The results we achieved are very convincing. Our submissions ranked first and the third in the automatic annotation task out of a total of 44 submissions from 12 groups.", "paper_title": "FIRE in ImageCLEF 2005: Combining content-based image retrieval with textual information retrieval", "paper_id": "WOS:000241359000072"}