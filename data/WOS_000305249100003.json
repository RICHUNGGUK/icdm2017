{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "major_performance_limiter"}, {"score": 0.0047804843375940835, "phrase": "modern_processors"}, {"score": 0.0047292449487169345, "phrase": "long_latencies"}, {"score": 0.00467855218490191, "phrase": "data_cache"}, {"score": 0.0046118021635786315, "phrase": "compiler-_and_hardware-based_prefetching_schemes"}, {"score": 0.004449045430179066, "phrase": "compiler_techniques"}, {"score": 0.00441718685609235, "phrase": "memory_access_patterns"}, {"score": 0.004385555408850022, "phrase": "code_analysis"}, {"score": 0.004322967486451877, "phrase": "appropriate_prefetch_instructions"}, {"score": 0.0042920078348374375, "phrase": "hardware_prefetching_techniques"}, {"score": 0.004155399041702324, "phrase": "access_stream"}, {"score": 0.003798231095121328, "phrase": "architecture-based_prefetching_techniques"}, {"score": 0.0036247638406450735, "phrase": "compilers'_ability"}, {"score": 0.0035858673522839407, "phrase": "good_results"}, {"score": 0.0035601676907962626, "phrase": "extreme_expertise"}, {"score": 0.003150319576043518, "phrase": "minor_slowdown"}, {"score": 0.0030830390264125923, "phrase": "substantial_speedup"}, {"score": 0.0030171910207671205, "phrase": "software_schemes"}, {"score": 0.002995554770117301, "phrase": "hardware_prefetching_schemes"}, {"score": 0.0025660347613972573, "phrase": "access_patterns"}, {"score": 0.0024399036842105205, "phrase": "observed_miss_sequence"}, {"score": 0.002387758958649797, "phrase": "address_sequences"}, {"score": 0.002245975340642921, "phrase": "individual_loads"}], "paper_keywords": ["Cache", " software prefetch", " hardware prefetch"], "paper_abstract": "A major performance limiter in modern processors is the long latencies caused by data cache misses. Both compiler- and hardware-based prefetching schemes help hide these latencies and so improve performance. Compiler techniques infer memory access patterns through code analysis, and insert appropriate prefetch instructions. Hardware prefetching techniques work independently from the compiler by monitoring an access stream, detecting patterns in this stream and issuing prefetches based on these patterns. This paper looks at the interplay between compiler and hardware architecture-based prefetching techniques. Does either technique make the other one unnecessary? First, compilers' ability to achieve good results without extreme expertise is evaluated by preparing binaries with no prefetch, one-flag prefetch (no tuning), and expertly tuned prefetch. From runs of SPECcpu2006 binaries, we find that expertise avoids minor slowdown in a few benchmarks and provides substantial speedup in others. We compare software schemes to hardware prefetching schemes and our simulations show software alone substantially outperforms hardware alone on about half of a selection of benchmarks. While hardware matches or exceeds software in a few cases, software is better on average. Analysis reveals that in many cases hardware is not prefetching access patterns that it is capable of recognizing, due to some irregularities in the observed miss sequence. Hardware outperforms software on address sequences that the compiler would not guess. In general, while software is better at prefetching individual loads, hardware partly compensates for this by identifying more loads to prefetch. Using the two schemes together provides further benefits, but less than the sum of the contributions of each alone.", "paper_title": "THE INTERACTION AND RELATIVE EFFECTIVENESS OF HARDWARE AND SOFTWARE DATA PREFETCH", "paper_id": "WOS:000305249100003"}