{"auto_keywords": [{"score": 0.04218619026054096, "phrase": "noise_variables"}, {"score": 0.00481495049065317, "phrase": "nearest_neighbor_ensembles"}, {"score": 0.004665296491645837, "phrase": "statistical_discrimination"}, {"score": 0.004640808212832262, "phrase": "nearest_neighbor_methods"}, {"score": 0.00433386573276633, "phrase": "predictive_power"}, {"score": 0.00398370478688858, "phrase": "variable_selection"}, {"score": 0.00392125815948488, "phrase": "promising_approach"}, {"score": 0.0038597866217852353, "phrase": "paper's_main_focus"}, {"score": 0.0036810726176482278, "phrase": "nearest_neighbor_ensemble"}, {"score": 0.0036424917384748024, "phrase": "implicit_variable_selection"}, {"score": 0.0031929098985796814, "phrase": "real_world"}, {"score": 0.0031761255583359726, "phrase": "data_the_proposed_nearest_neighbor_ensemble"}, {"score": 0.00291923164591297, "phrase": "classification_tools"}, {"score": 0.002858313353461727, "phrase": "probability_estimates"}, {"score": 0.0027258422018680453, "phrase": "proposed_method's_performance"}, {"score": 0.0026270572353632297, "phrase": "relevant_covariates"}, {"score": 0.0024789887640568093, "phrase": "presented_ensemble"}, {"score": 0.002440071551819324, "phrase": "easy_identification"}, {"score": 0.0021957487795963666, "phrase": "feature_selection"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Nearest neighbor methods", " Variable selection", " Ensemble methods", " Classification"], "paper_abstract": "In the field of statistical discrimination nearest neighbor methods are a well known, quite simple but successful nonparametric classification tool If the number of predictors increases, however, predictive power normally deteriorates. In general. if some covariates are assumed to be noise variables. variable selection is a promising approach. The paper's main focus is on the development and evaluation of a nearest neighbor ensemble with implicit variable selection. In contrast to other nearest neighbor approaches we are not primarily interested in classification, but in estimating the (posterior) class probabilities. In simulation studies and for real world data the proposed nearest neighbor ensemble is compared to an extended forward/backward variable selection procedure for nearest neighbor classifiers, and some alternative well established classification tools (that offer probability estimates as well). Despite its simple structure, the proposed method's performance is quite good - especially if relevant covariates can be separated from noise variables. Another advantage of the presented ensemble is the easy identification of interactions that are usually hard to detect. So not simply variable selection but rather some kind of feature selection is performed. (C) 2009 Elsevier B.V. All rights reserved", "paper_title": "Feature selection and weighting by nearest neighbor ensembles", "paper_id": "WOS:000271254400004"}