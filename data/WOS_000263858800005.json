{"auto_keywords": [{"score": 0.048970045726729895, "phrase": "interactive_video_retrieval"}, {"score": 0.0465604823844301, "phrase": "new_formulation"}, {"score": 0.00481495049065317, "phrase": "structured_concept_threads"}, {"score": 0.00440976345264104, "phrase": "video_queries"}, {"score": 0.004332894955218135, "phrase": "concept_threads"}, {"score": 0.004207734323806386, "phrase": "general_query-by-concept_paradigm"}, {"score": 0.0041102032028337366, "phrase": "low-dimensional_region"}, {"score": 0.0040385352882334235, "phrase": "concept_space"}, {"score": 0.003991449490087454, "phrase": "concept_thread"}, {"score": 0.0039218440805789965, "phrase": "ranked_list"}, {"score": 0.0038761135052054765, "phrase": "video_documents"}, {"score": 0.003742084495435749, "phrase": "localized_representation"}, {"score": 0.003676811616723809, "phrase": "previous_concept"}, {"score": 0.0035705347414368696, "phrase": "special_case"}, {"score": 0.003487721546598799, "phrase": "restricted_and_concept_combination_logic"}, {"score": 0.0034268702387746106, "phrase": "two-level_concept_inference_network"}, {"score": 0.0032315723330399375, "phrase": "abundant_feedback_information"}, {"score": 0.00304737045343781, "phrase": "complex_query_semantics"}, {"score": 0.0030118058266380503, "phrase": "simulative_experiments"}, {"score": 0.00284009509859163, "phrase": "concept_lexicons"}, {"score": 0.0027417911324611917, "phrase": "proposed_formulation"}, {"score": 0.002693919110230191, "phrase": "proposed_query_formulation"}, {"score": 0.002600661525224505, "phrase": "simple_browsing_search_baseline"}, {"score": 0.002570296816631395, "phrase": "nearly_real_time"}, {"score": 0.0025106241866273897, "phrase": "clear_advantages"}, {"score": 0.002381365139274329, "phrase": "state-of-the-art_online_ordinal_reranking_approach"}, {"score": 0.002272053079580848, "phrase": "user's_workload"}, {"score": 0.0021805201234139475, "phrase": "user_mislabeling_errors"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Interactive video retrieval", " Query concept mapping", " Concept thread", " Structured query formulation", " Concept tf-idf", " Semantic feedback", " Query representation", " TRECVID"], "paper_abstract": "In this paper, we provide a new formulation for video queries as structured combination of concept threads, contributing to the general query-by-concept paradigm. Occupying a low-dimensional region in the concept space, concept thread defines a ranked list of video documents ordered by their combined concept predictions. This localized representation incorporates the previous concept based formulation as a special case and extends the restricted AND concept combination logic to a two-level concept inference network. We apply this new formulation to interactive video retrieval and utilize abundant feedback information to mine the latent semantic concept threads for answering complex query semantics. Simulative experiments which are conducted on two years' TRECVID data sets with two sets of concept lexicons demonstrate the advantage of the proposed formulation. The proposed query formulation offers some 60% improvements over the simple browsing search baseline in nearly real time. It has clear advantages over c-tf-idf and achieves better results over the state-of-the-art online ordinal reranking approach. Meanwhile, it not only alleviates user's workload significantly but also is robust to user mislabeling errors. (C) 2008 Elsevier Inc. All rights reserved", "paper_title": "Query representation by structured concept threads with application to interactive video retrieval", "paper_id": "WOS:000263858800005"}