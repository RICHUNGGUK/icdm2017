{"auto_keywords": [{"score": 0.04753799882019955, "phrase": "speech_signal"}, {"score": 0.04217034561110977, "phrase": "mapping_functions"}, {"score": 0.04081002585718696, "phrase": "pitch_synchronous_analysis"}, {"score": 0.038214415210524454, "phrase": "significant_excitation"}, {"score": 0.015649299170143113, "phrase": "pitch_synchronous_approach"}, {"score": 0.015439904543519832, "phrase": "voice_conversion_system"}, {"score": 0.014629560623986121, "phrase": "different_levels"}, {"score": 0.011420747608110491, "phrase": "glottal_closure"}, {"score": 0.00481495049065317, "phrase": "speaker-specific_features"}, {"score": 0.004760617860507055, "phrase": "basic_goal"}, {"score": 0.004674952036988355, "phrase": "speaker-specific_characteristics"}, {"score": 0.00460125407969429, "phrase": "environmental_information"}, {"score": 0.004528712642539063, "phrase": "speaker_characteristics"}, {"score": 0.004387027668937774, "phrase": "glottal_pulse"}, {"score": 0.004278807087784626, "phrase": "vocal_tract"}, {"score": 0.004192243260182271, "phrase": "long-term_features"}, {"score": 0.004051828608343507, "phrase": "neural_network_models"}, {"score": 0.0038281374948654925, "phrase": "accurate_vocal_tract_parameters"}, {"score": 0.0037506567448470163, "phrase": "pitch_period"}, {"score": 0.003708289015692081, "phrase": "adjacent_pitch_cycles"}, {"score": 0.003600351201298387, "phrase": "pitch_markers"}, {"score": 0.00352746447572238, "phrase": "significant_excitation_correspond"}, {"score": 0.003424771860049617, "phrase": "voiced_speech"}, {"score": 0.003386072841722016, "phrase": "random_excitations"}, {"score": 0.0033175095965171674, "phrase": "nonvoiced_speech"}, {"score": 0.0032503301334579717, "phrase": "linear_prediction"}, {"score": 0.003206298867805933, "phrase": "speech_signals"}, {"score": 0.0031628621880184114, "phrase": "average_group-delay"}, {"score": 0.003148514042945515, "phrase": "minimum_phase_signals"}, {"score": 0.003105857752110456, "phrase": "line_spectral_frequencies"}, {"score": 0.00304295114679455, "phrase": "vocal_tract_characteristics"}, {"score": 0.0029409171055888804, "phrase": "excitation_source"}, {"score": 0.002914288956035066, "phrase": "residual_samples"}, {"score": 0.0028422946420821075, "phrase": "prosodic_parameters"}, {"score": 0.002816556934231128, "phrase": "phrase_levels"}, {"score": 0.002778385486855157, "phrase": "mapping_function"}, {"score": 0.002753224894944965, "phrase": "system_level_mapping_functions"}, {"score": 0.0026913130726432645, "phrase": "target_prosodic_parameters"}, {"score": 0.0025833500717948343, "phrase": "listening_tests"}, {"score": 0.0025657809900813877, "phrase": "prediction_accuracy"}, {"score": 0.0024853548277490468, "phrase": "proposed_voice_conversion_system"}, {"score": 0.00245724480030654, "phrase": "objective_measures"}, {"score": 0.0023965141236111194, "phrase": "square_error"}, {"score": 0.0023108417343022537, "phrase": "proposed_approach"}, {"score": 0.002238388884010998, "phrase": "voice_conversion"}, {"score": 0.0021880287881785223, "phrase": "earlier_method"}, {"score": 0.0021682027434117095, "phrase": "vocal_tract_parameters"}, {"score": 0.0021583570446663818, "phrase": "block_processing"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Mapping function", " Feedforward neural network (FFNN)", " Pitch contour", " Excitation source", " LP residual", " Instants of significant excitation (epochs)", " Prosody characteristics", " Duration and energy patterns", " Glottal closure", " Voice conversion", " Objective measures", " Mean opinion score (MOS)", " ABX test"], "paper_abstract": "The basic goal of the voice conversion system is to modify the speaker-specific characteristics, keeping the message and the environmental information contained in the speech signal intact. Speaker characteristics reflect in speech at different levels, such as, the shape of the glottal pulse (excitation source characteristics), the shape of the vocal tract (vocal tract system characteristics) and the long-term features (suprasegmental or prosodic characteristics). In this paper, we are proposing neural network models for developing mapping functions at each level. The features used for developing the mapping functions are extracted using pitch synchronous analysis. Pitch synchronous analysis provides the estimation of accurate vocal tract parameters, by analyzing the speech signal independently in each pitch period without influenced by the adjacent pitch cycles. In this work, the instants of significant excitation are used as pitch markers to perform the pitch synchronous analysis. The instants of significant excitation correspond to the instants of glottal closure (epochs) in the case of voiced speech, and to some random excitations like onset of burst in the case of nonvoiced speech. Instants of significant excitation are computed from the linear prediction (LP) residual of speech signals by using the property of average group-delay of minimum phase signals. In this paper, line spectral frequencies (LSFs) are used for representing the vocal tract characteristics, and for developing its associated mapping function. LP residual of the speech signal is viewed as excitation source, and the residual samples around the instant of glottal closure are used for mapping. Prosodic parameters at syllable and phrase levels are used for deriving the mapping function. Source and system level mapping functions are derived pitch synchronously, and the incorporation of target prosodic parameters is performed pitch synchronously using instants of significant excitation. The performance of the voice conversion system is evaluated using listening tests. The prediction accuracy of the mapping functions (neural network models) used at different levels in the proposed voice conversion system is further evaluated using objective measures such as deviation (D(i)), root mean square error (mu(RMSE)) and correlation coefficient (gamma(X,Y)). The proposed approach (i.e., mapping and modification of parameters using pitch synchronous approach) used for voice conversion is shown to be performed better compared to the earlier method (mapping the vocal tract parameters using block processing) proposed by the author. (C) 2009 Elsevier Ltd. All rights reserved.", "paper_title": "Voice conversion by mapping the speaker-specific features using pitch synchronous approach", "paper_id": "WOS:000277330400005"}