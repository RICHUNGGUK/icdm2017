{"auto_keywords": [{"score": 0.049509300669177574, "phrase": "distribution_algorithms"}, {"score": 0.00481495049065317, "phrase": "continuous_estimation"}, {"score": 0.004617328272121826, "phrase": "well-known_technique"}, {"score": 0.004508048086020253, "phrase": "model_estimation"}, {"score": 0.004322967486451877, "phrase": "generalization_ability"}, {"score": 0.0042459818200777846, "phrase": "estimated_model"}, {"score": 0.004120694410890683, "phrase": "regularization_methods"}, {"score": 0.003975200317233532, "phrase": "variable_selection"}, {"score": 0.0038348235692738783, "phrase": "high-dimensional_problems"}, {"score": 0.0034220655476652683, "phrase": "continuous_optimization"}, {"score": 0.003361069456060196, "phrase": "gaussian_distributions"}, {"score": 0.0032229262928681304, "phrase": "regularized_model_estimation"}, {"score": 0.003071965703296204, "phrase": "computational_complexity"}, {"score": 0.0028758391869611374, "phrase": "proposed_algorithms"}, {"score": 0.002790867657645595, "phrase": "continuous_optimization_functions"}, {"score": 0.002597012212823168, "phrase": "optimization_performance"}, {"score": 0.00255068452076921, "phrase": "proposed_regedas"}, {"score": 0.002416589459425828, "phrase": "problem_size"}, {"score": 0.0022758279600841014, "phrase": "significantly_better_optimization_values"}, {"score": 0.0021821915946356168, "phrase": "high-dimensional_settings"}, {"score": 0.002105007807034302, "phrase": "elsevier"}], "paper_keywords": ["Estimation of distribution algorithm", " Regularized model estimation", " Continuous optimization", " High-dimensionality"], "paper_abstract": "Regularization is a well-known technique in statistics for model estimation which is used to improve the generalization ability of the estimated model. Some of the regularization methods can also be used for variable selection that is especially useful in high-dimensional problems. This paper studies the use of regularized model learning in estimation of distribution algorithms (EDAs) for continuous optimization based on Gaussian distributions. We introduce two approaches to the regularized model estimation and analyze their effect on the accuracy and computational complexity of model learning in EDAs. We then apply the proposed algorithms to a number of continuous optimization functions and compare their results with other Gaussian distribution-based EDAs. The results show that the optimization performance of the proposed RegEDAs is less affected by the increase in the problem size than other EDAs, and they are able to obtain significantly better optimization values for many of the functions in high-dimensional settings. (C) 2012 Elsevier B. V. All rights reserved.", "paper_title": "Regularized continuous estimation of distribution algorithms", "paper_id": "WOS:000319205200019"}