{"auto_keywords": [{"score": 0.03613346133936676, "phrase": "decision_map"}, {"score": 0.00481495049065317, "phrase": "dictionary-based_sparse_representation"}, {"score": 0.004767826806287385, "phrase": "multi-focus"}, {"score": 0.004606479650820579, "phrase": "major_topic"}, {"score": 0.004561386908745206, "phrase": "image_processing"}, {"score": 0.00447251540886613, "phrase": "-focus_images"}, {"score": 0.004428728205625129, "phrase": "increased_depth"}, {"score": 0.004299910946753963, "phrase": "multi-focus_photographs"}, {"score": 0.00376488621224566, "phrase": "image_fusion_quality_degradations"}, {"score": 0.003584025547693836, "phrase": "halo_artifacts"}, {"score": 0.003548905904860611, "phrase": "contrast_decrease"}, {"score": 0.0035141291835319682, "phrase": "sharpness_reduction"}, {"score": 0.0033950634506367235, "phrase": "object_boundaries"}, {"score": 0.0032639039638211347, "phrase": "novel_multi-focus_image_fusion_method"}, {"score": 0.00307657476125683, "phrase": "local_patches"}, {"score": 0.0030464123943266673, "phrase": "source_images"}, {"score": 0.003016544840824688, "phrase": "sparse_representation"}, {"score": 0.002986969236641105, "phrase": "relative_sharpness_measure"}, {"score": 0.002943147037670826, "phrase": "trained_dictionary"}, {"score": 0.002843372121209168, "phrase": "corresponding_pooled_features"}, {"score": 0.0027741761880779535, "phrase": "pooled_features"}, {"score": 0.0027469703311742647, "phrase": "sparse_representations"}, {"score": 0.0027200305495826797, "phrase": "input_images"}, {"score": 0.002680114113899346, "phrase": "pixel_level_score"}, {"score": 0.0026020254041372723, "phrase": "final_regularized_decision_map"}, {"score": 0.0024768883044869023, "phrase": "new_color_multi-focus_image"}, {"score": 0.0023928819778638055, "phrase": "traditional_multi-focus_image_sets"}, {"score": 0.0021682027434117095, "phrase": "visual_and_quantitative_evaluations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Multi-focus image fusion", " Dictionary learning", " K-SVD", " Sparse representation", " Guided image filtering"], "paper_abstract": "Multi-focus image fusion has emerged as a major topic in image processing to generate all-focus images with increased depth-of-field from multi-focus photographs. Different approaches have been used in spatial or transform domain for this purpose. But most of them are subject to one or more of image fusion quality degradations such as blocking artifacts, ringing effects, artificial edges, halo artifacts, contrast decrease, sharpness reduction, and misalignment of decision map with object boundaries. In this paper we present a novel multi-focus image fusion method in spatial domain that utilizes a dictionary which is learned from local patches of source images. Sparse representation of relative sharpness measure over this trained dictionary are pooled together to get the corresponding pooled features. Correlation of the pooled features with sparse representations of input images produces a pixel level score for decision map of fusion. Final regularized decision map is obtained using Markov Random Field (MRF) optimization. We also gathered a new color multi-focus image dataset which has more variety than traditional multi-focus image sets. Experimental results demonstrate that our proposed method outperforms existing state-of-the-art methods, in terms of visual and quantitative evaluations. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Multi-focus image fusion using dictionary-based sparse representation", "paper_id": "WOS:000351972800007"}