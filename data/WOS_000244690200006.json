{"auto_keywords": [{"score": 0.0385440444433442, "phrase": "clustering_problems"}, {"score": 0.034860801016357974, "phrase": "k-means"}, {"score": 0.00481495049065317, "phrase": "statistical_clustering"}, {"score": 0.004773476989344654, "phrase": "constant_time_approximation_algorithms"}, {"score": 0.004732363941068018, "phrase": "k-median"}, {"score": 0.0046918318726087305, "phrase": "k-"}, {"score": 0.0045124316982387315, "phrase": "sample-based_clustering"}, {"score": 0.0043213410601860985, "phrase": "clustering_algorithm"}, {"score": 0.004174287115855492, "phrase": "unknown_arbitrary_distribution"}, {"score": 0.003911862375084159, "phrase": "full_domain_set"}, {"score": 0.0037623642073222547, "phrase": "underlying_distribution"}, {"score": 0.003697760799674494, "phrase": "general_conditions"}, {"score": 0.003465189575252443, "phrase": "optimal_clustering"}, {"score": 0.0033762956164519286, "phrase": "k-median_clustering"}, {"score": 0.003265677362270792, "phrase": "vector"}, {"score": 0.0030960762496815737, "phrase": "combinatorial_optimization"}, {"score": 0.0029776614744264724, "phrase": "input_set"}, {"score": 0.002913837945508097, "phrase": "constant_time"}, {"score": 0.0028513785049061767, "phrase": "sampling-based_algorithm"}, {"score": 0.0027068691342344545, "phrase": "almost_optimal_set"}, {"score": 0.0025808284847319528, "phrase": "accuracy_parameters"}, {"score": 0.0024820711838337713, "phrase": "input_size"}, {"score": 0.0024183363693242943, "phrase": "euclidean_input_case"}, {"score": 0.0023562342764987254, "phrase": "running_time"}, {"score": 0.0023056996845692355, "phrase": "euclidean_dimension"}, {"score": 0.002227083991228041, "phrase": "uniform_convergence_result"}, {"score": 0.002207851585508636, "phrase": "center_based_clustering"}, {"score": 0.0021233361369222344, "phrase": "effective_vc-dimension"}, {"score": 0.0021049977753042253, "phrase": "k-center_clustering"}], "paper_keywords": ["k-means clustering", " k-median clustering", " sample-based clustering", " approximation algorithms", " description schemes"], "paper_abstract": "We consider a framework of sample-based clustering. In this setting, the input to a clustering algorithm is a sample generated i.i.d by some unknown arbitrary distribution. Based on such a sample, the algorithm has to output a clustering of the full domain set, that is evaluated with respect to the underlying distribution. We provide general conditions on clustering problems that imply the existence of sampling based clustering algorithms that approximate the optimal clustering. We show that the K-median clustering, as well as K-means and the Vector Quantization problems, satisfy these conditions. Our results apply to the combinatorial optimization setting where, assuming that sampling uniformly over an input set can be done in constant time, we get a sampling-based algorithm for the K-median and K-means clustering problems that finds an almost optimal set of centers in time depending only on the confidence and accuracy parameters of the approximation, but independent of the input size. Furthermore, in the Euclidean input case, the dependence of the running time of our algorithm on the Euclidean dimension is only linear. Our main technical tool is a uniform convergence result for center based clustering that can be viewed as showing that the effective VC-dimension of k-center clustering equals k.", "paper_title": "A framework for statistical clustering with constant time approximation algorithms for K-median and K-means clustering", "paper_id": "WOS:000244690200006"}