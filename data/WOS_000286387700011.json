{"auto_keywords": [{"score": 0.03843856552198327, "phrase": "local_pixel_structures"}, {"score": 0.03798322760335939, "phrase": "target_hr_face"}, {"score": 0.010612387000973441, "phrase": "local_pixel_structure"}, {"score": 0.007018276141570669, "phrase": "k_example"}, {"score": 0.004775531918452571, "phrase": "global_image_super-resolution"}, {"score": 0.004545675105321216, "phrase": "new_face_hallucination_framework"}, {"score": 0.00445318311339027, "phrase": "global_image"}, {"score": 0.004135458387200662, "phrase": "similar_local_pixel_structures"}, {"score": 0.004084744133085742, "phrase": "new_framework"}, {"score": 0.004018087343963485, "phrase": "input_low-resolution"}, {"score": 0.0038720442355114045, "phrase": "face_database"}, {"score": 0.0038403151693333017, "phrase": "similar_example"}, {"score": 0.0035224030823976186, "phrase": "input_lr_face"}, {"score": 0.003479180627368156, "phrase": "learned_pixel_structures"}, {"score": 0.0033251716926666437, "phrase": "three-step_implementation_procedure"}, {"score": 0.0029876282026237207, "phrase": "k_example_images"}, {"score": 0.00292674497467906, "phrase": "optical_flow"}, {"score": 0.0028553159147435424, "phrase": "warped_hr_version"}, {"score": 0.0026953359825383624, "phrase": "effective_method"}, {"score": 0.002629539710839523, "phrase": "individual_face"}, {"score": 0.0025865679621853667, "phrase": "adaptive_procedure"}, {"score": 0.002523420125608051, "phrase": "different_example"}, {"score": 0.00245168871716047, "phrase": "warping_errors"}, {"score": 0.002314271047073693, "phrase": "constrained_optimization_problem"}, {"score": 0.0022670785913397637, "phrase": "iterative_procedure"}, {"score": 0.0022484715639779153, "phrase": "experimental_results"}, {"score": 0.002193559776999383, "phrase": "good_performances"}, {"score": 0.0021755548389283856, "phrase": "face_hallucination"}, {"score": 0.0021224200236681498, "phrase": "reconstruction_error"}, {"score": 0.0021049977753042253, "phrase": "visual_quality"}], "paper_keywords": ["Face hallucination", " face super-resolution (SR)", " neighbor embedding", " pixel-structure learning"], "paper_abstract": "We have developed a new face hallucination framework termed from local pixel structure to global image super-resolution (LPS-GIS). Based on the assumption that two similar face images should have similar local pixel structures, the new framework first uses the input low-resolution (LR) face image to search a face database for similar example high-resolution (HR) faces in order to learn the local pixel structures for the target HR face. It then uses the input LR face and the learned pixel structures as priors to estimate the target HR face. We present a three-step implementation procedure for the framework. Step 1 searches the database for K example faces that are the most similar to the input, and then warps the K example images to the input using optical flow. Step 2 uses the warped HR version of the K example faces to learn the local pixel structures for the target HR face. An effective method for learning local pixel structures from an individual face, and an adaptive procedure for fusing the local pixel structures of different example faces to reduce the influence of warping errors, have been developed. Step 3 estimates the target HR face by solving a constrained optimization problem by means of an iterative procedure. Experimental results show that our new method can provide good performances for face hallucination, both in terms of reconstruction error and visual quality; and that it is competitive with existing state-of-the-art methods.", "paper_title": "From Local Pixel Structure to Global Image Super-Resolution: A New Face Hallucination Framework", "paper_id": "WOS:000286387700011"}