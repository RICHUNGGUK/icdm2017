{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "missing_feature_problem"}, {"score": 0.04191609033475784, "phrase": "missing_values"}, {"score": 0.004375061788023814, "phrase": "random_subspace_selection"}, {"score": 0.004220624516321415, "phrase": "supervised_classification"}, {"score": 0.003951453722517865, "phrase": "estimated_ones"}, {"score": 0.003789137457228946, "phrase": "specific_assumptions"}, {"score": 0.0037216229812089686, "phrase": "underlying_data_distribution"}, {"score": 0.0034220655476652683, "phrase": "random_subset"}, {"score": 0.003361069456060196, "phrase": "available_features"}, {"score": 0.0031845067058084583, "phrase": "majority_voting"}, {"score": 0.0030171910207671205, "phrase": "missing_features"}, {"score": 0.0028758391869611374, "phrase": "substantial_amount"}, {"score": 0.002841545331522694, "phrase": "missing_data"}, {"score": 0.0026600905156986317, "phrase": "missing_data_increases"}, {"score": 0.00247529638625566, "phrase": "random_feature_subsets"}, {"score": 0.002373472641477602, "phrase": "algorithm_performance"}, {"score": 0.0022218413146898887, "phrase": "proposed_approach"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Missing data", " Missing features", " Ensemble of classifiers", " Random subspace method"], "paper_abstract": "We introduce Learn(++).MF, an ensemble-of-classifiers based algorithm that employs random subspace selection to address the missing feature problem in supervised classification. Unlike most established approaches, Learn(++).MF does not replace missing values with estimated ones, and hence does not need specific assumptions on the underlying data distribution. Instead, it trains an ensemble of classifiers, each on a random subset of the available features. Instances with missing values are classified by the majority voting of those classifiers whose training data did not include the missing features. We show that Learn(++).MF can accommodate substantial amount of missing data, and with only gradual decline in performance as the amount of missing data increases. We also analyze the effect of the cardinality of the random feature subsets, and the ensemble size on algorithm performance. Finally, we discuss the conditions under which the proposed approach is most effective. (C) 2010 Elsevier Ltd. All rights reserved.", "paper_title": "Learn(++).MF: A random subspace approach for the missing feature problem", "paper_id": "WOS:000280983100011"}