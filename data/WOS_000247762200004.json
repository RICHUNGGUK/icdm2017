{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "activity-travel_patterns"}, {"score": 0.003968112038249246, "phrase": "transport_modes"}, {"score": 0.0038647641000798135, "phrase": "main_contributions"}, {"score": 0.00376409764683147, "phrase": "current_state-of-the_art"}, {"score": 0.002994178996584381, "phrase": "realistic_travel_times"}, {"score": 0.0028151944356239952, "phrase": "location_allocation_problem"}, {"score": 0.002555247330102505, "phrase": "respondents'_reward"}, {"score": 0.002381365139274329, "phrase": "minimum_travel_duration"}, {"score": 0.0022192891418394514, "phrase": "optimal_time_allocation"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["reinforcement learning", " Q-learning", " agent-based micro-simulation systems", " activity-based modelling"], "paper_abstract": "The Reinforcement Machine Learning technique presented in this paper simulates time and location information for a given sequence of activities and transport modes. The main contributions to the current state-of-the art are the allocation of location information in the simulation of activity-travel patterns, the non-restriction to a given number of activities and the incorporation of realistic travel times. Furthermore, the time and location allocation problem were treated and integrated simultaneously, which means that the respondents' reward is not only maximized in terms of minimum travel duration, but also simultaneously in terms of optimal time allocation. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Allocating time and location information to activity-travel patterns through reinforcement learning", "paper_id": "WOS:000247762200004"}