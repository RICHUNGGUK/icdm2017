{"auto_keywords": [{"score": 0.049651030276363126, "phrase": "kernel_matrix"}, {"score": 0.015719716506582538, "phrase": "spectral_perturbation_stability"}, {"score": 0.014004183242178326, "phrase": "generalization_error"}, {"score": 0.00855926152707603, "phrase": "kernel_selection"}, {"score": 0.00811185139397496, "phrase": "kernel_methods"}, {"score": 0.0046242451772036145, "phrase": "key_issues"}, {"score": 0.004562362497952548, "phrase": "recent_research"}, {"score": 0.0038636556112977226, "phrase": "existing_notions"}, {"score": 0.0037272031155266556, "phrase": "theoretical_generalization_error_bounds"}, {"score": 0.0032132782979796895, "phrase": "important_role"}, {"score": 0.003044455555031339, "phrase": "new_notion"}, {"score": 0.002897482096228207, "phrase": "kernel_selection_problem"}, {"score": 0.0028586409810976367, "phrase": "proposed_stability"}, {"score": 0.002820319063320601, "phrase": "spectral_perturbation"}, {"score": 0.0026841368358805407, "phrase": "training_set"}, {"score": 0.00249767641333441, "phrase": "derived_generalization_error"}, {"score": 0.0024311346712789553, "phrase": "new_kernel_selection_criterion"}, {"score": 0.002387758958649797, "phrase": "good_generalization_properties"}, {"score": 0.00216263228969761, "phrase": "newly_defined_generalized_kernel_matrix"}, {"score": 0.0021049977753042253, "phrase": "experimental_results"}], "paper_keywords": ["kernel methods", " kernel selection", " stability", " spectral perturbation stability", " generalization error bound"], "paper_abstract": "Kernel selection is one of the key issues both in recent research and application of kernel methods. This is usually done by minimizing either an estimate of generalization error or some other related performance measure. Use of notions of stability to estimate the generalization error has attracted much attention in recent years. Unfortunately, the existing notions of stability, proposed to derive the theoretical generalization error bounds, are difficult to be used for kernel selection in practice. It is well known that the kernel matrix contains most of the information needed by kernel methods, and the eigenvalues play an important role in the kernel matrix. Therefore, we aim at introducing a new notion of stability, called the spectral perturbation stability, to study the kernel selection problem. This proposed stability quantifies the spectral perturbation of the kernel matrix with respect to the changes in the training set. We establish the connection between the spectral perturbation stability and the generalization error. By minimizing the derived generalization error bound, we propose a new kernel selection criterion that can guarantee good generalization properties. In our criterion, the perturbation of the eigenvalues of the kernel matrix is efficiently computed by solving the derivative of a newly defined generalized kernel matrix. Both theoretical analysis and experimental results demonstrate that our criterion is sound and effective.", "paper_title": "Kernel selection with spectral perturbation stability of kernel matrix", "paper_id": "WOS:000343081700007"}