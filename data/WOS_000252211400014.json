{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "keyword-integrated_bayesian_reasoning"}, {"score": 0.009471782479873788, "phrase": "semantic_gap"}, {"score": 0.004593787100061613, "phrase": "main_cause"}, {"score": 0.0045324756541157574, "phrase": "semantic_gaps"}, {"score": 0.004471978831302331, "phrase": "content-based_image_retrieval"}, {"score": 0.004237925318473508, "phrase": "semantic_description"}, {"score": 0.00418134346679498, "phrase": "image_global_scale"}, {"score": 0.00398916666053909, "phrase": "visual_features"}, {"score": 0.003679969180334367, "phrase": "region_retrieval_framework"}, {"score": 0.003510754567808717, "phrase": "first_issue"}, {"score": 0.00344062888674746, "phrase": "region-level_visual_dictionary"}, {"score": 0.0033492947290751996, "phrase": "pre-labeled_segmented_images"}, {"score": 0.003238517900104576, "phrase": "second_issue"}, {"score": 0.0030895394261534776, "phrase": "similarity_ranking"}, {"score": 0.0029873281676201565, "phrase": "visual_dictionary"}, {"score": 0.002811770047652563, "phrase": "users'_relevance_feedback"}, {"score": 0.002700485592691974, "phrase": "semantic_revealing_ability"}, {"score": 0.0025761937402886954, "phrase": "reasoning_framework"}, {"score": 0.0023923066544220277, "phrase": "keyword_scenarios"}, {"score": 0.0023131084326717755, "phrase": "user_query"}, {"score": 0.0022668507535947976, "phrase": "promising_experimental_result"}, {"score": 0.0021049977753042253, "phrase": "region-based_image_retrieval"}], "paper_keywords": ["image retrieval", " image segmentation", " image annotation", " region matching", " Bayesian reasoning"], "paper_abstract": "Inaccurate semantic representation is the main cause of semantic gaps in content-based image retrieval, owing to: 1. imprecise semantic description at image global scale; 2. inaccurate mapping from visual features to image perception. In this paper, we propose a region retrieval framework using keyword-integrated Bayesian reasoning. To address the first issue, a region-level visual dictionary is constructed using pre-labeled segmented images. To address the second issue, a keyword-integrated Bayesian reasoning is adopted for similarity ranking, together with the visual dictionary to precisely bridge the semantic gap. Furthermore, users' relevance feedback is utilized to adjust the semantic revealing ability of keywords. Based on this reasoning framework, both queryby-example and query-by-keyword scenarios are provided to facilitate user query. The promising experimental result indicates the effectiveness Of OUT algorithm in enhancing the performance of region-based image retrieval and narrowing down the semantic gap.", "paper_title": "Semantic sensitive region retrieval using keyword-integrated bayesian reasoning", "paper_id": "WOS:000252211400014"}