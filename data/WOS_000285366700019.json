{"auto_keywords": [{"score": 0.02565372192030359, "phrase": "tri"}, {"score": 0.00481495049065317, "phrase": "uncertain_data"}, {"score": 0.004579780586951551, "phrase": "data_objects"}, {"score": 0.004534136929881113, "phrase": "location_uncertainty"}, {"score": 0.004399905285945236, "phrase": "data_object"}, {"score": 0.004291073117901643, "phrase": "uncertainty_region"}, {"score": 0.004205940624913343, "phrase": "probability_density_function"}, {"score": 0.003901407184706592, "phrase": "uk-means_algorithm"}, {"score": 0.0037480753312398754, "phrase": "traditional_k-means_algorithm"}, {"score": 0.0035292625231068517, "phrase": "smallest_expected_distance"}, {"score": 0.003441891354624516, "phrase": "arbitrary_pdf"}, {"score": 0.0033735490732324713, "phrase": "expected_distance"}, {"score": 0.00327356326590461, "phrase": "cluster_representative"}, {"score": 0.003240895431893263, "phrase": "expensive_integration"}, {"score": 0.0027602925235474317, "phrase": "pruning_methods"}, {"score": 0.002719055901632759, "phrase": "good_bounding_techniques"}, {"score": 0.0025730425700096365, "phrase": "metric_properties"}, {"score": 0.0022696277881969896, "phrase": "expected_distance_calculations"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Clustering", " Data uncertainty"], "paper_abstract": "We study the problem of clustering data objects with location uncertainty. In our model, a data object is represented by an uncertainty region over which a probability density function (pdf) is defined. One method to cluster such uncertain objects is to apply the UK-means algorithm [11, an extension of the traditional K-means algorithm, which assigns each object to the cluster whose representative has the smallest expected distance from it. For arbitrary pdf, calculating the expected distance between an object and a cluster representative requires expensive integration of the pdf. We study two pruning methods: pre-computation (PC) and cluster shift (CS) that can significantly reduce the number of integrations computed. Both pruning methods rely on good bounding techniques. We propose and evaluate two such techniques that are based on metric properties (Met) and trigonometry (Tri). Our experimental results show that Tri offers a very high pruning power. In some cases, more than 99.9% of the expected distance calculations are pruned. This results in a very efficient clustering algorithm.(1) (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Metric and trigonometric pruning for clustering of uncertain data in 2D geometric space", "paper_id": "WOS:000285366700019"}