{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "misclassification_errors"}, {"score": 0.012515776067387126, "phrase": "large_samples"}, {"score": 0.004569630374630379, "phrase": "simulation_studies"}, {"score": 0.004475022550508119, "phrase": "discriminant_analysis"}, {"score": 0.0037066895459425824, "phrase": "known_populations"}, {"score": 0.003303412571939192, "phrase": "underlying_distributions"}, {"score": 0.0030062165552187086, "phrase": "small_interval"}, {"score": 0.0027356847952125433, "phrase": "unexpected_results"}, {"score": 0.0024894376091589244, "phrase": "lda_misclassification_error"}, {"score": 0.002387214876538434, "phrase": "monte_carlo_method"}, {"score": 0.002218299213266519, "phrase": "bayes_error"}, {"score": 0.0021049977753042253, "phrase": "rigorous_explanation"}], "paper_keywords": ["Bayes error", " linear discriminant analysis", " misclassification", " Monte Carlo"], "paper_abstract": "In simulation studies for discriminant analysis, misclassification errors are often computed using the Monte Carlo method, by testing a classifier on large samples generated from known populations. Although large samples are expected to behave closely to the underlying distributions, they may not do so in a small interval or region, and thus may lead to unexpected results. We demonstrate with an example that the LDA misclassification error computed via the Monte Carlo method may often be smaller than the Bayes error. We give a rigorous explanation and recommend a method to properly compute misclassification errors.", "paper_title": "Why do we observe misclassification errors smaller than the Bayes error?", "paper_id": "WOS:000265453400007"}