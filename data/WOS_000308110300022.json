{"auto_keywords": [{"score": 0.04208729377636017, "phrase": "better_performance"}, {"score": 0.00481495049065317, "phrase": "layered_self-scheduling_approach"}, {"score": 0.004766683200410046, "phrase": "heterogeneous_multicore_cluster_systems"}, {"score": 0.004509694461067052, "phrase": "hybrid_mpi_and_openmp_based_loop_self-scheduling_approach"}, {"score": 0.004309725894724034, "phrase": "cluster_system"}, {"score": 0.004245051445971095, "phrase": "multi-core_compute_nodes"}, {"score": 0.004160319763461951, "phrase": "allocation_functions"}, {"score": 0.00395599516685797, "phrase": "lss"}, {"score": 0.0038573081851680656, "phrase": "conventional_self-scheduling_schemes"}, {"score": 0.003558294449586273, "phrase": "newly_proposed_task_scheduling_strategy"}, {"score": 0.0035048567587934254, "phrase": "enhanced_layered_self-scheduling"}, {"score": 0.0033156708990372077, "phrase": "compute_powers"}, {"score": 0.003282383509542342, "phrase": "multiple_processor_cores"}, {"score": 0.002952356518921907, "phrase": "new_task_scheduling_strategy"}, {"score": 0.0028933521924166287, "phrase": "matrix_multiplication"}, {"score": 0.0028642924503126154, "phrase": "monte_carlo_integration"}, {"score": 0.002821247621250663, "phrase": "mandelbrot_set_computation"}, {"score": 0.002723301730223192, "phrase": "global_scheduler"}, {"score": 0.0026959452932289797, "phrase": "guided_self-scheduling"}, {"score": 0.0026688823897094947, "phrase": "gss"}, {"score": 0.0025761937402886954, "phrase": "local_scheduler"}, {"score": 0.0025374674652885354, "phrase": "static_scheme"}, {"score": 0.002486734224234698, "phrase": "regular_workload_distribution"}, {"score": 0.002400373755068185, "phrase": "irregular_workload_distribution"}, {"score": 0.0023762535034673017, "phrase": "experimental_results"}, {"score": 0.0023405257495466352, "phrase": "best_speedups"}, {"score": 0.0023053339328456234, "phrase": "elss"}, {"score": 0.002105007180057976, "phrase": "lss."}], "paper_keywords": ["Cluster systems", " Self-scheduling", " MPI", " OpenMP", " Multicore processor"], "paper_abstract": "Previously we have proposed a Layered Self-Scheduling (LSS) approach that is a hybrid MPI and OpenMP based loop self-scheduling approach for dealing with the heterogeneity problem on a cluster system consisting of multi-core compute nodes, where the allocation functions of several well-known schemes have been modified for better performance. Though LSS provides better performance than the conventional self-scheduling schemes, we found the performance can be improved further after our comprehensive experiments and analyses. The newly proposed task scheduling strategy, called Enhanced Layered Self-Scheduling (ELSS), aims at how to utilize the compute powers of multiple processor cores more efficiently in the master compute node and how to schedule tasks to have more stable performance improvements. We have evaluated the new task scheduling strategy by three benchmark applications: Matrix Multiplication, Monte Carlo Integration, and Mandelbrot Set Computation. It is recommended that the global scheduler adopts Guided Self-Scheduling (GSS) for all, and the local scheduler adopts the static scheme for applications with regular workload distribution but any scheme for applications with irregular workload distribution. Experimental results show the best speedups obtained by ELSS for the three benchmark programs are 1.373, 13.34 and 2.4, respectively, compared with that scheduled by LSS.", "paper_title": "Performance evaluation of enhancement of the layered self-scheduling approach for heterogeneous multicore cluster systems", "paper_id": "WOS:000308110300022"}