{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "pedestrian_detection"}, {"score": 0.011889920216636004, "phrase": "real-world_images"}, {"score": 0.009467025523672658, "phrase": "target_domain"}, {"score": 0.0047013405841819025, "phrase": "paramount_interest"}, {"score": 0.004546755482549647, "phrase": "discriminatively_learnt_classifiers"}, {"score": 0.004418287966422041, "phrase": "annotated_samples"}, {"score": 0.004313996835376177, "phrase": "annotation_step"}, {"score": 0.004252602474733162, "phrase": "human_intensive_and_subjective_task"}, {"score": 0.00409310463335204, "phrase": "virtual_worlds"}, {"score": 0.003996458454723708, "phrase": "precise_and_rich_annotations"}, {"score": 0.003791763445590174, "phrase": "pedestrian_appearance_model"}, {"score": 0.0037377733149169573, "phrase": "realistic_virtual_worlds"}, {"score": 0.003529364798514874, "phrase": "virtual-world_based_training"}, {"score": 0.0034790978593553794, "phrase": "excellent_testing_accuracy"}, {"score": 0.0034459835582278746, "phrase": "real_world"}, {"score": 0.0033166379485150507, "phrase": "data_set_shift_problem"}, {"score": 0.0032850648549389025, "phrase": "real-world_based_training"}, {"score": 0.003146652729098066, "phrase": "domain_adaptation_framework"}, {"score": 0.0029853535424953595, "phrase": "different_techniques"}, {"score": 0.0027129118211250336, "phrase": "source_domain"}, {"score": 0.0025737890313763407, "phrase": "adapted_pedestrian_classifier"}, {"score": 0.002187194307878705, "phrase": "first_work"}, {"score": 0.002145703330831668, "phrase": "virtual_and_real_worlds"}, {"score": 0.0021049977753042253, "phrase": "object_detector"}], "paper_keywords": ["Pedestrian detection", " photo-realistic computer animation", " data set shift", " domain adaptation"], "paper_abstract": "Pedestrian detection is of paramount interest for many applications. Most promising detectors rely on discriminatively learnt classifiers, i.e., trained with annotated samples. However, the annotation step is a human intensive and subjective task worth to be minimized. By using virtual worlds we can automatically obtain precise and rich annotations. Thus, we face the question: can a pedestrian appearance model learnt in realistic virtual worlds work successfully for pedestrian detection in real-world images? Conducted experiments show that virtual-world based training can provide excellent testing accuracy in real world, but it can also suffer the data set shift problem as real-world based training does. Accordingly, we have designed a domain adaptation framework, V-AYLA, in which we have tested different techniques to collect a few pedestrian samples from the target domain (real world) and combine them with the many examples of the source domain (virtual world) in order to train a domain adapted pedestrian classifier that will operate in the target domain. V-AYLA reports the same detection accuracy than when training with many human-provided pedestrian annotations and testing with real-world images of the same domain. To the best of our knowledge, this is the first work demonstrating adaptation of virtual and real worlds for developing an object detector.", "paper_title": "Virtual and Real World Adaptation for Pedestrian Detection", "paper_id": "WOS:000334109000013"}