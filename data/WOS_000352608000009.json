{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "learning_balanced"}, {"score": 0.00471193241675062, "phrase": "low-rank_coding"}, {"score": 0.004435006247087171, "phrase": "real-world_applications"}, {"score": 0.004138309011478741, "phrase": "effective_graph"}, {"score": 0.0040672766251859975, "phrase": "open_problem"}, {"score": 0.003911862375084159, "phrase": "novel_approach"}, {"score": 0.003697760799674494, "phrase": "recent_advances"}, {"score": 0.003665874747419775, "phrase": "low-rank_subspace_recovery"}, {"score": 0.003510507340837656, "phrase": "low-rank_code_space"}, {"score": 0.0033909518548844047, "phrase": "sample_space"}, {"score": 0.0033182992967343916, "phrase": "sparse_and_balanced_graph"}, {"score": 0.0032191849045822415, "phrase": "learning_tasks"}, {"score": 0.003163878786694538, "phrase": "label_propagation"}, {"score": 0.0031230216871739776, "phrase": "based_semi-supervised_learning"}, {"score": 0.00308269056870936, "phrase": "k-nn_sparsification"}, {"score": 0.0030428787018636147, "phrase": "fast_solutions"}, {"score": 0.003003579442221871, "phrase": "unbalanced_sparse_graphs"}, {"score": 0.002888692115811987, "phrase": "necessary_route"}, {"score": 0.0028513785049061767, "phrase": "balanced_graphs"}, {"score": 0.0027304365438083874, "phrase": "low-rank_codes"}, {"score": 0.002525489173110693, "phrase": "k-nn_constraint"}, {"score": 0.0025036862991477437, "phrase": "b-matching_constraint"}, {"score": 0.0024713335323674223, "phrase": "low-rank_representation_model"}, {"score": 0.0023974563359295043, "phrase": "majorization-minimization_augmented_lagrange_multiplier"}, {"score": 0.0022957232752482196, "phrase": "proposed_models"}, {"score": 0.0022758994740331258, "phrase": "extensive_experimental_results"}, {"score": 0.0021049977753042253, "phrase": "data_clustering"}], "paper_keywords": ["Low-rank learning", " graph construction", " b-matching", " similarity metric", " clustering", " semi-supervised classification"], "paper_abstract": "Graphs have been widely applied in modeling the relationships and structures in real-world applications. Graph construction is the most critical part in these models, while how to construct an effective graph is still an open problem. In this paper, we propose a novel approach to graph construction based on two observations. First, by virtue of recent advances in low-rank subspace recovery, the similarity between every two samples evaluated in the low-rank code space is more robust than that in the sample space. Second, a sparse and balanced graph can greatly increase the performance of learning tasks, such as label propagation in graph based semi-supervised learning. The k-NN sparsification can provide fast solutions to constructing unbalanced sparse graphs, and b-matching constraint is a necessary route for generating balanced graphs. These observations motivate us to jointly learn the low-rank codes and balanced (or unbalanced) graph simultaneously. In particular, two non-convex models are built by incorporating k-NN constraint and b-matching constraint into the low-rank representation model, respectively. We design a majorization-minimization augmented Lagrange multiplier (MM-ALM) algorithm to solve the proposed models. Extensive experimental results on four image databases demonstrate the superiority of our graphs over several state-of-the-art graphs in data clustering, transductive and inductive semi-supervised learning.", "paper_title": "Learning Balanced and Unbalanced Graphs via Low-Rank Coding", "paper_id": "WOS:000352608000009"}