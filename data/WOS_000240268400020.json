{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "embodied_conversational_agents"}, {"score": 0.036588740387536144, "phrase": "surface_text"}, {"score": 0.004717723626157272, "phrase": "believable_nonverbal_behaviors"}, {"score": 0.0037307208089736835, "phrase": "nonverbal_behavior_generator"}, {"score": 0.003581412258960711, "phrase": "syntactic_and_semantic_structure"}, {"score": 0.0033004240095380623, "phrase": "affective_state"}, {"score": 0.00320082590111849, "phrase": "eca"}, {"score": 0.003010496595090984, "phrase": "appropriate_nonverbal_behaviors"}, {"score": 0.002860546817196148, "phrase": "video_clips"}, {"score": 0.0026091594819333654, "phrase": "nonverbal_behavior_generation_rules"}, {"score": 0.0021049977753042253, "phrase": "current_behavior_generation_rules"}], "paper_keywords": [""], "paper_abstract": "Believable nonverbal behaviors for embodied conversational agents (ECA) can create a more immersive experience for users and improve the effectiveness of communication. This paper describes a nonverbal behavior generator that analyzes the syntactic and semantic structure of the surface text as well as the affective state of the ECA and annotates the surface text with appropriate nonverbal behaviors. A number of video clips of people conversing were analyzed to extract the nonverbal behavior generation rules. The system works in real-time and is user-extensible so that users can easily modify or extend the current behavior generation rules.", "paper_title": "Nonverbal behavior generator for embodied conversational agents", "paper_id": "WOS:000240268400020"}