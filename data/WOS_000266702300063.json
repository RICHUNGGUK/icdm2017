{"auto_keywords": [{"score": 0.049613254104042076, "phrase": "rbf"}, {"score": 0.00481495049065317, "phrase": "input_variable_and_basis_function_selection"}, {"score": 0.0046986841646790315, "phrase": "input_selection"}, {"score": 0.004607686390487483, "phrase": "regression_problems"}, {"score": 0.004387793971765289, "phrase": "training_time"}, {"score": 0.00428179779071721, "phrase": "measurement_costs"}, {"score": 0.0041174821422410544, "phrase": "high_dimensionality"}, {"score": 0.003978866233891427, "phrase": "useless_inputs"}, {"score": 0.0037888687452790953, "phrase": "neural_networks"}, {"score": 0.0037519679864796906, "phrase": "good_generalization"}, {"score": 0.0032714270066711835, "phrase": "present_work"}, {"score": 0.0030397596289795143, "phrase": "constrained_optimization_problem"}, {"score": 0.0026501935378083663, "phrase": "output_layer_coefficients"}, {"score": 0.0024264776194357993, "phrase": "proposed_method"}, {"score": 0.002379379676378223, "phrase": "simulated_and_benchmark_data"}, {"score": 0.00229914226836813, "phrase": "existing_methods"}, {"score": 0.002265586601922693, "phrase": "resulting_rbf_networks"}, {"score": 0.0022434880661725493, "phrase": "similar_prediction_accuracies"}, {"score": 0.0022107428653358715, "phrase": "smaller_numbers"}, {"score": 0.0021678232353129472, "phrase": "basis_functions"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Regression", " Function approximation", " Feedforward neural network", " Radial basis function network", " RBF", " Input selection", " Basis function selection", " Feature selection"], "paper_abstract": "Input selection is advantageous in regression problems. It may, for example, decrease the training time of models, reduce measurement costs, and assist in circumventing problems of high dimensionality. Also, the inclusion of useless inputs into the model increases the likelihood of overfitting. Neural networks provide good generalization in many cases, but their interpretability is usually limited. However, selecting a subset of variables and estimating their relative importances would be valuable in many real world applications. In the present work, a simultaneous input and basis function selection method for a radial basis function (RBF) network is proposed. The selection is performed by minimizing a constrained optimization problem, in which sparsity of the network is controlled by two continuous valued shrinkage parameters. Each input dimension is weighted and the constraints are imposed on these weights and the output layer coefficients. Direct and alternating optimization (AO) procedures are presented to solve the problem. The proposed method is applied to simulated and benchmark data. In the comparison with the existing methods, the resulting RBF networks have similar prediction accuracies with the smaller numbers of inputs and basis functions. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Simultaneous input variable and basis function selection for RBF networks", "paper_id": "WOS:000266702300063"}