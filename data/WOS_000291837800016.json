{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "psychological_distance"}, {"score": 0.012717973571088956, "phrase": "visual_stimuli"}, {"score": 0.007304132231357609, "phrase": "visual_scene"}, {"score": 0.006588950583615961, "phrase": "proposed_model"}, {"score": 0.004709567162738894, "phrase": "new_affective_saliency_map"}, {"score": 0.004522291357556591, "phrase": "pop-out_property"}, {"score": 0.00447251540886613, "phrase": "relative_spatial_distribution"}, {"score": 0.004423284899590467, "phrase": "primitive_visual_features"}, {"score": 0.004154332348800334, "phrase": "spatial_distance"}, {"score": 0.004108589735101849, "phrase": "spatial_proximity"}, {"score": 0.003844478919573134, "phrase": "proposed_sm_model"}, {"score": 0.0036914757355166966, "phrase": "primary_visual_perception"}, {"score": 0.0035445401296650535, "phrase": "social_distance"}, {"score": 0.003479692058963528, "phrase": "proximal_entity"}, {"score": 0.003304339421246321, "phrase": "distal_entity"}, {"score": 0.0027571412070078703, "phrase": "psychological_depth_cues"}, {"score": 0.0026375303198093764, "phrase": "depth_perception"}, {"score": 0.0025796799784169196, "phrase": "real_spatial_distance"}, {"score": 0.0025606791601860543, "phrase": "visual_target"}, {"score": 0.0024677487011556427, "phrase": "proposed_affective_sm_model"}, {"score": 0.0024405312482831646, "phrase": "eye_tracking_system"}, {"score": 0.0023869914500743083, "phrase": "visual_scan_path"}, {"score": 0.0023694065215394593, "phrase": "fixation_time"}, {"score": 0.002343271162668978, "phrase": "specific_local_area"}, {"score": 0.0023088708688076666, "phrase": "visual_scenes"}, {"score": 0.0022918601312169676, "phrase": "human_subjects"}, {"score": 0.0022749744354271834, "phrase": "experimental_results"}, {"score": 0.0022168460543913787, "phrase": "plausible_visual_selective_attention"}, {"score": 0.0021682027434117095, "phrase": "primitive_visual_stimuli"}, {"score": 0.0021522261505574035, "phrase": "pop-out_bottom-up_features"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Affective saliency map", " Psychological distance", " Stereo-saliency map", " Bottom-up saliency map", " Selective attention"], "paper_abstract": "This paper proposes a new affective saliency map (SM) model considering psychological distance as well as the pop-out property based on relative spatial distribution of the primitive visual features such as intensity, edge, color, and orientation. By reflecting congruency between the spatial distance caused by spatial proximity and distal in a visual scene and psychological distance caused by the way people think about visual stimuli, the proposed SM model can produce more human-like visual selective attention than a conventional SM model based on primary visual perception. In the proposed model, a psychological distance caused by a social distance, in which a proximal entity such as friend becomes more attractive when it is located near but a distal entity such as enemy becomes more attractive when it is located far from an observer, is considered. In the experiments, two types of visual stimuli are considered, mono-stimuli and stereo-stimuli. In the case of mono-stimuli, the visual stimuli on a picture with psychological depth cues were considered. Instead, in the case of stereo-stimuli, depth perception is also considered for obtaining real spatial distance of visual target in a visual scene. In order to verify the proposed affective SM model, an eye tracking system was used to measure the visual scan path and fixation time on a specific local area while monitoring the visual scenes by human subjects. Experimental results show that the proposed model can generate plausible visual selective attention properly reflecting both psychological distance and primitive visual stimuli inducing pop-out bottom-up features. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Affective saliency map considering psychological distance", "paper_id": "WOS:000291837800016"}