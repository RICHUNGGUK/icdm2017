{"auto_keywords": [{"score": 0.042657423330974706, "phrase": "mhi"}, {"score": 0.016528423691446213, "phrase": "interest_point"}, {"score": 0.010612381429378998, "phrase": "action_recognition"}, {"score": 0.010537504566782208, "phrase": "crowded_videos"}, {"score": 0.004713162564945179, "phrase": "cluttered_and_moving_background"}, {"score": 0.004663074596384574, "phrase": "challenging_problem"}, {"score": 0.004515967518891287, "phrase": "motion_field"}, {"score": 0.004467965784278827, "phrase": "action_region"}, {"score": 0.004389089062127892, "phrase": "background_motions"}, {"score": 0.004311598785718415, "phrase": "hierarchical_filtered_motion"}, {"score": 0.004101797841848363, "phrase": "motion_history_image"}, {"score": 0.004029359223675788, "phrase": "basic_representations"}, {"score": 0.003846926701870193, "phrase": "interest_points"}, {"score": 0.0038060092376105414, "phrase": "two-dimensional_harris_corners"}, {"score": 0.003685840071638243, "phrase": "high_intensities"}, {"score": 0.003646629898310395, "phrase": "mhi."}, {"score": 0.0035949949979695063, "phrase": "global_spatial_motion_smoothing_filter"}, {"score": 0.0034567253581991226, "phrase": "isolated_unreliable_or_noisy_motions"}, {"score": 0.003371508176308189, "phrase": "local_motion_field_filter"}, {"score": 0.0033119237381809617, "phrase": "smoothed_gradients"}, {"score": 0.0032418062548293745, "phrase": "structure_proximity"}, {"score": 0.0031731685183735508, "phrase": "local_region"}, {"score": 0.0028511121935559072, "phrase": "spatial_and_temporal_features"}, {"score": 0.0028107098861552124, "phrase": "oriented_gradient"}, {"score": 0.002780783274864117, "phrase": "intensity_image"}, {"score": 0.002683304054823427, "phrase": "gaussian-mixture-model-based_classifier"}, {"score": 0.0025984901976634726, "phrase": "proposed_approach"}, {"score": 0.0024895500851796603, "phrase": "kth_dataset"}, {"score": 0.0024630345285372958, "phrase": "clean_background"}, {"score": 0.0024022553322977165, "phrase": "cross-dataset_action_classification_and_detection_experiments"}, {"score": 0.0023682018335885488, "phrase": "kth"}, {"score": 0.002127667143545464, "phrase": "proposed_hfm_method"}, {"score": 0.0021049977753042253, "phrase": "existing_techniques"}], "paper_keywords": ["Action classification", " action detection", " crowded videos", " hierarchical filtered motion (HFM)", " motion history image (MHI)"], "paper_abstract": "Action recognition with cluttered and moving background is a challenging problem. One main difficulty lies in the fact that the motion field in an action region is contaminated by the background motions. We propose a hierarchical filtered motion (HFM) method to recognize actions in crowded videos by the use of motion history image (MHI) as basic representations of motion because of its robustness and efficiency. First, we detect interest points as the two-dimensional Harris corners with recent motion, e.g., locations with high intensities in the MHI. Then, a global spatial motion smoothing filter is applied to the gradients of the MHI to eliminate isolated unreliable or noisy motions. At each interest point, a local motion field filter is applied to the smoothed gradients of the MHI by computing structure proximity between any pixel in the local region and the interest point. Thus, the motion at a pixel is enhanced or weakened based on its structure proximity with the interest point. To validate its effectiveness, we characterize the spatial and temporal features by histograms of oriented gradient in the intensity image and the MHI, respectively, and use a Gaussian-mixture-model-based classifier for action recognition. The performance of the proposed approach achieves the state-of-the-art results on the KTH dataset that has clean background. More importantly, we perform cross-dataset action classification and detection experiments, where the KTH dataset is used for training, while the microsoft research (MSR) action dataset II that consists of crowded videos with people moving in the background is used for testing. Our experiments show that the proposed HFM method significantly outperforms existing techniques.", "paper_title": "Hierarchical Filtered Motion for Action Recognition in Crowded Videos", "paper_id": "WOS:000303069100003"}