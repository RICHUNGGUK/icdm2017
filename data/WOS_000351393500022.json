{"auto_keywords": [{"score": 0.04005235829421411, "phrase": "standard_normal_curve"}, {"score": 0.011400564813383555, "phrase": "equal_probability"}, {"score": 0.00481495049065317, "phrase": "sax_discretization"}, {"score": 0.004642292792558686, "phrase": "time_series_analysis_research"}, {"score": 0.004537525607322823, "phrase": "strong_interest"}, {"score": 0.004496280772084575, "phrase": "discrete_representations"}, {"score": 0.004455409162867219, "phrase": "real_valued_data_streams"}, {"score": 0.0039928721865882, "phrase": "sax_assumption"}, {"score": 0.003920573616298175, "phrase": "highly_gaussian"}, {"score": 0.0036441884295335502, "phrase": "sax_approach"}, {"score": 0.0032955848190195343, "phrase": "time_series"}, {"score": 0.0029128614098881253, "phrase": "intermediate_step"}, {"score": 0.0028863414975346512, "phrase": "piecewise_aggregate_approximation"}, {"score": 0.002732205765587878, "phrase": "paa"}, {"score": 0.002551022760887132, "phrase": "shrinking_standard_deviation"}, {"score": 0.002370955769074803, "phrase": "paa_representation"}, {"score": 0.002234031373581961, "phrase": "statistically_significant_auto-correlation"}, {"score": 0.0021735249249471614, "phrase": "shrinking_distribution"}, {"score": 0.0021340985236583034, "phrase": "standard_deviation"}, {"score": 0.0021049977753042253, "phrase": "data_contracts"}], "paper_keywords": ["SAX", " time series analysis", " discretization", " auto-correlation"], "paper_abstract": "In time series analysis research, there is a strong interest in discrete representations of real valued data streams. One approach still considered state-of-the-art is the Symbolic Aggregate Approximation (SAX) algorithm. The interest of this paper concerns the SAX assumption of data being highly Gaussian and the use of the standard normal curve to choose partitions to discretize the data. The SAX approach chooses partitions on the standard normal curve that would produce an equal probability for each symbol. This procedure is generally valid as a time series is normalized to have mu = 0 and sigma = 1. However, there exists a caveat to this assumption of equi-probability due to the intermediate step of Piecewise Aggregate Approximation (PAA). We show in this paper that when PAA is applied, the distribution of the data is altered, resulting in a shrinking standard deviation that is proportional to the number of points used to create a segment of the PAA representation and the degree of auto-correlation within the series. Data that exhibits statistically significant auto-correlation is less affected by this shrinking distribution. As the standard deviation of the data contracts, the mean remains the same, however the distribution is no longer standard normal and therefore the partitions based on the standard normal curve are no longer valid for the assumption of equal probability.", "paper_title": "SAX Discretization Does Not Guarantee Equiprobable Symbols", "paper_id": "WOS:000351393500022"}