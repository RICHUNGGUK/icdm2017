{"auto_keywords": [{"score": 0.04883313245975001, "phrase": "nmf"}, {"score": 0.04781649621498736, "phrase": "plsa"}, {"score": 0.01264472591181058, "phrase": "multi-way_data"}, {"score": 0.008760547751836946, "phrase": "ntf"}, {"score": 0.00481495049065317, "phrase": "nonnegative_tensor_factorization"}, {"score": 0.004772818068176176, "phrase": "tensorial_probabilistic_latent_semantic_analysis"}, {"score": 0.0047310525657970615, "phrase": "non-negative_matrix_factorization"}, {"score": 0.004628223381645729, "phrase": "probabilistic_latent_semantic_analysis"}, {"score": 0.004487989502479992, "phrase": "non-negative_data_decomposition"}, {"score": 0.004448705308279165, "phrase": "two-way_data"}, {"score": 0.004074212307838049, "phrase": "kullback-leibler_divergence_objective"}, {"score": 0.00355485940716082, "phrase": "rich_intrinsic_structures"}, {"score": 0.002890557197908352, "phrase": "t-plsa_models"}, {"score": 0.00277825332331098, "phrase": "parafac"}, {"score": 0.002705808393126695, "phrase": "kl-divergence_objective"}, {"score": 0.0025328377393370642, "phrase": "objective_functions"}, {"score": 0.0023192471808039746, "phrase": "hybrid_method"}, {"score": 0.0021709339252206825, "phrase": "other's_local_minima"}, {"score": 0.0021049977753042253, "phrase": "better_clustering_performance"}], "paper_keywords": ["Nonnegative tensor factorization", " Probabilistic latent semantic analysis", " Clustering"], "paper_abstract": "Non-negative Matrix Factorization (NMF) and Probabilistic Latent Semantic Analysis (PLSA) are two widely used methods for non-negative data decomposition of two-way data (e.g., document-term matrices). Studies have shown that PLSA and NMF (with the Kullback-Leibler divergence objective) are different algorithms optimizing the same objective function. Recently, analyzing multi-way data (i.e., tensors), has attracted a lot of attention as multi-way data have rich intrinsic structures and naturally appear in many real-world applications. In this paper, the relationships between NMF and PLSA extensions on multi-way data, e.g., NTF (Non-negative Tensor Factorization) and T-PLSA (Tensorial Probabilistic Latent Semantic Analysis), are studied. Two types of T-PLSA models are shown to be equivalent to two well-known non-negative factorization models: PARAFAC and Tucker3 (with the KL-divergence objective). NTF and T-PLSA are also compared empirically in terms of objective functions, decomposition results, clustering quality, and computation complexity on both synthetic and real-world datasets. Finally, we show that a hybrid method by running NTF and T-PLSA alternatively can successfully jump out of each other's local minima and thus be able to achieve better clustering performance.", "paper_title": "On the equivalence between nonnegative tensor factorization and tensorial probabilistic latent semantic analysis", "paper_id": "WOS:000294689900009"}