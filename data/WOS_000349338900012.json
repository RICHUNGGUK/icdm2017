{"auto_keywords": [{"score": 0.03905383994125658, "phrase": "semantic_gap"}, {"score": 0.03438524869625368, "phrase": "supervised_information"}, {"score": 0.00481495049065317, "phrase": "large-scale_histopathological_image_analysis"}, {"score": 0.004775531918452571, "phrase": "hashing-based_image_retrieval"}, {"score": 0.004678384952779725, "phrase": "histopathological_images"}, {"score": 0.004564401713056939, "phrase": "computational_image-processing_methods"}, {"score": 0.004527024978801684, "phrase": "modern_machine_learning_techniques"}, {"score": 0.004471530397729526, "phrase": "computer-aided_diagnosis"}, {"score": 0.004380540407926982, "phrase": "content-based_image-retrieval"}, {"score": 0.0041696157492057, "phrase": "disease_detection"}, {"score": 0.0041184843463633386, "phrase": "decision_support"}, {"score": 0.003968806706727518, "phrase": "ever-increasing_amount"}, {"score": 0.0039362878637371574, "phrase": "annotated_medical_data"}, {"score": 0.0038720442355114045, "phrase": "data-driven_methods"}, {"score": 0.0036553070575015344, "phrase": "diagnostic_information"}, {"score": 0.0035079364710988627, "phrase": "scalable_image-retrieval_techniques"}, {"score": 0.0034364867143322274, "phrase": "massive_histopathological_images"}, {"score": 0.0033388871136347704, "phrase": "supervised_kernel_hashing_technique"}, {"score": 0.003284361433827464, "phrase": "small_amount"}, {"score": 0.0031132086055691214, "phrase": "binary_bits"}, {"score": 0.003074991770768925, "phrase": "informative_signatures"}, {"score": 0.0030247625535682987, "phrase": "binary_codes"}, {"score": 0.0029509483926257645, "phrase": "hash_table"}, {"score": 0.0029147175927233546, "phrase": "real-time_retrieval"}, {"score": 0.0028553159147435424, "phrase": "large_database"}, {"score": 0.0027064605585684696, "phrase": "low-level_image_features"}, {"score": 0.002684257009647205, "phrase": "high-level_diagnostic_information"}, {"score": 0.002629539710839523, "phrase": "scalable_image-retrieval_framework"}, {"score": 0.0025865679621853667, "phrase": "supervised_hashing_technique"}, {"score": 0.0025027144548626975, "phrase": "breast_microscopic_tissues"}, {"score": 0.0024821782596371536, "phrase": "extensive_evaluations"}, {"score": 0.0024116163689723354, "phrase": "image_classification"}, {"score": 0.0023527296826339225, "phrase": "actionable_categorization"}, {"score": 0.002323826502178581, "phrase": "retrieval_tests"}, {"score": 0.0022484715639779153, "phrase": "promising_time_efficiency"}], "paper_keywords": ["Breast lesion", " hashing", " high dimension", " histopathological image analysis", " large-scale image retrieval", " supervised learning"], "paper_abstract": "Automatic analysis of histopathological images has been widely utilized leveraging computational image-processing methods and modern machine learning techniques. Both computer-aided diagnosis (CAD) and content-based image-retrieval (CBIR) systems have been successfully developed for diagnosis, disease detection, and decision support in this area. Recently, with the ever-increasing amount of annotated medical data, large-scale and data-driven methods have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing scalable image-retrieval techniques to cope intelligently with massive histopathological images. Specifically, we present a supervised kernel hashing technique which leverages a small amount of supervised information in learning to compress a 10 000-dimensional image feature vector into only tens of binary bits with the informative signatures preserved. These binary codes are then indexed into a hash table that enables real-time retrieval of images in a large database. Critically, the supervised information is employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build a scalable image-retrieval framework based on the supervised hashing technique and validate its performance on several thousand histopathological images acquired from breast microscopic tissues. Extensive evaluations are carried out in terms of image classification (i.e., benign versus actionable categorization) and retrieval tests. Our framework achieves about 88.1% classification accuracy as well as promising time efficiency. For example, the framework can execute around 800 queries in only 0.01 s, comparing favorably with other commonly used dimensionality reduction and feature selection methods.", "paper_title": "Towards Large-Scale Histopathological Image Analysis: Hashing-Based Image Retrieval", "paper_id": "WOS:000349338900012"}