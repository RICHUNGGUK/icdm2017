{"auto_keywords": [{"score": 0.040984019337186935, "phrase": "hmm"}, {"score": 0.036572864113775014, "phrase": "em"}, {"score": 0.02932836226258493, "phrase": "sasem"}, {"score": 0.00481495049065317, "phrase": "expectation_maximization_algorithm"}, {"score": 0.0047283116134926645, "phrase": "better_estimation"}, {"score": 0.0046432244185370605, "phrase": "hidden_markov_model"}, {"score": 0.004317848984770719, "phrase": "local_convergence_problem"}, {"score": 0.004201774694043468, "phrase": "expectation_maximization"}, {"score": 0.004051828608343507, "phrase": "based_training"}, {"score": 0.003802135020791801, "phrase": "speech_recognition"}, {"score": 0.0036332251283046997, "phrase": "hybrid_algorithm"}, {"score": 0.0035677736570659813, "phrase": "simulated_annealing_stochastic"}, {"score": 0.003287482882222731, "phrase": "simulated_annealing"}, {"score": 0.0031129269142224168, "phrase": "hmm_estimation_process"}, {"score": 0.0030291453183733897, "phrase": "stochastic_step"}, {"score": 0.002947611960613497, "phrase": "em_steps"}, {"score": 0.0028682711327744047, "phrase": "sa."}, {"score": 0.002816556934231128, "phrase": "stochastic_processes"}, {"score": 0.002525248554951453, "phrase": "local_maximum"}, {"score": 0.00245724480030654, "phrase": "improved_estimation"}, {"score": 0.0023479408542211875, "phrase": "global_convergence_properties"}, {"score": 0.002305589818994465, "phrase": "sa._experiments"}, {"score": 0.0022434880661725493, "phrase": "timit_speech_corpus_show"}, {"score": 0.0021632743048552554, "phrase": "higher_recognition_accuracies"}], "paper_keywords": ["Hidden Markov Model", " Expectation Maximization", " Speech recognition", " Constraint-based Evolutionary Algorithm", " Stochastic EM"], "paper_abstract": "This paper attempts to overcome the local convergence problem of the Expectation Maximization (EM) based training of the Hidden Markov Model (HMM) in speech recognition. We propose a hybrid algorithm, Simulated Annealing Stochastic version of EM (SASEM), combining Simulated Annealing with EM that reformulates the HMM estimation process using a stochastic step between the EM steps and the SA. The stochastic processes of SASEM inside EM can prevent EM from converging to a local maximum and find improved estimation for HMM using the global convergence properties of SA. Experiments on the TIMIT speech corpus show that SASEM obtains higher recognition accuracies than the EM. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "A stochastic version of Expectation Maximization algorithm for better estimation of Hidden Markov Model", "paper_id": "WOS:000270122800007"}