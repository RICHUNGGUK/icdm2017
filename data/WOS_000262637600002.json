{"auto_keywords": [{"score": 0.04491014564883475, "phrase": "mnd"}, {"score": 0.010612384215170072, "phrase": "nonlinear_independent_component_analysis"}, {"score": 0.004351595642056769, "phrase": "\"minimal_nonlinear_distortion"}, {"score": 0.004154332348800334, "phrase": "nonlinear_ica_problems"}, {"score": 0.004067635935640407, "phrase": "nonlinear_ica_solution"}, {"score": 0.004016485454498076, "phrase": "estimated_mixing_procedure"}, {"score": 0.003850566273995209, "phrase": "possible_solutions"}, {"score": 0.003738502710504415, "phrase": "local_optima"}, {"score": 0.0035539019235553897, "phrase": "regularization_term"}, {"score": 0.0034944094552943, "phrase": "mean_square_error"}, {"score": 0.0034504423179340738, "phrase": "nonlinear_mixing_mapping"}, {"score": 0.003407026489727146, "phrase": "best-fitting_linear"}, {"score": 0.0032800186243040663, "phrase": "inherent_trivial_and_non-trivial_indeterminacies"}, {"score": 0.003104849179057156, "phrase": "local_mnd"}, {"score": 0.0029890721584351684, "phrase": "large_curvature"}, {"score": 0.0029266219967426224, "phrase": "useful_regularization_condition"}, {"score": 0.0029020077365708966, "phrase": "nonlinear_ica._experiments"}, {"score": 0.00287759989638073, "phrase": "synthetic_data"}, {"score": 0.002805597755796506, "phrase": "mnd_principle"}, {"score": 0.002655697256976997, "phrase": "nonlinear_ica"}, {"score": 0.002600194073758015, "phrase": "daily_returns"}, {"score": 0.002524428047147766, "phrase": "hong_kong"}, {"score": 0.002482126086922683, "phrase": "linear_causal_relations"}, {"score": 0.0023996317685956213, "phrase": "resulting_causal_relations"}, {"score": 0.0023694065215394593, "phrase": "interesting_insights"}, {"score": 0.0023395610923736595, "phrase": "stock_market"}, {"score": 0.002261794227418188, "phrase": "linear_ica._simulation_studies"}, {"score": 0.0022051664509486206, "phrase": "causality_discovery"}, {"score": 0.002131857309586904, "phrase": "nonlinear_distortion"}, {"score": 0.0021049977753042253, "phrase": "data_generation_procedure"}], "paper_keywords": ["nonlinear ICA", " regularization", " minimal nonlinear distortion", " mean square error", " best linear reconstruction"], "paper_abstract": "It is well known that solutions to the nonlinear independent component analysis (ICA) problem are highly non-unique. In this paper we propose the \"minimal nonlinear distortion\" (MND) principle for tackling the ill-posedness of nonlinear ICA problems. MND prefers the nonlinear ICA solution with the estimated mixing procedure as close as possible to linear, among all possible solutions. It also helps to avoid local optima in the solutions. To achieve MND, we exploit a regularization term to minimize the mean square error between the nonlinear mixing mapping and the best-fitting linear one. The effect of MND on the inherent trivial and non-trivial indeterminacies in nonlinear ICA solutions is investigated. Moreover, we show that local MND is closely related to the smoothness regularizer penalizing large curvature, which provides another useful regularization condition for nonlinear ICA. Experiments on synthetic data show the usefulness of the MND principle for separating various nonlinear mixtures. Finally, as an application, we use nonlinear ICA with MND to separate daily returns of a set of stocks in Hong Kong, and the linear causal relations among them are successfully discovered. The resulting causal relations give some interesting insights into the stock market. Such a result can not be achieved by linear ICA. Simulation studies also verify that when doing causality discovery, sometimes one should not ignore the nonlinear distortion in the data generation procedure, even if it is weak.", "paper_title": "Minimal Nonlinear Distortion Principle for Nonlinear Independent Component Analysis", "paper_id": "WOS:000262637600002"}