{"auto_keywords": [{"score": 0.04874330526858654, "phrase": "la"}, {"score": 0.006461097727803867, "phrase": "assured_e-optimality"}, {"score": 0.00481495049065317, "phrase": "epsilon-optimal_discretized_pursuit_learning_automata"}, {"score": 0.0046018264570209765, "phrase": "powerful_tools"}, {"score": 0.004550029253278477, "phrase": "reinforcement_learning"}, {"score": 0.00447341965028879, "phrase": "discretized_pursuit"}, {"score": 0.00399449659126893, "phrase": "next_action"}, {"score": 0.0038610400240820307, "phrase": "optimal_estimated_action"}, {"score": 0.0037109446302945903, "phrase": "state_probability"}, {"score": 0.003148612096891635, "phrase": "increased_updates"}, {"score": 0.002975099633631871, "phrase": "new_fast_discretized_pursuit"}, {"score": 0.0027325449069867222, "phrase": "computational_complexity"}, {"score": 0.0025239898026543964, "phrase": "faster_convergence_speed"}, {"score": 0.0024814079299143536, "phrase": "classical_one"}, {"score": 0.0024257447861185813, "phrase": "stationary_environments"}, {"score": 0.0022661190184053628, "phrase": "large-scale-action_oriented_area"}, {"score": 0.002141134176057931, "phrase": "fast_convergence_speed"}, {"score": 0.0021049977753042253, "phrase": "low_computational_complexity"}], "paper_keywords": ["Discretized pursuit learning automata (LA)", " low computational complexity", " stationary environments"], "paper_abstract": "Learning automata (LA) are powerful tools for reinforcement learning. A discretized pursuit LA is the most popular one among them. During an iteration its operation consists of three basic phases: 1) selecting the next action; 2) finding the optimal estimated action; and 3) updating the state probability. However, when the number of actions is large, the learning becomes extremely slow because there are too many updates to be made at each iteration. The increased updates are mostly from phases 1 and 3. A new fast discretized pursuit LA with assured e-optimality is proposed to perform both phases 1 and 3 with the computational complexity independent of the number of actions. Apart from its low computational complexity, it achieves faster convergence speed than the classical one when operating in stationary environments. This paper can promote the applications of LA toward the large-scale-action oriented area that requires efficient reinforcement learning tools with assured e-optimality, fast convergence speed, and low computational complexity for each iteration.", "paper_title": "Fast and Epsilon-Optimal Discretized Pursuit Learning Automata", "paper_id": "WOS:000361751900006"}