{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "audio-visual_speech_recognition"}, {"score": 0.004345706062641742, "phrase": "traditional_acoustic_speech_recognition"}, {"score": 0.004116012194714212, "phrase": "considerable_improvement"}, {"score": 0.00406663414150229, "phrase": "acoustic-only_approaches"}, {"score": 0.0038054151244558123, "phrase": "automotive_cabin"}, {"score": 0.003539479990299223, "phrase": "established_audio-visual_speech_recognition_literature"}, {"score": 0.0033929894721242367, "phrase": "speech_recognition_accuracy"}, {"score": 0.0032920678776655783, "phrase": "multiple_frontal"}, {"score": 0.003252542052430779, "phrase": "near-frontal_views"}, {"score": 0.0031941384895530426, "phrase": "speaker's_face"}, {"score": 0.00306189690236109, "phrase": "visual_speech_recognition_experiments"}, {"score": 0.0030069062905274976, "phrase": "four-stream_visual_synchronous_hidden_markov_model"}, {"score": 0.0028650312174624635, "phrase": "four-camera_avicar_automotive_audio-visual_speech_database"}, {"score": 0.002680789041160613, "phrase": "central_orientated_cameras"}, {"score": 0.0026326249204932733, "phrase": "visual_speech_recognition_accuracy"}, {"score": 0.0024932498388507084, "phrase": "single_audio_stream"}, {"score": 0.0024336917123957387, "phrase": "shmm"}, {"score": 0.002389956401870098, "phrase": "relative_improvement"}, {"score": 0.0023328599525181707, "phrase": "word_recognition_accuracy"}, {"score": 0.0022633993976138387, "phrase": "acoustic-only_approach"}, {"score": 0.002222717552124615, "phrase": "noisiest_conditions"}, {"score": 0.0021827653135510225, "phrase": "avicar_database"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["AVASR", " AVICAR database", " Speech recognition", " Multi-stream HMM", " Automotive environment"], "paper_abstract": "Audio-visual speech recognition, or the combination of visual lip-reading with traditional acoustic speech recognition, has been previously shown to provide a considerable improvement over acoustic-only approaches in noisy environments, such as that present in an automotive cabin. The research presented in this paper will extend upon the established audio-visual speech recognition literature to show that further improvements in speech recognition accuracy can be obtained when multiple frontal or near-frontal views of a speaker's face are available. A series of visual speech recognition experiments using a four-stream visual synchronous hidden Markov model (SHMM) are conducted on the four-camera AVICAR automotive audio-visual speech database. We study the relative contribution between the side and central orientated cameras in improving visual speech recognition accuracy. Finally combination of the four visual streams with a single audio stream in a five-stream SHMM demonstrates a relative improvement of over 56% in word recognition accuracy when compared to the acoustic-only approach in the noisiest conditions of the AVICAR database. (c) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Multiple cameras for audio-visual speech recognition in an automotive environment", "paper_id": "WOS:000316524200002"}