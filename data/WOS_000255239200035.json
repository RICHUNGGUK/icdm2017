{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "implicit_acquisition"}, {"score": 0.048778468893892965, "phrase": "context-free_grammar"}, {"score": 0.047510470298773595, "phrase": "simple_recurrent_neural_network"}, {"score": 0.0035559054655873437, "phrase": "elman"}, {"score": 0.0033037970113095577, "phrase": "previous_work"}, {"score": 0.003213920601037463, "phrase": "multilayer_extension"}, {"score": 0.003126481516783286, "phrase": "basic_form"}, {"score": 0.0030695103543472908, "phrase": "simple_recurrent_network"}, {"score": 0.002851790448644913, "phrase": "test_corpora"}, {"score": 0.0027741761880779535, "phrase": "high_performance"}, {"score": 0.0026494723416072316, "phrase": "well-organized_internal_representation"}, {"score": 0.00241658945942583, "phrase": "principal-component_analysis"}, {"score": 0.0023507916951658455, "phrase": "hidden-layer_activities"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["language acquisition", " context-free grammar", " simple recurrent network", " internal representation", " generalization capacity"], "paper_abstract": "The performance of a simple recurrent neural network on the implicit acquisition of a context-free grammar is re-examined and found to be significantly higher than previously reported by Elman. This result is obtained although the previous work employed it multilayer extension of the basic form of simple recurrent network and restricted the complexity of training and test corpora. The high performance is traced to a well-organized internal representation of the grammatical elements, as probed by a principal-component analysis of the hidden-layer activities. From the next-symbol-prediction performance on sentences not present in the training corpus, it capacity of generalization is demonstrated. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "On the implicit acquisition of a context-free grammar by a simple recurrent neural network", "paper_id": "WOS:000255239200035"}