{"auto_keywords": [{"score": 0.02762894797470631, "phrase": "mpit"}, {"score": 0.004815001979271996, "phrase": "concurrent"}, {"score": 0.0047292449487169345, "phrase": "parallel_mpi_applications"}, {"score": 0.004687124773838711, "phrase": "mpi"}, {"score": 0.003987126862293129, "phrase": "user_interfaces"}, {"score": 0.0037104876694493815, "phrase": "multiple_functional_units"}, {"score": 0.003628024127607343, "phrase": "evolving_application_mix"}, {"score": 0.003563370084662192, "phrase": "hardware_architecture"}, {"score": 0.0034220655476652683, "phrase": "traditional_programming_models"}, {"score": 0.0033011569787033297, "phrase": "conventional_threads_apis"}, {"score": 0.0032716049995285606, "phrase": "posix"}, {"score": 0.003198860258228543, "phrase": "messaging_libraries"}, {"score": 0.003071965703296204, "phrase": "significant_programmability_concerns"}, {"score": 0.0028844769395018595, "phrase": "novel_api"}, {"score": 0.0028586409810976367, "phrase": "associated_runtime"}, {"score": 0.002833035775182696, "phrase": "concurrent_programming"}, {"score": 0.0027950561494657633, "phrase": "mpi_threads"}, {"score": 0.0026962411675196213, "phrase": "portable_and_reliable_abstraction"}, {"score": 0.0026720866990543744, "phrase": "low-level_threading_facilities"}, {"score": 0.0024864612830452254, "phrase": "performance_measurements"}, {"score": 0.0022520496048464406, "phrase": "parallel_information_retrieval_system"}, {"score": 0.0021049977753042253, "phrase": "large_parallel_ensembles"}], "paper_keywords": ["Threads", " Parallel programming", " Concurrent programming", " Reliability", " Performance"], "paper_abstract": "Concurrency and parallelism have long been viewed as important, but somewhat distinct concepts. While concurrency is extensively used to amortize latency (for example, in web- and database-servers, user interfaces, etc.), parallelism is traditionally used to enhance performance through execution on multiple functional units. Motivated by an evolving application mix and trends in hardware architecture, there has been a push toward integrating traditional programming models for concurrency and parallelism. Use of conventional threads APIs (POSIX, OpenMP) with messaging libraries (MPI), however, leads to significant programmability concerns, owing primarily to their disparate programming models. In this paper, we describe a novel API and associated runtime for concurrent programming, called MPI Threads (MPIT), which provides a portable and reliable abstraction of low-level threading facilities. We describe various design decisions in MPIT, their underlying motivation, and associated semantics. We provide performance measurements for our prototype implementation to quantify overheads associated with various operations. Finally, we discuss two real-world use cases: an asynchronous message queue and a parallel information retrieval system. We demonstrate that MPIT provides a versatile, low overhead programming model that can be leveraged to program large parallel ensembles.", "paper_title": "Concurrent programming constructs for parallel MPI applications The MPI threads library", "paper_id": "WOS:000314064000005"}