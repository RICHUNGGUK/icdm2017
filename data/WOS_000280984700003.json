{"auto_keywords": [{"score": 0.028930494932271376, "phrase": "large-scale_scenarios"}, {"score": 0.00481495049065317, "phrase": "collaborative_peer-to-peer_wiki_system"}, {"score": 0.004644014990871423, "phrase": "ever_growing_request"}, {"score": 0.004596295252559861, "phrase": "digital_information"}, {"score": 0.004479120557712926, "phrase": "content_distribution_architectures"}, {"score": 0.00443308765153716, "phrase": "high_storage_capacity"}, {"score": 0.0043875257506180865, "phrase": "data_availability"}, {"score": 0.004342430078306461, "phrase": "good_performance"}, {"score": 0.004231699728933577, "phrase": "scalable_distribution"}, {"score": 0.004188198923320451, "phrase": "quasi-static_content"}, {"score": 0.003835972725191194, "phrase": "highly_dynamic_content"}, {"score": 0.0035866734383189396, "phrase": "peer-to-peer_solution"}, {"score": 0.0034951469511975346, "phrase": "dynamic_content"}, {"score": 0.0033883824438527316, "phrase": "distributed_hash_tables"}, {"score": 0.003353537992239254, "phrase": "dht"}, {"score": 0.002629743982693993, "phrase": "damon"}, {"score": 0.002575874349501897, "phrase": "aop"}, {"score": 0.0023225701080913388, "phrase": "third_party_wiki_engines"}, {"score": 0.0022749744354271816, "phrase": "uniwiki"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Collaborative editing", " Peer-to-peer", " Distributed interception", " Optimistic replication"], "paper_abstract": "The ever growing request for digital information raises the need for content distribution architectures providing high storage capacity, data availability and good performance. While many simple solutions for scalable distribution of quasi-static content exist, there are still no approaches that can ensure both scalability and consistency for the case of highly dynamic content, such as the data managed inside wikis. We propose a peer-to-peer solution for distributing and managing dynamic content, that combines two widely studied technologies: Distributed Hash Tables (DHT) and optimistic replication. In our \"universal wiki\" engine architecture (UniWiki), on top of a reliable, inexpensive and consistent DHT-based storage, any number of front-ends can be added, ensuring both read and write scalability, as well as suitability for large-scale scenarios. The implementation is based on Damon, a distributed AOP middleware, thus separating distribution, replication, and consistency responsibilities, and also making our system transparently usable by third party wiki engines. Finally, UniWiki has been proved viable and fairly efficient in large-scale scenarios. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Building a collaborative peer-to-peer wiki system on a structured overlay", "paper_id": "WOS:000280984700003"}