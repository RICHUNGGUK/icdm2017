{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "information_retrieval"}, {"score": 0.00424734451992536, "phrase": "information_retrieval_community"}, {"score": 0.003830312347175889, "phrase": "common_underlying_framework"}, {"score": 0.003531474887552889, "phrase": "theoretical_issues"}, {"score": 0.003353521531649663, "phrase": "novel_look"}, {"score": 0.0032800186243040663, "phrase": "parameter_space"}, {"score": 0.003161065111494053, "phrase": "supervised_training_algorithms"}, {"score": 0.0028928306994090453, "phrase": "mean_average_precision"}, {"score": 0.0027469703311742647, "phrase": "training_models"}, {"score": 0.0026084451971464867, "phrase": "significantly_better_test_set_performance"}, {"score": 0.0023003498123420237, "phrase": "linear_feature-based_models"}, {"score": 0.0022005118194652704, "phrase": "current_state"}, {"score": 0.0021522261505574035, "phrase": "art_retrieval_models"}, {"score": 0.0021049977753042253, "phrase": "correct_choice"}], "paper_keywords": ["retrieval models", " linear models", " features", " direct maximization"], "paper_abstract": "There have been a number of linear, feature-based models proposed by the information retrieval community recently. Although each model is presented differently, they all share a common underlying framework. In this paper, we explore and discuss the theoretical issues of this framework, including a novel look at the parameter space. We then detail supervised training algorithms that directly maximize the evaluation metric under consideration, such as mean average precision. We present results that show training models in this way can lead to significantly better test set performance compared to other training methods that do not directly maximize the metric. Finally, we show that linear feature-based models can consistently and significantly outperform current state of the art retrieval models with the correct choice of features.", "paper_title": "Linear feature-based models for information retrieval", "paper_id": "WOS:000247204400003"}