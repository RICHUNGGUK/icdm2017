{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "aperiodic_tasks"}, {"score": 0.010553055602797136, "phrase": "inter-cloud_environments"}, {"score": 0.010377023451745786, "phrase": "resource_management"}, {"score": 0.008082924930728642, "phrase": "deadline_constraints"}, {"score": 0.004654749973584499, "phrase": "big_data_era"}, {"score": 0.004589575891660242, "phrase": "analytical_processing"}, {"score": 0.0044998554636609955, "phrase": "retrieval_capabilities"}, {"score": 0.0044619403653966645, "phrase": "large_amounts"}, {"score": 0.004387061665897055, "phrase": "distributed_crunching_applications"}, {"score": 0.004337838898735768, "phrase": "useful_information"}, {"score": 0.004277083020756253, "phrase": "difficult_challenges"}, {"score": 0.00407678138571414, "phrase": "optimum_data_crunching_cost"}, {"score": 0.00399704519135802, "phrase": "service_level_agreements"}, {"score": 0.003963349828993976, "phrase": "limited_budget"}, {"score": 0.003929937400027523, "phrase": "today's_data_centers"}, {"score": 0.003907818467897337, "phrase": "data_processing_on_demand_and_data_transfers_requests"}, {"score": 0.003590535800280948, "phrase": "massively_multithreaded_computing_systems"}, {"score": 0.003550218173441985, "phrase": "data-intensive_applications"}, {"score": 0.0035302288468578615, "phrase": "hadoop_and_bats_tasks"}, {"score": 0.003470931285852744, "phrase": "traditional_scheduling_approaches"}, {"score": 0.003336401996895057, "phrase": "main_constraint"}, {"score": 0.003117761489610736, "phrase": "data_transfers"}, {"score": 0.0030740412863259226, "phrase": "classical_scheduling_techniques"}, {"score": 0.0030395056129324575, "phrase": "asynchronous_tasks"}, {"score": 0.002938202365941281, "phrase": "task_creation"}, {"score": 0.002824262516441788, "phrase": "peer-to-peer_relation"}, {"score": 0.002768955745188582, "phrase": "client-server_architecture"}, {"score": 0.0027070693607577, "phrase": "mathematical_model"}, {"score": 0.0026766454067568713, "phrase": "different_simulation_scenarios"}, {"score": 0.0025439032008217725, "phrase": "single_one"}, {"score": 0.0024452162861064524, "phrase": "estimated_resources"}, {"score": 0.0024245711012002083, "phrase": "data_center_capacity"}, {"score": 0.0023703634459582546, "phrase": "heterogeneous_data_center"}, {"score": 0.002337099394527396, "phrase": "higher_number"}, {"score": 0.002141009796880959, "phrase": "data_centers"}, {"score": 0.0021229275892217583, "phrase": "novel_challenges"}, {"score": 0.0021049977753042253, "phrase": "next-generation_big_data_applications"}], "paper_keywords": ["Deadline scheduling", " Aperiodic tasks", " Resource allocation and Cloud environments", " Big data"], "paper_abstract": "In the big data era, the speed of analytical processing is influenced by the storage and retrieval capabilities to handle large amounts of data. While the distributed crunching applications themselves can yield useful information, the analysts face difficult challenges: they need to predict how much data to process and where, such that to get an optimum data crunching cost, while also respect deadlines and service level agreements within a limited budget. In today's data centers, data processing on demand and data transfers requests coming from distributed applications are usually expressed as aperiodic tasks. In this paper, we challenge the problem of tasks scheduling with deadline constraints of aperiodic tasks within inter-Cloud environments. In massively multithreaded computing systems that deal with data-intensive applications, Hadoop and BaTs tasks arrive periodically, which challenges traditional scheduling approaches previously proposed for supercomputing. Here, we consider the deadline as the main constraint, and propose a method to estimate the number of resources needed to schedule a set of aperiodic tasks, considering both execution and data transfers costs. Starting from classical scheduling techniques, and considering asynchronous tasks handling, we analyze the possibility of decoupling task arriving from task creation, scheduling and execution, sets of actions that can be put into a peer-to-peer relation over a network or over a client-server architecture in the Cloud. Based on a mathematical model, and using different simulation scenarios, we prove the following statements: (1) multiple source of independent aperiodic tasks can be considered similar to a single one; (2) with respect to the global deadline, the tasks migration between different regional centers is the appropriate solution when the number of estimated resources exceed a data center capacity; and (3) in a heterogeneous data center, we need a higher number of resources for the same request in order to respect the deadline constraints. We believe such results will benefit researchers and practitioners alike, who are interested in optimizing the resource management in data centers according to novel challenges coming from next-generation big data applications.", "paper_title": "Deadline scheduling for aperiodic tasks in inter-Cloud environments: a new approach to resource management", "paper_id": "WOS:000353786700010"}