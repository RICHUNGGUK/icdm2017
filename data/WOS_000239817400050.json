{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "lossy_compression_algorithm"}, {"score": 0.004746263721902201, "phrase": "large_databases"}, {"score": 0.00467855218490191, "phrase": "motion_capture_data"}, {"score": 0.004546000131069232, "phrase": "short_clips"}, {"score": 0.00441718685609235, "phrase": "bezier_curves"}, {"score": 0.004081385289516914, "phrase": "smoothing_effect"}, {"score": 0.003637822529522622, "phrase": "important_detail"}, {"score": 0.003385336776758738, "phrase": "environmental_contacts"}, {"score": 0.00326572165784246, "phrase": "compression_algorithm"}, {"score": 0.0023451553255837317, "phrase": "second_animation"}, {"score": 0.002245975340642921, "phrase": "smaller_compressed_representation"}, {"score": 0.0021509807762081145, "phrase": "smaller_error"}], "paper_keywords": ["motion capture", " compression", " perception of motion"], "paper_abstract": "We present a lossy compression algorithm for large databases of motion capture data. We approximate short clips of motion using Bezier curves and clustered principal component analysis. This approximation has a smoothing effect on the motion. Contacts with the environment ( such as foot strikes) have important detail that needs to be maintained. We compress these environmental contacts using a separate, JPEG like compression algorithm and ensure these contacts are maintained during decompression. Our method can compress 6 hours 34 minutes of human motion capture from 1080 MB data into 35.5 MB with little visible degradation. Compression and decompression is fast: our research implementation can decompress at about 1.2 milliseconds/ frame, 7 times faster than real-time ( for 120 frames per second animation). Our method also yields smaller compressed representation for the same error or produces smaller error for the same compressed size.", "paper_title": "Compression of motion capture databases", "paper_id": "WOS:000239817400050"}