{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "content-aware_web_visualization_tools"}, {"score": 0.004056769841308405, "phrase": "written_transmission"}, {"score": 0.00363080961099728, "phrase": "web-based_computational_tools"}, {"score": 0.003216804708106142, "phrase": "primarily_non-notated_melodies"}, {"score": 0.0027929100418926725, "phrase": "music_theorist"}, {"score": 0.0026554236621262515, "phrase": "system_design"}, {"score": 0.002524688179363081, "phrase": "manual_annotations"}, {"score": 0.002400373755068185, "phrase": "design_process"}, {"score": 0.0023053339328456234, "phrase": "novel_content-based_visualization"}, {"score": 0.0021049977753042253, "phrase": "problem-seeking_exploration"}], "paper_keywords": ["Multimedia annotation", " Multimedia analysis", " Audio feature extraction", " Semi-automatic annotation", " Machine learning"], "paper_abstract": "Chant and cantillation research is particularly interesting as it explores the transition from oral to written transmission of music. The goal of this work to create web-based computational tools that can assist the study of how diverse recitation traditions, having their origin in primarily non-notated melodies, later became codified. One of the authors is a musicologist and music theorist who has guided the system design and development by providing manual annotations and participating in the design process. We describe novel content-based visualization and analysis algorithms that can be used for problem-seeking exploration of audio recordings of chant and recitations.", "paper_title": "Computer-assisted cantillation and chant research using content-aware web visualization tools", "paper_id": "WOS:000276079400012"}