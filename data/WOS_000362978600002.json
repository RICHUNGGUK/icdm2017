{"auto_keywords": [{"score": 0.04922330296681037, "phrase": "parallel_jobs"}, {"score": 0.00481495049065317, "phrase": "sparse_promoting_method"}, {"score": 0.004780334370089564, "phrase": "linear_programming_approximations"}, {"score": 0.004577777897335174, "phrase": "well-known_problem"}, {"score": 0.004274396662662802, "phrase": "multiprocessor_computer"}, {"score": 0.004213123914295882, "phrase": "makespan_objective"}, {"score": 0.004063741692442559, "phrase": "last_job"}, {"score": 0.003935416218386023, "phrase": "np"}, {"score": 0.003753411452669234, "phrase": "execution_time"}, {"score": 0.0036333693364337953, "phrase": "rigid_and_moldable_jobs"}, {"score": 0.003529880686744397, "phrase": "new_approach"}, {"score": 0.0034918342672996066, "phrase": "scheduling_problem"}, {"score": 0.0034293295415901807, "phrase": "recent_discoveries"}, {"score": 0.003367939885018247, "phrase": "compressed_sensing"}, {"score": 0.0033196177202591843, "phrase": "proposed_approach"}, {"score": 0.003283830127906969, "phrase": "possible_positions"}, {"score": 0.0030548779592763824, "phrase": "best_columns"}, {"score": 0.0030328769643087066, "phrase": "natural_constraints"}, {"score": 0.0029464414592923196, "phrase": "new_scheduling_formulation"}, {"score": 0.002852134080296829, "phrase": "appropriate_relaxations"}, {"score": 0.002811191663575046, "phrase": "optimization_task"}, {"score": 0.0027808699346360656, "phrase": "quickest_possible_way"}, {"score": 0.002486021541116251, "phrase": "successive_linear_programming_approximation_heuristic"}, {"score": 0.0022711207841260767, "phrase": "classic_largest_task_first_list"}, {"score": 0.002230418233881411, "phrase": "small_to_medium_instances"}, {"score": 0.0021746545596056125, "phrase": "larger_numbers"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["job folding", " moldable mob", " scheduling", " makespan", " virtualization", " sparse integer linear programming"], "paper_abstract": "In this paper, we tackle the well-known problem of scheduling a collection of parallel jobs on a set of processors either in a cluster or in a multiprocessor computer. For the makespan objective, that is, the completion time of the last job, this problem has been shown to be NP-hard, and several heuristics have already been proposed to minimize the execution time. In this paper, we consider both rigid and moldable jobs. Our main contribution is the introduction of a new approach to the scheduling problem, based on the recent discoveries in the field of compressed sensing. In the proposed approach, all possible positions and shapes of the jobs are encoded into a matrix, and the scheduling is performed by selecting the best columns under natural constraints. Thus, the solution to the new scheduling formulation is naturally sparse, and we may use appropriate relaxations to achieve the optimization task in the quickest possible way. Among many possible relaxation strategies, we choose to minimize the l(p)-quasi-norm for p is an element of (0, 1). Minimization of the l(p)-quasi-norm is implemented via a successive linear programming approximation heuristic. We propose several new algorithms based on this approach, and we assess their efficiency through simulations. The experiments show that the scheme outperforms the classic Largest Task First list based algorithm for scheduling small to medium instances but needs improvements to compete on larger numbers of jobs. Copyright (C) 2014 John Wiley & Sons, Ltd.", "paper_title": "Using a sparse promoting method in linear programming approximations to schedule parallel jobs", "paper_id": "WOS:000362978600002"}