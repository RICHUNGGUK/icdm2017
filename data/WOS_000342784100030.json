{"auto_keywords": [{"score": 0.04838919478929022, "phrase": "two-stage_neural_network-based_approach"}, {"score": 0.04183563930934435, "phrase": "input_grapheme"}, {"score": 0.03641635546164472, "phrase": "output_phoneme"}, {"score": 0.0359965359551688, "phrase": "second_stage"}, {"score": 0.00481495049065317, "phrase": "phoneme_conflict"}, {"score": 0.004701015188740582, "phrase": "phoneme_conversion"}, {"score": 0.004571478018964363, "phrase": "high_quality_output_speech_synthesis_systems"}, {"score": 0.00405538690701843, "phrase": "conflicting_phonemes"}, {"score": 0.003526186748088922, "phrase": "first_stage"}, {"score": 0.0033745298175222056, "phrase": "phonemic_information"}, {"score": 0.003321008590273796, "phrase": "first-stage_neural_network"}, {"score": 0.0032423089921154503, "phrase": "many-to-many_mapping_model"}, {"score": 0.0031528393611136704, "phrase": "phoneme_sequences"}, {"score": 0.0030292784088033838, "phrase": "obtained_phoneme_sequences"}, {"score": 0.0027741761880779535, "phrase": "american_english_words-based_pronunciation_dictionary"}, {"score": 0.002730150696072947, "phrase": "auto-aligned_cmudict_corpus"}, {"score": 0.002623111480310373, "phrase": "word_accuracy"}, {"score": 0.0025918235228843444, "phrase": "oov_words"}, {"score": 0.0025101968585850474, "phrase": "evaluation_results"}, {"score": 0.0024408799645640345, "phrase": "previous_one-stage_neural_network-based_approach"}, {"score": 0.0023357913211723884, "phrase": "existing_approach"}, {"score": 0.0022895278869126848, "phrase": "higher_phoneme_accuracy"}, {"score": 0.0022712795176156536, "phrase": "lower_word_accuracy"}, {"score": 0.002244178699939059, "phrase": "general_dataset"}], "paper_keywords": ["two-stage neural network", " grapheme-to-phoneme conversion", " many-to-many mapping", " prediction through phonemic information", " phoneme conflict"], "paper_abstract": "To achieve high quality output speech synthesis systems, data-driven grapheme-to-phoneme (G2P) conversion is usually used to generate the phonetic transcription of out-of-vocabulary (OOV) words. To improve the performance of G2P conversion, this paper deals with the problem of conflicting phonemes, where an input grapheme can, in the same context, produce many possible output phonemes at the same time. To this end, we propose a two-stage neural network-based approach that converts the input text to phoneme sequences in the first stage and then predicts each output phoneme in the second stage using the phonemic information obtained. The first-stage neural network is fundamentally implemented as a many-to-many mapping model for automatic conversion of word to phoneme sequences, while the second stage uses a combination of the obtained phoneme sequences to predict the output phoneme corresponding to each input grapheme in a given word. We evaluate the performance of this approach using the American English words-based pronunciation dictionary known as the auto-aligned CMUDict corpus [1]. In terms of phoneme and word accuracy of the OOV words, on comparison with several proposed baseline approaches, the evaluation results show that our proposed approach improves on the previous one-stage neural network-based approach for G2P conversion. The results of comparison with another existing approach indicate that it provides higher phoneme accuracy but lower word accuracy on a general dataset, and slightly higher phoneme and word accuracy on a selection of words consisting of more than one phoneme conflicts.", "paper_title": "Solving the Phoneme Conflict in Grapheme-to-Phoneme Conversion Using a Two-Stage Neural Network-Based Approach", "paper_id": "WOS:000342784100030"}