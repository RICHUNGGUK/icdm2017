{"auto_keywords": [{"score": 0.0495037775396638, "phrase": "bayesian"}, {"score": 0.00481495049065317, "phrase": "bayesian_networks_based_on_maximal_prime_subgraphs."}, {"score": 0.004700145854328397, "phrase": "bn"}, {"score": 0.004406360418456518, "phrase": "probability_distributions"}, {"score": 0.004283739213556286, "phrase": "total_recompilation"}, {"score": 0.003951800212882157, "phrase": "dynamic_models"}, {"score": 0.003417565253539315, "phrase": "iterative_process"}, {"score": 0.0033492947290751996, "phrase": "clear_lack"}, {"score": 0.0032428780373184207, "phrase": "term_incremental_compilation"}, {"score": 0.0030523478413779686, "phrase": "complete_recompilation"}, {"score": 0.002861402531078998, "phrase": "main_point"}, {"score": 0.002759279370360986, "phrase": "jt-based_inference"}, {"score": 0.00266079124891013, "phrase": "triangulation_problem"}, {"score": 0.0025866199378466754, "phrase": "great_improvement"}, {"score": 0.0025349272063867126, "phrase": "bns"}, {"score": 0.0024642355970277497, "phrase": "new_architecture"}, {"score": 0.0024444073418288703, "phrase": "bns_inference"}, {"score": 0.0023666982551221283, "phrase": "jt"}, {"score": 0.0023287359930308864, "phrase": "probability_propagation"}, {"score": 0.0023006844922463664, "phrase": "hugin"}, {"score": 0.0022821699053681573, "phrase": "shenoy"}, {"score": 0.002263814422410294, "phrase": "shafer"}, {"score": 0.0021392979397427984, "phrase": "better_performance"}, {"score": 0.0021049977753042253, "phrase": "experimental_evaluation"}], "paper_keywords": ["Bayesian networks inference", " maximal prime subgraphs", " incremental compilation", " triangulation", " join/junction trees"], "paper_abstract": "When a Bayesian network (BN) is modified, for example adding or deleting a node, or changing the probability distributions, we usually will need a total recompilation of the model, despite feeling that a partial (re)compilation could have been enough. Especially when considering dynamic models, in which variables are added and removed very frequently, these recompilations are quite resource consuming. But even further, for the task of building a model, which is in many occasions an iterative process, there is a clear lack of flexibility. When we use the term Incremental Compilation or IC we refer to the possibility of modifying a network and avoiding a complete recompilation to obtain I he new (and different) join tree (JT) The main point we intend to study in this work is JT-based inference in Bayesian networks. Apart from undertaking the triangulation problem itself, we have achieved a great improvement for the compilation in BNs. We do not develop a new architecture for BNs inference, but taking some already existing framework JT-based for probability propagation such as Hugin or Shenoy and Shafer, we have designed a method that can be successfully applied to get better performance, as the experimental evaluation will show.", "paper_title": "INCREMENTAL COMPILATION OF BAYESIAN NETWORKS BASED ON MAXIMAL PRIME SUBGRAPHS", "paper_id": "WOS:000289175300001"}