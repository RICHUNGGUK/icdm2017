{"auto_keywords": [{"score": 0.034503478591515375, "phrase": "neural_network"}, {"score": 0.00481495049065317, "phrase": "quadratic_programming"}, {"score": 0.004202741104973709, "phrase": "new_recurrent_neural_network"}, {"score": 0.003905864553426306, "phrase": "dual_neural_network"}, {"score": 0.003480993634130542, "phrase": "convergence_property"}, {"score": 0.003373334961160647, "phrase": "computational_complexity"}, {"score": 0.0031678720736808574, "phrase": "simplified_dual_neural_network"}, {"score": 0.0028828348726682965, "phrase": "exact_optimal_solution"}, {"score": 0.0027071661844502992, "phrase": "neural_network_architecture"}, {"score": 0.002362320344521919, "phrase": "inequality_constraints"}], "paper_keywords": ["global stability", " k-winners-take-all (KWTA)", " quadratic programming", " recurrent neural networks"], "paper_abstract": "The design, analysis, and application of a new recurrent neural network for quadratic programming, called simplified dual neural network, are discussed. The analysis mainly concentrates on the convergence property and the computational complexity of the neural network. The simplified dual neural network is shown to be globally convergent to the exact optimal solution. The complexity of the neural network architecture is reduced with the number of neurons equal to the number of inequality constraints. Its application to k-winners-take-all (KWTA) operation is discussed to demonstrate how to solve problems with this neural network.", "paper_title": "A simplified dual neural network for quadratic programming with its KWTA application", "paper_id": "WOS:000241933100013"}