{"auto_keywords": [{"score": 0.031449918411730886, "phrase": "dp"}, {"score": 0.00481495049065317, "phrase": "optimal_budget_allocation"}, {"score": 0.004772137871562584, "phrase": "crowd_labeling"}, {"score": 0.004502943680955863, "phrase": "commercial_crowdsourcing_services"}, {"score": 0.0044430006374681285, "phrase": "crowdsourcing_workers"}, {"score": 0.00419229472352669, "phrase": "task_requester"}, {"score": 0.004009074013302036, "phrase": "data_instances"}, {"score": 0.003973398317120165, "phrase": "different_levels"}, {"score": 0.0038338299812503, "phrase": "different_reliability"}, {"score": 0.0037827603118271757, "phrase": "labeling_task"}, {"score": 0.003505908076430666, "phrase": "overall_labeling_quality"}, {"score": 0.0033376244286643176, "phrase": "budget_allocation_problem"}, {"score": 0.003293142761521425, "phrase": "bayesian_markov_decision_process"}, {"score": 0.0030932495918679285, "phrase": "optimal_allocation_policy"}, {"score": 0.0029978863469038914, "phrase": "dynamic_programming"}, {"score": 0.0026330549554033876, "phrase": "computationally_efficient_approximate_policy"}, {"score": 0.0024842242921857705, "phrase": "crowdsourcing_marketplaces"}, {"score": 0.0024620842899061614, "phrase": "homogeneous_workers"}, {"score": 0.0024075916292945715, "phrase": "heterogeneous_workers"}, {"score": 0.0023333173799963795, "phrase": "contextual_information"}, {"score": 0.0021526564019119466, "phrase": "higher_labeling_quality"}], "paper_keywords": ["crowdsourcing", " budget allocation", " Markov decision process", " dynamic programming", " optimistic knowledge gradient"], "paper_abstract": "It has become increasingly popular to obtain machine learning labels through commercial crowdsourcing services. The crowdsourcing workers or annotators are paid for each label they provide, but the task requester usually has only a limited amount of the budget. Since the data instances have different levels of labeling difficulty and the workers have different reliability for the labeling task, it is desirable to wisely allocate the budget among all the instances and workers such that the overall labeling quality is maximized. In this paper, we formulate the budget allocation problem as a Bayesian Markov decision process (MDP), which simultaneously conducts learning and decision making. The optimal allocation policy can be obtained by using the dynamic programming (DP) recurrence. However, DP quickly becomes computationally intractable when the size of the problem increases. To solve this challenge, we propose a computationally efficient approximate policy which is called optimistic knowledge gradient. Our method applies to both pull crowdsourcing marketplaces with homogeneous workers and push marketplaces with heterogeneous workers. It can also incorporate the contextual information of instances when they are available. The experiments on both simulated and real data show that our policy achieves a higher labeling quality than other existing policies at the same budget level.", "paper_title": "Statistical Decision Making for Optimal Budget Allocation in Crowd Labeling", "paper_id": "WOS:000369885500001"}