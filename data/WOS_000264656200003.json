{"auto_keywords": [{"score": 0.03389774710214817, "phrase": "cell_processor"}, {"score": 0.00481495049065317, "phrase": "matrix_multiplication"}, {"score": 0.0047395356621991935, "phrase": "short-vector_simd_architecture_-_cell_processor"}, {"score": 0.004698271683920265, "phrase": "matrix"}, {"score": 0.004379737380744606, "phrase": "dense_linear_algebra"}, {"score": 0.004089991141220082, "phrase": "linear_systems"}, {"score": 0.0040047396607954325, "phrase": "least_square_problems"}, {"score": 0.003941964605885606, "phrase": "singular_and_eigen-value_computations"}, {"score": 0.003880189340783678, "phrase": "sti"}, {"score": 0.003861583520297204, "phrase": "cell"}, {"score": 0.0036043137580229873, "phrase": "peak_single_precision"}, {"score": 0.0035665344993417603, "phrase": "floating_point_performance"}, {"score": 0.003492155652400838, "phrase": "special_purpose_accelerators"}, {"score": 0.0034555479218891638, "phrase": "graphics_processing_units"}, {"score": 0.0031594291695784286, "phrase": "wide_range"}, {"score": 0.0031262984171100856, "phrase": "numerical_algorithms"}, {"score": 0.003028969851366049, "phrase": "matrix_multiplication_operation"}, {"score": 0.0029501745152877732, "phrase": "crucial_component"}, {"score": 0.0029038817737006405, "phrase": "matrix_multiplication_kernel"}, {"score": 0.0028432828877281388, "phrase": "short_vector_single_instruction_multiple_data_architecture"}, {"score": 0.0026830601040919166, "phrase": "single_precision_matrix_multiplication_kernels"}, {"score": 0.002440071551819324, "phrase": "latter_case"}, {"score": 0.002172701452347454, "phrase": "auxiliary_data_structures"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Instruction level parallelism", " Single Instruction Multiple Data", " Synergistic Processing Element", " Loop optimizations", " Vectorization"], "paper_abstract": "Matrix multiplication is one of the most common numerical operations, especially in the area of dense linear algebra, where it forms the core of many important algorithms, including solvers of linear systems of equations, least square problems, and singular and eigen-value computations. The STI CELL processor exceeds the capabilities of any other processor available today in terms of peak single precision, floating point performance, aside from special purpose accelerators like Graphics Processing Units (GPUs). In order to fully exploit the potential of the CELL processor for a wide range of numerical algorithms, fast implementation of the matrix multiplication operation is essential. The crucial component is the matrix multiplication kernel crafted for the short vector Single Instruction Multiple Data architecture of the Synergistic Processing Element of the CELL processor. In this paper, single precision matrix multiplication kernels are presented implementing the C = C - A x B(T) operation and the C = C - A x B operation for matrices of size 64 x 64 elements. For the latter case, the performance of 25.55 Gflop/s is reported, or 99.80% of the peak, using as little as 5.9 kB of storage for code and auxiliary data structures. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "Optimizing matrix multiplication for a short-vector SIMD architecture - CELL processor", "paper_id": "WOS:000264656200003"}