{"auto_keywords": [{"score": 0.031158790934142398, "phrase": "control_group"}, {"score": 0.0041446453895708, "phrase": "nonrigid_facial_movement"}, {"score": 0.0040190868373730015, "phrase": "multiple_templates"}, {"score": 0.0038674532861321864, "phrase": "large_database"}, {"score": 0.0035536228914319354, "phrase": "nonrigid_deformations"}, {"score": 0.0033543281764294927, "phrase": "hierarchical_geodesic-based_resampling_approach"}, {"score": 0.0032526334220034326, "phrase": "facial_surface_deformations"}, {"score": 0.0031058249097051555, "phrase": "small_group"}, {"score": 0.002875678729214611, "phrase": "deformed_template"}, {"score": 0.0026421139329830755, "phrase": "synthesized_deformations"}, {"score": 0.0025917270871556475, "phrase": "generative_deformable_model"}, {"score": 0.0025619562094446884, "phrase": "test_scan"}, {"score": 0.002532526438148958, "phrase": "proposed_approach"}, {"score": 0.002326767693352058, "phrase": "proposed_deformation_modeling_scheme"}, {"score": 0.0022046030435199796, "phrase": "percentage_points"}], "paper_keywords": ["deformation modeling", " 3D face recognition", " facial expression", " deformable model", " expression transfer", " nonrigid"], "paper_abstract": "Face recognition based on 3D surface matching is promising for overcoming some of the limitations of current 2D image-based face recognition systems. The 3D shape is generally invariant to the pose and lighting changes, but not invariant to the nonrigid facial movement such as expressions. Collecting and storing multiple templates to account for various expressions for each subject in a large database is not practical. We propose a facial surface modeling and matching scheme to match 2.5D facial scans in the presence of both nonrigid deformations and pose changes (multiview) to a stored 3D face model with neutral expression. A hierarchical geodesic-based resampling approach is applied to extract landmarks for modeling facial surface deformations. We are able to synthesize the deformation learned from a small group of subjects (control group) onto a 3D neutral model (not in the control group), resulting in a deformed template. A user-specific (3D) deformable model is built for each subject in the gallery with respect to the control group by combining the templates with synthesized deformations. By fitting this generative deformable model to a test scan, the proposed approach is able to handle expressions and pose changes simultaneously. A fully automatic and prototypic deformable model based 3D face matching system has been developed. Experimental results demonstrate that the proposed deformation modeling scheme increases the 3D face matching accuracy in comparison to matching with 3D neutral models by 7 and 10 percentage points, respectively, on a subset of the FRGC v2.0 3D benchmark and the MSU multiview 3D face database with expression variations.", "paper_title": "Deformation modeling for robust 3D face matching", "paper_id": "WOS:000256679700003"}