{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "point_processes"}, {"score": 0.03472642561979023, "phrase": "proposed_approach"}, {"score": 0.004731492618963217, "phrase": "likelihood-based_encoding_models"}, {"score": 0.004588891098290524, "phrase": "significant_attention"}, {"score": 0.004316396683332752, "phrase": "neural_populations"}, {"score": 0.0041136473765874815, "phrase": "point-process_model"}, {"score": 0.003954837422946628, "phrase": "continuous_time_process"}, {"score": 0.003852371777780562, "phrase": "neural_spike_trains"}, {"score": 0.003752550907120244, "phrase": "refractory_period"}, {"score": 0.0036553070575015344, "phrase": "conditional_intensity_function"}, {"score": 0.003453140302583322, "phrase": "large_class"}, {"score": 0.0032336801561165113, "phrase": "conventional_ones"}, {"score": 0.0031223774204093713, "phrase": "standard_fitting_procedures"}, {"score": 0.0030951536886513567, "phrase": "generalized_linear_models"}, {"score": 0.0030547611342112693, "phrase": "iteratively_reweighted_least_squares"}, {"score": 0.0027741761880779535, "phrase": "underlying_continuous-time_model"}, {"score": 0.0026436755508085223, "phrase": "larger_bin_size"}, {"score": 0.0025750928944698673, "phrase": "conventional_approaches"}, {"score": 0.002530359917257626, "phrase": "smaller_bin_size"}, {"score": 0.002443206010337041, "phrase": "neural_data"}, {"score": 0.0024218895273910943, "phrase": "high_mean_and_instantaneous_firing_rates"}, {"score": 0.0023487324083283205, "phrase": "simulated_and_real_neural_spiking_activity"}, {"score": 0.002297831085501592, "phrase": "substantive_increase"}, {"score": 0.0022678201262721323, "phrase": "required_bin_size"}, {"score": 0.0021328586481696157, "phrase": "point-process_methods"}, {"score": 0.0021049977753042253, "phrase": "increasing_number"}], "paper_keywords": [""], "paper_abstract": "Likelihood-based encoding models founded on point processes have received significant attention in the literature because of their ability to reveal the information encoded by spiking neural populations. We propose an approximation to the likelihood of a point-process model of neurons that holds under assumptions about the continuous time process that are physiologically reasonable for neural spike trains: the presence of a refractory period, the predictability of the conditional intensity function, and its integrability. These are properties that apply to a large class of point processes arising in applications other than neuroscience. The proposed approach has several advantages over conventional ones. In particular, one can use standard fitting procedures for generalized linear models based on iteratively reweighted least squares while improving the accuracy of the approximation to the likelihood and reducing bias in the estimation of the parameters of the underlying continuous-time model. As a result, the proposed approach can use a larger bin size to achieve the same accuracy as conventional approaches would with a smaller bin size. This is particularly important when analyzing neural data with high mean and instantaneous firing rates. We demonstrate these claims on simulated and real neural spiking activity. By allowing a substantive increase in the required bin size, our algorithm has the potential to lower the barrier to the use of point-process methods in an increasing number of applications.", "paper_title": "Likelihood Methods for Point Processes with Refractoriness", "paper_id": "WOS:000329290300001"}