{"auto_keywords": [{"score": 0.05007126221988649, "phrase": "source_code_level_portability"}, {"score": 0.04936215406482973, "phrase": "gpu"}, {"score": 0.032245609534519944, "phrase": "mapcg"}, {"score": 0.004707188147442449, "phrase": "mapcg._graphics_processing_units"}, {"score": 0.004584495834677719, "phrase": "important_role"}, {"score": 0.004532892812505505, "phrase": "general_purpose_computing_market"}, {"score": 0.004398094237005956, "phrase": "common_approach"}, {"score": 0.004348580182733617, "phrase": "gpu_units"}, {"score": 0.004283423748543866, "phrase": "gpu_specific_code"}, {"score": 0.004251210982670317, "phrase": "low_level_gpu_apis"}, {"score": 0.0042033648065750995, "phrase": "cuda."}, {"score": 0.004109212945115815, "phrase": "good_performance"}, {"score": 0.004047628461126961, "phrase": "serious_portability_issues"}, {"score": 0.003927203683176278, "phrase": "specific_version"}, {"score": 0.0038392331564122387, "phrase": "potential_target_architecture"}, {"score": 0.0037674258625824113, "phrase": "high_development_and_maintenance_costs"}, {"score": 0.003627800727103479, "phrase": "programming_model"}, {"score": 0.0035869274480340727, "phrase": "source_code_portability"}, {"score": 0.003467040410632942, "phrase": "different_gpus"}, {"score": 0.0028378330964389797, "phrase": "opencl"}, {"score": 0.002722234804904997, "phrase": "high_level_programming_model"}, {"score": 0.002562451837774567, "phrase": "mapreduce-style_high-level_programming_framework"}, {"score": 0.002476763466856586, "phrase": "gpu."}, {"score": 0.00243033541656411, "phrase": "mapcg_runtime"}, {"score": 0.002402921062033032, "phrase": "multi-core_cpus"}, {"score": 0.0023848164282879885, "phrase": "nvidia_gpus"}, {"score": 0.0022447938263410005, "phrase": "multi-core_cpu_platforms"}, {"score": 0.0021944267528581094, "phrase": "average_speedup"}, {"score": 0.002137088643982437, "phrase": "previous_implementations"}, {"score": 0.002121033180055826, "phrase": "mapreduce"}, {"score": 0.0021049977753042253, "phrase": "eight_commonly_used_applications"}], "paper_keywords": ["portability", " parallel", " GPU programming"], "paper_abstract": "Graphics processing units (GPU) have taken an important role in the general purpose computing market in recent years. At present, the common approach to programming GPU units is to write GPU specific code with low level GPU APIs such as CUDA. Although this approach can achieve good performance, it creates serious portability issues as programmers are required to write a specific version of the code for each potential target architecture. This results in high development and maintenance costs. We believe it is desirable to have a programming model which provides source code portability between CPUs and GPUs, as well as different GPUs. This would allow programmers to write one version of the code, which can be compiled and executed on either CPUs or GPUs efficiently without modification. In this paper, we propose MapCG, a MapReduce framework to provide source code level portability between CPUs and GPUs. In contrast to other approaches such as OpenCL, our framework, based on MapReduce, provides a high level programming model and makes programming much easier. We describe the design of MapCG, including the MapReduce-style high-level programming framework and the runtime system on the CPU and GPU. A prototype of the MapCG runtime, supporting multi-core CPUs and NVIDIA GPUs, was implemented. Our experimental results show that this implementation can execute the same source code efficiently on multi-core CPU platforms and GPUs, achieving an average speedup of 1.6 similar to 2.5x over previous implementations of MapReduce on eight commonly used applications.", "paper_title": "Providing Source Code Level Portability Between CPU and GPU with MapCG", "paper_id": "WOS:000299938700004"}