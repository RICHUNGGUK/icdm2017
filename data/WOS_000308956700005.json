{"auto_keywords": [{"score": 0.03543656397555333, "phrase": "unn"}, {"score": 0.015719711310935386, "phrase": "natural_scenes"}, {"score": 0.004779031979178425, "phrase": "k-nearest_neighbors"}, {"score": 0.004626441515623478, "phrase": "countless_many_computer_vision_applications"}, {"score": 0.004569052789469628, "phrase": "image_categorization"}, {"score": 0.00452365245546062, "phrase": "uniform_voting"}, {"score": 0.0044898971618201255, "phrase": "nearest_prototypes"}, {"score": 0.004335658280718254, "phrase": "multi-class_problems"}, {"score": 0.004303299727138449, "phrase": "classic_k-nn_rule"}, {"score": 0.004218181063178522, "phrase": "sparse_prototype_datasets"}, {"score": 0.0041971646630146135, "phrase": "high_dimensions"}, {"score": 0.0040834246216588915, "phrase": "k-nn_classification"}, {"score": 0.00400263757329054, "phrase": "nearest_neighborhood_relationship"}, {"score": 0.003962843010801056, "phrase": "distance_function"}, {"score": 0.003923442530716965, "phrase": "input_space"}, {"score": 0.0038844322613100692, "phrase": "subspace_selection"}, {"score": 0.003845808368280361, "phrase": "computational_standpoint"}, {"score": 0.003760297688599612, "phrase": "nearest_neighbor_retrieval"}, {"score": 0.0037229034839372675, "phrase": "multidimensional_vector_spaces"}, {"score": 0.0037043455439373326, "phrase": "nonvector_spaces"}, {"score": 0.003676681302049705, "phrase": "computationally_expensive_distance_measures"}, {"score": 0.0035414174699534133, "phrase": "k-nn_rule"}, {"score": 0.0034974406406627183, "phrase": "new_k-nn_boosting_algorithm"}, {"score": 0.003454008016586962, "phrase": "universal_nearest_neighbors"}, {"score": 0.0033941038896838976, "phrase": "leveraged_k-nn."}, {"score": 0.003335235224891481, "phrase": "formal_boosting_algorithm"}, {"score": 0.003310318358799954, "phrase": "original_boosting_terminology"}, {"score": 0.003252898159771322, "phrase": "voting_rule"}, {"score": 0.003228594424567862, "phrase": "strong_classifier"}, {"score": 0.0031725872822056054, "phrase": "k_closest_prototypes"}, {"score": 0.003125352664571698, "phrase": "nearest_neighbors_examples"}, {"score": 0.00310199890835121, "phrase": "weak_classifiers"}, {"score": 0.0029729094416802333, "phrase": "surrogate_risk"}, {"score": 0.0029286389651826793, "phrase": "empirical_misclassification_rate"}, {"score": 0.0029140286967542913, "phrase": "training_data"}, {"score": 0.0028922494475899837, "phrase": "leveraging_coefficients"}, {"score": 0.0027649406355736757, "phrase": "k-nearest_neighborhood_relationship"}, {"score": 0.002710167675474143, "phrase": "k-nn_search"}, {"score": 0.0026366174524476557, "phrase": "support_vector_machines"}, {"score": 0.0026235423630175912, "phrase": "svm"}, {"score": 0.0025586496148808984, "phrase": "state-of-the_art_image_descriptors"}, {"score": 0.002545886673710943, "phrase": "gist"}, {"score": 0.0025331751672964045, "phrase": "bag-of-features"}, {"score": 0.00251423483919321, "phrase": "real_images"}, {"score": 0.0024892011202241886, "phrase": "j._comput"}, {"score": 0.002421633244508846, "phrase": "fei-fei"}, {"score": 0.002409546550775138, "phrase": "perona"}, {"score": 0.0023975191459662615, "phrase": "ieee_computer_society_conference_on_computer_vision_and_pattern_recognition"}, {"score": 0.0023092061745871124, "phrase": "xiao_et_al"}, {"score": 0.002274796550579261, "phrase": "computer_vision"}, {"score": 0.0021049977753042253, "phrase": "comparatively_small_training_and_testing_times"}], "paper_keywords": ["Boosting", " k nearest neighbors", " Image categorization", " Scene classification"], "paper_abstract": "The k-nearest neighbors (k-NN) classification rule has proven extremely successful in countless many computer vision applications. For example, image categorization often relies on uniform voting among the nearest prototypes in the space of descriptors. In spite of its good generalization properties and its natural extension to multi-class problems, the classic k-NN rule suffers from high variance when dealing with sparse prototype datasets in high dimensions. A few techniques have been proposed in order to improve k-NN classification, which rely on either deforming the nearest neighborhood relationship by learning a distance function or modifying the input space by means of subspace selection. From the computational standpoint, many methods have been proposed for speeding up nearest neighbor retrieval, both for multidimensional vector spaces and nonvector spaces induced by computationally expensive distance measures. In this paper, we propose a novel boosting approach for generalizing the k-NN rule, by providing a new k-NN boosting algorithm, called UNN (Universal Nearest Neighbors), for the induction of leveraged k-NN. We emphasize that UNN is a formal boosting algorithm in the original boosting terminology. Our approach consists in redefining the voting rule as a strong classifier that linearly combines predictions from the k closest prototypes. Therefore, the k nearest neighbors examples act as weak classifiers and their weights, called leveraging coefficients, are learned by UNN so as to minimize a surrogate risk, which upper bounds the empirical misclassification rate over training data. These leveraging coefficients allows us to distinguish the most relevant prototypes for a given class. Indeed, UNN does not affect the k-nearest neighborhood relationship, but rather acts on top of k-NN search. We carried out experiments comparing UNN to k-NN, support vector machines (SVM) and AdaBoost on categorization of natural scenes, using state-of-the art image descriptors (Gist and Bag-of-Features) on real images from Oliva and Torralba (Int. J. Comput. Vis. 42(3):145-175, 2001), Fei-Fei and Perona (IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pp. 524-531, 2005), and Xiao et al. (IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3485-3492, 2010). Results display the ability of UNN to compete with or beat the other contenders, while achieving comparatively small training and testing times.", "paper_title": "Boosting k-NN for Categorization of Natural Scenes", "paper_id": "WOS:000308956700005"}