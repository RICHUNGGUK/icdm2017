{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "string_kernels"}, {"score": 0.004300133642951283, "phrase": "high_dimensional_feature_space"}, {"score": 0.0041170581247889654, "phrase": "language-theoretic_properties"}, {"score": 0.003941746077126688, "phrase": "particular_reference"}, {"score": 0.0038401488612789963, "phrase": "implicit_feature_maps"}, {"score": 0.003613119346373748, "phrase": "expressive_power"}, {"score": 0.003115908199991072, "phrase": "new_family"}, {"score": 0.003062091606343783, "phrase": "grammatical_inference_algorithms"}, {"score": 0.0028065957753430713, "phrase": "mildly_context-sensitive_languages"}, {"score": 0.0024201029474586007, "phrase": "kernel_pca."}, {"score": 0.0021987994275190314, "phrase": "standard_examples"}, {"score": 0.0021420294823879292, "phrase": "-sensitive_languages"}, {"score": 0.0021049977753042253, "phrase": "small_synthetic_data_sets"}], "paper_keywords": ["Kernel methods", " Grammatical inference"], "paper_abstract": "Using string kernels, languages can be represented as hyperplanes in a high dimensional feature space. We discuss the language-theoretic properties of this formalism with particular reference to the implicit feature maps defined by string kernels, considering the expressive power of the formalism, its closure properties and its relationship to other formalisms. We present a new family of grammatical inference algorithms based on this idea. We demonstrate that some mildly context-sensitive languages can be represented in this way and that it is possible to efficiently learn these using kernel PCA. We experimentally demonstrate the effectiveness of this approach on some standard examples of context-sensitive languages using small synthetic data sets.", "paper_title": "Languages as hyperplanes: grammatical inference with string kernels", "paper_id": "WOS:000288022900005"}