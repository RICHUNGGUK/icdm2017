{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "facial_expression"}, {"score": 0.004641890423057823, "phrase": "emotion_recognition"}, {"score": 0.004314127287770832, "phrase": "gesture_image_sequences"}, {"score": 0.004202741104973709, "phrase": "video-based_bimodal_emotion_recognition_problem"}, {"score": 0.004094324847571053, "phrase": "harris"}, {"score": 0.004051595625804513, "phrase": "cuboids_spatio-temporal_feature"}, {"score": 0.004010672571430509, "phrase": "hst"}, {"score": 0.003946960862020283, "phrase": "sparse_canonical_correlation_analysis"}, {"score": 0.0039058668760097266, "phrase": "scca"}, {"score": 0.00386519448487341, "phrase": "fusion_method"}, {"score": 0.003629882559085245, "phrase": "spatio-temporal_features"}, {"score": 0.003480997258063477, "phrase": "laptev"}, {"score": 0.0034447343117276715, "phrase": "lindeberg"}, {"score": 0.0032861588691414667, "phrase": "gesture_videos"}, {"score": 0.0031845067058084583, "phrase": "cuboids_feature_descriptor"}, {"score": 0.0028527866590859967, "phrase": "common_emotion_features"}, {"score": 0.002808298910480358, "phrase": "facial_expression_feature"}, {"score": 0.002693018258362651, "phrase": "scca_method"}, {"score": 0.0026233771102489416, "phrase": "extracted_emotion_features"}, {"score": 0.0025555322596460036, "phrase": "biomodal_emotion_classification"}, {"score": 0.0025025186963415, "phrase": "k-nearest_neighbor_classifier"}, {"score": 0.0024636340817769456, "phrase": "svm"}, {"score": 0.0022772115643656153, "phrase": "biomodal_face"}, {"score": 0.002253461585851626, "phrase": "body_gesture"}, {"score": 0.002229959084103971, "phrase": "fabo"}, {"score": 0.002172266188075892, "phrase": "experimental_results"}, {"score": 0.0021383680500215267, "phrase": "better_recognition_accuracy"}], "paper_keywords": ["bimodal emotion recognition", " Harris plus cuboids spatio-temporal feature (HST)", " sparse canonical correlation analysis (SCCA)"], "paper_abstract": "In this letter, we research the method of using face and gesture image sequences to deal with the video-based bimodal emotion recognition problem, in which both Harris plus cuboids spatio-temporal feature (HST) and sparse canonical correlation analysis (SCCA) fusion method are applied to this end. To efficaciously pick up the spatio-temporal features, we adopt the Harris 3D feature detector proposed by Laptev and Lindeberg to find the points from both face and gesture videos, and then apply the cuboids feature descriptor to extract the facial expression and gesture emotion features [1], [2]. To further extract the common emotion features from both facial expression feature set and gesture feature set, the SCCA method is applied and the extracted emotion features are used for the biomodal emotion classification, where the K-nearest neighbor classifier and the SVM classifier are respectively used for this purpose. We test this method on the biomodal face and body gesture (FABO) database and the experimental results demonstrate the better recognition accuracy compared with other methods.", "paper_title": "Integrating Facial Expression and Body Gesture in Videos for Emotion Recognition", "paper_id": "WOS:000332590900028"}