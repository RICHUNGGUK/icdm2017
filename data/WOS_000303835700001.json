{"auto_keywords": [{"score": 0.03266002220799323, "phrase": "model_space"}, {"score": 0.00481495049065317, "phrase": "model_equivalences"}, {"score": 0.004763565662615503, "phrase": "interactive_dynamic_influence_diagrams"}, {"score": 0.00462919213721188, "phrase": "sequential_decision"}, {"score": 0.004579780586951551, "phrase": "partially_observable_environments"}, {"score": 0.00449859196755507, "phrase": "uncertain_types"}, {"score": 0.004466519142879166, "phrase": "similar_or_conflicting_objectives"}, {"score": 0.004324985524216987, "phrase": "multiple_frameworks"}, {"score": 0.004233119608341877, "phrase": "interactive_dynamic_influence_diagram"}, {"score": 0.004084307764140389, "phrase": "well-known_influence_diagram"}, {"score": 0.003969018740062018, "phrase": "graphical_models"}, {"score": 0.0037480753312398754, "phrase": "physical_state"}, {"score": 0.0037213333316218522, "phrase": "others'_models"}, {"score": 0.0035648266669315943, "phrase": "multiagent_setting"}, {"score": 0.0033303306367699816, "phrase": "large_space"}, {"score": 0.003306559295382181, "phrase": "candidate_models"}, {"score": 0.0030017207229983385, "phrase": "individual_models"}, {"score": 0.0029802879302375986, "phrase": "equivalence_classes"}, {"score": 0.0028142286985235977, "phrase": "predictive_behaviors"}, {"score": 0.002734692147497601, "phrase": "updated_model_space"}, {"score": 0.0027054473441439422, "phrase": "second_method"}, {"score": 0.0026008598632891837, "phrase": "behavioral_predictions"}, {"score": 0.0025364139244227436, "phrase": "equivalent_models"}, {"score": 0.002509284173541882, "phrase": "identical_actions"}, {"score": 0.002482443883144136, "phrase": "single_time_step"}, {"score": 0.00235247790591897, "phrase": "initial_set"}, {"score": 0.0021049977753042253, "phrase": "improved_efficiency"}], "paper_keywords": [""], "paper_abstract": "We focus on the problem of sequential decision making in partially observable environments shared with other agents of uncertain types having similar or conflicting objectives. This problem has been previously formalized by multiple frameworks one of which is the interactive dynamic influence diagram (I-DID), which generalizes the well-known influence diagram to the multiagent setting. I-DIDs are graphical models and may be used to compute the policy of an agent given its belief over the physical state and others' models, which changes as the agent acts and observes in the multiagent setting. As we may expect, solving I-DIDs is computationally hard. This is predominantly due to the large space of candidate models ascribed to the other agents and its exponential growth over time. We present two methods for reducing the size of the model space and stemming its exponential growth. Both these methods involve aggregating individual models into equivalence classes. Our first method groups together behaviorally equivalent models and selects only those models for updating which will result in predictive behaviors that are distinct from others in the updated model space. The second method further compacts the model space by focusing on portions of the behavioral predictions. Specifically, we cluster actionally equivalent models that prescribe identical actions at a single time step. Exactly identifying the equivalences would require us to solve all models in the initial set. We avoid this by selectively solving some of the models, thereby introducing an approximation. We discuss the error introduced by the approximation, and empirically demonstrate the improved efficiency in solving I-DIDs due to the equivalences.", "paper_title": "Exploiting Model Equivalences for Solving Interactive Dynamic Influence Diagrams", "paper_id": "WOS:000303835700001"}