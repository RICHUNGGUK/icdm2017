{"auto_keywords": [{"score": 0.04930986456658361, "phrase": "neural_gas"}, {"score": 0.003567455727660992, "phrase": "batch_version"}, {"score": 0.0035100601949451028, "phrase": "supervised_neural_gas_training"}, {"score": 0.0033163269450817716, "phrase": "prototype-based_classification"}, {"score": 0.0032629585038738856, "phrase": "provided_training_data"}, {"score": 0.0030086877092638945, "phrase": "simpler_cost_function"}, {"score": 0.0029602552900111407, "phrase": "online_supervised_neural_gas"}, {"score": 0.002865710140187219, "phrase": "simpler_update_formulas"}, {"score": 0.0026423134393535265, "phrase": "general_framework"}, {"score": 0.0023016843709107297, "phrase": "metric_adaptation"}, {"score": 0.0021922308351126746, "phrase": "proximity_data"}, {"score": 0.0021049977753042253, "phrase": "real-vector_space"}], "paper_keywords": [""], "paper_abstract": "Recently, two extensions of neural gas have been proposed: a fast batch version of neural gas for data given in advance, and extensions of neural gas to learn a (possibly fuzzy) supervised classification. Here we propose a batch version for supervised neural gas training which allows to efficiently learn a prototype-based classification, provided training data are given beforehand. The method relies on a simpler cost function than online supervised neural gas and leads to simpler update formulas. We prove convergence of the algorithm in a general framework, which also incorporates supervised k-means and supervised batch-SOM, and which opens the way towards metric adaptation as well as application to proximity data not embedded in a real-vector space.", "paper_title": "Supervised batch neural gas", "paper_id": "WOS:000241011900004"}