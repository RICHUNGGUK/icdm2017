{"auto_keywords": [{"score": 0.03966820445713652, "phrase": "sensory_input_signals"}, {"score": 0.03508855842078276, "phrase": "discount_rate"}, {"score": 0.02819806867961193, "phrase": "substantial_accuracy"}, {"score": 0.00481495049065317, "phrase": "reinforcement_learning_robot"}, {"score": 0.004195418010131832, "phrase": "basic_kind"}, {"score": 0.0041051328120736575, "phrase": "one's_environment"}, {"score": 0.0038737214010638745, "phrase": "real_time"}, {"score": 0.003589602322126282, "phrase": "value_functions"}, {"score": 0.003537886893587656, "phrase": "reinforcement_learning"}, {"score": 0.0034742854447532678, "phrase": "arbitrary_function"}, {"score": 0.0033748847621075536, "phrase": "pseudo_reward"}, {"score": 0.0032310733124059536, "phrase": "six_thousand_predictions"}, {"score": 0.0031386091093713706, "phrase": "six_thousand_features"}, {"score": 0.00295078850927459, "phrase": "laptop_computer"}, {"score": 0.0027441220799352926, "phrase": "real-time_learning"}, {"score": 0.00269475174341129, "phrase": "sufficiently_data"}, {"score": 0.0025892330566358503, "phrase": "single_tile-coded_feature_representation"}, {"score": 0.002515090164966655, "phrase": "significant_range"}, {"score": 0.0024342079318127423, "phrase": "simple_timescales"}, {"score": 0.0022148335975074904, "phrase": "general_nexting"}, {"score": 0.002190825828942124, "phrase": "simple_yet_powerful_mechanism"}, {"score": 0.0021435864990577945, "phrase": "predictive_knowledge"}], "paper_keywords": ["Reinforcement learning", " robotics", " predictive knowledge", " temporal difference learning"], "paper_abstract": "The term nexting' has been used by psychologists to refer to the propensity of people and many other animals to continually predict what will happen next in an immediate, local, and personal sense. The ability to next' constitutes a basic kind of awareness and knowledge of one's environment. In this paper we present results with a robot that learns to next in real time, making thousands of predictions about sensory input signals at timescales from 0.1 to 8 seconds. Our predictions are formulated as a generalization of the value functions commonly used in reinforcement learning, where now an arbitrary function of the sensory input signals is used as a pseudo reward, and the discount rate determines the timescale. We show that six thousand predictions, each computed as a function of six thousand features of the state, can be learned and updated online ten times per second on a laptop computer, using the standard temporal-difference() algorithm with linear function approximation. This approach is sufficiently computationally efficient to be used for real-time learning on the robot and sufficiently data efficient to achieve substantial accuracy within 30 minutes. Moreover, a single tile-coded feature representation suffices to accurately predict many different signals over a significant range of timescales. We also extend nexting beyond simple timescales by letting the discount rate be a function of the state and show that nexting predictions of this more general form can also be learned with substantial accuracy. General nexting provides a simple yet powerful mechanism for a robot to acquire predictive knowledge of the dynamics of its environment.", "paper_title": "Multi-timescale nexting in a reinforcement learning robot", "paper_id": "WOS:000332967200004"}