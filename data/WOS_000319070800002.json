{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "data_streams"}, {"score": 0.03500203777889007, "phrase": "positive_examples"}, {"score": 0.004691136491297242, "phrase": "streaming_data_classification"}, {"score": 0.004519736937243476, "phrase": "fully_labeled_stream"}, {"score": 0.004133390261297075, "phrase": "data_stream"}, {"score": 0.004012061349250865, "phrase": "conventional_supervised_learning_approaches"}, {"score": 0.0038798015183611275, "phrase": "credit_fraud_detection"}, {"score": 0.0038510053729959074, "phrase": "intrusion_detection"}, {"score": 0.003808209866576388, "phrase": "rare_event_prediction"}, {"score": 0.0037658881407605445, "phrase": "previous_work"}, {"score": 0.0036281710561308377, "phrase": "positive_and_unlabeled_learning_problem"}, {"score": 0.003561205990687285, "phrase": "learning_algorithm"}, {"score": 0.00353476609156032, "phrase": "ocvfd"}, {"score": 0.003256526411907174, "phrase": "unlabeled_examples"}, {"score": 0.0031726587374218277, "phrase": "streaming_environment"}, {"score": 0.0030909442697163356, "phrase": "real-life_applications"}, {"score": 0.0030225753906647935, "phrase": "li_et_al"}, {"score": 0.002815864555488112, "phrase": "training_stream"}, {"score": 0.0027535633837592597, "phrase": "numeric_attributes"}, {"score": 0.0026428931714865115, "phrase": "experimental_results"}, {"score": 0.0026232532659260033, "phrase": "synthetic_and_real-life_datasets"}, {"score": 0.0024897902536499005, "phrase": "strong_ability"}, {"score": 0.0023719332915829268, "phrase": "learning_time"}, {"score": 0.002354302193867031, "phrase": "ocvfdt"}, {"score": 0.002217880187104576, "phrase": "training_data"}, {"score": 0.0021850254717637172, "phrase": "puvfdt"}, {"score": 0.0021446391766277817, "phrase": "competitive_classification_performance"}, {"score": 0.0021049977753042253, "phrase": "vfdtcnb"}], "paper_keywords": ["Positive and unlabeled learning", " Data stream classification", " Incremental learning", " Functional leaves"], "paper_abstract": "Many studies on streaming data classification have been based on a paradigm in which a fully labeled stream is available for learning purposes. However, it is often too labor-intensive and time-consuming to manually label a data stream for training. This difficulty may cause conventional supervised learning approaches to be infeasible in many real world applications, such as credit fraud detection, intrusion detection, and rare event prediction. In previous work, Li et al. suggested that these applications be treated as Positive and Unlabeled learning problem, and proposed a learning algorithm, OcVFD, as a solution (Li et al. 2009). Their method requires only a set of positive examples and a set of unlabeled examples which is easily obtainable in a streaming environment, making it widely applicable to real-life applications. Here, we enhance Li et al.'s solution by adding three features: an efficient method to estimate the percentage of positive examples in the training stream, the ability to handle numeric attributes, and the use of more appropriate classification methods at tree leaves. Experimental results on synthetic and real-life datasets show that our enhanced solution (called PUVFDT) has very good classification performance and a strong ability to learn from data streams with only positive and unlabeled examples. Furthermore, our enhanced solution reduces the learning time of OcVFDT by about an order of magnitude. Even with 80 % of the examples in the training data stream unlabeled, PUVFDT can still achieve a competitive classification performance compared with that of VFDTcNB (Gama et al. 2003), a supervised learning algorithm.", "paper_title": "Learning from data streams with only positive and unlabeled data", "paper_id": "WOS:000319070800002"}