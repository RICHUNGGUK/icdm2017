{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "useful_static_instruction-level_parallelism"}, {"score": 0.0045726187330434025, "phrase": "unanticipable_latencies"}, {"score": 0.004466519142879166, "phrase": "load_instructions"}, {"score": 0.004383406949799696, "phrase": "vexing_problem"}, {"score": 0.004047020753789236, "phrase": "scheduling_work"}, {"score": 0.003897742942358768, "phrase": "additional_pipeline_overhead"}, {"score": 0.0031995142224983094, "phrase": "microarchitectural_technique"}, {"score": 0.0029260602766930065, "phrase": "\"advance\"_pipeline"}, {"score": 0.0028446460307503343, "phrase": "unready_operands"}, {"score": 0.002765490759189057, "phrase": "\"backup\"_pipeline"}, {"score": 0.002650857539177183, "phrase": "first_pipeline"}, {"score": 0.0026014425686078993, "phrase": "useful_\"advanced\"_execution"}, {"score": 0.0025290375256888883, "phrase": "accompanying_compiler_technique"}, {"score": 0.0024241817763927163, "phrase": "miss_latencies"}, {"score": 0.0021049977753042253, "phrase": "idealized_out-of-order_design's_speedup"}], "paper_keywords": ["runahead execution", " out-of-order execution", " prefetching", " cache-miss tolerance"], "paper_abstract": "While compilers have generally proven adept at planning useful static instruction-level parallelism for in-order microarchitectures, the efficient accommodation of unanticipable latencies, like those of load instructions, remains a vexing problem. Traditional out-of-order execution hides some of these latencies, but repeats scheduling work already done by the compiler and adds additional pipeline overhead. Other techniques, such as prefetching and multithreading, can hide some anticipable, long-latency misses, but not the shorter, more diffuse stalls due to difficult-to-anticipate, first or second-level misses. Our work proposes a microarchitectural technique, two-pass pipelining, whereby the program executes on two in-order back-end pipelines coupled by a queue. The \"advance\" pipeline often defers instructions dispatching with unready operands rather than stalling. The \"backup\" pipeline allows concurrent resolution of instructions deferred by the first pipeline allowing overlapping of useful \"advanced\" execution with miss resolution. An accompanying compiler technique and instruction marking further enhance the handling of miss latencies. Applying our technique to an Itanium 2-like design achieves a speedup of 1.38 x in mcf, the most memory-intensive SPECint2000 benchmark, and an average of 1.12x across other selected benchmarks, yielding between 32 percent and 67 percent of an idealized out-of-order design's speedup at a much lower design cost and complexity.", "paper_title": "Beating in-order stalls with \"flea-flicker\" two-pass pipelining", "paper_id": "WOS:000233304800003"}