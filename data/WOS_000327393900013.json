{"auto_keywords": [{"score": 0.04355159126538614, "phrase": "sub-emotional_states"}, {"score": 0.04227539537967157, "phrase": "temporal_phases"}, {"score": 0.02862805203651978, "phrase": "experimental_results"}, {"score": 0.00481495049065317, "phrase": "semi-coupled_hmm-based_audiovisual_emotion_recognition"}, {"score": 0.004688989566904871, "phrase": "complete_emotional_expression"}, {"score": 0.004606843145343611, "phrase": "complex_temporal_course"}, {"score": 0.004566308708871429, "phrase": "face-to-face_natural_conversation"}, {"score": 0.00436890075128947, "phrase": "markov_model"}, {"score": 0.0037925389501636975, "phrase": "temporal_course"}, {"score": 0.003742554019950264, "phrase": "emotional_expression"}, {"score": 0.003709595902020469, "phrase": "audio_and_visual_signal_streams"}, {"score": 0.003660700128133065, "phrase": "two-level_hierarchical_alignment_mechanism"}, {"score": 0.00344087639309216, "phrase": "audio_and_visual_hmm_sequences"}, {"score": 0.0033955105098235345, "phrase": "model_and_state_levels"}, {"score": 0.003350740737336966, "phrase": "proposed_semi-coupled_hidden_markov_model"}, {"score": 0.0031774686451753477, "phrase": "sub-emotion_language_model"}, {"score": 0.0031079352545607267, "phrase": "temporal_transition"}, {"score": 0.0027700855441353165, "phrase": "allowable_temporal_structures"}, {"score": 0.002721464488351771, "phrase": "optimal_emotional_state"}, {"score": 0.0026501241093379786, "phrase": "proposed_approach"}, {"score": 0.002615156460073562, "phrase": "satisfactory_results"}, {"score": 0.0025578967205807843, "phrase": "naturalistic_semaine_databases"}, {"score": 0.0024798279465139688, "phrase": "complex_temporal_structure"}, {"score": 0.0024148064819862337, "phrase": "emotion_recognition_performance"}, {"score": 0.002361923085067681, "phrase": "naturalistic_database"}, {"score": 0.0021712920081029194, "phrase": "acceptable_performance"}, {"score": 0.002123730137917387, "phrase": "sparse_training_data"}, {"score": 0.0021049977753042253, "phrase": "noisy_conditions"}], "paper_keywords": ["Emotion recognition", " semi-coupled hidden Markov model (SC-HMM)", " temporal course."], "paper_abstract": "A complete emotional expression typically contains a complex temporal course in face-to-face natural conversation. To address this problem, a bimodal hidden Markov model (HMM)-based emotion recognition scheme, constructed in terms of sub-emotional states, which are defined to represent temporal phases of onset, apex, and offset, is adopted to model the temporal course of an emotional expression for audio and visual signal streams. A two-level hierarchical alignment mechanism is proposed to align the relationship within and between the temporal phases in the audio and visual HMM sequences at the model and state levels in a proposed semi-coupled hidden Markov model (SC-HMM). Furthermore, by integrating a sub-emotion language model, which considers the temporal transition between sub-emotional states, the proposed two-level hierarchical alignment-based SC-HMM (2H-SC-HMM) can provide a constraint on allowable temporal structures to determine an optimal emotional state. Experimental results show that the proposed approach can yield satisfactory results in both the posed MHMC and the naturalistic SEMAINE databases, and shows that modeling the complex temporal structure is useful to improve the emotion recognition performance, especially for the naturalistic database (i.e., natural conversation). The experimental results also confirm that the proposed 2H-SC-HMM can achieve an acceptable performance for the systems with sparse training data or noisy conditions.", "paper_title": "Two-Level Hierarchical Alignment for Semi-Coupled HMM-Based Audiovisual Emotion Recognition With Temporal Course", "paper_id": "WOS:000327393900013"}