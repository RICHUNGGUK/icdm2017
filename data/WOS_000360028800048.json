{"auto_keywords": [{"score": 0.04827794640391151, "phrase": "elm"}, {"score": 0.007153183343938197, "phrase": "dynamic_time_warping"}, {"score": 0.00481495049065317, "phrase": "automatic_emergency_state_detection"}, {"score": 0.004673530058379246, "phrase": "extreme_learning_machine"}, {"score": 0.0045556080393342165, "phrase": "popular_paradigm"}, {"score": 0.004497762477097628, "phrase": "feedforward_neural_networks"}, {"score": 0.004273601449537163, "phrase": "automatic_classification"}, {"score": 0.0042373381286051354, "phrase": "speech_utterances"}, {"score": 0.004201381218977942, "phrase": "power_normalized_cepstral_coefficients"}, {"score": 0.0040779081518317415, "phrase": "feature_vectors"}, {"score": 0.003991932110277654, "phrase": "final_classification"}, {"score": 0.0037287578312533596, "phrase": "fixed_number"}, {"score": 0.003697100573612401, "phrase": "input_neurons"}, {"score": 0.0036037265181631324, "phrase": "length_normalization_algorithm"}, {"score": 0.003512702405367876, "phrase": "pncc_sequence"}, {"score": 0.0034386016613475335, "phrase": "fixed_length"}, {"score": 0.003409399407390298, "phrase": "length_normalization"}, {"score": 0.003117307618682836, "phrase": "vectorized_outerproduct"}, {"score": 0.0030908254851076005, "phrase": "trajectory_matrix"}, {"score": 0.0029871209444889716, "phrase": "tidigits_corpus"}, {"score": 0.002886885861509621, "phrase": "isolated_speech_recognition_task"}, {"score": 0.002838033152426417, "phrase": "itaal"}, {"score": 0.002742787059497186, "phrase": "emergency_detection_task"}, {"score": 0.0027194778713860715, "phrase": "realistic_acoustic_conditions"}, {"score": 0.00268488398249084, "phrase": "elm_approach"}, {"score": 0.0026282000779095987, "phrase": "template_matching"}, {"score": 0.002550842302473891, "phrase": "support_vector_machine"}, {"score": 0.002539978170928796, "phrase": "based_speech_recognizer"}, {"score": 0.0025076619172878945, "phrase": "obtained_results"}, {"score": 0.0023926387830753033, "phrase": "recognition_performance"}, {"score": 0.0022634699331607615, "phrase": "dtw_distances"}, {"score": 0.0022442249871042026, "phrase": "elm_kernel"}, {"score": 0.0022062235065459274, "phrase": "best_performing_algorithm"}, {"score": 0.002159623311924437, "phrase": "recognition_accuracy"}], "paper_keywords": ["Extreme Learning Machine", " Automatic speech recognition", " Support Vector Machine", " Dynamic time warping", " Template matching"], "paper_abstract": "Extreme Learning Machine (ELM) represents a popular paradigm for training feedforward neural networks due to its fast learning time. This paper applies the technique for the automatic classification of speech utterances. Power Normalized Cepstral Coefficients (PNCC) are employed as feature vectors and ELM performs the final classification. Both the baseline ELM algorithm and ELM with kernel have been employed and tested. Due to the fixed number of input neurons in the ELM, a length normalization algorithm is employed to transform the PNCC sequence into a vector of fixed length. Length normalization has been performed using two techniques: the first is based on Dynamic Time Warping (DTW) distances, the second on the vectorized outerproduct of trajectory matrix. Experiments have been conducted on the TIDIGITS corpus, to assess the performance on an isolated speech recognition task, and on ITAAL, to validate the system in an emergency detection task in realistic acoustic conditions. The ELM approach has been compared to template matching based on Dynamic Time Warping and to a Support Vector Machine based speech recognizer. The obtained results demonstrated the effectiveness of the approach both in terms of recognition performance and execution times. In particular, classification based on PNCCs, DTW distances and ELM kernel resulted in the best performing algorithm both in terms of recognition accuracy and execution times. (C) 2014 Elsevier B.V. All rights reserved.", "paper_title": "Acoustic template-matching for automatic emergency state detection: An ELM based algorithm", "paper_id": "WOS:000360028800048"}