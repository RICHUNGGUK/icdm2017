{"auto_keywords": [{"score": 0.04431606976723999, "phrase": "dagsvm"}, {"score": 0.00481495049065317, "phrase": "pairwise_multi-category_support_vector_machines"}, {"score": 0.004672444473700524, "phrase": "svm-based_methods"}, {"score": 0.004602773636967002, "phrase": "multi-category_classification"}, {"score": 0.003757480190200645, "phrase": "long_training_time"}, {"score": 0.003701401653850141, "phrase": "unclassifiable_region"}, {"score": 0.0032571885279065126, "phrase": "uncertainty_sampling-based_multi-category"}, {"score": 0.003066945490483524, "phrase": "new_method"}, {"score": 0.0029984960344766705, "phrase": "necessary_sub-classifiers"}, {"score": 0.0029095936591723645, "phrase": "n_x"}, {"score": 0.0026986685585382347, "phrase": "uncertainty_sampling_strategy"}, {"score": 0.0024105326885334962, "phrase": "uncertainty_sampling-based_method"}, {"score": 0.002252602622785975, "phrase": "experimental_results"}, {"score": 0.0022022878843247257, "phrase": "benchmark_data"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["SVM", " multi-category classification", " pairwise", " uncertainty sampling"], "paper_abstract": "Among the SVM-based methods for multi-category classification, \"l-a-r\", pairwise and DAGSVM are most widely used. The deficiency of \"l-a-r\" is long training time and unclassifiable region; the deficiency of pairwise and DAGSVM is the redundancy of sub-classifiers. We propose an uncertainty sampling-based multi-category SVM in this paper. In the new method, some necessary sub-classifiers instead of all N x (N - 1)/2 sub-classifiers are selected to be trained and the uncertainty sampling strategy is used to decide which samples should be selected in each training round. This uncertainty sampling-based method is proved to be accurate and efficient by experimental results on the benchmark data. (C) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Reducing the number of sub-classifiers for pairwise multi-category support vector machines", "paper_id": "WOS:000250377600020"}