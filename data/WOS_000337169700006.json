{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "social_networks"}, {"score": 0.004666228956744244, "phrase": "reputation-based_assessment_approach"}, {"score": 0.0037066895459425824, "phrase": "real_evidence"}, {"score": 0.0035176353680157367, "phrase": "substantial_risks"}, {"score": 0.003444732262403694, "phrase": "malicious_users"}, {"score": 0.0033381913087533457, "phrase": "harmless_content"}, {"score": 0.0027071661844502992, "phrase": "human_administrators"}, {"score": 0.0026233771102489416, "phrase": "authors'_reputation-based_approach"}, {"score": 0.002412371116984224, "phrase": "social_networking_site"}, {"score": 0.002337684811187166, "phrase": "reported_content"}, {"score": 0.002241679436497571, "phrase": "honest_users"}, {"score": 0.002172266188075892, "phrase": "inappropriate_content"}], "paper_keywords": [""], "paper_abstract": "Social network users can report other users' content as inappropriate by arguing that it encroaches on their privacy rights. Blindly accepting such reports as real evidence of something offensive poses substantial risks; malicious users might report harmless content just to compromise that material. The large number of users who flag content as offensive makes moderation difficult for human administrators. The authors' reputation-based approach automatically assesses accusers' honesty before a social networking site withdraws any reported content. It encourages honest users to report inappropriate content by increasing their reputation within the system.", "paper_title": "Reporting Offensive Content in Social Networks Toward a Reputation-Based Assessment Approach", "paper_id": "WOS:000337169700006"}