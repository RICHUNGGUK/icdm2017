{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "robotic_turing_test"}, {"score": 0.003315374849824563, "phrase": "telekinetic_power"}, {"score": 0.002992313172550772, "phrase": "causal_power"}, {"score": 0.0026613618933208467, "phrase": "empirical_target"}, {"score": 0.002622647280008795, "phrase": "cognitive_science"}], "paper_keywords": ["Artificial intelligence", " Consciousness", " Feeling", " Functionalism", " Mind/body problem", " Robotics", " Turing test"], "paper_abstract": "Consciousness is feeling, and the problem of consciousness is the problem of explaining how and why some of the functions underlying some of our performance capacities are felt rather than just \"functed.\" But unless we are prepared to assign to feeling a telekinetic power (which all evidence contradicts), feeling cannot be assigned any causal power at all. We cannot explain how or why we feet. Hence the empirical target of cognitive science can only be to scale up to the robotic Turing test, which is to explain all of our performance capacity, but without explaining consciousness or incorporating it in any way in our functional explanation. (c) 2008 Elsevier B.V. All rights reserved.", "paper_title": "First, scale up to the robotic Turing test, then worry about feeling", "paper_id": "WOS:000261542800003"}