{"auto_keywords": [{"score": 0.04962828441049361, "phrase": "online_temporal_fusion"}, {"score": 0.045745364372558925, "phrase": "specific_points"}, {"score": 0.015476467843948773, "phrase": "multisensor_systems"}, {"score": 0.011356848661265604, "phrase": "temporal_fusion"}, {"score": 0.00481495049065317, "phrase": "dynamic_time"}, {"score": 0.00470983237900705, "phrase": "sensor_fusion"}, {"score": 0.0046069985410261746, "phrase": "multiple_sensors"}, {"score": 0.004549242970806199, "phrase": "raw_data"}, {"score": 0.004244234872662471, "phrase": "growing_interest"}, {"score": 0.004191007935893067, "phrase": "behavioural_aspects"}, {"score": 0.00389760315371842, "phrase": "environmental_behaviours"}, {"score": 0.0037409118365761894, "phrase": "geographically_distributed_sensors"}, {"score": 0.003579179502431823, "phrase": "multisensor_data"}, {"score": 0.0034136194753440745, "phrase": "challenging_task"}, {"score": 0.003307508702661699, "phrase": "complex_sequences"}, {"score": 0.0029990127367275966, "phrase": "large_amounts"}, {"score": 0.002860212113080887, "phrase": "robust_and_efficient_framework"}, {"score": 0.0027625134766418266, "phrase": "core_recognizer"}, {"score": 0.002626317051411829, "phrase": "online_temporal_fusion_system"}, {"score": 0.0024889396846235, "phrase": "mobile_device"}, {"score": 0.002457671567833087, "phrase": "predefined_user_scenarios"}, {"score": 0.0024421847638964947, "phrase": "performance_results"}, {"score": 0.002419136901298873, "phrase": "dtw-based_system"}, {"score": 0.0023661988912166234, "phrase": "hidden_markov_model"}, {"score": 0.0023071120479647325, "phrase": "experimental_results"}, {"score": 0.002256619934086924, "phrase": "proposed_system"}, {"score": 0.0022353193959268767, "phrase": "based_systems"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["dynamic time warping", " temporal fusion", " context-awareness", " gesture recognition"], "paper_abstract": "Sensor fusion is concerned with gaining information from multiple sensors by fusing across raw data, features or decisions. Traditionally these fusion processes only concern fusion at specific points in time. However recently, there is a growing interest in inferring the behavioural aspects of environments or objects that are monitored by multisensor systems, rather than just their states at specific points in time. In order to infer environmental behaviours, it may be necessary to fuse data acquired from (i) geographically distributed sensors at specific points of time and (ii) specific sensors over a period of time. Fusing multisensor data over a period of time (also known as Temporal fusion) is,a challenging task, since the data to be fused consists of complex sequences that are multi-dimensional, multimodal, interacting, and time-varying in nature. Additionally, performing temporal fusion efficiently in real-time is another challenge due to the large amounts of data to be fused. To address this issue, we propose a robust and efficient framework that uses dynamic time warping (DTW) as the core recognizer to perform online temporal fusion on either the raw data or the features. We evaluate the performance of the online temporal fusion system on two real world datasets: (1) accelerometer data acquired from performing two hand gestures, and (2) a benchmark dataset acquired from carrying a mobile device and performing the predefined user scenarios. Performance results of the DTW-based system are compared with those of a Hidden Markov Model (HMM) based system. The experimental results from both datasets demonstrate that the proposed system outperforms HMM based systems, and has the capability to perform online temporal fusion efficiently and accurately in real-time. (C) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Using dynamic time warping for online temporal fusion in multisensor systems", "paper_id": "WOS:000257002500006"}