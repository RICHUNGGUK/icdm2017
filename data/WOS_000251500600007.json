{"auto_keywords": [{"score": 0.048231156244864744, "phrase": "hardware_implementations"}, {"score": 0.00481495049065317, "phrase": "general_regression_neural_network_coprocessor"}, {"score": 0.004561386908745206, "phrase": "general_regression_neural_network"}, {"score": 0.004257806363128601, "phrase": "neural_network"}, {"score": 0.004216112320418982, "phrase": "different_fixed_and_floating_point_implementations"}, {"score": 0.003858697684681798, "phrase": "precision_loss"}, {"score": 0.003709693561373117, "phrase": "resulting_neural_network_coprocessor"}, {"score": 0.003548905904860611, "phrase": "programmable_chip"}, {"score": 0.003428665921276366, "phrase": "approximate_functions"}, {"score": 0.003200230621987751, "phrase": "engine_management"}, {"score": 0.0030614565460256897, "phrase": "software_entities"}, {"score": 0.002986969236641105, "phrase": "great_amount"}, {"score": 0.0029576827451501956, "phrase": "complex_mathematical_operations"}, {"score": 0.002899965889623787, "phrase": "increasing_power"}, {"score": 0.002843372121209168, "phrase": "current_fpgas"}, {"score": 0.0026020254041372723, "phrase": "reconfigurable_feature"}, {"score": 0.0023694065215394593, "phrase": "neural_networks"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["GRNN", " FPGA", " matlab", " neural networks", " SoPC"], "paper_abstract": "This article presents a series of hardware implementations of a general regression neural network (GRNN) using FPGAs. The paper describes the study of this neural network using different fixed and floating point implementations. The implementation includes training as well as testing of the network. It is focused on precision loss and area and speed results of the resulting neural network coprocessor that can be used in a System on Programmable Chip. A GRNN is able to approximate functions and it has been used in control, prediction, fault diagnosis, engine management among others. They are mainly implemented as software entities because they require a great amount of complex mathematical operations. With the increasing power and capabilities of current FPGAs, now it is possible not only to translate them into hardware but, due to the reconfigurable feature of these devices, to explore different hardware/software partitions as well. These hardware implementations increase both the speed and performance of these neural networks, and the designer can select the area-speed trade-off that best fits the application. (c) 2007 Elsevier B.V. All rights reserved.", "paper_title": "Hardware architecture for a general regression neural network coprocessor", "paper_id": "WOS:000251500600007"}