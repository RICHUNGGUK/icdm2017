{"auto_keywords": [{"score": 0.044949655305819104, "phrase": "optimal_routing_policies"}, {"score": 0.04133331890311128, "phrase": "stochastic_dynamic_networks"}, {"score": 0.014791106559164326, "phrase": "sdp"}, {"score": 0.00481495049065317, "phrase": "time_reduction_techniques"}, {"score": 0.004741395005218184, "phrase": "stochastic_dynamic_programming_approach"}, {"score": 0.004692980391580608, "phrase": "hazardous_material_route_selection_problem"}, {"score": 0.004574085781766281, "phrase": "stochastic_dynamic_programming"}, {"score": 0.004235095881928715, "phrase": "stochastic_dynamic_network"}, {"score": 0.003413284742632989, "phrase": "start_time_and_origin_location"}, {"score": 0.0030017207229983385, "phrase": "significant_computational_advantage"}, {"score": 0.002971016979295967, "phrase": "conventional_sdp."}, {"score": 0.002851301751761804, "phrase": "computational_advantage"}, {"score": 0.0028076592725295646, "phrase": "pruning_strategies"}, {"score": 0.0027363971333961967, "phrase": "start_time"}, {"score": 0.0026261108615242557, "phrase": "time_input"}, {"score": 0.002443671484766342, "phrase": "experiments_section"}, {"score": 0.0023451553255837317, "phrase": "computational_performances"}, {"score": 0.0023211517663846346, "phrase": "time-dependent_techniques"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Stochastic dynamic networks", " Dynamic programming", " Markov decision process"], "paper_abstract": "We use a stochastic dynamic programming (SDP) approach to solve the problem of determining the optimal routing policies in a stochastic dynamic network. Due to its long time for solving SDP, we propose three techniques for pruning stochastic dynamic networks to expedite the process of obtaining optimal routing policies. The techniques include: (I) use of static upper/lower bounds, (2) pre-processing the stochastic dynamic networks by using the start time and origin location of the vehicle, and (3) a mix of preprocessing and upper/lower bounds. Our experiments show that while finding optimal routing policies in stochastic dynamic networks, the last two of the three strategies have a significant computational advantage over conventional SDP. Our main observation from these experiments was that the computational advantage of the pruning strategies that depend on the start time of the vehicle varies according to the time input to the problem. We present the results of this variation in the experiments section. We recommend that while comparing the computational performances of time-dependent techniques, it is very important to test the performance of such strategies at various time inputs. (C) 2013 Elsevier Ltd. All rights reserved.", "paper_title": "Solution time reduction techniques of a stochastic dynamic programming approach for hazardous material route selection problem", "paper_id": "WOS:000322563200013"}