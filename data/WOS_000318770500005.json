{"auto_keywords": [{"score": 0.032550387777267584, "phrase": "gradient_estimates"}, {"score": 0.015201892968430396, "phrase": "parameter-based_exploration"}, {"score": 0.00481495049065317, "phrase": "efficient_sample"}, {"score": 0.00471811808206897, "phrase": "policy_gradients"}, {"score": 0.004561019117546361, "phrase": "policy_gradient_approach"}, {"score": 0.0044692705329574, "phrase": "flexible_and_powerful_reinforcement_learning_method"}, {"score": 0.004320421465896323, "phrase": "continuous_actions"}, {"score": 0.004233492114255375, "phrase": "robot_control"}, {"score": 0.00414830454375092, "phrase": "common_challenge"}, {"score": 0.0038242899532391914, "phrase": "reliable_policy_updates"}, {"score": 0.0035016702571862165, "phrase": "highly_effective_policy_gradient_method"}, {"score": 0.0031203609829058587, "phrase": "low_variance"}, {"score": 0.0027804579695873827, "phrase": "previously_gathered_data"}, {"score": 0.002724428781940696, "phrase": "consistent_way"}, {"score": 0.002330664671716791, "phrase": "proposed_method"}, {"score": 0.002252880693912436, "phrase": "theoretical_analysis"}, {"score": 0.0021049977753042253, "phrase": "extensive_experiments"}], "paper_keywords": [""], "paper_abstract": "The policy gradient approach is a flexible and powerful reinforcement learning method particularly for problems with continuous actions such as robot control. A common challenge is how to reduce the variance of policy gradient estimates for reliable policy updates. In this letter, we combine the following three ideas and give a highly effective policy gradient method: (1) policy gradients with parameter-based exploration, a recently proposed policy search method with low variance of gradient estimates; (2) an importance sampling technique, which allows us to reuse previously gathered data in a consistent way; and (3) an optimal baseline, which minimizes the variance of gradient estimates with their unbiasedness being maintained. For the proposed method, we give a theoretical analysis of the variance of gradient estimates and show its usefulness through extensive experiments.", "paper_title": "Efficient Sample Reuse in Policy Gradients with Parameter-Based Exploration", "paper_id": "WOS:000318770500005"}