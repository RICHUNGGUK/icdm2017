{"auto_keywords": [{"score": 0.0053134973060343675, "phrase": "weak_systems"}, {"score": 0.00481495049065317, "phrase": "diversified_translation_systems"}, {"score": 0.00475413908468027, "phrase": "single_statistical_machine_translation"}, {"score": 0.004634799977448855, "phrase": "system_combination"}, {"score": 0.004576253356889219, "phrase": "traditional_approaches"}, {"score": 0.0044424917428102445, "phrase": "multiple_structurally_different_smt_systems"}, {"score": 0.004312622975366676, "phrase": "strong_smt_system"}, {"score": 0.004258128672571261, "phrase": "single_translation_engine"}, {"score": 0.004204320052179726, "phrase": "principled_way"}, {"score": 0.0039620308501590795, "phrase": "general_framework"}, {"score": 0.003928572641266562, "phrase": "ensemble_learning"}, {"score": 0.0038789122930433305, "phrase": "basic_idea"}, {"score": 0.0037336520904376687, "phrase": "weak_translation_systems"}, {"score": 0.0036864465771943933, "phrase": "base_learning_algorithm"}, {"score": 0.003593812067062062, "phrase": "strong_translation_system"}, {"score": 0.003315499339103866, "phrase": "current_smt_systems"}, {"score": 0.0030457198309616694, "phrase": "proposed_framework"}, {"score": 0.002994449398035894, "phrase": "final_translation_system"}, {"score": 0.002857849698346116, "phrase": "chinese-english_translation"}, {"score": 0.0027159094186967247, "phrase": "hierarchical_phrase-based_system"}, {"score": 0.0026815368507715, "phrase": "syntax-based_system"}, {"score": 0.0026140878612307536, "phrase": "nist_mt_evaluation"}, {"score": 0.0025375331660958665, "phrase": "significant_improvements"}, {"score": 0.0025160740422447837, "phrase": "translation_accuracy"}, {"score": 0.0023309080951251335, "phrase": "existing_system_combination_systems"}, {"score": 0.0023013968622710847, "phrase": "biggest_improvements"}, {"score": 0.0021870332034407817, "phrase": "strong_system"}, {"score": 0.0021593396036472777, "phrase": "state-of-the-art_system_combination_method"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Statistical machine translation", " Ensemble learning", " System combination"], "paper_abstract": "In this article we address the issue of generating diversified translation systems from a single Statistical Machine Translation (SMT) engine for system combination. Unlike traditional approaches, we do not resort to multiple structurally different SMT systems, but instead directly learn a strong SMT system from a single translation engine in a principled way. Our approach is based on Bagging and Boosting which are two instances of the general framework of ensemble learning. The basic idea is that we first generate an ensemble of weak translation systems using a base learning algorithm, and then learn a strong translation system from the ensemble. One of the advantages of our approach is that it can work with any of current SMT systems and make them stronger almost \"for free\". Beyond this, most system combination methods are directly applicable to the proposed framework for generating the final translation system from the ensemble of weak systems. We evaluate our approach on Chinese-English translation in three state-of-the-art SMT systems, including a phrase-based system, a hierarchical phrase-based system and a syntax-based system. Experimental results on the NIST MT evaluation corpora show that our approach leads to significant improvements in translation accuracy over the baselines. More interestingly, it is observed that our approach is able to improve the existing system combination systems. The biggest improvements are obtained by generating weak systems using Bagging/Boosting, and learning the strong system using a state-of-the-art system combination method. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Bagging and Boosting statistical machine translation systems", "paper_id": "WOS:000315839600019"}