{"auto_keywords": [{"score": 0.04857419429813187, "phrase": "nonlocal_principle"}, {"score": 0.015719716506582538, "phrase": "knn_matting"}, {"score": 0.004626553103375699, "phrase": "general_alpha_matting"}, {"score": 0.004571478018964363, "phrase": "simultaneous_extraction"}, {"score": 0.004535124351828787, "phrase": "multiple_image_layers"}, {"score": 0.004357627943575288, "phrase": "coherent_segments"}, {"score": 0.004305740330804528, "phrase": "foreground_mattes"}, {"score": 0.004271490815763164, "phrase": "natural_image_matting"}, {"score": 0.004220624516321415, "phrase": "estimated_alphas"}, {"score": 0.004153739859461064, "phrase": "summation_constraint"}, {"score": 0.004087910779160781, "phrase": "nonlocal_matting"}, {"score": 0.003975200317233532, "phrase": "local_color-line_model"}, {"score": 0.0038965930422333035, "phrase": "sophisticated_sampling"}, {"score": 0.0036553070575015344, "phrase": "feature_space"}, {"score": 0.003361069456060196, "phrase": "arguably_simpler_implementation"}, {"score": 0.0031908963946938648, "phrase": "knn"}, {"score": 0.0030781126453776723, "phrase": "k_nearest_neighbors"}, {"score": 0.003005151718290603, "phrase": "nonlocal_neighborhoods"}, {"score": 0.002945669860541221, "phrase": "simple_and_fast_algorithm"}, {"score": 0.002910545717767559, "phrase": "competitive_results"}, {"score": 0.00288736193515505, "phrase": "sparse_user_markups"}, {"score": 0.0028302049070944944, "phrase": "closed-form_solution"}, {"score": 0.0027741761880779535, "phrase": "preconditioned_conjugate_gradient_method"}, {"score": 0.002730150696072947, "phrase": "efficient_implementation"}, {"score": 0.002708399936381754, "phrase": "experimental_evaluation"}, {"score": 0.002686821995335494, "phrase": "benchmark_datasets"}, {"score": 0.0025918235228843444, "phrase": "higher_quality"}, {"score": 0.002382987346529592, "phrase": "alpha_estimation"}, {"score": 0.0023545567809591804, "phrase": "overlapping_image_layers"}, {"score": 0.0022895278869126848, "phrase": "alpha_value"}, {"score": 0.002199725773957207, "phrase": "multilayer_extraction_problem"}, {"score": 0.0021647968783414504, "phrase": "qualitative_and_quantitative_comparisons"}, {"score": 0.0021049977753042253, "phrase": "extracted_image_layers"}], "paper_keywords": ["Natural image matting", " layer extraction"], "paper_abstract": "This paper proposes to apply the nonlocal principle to general alpha matting for the simultaneous extraction of multiple image layers; each layer may have disjoint as well as coherent segments typical of foreground mattes in natural image matting. The estimated alphas also satisfy the summation constraint. As in nonlocal matting, our approach does not assume the local color-line model and does not require sophisticated sampling or learning strategies. On the other hand, our matting method generalizes well to any color or feature space in any dimension, any number of alphas and layers at a pixel beyond two, and comes with an arguably simpler implementation, which we have made publicly available. Our matting technique, aptly called KNN matting, capitalizes on the nonlocal principle by using K nearest neighbors (KNN) in matching nonlocal neighborhoods, and contributes a simple and fast algorithm that produces competitive results with sparse user markups. KNN matting has a closed-form solution that can leverage the preconditioned conjugate gradient method to produce an efficient implementation. Experimental evaluation on benchmark datasets indicates that our matting results are comparable to or of higher quality than state-of-the-art methods requiring more involved implementation. In this paper, we take the nonlocal principle beyond alpha estimation and extract overlapping image layers using the same Laplacian framework. Given the alpha value, our closed form solution can be elegantly generalized to solve the multilayer extraction problem. We perform qualitative and quantitative comparisons to demonstrate the accuracy of the extracted image layers.", "paper_title": "KNN Matting", "paper_id": "WOS:000322029000010"}