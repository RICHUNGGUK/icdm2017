{"auto_keywords": [{"score": 0.04346898089428127, "phrase": "multiple_domains"}, {"score": 0.00481495049065317, "phrase": "confidence-weighted_parameter_combination"}, {"score": 0.00475070135279933, "phrase": "state-of-the-art_statistical_nlp_systems"}, {"score": 0.004502126088469323, "phrase": "labeled_training_data"}, {"score": 0.0037297918570822876, "phrase": "spam_filtering_system"}, {"score": 0.0036553070575015344, "phrase": "high_quality_predictions"}, {"score": 0.003417565253539315, "phrase": "different_sources"}, {"score": 0.0033268412940032103, "phrase": "slightly_different_decisions"}, {"score": 0.0030688220103201836, "phrase": "separate_models"}, {"score": 0.002755567647101251, "phrase": "new_multi-domain"}, {"score": 0.002646501671714952, "phrase": "parameter_combination"}, {"score": 0.0026111116934081284, "phrase": "multiple_classifiers"}, {"score": 0.002524688179363081, "phrase": "multi-task_learning"}, {"score": 0.0024247382451294255, "phrase": "multiple_source_domain_classifiers"}, {"score": 0.0023762535034673017, "phrase": "new_target_domain"}, {"score": 0.0023131084326717755, "phrase": "multiple_similar_domains"}, {"score": 0.0022215160785078797, "phrase": "large_number"}, {"score": 0.0021917966722180132, "phrase": "disparate_domains"}], "paper_keywords": ["Online learning", " Domain adaptation", " Classifier combination", " Transfer learning", " Multi-task learning"], "paper_abstract": "State-of-the-art statistical NLP systems for a variety of tasks learn from labeled training data that is often domain specific. However, there may be multiple domains or sources of interest on which the system must perform. For example, a spam filtering system must give high quality predictions for many users, each of whom receives emails from different sources and may make slightly different decisions about what is or is not spam. Rather than learning separate models for each domain, we explore systems that learn across multiple domains. We develop a new multi-domain online learning framework based on parameter combination from multiple classifiers. Our algorithms draw from multi-task learning and domain adaptation to adapt multiple source domain classifiers to a new target domain, learn across multiple similar domains, and learn across a large number of disparate domains. We evaluate our algorithms on two popular NLP domain adaptation tasks: sentiment classification and spam filtering.", "paper_title": "Multi-domain learning by confidence-weighted parameter combination", "paper_id": "WOS:000275754600007"}