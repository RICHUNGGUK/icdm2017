{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multi-party_computation"}, {"score": 0.03452834301390204, "phrase": "rational_parties"}, {"score": 0.031699164005120746, "phrase": "rational_party"}, {"score": 0.004452641437293878, "phrase": "participating_parties"}, {"score": 0.003959447096055027, "phrase": "new_model"}, {"score": 0.0034355662264234864, "phrase": "trusted_mediator"}, {"score": 0.002548331088496964, "phrase": "malicious_adversary"}, {"score": 0.002333193766510394, "phrase": "rational_participants"}], "paper_keywords": [""], "paper_abstract": "We study multi-party computation in the model where none of n participating parties are honest: they are either rational, acting in their selfish interest to maximize their utility, or adversarial, acting arbitrarily. In this new model, which we call the mixed-behavior model, we define a class of functions that can be computed in the presence of an adversary using a trusted mediator. We then give a protocol that allows the rational parties to emulate the mediator and jointly compute the function such that (1) assuming that each rational party prefers that it learns the output while others do not, no rational party has an incentive to deviate from the protocol; and (2) the rational parties are protected from a malicious adversary controlling [n/2] - 2 of the participants: the adversary can only either cause all rational participants to abort (so no one learns the function they are trying to compute), or can only learn whatever information is implied by the output of the function.", "paper_title": "Rationality and adversarial behavior in multi-party computation (Extended abstract)", "paper_id": "WOS:000240079900011"}