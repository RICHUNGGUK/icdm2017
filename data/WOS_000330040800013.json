{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "new_methodology"}, {"score": 0.004695900553353526, "phrase": "dense_visual_flow"}, {"score": 0.004579780586951551, "phrase": "precise_timings"}, {"score": 0.004392565073466714, "phrase": "asynchronous_event-based_retina"}, {"score": 0.003685972800046028, "phrase": "light_acquisition"}, {"score": 0.00347657813672945, "phrase": "currently_used_frame-grabber_technologies"}, {"score": 0.0032246835734680377, "phrase": "visual_flow"}, {"score": 0.0031448288291084, "phrase": "local_properties"}, {"score": 0.003092690568543981, "phrase": "events'_spatiotemporal_space"}, {"score": 0.002941389980674657, "phrase": "precise_visual_flow_orientation"}, {"score": 0.0027510752634224726, "phrase": "local_differential_approach"}, {"score": 0.0026164433143193015, "phrase": "coactive_events"}, {"score": 0.0025730425700096365, "phrase": "experimental_results"}, {"score": 0.002426717832834137, "phrase": "method_adequacy"}, {"score": 0.0023864566654035924, "phrase": "high_data_sparseness"}, {"score": 0.002346861891137455, "phrase": "temporal_resolution"}, {"score": 0.0023079225317714815, "phrase": "event-based_acquisition"}, {"score": 0.002194929830604162, "phrase": "motion_flow"}, {"score": 0.002158505888557746, "phrase": "microsecond_accuracy"}], "paper_keywords": ["Event-based vision", " event-based visual motion flow", " neuromorphic sensors", " real time"], "paper_abstract": "This paper introduces a new methodology to compute dense visual flow using the precise timings of spikes from an asynchronous event-based retina. Biological retinas, and their artificial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual flow from the local properties of events' spatiotemporal space. We will show that precise visual flow orientation and amplitude can be estimated using a local differential approach on the surface defined by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-based acquisition that allows the computation of motion flow with microsecond accuracy and at very low computational cost.", "paper_title": "Event-Based Visual Flow", "paper_id": "WOS:000330040800013"}