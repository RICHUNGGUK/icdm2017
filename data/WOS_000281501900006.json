{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "general_machine"}, {"score": 0.004777214679969785, "phrase": "learning_framework"}, {"score": 0.00348655247465418, "phrase": "restricted_but_important_case"}, {"score": 0.003299460925313939, "phrase": "single_point"}, {"score": 0.0031970796597571367, "phrase": "mild_assumptions"}, {"score": 0.002426137929553722, "phrase": "general_setting"}, {"score": 0.0023694065215394593, "phrase": "vcg_mechanism"}, {"score": 0.0022070310530794097, "phrase": "economic_efficiency"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Algorithmic mechanism design", " Computational learning theory", " Regression analysis"], "paper_abstract": "We initiate the study of incentives in a general machine learning framework. We focus on a game-theoretic regression learning setting where private information is elicited from multiple agents with different, possibly conflicting, views on how to label the points of an input space. This conflict potentially gives rise to untruthfulness on the part of the agents. In the restricted but important case when every agent cares about a single point, and under mild assumptions, we show that agents are motivated to tell the truth. In a more general setting, we study the power and limitations of mechanisms without payments. We finally establish that, in the general setting, the VCG mechanism goes a long way in guaranteeing truthfulness and economic efficiency. (C) 2010 Elsevier Inc. All rights reserved.", "paper_title": "Incentive compatible regression learning", "paper_id": "WOS:000281501900006"}