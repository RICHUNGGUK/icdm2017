{"auto_keywords": [{"score": 0.04963992389677819, "phrase": "document_representation"}, {"score": 0.04505014996365287, "phrase": "trsm"}, {"score": 0.04135304713660233, "phrase": "weight_vector"}, {"score": 0.02489217201230794, "phrase": "trsm_method"}, {"score": 0.0048150420240970805, "phrase": "lexicon"}, {"score": 0.004698086429418318, "phrase": "big_challenge"}, {"score": 0.004654993966953098, "phrase": "information_retrieval_system"}, {"score": 0.0046267682523833484, "phrase": "irs"}, {"score": 0.004445362365289235, "phrase": "common_form"}, {"score": 0.0043374295116776675, "phrase": "rough_sets_models"}, {"score": 0.004219121035447185, "phrase": "rough_sets"}, {"score": 0.004066360459825868, "phrase": "semantic_relatedness"}, {"score": 0.004016674413640846, "phrase": "system_efficiency"}, {"score": 0.0037081324077511482, "phrase": "trsm-representation"}, {"score": 0.003444341260156638, "phrase": "lex"}, {"score": 0.003319528548591761, "phrase": "compact_form"}, {"score": 0.003268867709471835, "phrase": "lower_dimensional_space"}, {"score": 0.0032288944757814936, "phrase": "informal_terms"}, {"score": 0.003189408489240117, "phrase": "trsm-vector"}, {"score": 0.002999083173896382, "phrase": "information_retrieval"}, {"score": 0.002709487386923251, "phrase": "existing_trsm-representation"}, {"score": 0.0026681117410294708, "phrase": "lexicon-based_document_representation"}, {"score": 0.0024857542101349808, "phrase": "linguistic_computation"}, {"score": 0.002440262939107715, "phrase": "feature_selection"}, {"score": 0.0023808972257735018, "phrase": "high_weight"}, {"score": 0.0022945393604862354, "phrase": "tolerance_class"}, {"score": 0.0021909737736168122, "phrase": "tolerance_classes"}, {"score": 0.0021310870821926917, "phrase": "wikipedia_indonesia"}, {"score": 0.0021049977753042253, "phrase": "better_tolerance_class"}], "paper_keywords": ["Tolerance rough sets model", " information retrieval"], "paper_abstract": "It is a big challenge for an information retrieval system (IRS) to interpret the queries made by users, particularly because the common form of query consists of very few terms. Tolerance rough sets models (TRSM), as an extension of rough sets theory, have demonstrated their ability to enrich document representation in terms of semantic relatedness. However, system efficiency is at stake because the weight vector created by TRSM (TRSM-representation) is much less sparse. We mapped the terms occurring in TRSM-representation to terms in the lexicon, hence the final representation of a document was a weight vector consisting only of terms that occurred in the lexicon (LEX-representation). The LEX-representation can be viewed as a compact form of TRSM-representation in a lower dimensional space and eliminates all informal terms previously occurring in TRSM-vector. With these facts, we may expect a more efficient system. We employed recall and precision commonly used in information retrieval to evaluate the effectiveness of LEX-representation. Based on our examination, we found that the effectiveness of LEX-representation is comparable with TRSM-representation while the efficiency of LEX-representation should be better than the existing TRSM-representation. We concluded that lexicon-based document representation was another alternative potentially used to represent a document while considering semantics. We are tempted to implement the LEX-representation together with linguistic computation, such as tagging and feature selection, in order to retrieve more relevant terms with high weight. With regard to the TRSM method, enhancing the quality of tolerance class is crucial based on the fact that the TRSM method is fully reliant on the tolerance classes. We plan to combine other resources such as Wikipedia Indonesia to generate a better tolerance class.", "paper_title": "Lexicon-based Document Representation", "paper_id": "WOS:000320501200003"}