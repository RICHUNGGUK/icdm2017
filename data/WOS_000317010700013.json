{"auto_keywords": [{"score": 0.04145532680087399, "phrase": "existing_techniques"}, {"score": 0.028282402131747257, "phrase": "speculative_threads"}, {"score": 0.00481495049065317, "phrase": "speculative_loop_execution"}, {"score": 0.004742511243894382, "phrase": "compiler_techniques"}, {"score": 0.004706699397060569, "phrase": "thread-level_loop_speculation"}, {"score": 0.004281125387210667, "phrase": "extensive_profiling"}, {"score": 0.004075198669927074, "phrase": "production_compiler"}, {"score": 0.0040444053843446326, "phrase": "speculative_multithreaded_multicore_processors"}, {"score": 0.0037774893672602506, "phrase": "different_inputs"}, {"score": 0.00362308996613223, "phrase": "selected_loop_candidates"}, {"score": 0.0035550029054401016, "phrase": "run_time"}, {"score": 0.0034618177773967015, "phrase": "statically_greedy"}, {"score": 0.003435643372146385, "phrase": "dynamically_adaptive"}, {"score": 0.0033967510986397946, "phrase": "thread-level_speculation"}, {"score": 0.0031604223680801774, "phrase": "loop_candidates"}, {"score": 0.0030892533800837463, "phrase": "input-independent_way"}, {"score": 0.0030311679447397725, "phrase": "runtime_scheduler"}, {"score": 0.0030082398041055003, "phrase": "schedule_loop_iterations"}, {"score": 0.0025941547726803594, "phrase": "effective_cost_model"}, {"score": 0.002497470177389344, "phrase": "loop_nesting_structures"}, {"score": 0.002279841453843241, "phrase": "olden_benchmarks"}, {"score": 0.0022200068884960836, "phrase": "program's_loop_candidates"}, {"score": 0.002137236968970666, "phrase": "comparable_or_better_performance"}, {"score": 0.0021049977753042253, "phrase": "entire_loop_candidate_selection_process"}], "paper_keywords": ["Loop-level speculation", " thread-level speculation", " speculative compilation"], "paper_abstract": "Research on compiler techniques for thread-level loop speculation has so far remained on studying its performance limits: loop candidates that are worthy of parallelization are manually selected by the researchers or based on extensive profiling and preexecution. It is therefore difficult to include them in a production compiler for speculative multithreaded multicore processors. In a way, existing techniques are statically adaptive (\"realized\" by the researchers for different inputs) yet dynamically greedy (since all iterations of all selected loop candidates are always parallelized at run time). This paper introduces a Statically GrEEdy and Dynamically Adaptive (SEED) approach for thread-level speculation on loops that is quite different from most other existing techniques. SEED relies on the compiler to select and optimize loop candidates greedily (possibly in an input-independent way) and provides a runtime scheduler to schedule loop iterations adaptively. To select loops for parallelization at runtime (subject to program inputs), loop iterations are prioritized in terms of their potential benefits rather than their degree of speculation as in many prior studies. In our current implementation, the benefits of speculative threads are estimated by a simple yet effective cost model. It comprises a mechanism for efficiently tracing the loop nesting structures of the program and a mechanism for predicting the outcome of speculative threads. We have evaluated SEED using a set of SPECint2000 and Olden benchmarks. Compared to existing techniques with a program's loop candidates being ideally selected a priori, SEED can achieve comparable or better performance while aututomating the entire loop candidate selection process.", "paper_title": "SEED: A Statically Greedy and Dynamically Adaptive Approach for Speculative Loop Execution", "paper_id": "WOS:000317010700013"}