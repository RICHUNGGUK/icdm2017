{"auto_keywords": [{"score": 0.04926219622874721, "phrase": "iqa"}, {"score": 0.010612379340043753, "phrase": "perceptual_image_quality_assessment"}, {"score": 0.007278440323764218, "phrase": "vs"}, {"score": 0.006077096090367619, "phrase": "proposed_iqa_index"}, {"score": 0.0051833720878693415, "phrase": "vsi"}, {"score": 0.004632039024076267, "phrase": "computational_models"}, {"score": 0.004552981066668676, "phrase": "image_quality"}, {"score": 0.004475266375001531, "phrase": "subjective_evaluations"}, {"score": 0.0044369056710423065, "phrase": "visual_saliency"}, {"score": 0.0041773934798743405, "phrase": "computer_scientists"}, {"score": 0.003899269293218826, "phrase": "human_visual_system"}, {"score": 0.0037028514035425037, "phrase": "suprathreshold_distortions"}, {"score": 0.0036395944934310524, "phrase": "vs_maps"}, {"score": 0.003471135453226184, "phrase": "simple_but_very_effective_full_reference_iqa_method"}, {"score": 0.0034414505378408595, "phrase": "vs."}, {"score": 0.0030898642396380662, "phrase": "local_quality_map"}, {"score": 0.003050166508545763, "phrase": "distorted_image"}, {"score": 0.00295950473406239, "phrase": "quality_score"}, {"score": 0.0028715299874549245, "phrase": "weighting_function"}, {"score": 0.0027861630854233693, "phrase": "local_region"}, {"score": 0.0024375261163128064, "phrase": "vsi."}, {"score": 0.002427035025924384, "phrase": "extensive_experiments"}, {"score": 0.0022749744354271816, "phrase": "prediction_accuracy"}, {"score": 0.0022457226013538343, "phrase": "state-of-the-art_iqa_indices"}, {"score": 0.0021789194955896124, "phrase": "moderate_computational_complexity"}, {"score": 0.002150900082318562, "phrase": "matlab_source_code"}, {"score": 0.0021049977753042253, "phrase": "evaluation_results"}], "paper_keywords": ["Perceptual image quality assessment", " visual saliency"], "paper_abstract": "Perceptual image quality assessment (IQA) aims to use computational models to measure the image quality in consistent with subjective evaluations. Visual saliency (VS) has been widely studied by psychologists, neurobiologists, and computer scientists during the last decade to investigate, which areas of an image will attract the most attention of the human visual system. Intuitively, VS is closely related to IQA in that suprathreshold distortions can largely affect VS maps of images. With this consideration, we propose a simple but very effective full reference IQA method using VS. In our proposed IQA model, the role of VS is twofold. First, VS is used as a feature when computing the local quality map of the distorted image. Second, when pooling the quality score, VS is employed as a weighting function to reflect the importance of a local region. The proposed IQA index is called visual saliency-based index (VSI). Several prominent computational VS models have been investigated in the context of IQA and the best one is chosen for VSI. Extensive experiments performed on four large-scale benchmark databases demonstrate that the proposed IQA index VSI works better in terms of the prediction accuracy than all state-of-the-art IQA indices we can find while maintaining a moderate computational complexity. The MATLAB source code of VSI and the evaluation results are publicly available online at http://sse.tongji.edu.cn/linzhang/IQA/VSI/VSI.htm.", "paper_title": "VSI: A Visual Saliency-Induced Index for Perceptual Image Quality Assessment", "paper_id": "WOS:000341706700005"}