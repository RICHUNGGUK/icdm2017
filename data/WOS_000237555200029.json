{"auto_keywords": [{"score": 0.03029870759132602, "phrase": "bayesian"}, {"score": 0.00481495049065317, "phrase": "statistical_face_recognition"}, {"score": 0.004448169552315403, "phrase": "appropriate_feature_representation"}, {"score": 0.004324031677173549, "phrase": "video-based_face_recognition"}, {"score": 0.00417961150804265, "phrase": "spatial_and_temporal_information"}, {"score": 0.00399449659126893, "phrase": "spatio-temporal_embedding"}, {"score": 0.003882970272082245, "phrase": "raw_video"}, {"score": 0.0037745459666402915, "phrase": "video_sequence"}, {"score": 0.0035869274480340727, "phrase": "space-time_characteristics"}, {"score": 0.0034279721355412285, "phrase": "co-occurrence_statistics"}, {"score": 0.0033576301168548373, "phrase": "ste"}, {"score": 0.003313380246267815, "phrase": "training_videos"}, {"score": 0.0032208091960514128, "phrase": "intrinsic_temporal_structures"}, {"score": 0.0031665087019813244, "phrase": "video_volume"}, {"score": 0.003078028357912228, "phrase": "discriminative_cues"}, {"score": 0.00302612773666719, "phrase": "spatial_domain"}, {"score": 0.002671263324230699, "phrase": "temporal_and_spatial_learning"}, {"score": 0.0025673005153462707, "phrase": "learned_stes"}, {"score": 0.002495521662819317, "phrase": "statistical_formulation"}, {"score": 0.0024534188907003726, "phrase": "recognition_problem"}, {"score": 0.0024120247307686084, "phrase": "probabilistic_fusion_model"}, {"score": 0.0023579143175099324, "phrase": "large_face_video_database"}, {"score": 0.0022919762167777427, "phrase": "testing_sequences"}, {"score": 0.0021049977753042253, "phrase": "perfect_recognition_accuracy"}], "paper_keywords": [""], "paper_abstract": "This paper addresses the problem of how to learn an appropriate feature representation from video to benefit video-based face recognition. By simultaneously exploiting the spatial and temporal information, the problem is posed as learning Spatio-Temporal Embedding (STE) from raw video. STE of a video sequence is defined as its condensed version capturing the essence of space-time characteristics of the video. Relying on the co-occurrence statistics and supervised signatures provided by training videos, STE preserves the intrinsic temporal structures hidden in video volume, meanwhile encodes the discriminative cues into the spatial domain. To conduct STE, we propose two novel techniques, Bayesian keyframe learning and nonparametric discriminant embedding (NDE), for temporal and spatial learning, respectively. In terms of learned STEs, we derive a statistical formulation to the recognition problem with a probabilistic fusion model. On a large face video database containing more than 200 training and testing sequences, our approach consistently outperforms state-of-the-art methods, achieving a perfect recognition accuracy.", "paper_title": "Spatio-temporal embedding for statistical face recognition from video", "paper_id": "WOS:000237555200029"}