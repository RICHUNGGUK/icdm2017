{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "coherence-feature_extraction"}, {"score": 0.045912844607109565, "phrase": "coherence_features"}, {"score": 0.035620716932052585, "phrase": "experimental_results"}, {"score": 0.03408663291404538, "phrase": "adjacent_agreement_rate"}, {"score": 0.03363896917055258, "phrase": "exact_agreement_rate"}, {"score": 0.004540271807397052, "phrase": "markov"}, {"score": 0.004357245559948974, "phrase": "rank_content"}, {"score": 0.004317848984770719, "phrase": "coherence_hmm"}, {"score": 0.004221028421401076, "phrase": "hmm"}, {"score": 0.004088807948906792, "phrase": "stochastic_process"}, {"score": 0.004051828608343507, "phrase": "essay_writing"}, {"score": 0.003960831041259951, "phrase": "hidden_states"}, {"score": 0.003907212558276185, "phrase": "sequenced_clauses"}, {"score": 0.0037848978618663684, "phrase": "probabilistic_latent_semantic_analysis"}, {"score": 0.0036167509502276294, "phrase": "support_vector_regression"}, {"score": 0.003535489842686145, "phrase": "surface_features"}, {"score": 0.003424771860049617, "phrase": "essay_grading"}, {"score": 0.003332636204954288, "phrase": "svr"}, {"score": 0.0030017207229983385, "phrase": "high-scoring_essays"}, {"score": 0.002753224894944965, "phrase": "content_ranking"}, {"score": 0.00266693888510356, "phrase": "intelligent_assisted_blog_writing_system"}, {"score": 0.0026188490199688013, "phrase": "coherence-hmm_ranking_model"}, {"score": 0.002491015208328868, "phrase": "blog_articles"}, {"score": 0.0023372808856170386, "phrase": "candidate_texts"}, {"score": 0.0022847009758393405, "phrase": "current_clause"}, {"score": 0.0021049977753042253, "phrase": "considerable_time"}], "paper_keywords": ["Coherence-feature extraction", " hidden Markov model (HMM)", " input devices and strategies", " natural language processing (NLP)", " predictive content"], "paper_abstract": "In this paper, we propose an algorithm called coherence hidden Markov model (HMM) to extract coherence features and rank content. Coherence HMM is a variant of HMM and is used to model the stochastic process of essay writing and identify topics as hidden states, given sequenced clauses as observations. This study uses probabilistic latent semantic analysis for parameter estimation of coherence HMM. In coherence-feature extraction, support vector regression (SVR) with surface features and coherence features is used for essay grading. The experimental results indicate that SVR can benefit from coherence features. The adjacent agreement rate and the exact agreement rate are 95.24% and 59.80%, respectively. Moreover, this study submits high-scoring essays to the same experiment and finds that the adjacent agreement rate and exact agreement rate are 98.33% and 64.50%, respectively. In content ranking, we design and implement an intelligent assisted blog writing system based on the coherence-HMM ranking model. Several corpora are employed to help users efficiently compose blog articles. When users finish composing a clause or sentence, the system provides candidate texts for their reference based on current clause or sentence content. The experimental results demonstrate that all participants can benefit from the system and save considerable time on writing articles.", "paper_title": "An HMM-Based Algorithm for Content Ranking and Coherence-Feature Extraction", "paper_id": "WOS:000317614400017"}