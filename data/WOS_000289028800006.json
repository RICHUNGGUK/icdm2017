{"auto_keywords": [{"score": 0.039978282308139886, "phrase": "svm"}, {"score": 0.00481495049065317, "phrase": "quadratic_loss_multi-class_svm"}, {"score": 0.004637478829869904, "phrase": "radius-margin_bound"}, {"score": 0.003990385737207714, "phrase": "leave-one-out_error"}, {"score": 0.0031845067058084583, "phrase": "hard_margin_machine"}, {"score": 0.0027139447110929586, "phrase": "first_quadratic_loss_multi-class_svm"}, {"score": 0.0024014759148123736, "phrase": "direct_extension"}, {"score": 0.0022696277881969896, "phrase": "multi-class_case"}, {"score": 0.0021049977753042253, "phrase": "corresponding_generalized_radius-margin"}], "paper_keywords": ["multi-class SVMs", " model selection", " leave-one-out cross-validation error", " radius-margin bounds"], "paper_abstract": "To set the values of the hyperparameters of a support vector machine (SVM), the method of choice is cross-validation. Several upper bounds on the leave-one-out error of the pattern recognition SVM have been derived. One of the most popular is the radius-margin bound. It applies to the hard margin machine, and, by extension, to the 2-norm SVM. In this article, we introduce the first quadratic loss multi-class SVM: the M-SVM2. It can be seen as a direct extension of the 2-norm SVM to the multi-class case, which we establish by deriving the corresponding generalized radius-margin bound.", "paper_title": "A Quadratic Loss Multi-Class SVM for which a Radius-Margin Bound Applies", "paper_id": "WOS:000289028800006"}