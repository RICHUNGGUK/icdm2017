{"auto_keywords": [{"score": 0.03978021035630368, "phrase": "occluded_background_regions"}, {"score": 0.00481495049065317, "phrase": "complete_surfaces"}, {"score": 0.004605748839642513, "phrase": "scene_understanding"}, {"score": 0.003959863717046575, "phrase": "simple_and_general_approach"}, {"score": 0.0035908627899097407, "phrase": "visible_surrounding_background"}, {"score": 0.003527550673371394, "phrase": "detected_objects"}, {"score": 0.003434662174045939, "phrase": "shape_priors"}, {"score": 0.003374094774912924, "phrase": "transferred_training_regions"}, {"score": 0.002900426826591769, "phrase": "streetscenes"}, {"score": 0.0024930878032164757, "phrase": "proposed_approach"}, {"score": 0.002321665383971456, "phrase": "layered_support_surfaces"}, {"score": 0.0022806798371116698, "phrase": "rgb-depth_scenes"}, {"score": 0.0021049977753042253, "phrase": "competent_baselines"}], "paper_keywords": ["Scene understanding", " Image parsing", " Geometric layout", " RGB-depth"], "paper_abstract": "Scene understanding requires reasoning about both what we can see and what is occluded. We offer a simple and general approach to infer labels of occluded background regions. Our approach incorporates estimates of visible surrounding background, detected objects, and shape priors from transferred training regions. We demonstrate the ability to infer the labels of occluded background regions in three datasets: the outdoor StreetScenes dataset, IndoorScene dataset and SUN09 dataset, all using the same approach. Furthermore, the proposed approach is extended to 3D space to find layered support surfaces in RGB-Depth scenes. Our experiments and analysis show that our method outperforms competent baselines.", "paper_title": "Labeling Complete Surfaces in Scene Understanding", "paper_id": "WOS:000351518500004"}