{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "mapreduce_pattern"}, {"score": 0.0047563776685277314, "phrase": "parallel_computing_platforms"}, {"score": 0.00428629884026304, "phrase": "system_parallelism"}, {"score": 0.004208282550386197, "phrase": "previous_work"}, {"score": 0.0038154673253945003, "phrase": "compilation_approach"}, {"score": 0.0036107898615445797, "phrase": "field-programmable_gate_array"}, {"score": 0.003566850016466814, "phrase": "fpga"}, {"score": 0.0035233696341819437, "phrase": "based_parallel_computing_platforms"}, {"score": 0.0032336801561165113, "phrase": "geometric_programming_model"}, {"score": 0.0031360786664165093, "phrase": "loop-level_parallelism"}, {"score": 0.003022825806274343, "phrase": "optimal_implementation"}, {"score": 0.0028430608076324727, "phrase": "single_and_multiple_nested_mapreduce_patterns"}, {"score": 0.0027403605798830984, "phrase": "important_variations"}, {"score": 0.002706977532204992, "phrase": "mapreduce"}, {"score": 0.0026091594819333654, "phrase": "linear_structure"}, {"score": 0.0025459275963373496, "phrase": "tree_structure"}, {"score": 0.002499508839669243, "phrase": "intermediate_results"}, {"score": 0.0023944552329463035, "phrase": "six_benchmarks"}, {"score": 0.0023079225317714815, "phrase": "performance-optimal_designs"}, {"score": 0.00226583335721762, "phrase": "design_space"}, {"score": 0.002224510044064184, "phrase": "system_performance"}, {"score": 0.0021441057555396013, "phrase": "initial_designs"}, {"score": 0.0021049977753042253, "phrase": "target_platform"}], "paper_keywords": ["Parallel computing", " MapReduce", " Pipelining", " Geometric programming"], "paper_abstract": "The MapReduce pattern can be found in many important applications, and can be exploited to significantly improve system parallelism. Unlike previous work, in which designers explicitly specify how to exploit the pattern, we develop a compilation approach for mapping applications with the MapReduce pattern automatically onto Field-Programmable Gate Array (FPGA) based parallel computing platforms. We formulate the problem of mapping the MapReduce pattern to hardware as a geometric programming model; this model exploits loop-level parallelism and pipelining to give an optimal implementation on given hardware resources. The approach is capable of handling single and multiple nested MapReduce patterns. Furthermore, we explore important variations of MapReduce, such as using a linear structure rather than a tree structure for merging intermediate results generated in parallel. Results for six benchmarks show that our approach can find performance-optimal designs in the design space, improving system performance by up to 170 times compared to the initial designs on the target platform.", "paper_title": "Automated Mapping of the MapReduce Pattern onto Parallel Computing Platforms", "paper_id": "WOS:000300852200006"}