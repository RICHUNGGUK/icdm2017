{"auto_keywords": [{"score": 0.049655608595442415, "phrase": "auditory_scenes"}, {"score": 0.0074496569945985336, "phrase": "co-clustering_scheme"}, {"score": 0.00481495049065317, "phrase": "auditory_scene_categorization"}, {"score": 0.004730158389701481, "phrase": "temporal_audio_segments"}, {"score": 0.004688321299229397, "phrase": "coherent_semantic_content"}, {"score": 0.004524624065803229, "phrase": "similar_semantics"}, {"score": 0.004327981760540394, "phrase": "semantic_event_detection"}, {"score": 0.004048860957751714, "phrase": "mid-level_representations"}, {"score": 0.0038728151007982378, "phrase": "unsupervised_clustering_algorithms"}, {"score": 0.003804550737731054, "phrase": "group_scene_segments"}, {"score": 0.003543273649210823, "phrase": "audio_scenes"}, {"score": 0.0035118972210075633, "phrase": "unsupervised_manner"}, {"score": 0.003329368827624161, "phrase": "potential_grouping_trends"}, {"score": 0.003299880298525127, "phrase": "different_dimensions"}, {"score": 0.0032706520949775065, "phrase": "feature_spaces"}, {"score": 0.002811464848641341, "phrase": "bayesian_information_criterion"}, {"score": 0.0027865724584843505, "phrase": "bic"}, {"score": 0.0025492038831408715, "phrase": "categorization_results"}, {"score": 0.002470987929071079, "phrase": "better_performance"}, {"score": 0.002427372728532664, "phrase": "traditional_one-way_clustering_algorithms"}, {"score": 0.0023633857274905977, "phrase": "low-level_acoustic_features"}, {"score": 0.002321665383971456, "phrase": "mid-level_audio_effect_representations"}, {"score": 0.0021813467128927347, "phrase": "general_multimedia_data"}, {"score": 0.002123831297790248, "phrase": "preliminary_results"}, {"score": 0.0021049977753042253, "phrase": "content-based_image_clustering"}], "paper_keywords": ["audio content analysis", " auditory scene categorization", " co-clustering", " local feature grouping trends"], "paper_abstract": "Auditory scenes are temporal audio segments with coherent semantic content. Automatically classifying and grouping auditory scenes with similar semantics into categories is beneficial for many multimedia applications, such as semantic event detection and indexing. For such semantic categorization, auditory scenes are first characterized with either low-level acoustic features or some mid-level representations like audio effects, and then supervised classifiers or unsupervised clustering algorithms are employed to group scene segments into various semantic categories. In this paper, we focus on the problem of automatically categorizing audio scenes in unsupervised manner. To achieve more reasonable clustering results, we introduce the co-clustering scheme to exploit potential grouping trends among different dimensions of feature spaces (either low-level or mid-level feature spaces), and provide more accurate similarity measure for comparing auditory scenes. Moreover, we also extend the co-clustering scheme with a strategy based on the Bayesian information criterion (BIC) to automatically estimate the numbers of clusters. Evaluation performed on 272 auditory scenes extracted from 12-h audio data shows very encouraging categorization results. Co-clustering achieved a better performance compared to some traditional one-way clustering algorithms, both based on the low-level acoustic features and on the mid-level audio effect representations. Finally, we present our vision regarding the applicability of this approach on general multimedia data, and also show some preliminary results on content-based image clustering.", "paper_title": "Co-clustering for auditory scene categorization", "paper_id": "WOS:000258767200005"}