{"auto_keywords": [{"score": 0.04747711884700751, "phrase": "traditional_work-stealing_schedulers"}, {"score": 0.03976161679769431, "phrase": "laws"}, {"score": 0.014090723564469618, "phrase": "remote_memory_accesses"}, {"score": 0.00970482563562912, "phrase": "cache-friendly_subtrees"}, {"score": 0.00481495049065317, "phrase": "online_profiling"}, {"score": 0.00476697427418509, "phrase": "auto-tuning_for_multisocket_multicore_architectures"}, {"score": 0.004719473826242326, "phrase": "modern_mainstream_powerful_computers"}, {"score": 0.004672444473700524, "phrase": "multisocket_multicore_cpu_architecture"}, {"score": 0.004625881588444304, "phrase": "numa-based_memory_architecture"}, {"score": 0.004466519142879166, "phrase": "single-socket_architectures"}, {"score": 0.004377921202912336, "phrase": "severe_shared_cache"}, {"score": 0.0038431888954930083, "phrase": "memory_system"}, {"score": 0.003729335910488339, "phrase": "load-balanced_task_allocator"}, {"score": 0.003306559295382181, "phrase": "local_memory"}, {"score": 0.003129096013910626, "phrase": "adaptive_dag_packer"}, {"score": 0.0030823667846259836, "phrase": "auto-tuning_approach"}, {"score": 0.002816246391862638, "phrase": "cache-friendly_subtrees_sequentially"}, {"score": 0.0027741761880779535, "phrase": "shared_cache_usage"}, {"score": 0.0027054473441439422, "phrase": "triple-level_work-stealing_scheduler"}, {"score": 0.002509284173541882, "phrase": "theoretical_analysis"}, {"score": 0.002422661411769552, "phrase": "comparable_time"}, {"score": 0.002398464540102246, "phrase": "space_bounds"}, {"score": 0.002224510044064184, "phrase": "memory-bound_programs"}, {"score": 0.0021693692831601745, "phrase": "amd-based_experimental_platforms"}, {"score": 0.0021049977753042253, "phrase": "intel-based_experimental_platforms"}], "paper_keywords": ["Design", " Algorithms", " Performance", " Memory subsystem", " History-based auto-tuning", " Task scheduling"], "paper_abstract": "Modern mainstream powerful computers adopt multisocket multicore CPU architecture and NUMA-based memory architecture. While traditional work-stealing schedulers are designed for single-socket architectures, they incur severe shared cache misses and remote memory accesses in these computers. To solve the problem, we propose a locality-aware work-stealing (LAWS) scheduler, which better utilizes both the shared cache and the memory system. In LAWS, a load-balanced task allocator is used to evenly split and store the dataset of a program to all the memory nodes and allocate a task to the socket where the local memory node stores its data for reducing remote memory accesses. Then, an adaptive DAG packer adopts an auto-tuning approach to optimally pack an execution DAG into cache-friendly subtrees. After cache-friendly subtrees are created, every socket executes cache-friendly subtrees sequentially for optimizing shared cache usage. Meanwhile, a triple-level work-stealing scheduler is applied to schedule the subtrees and the tasks in each subtree. Through theoretical analysis, we show that LAWS has comparable time and space bounds compared with traditional work-stealing schedulers. Experimental results show that LAWS can improve the performance of memory-bound programs up to 54.2% on AMD-based experimental platforms and up to 48.6% on Intel-based experimental platforms compared with traditional work-stealing schedulers.", "paper_title": "Locality-Aware Work Stealing Based on Online Profiling and Auto-Tuning for Multisocket Multicore Architectures", "paper_id": "WOS:000357952000014"}