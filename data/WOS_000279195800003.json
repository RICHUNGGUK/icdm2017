{"auto_keywords": [{"score": 0.03484489650352155, "phrase": "proposed_method"}, {"score": 0.007994834273460746, "phrase": "imaging_conditions"}, {"score": 0.006455923050773541, "phrase": "color_models"}, {"score": 0.00481495049065317, "phrase": "photometric_invariance"}, {"score": 0.004781777766309739, "phrase": "object_detection"}, {"score": 0.004699837689671504, "phrase": "powerful_visual_cue"}, {"score": 0.004619295212985837, "phrase": "image_segmentation"}, {"score": 0.004587464246981363, "phrase": "object_recognition"}, {"score": 0.004477765573115626, "phrase": "existing_color_models"}, {"score": 0.004193000200816171, "phrase": "reflection_model"}, {"score": 0.004135388604075617, "phrase": "lambertian"}, {"score": 0.004008624230034271, "phrase": "color_invariant_models"}, {"score": 0.0038456073694665, "phrase": "real-world_scenes"}, {"score": 0.003805895710941199, "phrase": "different_reflectance_mechanisms"}, {"score": 0.0036133826040506798, "phrase": "color_invariance"}, {"score": 0.0035268943257252224, "phrase": "diversified_color_invariant_ensembles"}, {"score": 0.003466382911409225, "phrase": "photometrical_orthogonal_and_non-redundant_color_model"}, {"score": 0.0033834012029672423, "phrase": "color_variants"}, {"score": 0.0032121901685844803, "phrase": "diversified_color_ensemble"}, {"score": 0.0031789986177545586, "phrase": "proper_balance"}, {"score": 0.003102875178186416, "phrase": "discriminative_power"}, {"score": 0.002976581914095474, "phrase": "multi-view_approach"}, {"score": 0.0029356335847783195, "phrase": "estimation_error"}, {"score": 0.002825898877873034, "phrase": "data_uncertainty"}, {"score": 0.002796687674642564, "phrase": "properly_diversified_color_invariant_ensembles"}, {"score": 0.002692132776447632, "phrase": "temporal_data"}, {"score": 0.0024432508011008563, "phrase": "severe_variations"}, {"score": 0.0023356349192255074, "phrase": "parameter_tuning"}, {"score": 0.0023034836169432233, "phrase": "state-of-the-art_detection_techniques"}, {"score": 0.0022020103573658035, "phrase": "sequential_data"}, {"score": 0.0021343846011837204, "phrase": "future_observations"}], "paper_keywords": ["Object detection", " Color models", " Learning", " Photometric invariance", " Combining classifiers", " Diversified ensembles"], "paper_abstract": "Color is a powerful visual cue in many computer vision applications such as image segmentation and object recognition. However, most of the existing color models depend on the imaging conditions that negatively affect the performance of the task at hand. Often, a reflection model (e.g., Lambertian or dichromatic reflectance) is used to derive color invariant models. However, this approach may be too restricted to model real-world scenes in which different reflectance mechanisms can hold simultaneously. Therefore, in this paper, we aim to derive color invariance by learning from color models to obtain diversified color invariant ensembles. First, a photometrical orthogonal and non-redundant color model set is computed composed of both color variants and invariants. Then, the proposed method combines these color models to arrive at a diversified color ensemble yielding a proper balance between invariance (repeatability) and discriminative power (distinctiveness). To achieve this, our fusion method uses a multi-view approach to minimize the estimation error. In this way, the proposed method is robust to data uncertainty and produces properly diversified color invariant ensembles. Further, the proposed method is extended to deal with temporal data by predicting the evolution of observations over time. Experiments are conducted on three different image datasets to validate the proposed method. Both the theoretical and experimental results show that the method is robust against severe variations in imaging conditions. The method is not restricted to a certain reflection model or parameter tuning, and outperforms state-of-the-art detection techniques in the field of object, skin and road recognition. Considering sequential data, the proposed method (extended to deal with future observations) outperforms the other methods.", "paper_title": "Learning Photometric Invariance for Object Detection", "paper_id": "WOS:000279195800003"}