{"auto_keywords": [{"score": 0.043704949447414876, "phrase": "base_learners"}, {"score": 0.04278172255856689, "phrase": "functional_space"}, {"score": 0.00481495049065317, "phrase": "structured_sparse_boosting_for_graph_classification"}, {"score": 0.004709193603747991, "phrase": "highly_effective_algorithm"}, {"score": 0.004626255242038005, "phrase": "linear_combination"}, {"score": 0.004585332915477379, "phrase": "weak_classifiers"}, {"score": 0.004405596416783185, "phrase": "high-quality_classification_models"}, {"score": 0.004232875294230749, "phrase": "generalized_logit_boost_algorithm"}, {"score": 0.004139850082354509, "phrase": "structural_relationships"}, {"score": 0.0038556354709511818, "phrase": "emerging_topic"}, {"score": 0.003821503621554738, "phrase": "pattern-based_classification"}, {"score": 0.0036715973701254823, "phrase": "efficient_incorporation"}, {"score": 0.0036229421570951807, "phrase": "structure_information"}, {"score": 0.003527550673371394, "phrase": "general_model"}, {"score": 0.003434662174045939, "phrase": "undirected_graph"}, {"score": 0.0033442114331500407, "phrase": "subgraph-based_base_learners"}, {"score": 0.002900426826591769, "phrase": "efficient_optimization_algorithms"}, {"score": 0.002861961643289598, "phrase": "coordinate_descent"}, {"score": 0.002824005136794786, "phrase": "new_boosting_formulation"}, {"score": 0.0027252240573281163, "phrase": "natural_grouping_effect"}, {"score": 0.0027010719929751, "phrase": "nearby_spatial_or_overlapping_base_learners"}, {"score": 0.002482013330276732, "phrase": "logistic_regression"}, {"score": 0.0023845255359681143, "phrase": "vectorial_data"}, {"score": 0.0023010815714140467, "phrase": "comprehensive_experimental_study"}, {"score": 0.0021049977753042253, "phrase": "proposed_learning_method"}], "paper_keywords": ["Regularization", " structural sparsity", " graph classification", " semistructured data", " boosting", " logistic regression", " feature selection"], "paper_abstract": "Boosting is a highly effective algorithm that produces a linear combination of weak classifiers (a.k.a. base learners) to obtain high-quality classification models. In this article, we propose a generalized logit boost algorithm in which base learners have structural relationships in the functional space. Although such relationships are generic, our work is particularly motivated by the emerging topic of pattern-based classification for semistructured data including graphs. Toward an efficient incorporation of the structure information, we have designed a general model in which we use an undirected graph to capture the relationship of subgraph-based base learners. In our method, we employ both L-1 and Laplacian-based L-2 regularization to logit boosting to achieve model sparsity and smoothness in the functional space spanned by the base learners. We have derived efficient optimization algorithms based on coordinate descent for the new boosting formulation and theoretically prove that it exhibits a natural grouping effect for nearby spatial or overlapping base learners and that the resulting estimator is consistent. Additionally, motivated by the connection between logit boosting and logistic regression, we extend our structured sparse regularization framework to logistic regression for vectorial data in which features are structured. Using comprehensive experimental study and comparing our work with the state-of-the-art, we have demonstrated the effectiveness of the proposed learning method.", "paper_title": "Structured Sparse Boosting for Graph Classification", "paper_id": "WOS:000344353300004"}