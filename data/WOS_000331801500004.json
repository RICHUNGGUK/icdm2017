{"auto_keywords": [{"score": 0.047686709462732416, "phrase": "head_nod"}, {"score": 0.046760690112562876, "phrase": "eye_tracking"}, {"score": 0.015719716506582538, "phrase": "head_detection"}, {"score": 0.007737369741068755, "phrase": "directional_vector"}, {"score": 0.00478218760286811, "phrase": "tracking_systems"}, {"score": 0.004749646583168342, "phrase": "visual_surveillance"}, {"score": 0.0044512920090463105, "phrase": "head_motion_decision"}, {"score": 0.004405919996432158, "phrase": "eye_tracking_step"}, {"score": 0.004346139434813299, "phrase": "face_detection"}, {"score": 0.004316552692395911, "phrase": "eye_location"}, {"score": 0.004214569581360156, "phrase": "motion_segmentation_algorithm"}, {"score": 0.004129067429043414, "phrase": "people's_faces"}, {"score": 0.0040452928361255445, "phrase": "hidden_markov_model-based_head_detection_module"}, {"score": 0.003990385737207714, "phrase": "complete_detection"}, {"score": 0.003949693102823493, "phrase": "input_images"}, {"score": 0.00388278852285898, "phrase": "eye_tracking_module"}, {"score": 0.003778081566896723, "phrase": "candidate_list"}, {"score": 0.0037267877774290374, "phrase": "preprocessing_module"}, {"score": 0.003577032245103867, "phrase": "real-time_input_images"}, {"score": 0.0033982429092938764, "phrase": "edge_lines"}, {"score": 0.00332924643541238, "phrase": "face_area"}, {"score": 0.0032728171827367068, "phrase": "head_candidate"}, {"score": 0.003195414285736136, "phrase": "k-means_algorithm"}, {"score": 0.003152006152091526, "phrase": "head_region"}, {"score": 0.003014948673771347, "phrase": "detected_face_region"}, {"score": 0.002825251837733693, "phrase": "detected_eyes"}, {"score": 0.002777341265639153, "phrase": "normalized_vector"}, {"score": 0.0025848074189353397, "phrase": "hmm_representation"}, {"score": 0.0025236349164549877, "phrase": "underlying_hmm_states"}, {"score": 0.002480826434008026, "phrase": "face_images"}, {"score": 0.002285216591220303, "phrase": "head_movement"}, {"score": 0.0021049977753042253, "phrase": "notable_success"}], "paper_keywords": ["Head detection", " Head location", " Eye location", " Hidden Markov Models"], "paper_abstract": "This paper proposes a technique for the detection of head nod and shake gestures based on eye tracking and head motion decision. The eye tracking step is divided into face detection and eye location. Here, we apply a motion segmentation algorithm that examines differences in moving people's faces. This system utilizes a Hidden Markov Model-based head detection module that carries out complete detection in the input images, followed by the eye tracking module that refines the search based on a candidate list provided by the preprocessing module. The novelty of this paper is derived from differences in real-time input images, preprocessing to remove noises (morphological operators and so on), detecting edge lines and restoration, finding the face area, and cutting the head candidate. Moreover, we adopt a K-means algorithm for finding the head region. Real-time eye tracking extracts the location of eyes from the detected face region and is performed at close to a pair of eyes. After eye tracking, the coordinates of the detected eyes are transformed into a normalized vector of x-coordinate and y-coordinate. Head nod and shake detector uses three hidden Markov models (HMMs). HMM representation of the head detection can estimate the underlying HMM states from a sequence of face images. Head nod and shake can be detected by three HMMs that are adapted by a directional vector. The directional vector represents the direction of the head movement. The vector is HMMs for determining neutral as well as head nod and shake. These techniques are implemented on images, and notable success is notified.", "paper_title": "Development of head detection and tracking systems for visual surveillance", "paper_id": "WOS:000331801500004"}