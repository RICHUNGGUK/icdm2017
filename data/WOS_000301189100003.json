{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "hybrid_mpi"}, {"score": 0.0481268248059887, "phrase": "parallel_loop_self-scheduling_schemes"}, {"score": 0.03963329481008675, "phrase": "computing_node"}, {"score": 0.03720707411991549, "phrase": "processor_core"}, {"score": 0.004758053266234474, "phrase": "openmp_programming"}, {"score": 0.004149922666541166, "phrase": "heterogeneous_cluster_systems"}, {"score": 0.003980687255880282, "phrase": "mpi_programming_model"}, {"score": 0.003728529119516347, "phrase": "multicore_architecture"}, {"score": 0.0033898953358387075, "phrase": "master_node"}, {"score": 0.0033299015941662302, "phrase": "new_tasks"}, {"score": 0.0031939996970411027, "phrase": "processor_cores"}, {"score": 0.002991524908432975, "phrase": "underlying_shared_memory"}, {"score": 0.0028693932802982417, "phrase": "higher_communication_overhead"}, {"score": 0.0026874405408023956, "phrase": "openmp_programming_model"}, {"score": 0.002639845784408318, "phrase": "two-level_parallel_loop_self-scheduling_schemes"}, {"score": 0.002472412920623605, "phrase": "mpi_process"}, {"score": 0.0024431289979171505, "phrase": "inter-node_communications"}, {"score": 0.002385595105638277, "phrase": "second_level"}, {"score": 0.0023018188296933923, "phrase": "openmp_thread"}, {"score": 0.002181626277903721, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "previous_works"}], "paper_keywords": ["Parallel loop scheduling", " Cluster computing", " Multicore architecture", " MPI programming", " OpenMP programming", " Hybrid programming"], "paper_abstract": "Recently, a series of parallel loop self-scheduling schemes have been proposed, especially for heterogeneous cluster systems. However, they employed the MPI programming model to construct the applications without considering whether the computing node is multicore architecture or not. As a result, every processor core has to communicate directly with the master node for requesting new tasks no matter the fact that the processor cores on the same node can communicate with each other through the underlying shared memory. To address the problem of higher communication overhead, in this paper we propose to adopt hybrid MPI and OpenMP programming model to design two-level parallel loop self-scheduling schemes. In the first level, each computing node runs an MPI process for inter-node communications. In the second level, each processor core runs an OpenMP thread to execute the iterations assigned for its resident node. Experimental results show that our method outperforms the previous works.", "paper_title": "Using hybrid MPI and OpenMP programming to optimize communications in parallel loop self-scheduling schemes for multicore PC clusters", "paper_id": "WOS:000301189100003"}