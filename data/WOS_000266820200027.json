{"auto_keywords": [{"score": 0.03424383087472138, "phrase": "virtual_table"}, {"score": 0.010872854450566294, "phrase": "btb"}, {"score": 0.009924345167561183, "phrase": "dedicated_storage"}, {"score": 0.00481495049065317, "phrase": "virtualized_branch_target_buffer_design"}, {"score": 0.0047709540557306284, "phrase": "modern_processors"}, {"score": 0.0047273577269638725, "phrase": "branch_target_buffers"}, {"score": 0.004577869668211548, "phrase": "target_address"}, {"score": 0.004352411290383643, "phrase": "instruction_stream"}, {"score": 0.004044064541716598, "phrase": "entire_working_set"}, {"score": 0.0038981499110532307, "phrase": "fast_access"}, {"score": 0.0038624981944755813, "phrase": "practical_on-chip_dedicated_storage"}, {"score": 0.0035722806911457545, "phrase": "btb_design"}, {"score": 0.0035233696341819437, "phrase": "large_instruction_footprints"}, {"score": 0.0034433297275344877, "phrase": "-chip_resources"}, {"score": 0.0031991799574455555, "phrase": "branch_target_information"}, {"score": 0.00283870598459543, "phrase": "on-chip_caches"}, {"score": 0.002799810685137358, "phrase": "cache_line_granularity"}, {"score": 0.0026252106881752067, "phrase": "dedicated_conventional_btb"}, {"score": 0.0025420267431501367, "phrase": "experimental_results"}, {"score": 0.002518746501941657, "phrase": "commercial_workloads"}, {"score": 0.002427732996314194, "phrase": "pbtb"}, {"score": 0.002405496949144104, "phrase": "ipc_performance"}, {"score": 0.0022450768409733807, "phrase": "storage_overhead"}], "paper_keywords": ["Design", " Performance", " Measurement", " Predictor Metadata Prefetching", " Predictor Virtualization", " Branch Target Buffer"], "paper_abstract": "Modern processors use branch target buffers (BTBs) to predict the target address of branches such that they can fetch ahead in the instruction stream increasing concurrency and performance. Ideally, BTBs would be sufficiently large to capture the entire working set of the application and sufficiently small for fast access and practical on-chip dedicated storage. Depending on the application, these requirements are at odds. This work introduces a BTB design that accommodates large instruction footprints without dedicating expensive on-chip resources. In the proposed Phantom-BTB (PBTB) design, a conventional BTB is augmented with a virtual table that collects branch target information as the application runs. The virtual table does not have fixed dedicated storage. Instead, it is transparently allocated, on demand, in the on-chip caches, at cache line granularity. The entries in the virtual table are proactively prefetched and installed in the dedicated conventional BTB, thus, increasing its perceived capacity. Experimental results with commercial workloads under full-system simulation demonstrate that PBTB improves IPC performance over a 1K-entry BTB by 6.9% on average and up to 12.7%, with a storage overhead of only 8%. Overall, the virtualized design performs within 1% of a conventional 4K-entry, single-cycle access BTB, while the dedicated storage is 3.6 times smaller.", "paper_title": "Phantom-BTB: A Virtualized Branch Target Buffer Design", "paper_id": "WOS:000266820200027"}