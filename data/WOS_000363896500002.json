{"auto_keywords": [{"score": 0.043211748297316055, "phrase": "feature_space"}, {"score": 0.015170921215896329, "phrase": "image_classification"}, {"score": 0.004814971944289977, "phrase": "bregman"}, {"score": 0.004435363840720883, "phrase": "novel_feature-space_local_pooling_method"}, {"score": 0.004064653055162238, "phrase": "visual_appearance"}, {"score": 0.004002513373645485, "phrase": "pooling_bins"}, {"score": 0.0037057255600764475, "phrase": "smaller_number"}, {"score": 0.003413284742632989, "phrase": "visual_prototypes"}, {"score": 0.003343841875107018, "phrase": "similar_images"}, {"score": 0.0030798711656591948, "phrase": "bregman_co-clustering"}, {"score": 0.0030640804704319255, "phrase": "applied_offline"}, {"score": 0.002986329509791943, "phrase": "training_data"}, {"score": 0.0028659990472580154, "phrase": "semantic_context"}, {"score": 0.0028221322455573624, "phrase": "input_image"}, {"score": 0.0027646829399573434, "phrase": "higher_discriminative_power"}, {"score": 0.0026806884201358515, "phrase": "appearance-based_partitioning"}, {"score": 0.0023816257768353344, "phrase": "proposed_method"}, {"score": 0.0023331227492950422, "phrase": "previous_works"}, {"score": 0.0021487685525986094, "phrase": "spatial_pyramid"}, {"score": 0.0021049977753042253, "phrase": "comparable_results"}], "paper_keywords": ["Image classification", " Image representation", " Feature pooling", " Co-clustering", " Bregman divergence"], "paper_abstract": "In this paper, we propose a novel feature-space local pooling method for the commonly adopted architecture of image classification. While existing methods partition the feature space based on visual appearance to obtain pooling bins, learning more accurate space partitioning that takes semantics into account boosts performance even for a smaller number of bins. To this end, we propose partitioning the feature space over clusters of visual prototypes common to semantically similar images (i.e., images belonging to the same category). The clusters are obtained by Bregman co-clustering applied offline on a subset of training data. Therefore, being aware of the semantic context of the input image, our features have higher discriminative power than do those pooled from appearance-based partitioning. Testing on four datasets (Caltech-101, Caltech-256, 15 Scenes, and 17 Flowers) belonging to three different classification tasks showed that the proposed method outperforms methods in previous works on local pooling in the feature space for less feature dimensionality. Moreover, when implemented within a spatial pyramid, our method achieves comparable results on three of the datasets used.", "paper_title": "Bregman pooling: feature-space local pooling for image classification", "paper_id": "WOS:000363896500002"}