{"auto_keywords": [{"score": 0.043106896934820046, "phrase": "decision_tree"}, {"score": 0.00481495049065317, "phrase": "new_decision_tree_algorithm"}, {"score": 0.004784909348794283, "phrase": "based_on_rough_set_theory._decision_trees"}, {"score": 0.004551199992546761, "phrase": "classification_systems"}, {"score": 0.003795335309109018, "phrase": "minimum_number"}, {"score": 0.0036782824183282823, "phrase": "iterative_dichotomiser"}, {"score": 0.0025409639091476363, "phrase": "rough_set_theory"}, {"score": 0.0023419588513908783, "phrase": "experimental_comparisons"}, {"score": 0.002298288831092204, "phrase": "new_decision_tree_algorithms"}, {"score": 0.0021995257343837547, "phrase": "rough_set_approach"}, {"score": 0.0021049977753042253, "phrase": "rule_simplification"}], "paper_keywords": ["Rough set", " Decision tree", " Reduct"], "paper_abstract": "Decision trees are often used in data mining and classification systems because they are easily interpreted, accurate, and fast. One important step in constructing a decision tree is the selection of node attributes so that the tree has a minimum number of branches. While Iterative Dichotomiser 3 (ID3) and C4.5 are the best known of the many decision tree induction algorithms, they do not consider the dependency between entities or the importance of the attributes to the classification. Here, we present two new decision tree classification algorithms, the entity attribute decision tree (EDT) and the reduct attribute decision tree (RDT). These are based on rough set theory and on comparing the values of attributes between entities. We performed experimental comparisons of the new decision tree algorithms with ID3 and C4.5 using the rough set approach to show their advantages of accuracy and rule simplification.", "paper_title": "A NEW DECISION TREE ALGORITHM BASED ON ROUGH SET THEORY", "paper_id": "WOS:000260104100027"}