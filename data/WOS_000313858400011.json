{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "supervised_feature_selection"}, {"score": 0.04206483306533287, "phrase": "sotoca"}, {"score": 0.03593976593369695, "phrase": "objective_function"}, {"score": 0.004742511243894382, "phrase": "conditional_mutual_information-based_distances"}, {"score": 0.004618342952383313, "phrase": "important_problem"}, {"score": 0.004583464412234181, "phrase": "pattern_recognition"}, {"score": 0.004396267325338022, "phrase": "mutual_information"}, {"score": 0.004363058588000252, "phrase": "conditional_mutual_information_measures"}, {"score": 0.004121826934975274, "phrase": "interesting_paper"}, {"score": 0.003953694652922777, "phrase": "vol"}, {"score": 0.003501452436803395, "phrase": "conditional_mutual_information_based_distance_measure"}, {"score": 0.0031845067058084583, "phrase": "upper_bound"}, {"score": 0.0031484483754909026, "phrase": "information_loss"}, {"score": 0.0031127970604842375, "phrase": "full_set"}, {"score": 0.0030311679447397725, "phrase": "smaller_subset"}, {"score": 0.0026945722090537397, "phrase": "reported_work"}, {"score": 0.002643888053328987, "phrase": "specific_conditions"}, {"score": 0.002413531395475291, "phrase": "reasonable_condition"}, {"score": 0.0023235629819760018, "phrase": "class_variable"}, {"score": 0.0022711961447468114, "phrase": "popular_naive_bayes_classifier"}, {"score": 0.002169968849836984, "phrase": "pla's_framework"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Feature selection", " Conditional mutual information", " Mutual information properties", " Clustering", " Classification", " Naive Bayes classifier"], "paper_abstract": "Supervised feature selection is an important problem in pattern recognition. Of the many methods introduced, those based on the mutual information and conditional mutual information measures are among the most widely adopted approaches. In this paper, we re-analyze an interesting paper on this topic recently published by Sotoca and Pla (Pattern Recognition, Vol. 43 Issue 6, June, 2010, pp. 2068-2081). In that work, a method for supervised feature selection based on clustering the features into groups is proposed, using a conditional mutual information based distance measure. The clustering procedure minimizes the objective function named the minimal relevant redundancy-mRR criterion. It is proposed that this objective function is the upper bound of the information loss when the full set of features is replaced by a smaller subset. We have found that their proof for this proposition is based on certain erroneous assumptions, and that the proposition itself is not true in general. In order to remedy the reported work, we characterize the specific conditions under which the assumptions used in the proof, and hence the proposition, hold true. It is our finding that there is a reasonable condition, namely when all features are independent given the class variable (as assumed by the popular naive Bayes classifier), under which the assumptions as required by Sotoca and Pla's framework hold true. (C) 2012 Elsevier Ltd. All rights reserved.", "paper_title": "Comments on supervised feature selection by clustering using conditional mutual information-based distances", "paper_id": "WOS:000313858400011"}