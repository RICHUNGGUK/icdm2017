{"auto_keywords": [{"score": 0.045319229878670764, "phrase": "motion_fields"}, {"score": 0.00481495049065317, "phrase": "video_analysis"}, {"score": 0.004630150894006861, "phrase": "general_method"}, {"score": 0.004530552828603269, "phrase": "video_frames"}, {"score": 0.00443308765153716, "phrase": "conventional_appearance-based_methods"}, {"score": 0.004300133642951283, "phrase": "original_videos"}, {"score": 0.00420760449108585, "phrase": "huge_memory_requirement"}, {"score": 0.004135010810625326, "phrase": "previous_approaches"}, {"score": 0.004010960493946656, "phrase": "motion_vectors"}, {"score": 0.003993544228876303, "phrase": "\"_model"}, {"score": 0.003924629168434799, "phrase": "gaussian_mixture_model"}, {"score": 0.0038906171474520756, "phrase": "compact_representation"}, {"score": 0.0035507457285983268, "phrase": "earth_mover_distance"}, {"score": 0.0033553473725594003, "phrase": "inter-frame_distance"}, {"score": 0.00326881479036966, "phrase": "distance_measures"}, {"score": 0.0032263862712733934, "phrase": "full_video_sequences"}, {"score": 0.003062091606343783, "phrase": "tangent_vector_field"}, {"score": 0.002918826667294298, "phrase": "intensity_gradient_space"}, {"score": 0.002831158147480665, "phrase": "former_space"}, {"score": 0.002640507929183363, "phrase": "generative_model"}, {"score": 0.002629026692001082, "phrase": "named_dynamic_conditional_random_fields"}, {"score": 0.0024842242921857705, "phrase": "markov_volumetric_regression"}, {"score": 0.0023782753249846794, "phrase": "rank_deficiency_problem"}, {"score": 0.0023168823213024856, "phrase": "video_distance"}, {"score": 0.00226693109377084, "phrase": "human_intuition"}, {"score": 0.0022277448907881306, "phrase": "better_tradeoff"}, {"score": 0.0022084059770026416, "phrase": "frame_dissimilarity"}, {"score": 0.0021892345747666977, "phrase": "chronological_ordering"}, {"score": 0.002132711053003407, "phrase": "frame_distance"}, {"score": 0.0021049977753042253, "phrase": "partial_distance"}], "paper_keywords": ["video analysis", " motion field", " activity classification"], "paper_abstract": "In this work, we propose a general method for computing distance between video frames or sequences. Unlike conventional appearance-based methods, we first extract motion fields from original videos. To avoid the huge memory requirement demanded by the previous approaches, we utilize the \"bag of motion vectors\" model, and select Gaussian mixture model as compact representation. Thus, estimating distance between two frames is equivalent to calculating the distance between their corresponding Gaussian mixture models, which is solved via earth mover distance (EMD) in this paper. On the basis of the inter-frame distance, we further develop the distance measures for both full video sequences. Our main contribution is four-fold. Firstly, we operate on a tangent vector field of spatio-temporal 2D surface manifold generated by video motions, rather than the intensity gradient space. Here we argue that the former space is more fundamental. Secondly, the correlations between frames are explicitly exploited using a generative model named dynamic conditional random fields (DCRF). Under this framework, motion fields are estimated by Markov volumetric regression, which is more robust and may avoid the rank deficiency problem. Thirdly, our definition for video distance is in accord with human intuition and makes a better tradeoff between frame dissimilarity and chronological ordering. Lastly, our definition for frame distance allows for partial distance.", "paper_title": "Contextual motion field-based distance for video analysis", "paper_id": "WOS:000257384800015"}