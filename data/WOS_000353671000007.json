{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "ramp_transformation"}, {"score": 0.0047872135686404275, "phrase": "single_image_super-resolution"}, {"score": 0.004691380685111258, "phrase": "explicitly_identified_image_structure"}, {"score": 0.004466519142879166, "phrase": "homogeneous_regions"}, {"score": 0.004415189385015778, "phrase": "ramp_edges"}, {"score": 0.004377077848734575, "phrase": "larger_contrast"}, {"score": 0.004215677131963292, "phrase": "ramp_pixel"}, {"score": 0.004013524489681638, "phrase": "intensity_values"}, {"score": 0.003921763664916815, "phrase": "large_contrast"}, {"score": 0.0038099959232779194, "phrase": "sr_problem"}, {"score": 0.0036482665232275583, "phrase": "relatively_homogeneous_interiors"}, {"score": 0.003595891416028495, "phrase": "simpler_methods"}, {"score": 0.003443219062200627, "phrase": "learnt_transformations"}, {"score": 0.0033839745649214548, "phrase": "test_image"}, {"score": 0.003297007337505949, "phrase": "transformed_ramps"}, {"score": 0.0032496585171039797, "phrase": "regularization_framework"}, {"score": 0.0032122679403131537, "phrase": "traditional_backprojection_constraint"}, {"score": 0.003166132209407694, "phrase": "data_term"}, {"score": 0.003120657021758196, "phrase": "conventional_edge"}, {"score": 0.0031116404200520614, "phrase": "based_sr_methods"}, {"score": 0.002911278281894321, "phrase": "heuristically_chosen_parameters"}, {"score": 0.002861160152640875, "phrase": "different_gradient_values"}, {"score": 0.0028037753646260937, "phrase": "gradient_domain_correspondences"}, {"score": 0.002787591531872224, "phrase": "different_resolutions"}, {"score": 0.0027475383418803724, "phrase": "ramp_profiles"}, {"score": 0.002608040688794517, "phrase": "absolute_brightness_levels"}, {"score": 0.0025044454602720597, "phrase": "image_intensity_domain"}, {"score": 0.0024541975028954497, "phrase": "brightness_consistency"}, {"score": 0.002411929059405882, "phrase": "previous_gradient_based_methods"}, {"score": 0.0023566987138026285, "phrase": "closely_spaced_edges"}, {"score": 0.0023363141951290526, "phrase": "ramp_correspondences"}, {"score": 0.0023027301589859496, "phrase": "better_recovery"}, {"score": 0.002276210060619432, "phrase": "thin_structures"}, {"score": 0.0022499947003073654, "phrase": "high_spatial_frequency_areas"}, {"score": 0.0021668575137633317, "phrase": "true_image_color"}, {"score": 0.002141898874982106, "phrase": "almost_no_ringing_artifacts"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Super-resolution", " Segmentation", " Low-level vision"], "paper_abstract": "We propose the use of explicitly identified image structure to guide the solution of the single image super-resolution (SR) problem. We treat the image as a layout of homogeneous regions, surrounded by ramp edges of a larger contrast. Ramps are characterized by the property that any path through any ramp pixel, monotonically leading from one to the other side, has monotonically increasing (or decreasing) intensity values along it. Such a ramp profile thus captures the large contrast between the two homogeneous regions. In this paper, the SR problem is viewed primarily as one of super-resolving these ramps, since the relatively homogeneous interiors can be handled using simpler methods. Our approach involves learning how these ramps transform across resolutions, and applying the learnt transformations to the ramps of a test image. To obtain our final SR reconstruction, we use the transformed ramps as priors in a regularization framework, where the traditional backprojection constraint is used as the data term. As compared to conventional edge based SR methods, our approach provides three distinct advantages: (1) Conventional edge based SR methods are based on gradients, which use 2D filters with heuristically chosen parameters and these choices result in different gradient values. This sensitivity adversely affects learning gradient domain correspondences across different resolutions. We show that ramp profiles are more adaptive, stable and therefore reliable representations for learning edge transformations across resolutions. (2) Existing gradient based SR methods are often unable to sufficiently constrain the absolute brightness levels in the image. Our approach on the other hand, operates directly in the image intensity domain, enforcing sharpness as well as brightness consistency. (3) Unlike previous gradient based methods, we also explicitly incorporate dependency between closely spaced edges while learning ramp correspondences. This allows for better recovery of contrast across thin structures such as in high spatial frequency areas. We obtain results that are sharper and more faithful to the true image color, and show almost no ringing artifacts. (C) 2015 Elsevier Inc. All rights reserved.", "paper_title": "Learning ramp transformation for single image super-resolution", "paper_id": "WOS:000353671000007"}