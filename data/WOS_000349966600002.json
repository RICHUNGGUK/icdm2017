{"auto_keywords": [{"score": 0.04437825901136091, "phrase": "vrm"}, {"score": 0.015719709579057044, "phrase": "vicinal-risk_minimization"}, {"score": 0.0041001740903338834, "phrase": "training_genetic_programming_classifiers"}, {"score": 0.0036553070575015344, "phrase": "attractive_properties"}, {"score": 0.003372844338742438, "phrase": "better_correlation"}, {"score": 0.003296212583539166, "phrase": "generalization_error"}, {"score": 0.0031845067058084583, "phrase": "empirical_risk_minimization"}, {"score": 0.002806256131739047, "phrase": "better_generalization_performance"}, {"score": 0.002530359917257626, "phrase": "statistical_tests"}, {"score": 0.0023889533502525527, "phrase": "real_and_synthetic_datasets"}, {"score": 0.0021789194955896124, "phrase": "consistently_superior_generalization_errors"}, {"score": 0.0021049977753042253, "phrase": "conventional_erm."}], "paper_keywords": ["Genetic programming", " Classification", " Vicinal-risk minimization"], "paper_abstract": "We propose and motivate the use of vicinal-risk minimization (VRM) for training genetic programming classifiers. We demonstrate that VRM has a number of attractive properties and demonstrate that it has a better correlation with generalization error compared to empirical risk minimization (ERM) so is more likely to lead to better generalization performance, in general. From the results of statistical tests over a range of real and synthetic datasets, we further demonstrate that VRM yields consistently superior generalization errors compared to conventional ERM.", "paper_title": "Training genetic programming classifiers by vicinal-risk minimization", "paper_id": "WOS:000349966600002"}