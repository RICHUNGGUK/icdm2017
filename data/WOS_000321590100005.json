{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "structural_sparsity"}, {"score": 0.004645057834614705, "phrase": "powerful_tools"}, {"score": 0.004597622380240611, "phrase": "machine_learning_and_data_mining_techniques"}, {"score": 0.004256895619944631, "phrase": "accurate_black_box_predictors"}, {"score": 0.004106612344123407, "phrase": "white_box_mechanisms"}, {"score": 0.004002513373645485, "phrase": "predictive_patterns"}, {"score": 0.0034308688638878286, "phrase": "increasing_attentions"}, {"score": 0.003378385493203297, "phrase": "previous_research"}, {"score": 0.002940626369102927, "phrase": "explicit_and_group_norm"}, {"score": 0.0027646829399573434, "phrase": "intractable_optimizations"}, {"score": 0.0026945086500597304, "phrase": "general_lipschitz_auxiliary_function"}, {"score": 0.00263965046277432, "phrase": "simple_iterative_algorithms"}, {"score": 0.002559444836360178, "phrase": "optimal_solution"}, {"score": 0.002494466951433885, "phrase": "induced_subproblem"}, {"score": 0.0023451553255837317, "phrase": "local_convergent_rate"}, {"score": 0.0022161333611134806, "phrase": "multitask_feature_learning_problem"}], "paper_keywords": ["Structural sparsity", " Sparse learning", " Multitask learning"], "paper_abstract": "As powerful tools, machine learning and data mining techniques have been widely applied in various areas. However, in many real-world applications, besides establishing accurate black box predictors, we are also interested in white box mechanisms, such as discovering predictive patterns in data that enhance our understanding of underlying physical, biological and other natural processes. For these purposes, sparse representation and its variations have been one of the focuses. More recently, structural sparsity has attracted increasing attentions. In previous research, structural sparsity was often achieved by imposing convex but non-smooth norms such as and group norms. In this paper, we present the explicit and group norm to directly approach the structural sparsity. To tackle the problem of intractable optimizations, we develop a general Lipschitz auxiliary function that leads to simple iterative algorithms. In each iteration, optimal solution is achieved for the induced subproblem and a guarantee of convergence is provided. Furthermore, the local convergent rate is also theoretically bounded. We test our optimization techniques in the multitask feature learning problem. Experimental results suggest that our approaches outperform other approaches in both synthetic and real-world data sets.", "paper_title": "Toward structural sparsity: an explicit approach", "paper_id": "WOS:000321590100005"}