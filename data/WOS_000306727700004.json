{"auto_keywords": [{"score": 0.026247161753710568, "phrase": "opencl"}, {"score": 0.01976034433479718, "phrase": "cuda."}, {"score": 0.00491209413138525, "phrase": "gpgpu."}, {"score": 0.00481495049065317, "phrase": "performance-portable_solution"}, {"score": 0.004774937143916685, "phrase": "multi-platform_gpu_programming"}, {"score": 0.0045607070754363245, "phrase": "programming_tool"}, {"score": 0.004503959683578956, "phrase": "performance-portable_applications"}, {"score": 0.004410938507689426, "phrase": "khronos_group"}, {"score": 0.004337900700685262, "phrase": "programming_portability"}, {"score": 0.004108742905942481, "phrase": "performance-impacting_initializations"}, {"score": 0.003970233339468379, "phrase": "trsm"}, {"score": 0.0038112201846057445, "phrase": "single_library"}, {"score": 0.0037795163893761027, "phrase": "decent_performance"}, {"score": 0.0036400696415545813, "phrase": "triangular_solver"}, {"score": 0.0035648266669315943, "phrase": "matrix_multiplication"}, {"score": 0.0034911335714333507, "phrase": "representative_level"}, {"score": 0.0034620831765465425, "phrase": "blas_routines"}, {"score": 0.003306559295382181, "phrase": "time_distribution"}, {"score": 0.003265365666305185, "phrase": "opencl_runtime_system"}, {"score": 0.003197843245296877, "phrase": "tuned_gemm_kernels"}, {"score": 0.00290473242917264, "phrase": "texture_cache"}, {"score": 0.0027395968397212053, "phrase": "opencl_and_cuda_compilers'_optimizations"}, {"score": 0.002627407106087633, "phrase": "experimental_results"}, {"score": 0.0025730425700096365, "phrase": "peak_performance"}, {"score": 0.002158505888557746, "phrase": "search_harness"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Hardware accelerators", " Portability", " Auto-tuning"], "paper_abstract": "In this work, we evaluate OpenCL as a programming tool for developing performance-portable applications for GPGPU. While the Khronos group developed OpenCL with programming portability in mind, performance is not necessarily portable. OpenCL has required performance-impacting initializations that do not exist in other languages such as CUDA. Understanding these implications allows us to provide a single library with decent performance on a variety of platforms. We choose triangular solver (TRSM) and matrix multiplication (GEMM) as representative level 3 BLAS routines to implement in OpenCL We profile TRSM to get the time distribution of the OpenCL runtime system. We then provide tuned GEMM kernels for both the NVIDIA Tesla C2050 and ATI Radeon 5870, the latest GPUs offered by both companies. We explore the benefits of using the texture cache, the performance ramifications of copying data into images, discrepancies in the OpenCL and CUDA compilers' optimizations, and other issues that affect the performance. Experimental results show that nearly 50% of peak performance can be obtained in GEMM on both GPUs in OpenCL We also show that the performance of these kernels is not highly portable. Finally, we propose the use of auto-tuning to better explore these kernels' parameter space using search harness. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "From CUDA to OpenCL: Towards a performance-portable solution for multi-platform GPU programming", "paper_id": "WOS:000306727700004"}