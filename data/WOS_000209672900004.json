{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "concurrent_programs"}, {"score": 0.014677738722640969, "phrase": "concurrent_runs"}, {"score": 0.013259318217170976, "phrase": "data_races"}, {"score": 0.013186622772741876, "phrase": "atomicity_violations"}, {"score": 0.004788327412856401, "phrase": "ai_automated_planning_techniques"}, {"score": 0.004709333998298903, "phrase": "challenging_problem"}, {"score": 0.004670325028652672, "phrase": "interleaving_explosion"}, {"score": 0.004606023493393774, "phrase": "fixed_set"}, {"score": 0.004517479191423587, "phrase": "huge_number"}, {"score": 0.004381749459671914, "phrase": "scheduler_behavior"}, {"score": 0.004333406378146173, "phrase": "possible_schedules"}, {"score": 0.004203183846976328, "phrase": "select_subset"}, {"score": 0.0039543149184722804, "phrase": "large_proportion"}, {"score": 0.0039324317085106105, "phrase": "concurrency_bugs"}, {"score": 0.0038460985534832237, "phrase": "general_approach"}, {"score": 0.0038248119140797984, "phrase": "concurrent_program_testing"}, {"score": 0.003751228706861377, "phrase": "artificial_intelligence"}, {"score": 0.00370981613076245, "phrase": "automated_planning"}, {"score": 0.003628352506247126, "phrase": "concurrent_program"}, {"score": 0.0035585353595660708, "phrase": "generic_correctness_specifications"}, {"score": 0.0034324073240680213, "phrase": "null-pointer_dereferences"}, {"score": 0.003347707505274641, "phrase": "arbitrary_run"}, {"score": 0.0031405975280029913, "phrase": "new_runs"}, {"score": 0.0029791773211792277, "phrase": "ai_sequential_planning_problem"}, {"score": 0.0029544572689681934, "phrase": "temporally_extended_goal"}, {"score": 0.002921815042028607, "phrase": "particular_violation_pattern"}, {"score": 0.002779318608820933, "phrase": "predicted_runs"}, {"score": 0.002718231974492536, "phrase": "generated_runs"}, {"score": 0.002564175487633413, "phrase": "violation_patterns"}, {"score": 0.0025287979714720423, "phrase": "selection_criteria"}, {"score": 0.002486987042061596, "phrase": "state_space"}, {"score": 0.0024121165531533545, "phrase": "planning_goal"}, {"score": 0.0023656467839555458, "phrase": "state-of-the-art_ai_planning_techniques"}, {"score": 0.0023265270905455334, "phrase": "penelope_concurrent_program_testing_framework"}, {"score": 0.0022129983153880467, "phrase": "program_testing_frameworks"}, {"score": 0.0021824553326294702, "phrase": "benchmark_suite"}, {"score": 0.0021049977753042253, "phrase": "known_bugs"}], "paper_keywords": ["Concurrent programs", " Testing", " AI planning"], "paper_abstract": "Testing concurrent programs is a challenging problem due to interleaving explosion: even for a fixed set of inputs, there is a huge number of concurrent runs that need to be tested to account for scheduler behavior. Testing all possible schedules is not practical. Consequently, most effective testing algorithms only test a select subset of runs. For example, limiting testing to runs that contain data races or atomicity violations has been shown to capture a large proportion of concurrency bugs. In this paper we present a general approach to concurrent program testing that is based on techniques from artificial intelligence (AI) automated planning. We propose a framework for predicting concurrent program runs that violate a collection of generic correctness specifications for concurrent programs, namely runs that contain data races, atomicity violations, or null-pointer dereferences. Our prediction is based on observing an arbitrary run of the program, and using information collected from this run to model the behavior of the program, and to predict new runs that contain bugs with one of the above noted violation patterns. We characterize the problem of predicting such new runs as an AI sequential planning problem with the temporally extended goal of achieving a particular violation pattern. In contrast to many state-of-the-art approaches, in our approach feasibility of the predicted runs is guaranteed and, therefore, all generated runs are fully usable for testing. Moreover, our planning-based approach has the merit that it can easily accommodate a variety of violation patterns which serve as the selection criteria for guiding search in the state space of concurrent runs. This is achieved by simply modifying the planning goal. We have implemented our approach using state-of-the-art AI planning techniques and tested it within the Penelope concurrent program testing framework [35]. Nevertheless, the approach is general and is amenable to a variety of program testing frameworks. Our experiments with a benchmark suite showed that our approach is very fast and highly effective, finding all known bugs.", "paper_title": "Generating effective tests for concurrent programs via AI automated planning techniques", "paper_id": "WOS:000209672900004"}