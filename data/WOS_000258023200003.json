{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "segment_models"}, {"score": 0.004752221133109136, "phrase": "tennis_video_parsing"}, {"score": 0.004690305164360866, "phrase": "automatic_video_content_analysis"}, {"score": 0.004598933498016774, "phrase": "emerging_research_subject"}, {"score": 0.004539005582217309, "phrase": "numerous_applications"}, {"score": 0.004479855062309818, "phrase": "large_video_databases"}, {"score": 0.004421471944783611, "phrase": "personal_video_recording_systems"}, {"score": 0.004140726362519362, "phrase": "multimodal_information"}, {"score": 0.003954837422946628, "phrase": "underlying_structure"}, {"score": 0.003903269701018361, "phrase": "tennis_broadcasts"}, {"score": 0.0038271712887391015, "phrase": "frame-based_observation_distributions"}, {"score": 0.003584025547693836, "phrase": "heterogeneous_audiovisual_data"}, {"score": 0.003400640983719424, "phrase": "segmental_features"}, {"score": 0.00308163068747474, "phrase": "synchronization_points"}, {"score": 0.003021502415143067, "phrase": "segment_boundaries"}, {"score": 0.0028857130140890787, "phrase": "video_scene"}, {"score": 0.0028108690791085536, "phrase": "visual_features"}, {"score": 0.0027379609683723938, "phrase": "scene_boundaries"}, {"score": 0.002530359917257626, "phrase": "experimental_results"}, {"score": 0.0024007585788965655, "phrase": "performance_superiority"}, {"score": 0.0023384629381463054, "phrase": "synchronous_audiovisual_fusion"}, {"score": 0.0023079225317714815, "phrase": "hidden_markov_models"}, {"score": 0.002233301265743633, "phrase": "asynchronous_fusion"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Hidden Markov Models", " Segment Models", " multimodal fusion", " video indexing", " video summarization"], "paper_abstract": "Automatic video content analysis is an emerging research subject with numerous applications to large video databases and personal video recording systems. The aim of this study is to fuse multimodal information in order to automatically parse the underlying structure of tennis broadcasts. The frame-based observation distributions of Hidden Markov Models are too strict in modeling heterogeneous audiovisual data. We propose instead the use of segmental features, of the framework of Segment Models, to overcome this limitation and extend the synchronization points to the segment boundaries. Considering each segment as a video scene, auditory and visual features collected inside the scene boundaries can thus be sampled and modeled with their native sampling rates and models. Experimental results on a corpus of 15-h tennis video demonstrated a performance superiority of Segment Models with synchronous audiovisual fusion over Hidden Markov Models. Results though with asynchronous fusion are less optimistic. (C) 2007 Elsevier Inc. All rights reserved.", "paper_title": "Audiovisual integration with Segment Models for tennis video parsing", "paper_id": "WOS:000258023200003"}