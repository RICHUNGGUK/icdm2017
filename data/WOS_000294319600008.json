{"auto_keywords": [{"score": 0.0356683943368949, "phrase": "perceptual_cues"}, {"score": 0.010612387000973441, "phrase": "computer-aided_credibility_assessment"}, {"score": 0.00927612367839956, "phrase": "decision_aids"}, {"score": 0.005252259299314238, "phrase": "decision_aid's_recommendations"}, {"score": 0.004722791767189843, "phrase": "inaccurate_credibility_assessments"}, {"score": 0.004632388761885302, "phrase": "tremendous_costs"}, {"score": 0.004478308876320956, "phrase": "recent_research"}, {"score": 0.004435230698216773, "phrase": "unobtrusive_credibility_assessment_aids"}, {"score": 0.004007083686875716, "phrase": "aids'_recommendations"}, {"score": 0.0038737214010638745, "phrase": "signal_detection_theory"}, {"score": 0.0036730297909962142, "phrase": "automated_and_participatory_decision_support"}, {"score": 0.0035507457285983268, "phrase": "decision-making_theory"}, {"score": 0.0034491650585057754, "phrase": "increased_acceptance"}, {"score": 0.0034159525504642656, "phrase": "assessment_aid_recommendations"}, {"score": 0.003131023880006021, "phrase": "hybrid_decision_aid"}, {"score": 0.0030858947334838145, "phrase": "automated_linguistic_analysis"}, {"score": 0.002883718207958817, "phrase": "laboratory_experiment"}, {"score": 0.002801166393333128, "phrase": "linguistic_and_perceptual_cues"}, {"score": 0.002655894070657161, "phrase": "automatic_analysis"}, {"score": 0.002630299922281955, "phrase": "linguistic_cues"}, {"score": 0.0025673856614952854, "phrase": "users'_credibility_assessment_accuracy"}, {"score": 0.0023417010799384524, "phrase": "users'_assessment_accuracy"}, {"score": 0.002230984431056064, "phrase": "user_acceptance"}, {"score": 0.0021254913611527455, "phrase": "future_development"}, {"score": 0.0021049977753042253, "phrase": "credibility_assessment_decision_aids"}], "paper_keywords": ["credibility assessment", " decision support systems", " indirect cues elicitation", " linguistic analysis", " signal detection theory"], "paper_abstract": "Historically, inaccurate credibility assessments have resulted in tremendous costs to businesses and to society. Recent research offers unobtrusive credibility assessment aids as a solution; however, the accuracy of these decision aids is inadequate, and users often resist accepting the aids' recommendations. We follow the principles of signal detection theory to improve the accuracy of recommendations in computer-aided credibility assessment by combining automated and participatory decision support. We also leverage participation in decision-making theory to explain and predict an increased acceptance of assessment aid recommendations when perceptual cues are elicited from users. Based on these two theories, we design and test a hybrid decision aid to perform automated linguistic analysis and to elicit and analyze perceptual cues from an observer. Results from a laboratory experiment indicate that decision aids that use linguistic and perceptual cues offer more accurate recommendations than aids that use only one type of cue. Automatic analysis of linguistic cues improved both the decision aid's recommendations and the users' credibility assessment accuracy. Challenging the generalizability of past findings, the elicitation of perceptual cues did not improve the decision aid's recommendations or the users' assessment accuracy. Elicitation of perceptual cues, however, did improve user acceptance of the decision aid's recommendations. These findings provide guidance for future development of credibility assessment decision aids.", "paper_title": "Effects of Automated and Participative Decision Support in Computer-Aided Credibility Assessment", "paper_id": "WOS:000294319600008"}