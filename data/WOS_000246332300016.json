{"auto_keywords": [{"score": 0.049618672169140725, "phrase": "multi-label_learning"}, {"score": 0.0450260882774516, "phrase": "training_set"}, {"score": 0.041030905463758836, "phrase": "label_sets"}, {"score": 0.034356391305085915, "phrase": "unseen_instance"}, {"score": 0.03098408925965231, "phrase": "neighboring_instances"}, {"score": 0.00481495049065317, "phrase": "multi-label_leaming"}, {"score": 0.004632388761885302, "phrase": "text_categorization_problem"}, {"score": 0.0038737214010638745, "phrase": "unseen_instances"}, {"score": 0.0038179283509963695, "phrase": "training_instances"}, {"score": 0.0037811784409635023, "phrase": "known_label_sets"}, {"score": 0.0036553070575015344, "phrase": "multi-label_lazy_learning_approach"}, {"score": 0.0034325187732054093, "phrase": "traditional_k-nearest_neighbor"}, {"score": 0.0030267296900520217, "phrase": "statistical_information"}, {"score": 0.0027876387169652717, "phrase": "possible_class"}, {"score": 0.0027103263029054116, "phrase": "map"}, {"score": 0.002263639474937039, "phrase": "superior_performance"}, {"score": 0.002230984431056064, "phrase": "well-established_multi-label_learning_algorithms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["machine learning", " multi-label learning", " lazy learning", " K-nearest neighbor", " functional genomics", " natural scene classification", " text categorization"], "paper_abstract": "Multi-label learning originated from the investigation of text categorization problem, where each document may belong to several predefined topics simultaneously. In multi-label learning, the training set is composed of instances each associated with a set of labels, and the task is to predict the label sets of unseen instances through analyzing training instances with known label sets. In this paper, a multi-label lazy learning approach named ML-KNN is presented, which is derived from the traditional K-nearest neighbor (KNN) algorithm. In detail, for each unseen instance, its K nearest neighbors in the training set are firstly identified. After that, based on statistical information gained from the label sets of these neighboring instances, i.e. the number of neighboring instances belonging to each possible class, maximum a posteriori (MAP) principle is utilized to determine the label set for the unseen instance. Experiments on three different real-world multi-label learning problems, i.e. Yeast gene functional analysis, natural scene classification and automatic web page categorization, show that ML-KNN achieves superior performance to some well-established multi-label learning algorithms. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "paper_title": "ML-KNN: A lazy learning approach to multi-label leaming", "paper_id": "WOS:000246332300016"}