{"auto_keywords": [{"score": 0.04893638421315736, "phrase": "model_selection"}, {"score": 0.04848647943586379, "phrase": "neural_networks"}, {"score": 0.040273620909837375, "phrase": "whole_learning_samples"}, {"score": 0.032475287473738255, "phrase": "novel_instances"}, {"score": 0.00481495049065317, "phrase": "radial_basis_function_network"}, {"score": 0.004587835274176236, "phrase": "essential_procedure"}, {"score": 0.004392565073466714, "phrase": "compact_data_model"}, {"score": 0.004225950334493496, "phrase": "compact_model"}, {"score": 0.004085333687668526, "phrase": "machine_learning_methods"}, {"score": 0.0032546105164772995, "phrase": "learning_system"}, {"score": 0.00320770578058916, "phrase": "radial_basis_function"}, {"score": 0.003100865267124765, "phrase": "quick_learning"}, {"score": 0.0030121159909273897, "phrase": "on-line_periods"}, {"score": 0.0029117710453690827, "phrase": "pseudo_rehearsal"}, {"score": 0.002814759530655965, "phrase": "-service_periods"}, {"score": 0.0026817365934071486, "phrase": "incremental_learning"}, {"score": 0.002579847272930948, "phrase": "sleep_phases"}, {"score": 0.0024224481033945943, "phrase": "awake_phases"}, {"score": 0.002230984431056064, "phrase": "periodic_sleep_periods"}, {"score": 0.0022094759531152072, "phrase": "experimental_results"}], "paper_keywords": ["incremental learning", " sleep learning", " model selection", " RBF"], "paper_abstract": "The model selection for neural networks is an essential procedure to get not only high levels of generalization but also a compact data model. Especially in terms of getting the compact model, neural networks usually outperform other kinds of machine learning methods. Generally, models are selected by trial and error testing using whole learning samples given in advance. In many cases, however, it is difficult and time consuming to prepare whole learning samples in advance. To overcome these inconveniences, we propose a hybrid on-line learning system for a radial basis function (RBF) network that repeats quick learning of novel instances by rote during on-line periods (awake phases) and repeats pseudo rehearsal for model selection during out-of-service periods (sleep phases). We call this system Incremental Learning with Sleep (ILS). During sleep phases, the system basically stops the learning of novel instances, and during awake phases, the system responds quickly. We also extended the system so as to shorten the periodic sleep periods. Experimental results showed the system selects more compact data models than those selected by other machine learning systems.", "paper_title": "Incremental leaning and model selection for radial basis function network through sleep", "paper_id": "WOS:000245929200003"}