{"auto_keywords": [{"score": 0.015719716506582538, "phrase": "action-specific_person_detection"}, {"score": 0.014764883889974201, "phrase": "action_recognition"}, {"score": 0.011717137733505184, "phrase": "action_classification"}, {"score": 0.008551290679087498, "phrase": "pascal_voc"}, {"score": 0.00474614491353724, "phrase": "still_images"}, {"score": 0.004705332186103205, "phrase": "challenging_problem"}, {"score": 0.004678317945062391, "phrase": "computer_vision"}, {"score": 0.004624751696958501, "phrase": "comparative_evaluation"}, {"score": 0.004584978036864935, "phrase": "person_detection"}, {"score": 0.004545544875014869, "phrase": "standard_evaluation_protocol"}, {"score": 0.004480571767714176, "phrase": "oracle_person_detector"}, {"score": 0.004442032546224076, "phrase": "perfect_bounding_box_information"}, {"score": 0.004378532515411219, "phrase": "test_time"}, {"score": 0.004241995931481941, "phrase": "general_person_detector"}, {"score": 0.004205500128968766, "phrase": "candidate_bounding_boxes"}, {"score": 0.004004519212957236, "phrase": "action_class_labels"}, {"score": 0.00392456965725842, "phrase": "detection_stage"}, {"score": 0.003780286517897356, "phrase": "action_class"}, {"score": 0.003683505847679944, "phrase": "existing_state-of-the-art_generic_person_detectors"}, {"score": 0.0035175070315611088, "phrase": "limited_training_examples"}, {"score": 0.003487222504700868, "phrase": "direct_training"}, {"score": 0.0034671773098114192, "phrase": "action-specific_person_detectors"}, {"score": 0.00335896380465609, "phrase": "labeled_action_examples"}, {"score": 0.0033300397189425304, "phrase": "transfer_learning"}, {"score": 0.0032729341532134514, "phrase": "existing_detector"}, {"score": 0.003244748458248666, "phrase": "higher_quality_bounding_boxes"}, {"score": 0.003226092536458597, "phrase": "subsequent_action_classification"}, {"score": 0.0029844579234112466, "phrase": "extensive_experiments"}, {"score": 0.0028498718992429825, "phrase": "action_detection_task"}, {"score": 0.002690118949960196, "phrase": "general_person_detection"}, {"score": 0.0022365262201954643, "phrase": "ground-truth_person_localization"}, {"score": 0.0021049977753042253, "phrase": "person_locations"}], "paper_keywords": ["Action recognition", " transfer learning", " deep features"], "paper_abstract": "Action recognition in still images is a challenging problem in computer vision. To facilitate comparative evaluation independently of person detection, the standard evaluation protocol for action recognition uses an oracle person detector to obtain perfect bounding box information at both training and test time. The assumption is that, in practice, a general person detector will provide candidate bounding boxes for action recognition. In this paper, we argue that this paradigm is suboptimal and that action class labels should already be considered during the detection stage. Motivated by the observation that body pose is strongly conditioned on action class, we show that: 1) the existing state-of-the-art generic person detectors are not adequate for proposing candidate bounding boxes for action classification; 2) due to limited training examples, the direct training of action-specific person detectors is also inadequate; and 3) using only a small number of labeled action examples, the transfer learning is able to adapt an existing detector to propose higher quality bounding boxes for subsequent action classification. To the best of our knowledge, we are the first to investigate transfer learning for the task of action-specific person detection in still images. We perform extensive experiments on two benchmark data sets: 1) Stanford-40 and 2) PASCAL VOC 2012. For the action detection task (i.e., both person localization and classification of the action performed), our approach outperforms methods based on general person detection by 5.7% mean average precision (MAP) on Stanford-40 and 2.1% MAP on PASCAL VOC 2012. Our approach also significantly outperforms the state of the art with a MAP of 45.4% on Stanford-40 and 31.4% on PASCAL VOC 2012. We also evaluate our action detection approach for the task of action classification (i.e., recognizing actions without localizing them). For this task, our approach, without using any ground-truth person localization at test time, outperforms on both data sets state-of-the-art methods, which do use person locations.", "paper_title": "Recognizing Actions Through Action-Specific Person Detection", "paper_id": "WOS:000360408800004"}