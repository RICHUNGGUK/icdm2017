{"auto_keywords": [{"score": 0.048566997341190715, "phrase": "source_network"}, {"score": 0.04807284417213196, "phrase": "finite_alphabet_source"}, {"score": 0.039240862185946364, "phrase": "achievable_rates"}, {"score": 0.037945151553555774, "phrase": "feedback_source_network"}, {"score": 0.03333464622843145, "phrase": "simple_progressive_encoder"}, {"score": 0.0305135299280402, "phrase": "average_number"}, {"score": 0.02430845051317693, "phrase": "universal_decoding_algorithm"}, {"score": 0.00481495049065317, "phrase": "universal_multiterminal_source"}, {"score": 0.0047637310731655155, "phrase": "asymptotically_zero_feedback"}, {"score": 0.004201033616196156, "phrase": "side_information"}, {"score": 0.0036357909244344486, "phrase": "universal_source_coding"}, {"score": 0.0033913321452667708, "phrase": "random_database"}, {"score": 0.0029425839831784765, "phrase": "large_class"}, {"score": 0.0029034358982402346, "phrase": "mixing_conditions"}, {"score": 0.002737262446527767, "phrase": "conditional_entropy_h"}, {"score": 0.002439363579997196, "phrase": "corresponding_analysis_results"}, {"score": 0.002244876254113051, "phrase": "joint_typicality_decoding"}, {"score": 0.002220935192287471, "phrase": "resulting_universal_compression_algorithm"}, {"score": 0.0021049977753042253, "phrase": "jointly_memoryless_source-side_information_pairs"}], "paper_keywords": ["Database", " distributed source coding", " entropy", " feedback", " phi-mixing", " string matching", " universal data compression"], "paper_abstract": "Consider a source network in which a finite alphabet source X = {X-i}(i=0)(infinity) is to be encoded and transmitted, and another finite alphabet source Y = {Y-i}(i=0)(infinity) correlated with X is available only to the decoder as side information. Traditionally, the channel between the encoder and decoder in the source network is assumed to be one-way. This, together with the fact that the encoder does not have access to Y, implies that the encoder has to know the achievable rates before encoding. In this paper, we consider universal source coding for a feedback source network in which the channel between the encoder and decoder is two-way and asymmetric. Assume that the encoder and decoder share a random database that is independent of both X and Y. A string matching-based (variable-rate) block coding algorithm with simple progressive encoding and joint typicality decoding is first proposed for the feedback source network. The simple progressive encoder does not need to know the achievable rates at the beginning of encoding. It is proven that for any (X, Y) in a large class of sources satisfying some mixing conditions, the average number of bits per letter transmitted from the encoder to the decoder (compression rate) goes to the conditional entropy H (X vertical bar Y) of X given 11 asymptotically, and at the same time the average number of bits per letter transmitted from the decoder to the encoder (feedback rate) goes to 0 asymptotically. The algorithm and the corresponding analysis results are then extended to the case where both X and Y are to be encoded separately, but decoded jointly. Finally, a universal decoding algorithm is proposed to replace the joint typicality decoding, and the resulting universal compression algorithm consisting of the simple progressive encoder and the universal decoding algorithm is further shown to be asymptotically optimal for the class of all jointly memoryless source-side information pairs (X,Y).", "paper_title": "Universal Multiterminal Source Coding Algorithms With Asymptotically Zero Feedback: Fixed Database Case", "paper_id": "WOS:000261648100019"}