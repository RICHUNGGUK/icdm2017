{"auto_keywords": [{"score": 0.030159965914792215, "phrase": "class-dependent_codebook"}, {"score": 0.00481495049065317, "phrase": "class-dependent_tied-mixture_hmm"}, {"score": 0.0047013405841819025, "phrase": "speech-driven_lip-sync"}, {"score": 0.004568525347438891, "phrase": "real-time_lip-sync_method"}, {"score": 0.004418287966422041, "phrase": "corresponding_speech_signal"}, {"score": 0.004376273644295806, "phrase": "phoneme_recognition"}, {"score": 0.004252602474733162, "phrase": "important_task"}, {"score": 0.004132411680987228, "phrase": "real-time_lip-sync_system"}, {"score": 0.003632080001489739, "phrase": "co-articulation_effects"}, {"score": 0.003580355398511932, "phrase": "hbt_model"}, {"score": 0.00349577373145384, "phrase": "transition_parts"}, {"score": 0.0033806943112103397, "phrase": "small-sized_vocabulary_tasks"}, {"score": 0.003300813776412652, "phrase": "better_recognition_performance"}, {"score": 0.003043031131345537, "phrase": "vowel_recognition"}, {"score": 0.0026742419973883134, "phrase": "clear_representation"}, {"score": 0.00263612191603326, "phrase": "context_dependency_information"}, {"score": 0.002598543802992702, "phrase": "transient_parts"}, {"score": 0.0025616017921305137, "phrase": "gaussians"}, {"score": 0.0024771000236931836, "phrase": "proposed_method"}, {"score": 0.0024301229420875155, "phrase": "lip-sync_system"}, {"score": 0.002316532084420729, "phrase": "previous_designs"}, {"score": 0.0022834993174767016, "phrase": "hbt_and_continuous_hidden_markov_models"}, {"score": 0.0021560018573288666, "phrase": "model_parameters"}, {"score": 0.0021049977753042253, "phrase": "real-time_operation"}], "paper_keywords": ["Head-body-tail HMM", " phoneme recognition", " real-time lip-sync"], "paper_abstract": "This work describes a real-time lip-sync method using which an avatar's lip shape is synchronized with the corresponding speech signal. Phoneme recognition is generally regarded as an important task in the operation of a real-time lip-sync system. In this work, the use of the Head-Body-Tail (HBT) model is proposed for the purpose of more efficiently recognizing phonemes which are variously uttered due to co-articulation effects. The HBT model effectively deals with the transition parts of context-dependent models for small-sized vocabulary tasks. These models provide better recognition performance than general context-dependent or context-independent models for the task of digit or vowel recognition. Moreover, each phoneme is categorized into one among four classes and the class-dependent codebook is generated to further improve the performance. Additionally, for the clear representation of the context dependency information in the transient parts, some Gaussians are excluded from class-dependent codebook. The proposed method leads to a lip-sync system that performs at a level that is similar to previous designs based on HBT and continuous hidden Markov models (CHMMs). However, our method reduces the number of model parameters by one-third and enables real-time operation.", "paper_title": "Real-Time Continuous Phoneme Recognition System Using Class-Dependent Tied-Mixture HMM With HBT Structure for Speech-Driven Lip-Sync", "paper_id": "WOS:000261310700007"}