{"auto_keywords": [{"score": 0.043295135176914266, "phrase": "best_subset"}, {"score": 0.00481495049065317, "phrase": "mallows_c-p"}, {"score": 0.004058180509184539, "phrase": "explanatory_variables"}, {"score": 0.003944112858235306, "phrase": "linear_regression_model"}, {"score": 0.0038332390893263844, "phrase": "mallows'_c-p"}, {"score": 0.0035525230119401153, "phrase": "fit_measure"}, {"score": 0.0033875770020590796, "phrase": "subset_selection_problem"}, {"score": 0.0032922964156452696, "phrase": "mixed_integer_quadratic_programming_problem"}, {"score": 0.0027741761880779535, "phrase": "candidate_explanatory_variables"}, {"score": 0.0024513404432665153, "phrase": "large_number"}, {"score": 0.0023152577218214804, "phrase": "better-quality_solutions"}, {"score": 0.0022500695985527668, "phrase": "stepwise_regression_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Subset selection", " Mixed integer programming", " Mallows' C-p", " Linear regression model"], "paper_abstract": "This paper concerns a method of selecting the best subset of explanatory variables for a linear regression model. Employing Mallows' C-p, as a goodness-of-fit measure, we formulate the subset selection problem as a mixed integer quadratic programming problem. Computational results demonstrate that our method provides the best subset of variables in a few seconds when the number of candidate explanatory variables is less than 30. Furthermore, when handling datasets consisting of a large number of samples, it finds better-quality solutions faster than stepwise regression methods do. (C) 2014 Elsevier Ltd. All rights reserved.", "paper_title": "Subset selection by Mallows C-p: A mixed integer programming approach", "paper_id": "WOS:000344034300027"}