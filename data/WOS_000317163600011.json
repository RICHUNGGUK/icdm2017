{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "motion_data"}, {"score": 0.04679044933200289, "phrase": "activity_recognition"}, {"score": 0.004690583510896564, "phrase": "assistive_environments"}, {"score": 0.0046037124365759215, "phrase": "human_motion_data"}, {"score": 0.004451360793577698, "phrase": "emergency_event_detection"}, {"score": 0.0043363441738461335, "phrase": "elderly_or_disabled_people"}, {"score": 0.004084440052083978, "phrase": "audio_and_video_sensors"}, {"score": 0.00403885675788806, "phrase": "monitored_subject"}, {"score": 0.003890540531028228, "phrase": "surrounding_environment"}, {"score": 0.003861534816807933, "phrase": "visual_data"}, {"score": 0.0038041680562514064, "phrase": "user's_environment"}, {"score": 0.003761700847771486, "phrase": "overhead_cameras"}, {"score": 0.0035965032173588753, "phrase": "subject's_body"}, {"score": 0.003516635512391528, "phrase": "activity_detection_systems"}, {"score": 0.0034643747383816164, "phrase": "emergency_situations"}, {"score": 0.0033121909731471787, "phrase": "data_streams"}, {"score": 0.003275197814021, "phrase": "real_time_recognition"}, {"score": 0.0030275252142439213, "phrase": "classification_schemes"}, {"score": 0.0030049342542235466, "phrase": "traditional_classification_approaches"}, {"score": 0.002883655046524374, "phrase": "immediate_alarm"}, {"score": 0.0028514344213899177, "phrase": "fall_prevention"}, {"score": 0.0028195727965553367, "phrase": "cpu_power"}, {"score": 0.0027159094186967247, "phrase": "detection_algorithm"}, {"score": 0.002685558057339722, "phrase": "mobile_device"}, {"score": 0.002548331088496964, "phrase": "statistical_mining_methodology"}, {"score": 0.0024916819803100635, "phrase": "real_time_motion_data_processing"}, {"score": 0.002418099158357658, "phrase": "stream_data_analysis_methodology"}, {"score": 0.0023554947277883535, "phrase": "detection_system"}, {"score": 0.002320449502337321, "phrase": "initial_evaluation"}, {"score": 0.002294507393862231, "phrase": "achieved_accuracy"}, {"score": 0.002177218756653181, "phrase": "proposed_methodology"}, {"score": 0.00216907363015155, "phrase": "real_time_fall_detection"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Streaming motion data", " Fall detection", " Visual data", " Cumulative sum (CUSUM) algorithm"], "paper_abstract": "The analysis of human motion data is interesting in the context of activity recognition or emergency event detection, especially in the case of elderly or disabled people living independently in their homes. Several techniques have been proposed for identifying such distress situations using either motion, audio and video sensors on the monitored subject (wearable sensors) or devices installed at the surrounding environment. Visual data captured from the user's environment, using overhead cameras along with motion data, which are collected from accelerometers on the subject's body, can be fed to activity detection systems that can detect emergency situations like falls and injuries. The output of these sensors is data streams that require real time recognition, especially in such emergency situations. In this paper, we study motion and activity related streaming data and we propose classification schemes using traditional classification approaches. However, such approaches may not be always applicable for immediate alarm triggering and fall prevention or when CPU power and memory resources are limited (e.g. running the detection algorithm on a mobile device such as smartphones). To this end, we also propose a statistical mining methodology that may be used for real time motion data processing. The paper includes details of the stream data analysis methodology incorporated in the activity recognition and fall detection system along with an initial evaluation of the achieved accuracy in detecting falls. The results are promising and indicate that using the proposed methodology real time fall detection is feasible. (C) 2012 Elsevier B.V. All rights reserved.", "paper_title": "Statistical data mining of streaming motion data for activity and fall recognition in assistive environments", "paper_id": "WOS:000317163600011"}