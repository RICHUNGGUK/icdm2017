{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "dynamic_stimuli"}, {"score": 0.004701985831087475, "phrase": "visual_analytics_method"}, {"score": 0.004635477242873163, "phrase": "eye_movement_data"}, {"score": 0.004462663711734448, "phrase": "animated_graphics"}, {"score": 0.004116440453049531, "phrase": "general_viewing_behavior"}, {"score": 0.004058180509184539, "phrase": "time_sequences"}, {"score": 0.004019797503157808, "phrase": "attentional_synchrony"}, {"score": 0.003944112858235306, "phrase": "strong_attentional_focus"}, {"score": 0.0038515000499988673, "phrase": "space-time_cube_visualization"}, {"score": 0.00369022262431101, "phrase": "associated_eye"}, {"score": 0.0034526191487098093, "phrase": "potential_areas"}, {"score": 0.0031693980719538287, "phrase": "gaze_points"}, {"score": 0.0031096747349602344, "phrase": "density-based_color_mapping"}, {"score": 0.0029793675408245047, "phrase": "space-time_cube"}, {"score": 0.002937153116494391, "phrase": "analytical_process"}, {"score": 0.002881793492919646, "phrase": "multiple_coordinated_views"}, {"score": 0.0027741761880779535, "phrase": "different_aspects"}, {"score": 0.0027479040199262393, "phrase": "spatial_and_temporal_information"}, {"score": 0.0027218799769229596, "phrase": "eye_gaze_data"}, {"score": 0.002696101728474703, "phrase": "common_eye-tracking_visualization_techniques"}, {"score": 0.0026202187680903063, "phrase": "spatiotemporal_characteristics"}, {"score": 0.002522344964242888, "phrase": "heat_maps"}, {"score": 0.0024747842618794255, "phrase": "motion-compensated_heat_maps"}, {"score": 0.0024281181691350085, "phrase": "scan_paths"}, {"score": 0.002371018116266096, "phrase": "space-time_visualization"}, {"score": 0.0022933216359142736, "phrase": "qualitative_users"}, {"score": 0.0022608057001451414, "phrase": "expert_users"}, {"score": 0.0021049977753042253, "phrase": "different_analysis_strategies"}], "paper_keywords": ["Eye-tracking", " space-time cube", " dynamic areas of interest", " spatiotemporal clustering", " motion-compensated heat map"], "paper_abstract": "We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.", "paper_title": "Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli", "paper_id": "WOS:000325991600019"}