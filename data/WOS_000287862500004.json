{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "high-dimensional_data_spaces"}, {"score": 0.004518442937844318, "phrase": "underlying_linear"}, {"score": 0.004474468584252318, "phrase": "nonlinear_structures"}, {"score": 0.003959447096055027, "phrase": "compact_structure"}, {"score": 0.003920891569777894, "phrase": "complex_data"}, {"score": 0.003863758357292741, "phrase": "nonlinear_context"}, {"score": 0.0037519679864796906, "phrase": "nonlinear_partition_strategy"}, {"score": 0.003661275004971829, "phrase": "principal_curve_tree"}, {"score": 0.003287482882222731, "phrase": "data_distribution"}, {"score": 0.0031457622320220364, "phrase": "arc_length"}, {"score": 0.002951739421935396, "phrase": "residual_version"}, {"score": 0.0029086869572567072, "phrase": "pc-tree_algorithm"}, {"score": 0.0027969169552386, "phrase": "principal_component_analysis_tree"}, {"score": 0.002573424607574822, "phrase": "intrinsic_dimension"}, {"score": 0.002548331088496964, "phrase": "high-dimensional_data"}, {"score": 0.0024264776194357993, "phrase": "proposed_pc-tree_and_pcr-tree_approaches"}, {"score": 0.0023104373174118458, "phrase": "vector_quantization_error"}, {"score": 0.002287902310873394, "phrase": "nearest_neighbor_search"}, {"score": 0.0021678232353129472, "phrase": "competing_linear_methods"}, {"score": 0.002146676231930343, "phrase": "total_average_coverage"}, {"score": 0.0021049977753042253, "phrase": "nonlinear_compactness"}], "paper_keywords": ["Manifold learning", " principal component analysis", " principal curves", " space partitioning", " tree-based algorithms"], "paper_abstract": "Most partitioning algorithms iteratively partition a space into cells that contain underlying linear or nonlinear structures using linear partitioning strategies. The compactness of each cell depends on how well the (locally) linear partitioning strategy approximates the intrinsic structure. To partition a compact structure for complex data in a nonlinear context, this paper proposes a nonlinear partition strategy. This is a principal curve tree (PC-tree), which is implemented iteratively. Given that a PC passes through the middle of the data distribution, it allows for partitioning based on the arc length of the PC. To enhance the partitioning of a given space, a residual version of the PC-tree algorithm is developed, denoted here as the principal component analysis tree (PCR-tree) algorithm. Because of its residual property, the PCR-tree can yield the intrinsic dimension of high-dimensional data. Comparisons presented in this paper confirm that the proposed PC-tree and PCR-tree approaches show a better performance than several other competing partitioning algorithms in terms of vector quantization error and nearest neighbor search. The comparison also shows that the proposed algorithms outperform competing linear methods in total average coverage which measures the nonlinear compactness of partitioning algorithms.", "paper_title": "Principal Curve Algorithms for Partitioning High-Dimensional Data Spaces", "paper_id": "WOS:000287862500004"}