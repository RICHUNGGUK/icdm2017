{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "deep_web_data_extraction"}, {"score": 0.020030302213522557, "phrase": "deep_web_pages"}, {"score": 0.010187626648328467, "phrase": "web_databases"}, {"score": 0.004771196027464407, "phrase": "deep_web_contents"}, {"score": 0.004558289038745564, "phrase": "returned_data_records"}, {"score": 0.004475798524102238, "phrase": "dynamically_generated_web_pages"}, {"score": 0.004179480763003705, "phrase": "structured_data"}, {"score": 0.004085115444878828, "phrase": "challenging_problem"}, {"score": 0.0040111533608228195, "phrase": "underlying_intricate_structures"}, {"score": 0.003867206750827, "phrase": "large_number"}, {"score": 0.0035945701438887282, "phrase": "inherent_limitations"}, {"score": 0.0033410898465226417, "phrase": "popular_two-dimensional_media"}, {"score": 0.003265591844292821, "phrase": "web_pages"}, {"score": 0.0030352396244492604, "phrase": "different_way"}, {"score": 0.002926212333939311, "phrase": "previous_works"}, {"score": 0.0028731719610706214, "phrase": "interesting_common_visual_features"}, {"score": 0.00274472767672686, "phrase": "novel_vision-based_approach"}, {"score": 0.0025047659706737215, "phrase": "visual_features"}, {"score": 0.002403724423251419, "phrase": "data_record_extraction"}, {"score": 0.0023818288346547692, "phrase": "data_item_extraction"}, {"score": 0.0023173287402646577, "phrase": "new_evaluation_measure_revision"}, {"score": 0.002254571365634257, "phrase": "human_effort"}, {"score": 0.0022136780933978612, "phrase": "perfect_extraction"}, {"score": 0.002163600705898299, "phrase": "large_set"}, {"score": 0.0021049977753042253, "phrase": "proposed_vision-based_approach"}], "paper_keywords": ["Web mining", " Web data extraction", " visual features of deep Web pages", " wrapper generation"], "paper_abstract": "Deep Web contents are accessed by queries submitted to Web databases and the returned data records are enwrapped in dynamically generated Web pages (they will be called deep Web pages in this paper). Extracting structured data from deep Web pages is a challenging problem due to the underlying intricate structures of such pages. Until now, a large number of techniques have been proposed to address this problem, but all of them have inherent limitations because they are Web-page-programming-language-dependent. As the popular two-dimensional media, the contents on Web pages are always displayed regularly for users to browse. This motivates us to seek a different way for deep Web data extraction to overcome the limitations of previous works by utilizing some interesting common visual features on the deep Web pages. In this paper, a novel vision-based approach that is Web-page-programming-language-independent is proposed. This approach primarily utilizes the visual features on the deep Web pages to implement deep Web data extraction, including data record extraction and data item extraction. We also propose a new evaluation measure revision to capture the amount of human effort needed to produce perfect extraction. Our experiments on a large set of Web databases show that the proposed vision-based approach is highly effective for deep Web data extraction.", "paper_title": "ViDE: A Vision-Based Approach for Deep Web Data Extraction", "paper_id": "WOS:000273707000011"}