{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "text_knowledge"}, {"score": 0.010113936416165101, "phrase": "rich_knowledge"}, {"score": 0.0056482531970947995, "phrase": "lda."}, {"score": 0.004761494044422926, "phrase": "human_concept_learning"}, {"score": 0.00465634671242413, "phrase": "text_knowledge_representation_model"}, {"score": 0.004519736937243476, "phrase": "flexible_reasoning_ability"}, {"score": 0.004354572391793908, "phrase": "low_computational_complexity"}, {"score": 0.004290201740122912, "phrase": "fundamental_challenge"}, {"score": 0.004258372598568333, "phrase": "reasoning-based_knowledge_services"}, {"score": 0.004179824713643488, "phrase": "rapid_growth"}, {"score": 0.0041488110506566825, "phrase": "web_resources"}, {"score": 0.004087469540575263, "phrase": "current_text_knowledge_representation_models"}, {"score": 0.00399714680711765, "phrase": "e._g."}, {"score": 0.0038224221344037236, "phrase": "high_complex_computation"}, {"score": 0.003367611042980526, "phrase": "novel_text_knowledge_representation_model"}, {"score": 0.0032083351151314405, "phrase": "low_complex_computation"}, {"score": 0.0030225753906647935, "phrase": "automatic_construction"}, {"score": 0.002977835845437357, "phrase": "concept_algebra"}, {"score": 0.002826383890518307, "phrase": "power_series"}, {"score": 0.002722930209707764, "phrase": "proposed_psr_model"}, {"score": 0.0026330549554033876, "phrase": "lower_complex_computation"}, {"score": 0.0025747949123152824, "phrase": "vsm"}, {"score": 0.002508433454626386, "phrase": "hypothesis-based_reasoning_operations"}, {"score": 0.002345535736297701, "phrase": "current_knowledge_representation_models"}, {"score": 0.0023021895404322767, "phrase": "better_characteristics"}, {"score": 0.0021687806803474367, "phrase": "psr_model"}, {"score": 0.0021446391766277817, "phrase": "good_prospect"}, {"score": 0.0021049977753042253, "phrase": "web_semantic_search"}], "paper_keywords": ["Cognitive informatics", " human concept learning", " knowledge representation", " semantic search", " text understanding"], "paper_abstract": "How to build a text knowledge representation model, which carries rich knowledge and has a flexible reasoning ability as well as can be automatically constructed with a low computational complexity, is a fundamental challenge for reasoning-based knowledge services, especially with the rapid growth of web resources. However, current text knowledge representation models either lose much knowledge [e. g., vector space model (VSM)] or have a high complex computation [e. g., latent Dirichlet allocation (LDA)]; even some of them cannot be constructed automatically [e. g., web ontology language, (OWL)]. In this paper, a novel text knowledge representation model, power series representation (PSR) model, which has a low complex computation in text knowledge constructing process, is proposed to leverage the contradiction between carrying rich knowledge and automatic construction. First, concept algebra of human concept learning is developed to represent text knowledge as the form of power series. Then, degree-2 power series hypothesis is introduced to simplify the proposed PSR model, which can be automatically constructed with a lower complex computation and has more knowledge than the VSM and LDA. After that, degree-2 power series hypothesis-based reasoning operations are developed, which provide a more flexible reasoning ability than OWL and LDA. Furthermore, experiments and comparisons with current knowledge representation models show that our model has better characteristics than others when representing text knowledge. Finally, a demo is given to indicate that PSR model has a good prospect over the area of web semantic search.", "paper_title": "Power Series Representation Model of Text Knowledge Based on Human Concept Learning", "paper_id": "WOS:000329055600007"}