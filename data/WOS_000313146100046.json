{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "statistical_learning_theory"}, {"score": 0.029219690623003274, "phrase": "quasi-regular_case"}, {"score": 0.008848537308868787, "phrase": "regular_case"}, {"score": 0.004764542405129454, "phrase": "quasi-regular_cases"}, {"score": 0.004640808212832262, "phrase": "normal_mixtures"}, {"score": 0.004592214823540993, "phrase": "layered_neural_networks"}, {"score": 0.004520272777451894, "phrase": "regular_but_singular_statistical_models"}, {"score": 0.004288472456976113, "phrase": "probability_distribution"}, {"score": 0.004068510313497539, "phrase": "conventional_statistical_asymptotic_theory"}, {"score": 0.00388016972840459, "phrase": "likelihood_function"}, {"score": 0.0037397086147485897, "phrase": "normal_distribution"}, {"score": 0.0036617315529835497, "phrase": "new_statistical_theory"}, {"score": 0.0035477930970463432, "phrase": "algebraic_geometry"}, {"score": 0.0034193226278107346, "phrase": "generalization_and_training_errors"}, {"score": 0.002997203022420553, "phrase": "present_paper"}, {"score": 0.00291923164591297, "phrase": "new_concept"}, {"score": 0.002654911400878851, "phrase": "singular_case"}, {"score": 0.002172701452347454, "phrase": "training_errors"}, {"score": 0.0021049977753042253, "phrase": "concrete_values"}], "paper_keywords": ["statistical learning theory", " quasi-regular case", " birational invariants", " generalization error"], "paper_abstract": "Many learning machines such as normal mixtures and layered neural networks are not regular but singular statistical models, because the map from a parameter to a probability distribution is not one-to-one. The conventional statistical asymptotic theory can not be applied to such learning machines because the likelihood function can not be approximated by any normal distribution. Recently, new statistical theory has been established based on algebraic geometry and it was clarified that the generalization and training errors are determined by two birational invariants, the real log canonical threshold and the singular fluctuation. However, their concrete values are left unknown. In the present paper, we propose a new concept, a quasi-regular case in statistical learning theory. A quasi-regular case is not a regular case but a singular case, however, it has the same property as a regular case. In fact, we prove that, in a quasi-regular case, two birational invariants are equal to each other, resulting that the symmetry of the generalization and training errors holds. Moreover, the concrete values of two birational invariants are explicitly obtained, hence the quasi-regular case is useful to study statistical learning theory.", "paper_title": "Statistical Learning Theory of Quasi-Regular Cases", "paper_id": "WOS:000313146100046"}