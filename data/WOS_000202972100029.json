{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "locality_optimization"}, {"score": 0.009482488049491866, "phrase": "run_time"}, {"score": 0.007828702968692716, "phrase": "garbage_collection"}, {"score": 0.004680624753255133, "phrase": "garbage_collected_languages"}, {"score": 0.004627944735913613, "phrase": "large_dynamic_working_sets"}, {"score": 0.004575854901681043, "phrase": "poor_data_locality"}, {"score": 0.004448169552315403, "phrase": "new_system"}, {"score": 0.004348580182733617, "phrase": "program_data_locality"}, {"score": 0.004251210982670317, "phrase": "low_overhead"}, {"score": 0.0040171817997972335, "phrase": "garbage_collector"}, {"score": 0.003949508242904001, "phrase": "profile_information"}, {"score": 0.0038610400240820307, "phrase": "low-overhead_mechanism"}, {"score": 0.0036691380448651443, "phrase": "key_contributions"}, {"score": 0.0034279721355412285, "phrase": "proactive_technique"}, {"score": 0.003370190834214415, "phrase": "data_locality"}, {"score": 0.0032208091960514128, "phrase": "normal_garbage_collection"}, {"score": 0.0030955250132409964, "phrase": "cache_locality_optimization"}, {"score": 0.0029249294679606656, "phrase": "sufficiently_detailed_data_access_information"}, {"score": 0.0027794243746094905, "phrase": "low_runtime_overhead"}, {"score": 0.0027170943110836425, "phrase": "experimental_results"}, {"score": 0.0024673738215365104, "phrase": "significantly_improved_optimizations_benefits"}, {"score": 0.0024257447861185813, "phrase": "page_and_cache_locality_optimizations"}, {"score": 0.0023445770108033288, "phrase": "larger_average_execution_time_improvements"}, {"score": 0.0021049977753042253, "phrase": "limited_profiling_overhead"}], "paper_keywords": ["data locality", " garbage collectors", " cache optimization", " page optimization", " memory optimization"], "paper_abstract": "Many applications written in garbage collected languages have large dynamic working sets and poor data locality. We present a new system for continuously improving program data locality at run time with low overhead. Our system proactively reorganizes the heap by leveraging the garbage collector and uses profile information collected through a low-overhead mechanism to guide the reorganization at run time. The key contributions include making a case that garbage collection should be viewed as a proactive technique for improving data locality by triggering garbage collection for locality optimization independently of normal garbage collection for space, combining page and cache locality optimization in the same system, and demonstrating that sampling provides sufficiently detailed data access information to guide both page and cache locality optimization with low runtime overhead. We present experimental results obtained by modifying a commercial, state-of-the-art garbage collector to support our claims. Independently triggering garbage collection for locality optimization significantly improved optimizations benefits. Combining page and cache locality optimizations in the same system provided larger average execution time improvements (17%) than either alone ( page 8%, cache 7%). Finally, using sampling limited profiling overhead to less than 3%, on average.", "paper_title": "Profile-guided proactive garbage collection for locality optimization", "paper_id": "WOS:000202972100029"}