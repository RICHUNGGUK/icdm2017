{"auto_keywords": [{"score": 0.048506844221552735, "phrase": "situation_awareness"}, {"score": 0.034188412736981345, "phrase": "traffic_vehicles"}, {"score": 0.00481495049065317, "phrase": "artificial_situation_awareness"}, {"score": 0.004774937143916685, "phrase": "increased_autonomy"}, {"score": 0.004735254735115024, "phrase": "unmanned_aerial_systems"}, {"score": 0.004598933498016774, "phrase": "human_function"}, {"score": 0.004319830179921363, "phrase": "critical_importance"}, {"score": 0.004266067096140677, "phrase": "safe_operation"}, {"score": 0.00417793854311445, "phrase": "highly_autonomous_unmanned_aerial_system"}, {"score": 0.0039571974661570695, "phrase": "acceptable_level"}, {"score": 0.003924284136338428, "phrase": "safety_verses"}, {"score": 0.0036400696415545813, "phrase": "terminal_area"}, {"score": 0.0035947360742084253, "phrase": "primary_concern"}, {"score": 0.003292770855568091, "phrase": "novel_method"}, {"score": 0.003265365666305185, "phrase": "spatial_projection"}, {"score": 0.0031845067058084583, "phrase": "autonomous_uas"}, {"score": 0.0031448288291084, "phrase": "terminal_stage"}, {"score": 0.0030797912111959137, "phrase": "projection_method"}, {"score": 0.003028727936200845, "phrase": "cooperative_means"}, {"score": 0.00300351371036355, "phrase": "traffic_perception"}, {"score": 0.002953711377604328, "phrase": "automated_dependant_surveillance_-_broadcast"}, {"score": 0.0028209599545587745, "phrase": "predefined_route"}, {"score": 0.0027510752634224726, "phrase": "terminal_region"}, {"score": 0.0024065032567542107, "phrase": "curvilinear_reference_frame"}, {"score": 0.0023665766694993535, "phrase": "discrete_transitions"}, {"score": 0.00216755493625594, "phrase": "computational_complexity"}, {"score": 0.0021049977753042253, "phrase": "significant_performance_benefit"}], "paper_keywords": ["Unmammed aerial system", " Autonomy", " Situation awareness"], "paper_abstract": "Situation awareness is the human function of perceiving, comprehending and projecting the state of the environment which is of critical importance to the safe operation of aircraft. A highly autonomous Unmanned Aerial System (UAS) must replicate this behaviour in order to maintain an acceptable level of safety verses a manned vehicle. Nowhere in the flight is situation awareness more critical than during operation in the terminal area. Of primary concern during this stage of flight is the awareness of other traffic heading for the same airfield. This paper presents of a novel method of spatial projection of traffic vehicles encountered by an autonomous UAS in the terminal stage of flight. This projection method relies on a cooperative means of traffic perception, such as Automated Dependant Surveillance - Broadcast (ADS-B) and assumes there is a predefined route which vehicles follow through the terminal region. Whilst this is the case at the majority of airfield, traffic vehicles will not follow this path perfectly. This uncertainty in path following accuracy is captured by utilising a curvilinear reference frame and dealing with discrete transitions (such as the initiation of a turn) separately. It is shown that whilst this technique increases the computational complexity of the problem it can offer significant performance benefit.", "paper_title": "Artificial Situation Awareness for Increased Autonomy of Unmanned Aerial Systems in the Terminal Area", "paper_id": "WOS:000312642600037"}