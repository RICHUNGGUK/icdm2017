{"auto_keywords": [{"score": 0.04263485709103403, "phrase": "nonresponse_error"}, {"score": 0.0036064757492752703, "phrase": "response_rates"}, {"score": 0.002830757050018908, "phrase": "confidence_intervals"}, {"score": 0.002664375650349975, "phrase": "research_findings"}, {"score": 0.0023603078194781965, "phrase": "general_discussion"}, {"score": 0.0021049977753042253, "phrase": "external_validity"}], "paper_keywords": ["response rate", " nonresponse errors", " external validity", " statistical conclusion validity"], "paper_abstract": "We believe IS researchers can and should do a better of job of improving ( assuring) the validity of their findings by minimizing nonresponse error. To demonstrate that there is, in fact, a problem, we first present the response rates reported in six well-regarded IS journals and summarize how nonresponse error was estimated and handled in published IS research. To illustrate how nonresponse error may bias findings in IS research, we calculate its impact on confidence intervals. After demonstrating the impact of nonresponse on research findings, we discuss three post hoc remedies and three preventative measures for the IS researcher to consider. The paper concludes with a general discussion about nonresponse and its implications for IS research practice. In our delimitations section, we suggest directions for further exploring external validity.", "paper_title": "How low should you go? Low response rates and the validity of inference in IS questionnaire research", "paper_id": "WOS:000246738500001"}