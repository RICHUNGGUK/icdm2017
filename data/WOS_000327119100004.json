{"auto_keywords": [{"score": 0.02927701149985092, "phrase": "gpu"}, {"score": 0.015033418419637855, "phrase": "heterogeneous_architectures"}, {"score": 0.009144717685649223, "phrase": "cpu"}, {"score": 0.00481495049065317, "phrase": "adaptive_virtual_channel"}, {"score": 0.004556901872357751, "phrase": "current_heterogeneous_chip-multiprocessors"}, {"score": 0.0044219992735047954, "phrase": "gpu_architecture"}, {"score": 0.004122490120202936, "phrase": "different_pressures"}, {"score": 0.004081385289516914, "phrase": "shared_resource_management"}, {"score": 0.004020492138367616, "phrase": "differing_characteristics"}, {"score": 0.003940706575253453, "phrase": "gpu_cores"}, {"score": 0.003766908559075843, "phrase": "-chip_resources"}, {"score": 0.003673675864705682, "phrase": "heterogeneous_system"}, {"score": 0.003407549468745519, "phrase": "chip_interconnection"}, {"score": 0.003339886795391701, "phrase": "shared_resources"}, {"score": 0.0032900200522703923, "phrase": "last-level_cache_tiles"}, {"score": 0.0031448288291084, "phrase": "on-chip_network"}, {"score": 0.0030823667846259836, "phrase": "significant_impact"}, {"score": 0.0029169007179202164, "phrase": "feedback-directed_virtual_channel"}, {"score": 0.0028446460307503343, "phrase": "on-chip_routers"}, {"score": 0.002816246391862638, "phrase": "effectively_share_network_bandwidth"}, {"score": 0.0027054473441439422, "phrase": "heterogeneous_architecture"}, {"score": 0.0026784342661280683, "phrase": "vcp"}, {"score": 0.0025473475682739784, "phrase": "separate_injection_queues"}, {"score": 0.0022696277881969896, "phrase": "best_partitioning_configuration"}, {"score": 0.0021802872319258977, "phrase": "system_throughput"}], "paper_keywords": ["Design", " Performance", " Heterogeneous architecture", " on-chip network", " quality-of-service"], "paper_abstract": "Current heterogeneous chip-multiprocessors (CMPs) integrate a GPU architecture on a die. However, the heterogeneity of this architecture inevitably exerts different pressures on shared resource management due to differing characteristics of CPU and GPU cores. We consider how to efficiently share on-chip resources between cores within the heterogeneous system, in particular the on-chip network. Heterogeneous architectures use an on-chip interconnection network to access shared resources such as last-level cache tiles and memory controllers, and this type of on-chip network will have a significant impact on performance. In this article, we propose a feedback-directed virtual channel partitioning (VCP) mechanism for on-chip routers to effectively share network bandwidth between CPU and GPU cores in a heterogeneous architecture. VCP dedicates a few virtual channels to CPU and GPU applications with separate injection queues. The proposed mechanism balances on-chip network bandwidth for applications running on CPU and GPU cores by adaptively choosing the best partitioning configuration. As a result, our mechanism improves system throughput by 15% over the baseline across 39 heterogeneous workloads.", "paper_title": "Adaptive Virtual Channel Partitioning for Network-on-Chip in Heterogeneous Architectures", "paper_id": "WOS:000327119100004"}