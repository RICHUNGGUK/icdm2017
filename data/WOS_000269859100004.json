{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "inexact_newton_method"}, {"score": 0.00475070135279933, "phrase": "nonconvex_equality"}, {"score": 0.0045324756541157574, "phrase": "matrix-free_line_search_algorithm"}, {"score": 0.004209539728590977, "phrase": "inexact_step_computations"}, {"score": 0.004125513927068713, "phrase": "strictly_convex_problems"}, {"score": 0.003935892934907777, "phrase": "inexact_sequential_quadratic_programming_approach"}, {"score": 0.0038573081851680656, "phrase": "byrd_et_al"}, {"score": 0.00344062888674746, "phrase": "nonconvex_problems"}, {"score": 0.003152531962718477, "phrase": "negative_curvature"}, {"score": 0.0029672941061574375, "phrase": "primal-dual_iteration_matrix"}, {"score": 0.002830757050018908, "phrase": "second-order_information"}, {"score": 0.0027741761880779535, "phrase": "problem_functions"}, {"score": 0.0026823700218343506, "phrase": "exact_second_derivatives"}, {"score": 0.002524688179363081, "phrase": "complete_algorithm"}, {"score": 0.0024247382451294255, "phrase": "sufficient_reductions"}, {"score": 0.0023287359930308864, "phrase": "exact_penalty_function"}, {"score": 0.002251637552201872, "phrase": "global_behavior"}, {"score": 0.0021770860717929192, "phrase": "present_numerical_results"}, {"score": 0.0021049977753042253, "phrase": "test_problems"}], "paper_keywords": ["Large-scale optimization", " Constrained optimization", " Nonconvex programming", " Inexact linear system solvers", " Krylov subspace methods"], "paper_abstract": "We present a matrix-free line search algorithm for large-scale equality constrained optimization that allows for inexact step computations. For strictly convex problems, the method reduces to the inexact sequential quadratic programming approach proposed by Byrd et al. [SIAM J. Optim. 19(1) 351-369, 2008]. For nonconvex problems, the methodology developed in this paper allows for the presence of negative curvature without requiring information about the inertia of the primal-dual iteration matrix. Negative curvature may arise from second-order information of the problem functions, but in fact exact second derivatives are not required in the approach. The complete algorithm is characterized by its emphasis on sufficient reductions in a model of an exact penalty function. We analyze the global behavior of the algorithm and present numerical results on a collection of test problems.", "paper_title": "An inexact Newton method for nonconvex equality constrained optimization", "paper_id": "WOS:000269859100004"}