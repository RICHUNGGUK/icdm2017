{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "media_stream_interactions"}, {"score": 0.004701015188740582, "phrase": "multimedia_browsing"}, {"score": 0.0038810583785936505, "phrase": "collaborative_meetings"}, {"score": 0.0036993855514735746, "phrase": "audio_channel"}, {"score": 0.0035687137873965684, "phrase": "shared_text_editor"}, {"score": 0.0034426417353349567, "phrase": "virtual_meeting_environment"}, {"score": 0.0031654684543975077, "phrase": "broadcasting_speech"}, {"score": 0.0027741761880779535, "phrase": "continuous_multimedia_data"}, {"score": 0.0024311346712789553, "phrase": "simple_linkage_patterns"}, {"score": 0.002262209824105154, "phrase": "information_retrieval"}, {"score": 0.0022085455097790537, "phrase": "non-linear_browsing"}, {"score": 0.0021049977753042253, "phrase": "audio_segmentation_issues"}], "paper_keywords": [""], "paper_abstract": "This paper presents an approach to the issue of adding structure to recordings of collaborative meetings supported by an audio channel and a shared text editor. The virtual meeting environment used is capable of capturing and broadcasting speech, gestures and editing operations in real-time, so recording results in continuous multimedia data. We describe the implementation of a browser which explores simple linkage patterns between these media to support information retrieval through non-linear browsing, and discuss audio segmentation issues arising from this approach.", "paper_title": "Exploring the structure of media stream interactions for multimedia browsing", "paper_id": "WOS:000236463100007"}