{"auto_keywords": [{"score": 0.03719615111360805, "phrase": "corruption_attacks"}, {"score": 0.013916972292378232, "phrase": "published_table"}, {"score": 0.00481495049065317, "phrase": "independent_l-diversity"}, {"score": 0.004747714939490445, "phrase": "individuals'_information"}, {"score": 0.004681413843223496, "phrase": "back-end_databases"}, {"score": 0.004551563730037998, "phrase": "social_networks"}, {"score": 0.004472234553892357, "phrase": "sensitive_individuals'_information"}, {"score": 0.004363480951473701, "phrase": "serious_problem"}, {"score": 0.0042126709243529275, "phrase": "social_network"}, {"score": 0.004124688058533477, "phrase": "valuable_information"}, {"score": 0.0040102178375662914, "phrase": "sensitive_information"}, {"score": 0.003737697279708501, "phrase": "corruption_attack"}, {"score": 0.003447035529485425, "phrase": "severe_information_loss"}, {"score": 0.0033513085425415545, "phrase": "published_data"}, {"score": 0.00329282940819675, "phrase": "ppdp_models"}, {"score": 0.0031901183059524804, "phrase": "individual_sensitive_information_disclosure"}, {"score": 0.00304737045343781, "phrase": "independent_l-diversity_principle"}, {"score": 0.0029212625534156063, "phrase": "ppdp_model"}, {"score": 0.0027225413530200505, "phrase": "corruption_abilities"}, {"score": 0.002693919110230191, "phrase": "new_data_utility_measurement_global_loss_penalty"}, {"score": 0.0026190518142076608, "phrase": "related_algorithms"}, {"score": 0.002537303919584199, "phrase": "extensive_experiments"}, {"score": 0.002290814637620121, "phrase": "l-diversity_model"}], "paper_keywords": ["anonymization", " privacy", " l-diversity", " social network"], "paper_abstract": "Datasets containing individuals' information (stored in back-end databases) are often published and shared in social networks. The disclosure of sensitive individuals' information in social networks is potentially a serious problem. When an attacker studies a published table in a social network, the attacker could infer valuable information of individuals if the attacker learnt some sensitive information of other related individuals from other sources which are different from the published table. This type of attack is referred to as corruption attack. Existing privacy-preserving data publication (PPDP) approaches have been developed against corruption attacks, however, they could cause severe information loss, and reduce the usefulness of the published data. In addition, PPDP models based on l-diversity and its variants may lead to individual sensitive information disclosure. Motivated by providing a solution to overcome these drawbacks, an independent l-diversity principle is proposed in this study. Based on this principle a PPDP model is presented. The model could prevent attacks from attackers who have known data publishing algorithms and have the corruption abilities. A new data utility measurement global loss penalty is also proposed in this study. Related algorithms to our approach have been developed and implemented. Extensive experiments have been performed and comparisons with other related methods have been made. The results have shown the effectiveness of our approaches. It has been noted that when compared with l-diversity model and its variant models, our model could resist corruption attacks more effectively; furthermore, when compared with other solutions against corruption attacks, our method would result in less information loss.", "paper_title": "Privacy-Preserving Data Publication with Features of Independent l-Diversity", "paper_id": "WOS:000359137500004"}