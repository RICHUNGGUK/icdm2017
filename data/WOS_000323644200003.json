{"auto_keywords": [{"score": 0.036866004068638804, "phrase": "denver"}, {"score": 0.00481495049065317, "phrase": "well-labeled_recordings"}, {"score": 0.004586531354697466, "phrase": "automated_facial_expression_recognition"}, {"score": 0.004392565073466714, "phrase": "publicly_available_databases"}, {"score": 0.004298666679374568, "phrase": "posed_facial_behavior"}, {"score": 0.0038168424095396205, "phrase": "publicly_available_corpora"}, {"score": 0.003775803846431323, "phrase": "well-labeled_video"}, {"score": 0.0034442607586033657, "phrase": "spontaneous_facial_action_database"}, {"score": 0.003407214479510987, "phrase": "twenty-seven_young_adults"}, {"score": 0.003298441494378465, "phrase": "stereo_camera"}, {"score": 0.0032278559855285945, "phrase": "video_clips"}, {"score": 0.003158776195052182, "phrase": "spontaneous_emotion_expression"}, {"score": 0.003107935254560724, "phrase": "video_frame"}, {"score": 0.0029126002350975634, "phrase": "facial_action_units"}, {"score": 0.0028502479839354637, "phrase": "facial_action_unit_coding_system"}, {"score": 0.0027741761880779535, "phrase": "action_units"}, {"score": 0.0027295084882654917, "phrase": "smallest_visibly_discriminable_changes"}, {"score": 0.002410058288617039, "phrase": "future_research"}, {"score": 0.002333044307949414, "phrase": "automated_action_unit_intensity_measurement"}, {"score": 0.0021627595586364724, "phrase": "computer_vision"}, {"score": 0.0021394674440767124, "phrase": "machine_learning"}, {"score": 0.0021049977753042253, "phrase": "affective_and_behavioral_science"}], "paper_keywords": ["FACS", " action units", " intensity", " spontaneous facial behavior", " facial expression", " video corpus"], "paper_abstract": "Access to well-labeled recordings of facial expression is critical to progress in automated facial expression recognition. With few exceptions [1], publicly available databases are limited to posed facial behavior that can differ markedly in conformation, intensity, and timing from what occurs spontaneously. To meet the need for publicly available corpora of well-labeled video, we collected, ground-truthed, and prepared for distribution the Denver intensity of spontaneous facial action database. Twenty-seven young adults were video recorded by a stereo camera while they viewed video clips intended to elicit spontaneous emotion expression. Each video frame was manually coded for presence, absence, and intensity of facial action units according to the facial action unit coding system [2]. Action units are the smallest visibly discriminable changes in facial action; they may occur individually and in combinations to comprise more molar facial expressions. To provide a baseline for use in future research, protocols and benchmarks for automated action unit intensity measurement are reported. Details are given for accessing the database for research in computer vision, machine learning, and affective and behavioral science.", "paper_title": "DISFA: A Spontaneous Facial Action Intensity Database", "paper_id": "WOS:000323644200003"}