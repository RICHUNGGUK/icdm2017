{"auto_keywords": [{"score": 0.04683843572993089, "phrase": "gpu"}, {"score": 0.04351243662816075, "phrase": "optimum_approach"}, {"score": 0.037415235204872284, "phrase": "single_gpu"}, {"score": 0.00481495049065317, "phrase": "violent_hydrodynamics"}, {"score": 0.00458063009056137, "phrase": "sph"}, {"score": 0.0045196012587080114, "phrase": "graphics_processing_unit"}, {"score": 0.004444921827311577, "phrase": "large_numbers"}, {"score": 0.004256455007398593, "phrase": "novel_hardware_architectures"}, {"score": 0.004103212598803194, "phrase": "multi-phase_scheme"}, {"score": 0.00406238127438793, "phrase": "new_challenges"}, {"score": 0.003800324235902955, "phrase": "largest_speed"}, {"score": 0.003737485125097945, "phrase": "time_step"}, {"score": 0.003687960013746783, "phrase": "efficient_computation"}, {"score": 0.0036390887584943723, "phrase": "full_advantage"}, {"score": 0.0036028592508983402, "phrase": "hardware_acceleration"}, {"score": 0.0035197152758635344, "phrase": "multi-phase_simulation"}, {"score": 0.003449972561293443, "phrase": "conditional_statements"}, {"score": 0.003427032390942116, "phrase": "binary_operators"}, {"score": 0.003404244237372396, "phrase": "separate_particle_lists"}, {"score": 0.003370344851760079, "phrase": "intermediate_global_function"}, {"score": 0.0033479323773364716, "phrase": "runtime_results"}, {"score": 0.0032597581672236453, "phrase": "separate_cell"}, {"score": 0.0032380786944838204, "phrase": "neighbour_lists"}, {"score": 0.0030595112110658675, "phrase": "memory_transactions"}, {"score": 0.0030391594477173485, "phrase": "arithmetic_operations"}, {"score": 0.0030189426536422577, "phrase": "significant_runtime_gains"}, {"score": 0.0029101233953870466, "phrase": "optimised_single-phase_gpu_code"}, {"score": 0.0028907624732186373, "phrase": "dualsphysics"}, {"score": 0.002795867549039675, "phrase": "multi-phase_functionality"}, {"score": 0.0027680095380207756, "phrase": "significant_computational_overhead"}, {"score": 0.0027131212233443137, "phrase": "optimised_cpu_code"}, {"score": 0.00260657976055413, "phrase": "openmp_simulation"}, {"score": 0.002529421374791293, "phrase": "single_thread_simulation"}, {"score": 0.002470987929071079, "phrase": "sph_gpu"}, {"score": 0.002366017944545902, "phrase": "better_agreement"}, {"score": 0.0023502683992739845, "phrase": "experimental_results"}, {"score": 0.0023268399760599336, "phrase": "equivalent_single-phase_code"}, {"score": 0.0023036445575469046, "phrase": "multi-phase_gpu_code"}, {"score": 0.0022057677637040396, "phrase": "large_number"}, {"score": 0.0021476098263617954, "phrase": "large_high_performance_computing_resources"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Meshfree methods", " SPH", " Multi-phase flows", " Gas-liquid flows", " GPU", " Optimisation"], "paper_abstract": "This paper presents the acceleration of multi-phase smoothed particle hydrodynamics (SPH) using a graphics processing unit (GPU) enabling large numbers of particles (10-20 million) to be simulated on just a single GPU card. With novel hardware architectures such as a GPU, the optimum approach to implement a multi-phase scheme presents some new challenges. Many more particles must be included in the calculation and there are very different speeds of sound in each phase with the largest speed of sound determining the time step. This requires efficient computation. To take full advantage of the hardware acceleration provided by a single GPU for a multi-phase simulation, four different algorithms are investigated: conditional statements, binary operators, separate particle lists and an intermediate global function. Runtime results show that the optimum approach needs to employ separate cell and neighbour lists for each phase. The profiler shows that this approach leads to a reduction in both memory transactions and arithmetic operations giving significant runtime gains. The four different algorithms are compared to the efficiency of the optimised single-phase GPU code, DualSPHysics, for 2-D and 3-D simulations which indicate that the multi-phase functionality has a significant computational overhead. A comparison with an optimised CPU code shows a speed up of an order of magnitude over an OpenMP simulation with 8 threads and two orders of magnitude over a single thread simulation. A demonstration of the multi-phase SPH GPU code is provided by a 3-D dam break case impacting an obstacle. This shows better agreement with experimental results than an equivalent single-phase code. The multi-phase GPU code enables a convergence study to be undertaken on a single GPU with a large number of particles that otherwise would have required large high performance computing resources. (C) 2015 Elsevier B.V. All rights reserved.", "paper_title": "Multi-phase SPH modelling of violent hydrodynamics on GPUs", "paper_id": "WOS:000362602900029"}