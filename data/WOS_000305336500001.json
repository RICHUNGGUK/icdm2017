{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "cognitive_architecture"}, {"score": 0.04190654586339915, "phrase": "irreducibility_problem"}, {"score": 0.027089261362038656, "phrase": "perceptual_abstraction"}, {"score": 0.004742948310694449, "phrase": "multiple_levels"}, {"score": 0.004648609688625397, "phrase": "intelligent_behavior"}, {"score": 0.004556138899217213, "phrase": "appropriate_abstract_representation"}, {"score": 0.004465499299203836, "phrase": "general-purpose_cognitive_architecture"}, {"score": 0.004387663527830982, "phrase": "abstraction_arise"}, {"score": 0.004151723505230932, "phrase": "single_perception_system"}, {"score": 0.0041102032028337366, "phrase": "appropriate_abstract_representations"}, {"score": 0.0038599102084533403, "phrase": "first_contribution"}, {"score": 0.0037546476864907443, "phrase": "second_contribution"}, {"score": 0.0036066231834717545, "phrase": "mental_imagery"}, {"score": 0.0034125384776896696, "phrase": "external_world"}, {"score": 0.0033868916699805224, "phrase": "abstract_representation"}, {"score": 0.0032779570262382366, "phrase": "concrete_representation"}, {"score": 0.0032207537133035822, "phrase": "abstract_information"}, {"score": 0.0031965436338347295, "phrase": "perceptual_processes"}, {"score": 0.0031725149598665395, "phrase": "resulting_concrete_state"}, {"score": 0.003117145951698424, "phrase": "perceptual_abstraction_problem"}, {"score": 0.00304737045343781, "phrase": "wider_variety"}, {"score": 0.002890557197908352, "phrase": "internal_simulation"}, {"score": 0.0028760489172318516, "phrase": "low-level_control_processes"}, {"score": 0.002748698897937274, "phrase": "soar_architecture"}, {"score": 0.002687148641091278, "phrase": "reinforcement_learning"}, {"score": 0.002646880721119838, "phrase": "arcade_game"}, {"score": 0.0026072146533685087, "phrase": "sampling-based_motion_planning"}, {"score": 0.0025876045125130154, "phrase": "car-like_vehicle"}, {"score": 0.0025106241866273897, "phrase": "associated_use"}, {"score": 0.0024605773668116893, "phrase": "complex_ai_tasks"}, {"score": 0.00244822194134941, "phrase": "previous_ai_systems"}, {"score": 0.0024298047493967628, "phrase": "imagery-like_processes"}, {"score": 0.0023994160566062563, "phrase": "functional_benefit"}, {"score": 0.002275869477027725, "phrase": "specialized_representation"}, {"score": 0.002169567905478814, "phrase": "broader_understanding"}, {"score": 0.002131665617422672, "phrase": "cognitive_systems"}], "paper_keywords": [""], "paper_abstract": "In a cognitive architecture, intelligent behavior is contingent upon the use of an appropriate abstract representation of the task. When designing a general-purpose cognitive architecture, two basic challenges related to abstraction arise, which are introduced and examined in this article. The perceptual abstraction problem results from the difficulty of creating a single perception system able to induce appropriate abstract representations in any task the agent might encounter, and the irreducibility problem arises because some tasks are resistant to being abstracted at all. The first contribution of this paper is identifying these problems, and the second contribution is showing a means to address them. This is accomplished through the use of mental imagery. To support imagery, a concrete (highly detailed) representation of the spatial state of the problem is maintained as an intermediate between the external world and an abstract representation. Actions can be simulated (imagined) in terms of this concrete representation, and the agent can derive abstract information by applying perceptual processes to the resulting concrete state. Imagery works to mitigate the perceptual abstraction problem by allowing a given perception system to work in a wider variety of tasks, since perception can be dynamically combined with imagery, and works to mitigate the irreducibility problem by allowing internal simulation of low-level control processes. To demonstrate these benefits, an implementation is described, which is an extension of the Soar architecture. An agent in this architecture that uses reinforcement learning and imagery to play an arcade game and an agent that performs sampling-based motion planning for a car-like vehicle are described, demonstrating the perceptual abstraction and irreducibility problems and the associated use of imagery to mitigate those problems in complex AI tasks. Previous AI systems have incorporated imagery-like processes, however, the functional benefit of imagery in those systems has typically been characterized as the ability to perform more efficient inference through the use of a specialized representation. The use of imagery here shows further benefits related to the perceptual abstraction and irreducibility problems, enriching the broader understanding of the role of imagery in cognitive systems. (C) 2012 Elsevier B. V. All rights reserved.", "paper_title": "Imagery in cognitive architecture: Representation and control at multiple levels of abstraction", "paper_id": "WOS:000305336500001"}