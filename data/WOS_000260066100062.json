{"auto_keywords": [{"score": 0.048718786750838995, "phrase": "pattern_storage"}, {"score": 0.004815315143889019, "phrase": "upper"}, {"score": 0.004589124394375718, "phrase": "feedforward_networks"}, {"score": 0.004168618849008299, "phrase": "nonlinear_feedforward_networks"}, {"score": 0.004089239912167375, "phrase": "analytic_activation_functions"}, {"score": 0.003934970057482768, "phrase": "multilayer_perceptron"}, {"score": 0.0038600230206554792, "phrase": "radial_basis_function_network"}, {"score": 0.0034392837410790293, "phrase": "network_weights"}, {"score": 0.0031238084716187805, "phrase": "output_nodes"}, {"score": 0.0030642636185693054, "phrase": "arbitrary_connectivity"}, {"score": 0.0029203055813347874, "phrase": "strict_interpolation_equations"}, {"score": 0.002864628676257225, "phrase": "exact_finite_degree_polynomial_models"}, {"score": 0.002677964894127131, "phrase": "straightforward_proof"}, {"score": 0.0025034338848015166, "phrase": "upper_bound"}, {"score": 0.00236289633510808, "phrase": "conjugate_gradient"}, {"score": 0.0021049977753042253, "phrase": "random_patterns"}], "paper_keywords": ["Pattern storage", " Memorization", " Upper bound"], "paper_abstract": "An upper bound on pattern storage is stated for nonlinear feedforward networks with analytic activation functions, like the multilayer perceptron and radial basis function network. The bound is given in terms of the number of network weights, and applies to networks having any number of output nodes and arbitrary connectivity. Starting from the strict interpolation equations and exact finite degree polynomial models for the hidden units, a straightforward proof by contradiction is developed for the upper bound. Several networks, trained by conjugate gradient, are used to demonstrate the tightness of the bound for random patterns. (C) 2008 Elsevier B.V. All rights reserved.", "paper_title": "Upper bound on pattern storage in feedforward networks", "paper_id": "WOS:000260066100062"}