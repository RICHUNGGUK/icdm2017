{"auto_keywords": [{"score": 0.04893638421315736, "phrase": "visual_features"}, {"score": 0.015129979968627577, "phrase": "web_image_retrieval"}, {"score": 0.014285999417050398, "phrase": "web_images"}, {"score": 0.0118510811489174, "phrase": "mmsar"}, {"score": 0.008506520874474718, "phrase": "proposed_approach"}, {"score": 0.00481495049065317, "phrase": "multi-modal_semantic_association_rules"}, {"score": 0.00456571874088313, "phrase": "recent_trend"}, {"score": 0.004521803560561489, "phrase": "image_search"}, {"score": 0.003987755561492638, "phrase": "key_issue"}, {"score": 0.0037087324991876727, "phrase": "new_approach"}, {"score": 0.0036553070575015344, "phrase": "multi-modal_semantic_association_rule"}, {"score": 0.003334309053314909, "phrase": "single_keyword"}, {"score": 0.0031159081999910694, "phrase": "customized_frequent_itemsets_mining_algorithm"}, {"score": 0.0030414140732789186, "phrase": "particular_mmsars"}, {"score": 0.0029830992938695007, "phrase": "existing_inverted_file"}, {"score": 0.002925899335792914, "phrase": "new_support-confidence_framework"}, {"score": 0.002855934865505357, "phrase": "mining_algorithm"}, {"score": 0.0027876387169652717, "phrase": "mined_mmsars"}, {"score": 0.002630299922281955, "phrase": "retrieval_process"}, {"score": 0.0025181367444581967, "phrase": "retrieval_precision"}, {"score": 0.0024578987081792405, "phrase": "fast_response_time"}, {"score": 0.0023530698447434308, "phrase": "web_image_retrieval_system"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Web image retrieval", " Multi-Modal Semantic Association Rule (MMSAR)", " Association rule mining", " Inverted file", " Relevance Feedback (RF)"], "paper_abstract": "A recent trend for image search is to fuse the two basic modalities of Web images, i.e., textual features (usually represented by keywords) and visual features for retrieval. The key issue is how to associate the two modalities for fusion. In this paper, a new approach based on Multi-Modal Semantic Association Rule (MMSAR) is proposed to fuse keywords and visual features automatically for Web image retrieval. A MMSAR contains a single keyword and several visual feature clusters, which crosses and associates the two modalities of Web images. A customized frequent itemsets mining algorithm is designed for the particular MMSARs based on the existing inverted file, and a new support-confidence framework is defined for the mining algorithm. Based on the mined MMSARs, the keywords and the visual features are fused automatically in the retrieval process. The proposed approach not only remarkably improves the retrieval precision, but also has fast response time. The experiments are carried out in a Web image retrieval system, VAST (VisuAl & SemanTic image search), and the results show the superiority and effectiveness of the proposed approach. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Using Multi-Modal Semantic Association Rules to fuse keywords and visual features automatically for Web image retrieval", "paper_id": "WOS:000290694100010"}