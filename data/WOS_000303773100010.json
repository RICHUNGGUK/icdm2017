{"auto_keywords": [{"score": 0.04981678864806054, "phrase": "dantzig_selector"}, {"score": 0.035620716932052585, "phrase": "proposed_method"}, {"score": 0.011496443425277555, "phrase": "large_probability"}, {"score": 0.007864475095834846, "phrase": "oracle_solution"}, {"score": 0.00481495049065317, "phrase": "multi-stage_framework"}, {"score": 0.00476238531747092, "phrase": "lasso."}, {"score": 0.004545240514015278, "phrase": "design_matrix_x"}, {"score": 0.0043738432231020885, "phrase": "noisy_observation_vector_y"}, {"score": 0.0041743471385355824, "phrase": "noise_vector"}, {"score": 0.0041400946070776256, "phrase": "gaussian_distribution"}, {"score": 0.003983913892907531, "phrase": "parameter_vector"}, {"score": 0.0038125954036382177, "phrase": "sparse_signal_recovery"}, {"score": 0.00379170322821611, "phrase": "strong_theoretical_guarantees"}, {"score": 0.003699090930502201, "phrase": "multi-stage_dantzig_selector_method"}, {"score": 0.003350642235305096, "phrase": "true_solution_beta"}, {"score": 0.003018273305489126, "phrase": "nonzero_entries"}, {"score": 0.0029289268294876397, "phrase": "delta"}, {"score": 0.002841092355583839, "phrase": "first_term"}, {"score": 0.002608893678760607, "phrase": "standard_dantzig_selector"}, {"score": 0.0024760366863460117, "phrase": "large_entries"}, {"score": 0.0024154816080358336, "phrase": "proposed_algorithm"}, {"score": 0.0023759346019385638, "phrase": "high_probability"}, {"score": 0.0023114531962324966, "phrase": "observation_vector_y"}, {"score": 0.0022987679645976354, "phrase": "true_features"}, {"score": 0.002199755017143123, "phrase": "correct_features"}, {"score": 0.0021816694697063843, "phrase": "milder_condition"}, {"score": 0.0021224490836605804, "phrase": "multi-stage_procedure"}, {"score": 0.0021049977753042253, "phrase": "lasso_case"}], "paper_keywords": ["multi-stage", " Dantzig selector", " LASSO", " sparse signal recovery"], "paper_abstract": "We consider the following sparse signal recovery (or feature selection) problem: given a design matrix X is an element of R-nxm (m >> n) and a noisy observation vector y is an element of R-n satisfying y = X beta* + epsilon where e is the noise vector following a Gaussian distribution N(0, sigma I-2), how to recover the signal (or parameter vector) beta* when the signal is sparse? The Dantzig selector has been proposed for sparse signal recovery with strong theoretical guarantees. In this paper, we propose a multi-stage Dantzig selector method, which iteratively refines the target signal beta*. We show that if X obeys a certain condition, then with a large probability the difference between the solution (beta) over cap estimated by the proposed method and the true solution beta* measured in terms of the l(p) norm (p >= 1) is bounded as parallel to(beta) over cap-beta*parallel to p <= (C(s-N)(1/p) root logm+Delta)sigma, where C is a constant, s is the number of nonzero entries in beta*, the risk of the oracle estimator Delta is independent of m and is much smaller than the first term, and N is the number of entries of beta* larger than a certain value in the order of O(sigma root logm). The proposed method improves the estimation bound of the standard Dantzig selector approximately from Cs-1/p root logm sigma to C(s-N)(1/p) root logm sigma where the value N depends on the number of large entries in beta*. When N = s, the proposed algorithm achieves the oracle solution with a high probability, where the oracle solution is the projection of the observation vector y onto true features. In addition, with a large probability, the proposed method can select the same number of correct features under a milder condition than the Dantzig selector. Finally, we extend this multi-stage procedure to the LASSO case.", "paper_title": "A Multi-Stage Framework for Dantzig Selector and LASSO", "paper_id": "WOS:000303773100010"}