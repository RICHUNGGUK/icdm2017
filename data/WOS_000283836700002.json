{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "lexical_inference"}, {"score": 0.0047057084749407485, "phrase": "distributional_word_similarity"}, {"score": 0.004342430078306461, "phrase": "symmetric_relation"}, {"score": 0.004147523799581407, "phrase": "directional_relations"}, {"score": 0.003961330917648707, "phrase": "lexical_semantics"}, {"score": 0.003531474887552889, "phrase": "symmetric_similarity_measures"}, {"score": 0.00290473242917264, "phrase": "distributional_feature_inclusion"}, {"score": 0.0027741761880779535, "phrase": "desired_properties"}, {"score": 0.002530359917257626, "phrase": "particular_measure"}, {"score": 0.002444544487772349, "phrase": "average_precision"}, {"score": 0.0022041312401435346, "phrase": "empirical_benefit"}, {"score": 0.0021539955106204354, "phrase": "directional_measures"}], "paper_keywords": [""], "paper_abstract": "Distributional word similarity is most commonly perceived as a symmetric relation. Yet, directional relations are abundant in lexical semantics and in many Natural Language Processing (NLP) settings that require lexical inference, making symmetric similarity measures less suitable for their identification. This paper investigates the nature of directional (asymmetric) similarity measures that aim to quantify distributional feature inclusion. We identify desired properties of such measures for lexical inference, specify a particular measure based on Average Precision that addresses these properties, and demonstrate the empirical benefit of directional measures for two different NLP datasets.", "paper_title": "Directional distributional similarity for lexical inference", "paper_id": "WOS:000283836700002"}