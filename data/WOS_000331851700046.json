{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "eyeball_movement_pattern"}, {"score": 0.03546730795101328, "phrase": "pupil_size"}, {"score": 0.033554212711224725, "phrase": "human's_implicit_intention"}, {"score": 0.02712650942783671, "phrase": "proposed_model"}, {"score": 0.004765173195920904, "phrase": "pupil_size_variation"}, {"score": 0.0046429592670444945, "phrase": "efficient_nonverbal_human_computer_interaction_system"}, {"score": 0.004477083974172596, "phrase": "user's_implicit_intention"}, {"score": 0.004294724955301414, "phrase": "cognitive_visuo-motor_theory"}, {"score": 0.00422826362023938, "phrase": "human_eye_movements"}, {"score": 0.004162826481635768, "phrase": "rich_source"}, {"score": 0.004055998173160551, "phrase": "human_intention"}, {"score": 0.003931402465972151, "phrase": "beatty's_study"}, {"score": 0.003870541730075597, "phrase": "task-evoked_pupillary_response"}, {"score": 0.0037321585095070483, "phrase": "human_cognitive_load"}, {"score": 0.0035245918797629804, "phrase": "novel_approach"}, {"score": 0.0034700069041302003, "phrase": "human's_implicit_intention_recognition"}, {"score": 0.0032599633778910516, "phrase": "bernard's_research"}, {"score": 0.0031270239691197515, "phrase": "visual_stimulus"}, {"score": 0.0030946423142739813, "phrase": "informational_and_navigational_intent"}, {"score": 0.0030308784612749647, "phrase": "present_study"}, {"score": 0.002983916676307492, "phrase": "navigational_intent"}, {"score": 0.0029224275921964724, "phrase": "human's_idea"}, {"score": 0.0028622019660721363, "phrase": "interesting_objects"}, {"score": 0.0028178463431115562, "phrase": "visual_input"}, {"score": 0.0027741761880779535, "phrase": "particular_goal"}, {"score": 0.0027311809666295565, "phrase": "informational_intent"}, {"score": 0.002674885993329912, "phrase": "human's_aspiration"}, {"score": 0.002619748321217153, "phrase": "particular_object"}, {"score": 0.002512850690695835, "phrase": "salient_features"}, {"score": 0.002435542816459651, "phrase": "fixation_length"}, {"score": 0.0024103044278902916, "phrase": "fixation_count"}, {"score": 0.0022524959504997303, "phrase": "experimental_results"}, {"score": 0.002171836484200008, "phrase": "plausible_recognition_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Eyeball movement", " Human implicit intention", " Navigational intent", " Informational intent", " Intention recognition", " Human computer interface and interaction", " Pupil size variation"], "paper_abstract": "To develop an efficient nonverbal human computer interaction system it is important to interpret the user's implicit intention, which is vague. According to cognitive visuo-motor theory, the human eye movements are a rich source of information about the human intention and behavior. According to Beatty's study, a task-evoked pupillary response is a consistent index of the human cognitive load and attention. In this paper, we propose a novel approach for a human's implicit intention recognition based on the eyeball movement pattern and pupil size variation. Based on the Bernard's research, we classify the human's implicit intention during a visual stimulus as informational and navigational intent. In the present study, the navigational intent refers to the human's idea to find some interesting objects in a visual input without a particular goal while the informational intent refers to the human's aspiration to find a particular object of interest. The proposed model utilizes the salient features of the eye such as fixation length, fixation count and pupil size variation as the inputs to classify the human's implicit intention. The experimental results show that the proposed model can achieve plausible recognition performance. (C) 2013 Elsevier B.V. All rights reserved.", "paper_title": "Human intention recognition based on eyeball movement pattern and pupil size variation", "paper_id": "WOS:000331851700046"}