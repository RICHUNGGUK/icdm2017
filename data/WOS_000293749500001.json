{"auto_keywords": [{"score": 0.04469716820426112, "phrase": "non-gaussian_noises"}, {"score": 0.00481495049065317, "phrase": "extended_hammerstein_systems_using_dynamic_self-optimizing_neural_networks"}, {"score": 0.004644014990871423, "phrase": "new_dynamic_self-optimizing_neural_network"}, {"score": 0.004525629293824217, "phrase": "online_adjusting_hidden_layer"}, {"score": 0.004320055598195391, "phrase": "extended_hammerstein_systems"}, {"score": 0.003997891221012094, "phrase": "system_order_estimation"}, {"score": 0.003936389070602614, "phrase": "designated_input_signal"}, {"score": 0.0038558497470953306, "phrase": "hidden_layer"}, {"score": 0.003680587852807675, "phrase": "growing_step"}, {"score": 0.0036052633308076933, "phrase": "plant_dynamics"}, {"score": 0.0035497797026638033, "phrase": "revised_pruning_step"}, {"score": 0.003459191419478298, "phrase": "hidden_structure"}, {"score": 0.0033883824438527316, "phrase": "generated_model"}, {"score": 0.0033190180867511605, "phrase": "minimal_realization"}, {"score": 0.0032848684681050745, "phrase": "satisfactory_performance"}, {"score": 0.0030396665931462, "phrase": "weight_variations"}, {"score": 0.0029620573986902416, "phrase": "structure_optimization"}, {"score": 0.0029164434911787187, "phrase": "integrated_performance"}, {"score": 0.0028715299874549245, "phrase": "identification_error"}, {"score": 0.0028273061946184645, "phrase": "additional_entropy_penalty_term"}, {"score": 0.0026026666736474404, "phrase": "unknown_plant"}, {"score": 0.0025493457404304446, "phrase": "suitable_structure"}, {"score": 0.0023958326775913165, "phrase": "learning_rates"}, {"score": 0.002358917661465133, "phrase": "proposed_dsonn"}, {"score": 0.002286781334850213, "phrase": "priori_knowledge"}, {"score": 0.002251542790734307, "phrase": "unknown_nonlinearity"}], "paper_keywords": ["Dynamic self-optimizing neural network", " extended Hammerstein systems", " integrated performance", " system identification"], "paper_abstract": "In this paper, a new dynamic self-optimizing neural network (DSONN) with online adjusting hidden layer and weights is proposed for a class of extended Hammerstein systems with non-Gaussian noises. Input vector to the network is first determined by means of system order estimation using a designated input signal. Then the hidden layer is generated online, which consists of a growing step according to the plant dynamics and a revised pruning step used to refine the hidden structure such that the generated model can be a minimal realization with satisfactory performance. The algorithm is capable of adjusting both the network structure and weights simultaneously by using of weight variations as the conditions of structure optimization. An integrated performance including the identification error and an additional entropy penalty term is employed such that the model can attenuate the non-Gaussian noises as well as match the unknown plant automatically with a suitable structure. Convergence of the weights is guaranteed by suitably choosing the learning rates. The proposed DSONN can be established without a priori knowledge of the unknown nonlinearity. The efficiency of the method is illustrated through the applications to three different Hammerstein systems.", "paper_title": "Identification of Extended Hammerstein Systems Using Dynamic Self-Optimizing Neural Networks", "paper_id": "WOS:000293749500001"}