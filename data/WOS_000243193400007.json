{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "gaussian_mixtures"}, {"score": 0.004460309246062286, "phrase": "new_unbiased_metric"}, {"score": 0.004068907083697369, "phrase": "density_estimation"}, {"score": 0.0031360786664165093, "phrase": "optimal_smoothness"}, {"score": 0.0029951555610569225, "phrase": "optimal_number"}, {"score": 0.002530359917257626, "phrase": "learning_strategy"}, {"score": 0.002453934333239467, "phrase": "gaussian_mixture_density_estimation"}, {"score": 0.002272794656458419, "phrase": "log_likelihood_maximization"}, {"score": 0.0021705796895687864, "phrase": "wide_range"}, {"score": 0.0021049977753042253, "phrase": "real-world_data_sets"}], "paper_keywords": [""], "paper_abstract": "We introduce a new unbiased metric for assessing the quality of density estimation based on gaussian mixtures, called differential log likelihood. As an application, we determine the optimal smoothness and the optimal number of kernels in gaussian mixtures. Furthermore, we suggest a learning strategy for gaussian mixture density estimation and compare its performance with log likelihood maximization for a wide range of real-world data sets.", "paper_title": "Differential log likelihood for evaluating and learning Gaussian mixtures", "paper_id": "WOS:000243193400007"}