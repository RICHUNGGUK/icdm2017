{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "nearest_neighbor_search"}, {"score": 0.004777569299319633, "phrase": "video_retrieval"}, {"score": 0.004703671193348433, "phrase": "similar_videos"}, {"score": 0.004648995193787914, "phrase": "query_clip"}, {"score": 0.004594951819987416, "phrase": "large_database"}, {"score": 0.004402088928254543, "phrase": "high-dimensional_feature_vectors"}, {"score": 0.004300310127339099, "phrase": "query_video"}, {"score": 0.004071846628708832, "phrase": "feature_vector"}, {"score": 0.003900853871728297, "phrase": "overall_similarity"}, {"score": 0.003781005930058317, "phrase": "single_content-based_video_retrieval"}, {"score": 0.003693533648584145, "phrase": "normally_nearby_feature_vectors"}, {"score": 0.003580032420161922, "phrase": "large_number"}, {"score": 0.003552204377093386, "phrase": "expensive_random_disk_accesses"}, {"score": 0.0034029588672379926, "phrase": "overall_query_performance"}, {"score": 0.0032220148724914867, "phrase": "individual_nn_searches"}, {"score": 0.0031474338010045386, "phrase": "novel_approach"}, {"score": 0.0031229578623834394, "phrase": "efficient_high-dimensional_bnn_search"}, {"score": 0.003015143226706584, "phrase": "advanced_optimizations"}, {"score": 0.0029338597685088603, "phrase": "overlapped_candidates"}, {"score": 0.0028436364707396613, "phrase": "pervious_query"}, {"score": 0.002766963729586353, "phrase": "candidate_sets"}, {"score": 0.002745438358145758, "phrase": "subsequent_queries"}, {"score": 0.0027240799841720957, "phrase": "dqo"}, {"score": 0.0026609940110902666, "phrase": "query_order"}, {"score": 0.002619748321217153, "phrase": "common_candidates"}, {"score": 0.002519402443228795, "phrase": "total_number"}, {"score": 0.0023946630984825207, "phrase": "candidate_overlapping_graph"}, {"score": 0.002311933249234786, "phrase": "next_query"}, {"score": 0.002188874450946842, "phrase": "dynamically_updated_cog._extensive_experiments"}, {"score": 0.002154930852763048, "phrase": "real_video_datasets"}], "paper_keywords": ["content-based retrieval", " high-dimensional indexing", " multimedia databases", " query processing"], "paper_abstract": "To retrieve similar videos to a query clip from a large database, each video is often represented by a sequence of high-dimensional feature vectors. Typically, given a query video containing m feature vectors, an independent nearest neighbor (NN) search for each feature vector is often first performed. After completing all the NN searches, an overall similarity is then computed, i.e., a single content-based video retrieval usually involves m individual NN searches. Since normally nearby feature vectors in a video are similar, a large number of expensive random disk accesses are expected to repeatedly occur, which crucially affects the overall query performance. Batch nearest neighbor (BNN) search is stated as a batch operation that performs a number of individual NN searches. This paper presents a novel approach towards efficient high-dimensional BNN search called dynamic query ordering (DQO) for advanced optimizations of both I/O and CPU costs. Observing the overlapped candidates (or search space) of a pervious query may help to further reduce the candidate sets of subsequent queries, DQO aims at progressively finding a query order such that the common candidates among queries are fully utilized to maximally reduce the total number of candidates. Modelling the candidate set relationship of queries by a candidate overlapping graph (COG), DQO iteratively selects the next query to be executed based on its estimated pruning power to the rest of queries with the dynamically updated COG. Extensive experiments are conducted on real video datasets and show the significance of our BNN query processing strategy.", "paper_title": "Batch nearest neighbor search for video retrieval", "paper_id": "WOS:000258767100010"}