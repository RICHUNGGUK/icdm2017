{"auto_keywords": [{"score": 0.0486744732916662, "phrase": "nearest_neighbor_classifier"}, {"score": 0.027658445865433756, "phrase": "prototype_selection"}, {"score": 0.00481495049065317, "phrase": "prototype_selection_for_nearest_neighbor_classification"}, {"score": 0.004290201740122912, "phrase": "data_mining"}, {"score": 0.0040571383470418085, "phrase": "high_storage_requirements"}, {"score": 0.004027031316965272, "phrase": "low_efficiency"}, {"score": 0.00399714680711765, "phrase": "classification_response"}, {"score": 0.00395273370234774, "phrase": "low_noise_tolerance"}, {"score": 0.0034824716857663114, "phrase": "classification_rule"}, {"score": 0.003367611042980526, "phrase": "relevant_prototypes"}, {"score": 0.003160854709666311, "phrase": "different_properties"}, {"score": 0.0030225753906647935, "phrase": "formal_categorization"}, {"score": 0.0028795712616923462, "phrase": "prototype_selection_methods"}, {"score": 0.0028053842615436706, "phrase": "theoretical_and_empirical_point"}, {"score": 0.0027433143290371293, "phrase": "theoretical_point"}, {"score": 0.0026330549554033876, "phrase": "main_characteristics"}, {"score": 0.002480520548392772, "phrase": "experimental_study"}, {"score": 0.0024620842899061614, "phrase": "different_sizes"}, {"score": 0.002443784721651744, "phrase": "data_sets"}, {"score": 0.002363101338529545, "phrase": "reduction_capabilities"}, {"score": 0.002234491924392104, "phrase": "nonparametric_statistical_tests"}, {"score": 0.0021049977753042253, "phrase": "nearest_neighbor_classification"}], "paper_keywords": ["Prototype selection", " nearest neighbor", " taxonomy", " condensation", " edition", " classification"], "paper_abstract": "The nearest neighbor classifier is one of the most used and well-known techniques for performing recognition tasks. It has also demonstrated itself to be one of the most useful algorithms in data mining in spite of its simplicity. However, the nearest neighbor classifier suffers from several drawbacks such as high storage requirements, low efficiency in classification response, and low noise tolerance. These weaknesses have been the subject of study for many researchers and many solutions have been proposed. Among them, one of the most promising solutions consists of reducing the data used for establishing a classification rule ( training data) by means of selecting relevant prototypes. Many prototype selection methods exist in the literature and the research in this area is still advancing. Different properties could be observed in the definition of them, but no formal categorization has been established yet. This paper provides a survey of the prototype selection methods proposed in the literature from a theoretical and empirical point of view. Considering a theoretical point of view, we propose a taxonomy based on the main characteristics presented in prototype selection and we analyze their advantages and drawbacks. Empirically, we conduct an experimental study involving different sizes of data sets for measuring their performance in terms of accuracy, reduction capabilities, and runtime. The results obtained by all the methods studied have been verified by nonparametric statistical tests. Several remarks, guidelines, and recommendations are made for the use of prototype selection for nearest neighbor classification.", "paper_title": "Prototype Selection for Nearest Neighbor Classification: Taxonomy and Empirical Study", "paper_id": "WOS:000299381600001"}