{"auto_keywords": [{"score": 0.048098874556743006, "phrase": "human-machine_interface"}, {"score": 0.03473932395322148, "phrase": "online_appearance_model"}, {"score": 0.004816334743260804, "phrase": "text"}, {"score": 0.004728624975677976, "phrase": "speech-driven_realistic"}, {"score": 0.004671932143798307, "phrase": "virtual_head"}, {"score": 0.004533142516832776, "phrase": "multiple_inputs-driven_realistic_facial_animation_system"}, {"score": 0.0037597491055035895, "phrase": "diverse_interfaces"}, {"score": 0.0036479584876742085, "phrase": "parameterized_model"}, {"score": 0.00360417515510547, "phrase": "muscular_model"}, {"score": 0.0034342161742428666, "phrase": "computational_efficiency"}, {"score": 0.0033929894721242367, "phrase": "high_realism"}, {"score": 0.00306189690236109, "phrase": "particle_filtering"}, {"score": 0.0028477727736832283, "phrase": "input_image"}, {"score": 0.0028136173491701243, "phrase": "gabor"}, {"score": 0.0027463775689957255, "phrase": "illumination_ratio_image"}, {"score": 0.002600995957987461, "phrase": "lighting_and_person_dependence"}, {"score": 0.002478225374613311, "phrase": "tri-phone_model"}, {"score": 0.002389956401870098, "phrase": "computational_consumption"}, {"score": 0.002361236012575149, "phrase": "visual_co"}, {"score": 0.002304824112812496, "phrase": "synchronized_viseme_synthesis"}, {"score": 0.002209319719984651, "phrase": "objective_and_subjective_experiments"}, {"score": 0.0021049977753042253, "phrase": "human-machine_interaction"}], "paper_keywords": ["Facial animation", " facial motion tracking", " human-machine interface", " virtual head"], "paper_abstract": "A multiple inputs-driven realistic facial animation system based on 3-D virtual head for human-machine interface is proposed. The system can be driven independently by video, text, and speech, thus can interact with humans through diverse interfaces. The combination of parameterized model and muscular model is used to obtain a tradeoff between computational efficiency and high realism of 3-D facial animation. The online appearance model is used to track 3-D facial motion from video in the framework of particle filtering, and multiple measurements, i.e., pixel color value of input image and Gabor wavelet coefficient of illumination ratio image, are infused to reduce the influence of lighting and person dependence for the construction of online appearance model. The tri-phone model is used to reduce the computational consumption of visual co-articulation in speech synchronized viseme synthesis without sacrificing any performance. The objective and subjective experiments show that the system is suitable for human-machine interaction.", "paper_title": "A Video, Text, and Speech-Driven Realistic 3-D Virtual Head for Human-Machine Interface", "paper_id": "WOS:000353152700010"}