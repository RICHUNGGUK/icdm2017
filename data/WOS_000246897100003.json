{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "combinatorial_optimization_problems"}, {"score": 0.004669845451682529, "phrase": "optimization_problems"}, {"score": 0.0032668821950788502, "phrase": "new_theory"}, {"score": 0.002949598537993663, "phrase": "shannon's_information_theory"}, {"score": 0.002718045523483502, "phrase": "new_epistasis_measure"}, {"score": 0.00240426758768164, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "efficient_evolutionary_algorithms"}], "paper_keywords": ["combinatorial optimization", " entropy", " mutual information", " variable interaction", " linkage", " entropic epistasis"], "paper_abstract": "In optimization problems, the contribution of a variable to fitness often depends on the states of other variables. This phenomenon is referred to as epistasis or linkage. In this paper, we show that a new theory of epistasis can be established on the basis of Shannon's information theory. From this, we derive a new epistasis measure called entropic epistasis and some theoretical results. We also provide experimental results verifying the measure and showing how it can be used for designing efficient evolutionary algorithms.", "paper_title": "An information-theoretic analysis on the interactions of variables in combinatorial optimization problems", "paper_id": "WOS:000246897100003"}