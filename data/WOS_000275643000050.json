{"auto_keywords": [{"score": 0.03528453069935319, "phrase": "mild_conditions"}, {"score": 0.025060400528401028, "phrase": "kernel_algorithm"}, {"score": 0.0048149941131289346, "phrase": "pca."}, {"score": 0.0046928556063004214, "phrase": "general_kernelization_framework"}, {"score": 0.0045348429403481464, "phrase": "two-stage_procedure"}, {"score": 0.00440093312826378, "phrase": "kernel_principal_component_analysis"}, {"score": 0.004216434794603139, "phrase": "learning_algorithm"}, {"score": 0.004162602203448056, "phrase": "transformed_data"}, {"score": 0.00350696416714684, "phrase": "kernelization_framework"}, {"score": 0.003432604816716035, "phrase": "rigorous_justification"}, {"score": 0.0032050528424273994, "phrase": "traditional_kernel_method"}, {"score": 0.0029416448256236057, "phrase": "learning_algorithms"}, {"score": 0.0027821202902740846, "phrase": "inner_product_form"}, {"score": 0.0027230880516264685, "phrase": "common_yet_vital_step"}, {"score": 0.0026998264237910884, "phrase": "traditional_kernel_methods"}, {"score": 0.002575385171755899, "phrase": "novel_kernel_method"}, {"score": 0.0025315664299815537, "phrase": "low-rank_kpca"}, {"score": 0.002404522326122611, "phrase": "feature_space"}, {"score": 0.0023134312557290043, "phrase": "numerical_stability"}, {"score": 0.0021599099979586946, "phrase": "proposed_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Kernel method", " Learning algorithm", " Kernel PCA", " Two-stage framework"], "paper_abstract": "In this paper, a general kernelization framework for learning algorithms is proposed via a two-stage procedure, i.e., transforming data by kernel principal component analysis (KPCA), and then directly performing the learning algorithm with the transformed data. It is worth noting that although a very few learning algorithms were also kernelized by this procedure before, why and under what condition this procedure is feasible have not been further studied. In this paper, we explicitly present this kernelization framework, and give a rigorous justification to reveal that under some mild conditions, the kernelization under this framework is equivalent to traditional kernel method. We show that these mild conditions are usually satisfied in most of learning algorithms. Therefore, most of learning algorithms can be kernelized under this framework without having to reformulate it into inner product form, which is a common yet vital step in traditional kernel methods. Enlightened by this framework, we also propose a novel kernel method based on the low-rank KPCA, which could be used to remove the noise in the feature space, speed up the kernel algorithm and improve the numerical stability for the kernel algorithm. Experiments are presented to verify the validity and effectiveness of the proposed methods. (C) 2009 Elsevier B.V. All rights reserved.", "paper_title": "A general kernelization framework for learning algorithms based on kernel PCA", "paper_id": "WOS:000275643000050"}