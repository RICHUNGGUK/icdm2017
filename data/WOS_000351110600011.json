{"auto_keywords": [{"score": 0.030025708036724715, "phrase": "reduced_data"}, {"score": 0.028244896027967887, "phrase": "dissimilarity_space"}, {"score": 0.00481495049065317, "phrase": "class_imbalances"}, {"score": 0.00447115003744675, "phrase": "naive_bayes"}, {"score": 0.004420472010542188, "phrase": "decision_trees_and_neural_networks"}, {"score": 0.004035107125458193, "phrase": "skewed_class_distribution"}, {"score": 0.003944112858235306, "phrase": "existing_classification_algorithms"}, {"score": 0.003725470458263889, "phrase": "imbalance_distribution"}, {"score": 0.003641433168173135, "phrase": "discriminative_ability"}, {"score": 0.0034988876789164235, "phrase": "class_imbalance_data"}, {"score": 0.0033619033669956317, "phrase": "dissimilarity-based_method"}, {"score": 0.003193606324727067, "phrase": "imbalanced_data"}, {"score": 0.00308610073274614, "phrase": "useless_and_redundant_features"}, {"score": 0.002881793492919646, "phrase": "representative_instances"}, {"score": 0.0026152363154073707, "phrase": "new_features"}, {"score": 0.0025416235470290286, "phrase": "classification_model"}, {"score": 0.002442025065383455, "phrase": "extensive_experiments"}, {"score": 0.0023329572140896237, "phrase": "seven_other_imbalance_data"}, {"score": 0.0022034318550547866, "phrase": "imbalance_learning"}], "paper_keywords": ["Dissimilarity-based classification", " Class imbalance", " Software defect prediction", " Feature selection", " Prototype selection"], "paper_abstract": "Class imbalances have been reported to compromise the performance of most standard classifiers, such as Naive Bayes, Decision Trees and Neural Networks. Aiming to solve this problem, various solutions have been explored mainly via balancing the skewed class distribution or improving the existing classification algorithms. However, these methods pay more attention on the imbalance distribution, ignoring the discriminative ability of features in the context of class imbalance data. In this perspective, a dissimilarity-based method is proposed to deal with the classification of imbalanced data. Our proposed method first removes the useless and redundant features by feature selection from the given data set; and then, extracts representative instances from the reduced data as prototypes; finally, projects the reduced data into a dissimilarity space by constructing new features, and builds the classification model with data in the dissimilarity space. Extensive experiments over 24 benchmark class imbalance data sets show that, compared with seven other imbalance data tackling solutions, our proposed method greatly improves the performance of imbalance learning, and outperforms the other solutions with all given classification algorithms.", "paper_title": "A dissimilarity-based imbalance data classification algorithm", "paper_id": "WOS:000351110600011"}