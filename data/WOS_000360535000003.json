{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "harnessing_data_parallel_hardware_for_server_workloads"}, {"score": 0.004721162131188487, "phrase": "increasing_web_traffic_demand"}, {"score": 0.004539005582217309, "phrase": "energy_efficiency"}, {"score": 0.004494570360108983, "phrase": "total_cost"}, {"score": 0.004406994912939125, "phrase": "present_work"}, {"score": 0.004342430078306461, "phrase": "data_center_efficiency"}, {"score": 0.004236908273106904, "phrase": "data_center"}, {"score": 0.003993958025223994, "phrase": "individual_servers"}, {"score": 0.003954837422946628, "phrase": "server_capacity"}, {"score": 0.0036553070575015344, "phrase": "long_run"}, {"score": 0.0034118234596993836, "phrase": "server_workload_execution_patterns"}, {"score": 0.003312486229143855, "phrase": "multiple_requests"}, {"score": 0.0032319109979344184, "phrase": "framework-called_rhythm-for"}, {"score": 0.0030464123943266673, "phrase": "server_performance"}, {"score": 0.0029576827451501956, "phrase": "parallel_executions"}, {"score": 0.002928682556953258, "phrase": "request_cohorts"}, {"score": 0.002843372121209168, "phrase": "specweb_banking_workload"}, {"score": 0.0027878797103973313, "phrase": "nvidia_gpus"}, {"score": 0.002640781900605126, "phrase": "future_cohort-based_servers"}, {"score": 0.002551231163230566, "phrase": "future_server_platforms"}, {"score": 0.0023117182131967523, "phrase": "dual_core_arm"}, {"score": 0.002255431275670053, "phrase": "rhythm_implementation"}, {"score": 0.0022223176391038785, "phrase": "transposed_responses"}], "paper_keywords": ["high throughput", " power efficiency", " execution similarity"], "paper_abstract": "Trends in increasing web traffic demand an increase in server throughput while preserving energy efficiency and total cost of ownership. Present work in optimizing data center efficiency primarily focuses on the data center as a whole, using off-the-shelf hardware for individual servers. Server capacity is typically increased by adding more machines, which is cheap, though inefficient in the long run in terms of energy and area. Our work builds on the observation that server workload execution patterns are not completely unique across multiple requests. We present a framework-called Rhythm-for high throughput servers that can exploit similarity across requests to improve server performance and power/energy efficiency by launching data parallel executions for request cohorts. An implementation of the SPECWeb Banking workload using Rhythm on NVIDIA GPUs provides a basis for evaluating both software and hardware for future cohort-based servers. Our evaluation of Rhythm on future server platforms shows that it achieves 4x the throughput (reqs/sec) of a core i7 at efficiencies (reqs/Joule) comparable to a dual core ARM Cortex A9. A Rhythm implementation that generates transposed responses achieves 8x the i7 throughput while processing 2.5x more requests/Joule compared to the A9.", "paper_title": "Rhythm: Harnessing Data Parallel Hardware for Server Workloads", "paper_id": "WOS:000360535000003"}