{"auto_keywords": [{"score": 0.04864125958549595, "phrase": "cued_speech"}, {"score": 0.013597513556561068, "phrase": "consonant_recognition"}, {"score": 0.010358144685918036, "phrase": "automatic_recognition"}, {"score": 0.009314890978040351, "phrase": "spoken_language"}, {"score": 0.008125196208068473, "phrase": "isolated_word_recognition_experiments"}, {"score": 0.006217257266297745, "phrase": "vowel_recognition"}, {"score": 0.00481495049065317, "phrase": "speech_automatic_recognition"}, {"score": 0.004785682967399109, "phrase": "normal-hearing_and_deaf_subjects"}, {"score": 0.0046420303343885794, "phrase": "french"}, {"score": 0.004599712603988837, "phrase": "hidden_markov_models"}, {"score": 0.00448886315956469, "phrase": "visual_mode"}, {"score": 0.00442093689661089, "phrase": "hand_shapes"}, {"score": 0.004394053797771851, "phrase": "different_positions"}, {"score": 0.004327555970055785, "phrase": "lip_patterns"}, {"score": 0.004172021058058737, "phrase": "deaf_people"}, {"score": 0.003973267259774664, "phrase": "deaf_children"}, {"score": 0.0038538647865057757, "phrase": "current_study"}, {"score": 0.0037839460525667485, "phrase": "visible_gestures"}, {"score": 0.0037266467875257136, "phrase": "audible_orofacial_gestures"}, {"score": 0.003703969862557761, "phrase": "phoneme_recognition"}, {"score": 0.003592630978298206, "phrase": "normal-hearing_cuer"}, {"score": 0.0034005585921467875, "phrase": "proposed_methods"}, {"score": 0.0033695566513755096, "phrase": "deaf_cuer"}, {"score": 0.0033388363997245286, "phrase": "achieved_results"}, {"score": 0.003288255061396602, "phrase": "significant_differences"}, {"score": 0.0032582736131450316, "phrase": "automatic_cued_speech_recognition"}, {"score": 0.003228564642402843, "phrase": "normal-hearing_subject"}, {"score": 0.003000411392166266, "phrase": "great_importance"}, {"score": 0.0029459306440711443, "phrase": "lip_shape_component"}, {"score": 0.002910159235873015, "phrase": "hand_component"}, {"score": 0.0028836151926021234, "phrase": "cued_speech_recognition"}, {"score": 0.002857312568125609, "phrase": "concatenative_feature_fusion"}, {"score": 0.0028312491793328043, "phrase": "hmm_decision_fusion"}, {"score": 0.002623072765271526, "phrase": "sole_use"}, {"score": 0.0026070935979443646, "phrase": "lip_shape_parameters"}, {"score": 0.0024525461181496753, "phrase": "lip_shape"}, {"score": 0.002371476222721094, "phrase": "complete_phoneme_recognition_experiment"}, {"score": 0.0023570261027098293, "phrase": "concatenated_feature_vectors"}, {"score": 0.0023426638248794643, "phrase": "gaussian_mixture_model"}, {"score": 0.0022514137676797985, "phrase": "word_recognition_experiments"}, {"score": 0.0021970315630373493, "phrase": "word_accuracy"}, {"score": 0.0021374167789011246, "phrase": "obtained_results"}], "paper_keywords": ["French Cued Speech", " Hidden Markov models", " Automatic recognition", " Feature fusion", " Multi-stream HMM decision fusion"], "paper_abstract": "This article discusses the automatic recognition of Cued Speech in French based on hidden Markov models (HMMs). Cued Speech is a visual mode which, by using hand shapes in different positions and in combination with lip patterns of speech, makes all the sounds of a spoken language clearly understandable to deaf people. The aim of Cued Speech is to overcome the problems of lipreading and thus enable deaf children and adults to understand spoken language completely. In the current study, the authors demonstrate that visible gestures are as discriminant as audible orofacial gestures. Phoneme recognition and isolated word recognition experiments have been conducted using data from a normal-hearing cuer. The results obtained were very promising, and the study has been extended by applying the proposed methods to a deaf cuer. The achieved results have not shown any significant differences compared to automatic Cued Speech recognition in a normal-hearing subject. In automatic recognition of Cued Speech, lip shape and gesture recognition are required. Moreover, the integration of the two modalities is of great importance. In this study, lip shape component is fused with hand component to realize Cued Speech recognition. Using concatenative feature fusion and multi-stream HMM decision fusion, vowel recognition, consonant recognition, and isolated word recognition experiments have been conducted. For vowel recognition, an 87.6% vowel accuracy was obtained showing a 61.3% relative improvement compared to the sole use of lip shape parameters. In the case of consonant recognition, a 78.9% accuracy was obtained showing a 56% relative improvement compared to the use of lip shape only. In addition to vowel and consonant recognition, a complete phoneme recognition experiment using concatenated feature vectors and Gaussian mixture model (GMM) discrimination was conducted, obtaining a 74.4% phoneme accuracy. Isolated word recognition experiments in both normal-hearing and deaf subjects were also conducted providing a word accuracy of 94.9% and 89%, respectively. The obtained results were compared with those obtained using audio signal, and comparable accuracies were observed. (C) 2010 Elsevier B.V. All rights reserved.", "paper_title": "Cued Speech automatic recognition in normal-hearing and deaf subjects", "paper_id": "WOS:000278282000004"}