{"auto_keywords": [{"score": 0.02410978339549448, "phrase": "mortar"}, {"score": 0.00481495049065317, "phrase": "data_center_memory"}, {"score": 0.00477190623242136, "phrase": "data_center_servers"}, {"score": 0.004645057834614705, "phrase": "spare_memory_and_cpu_capacity_idle"}, {"score": 0.004481132747216135, "phrase": "virtual_machines"}, {"score": 0.004303591748086452, "phrase": "fast_hotspot_mitigation"}, {"score": 0.0040777192615062815, "phrase": "spare_capacity"}, {"score": 0.004023120753104693, "phrase": "active_applications"}, {"score": 0.0037948184359488284, "phrase": "coarse_chunks"}, {"score": 0.0037608593980593035, "phrase": "long_timescales"}, {"score": 0.003611751858608048, "phrase": "poorly_utilized_memory"}, {"score": 0.003563370084662192, "phrase": "data_center"}, {"score": 0.003499864176875713, "phrase": "volatile_data_store"}, {"score": 0.0032132782979796895, "phrase": "disk_blocks"}, {"score": 0.003141830113006653, "phrase": "application-level_distributed_cache"}, {"score": 0.003085813569061001, "phrase": "memcached_protocol"}, {"score": 0.0027328817607818207, "phrase": "eviction_policies"}, {"score": 0.0025545134727682716, "phrase": "realistic_web_applications"}, {"score": 0.0025316254589087973, "phrase": "disk_benchmarks"}, {"score": 0.0024311346712789553, "phrase": "live_servers"}, {"score": 0.0023346234464901978, "phrase": "data_store_size"}, {"score": 0.002292965705677312, "phrase": "free_memory"}, {"score": 0.0022419349154472806, "phrase": "average_response_time"}, {"score": 0.0022118619998034742, "phrase": "web_application"}, {"score": 0.0021529183360603434, "phrase": "fixed_size"}, {"score": 0.002143247921132179, "phrase": "memcached_deployment"}, {"score": 0.0021049977753042253, "phrase": "overall_video_streaming_performance"}], "paper_keywords": ["Memory Management", " Virtualization", " Memcached", " Disk Prefetching"], "paper_abstract": "Data center servers are typically overprovisioned, leaving spare memory and CPU capacity idle to handle unpredictable workload bursts by the virtual machines running on them. While this allows for fast hotspot mitigation, it is also wasteful. Unfortunately, making use of spare capacity without impacting active applications is particularly difficult for memory since it typically must be allocated in coarse chunks over long timescales. In this work we propose repurposing the poorly utilized memory in a data center to store a volatile data store that is managed by the hypervisor. We present two uses for our Mortar framework: as a cache for prefetching disk blocks, and as an application-level distributed cache that follows the memcached protocol. Both prototypes use the framework to ask the hypervisor to store useful, but recoverable data within its free memory pool. This allows the hypervisor to control eviction policies and prioritize access to the cache. We demonstrate the benefits of our prototypes using realistic web applications and disk benchmarks, as well as memory traces gathered from live servers in our university's IT department. By expanding and contracting the data store size based on the free memory available, Mortar improves average response time of a web application by up to 35% compared to a fixed size memcached deployment, and improves overall video streaming performance by 45% through prefetching.", "paper_title": "Mortar: Filling the Gaps in Data Center Memory", "paper_id": "WOS:000344456400007"}