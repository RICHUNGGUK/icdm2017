{"auto_keywords": [{"score": 0.04643184783658168, "phrase": "scan_path"}, {"score": 0.015719716506582538, "phrase": "time_delay_neural_network"}, {"score": 0.015475774883350052, "phrase": "eye_gaze_data"}, {"score": 0.014310879490390964, "phrase": "human_being"}, {"score": 0.004702092660370367, "phrase": "human_eye_movement_modelling"}, {"score": 0.0045557008859819234, "phrase": "human_eye_movement"}, {"score": 0.004176102823067887, "phrase": "successful_modelling"}, {"score": 0.004143196873246147, "phrase": "human_eye_movements"}, {"score": 0.004078157608867258, "phrase": "wide_range"}, {"score": 0.003998286635727259, "phrase": "image_retrieval"}, {"score": 0.003966776222128288, "phrase": "image_annotation"}, {"score": 0.003935513160201076, "phrase": "medical_image_diagnosis"}, {"score": 0.003904495523681369, "phrase": "human_visual_perception"}, {"score": 0.003723438166874448, "phrase": "tdnn"}, {"score": 0.003536720212056521, "phrase": "non-intrusive_table-mounted_eye_tracker"}, {"score": 0.0034129490818185595, "phrase": "image_reading_process"}, {"score": 0.003372658906684677, "phrase": "single_subject"}, {"score": 0.0033460624879847667, "phrase": "seven_features"}, {"score": 0.0032161835102640372, "phrase": "human_oculomotor_system"}, {"score": 0.0031782087629067686, "phrase": "image_contents"}, {"score": 0.0030791137853734152, "phrase": "trained_tdnn"}, {"score": 0.00303072749758085, "phrase": "saccade_control_mechanism"}, {"score": 0.0028446460307503343, "phrase": "proposed_model"}, {"score": 0.002788865808981643, "phrase": "raw_eye_gaze_data"}, {"score": 0.002723367507064405, "phrase": "subjective_and_objective_methods"}, {"score": 0.002576442680766742, "phrase": "real_eye_gaze_data"}, {"score": 0.0025359354516609795, "phrase": "eye_tracker"}, {"score": 0.0025159206854716274, "phrase": "qualitative_assessment"}, {"score": 0.002278639906498682, "phrase": "coincident_probability"}, {"score": 0.0022162970216404927, "phrase": "quantitative_assessment"}, {"score": 0.002155656133617155, "phrase": "tdnn_model"}, {"score": 0.0021049977753042253, "phrase": "human_scan_paths"}], "paper_keywords": ["eye movement modelling", " visual attention model", " time delayed neural networks", " oculomotor control", " coincident probability", " coincident significance"], "paper_abstract": "Human eye movement modelling is a new, challenging and promising research topic in computer vision. Human eye movement modelling aims at simulating the scan path in which a human being views an image, a scene or a video. The successful modelling of human eye movements potentially benefits a wide range of applications such as image retrieval, image annotation, medical image diagnosis and human visual perception. This article presents a model based on a Time Delay Neural Network (TDNN) to simulate eye gaze data. First, 120 Hz eye gaze data are acquired by a non-intrusive table-mounted eye tracker. Our proposed model is to simulate the image reading process of a single subject. Seven features are then extracted based on the knowledge of the human oculomotor system and the image contents to train a TDNN. Finally, the trained TDNN combined with a saccade control mechanism is used to simulate the scan path of a human being viewing an image. The proposed model can generate 600 points of raw eye gaze data in a 5-second eye viewing window. Both subjective and objective methods are used to evaluate the model by comparing its behaviour and characteristics with the real eye gaze data collected from an eye tracker. Qualitative assessment shows that the subject can hardly tell the differences between the scan path from the model and that from a human being. By evaluating the coincident probability Cp and coincident significance Cs, quantitative assessment shows that the results from the TDNN model are reasonable and similar to human scan paths.", "paper_title": "A Time Delay Neural Network model for simulating eye gaze data", "paper_id": "WOS:000287493400009"}