{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "emotional_speech_recognition"}, {"score": 0.04412469500707909, "phrase": "emotional_states"}, {"score": 0.026277181841549552, "phrase": "classification_techniques"}, {"score": 0.0046328364646343375, "phrase": "first_goal"}, {"score": 0.00433645229352341, "phrase": "available_emotional_speech_data_collections"}, {"score": 0.003778253716938922, "phrase": "second_goal"}, {"score": 0.0034212450542713607, "phrase": "typical_features"}, {"score": 0.002996992362027833, "phrase": "teager"}, {"score": 0.00282048824450047, "phrase": "speech_signal"}, {"score": 0.0026986685585382347, "phrase": "third_goal"}, {"score": 0.002639740960006001, "phrase": "appropriate_techniques"}, {"score": 0.0024299678474208023, "phrase": "timing_information"}, {"score": 0.0022994427535192514, "phrase": "hidden_markov_models"}, {"score": 0.0022741894748181243, "phrase": "artificial_neural_networks"}, {"score": 0.0022492129111567802, "phrase": "linear_discriminant_analysis"}, {"score": 0.002224510044064184, "phrase": "k-nearest_neighbors"}, {"score": 0.002200077887697072, "phrase": "support_vector_machines"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["emotions", " emotional speech data collections", " emotional speech classification", " stress", " interfaces", " acoustic features"], "paper_abstract": "In this paper we overview emotional speech recognition having in mind three goals. The first goal is to provide an up-to-date record of the available emotional speech data collections. The number of emotional states, the language, the number of speakers, and the kind of speech are briefly addressed. The second goal is to present the most frequent acoustic features used for emotional speech recognition and to assess how the emotion affects them. Typical features are the pitch, the formants, the vocal tract cross-section areas, the mel-frequency cepstral coefficients, the Teager energy operator-based features, the intensity of the speech signal, and the speech rate. The third goal is to review appropriate techniques in order to classify speech into emotional states. We examine separately classification techniques that exploit timing information from which that ignore it. Classification techniques based on hidden Markov models, artificial neural networks, linear discriminant analysis, k-nearest neighbors, support vector machines are reviewed. (c) 2006 Elsevier B.V. All rights reserved.", "paper_title": "Emotional speech recognition: Resources, features, and methods", "paper_id": "WOS:000240185100009"}