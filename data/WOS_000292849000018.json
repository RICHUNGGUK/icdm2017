{"auto_keywords": [{"score": 0.04343924738517476, "phrase": "single_source_patterns"}, {"score": 0.010376319275654695, "phrase": "original_base_classifier"}, {"score": 0.00481495049065317, "phrase": "single-view_patterns"}, {"score": 0.0047602693158272655, "phrase": "existing_multi-view_learning"}, {"score": 0.004724160393778674, "phrase": "mvl"}, {"score": 0.004582423717777699, "phrase": "multiple_information_sources"}, {"score": 0.004394424341776717, "phrase": "significant_advantage"}, {"score": 0.00434449804021954, "phrase": "usual_single-view_learning"}, {"score": 0.004087609837102023, "phrase": "existing_mvl"}, {"score": 0.0038752755502006442, "phrase": "new_mvl_technique"}, {"score": 0.0037020429480068653, "phrase": "original_vector_representation"}, {"score": 0.00364603066037512, "phrase": "multiple_matrix_representations"}, {"score": 0.0035096666710980108, "phrase": "original_architecture"}, {"score": 0.003443402656397069, "phrase": "different_sub-ones"}, {"score": 0.003404244237372396, "phrase": "newly_generated_sub-classifier"}, {"score": 0.003036263091666092, "phrase": "different_views"}, {"score": 0.0028893844749296863, "phrase": "learning_process"}, {"score": 0.0028565082986974602, "phrase": "multi-view_sub-classifiers"}, {"score": 0.002739121808942775, "phrase": "vector-pattern-oriented_ho-kashyap_classifier"}, {"score": 0.0026771333996253783, "phrase": "mhks"}, {"score": 0.002537880772794665, "phrase": "proposed_joint_multi-view_learning"}, {"score": 0.002499438189264537, "phrase": "multiv-mhks."}, {"score": 0.0024150528983695446, "phrase": "proposed_multiv-mhks"}, {"score": 0.0023694065215394593, "phrase": "experimental_results"}, {"score": 0.002351389889948836, "phrase": "benchmark_data_sets"}, {"score": 0.002263336340041527, "phrase": "proposed_multi-view_approach"}, {"score": 0.002229043128610864, "phrase": "tighter_generalization_risk"}, {"score": 0.0021537671245615286, "phrase": "rademacher_complexity_analysis"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Multi-view learning", " Classifier design", " Rademacher complexity", " Ensemble learning", " Ho-Kashyap classifier", " Regularization learning", " Pattern recognition"], "paper_abstract": "The existing multi-view learning (MVL) learns how to process patterns with multiple information sources. In generalization this MVL is proven to have a significant advantage over the usual single-view learning (SVL). However, in most real-world cases we only have single source patterns to which the existing MVL is unable to be directly applied. This paper aims to develop a new MVL technique for single source patterns. To this end, we first reshape the original vector representation of single source patterns into multiple matrix representations. In doing so, we can change the original architecture of a given base classifier into different sub-ones. Each newly generated sub-classifier can classify the patterns represented with the matrix. Here each sub-classifier is taken as one view of the original base classifier. As a result, a set of sub-classifiers with different views are come into being. Then, one joint rather than separated learning process for the multi-view sub-classifiers is developed. In practice, the original base classifier employs the vector-pattern-oriented Ho-Kashyap classifier with regularization learning (called MHKS) as a paradigm which is not limited to MHKS. Thus, the proposed joint multi-view learning is named as MultiV-MHKS. Finally, the feasibility and effectiveness of the proposed MultiV-MHKS is demonstrated by the experimental results on benchmark data sets. More importantly, we have demonstrated that the proposed multi-view approach generally has a tighter generalization risk bound than its single-view one in terms of the Rademacher complexity analysis. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "A novel multi-view learning developed from single-view patterns", "paper_id": "WOS:000292849000018"}