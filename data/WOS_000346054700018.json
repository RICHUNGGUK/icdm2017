{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "efficient_multiview_depth_coding_optimization"}, {"score": 0.0047385702897315436, "phrase": "allowable_depth"}, {"score": 0.00458940888106061, "phrase": "depth_video"}, {"score": 0.004468684611798047, "phrase": "geometrical_information"}, {"score": 0.004103212598803194, "phrase": "depth_levels"}, {"score": 0.004059673618719782, "phrase": "disparity_levels"}, {"score": 0.003995226376780718, "phrase": "view_synthesis"}, {"score": 0.0038900709793274484, "phrase": "depth_distortion"}, {"score": 0.0038487848937121204, "phrase": "rendering_position_error"}, {"score": 0.003727527379253624, "phrase": "many-to-one_mapping_function"}, {"score": 0.0036488111139918135, "phrase": "different_depth_distortion_values"}, {"score": 0.0034777028461723198, "phrase": "synthesized_virtual_view_image"}, {"score": 0.0032969458013463807, "phrase": "allowable_depth_distortion"}, {"score": 0.003108911488613549, "phrase": "add-based_rate-distortion_model"}, {"score": 0.002931569771634119, "phrase": "view_synthesis_distortion"}, {"score": 0.002794001681064862, "phrase": "add-based_depth_bit_reduction_algorithm"}, {"score": 0.0026914710445743693, "phrase": "depth_bit_rate"}, {"score": 0.002592693161475495, "phrase": "synthesized_images"}, {"score": 0.00256514094268541, "phrase": "experimental_results"}, {"score": 0.0024578219177450876, "phrase": "proposed_overall_algorithm"}, {"score": 0.002431699464104896, "phrase": "bjontegaard_delta_peak_signal-to-noise_ratio_gains"}, {"score": 0.002317533977770783, "phrase": "half_and_integer-pixel_rendering_precisions"}, {"score": 0.002220551141101661, "phrase": "proposed_algorithms"}, {"score": 0.002150481043278758, "phrase": "inter_depth_coding"}, {"score": 0.0021049977753042253, "phrase": "different_metrics"}], "paper_keywords": ["3D video", " depth coding", " view synthesis", " depth no-synthesis-error", " rate-distortion optimization", " allowable depth distortion"], "paper_abstract": "Depth video is used as the geometrical information of 3D world scenes in 3D view synthesis. Due to the mismatch between the number of depth levels and disparity levels in the view synthesis, the relationship between depth distortion and rendering position error can be modeled as a many-to-one mapping function, in which different depth distortion values might be projected to the same geometrical distortion in the synthesized virtual view image. Based on this property, we present an allowable depth distortion (ADD) model for 3D depth map coding. Then, an ADD-based rate-distortion model is proposed for mode decision and motion/disparity estimation modules aiming at minimizing view synthesis distortion at a given bit rate constraint. In addition, an ADD-based depth bit reduction algorithm is proposed to further reduce the depth bit rate while maintaining the qualities of the synthesized images. Experimental results in intra depth coding show that the proposed overall algorithm achieves Bjontegaard delta peak signal-to-noise ratio gains of 1.58 and 2.68 dB on average for half and integer-pixel rendering precisions, respectively. In addition, the proposed algorithms are also highly efficient for inter depth coding when evaluated with different metrics.", "paper_title": "Efficient Multiview Depth Coding Optimization Based on Allowable Depth Distortion in View Synthesis", "paper_id": "WOS:000346054700018"}