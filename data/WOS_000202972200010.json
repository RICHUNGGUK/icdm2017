{"auto_keywords": [{"score": 0.04974208475172307, "phrase": "network_processors"}, {"score": 0.03664435957391309, "phrase": "runtime_management"}, {"score": 0.00481495049065317, "phrase": "thread_management"}, {"score": 0.004747429622531595, "phrase": "compiler_analysis"}, {"score": 0.00469740813902244, "phrase": "packet_processing_tasks"}, {"score": 0.004664352260912174, "phrase": "network_processor_micro-engines"}, {"score": 0.004330941610682453, "phrase": "code_store"}, {"score": 0.004255121395629569, "phrase": "application_requirements"}, {"score": 0.004151188559520802, "phrase": "heterogeneous_threads"}, {"score": 0.004049783994776266, "phrase": "different_tasks"}, {"score": 0.003813669883040509, "phrase": "pipelined_fashion"}, {"score": 0.003720479367430766, "phrase": "different_micro-engines"}, {"score": 0.0035283552859817764, "phrase": "different_run_time_performance_demands"}, {"score": 0.0034543031591181546, "phrase": "processor_sharing"}, {"score": 0.0034299649219748513, "phrase": "real-time_scheduling"}, {"score": 0.003346119094502001, "phrase": "runtime_environment"}, {"score": 0.003241312187060814, "phrase": "hardware_support"}, {"score": 0.002677744558540711, "phrase": "hardware_or_os_solution"}, {"score": 0.0025573643582417573, "phrase": "compiler_approach"}, {"score": 0.0025125151618810523, "phrase": "complete_compiler_solution"}, {"score": 0.0024772013657695896, "phrase": "explicit_context_switch"}, {"score": 0.0021731423856364003, "phrase": "heterogeneous_thread_programming"}, {"score": 0.0021049977753042253, "phrase": "multi-core_processors"}], "paper_keywords": ["performance", " design", " CPU scheduling", " real-time scheduling", " compiler optimizations", " network processors"], "paper_abstract": "Mapping packet processing tasks on network processor micro-engines involves complex tradeoffs that relating to maximizing parallelism and pipelining. Due to an increase in the size of the code store and complexity of the application requirements, network processors are being programmed with heterogeneous threads that may execute code belonging to different tasks on a given micro-engine. Also, most network applications are streaming applications that are typically processed in a pipelined fashion. Thus, the tasks on different micro-engines are pipelined in such a way as to maximize the throughput. Tasks themselves could have different run time performance demands. Traditionally, runtime management involving processor sharing, real-time scheduling etc. is provided by the runtime environment (typically an operating system) using the hardware support for timers and interrupts that allows time slicing the resource amongst the tasks. However, due to stringent performance requirements on network processors (which process packets from very high speed network traffic), neither OS nor hardware mechanisms are typically feasible/available. In this paper, we show that it is very difficult and inefficient for the programmer to meet the constraints of runtime management by coding them statically. Due to the infeasibility of hardware or OS solution (even in the near future), the only choice left is a compiler approach. We propose a complete compiler solution to automatically insert explicit context switch (ctx) instructions provided on the processors so that the execution of programs is better manipulated at runtime to meet their constraints. We show that such an approach is feasible opening new application domains that would need heterogeneous thread programming. Such approaches would in general become important for multi-core processors.", "paper_title": "Effective thread management on network processors with compiler analysis", "paper_id": "WOS:000202972200010"}