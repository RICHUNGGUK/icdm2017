{"auto_keywords": [{"score": 0.04466418483879831, "phrase": "speech_recognition"}, {"score": 0.041886289106049655, "phrase": "noisy_conditions"}, {"score": 0.0156107766127449, "phrase": "autocorrelation_domain"}, {"score": 0.014063155324772487, "phrase": "additive_noise"}, {"score": 0.01339367371160063, "phrase": "new_features"}, {"score": 0.01214764639452681, "phrase": "speech_signal"}, {"score": 0.010129859577480804, "phrase": "filter_bank"}, {"score": 0.00481495049065317, "phrase": "spectral_peaks"}, {"score": 0.004747714939490445, "phrase": "robust_speech_recognition"}, {"score": 0.0045037997020733415, "phrase": "peak_extraction"}, {"score": 0.004197878397604354, "phrase": "channel_characteristics"}, {"score": 0.004168448339217754, "phrase": "additive_noises"}, {"score": 0.0038715697646612766, "phrase": "autocorrelation_sequence"}, {"score": 0.0038309141193444015, "phrase": "speech_signal_frame"}, {"score": 0.003633927813203731, "phrase": "second_step"}, {"score": 0.0035579889785989738, "phrase": "short-time_power_spectrum"}, {"score": 0.003434922209075514, "phrase": "fast_fourier_transform"}, {"score": 0.0033988361874354306, "phrase": "power_spectrum_peaks"}, {"score": 0.003316098012193133, "phrase": "power_spectrum"}, {"score": 0.0030153435879168634, "phrase": "cepstral_coefficients"}, {"score": 0.0027225413530200505, "phrase": "speech_recognition_experiments"}, {"score": 0.0026750045328382717, "phrase": "multi-speaker_isolated-word_recognition"}, {"score": 0.002628295539850913, "phrase": "multi-speaker_continuous_speech_recognition"}, {"score": 0.0023315400785212785, "phrase": "experimental_results"}, {"score": 0.0023151639346874883, "phrase": "significant_improvements"}, {"score": 0.002234988641498543, "phrase": "traditional_feature_extraction_methods"}, {"score": 0.0021499920551456956, "phrase": "cepstral_mean_normalization"}, {"score": 0.0021049977753042253, "phrase": "robust_features"}], "paper_keywords": [""], "paper_abstract": "In this paper, a set of features derived by filtering and spectral peak extraction in autocorrelation domain are proposed. We focus on the effect of the additive noise on speech recognition. Assuming that the channel characteristics and additive noises are stationary, these new features improve the robustness of speech recognition in noisy conditions. In this approach, initially, the autocorrelation sequence of a speech signal frame is computed. Filtering of the autocorrelation of speech signal is carried out in the second step, and then, the short-time power spectrum of speech is obtained from the speech signal through the fast Fourier transform. The power spectrum peaks are then calculated by differentiating the power spectrum with respect to frequency. The magnitudes of these peaks are then projected onto the mel-scale and pass the filter bank. Finally, a set of cepstral coefficients are derived from the outputs of the filter bank. The effectiveness of the new features for speech recognition in noisy conditions will be shown in this paper through a number of speech recognition experiments. A task of multi-speaker isolated-word recognition and another one of multi-speaker continuous speech recognition with various artificially added noises such as factory, babble, car and F16 were used in these experiments. Also, a set of experiments were carried out on Aurora 2 task. Experimental results show significant improvements under noisy conditions in comparison to the results obtained using traditional feature extraction methods. We have also reported the results obtained by applying cepstral mean normalization on the methods to get robust features against both additive noise and channel distortion. (c) 2006 Elsevier Ltd. All rights reserved.", "paper_title": "Features based on filtering and spectral peaks in autocorrelation domain for robust speech recognition", "paper_id": "WOS:000241794800009"}