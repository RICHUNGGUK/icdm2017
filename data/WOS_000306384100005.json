{"auto_keywords": [{"score": 0.03594971232257351, "phrase": "large-scale_data_sets"}, {"score": 0.03343615427333049, "phrase": "small_granularity"}, {"score": 0.00481495049065317, "phrase": "multi-granulation_view"}, {"score": 0.004696491408936132, "phrase": "challenging_problem"}, {"score": 0.004599994523941615, "phrase": "pattern_recognition"}, {"score": 0.004486846016179313, "phrase": "rough"}, {"score": 0.004376378707877484, "phrase": "valid_soft_computing_tool"}, {"score": 0.004146327465630697, "phrase": "helpful_features"}, {"score": 0.00399415558125301, "phrase": "rough_set_theory"}, {"score": 0.003690927840780375, "phrase": "data_sets"}, {"score": 0.003630073540438812, "phrase": "large_scale"}, {"score": 0.003439117493141663, "phrase": "efficient_rough_feature_selection_algorithm"}, {"score": 0.0032446544415922615, "phrase": "data_set"}, {"score": 0.0031125001790084936, "phrase": "large-scale_data"}, {"score": 0.0030231983220281836, "phrase": "different_small_granularities"}, {"score": 0.00288800021194675, "phrase": "original_data"}, {"score": 0.0027818804382539444, "phrase": "small_granularities"}, {"score": 0.002690820958068933, "phrase": "approximate_reduct"}, {"score": 0.002624482632439123, "phrase": "total_time"}, {"score": 0.002591927716261631, "phrase": "computing_reducts"}, {"score": 0.002486292595645607, "phrase": "original_large-scale"}, {"score": 0.0023651843133643768, "phrase": "feature_subset"}, {"score": 0.002212812864395738, "phrase": "proposed_algorithm"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Feature selection", " Multi-granulation view", " Rough set theory", " Large-scale data sets"], "paper_abstract": "Feature selection is a challenging problem in many areas such as pattern recognition, machine learning and data mining. Rough set theory, as a valid soft computing tool to analyze various types of data, has been widely applied to select helpful features (also called attribute reduction). In rough set theory, many feature selection algorithms have been developed in the literatures, however, they are very time-consuming when data sets are in a large scale. To overcome this limitation, we propose in this paper an efficient rough feature selection algorithm for large-scale data sets, which is stimulated from multi-granulation. A sub-table of a data set can be considered as a small granularity. Given a large-scale data set, the algorithm first selects different small granularities and then estimate on each small granularity the reduct of the original data set. Fusing all of the estimates on small granularities together, the algorithm can get an approximate reduct. Because of that the total time spent on computing reducts for sub-tables is much less than that for the original large-scale one, the algorithm yields in a much less amount of time a feature subset (the approximate reduct). According to several decision performance measures, experimental results show that the proposed algorithm is feasible and efficient for large-scale data sets. (c) 2012 Elsevier Inc. All rights reserved.", "paper_title": "An efficient rough feature selection algorithm with a multi-granulation view", "paper_id": "WOS:000306384100005"}