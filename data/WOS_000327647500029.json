{"auto_keywords": [{"score": 0.04239913611090826, "phrase": "gaussian"}, {"score": 0.00481495049065317, "phrase": "discriminative_key_poses"}, {"score": 0.004769958800452922, "phrase": "action_recognition"}, {"score": 0.0045726187330434025, "phrase": "new_approach"}, {"score": 0.004529881123652277, "phrase": "human_action_recognition"}, {"score": 0.004466519142879166, "phrase": "key-pose_selection"}, {"score": 0.004342430078306461, "phrase": "video_frames"}, {"score": 0.004329242308448217, "phrase": "gabor"}, {"score": 0.004241648852523704, "phrase": "proposed_extensive_pyramidal_features"}, {"score": 0.003990385737207714, "phrase": "wavelet_pyramids"}, {"score": 0.0036324746826127997, "phrase": "informative_representation"}, {"score": 0.003598492288058048, "phrase": "human_poses"}, {"score": 0.0032756158688245, "phrase": "adaboost_algorithm"}, {"score": 0.0032239779327239066, "phrase": "svm"}, {"score": 0.0031845067058084583, "phrase": "discriminative_poses"}, {"score": 0.003125175084962886, "phrase": "boosted_poses"}, {"score": 0.0030954005063472284, "phrase": "bayes"}, {"score": 0.003081400693055518, "phrase": "video_sequence"}, {"score": 0.003038237581227068, "phrase": "new_classifier"}, {"score": 0.002995677265350124, "phrase": "local_naive_bayes"}, {"score": 0.0028986672783671147, "phrase": "final_action_classification"}, {"score": 0.0025290375256888883, "phrase": "proposed_method"}, {"score": 0.0024916582251593286, "phrase": "kth"}, {"score": 0.0024014759148123736, "phrase": "weizmann_data"}, {"score": 0.0023566987138026285, "phrase": "multiview_ixmas_data"}, {"score": 0.0022696277881969896, "phrase": "experimental_results"}, {"score": 0.0021049977753042253, "phrase": "recognition_rate"}], "paper_keywords": ["AdaBoost", " computer vision", " extensive pyramidal features (EPFs)", " human action recognition", " pose selection", " weighted local naive Bayes nearest neighbor (WLNBNN) classifier"], "paper_abstract": "In this paper, we present a new approach for human action recognition based on key-pose selection and representation. Poses in video frames are described by the proposed extensive pyramidal features (EPFs), which include the Gabor, Gaussian, and wavelet pyramids. These features are able to encode the orientation, intensity, and contour information and therefore provide an informative representation of human poses. Due to the fact that not all poses in a sequence are discriminative and representative, we further utilize the AdaBoost algorithm to learn a subset of discriminative poses. Given the boosted poses for each video sequence, a new classifier named weighted local naive Bayes nearest neighbor is proposed for the final action classification, which is demonstrated to be more accurate and robust than other classifiers, e.g., support vector machine (SVM) and naive Bayes nearest neighbor. The proposed method is systematically evaluated on the KTH data set, the Weizmann data set, the multiview IXMAS data set, and the challenging HMDB51 data set. Experimental results manifest that our method outperforms the state-of-the-art techniques in terms of recognition rate.", "paper_title": "Learning Discriminative Key Poses for Action Recognition", "paper_id": "WOS:000327647500029"}