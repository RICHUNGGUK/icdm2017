{"auto_keywords": [{"score": 0.04430475728264122, "phrase": "general-purpose_applications"}, {"score": 0.00481495049065317, "phrase": "speculatively_parallel_threads."}, {"score": 0.004676173016967478, "phrase": "multiple_cores"}, {"score": 0.004625164125506718, "phrase": "single_chip"}, {"score": 0.0043464021636703066, "phrase": "single_program"}, {"score": 0.00411436400374349, "phrase": "efficient_parallel_execution"}, {"score": 0.003995697901740734, "phrase": "ambiguous_data_dependences"}, {"score": 0.0039665679106594106, "phrase": "thread-level_speculation"}, {"score": 0.0037961770933599135, "phrase": "potentially_dependent_threads"}, {"score": 0.0036866541358511005, "phrase": "detailed_performance_trade-off_analysis"}, {"score": 0.0036198068824262464, "phrase": "efficient_parallel_programs"}, {"score": 0.003351987298847214, "phrase": "inter-thread_value_communication"}, {"score": 0.0032671775301001483, "phrase": "ubiquitous_existence"}, {"score": 0.0030700099570048346, "phrase": "program_patterns"}, {"score": 0.0029380187414193653, "phrase": "thread_performance"}, {"score": 0.00284275228258112, "phrase": "recovery_code"}, {"score": 0.0028014064098604093, "phrase": "critical_forwarding_path"}, {"score": 0.00276066021951467, "phrase": "memory_resident_values"}, {"score": 0.0027006464509273806, "phrase": "reduction_variables"}, {"score": 0.002622647280008795, "phrase": "serializing_execution"}, {"score": 0.0025468951021098717, "phrase": "consecutive_iterations"}, {"score": 0.0024642796422450755, "phrase": "unbalanced_workload"}, {"score": 0.0024462867877027435, "phrase": "detailed_evaluation"}, {"score": 0.002419542935774618, "phrase": "proposed_mechanism"}, {"score": 0.0023843376332011936, "phrase": "optimization_technique"}, {"score": 0.002248553559414903, "phrase": "proposed_optimizations"}, {"score": 0.0021049977753042253, "phrase": "register-resident_value_communication"}], "paper_keywords": ["Thread-level speculation", " multicore systems", " compiler optimizations", " parallelizing compiler"], "paper_abstract": "As technology advances, microprocessors that integrate multiple cores on a single chip are becoming increasingly common. How to use these processors to improve the performance of a single program has been a challenge. For general-purpose applications, it is especially difficult to create efficient parallel execution due to the complex control flow and ambiguous data dependences. Thread-level speculation and transactional memory provide two hardware mechanisms that are able to optimistically parallelize potentially dependent threads. However, a compiler that performs detailed performance trade-off analysis is essential for generating efficient parallel programs for these hardwares. This compiler must be able to take into consideration the cost of intra-thread as well as inter-thread value communication. On the other hand, the ubiquitous existence of complex, input-dependent control flow and data dependence patterns in general-purpose applications makes it impossible to have one technique optimize all program patterns. In this paper, we propose three optimization techniques to improve the thread performance: (i) scheduling instruction and generating recovery code to reduce the critical forwarding path introduced by synchronizing memory resident values; (ii) identifying reduction variables and transforming the code the minimize the serializing execution; and (iii) dynamically merging consecutive iterations of a loop to avoid stalls due to unbalanced workload. Detailed evaluation of the proposed mechanism shows that each optimization technique improves a subset but none improve all of the SPEC2000 benchmarks. On average, the proposed optimizations improve the performance by 7% for the set of the SPEC2000 benchmarks that have already been optimized for register-resident value communication.", "paper_title": "CODE TRANSFORMATIONS FOR ENHANCING THE PERFORMANCE OF SPECULATIVELY PARALLEL THREADS", "paper_id": "WOS:000305249100009"}