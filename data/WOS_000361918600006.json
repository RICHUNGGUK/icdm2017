{"auto_keywords": [{"score": 0.04879257974669139, "phrase": "natural_images"}, {"score": 0.031069894506734384, "phrase": "low_luminance_contrast"}, {"score": 0.02660751524225159, "phrase": "closed_boundary_regions"}, {"score": 0.00481495049065317, "phrase": "real-world_images"}, {"score": 0.00460125407969429, "phrase": "important_stage"}, {"score": 0.004497973025639345, "phrase": "content-based_image_retrieval"}, {"score": 0.004457309741979921, "phrase": "visual_impairment_assistance_systems"}, {"score": 0.004417012437860011, "phrase": "automatic_robot_navigation"}, {"score": 0.004377077848734575, "phrase": "urban_environments"}, {"score": 0.004337502738649814, "phrase": "tourist_assistance_systems"}, {"score": 0.003907212558276185, "phrase": "robust_scene_text_localization"}, {"score": 0.0038368442918503072, "phrase": "challenging_task"}, {"score": 0.003683097597914604, "phrase": "novel_method"}, {"score": 0.003287482882222731, "phrase": "uneven_illumination_conditions"}, {"score": 0.0031990183472675377, "phrase": "median_filtering"}, {"score": 0.0031556799865964974, "phrase": "nonlinear_edge-preserving_smoothing_filter"}, {"score": 0.002988101395789399, "phrase": "text_localization_system"}, {"score": 0.0029076695661972114, "phrase": "poor_quality_texts"}, {"score": 0.002753224894944965, "phrase": "nontext_ones"}, {"score": 0.0027159094186967247, "phrase": "unified_framework"}, {"score": 0.0026548344763838213, "phrase": "maximally_stable_extremal_regions"}, {"score": 0.0026188490199688013, "phrase": "novel_proposed_region_detector"}, {"score": 0.0024797072773840704, "phrase": "phase_congruency_and_laplacian_operators"}, {"score": 0.0023372808856170386, "phrase": "single_text_lines"}, {"score": 0.002305589818994465, "phrase": "meanshift_clustering"}, {"score": 0.002233301265743633, "phrase": "experimental_results"}, {"score": 0.002193013499219711, "phrase": "proposed_method"}, {"score": 0.002153450937601075, "phrase": "low_quality_scene_texts"}, {"score": 0.0021049977753042253, "phrase": "latin_scripts"}], "paper_keywords": ["Scene text localization", " closed boundary", " natural images", " luminance contrast", " content-based image retrieval", " visual impairment assistance system"], "paper_abstract": "Localization of texts in natural images could be an important stage in many applications such as content-based image retrieval, visual impairment assistance systems, automatic robot navigation in urban environments and tourist assistance systems. However due to the variations of font, script, scale, orientations, color, shadow and lighting conditions, robust scene text localization is still a challenging task. In this paper, we propose a novel method to localize not only Farsi/Arabic and Latin texts with different sizes, fonts and orientations but also low luminance contrast and poor quality ones in the natural images taken with uneven illumination conditions. Firstly, fast weighted median filtering as a nonlinear edge-preserving smoothing filter and then color contrast preserving decolorization are exploited to make the text localization system more robust for low luminance contrast and poor quality texts. In order to extract the Farsi/Arabic and Latin scene texts and also filter the nontext ones, a unified framework is proposed incorporating the maximally stable extremal regions and a novel proposed region detector called Stable Width Stroke Regions which is based on closed boundary regions. Phase congruency and Laplacian operators are exploited to extract the closed boundary regions. Finally, to extract the single text lines, the Meanshift clustering and radon transform were used. Experimental results show that the proposed method localize low luminance contrast and low quality scene texts for both Farsi/Arabic and Latin scripts encouragingly.", "paper_title": "Robust Localization of Texts in Real-World Images", "paper_id": "WOS:000361918600006"}