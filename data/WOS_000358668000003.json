{"auto_keywords": [{"score": 0.04942444706912143, "phrase": "gpu"}, {"score": 0.00481495049065317, "phrase": "graphics_processing_unit"}, {"score": 0.004525629293824217, "phrase": "faster_improvements"}, {"score": 0.004463723624910583, "phrase": "peak_processing_speed"}, {"score": 0.004195418010131832, "phrase": "highly_programmable_and_multithreaded_nature"}, {"score": 0.0039431758381711125, "phrase": "general_purpose_computing"}, {"score": 0.003809628721278519, "phrase": "non-graphics_computing"}, {"score": 0.0033651019362620866, "phrase": "better_hiding"}, {"score": 0.0031626225189867354, "phrase": "slow_global_memory"}, {"score": 0.0029928611380840757, "phrase": "proposed_method"}, {"score": 0.0028127163745564777, "phrase": "access_time"}, {"score": 0.0027741761880779535, "phrase": "off-chip_data"}, {"score": 0.00271735110571002, "phrase": "noticeable_role"}, {"score": 0.0026616868981501006, "phrase": "waiting_time"}, {"score": 0.002571429085596686, "phrase": "unutilized_elements"}, {"score": 0.0024842242921857705, "phrase": "processing_elements"}, {"score": 0.0024333239726872604, "phrase": "suitable_manner"}, {"score": 0.0023507916951658455, "phrase": "stall_times"}, {"score": 0.002302619021497886, "phrase": "memory_gap"}, {"score": 0.002255431275670053, "phrase": "energy-efficient_manner"}, {"score": 0.0021342613107011624, "phrase": "energy_consumption"}, {"score": 0.0021049977753042253, "phrase": "simulation_results"}], "paper_keywords": ["GPGPU", " Performance and power optimization", " Global memory access", " Prefetching", " Idle processing element", " Utilization"], "paper_abstract": "The graphics processing unit (GPU) is the most promising candidate platform for achieving faster improvements in peak processing speed, low latency and high performance. The highly programmable and multithreaded nature of GPUs makes them a remarkable candidate for general purpose computing. However, supporting non-graphics computing on graphics processors requires addressing several architectural challenges. In this paper, we focus on improving performance by better hiding long waiting time for transferring data from the slow global memory. Furthermore, we show that the proposed method can reduce power and energy. Reduction in access time to off-chip data has a noticeable role in reducing waiting time and the percentage of unutilized elements. Also, using processing elements in a suitable manner to prefetch data during stall times bridges the memory gap in an energy-efficient manner, and consequently leads to less power and energy consumption. Simulation results show that we can potentially improve instruction per cycle (IPC) up to 24.76 %. Moreover, results show that power, energy and energy efficiency improve by up to 22.47, 24.72 and 36.01 %, respectively.", "paper_title": "Power-efficient prefetching on GPGPUs", "paper_id": "WOS:000358668000003"}