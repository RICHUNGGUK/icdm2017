{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "multiple_cues"}, {"score": 0.004753194996637899, "phrase": "context-sensitive_reliabilities"}, {"score": 0.004342430078306461, "phrase": "visual_tracking"}, {"score": 0.0041773934798743405, "phrase": "multi-cue_integration"}, {"score": 0.003967021436047945, "phrase": "open_issue"}, {"score": 0.003742941972172613, "phrase": "novel_data_fusion_approach"}, {"score": 0.003694884775158077, "phrase": "multi-cue_tracking"}, {"score": 0.0035087260813209593, "phrase": "previous_approaches"}, {"score": 0.0030435998319355883, "phrase": "target_object"}, {"score": 0.002622947550220266, "phrase": "visual_cues"}, {"score": 0.0022457226013538343, "phrase": "tracking_accuracy"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Visual tracking", " Data fusion", " Multiple cues", " Particle filter"], "paper_abstract": "Many researchers argue that fusing multiple cues increases the reliability and robustness of visual tracking. However, how the multi-cue integration is realized during tracking is still an open issue. In this work, we present a novel data fusion approach for multi-cue tracking using particle filter. Our method differs from previous approaches in a number of ways. First, we carry out the integration of cues both in making predictions about the target object and in verifying them through observations. Our second and more significant contribution is that both stages of integration directly depend on the dynamically changing reliabilities of visual cues. These two aspects of our method allow the tracker to easily adapt itself to the changes in the context, and accordingly improve the tracking accuracy by resolving the ambiguities. (C) 2011 Elsevier Ltd. All rights reserved.", "paper_title": "Visual tracking by fusing multiple cues with context-sensitive reliabilities", "paper_id": "WOS:000301017700012"}