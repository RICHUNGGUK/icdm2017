{"auto_keywords": [{"score": 0.03955963658357214, "phrase": "partner_identity"}, {"score": 0.0156044203282763, "phrase": "human_-_computer_dialogue"}, {"score": 0.011746292197532057, "phrase": "syntactic_alignment"}, {"score": 0.010474094002392931, "phrase": "strong_default_preference"}, {"score": 0.00481495049065317, "phrase": "syntactic_choices"}, {"score": 0.004691136491297242, "phrase": "speech_interfaces"}, {"score": 0.00465634671242413, "phrase": "speech_interaction"}, {"score": 0.004621813738791474, "phrase": "computer_partners"}, {"score": 0.004419904580451831, "phrase": "users'_language_choices"}, {"score": 0.004387117409226736, "phrase": "human_computer_dialogue"}, {"score": 0.004258372598568333, "phrase": "picture-naming-matching_task"}, {"score": 0.0041642891310893, "phrase": "human_computer_speech-based_interactions"}, {"score": 0.00395273370234774, "phrase": "strong_default_grammatical_preferences"}, {"score": 0.00383668723824441, "phrase": "system_capabilities"}, {"score": 0.0034695189961509625, "phrase": "dative_structures"}, {"score": 0.0025556529150386168, "phrase": "practical_and_theoretical_implications"}, {"score": 0.002536668157912723, "phrase": "hci"}, {"score": 0.0024805205483927743, "phrase": "spoken_dialogue_system_behaviour"}, {"score": 0.0024529174827030787, "phrase": "users'_syntactic_choices"}, {"score": 0.0023807981747706376, "phrase": "natural_corpora_findings"}, {"score": 0.0023021895404322767, "phrase": "cognitive_mechanisms"}, {"score": 0.0021049977753042253, "phrase": "elsevier_ltd."}], "paper_keywords": ["Human - computer dialogue", " Syntactic alignment", " Speech interaction", " User behaviour", " Psycholinguistics", " Interlocutor modelling"], "paper_abstract": "The growth of speech interfaces and speech interaction with computer partners has made it increasingly important to understand the factors that determine users' language choices in human computer dialogue. We report two controlled experiments that used a picture-naming-matching task to investigate whether users in human computer speech-based interactions tend to use the same grammatical structures as their conversational partners, and whether such syntactic alignment can impact strong default grammatical preferences. We additionally investigate whether beliefs about system capabilities that are based on partner identity (i.e. human or computer) and speech interface design cues (here, voice anthropomorphism) affect the magnitude of syntactic alignment in such interactions. We demonstrate syntactic alignment for both dative structures (e.g., give the waitress the apple vs. give the apple to the waitress), where there is no strong default preference for one or other structure (Experiment 1), and noun phrase structures (e.g., a purple circle vs. a circle that is purple), where there is a strong default preference for one structure (Experiment 2). The tendency to align syntactically was unaffected by partner identity (human vs. computer) or voice anthropomorphism. These findings have both practical and theoretical implications for HCI by demonstrating the potential for spoken dialogue system behaviour to influence users' syntactic choices in interaction. As well as verifying natural corpora findings, this work also highlights that priming and cognitive mechanisms that are unmediated by beliefs about partner identity could be important in understanding why people align syntactically in human - computer dialogue. (C) 2015 Elsevier Ltd. All rights reserved.", "paper_title": "Voice anthropomorphism, interlocutor modelling and alignment effects on syntactic choices in human - computer dialogue", "paper_id": "WOS:000361582500003"}