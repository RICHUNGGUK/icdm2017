{"auto_keywords": [{"score": 0.03626275334087335, "phrase": "rl"}, {"score": 0.029480734250265747, "phrase": "value_function"}, {"score": 0.00481495049065317, "phrase": "responsive_grids"}, {"score": 0.004692227830462433, "phrase": "resource_sharing"}, {"score": 0.004513957235071457, "phrase": "large_scientific_collaborations"}, {"score": 0.004456044928556639, "phrase": "seamless_integration"}, {"score": 0.004342430078306461, "phrase": "everyday_use"}, {"score": 0.00409723267214392, "phrase": "elastic_clouds"}, {"score": 0.003767203575060969, "phrase": "model-free_resource_provisioning_strategy"}, {"score": 0.003531474887552889, "phrase": "continuous_action-state_space"}, {"score": 0.003486123304074186, "phrase": "multi-objective_reinforcement_learning"}, {"score": 0.003331915219811852, "phrase": "realistic_hypotheses"}, {"score": 0.003289117944111902, "phrase": "simple_utility_functions"}, {"score": 0.0032259472087775138, "phrase": "high_level_goals"}, {"score": 0.0030239842475439814, "phrase": "model-free_approach"}, {"score": 0.0029467742734417255, "phrase": "general_program"}, {"score": 0.0029089095588612007, "phrase": "autonomic_computing"}, {"score": 0.0028346293790895024, "phrase": "incremental_learning"}, {"score": 0.002709161672473817, "phrase": "rl_model"}, {"score": 0.0026570998719084153, "phrase": "so-called_feedback_loop"}, {"score": 0.00244278788608393, "phrase": "echo_state_network"}, {"score": 0.002411383506019635, "phrase": "experimental_validation"}, {"score": 0.0023650305205893353, "phrase": "real_data-set"}, {"score": 0.002319566486828135, "phrase": "egee_grid"}, {"score": 0.0022457226013538343, "phrase": "moderate_level"}, {"score": 0.002132420504803564, "phrase": "high_level"}, {"score": 0.0021049977753042253, "phrase": "user_satisfaction"}], "paper_keywords": ["Grid scheduling", " Performance of systems", " Machine learning", " Reinforcement learning"], "paper_abstract": "Grids organize resource sharing, a fundamental requirement of large scientific collaborations. Seamless integration of Grids into everyday use requires responsiveness, which can be provided by elastic Clouds, in the Infrastructure as a Service (IaaS) paradigm. This paper proposes a model-free resource provisioning strategy supporting both requirements. Provisioning is modeled as a continuous action-state space, multi-objective reinforcement learning (RL) problem, under realistic hypotheses; simple utility functions capture the high level goals of users, administrators, and shareholders. The model-free approach falls under the general program of autonomic computing, where the incremental learning of the value function associated with the RL model provides the so-called feedback loop. The RL model includes an approximation of the value function through an Echo State Network. Experimental validation on a real data-set from the EGEE Grid shows that introducing a moderate level of elasticity is critical to ensure a high level of user satisfaction.", "paper_title": "Multi-objective Reinforcement Learning for Responsive Grids", "paper_id": "WOS:000281066900005"}