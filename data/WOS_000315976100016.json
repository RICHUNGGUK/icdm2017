{"auto_keywords": [{"score": 0.03832932980111358, "phrase": "type_algorithms"}, {"score": 0.03656942654266258, "phrase": "decision_cluster_classifiers"}, {"score": 0.03371119733473879, "phrase": "initial_centers"}, {"score": 0.00481495049065317, "phrase": "nested_agglomerative_k-means"}, {"score": 0.00470975295439431, "phrase": "important_task"}, {"score": 0.0046683172874085015, "phrase": "machine_learning_community"}, {"score": 0.004606843145343611, "phrase": "basic_assumption"}, {"score": 0.00436890075128947, "phrase": "data_space"}, {"score": 0.004016938499717623, "phrase": "similar_objects"}, {"score": 0.002908306074124806, "phrase": "clustering_performance"}, {"score": 0.002661883310629088, "phrase": "agglomerative_fuzzy_k-means"}, {"score": 0.0025578967205807843, "phrase": "clustering_algorithm"}, {"score": 0.002341094670523097, "phrase": "cluster_validation_techniques"}, {"score": 0.0022396694076443446, "phrase": "density_level"}, {"score": 0.0021809311689473493, "phrase": "experimental_results"}, {"score": 0.002161695357601592, "phrase": "uci_benchmark_data_sets"}], "paper_keywords": ["Classification", " Decision cluster classifier", " Agglomerative K-Means"], "paper_abstract": "Classification is an important task in machine learning community. The basic assumption of classification is that the objects that are spatially close in data space tend to have the same label, which is quite similar to the objective of clustering, i.e. grouping similar objects into the same cluster. Based on this fact, several researchers have proposed to build classifiers by using the K-means type algorithms to partition the data sequentially, which are named as decision cluster classifiers. While it is wellknown that the performance of K-means type algorithms relies on the locations of initial centers and the selections of number of clusters, it is necessary to deal with both issues well such that the clustering performance is good enough to build such classifiers. In this paper, we propose to build decision cluster classifiers by using the agglomerative fuzzy K-means because of its three good properties: (1) the clustering algorithm is insensitive to initial centers; (2) the algorithm can automatically determine the number of clusters combined with cluster validation techniques; (3) the algorithm can control the density level of clusters identified. The experimental results on UCI benchmark data sets have shown the effectiveness of our proposed approach.", "paper_title": "A Novel Decision Cluster Classifier with Nested Agglomerative K-Means", "paper_id": "WOS:000315976100016"}