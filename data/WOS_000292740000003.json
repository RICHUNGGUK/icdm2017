{"auto_keywords": [{"score": 0.0446305392042061, "phrase": "action_variations"}, {"score": 0.00481495049065317, "phrase": "discriminative_video_pattern_search"}, {"score": 0.004776484866276242, "phrase": "efficient_action_detection"}, {"score": 0.004700468701207975, "phrase": "spatiotemporal_patterns"}, {"score": 0.004607139608615063, "phrase": "sliding_window-based_object_detection"}, {"score": 0.004425979295788883, "phrase": "pattern_matching"}, {"score": 0.004355516897622305, "phrase": "cluttered_and_dynamic_backgrounds"}, {"score": 0.004003511299646736, "phrase": "intrapattern_variations"}, {"score": 0.003876996400581697, "phrase": "action_pattern_search"}, {"score": 0.003845994935767022, "phrase": "cluttered_scenes"}, {"score": 0.003739421738326676, "phrase": "discriminative_pattern"}, {"score": 0.0036798490617699227, "phrase": "action_classification"}, {"score": 0.0036214238917505327, "phrase": "bayes"}, {"score": 0.0033958751452139984, "phrase": "spatiotemporal_invariant_features"}, {"score": 0.003301733505307784, "phrase": "action_class"}, {"score": 0.0032491108935498794, "phrase": "mutual_information"}, {"score": 0.0031590250068577867, "phrase": "matching_criterion"}, {"score": 0.0031337465656628132, "phrase": "action_detection"}, {"score": 0.003034633345146293, "phrase": "volumetric_video_space"}, {"score": 0.0029862549873935496, "phrase": "maximum_mutual_information"}, {"score": 0.0029504765287722465, "phrase": "specific_action_class"}, {"score": 0.0029034358982402346, "phrase": "spatiotemporal_branch"}, {"score": 0.0028229071631385634, "phrase": "search_algorithm"}, {"score": 0.0027446057983474994, "phrase": "optimal_solution"}, {"score": 0.002636489396049042, "phrase": "human_detection"}, {"score": 0.0025840347813610815, "phrase": "background_subtraction"}, {"score": 0.002472269923319476, "phrase": "style_variations"}, {"score": 0.002432834929068545, "phrase": "scale_changes"}, {"score": 0.0023558375480288297, "phrase": "dynamic_and_cluttered_backgrounds"}, {"score": 0.0023182554418193927, "phrase": "partial_occlusions"}, {"score": 0.0022904619303011097, "phrase": "cross-data_set_experiments"}, {"score": 0.002235877650610431, "phrase": "kth"}, {"score": 0.0022179605282337395, "phrase": "cmu_action_data_sets"}, {"score": 0.002182573128803447, "phrase": "new_msr_action_data_set"}, {"score": 0.0021049977753042253, "phrase": "proposed_multiclass_multiple-instance_action_detection_method"}], "paper_keywords": ["Video pattern search", " action detection", " spatiotemporal branch-and-bound search"], "paper_abstract": "Actions are spatiotemporal patterns. Similar to the sliding window-based object detection, action detection finds the reoccurrences of such spatiotemporal patterns through pattern matching, by handling cluttered and dynamic backgrounds and other types of action variations. We address two critical issues in pattern matching-based action detection: 1) the intrapattern variations in actions, and 2) the computational efficiency in performing action pattern search in cluttered scenes. First, we propose a discriminative pattern matching criterion for action classification, called naive Bayes mutual information maximization (NBMIM). Each action is characterized by a collection of spatiotemporal invariant features and we match it with an action class by measuring the mutual information between them. Based on this matching criterion, action detection is to localize a subvolume in the volumetric video space that has the maximum mutual information toward a specific action class. A novel spatiotemporal branch-and-bound (STBB) search algorithm is designed to efficiently find the optimal solution. Our proposed action detection method does not rely on the results of human detection, tracking, or background subtraction. It can handle action variations such as performing speed and style variations as well as scale changes well. It is also insensitive to dynamic and cluttered backgrounds and even to partial occlusions. The cross-data set experiments on action detection, including KTH, CMU action data sets, and another new MSR action data set, demonstrate the effectiveness and efficiency of the proposed multiclass multiple-instance action detection method.", "paper_title": "Discriminative Video Pattern Search for Efficient Action Detection", "paper_id": "WOS:000292740000003"}