{"auto_keywords": [{"score": 0.041821166199646924, "phrase": "xeon_phi"}, {"score": 0.00481495049065317, "phrase": "intel_xeon_phi_coprocessors"}, {"score": 0.004666460260366703, "phrase": "mrphi"}, {"score": 0.00459404255173625, "phrase": "mapreduce"}, {"score": 0.00452252857066346, "phrase": "heterogeneous_computing_platform"}, {"score": 0.004434824354230475, "phrase": "multiple_intel_xeon_phi_coprocessors"}, {"score": 0.00424779023663186, "phrase": "first_work"}, {"score": 0.004181743040532619, "phrase": "mapreduce_framework"}, {"score": 0.004036852178449883, "phrase": "advanced_features"}, {"score": 0.003943047070755799, "phrase": "high_performance"}, {"score": 0.0038969619124903884, "phrase": "single_coprocessor"}, {"score": 0.003821342577980031, "phrase": "vectorization_friendly_technique"}, {"score": 0.0037915057447460133, "phrase": "simd_hash_computation"}, {"score": 0.003717925116469845, "phrase": "simd_vectors"}, {"score": 0.0035332058983966424, "phrase": "resource_utilization"}, {"score": 0.0034510635632071978, "phrase": "multiple_local_arrays"}, {"score": 0.0034107088717109857, "phrase": "low_cost_atomic_operations"}, {"score": 0.0033708244679086265, "phrase": "global_array"}, {"score": 0.0033183674218329904, "phrase": "thread_scalability"}, {"score": 0.0031658283119347396, "phrase": "suitable_techniques"}, {"score": 0.0030321497870310077, "phrase": "heterogeneous_platform"}, {"score": 0.0029849474387154827, "phrase": "hardware_resource"}, {"score": 0.002892729377519916, "phrase": "data_transfer"}, {"score": 0.002847691227421257, "phrase": "communication_overhead"}, {"score": 0.002792375587031108, "phrase": "aligned_memory_transfer"}, {"score": 0.0027167292419065514, "phrase": "pcie_bandwidth"}, {"score": 0.002622465142275264, "phrase": "comprehensive_experiments"}, {"score": 0.0025215486544004134, "phrase": "state-of-the-art_multi-core_based_mapreduce_framework"}, {"score": 0.00238674051726235, "phrase": "experimental_results"}, {"score": 0.002259123228671651, "phrase": "single_xeon_phi"}, {"score": 0.0021551702945512494, "phrase": "linear_scalability"}], "paper_keywords": ["Xeon Phi", " Intel Many Integrated Core architecture (MIC)", " coprocessors", " MapReduce", " parallel programming", " high performance computing", " heterogeneous computing"], "paper_abstract": "In this work, we develop MrPhi, an optimized MapReduce framework on a heterogeneous computing platform, particularly equipped with multiple Intel Xeon Phi coprocessors. To the best of our knowledge, this is the first work to optimize the MapReduce framework on the Xeon Phi. We first focus on employing advanced features of the Xeon Phi to achieve high performance on a single coprocessor. We propose a vectorization friendly technique and SIMD hash computation algorithms to utilize the SIMD vectors. Then we pipeline the map and reduce phases to improve the resource utilization. Furthermore, we eliminate multiple local arrays but use low cost atomic operations on the global array to improve the thread scalability. For a given application, our framework is able to automatically detect suitable techniques to apply. Moreover, we extend our framework to a heterogeneous platform to utilize all hardware resource effectively. We adopt non-blocking data transfer to hide the communication overhead. We also adopt aligned memory transfer in order to fully utilize the PCIe bandwidth between the host and coprocessor. We conduct comprehensive experiments to benchmark the Xeon Phi and compare our optimized MapReduce framework with a state-of-the-art multi-core based MapReduce framework (Phoenix++). By evaluating six real-world applications, the experimental results show that our optimized framework is 1.2 to 38 x faster than Phoenix++ for various applications on a single Xeon Phi. Additionally, the performance of four applications is able to achieve linear scalability on a platform equipped with up to four Xeon Phi coprocessors.", "paper_title": "MrPhi: An Optimized MapReduce Framework on Intel Xeon Phi Coprocessors", "paper_id": "WOS:000362792200013"}