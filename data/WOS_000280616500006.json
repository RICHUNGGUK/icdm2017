{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "multi-modal_image_retrieval"}, {"score": 0.004768378525561471, "phrase": "integrating_web_image_annotation"}, {"score": 0.004722254884093624, "phrase": "concept_matching"}, {"score": 0.004676575291629554, "phrase": "fuzzy_ranking_techniques"}, {"score": 0.004631335513513859, "phrase": "traditional_image_retrieval"}, {"score": 0.004564291332315995, "phrase": "bridging_visual_images"}, {"score": 0.004520132822496416, "phrase": "human_concepts"}, {"score": 0.004476399615305783, "phrase": "visual_or_textual_descriptions"}, {"score": 0.004305639197085793, "phrase": "challenging_issue"}, {"score": 0.004121275290411653, "phrase": "user's_intentions"}, {"score": 0.003983334573043943, "phrase": "considerable_number"}, {"score": 0.0038499929374478125, "phrase": "multimedia_mining"}, {"score": 0.0036671822784770463, "phrase": "user's_requirements"}, {"score": 0.003631671435460452, "phrase": "image_retrieval"}, {"score": 0.003409057326528229, "phrase": "content-based_image_retrieval"}, {"score": 0.0032629585038738856, "phrase": "user's_interest"}, {"score": 0.003215659239270654, "phrase": "visual_descriptions"}, {"score": 0.0031536550157613974, "phrase": "textual-based_image_retrieval"}, {"score": 0.003107935254560724, "phrase": "modern_search_engines"}, {"score": 0.00303319936111073, "phrase": "high_manual_tagging_cost"}, {"score": 0.003003809128328864, "phrase": "low_automated_tagging_precision"}, {"score": 0.0029458777184930896, "phrase": "precise_image_retrieval"}, {"score": 0.0029031614127920232, "phrase": "unsatisfied_results"}, {"score": 0.0028471655497661528, "phrase": "rough_human_concepts"}, {"score": 0.0027922467043592597, "phrase": "user's_concept"}, {"score": 0.002711842889248926, "phrase": "novel_approach"}, {"score": 0.002672511078070529, "phrase": "intelligent_semantic_image_explorer"}, {"score": 0.002424450174817922, "phrase": "proposed_web_image_annotation"}, {"score": 0.002366110899738696, "phrase": "fuzzy_ranking_methods"}, {"score": 0.002286781334850213, "phrase": "desired_images"}, {"score": 0.0022536005664642294, "phrase": "image_collection"}, {"score": 0.0021886732310288128, "phrase": "empirical_evaluations"}, {"score": 0.002135995282374723, "phrase": "high_accuracy"}, {"score": 0.0021049977753042253, "phrase": "semantic_image_retrieval"}], "paper_keywords": ["Image retrieval", " image annotation", " fuzzy set", " cross media", " information retrieval"], "paper_abstract": "Traditional image retrieval aims at bridging visual images and human concepts through visual or textual descriptions. However, it is still a challenging issue to reduce the gap between the images and user's intentions. To this end, a considerable number of studies in the field of multimedia mining have been conducted on how to effectively meet the user's requirements for image retrieval over the past few decades. However, there remain some problems unsettled. For content-based image retrieval, it is not easy to identify the user's interest by using visual descriptions only. For textual-based image retrieval, the modern search engines incur the problems of high manual tagging cost and low automated tagging precision. Moreover, precise image retrieval also leads unsatisfied results because of the rough human concepts. To catch user's concept well, we propose a novel approach, namely Intelligent SeMantic Image explorER (iSMIER), which considers the requirements of usability, intelligence and effectiveness simultaneously. Based on the proposed web image annotation, concept matching and fuzzy ranking methods, the users can obtain the desired images from the image collection easily and effectively. Through empirical evaluations, our annotation models can deliver high accuracy for serving semantic image retrieval.", "paper_title": "Multi-Modal Image Retrieval by Integrating Web Image Annotation, Concept Matching and Fuzzy Ranking Techniques", "paper_id": "WOS:000280616500006"}