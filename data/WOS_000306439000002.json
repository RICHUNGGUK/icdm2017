{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "exploratory_data_mining_results"}, {"score": 0.025239150647283284, "phrase": "iterative_data_mining"}, {"score": 0.0046570462031865385, "phrase": "significantly_different_information"}, {"score": 0.003956234229826621, "phrase": "different_results"}, {"score": 0.003927004211021119, "phrase": "possibly_different_methods"}, {"score": 0.0037981086150309885, "phrase": "first_step"}, {"score": 0.003566028957296066, "phrase": "noisy_tiles"}, {"score": 0.003461758868675955, "phrase": "maximum_entropy_modelling"}, {"score": 0.003436169600453596, "phrase": "kullback-leibler_divergence"}, {"score": 0.0033480826365657303, "phrase": "information_theory"}, {"score": 0.0031317713853981064, "phrase": "background_knowledge"}, {"score": 0.0028121943702224326, "phrase": "jaccard_dissimilarity"}, {"score": 0.002760478838718213, "phrase": "exact_tiles"}, {"score": 0.002620666087191234, "phrase": "different_exploratory_data_mining_methods"}, {"score": 0.0024421501497321027, "phrase": "best_redescribe_other_results"}, {"score": 0.002258924405138231, "phrase": "maximal_novel_information"}, {"score": 0.002242206465278159, "phrase": "experimental_evaluation"}, {"score": 0.0022091400304857043, "phrase": "meaningful_results"}, {"score": 0.0021049977753042253, "phrase": "sound_redescriptions"}], "paper_keywords": ["Exploratory data mining", " Distance", " Maximum entropy model", " Iterative data mining", " Tiling", " Binary data"], "paper_abstract": "Deciding whether the results of two different mining algorithms provide significantly different information is an important, yet understudied, open problem in exploratory data mining. Whether the goal is to select the most informative result for analysis, or to decide which mining approach will most likely provide the most novel insight, it is essential that we can tell how different the information is that different results by possibly different methods provide. In this paper we take a first step towards comparing exploratory data mining results on binary data. We propose to meaningfully convert results into sets of noisy tiles, and compare between these sets by maximum entropy modelling and Kullback-Leibler divergence, well-founded notions from Information Theory. We so construct a measure that is highly flexible, and allows us to naturally include background knowledge, such that differences in results can be measured from the perspective of what a user already knows. Furthermore, adding to its interpretability, it coincides with Jaccard dissimilarity when we only consider exact tiles. Our approach provides a means to study and tell differences between results of different exploratory data mining methods. As an application, we show that our measure can also be used to identify which parts of results best redescribe other results. Furthermore, we study its use for iterative data mining, where one iteratively wants to find that result that will provide maximal novel information. Experimental evaluation shows our measure gives meaningful results, correctly identifies methods that are similar in nature, automatically provides sound redescriptions of results, and is highly applicable for iterative data mining.", "paper_title": "Comparing apples and oranges: measuring differences between exploratory data mining results", "paper_id": "WOS:000306439000002"}