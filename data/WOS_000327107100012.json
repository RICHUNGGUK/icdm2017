{"auto_keywords": [{"score": 0.04776427214624881, "phrase": "kinectfusion"}, {"score": 0.043122440159155284, "phrase": "sdf"}, {"score": 0.04066558262001855, "phrase": "parallel_computation"}, {"score": 0.0403681503613345, "phrase": "graphics_hardware"}, {"score": 0.0364170240290687, "phrase": "computation_time"}, {"score": 0.004814958357084662, "phrase": "octree"}, {"score": 0.004617455679463816, "phrase": "octree-based_surface_representation"}, {"score": 0.004461882369408972, "phrase": "in-door_scenes"}, {"score": 0.0044111930537670705, "phrase": "low-cost_moving_depth_camera"}, {"score": 0.004150377643719188, "phrase": "signed_distance_function"}, {"score": 0.004025787455454387, "phrase": "uniform_grid"}, {"score": 0.003934795713147731, "phrase": "grid-based_sdf"}, {"score": 0.003604576287781528, "phrase": "scene_volume"}, {"score": 0.0035096666710980108, "phrase": "memory_cost"}, {"score": 0.0032396224508754387, "phrase": "surface_prediction"}, {"score": 0.003106541164572609, "phrase": "reconstruction_update_step"}, {"score": 0.003071201732948199, "phrase": "octree_nodes"}, {"score": 0.003013191092393344, "phrase": "breath-first_order"}, {"score": 0.0029450186031370245, "phrase": "moving_objects"}, {"score": 0.0029115112555515277, "phrase": "corresponding_nodes"}, {"score": 0.002824005136794786, "phrase": "storage_overflow"}, {"score": 0.0027812405653371503, "phrase": "surface_prediction_step"}, {"score": 0.0027495914857929584, "phrase": "octree-based_ray_tracing_method"}, {"score": 0.002687366778212309, "phrase": "graphic_hardware"}, {"score": 0.002360381056508366, "phrase": "proposed_method"}, {"score": 0.002324620886282579, "phrase": "original_kinectfusion_method"}, {"score": 0.0022894012453842064, "phrase": "faster_performance"}, {"score": 0.0021049977753042253, "phrase": "elsevier_inc."}], "paper_keywords": ["Octree", " KinectFusion", " 3D reconstruction", " Graphics hardware", " Signed distance function", " Ray casting"], "paper_abstract": "This paper proposes an octree-based surface representation for KinectFusion, a realtime reconstruction technique of in-door scenes using a low-cost moving depth camera and a commodity graphics hardware. In KinectFusion, the scene is represented as a signed distance function (SDF) and stored as an uniform grid of voxels. Though the grid-based SDF is suitable for parallel computation in graphics hardware, most of the storage are wasted, because the geometry is very sparse in the scene volume. In order to reduce the memory cost and save the computation time, we represent the SDF in an octree, and developed several octree-based algorithms for reconstruction update and surface prediction that are suitable for parallel computation in graphics hardware. In the reconstruction update step, the octree nodes are adaptively split in breath-first order. To handle scenes with moving objects, the corresponding nodes are automatically detected and removed to avoid storage overflow. In the surface prediction step, an octree-based ray tracing method is adopted and parallelized for graphic hardware. To further reduce the computation time, the octree is organized into four layers, called top layer, branch layer, middle layer and data layer. The experiments showed that, the proposed method consumes only less than 10% memory of original KinectFusion method, and achieves faster performance. Consequently, it can reconstruct scenes with more than 10 times larger size than the original KinectFusion on the same hardware setup. (C) 2012 Elsevier Inc. All rights reserved.", "paper_title": "Octree-based fusion for realtime 3D reconstruction", "paper_id": "WOS:000327107100012"}