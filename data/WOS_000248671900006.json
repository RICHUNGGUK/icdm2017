{"auto_keywords": [{"score": 0.0500785296201053, "phrase": "fuzzy_rules"}, {"score": 0.01557763786427779, "phrase": "classification_problems"}, {"score": 0.015436823223834596, "phrase": "single-winner_inference"}, {"score": 0.004662705558154439, "phrase": "previous_studies"}, {"score": 0.004515252649226697, "phrase": "adaboost-based_fitness"}, {"score": 0.004372442291178139, "phrase": "genetic_algorithm"}, {"score": 0.004119049028319832, "phrase": "restrictive_constraints"}, {"score": 0.004007083686875716, "phrase": "logical_connectives"}, {"score": 0.0039522429946090174, "phrase": "inference_method"}, {"score": 0.0037921662574137535, "phrase": "adaboost_produces"}, {"score": 0.0036218682585355895, "phrase": "maximum_sum"}, {"score": 0.0035887342563437935, "phrase": "votes_scheme"}, {"score": 0.003459191419478298, "phrase": "t-norm_product"}, {"score": 0.0033961782274326948, "phrase": "\"and\"_operator"}, {"score": 0.0032436052954996097, "phrase": "linguistic_interpretability"}, {"score": 0.002799810685137358, "phrase": "individual_rules"}, {"score": 0.0027614468443073028, "phrase": "knowledge_base"}, {"score": 0.0026986844240380215, "phrase": "adaboost"}, {"score": 0.0024842242921857705, "phrase": "better_choice"}, {"score": 0.002405496949144104, "phrase": "nontrivial_hypotheses"}, {"score": 0.002265833357217618, "phrase": "boosting-based_genetic_method"}, {"score": 0.002224510044064184, "phrase": "weighted_fuzzy_rules"}, {"score": 0.002163930783583212, "phrase": "last_inference_method"}, {"score": 0.0021049977753042253, "phrase": "wiley_periodicals"}], "paper_keywords": [""], "paper_abstract": "In previous studies, we have shown that an Adaboost-based fitness can be successfully combined with a Genetic Algorithm to iteratively learn fuzzy rules from examples in classification problems. Unfortunately, some restrictive constraints in the implementation of the logical connectives and the inference method were assumed. Alas, the knowledge bases Adaboost produces are only compatible with an inference based on the maximum sum of votes scheme, and they can only use the t-norm product to model the \"and\" operator. This design is not optimal in terms of linguistic interpretability. Using the sum to aggregate votes allows many rules to be combined, when the class of an example is being decided. Because it can be difficult to isolate the contribution of individual rules to the knowledge base, fuzzy rules produced by Adaboost may be difficult to understand linguistically. In this point of view, single-winner inference would be a better choice, but it implies dropping some nontrivial hypotheses. In this work we introduce our first results in the search for a boosting-based genetic method able to learn weighted fuzzy rules that are compatible with this last inference method. (C) 2007 Wiley Periodicals, Inc.", "paper_title": "Boosting fuzzy rules in classification problems under single-winner inference", "paper_id": "WOS:000248671900006"}