{"auto_keywords": [{"score": 0.03719615111360803, "phrase": "scopus"}, {"score": 0.031042161122130953, "phrase": "google_scholar"}, {"score": 0.007900507035091289, "phrase": "bibliographic_data"}, {"score": 0.00481495049065317, "phrase": "video_retrieval_evaluation_benchmarking"}, {"score": 0.0045355866228818514, "phrase": "methodological_issues"}, {"score": 0.004472234553892357, "phrase": "scholarly_impact"}, {"score": 0.0044408896450445125, "phrase": "bibliometric_study"}, {"score": 0.004363480951473701, "phrase": "computer_science"}, {"score": 0.004227515355865597, "phrase": "video_retrieval_evaluation"}, {"score": 0.0039264465913491356, "phrase": "useful_information"}, {"score": 0.0037906837773782, "phrase": "similar_studies"}, {"score": 0.003724566354526513, "phrase": "particular_relevance"}, {"score": 0.00368544869176071, "phrase": "academic_disciplines"}, {"score": 0.0036467403626789666, "phrase": "publication_and_citation_norms"}, {"score": 0.0035579889785989738, "phrase": "traditional_tools"}, {"score": 0.003508322427645907, "phrase": "google"}, {"score": 0.003434922209075514, "phrase": "detailed_comparison"}, {"score": 0.0033749889869455407, "phrase": "different_search_methods"}, {"score": 0.0033513085425415545, "phrase": "cleaning_methods"}, {"score": 0.0032467792804296036, "phrase": "author_analysis"}, {"score": 0.0031901183059524804, "phrase": "additional_database_capabilities"}, {"score": 0.0031455000569352454, "phrase": "'scopus"}, {"score": 0.0030689098754563982, "phrase": "scopus_general'"}, {"score": 0.0030047427137652218, "phrase": "scopus_paper_coverage"}, {"score": 0.002880393760798211, "phrase": "superior_performance"}, {"score": 0.002790511479398411, "phrase": "additional_citations"}, {"score": 0.0027514668612638074, "phrase": "citation_totals"}, {"score": 0.0027034263575471352, "phrase": "relative_ranking"}, {"score": 0.0026190518142076608, "phrase": "software_wrapper"}, {"score": 0.0025194861926779223, "phrase": "possible_solutions"}, {"score": 0.0024842242921857705, "phrase": "data_cleaning_methods"}, {"score": 0.0024236964502593254, "phrase": "domain_checking"}, {"score": 0.002381365139274329, "phrase": "content_checking"}, {"score": 0.0023646398663605493, "phrase": "retrieved_papers"}, {"score": 0.002290814637620121, "phrase": "citation_count"}, {"score": 0.0021049977753042253, "phrase": "comparative_ease"}], "paper_keywords": ["bibliometrics", " methodology", " research evaluation", " TRECVid", " video retrieval", " visualization"], "paper_abstract": "This paper provides a discussion and analysis of methodological issues encountered during a scholarly impact and bibliometric study within the field of Computer Science (TRECVid Text Retrieval and Evaluation Conference, Video Retrieval Evaluation). The purpose of this paper is to provide a reflection and analysis of the methods used to provide useful information and guidance for those who may wish to undertake similar studies, and is of particular relevance for the academic disciplines which have publication and citation norms that may not perform well using traditional tools. Scopus and Google Scholar are discussed and a detailed comparison of the effects of different search methods and cleaning methods within and between these tools for subject and author analysis is provided. The additional database capabilities and usefulness of 'Scopus More' in addition to 'Scopus General' are discussed and evaluated. Scopus paper coverage is found to favourably compare with Google Scholar but Scholar consistently has superior performance at finding citations to those papers. These additional citations significantly increase the citation totals and also change the relative ranking of papers. Publish or Perish, a software wrapper for Google Scholar, is also examined and its limitations and some possible solutions are described. Data cleaning methods, including duplicate checks, expert domain checking of bibliographic data, and content checking of retrieved papers, are compared and their relative effects on paper and citation count discussed. Google Scholar and Scopus are also compared as tools for collecting bibliographic data for visualizations of developing trends and, owing to the comparative ease of collecting abstracts, Scopus is found far more effective.", "paper_title": "A bibliometric study of Video Retrieval Evaluation Benchmarking (TRECVid): A methodological analysis", "paper_id": "WOS:000298259200003"}