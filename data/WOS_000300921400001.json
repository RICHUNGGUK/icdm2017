{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "local_features"}, {"score": 0.015592422582013333, "phrase": "human_action_classification"}, {"score": 0.004697655699119423, "phrase": "human_action_recognition"}, {"score": 0.004640079189342692, "phrase": "promising_yet_non-trivial_computer_vision_field"}, {"score": 0.004471530397729526, "phrase": "bag-of-feature_approaches"}, {"score": 0.004344662696228875, "phrase": "human_actions"}, {"score": 0.00430907756010007, "phrase": "complex_context"}, {"score": 0.0041696157492057, "phrase": "common_practice"}, {"score": 0.00405127920820053, "phrase": "merely_an_orderless"}, {"score": 0.004001593118269276, "phrase": "local_salient_features"}, {"score": 0.0037776319581225046, "phrase": "traditional_approaches"}, {"score": 0.003746673633703251, "phrase": "robust_deployment"}, {"score": 0.0037159680715717056, "phrase": "real-life_scenarios"}, {"score": 0.0034935290662899488, "phrase": "account_global_configuration"}, {"score": 0.00338037259057507, "phrase": "recognition_performance"}, {"score": 0.0032979090806670493, "phrase": "novel_feature_selection_process"}, {"score": 0.00327086925741257, "phrase": "sparse_hierarchical_bayes_filter"}, {"score": 0.00313894917464766, "phrase": "neighboring_structure_constraints"}, {"score": 0.002999955539996569, "phrase": "human_action_analysis"}, {"score": 0.0029147175927233546, "phrase": "human_action"}, {"score": 0.0027856252557826467, "phrase": "different_spatial_and_temporal_feature_constraints"}, {"score": 0.0025865679621853667, "phrase": "action_localization"}, {"score": 0.002471973283582411, "phrase": "dynamic_conditional_random_field"}, {"score": 0.00245168871716047, "phrase": "probabilistic_perspective"}, {"score": 0.0024017007954518065, "phrase": "structural_support_vector_machine"}, {"score": 0.0023819914954155905, "phrase": "max-margin_point"}, {"score": 0.0021576973674470997, "phrase": "bag-of-feature_methods"}, {"score": 0.0021049977753042253, "phrase": "elsevier_b.v."}], "paper_keywords": ["Action recognition", " Action localization", " Structured Learning", " Local spatio-temporal features", " Hierarchical sparse Bayesian filter", " Support vector machine", " Dynamic conditional random fields", " Structural support vector machine"], "paper_abstract": "Human action recognition is a promising yet non-trivial computer vision field with many potential applications. Current advances in bag-of-feature approaches have brought significant insights into recognizing human actions within complex context. It is, however, a common practice in literature to consider action as merely an orderless set of local salient features. This representation has been shown to be oversimplified, which inherently limits traditional approaches from robust deployment in real-life scenarios. In this work, we propose and show that, by taking into account global configuration of local features, we can greatly improve recognition performance. We first introduce a novel feature selection process called Sparse Hierarchical Bayes Filter to select only the most contributive features of each action type based on neighboring structure constraints. We then present the application of structured learning in human action analysis. That is, by representing human action as a complex set of local features, we can incorporate different spatial and temporal feature constraints into the learning tasks of human action classification and localization. In particular, we tackle the problem of action localization in video using structured learning with two alternatives: one is Dynamic Conditional Random Field from probabilistic perspective; the other is Structural Support Vector Machine from max-margin point of view. We evaluate our modular classification-localization framework on various testbeds, in which our proposed framework is proven to be highly effective and robust compared against bag-of-feature methods. (C) 2011 Elsevier B.V. All rights reserved.", "paper_title": "Structured learning of local features for human action classification and localization", "paper_id": "WOS:000300921400001"}