{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "memory_constraints"}, {"score": 0.004693167092003573, "phrase": "current_high-performance_computing"}, {"score": 0.0045162169185355, "phrase": "exascale_systems"}, {"score": 0.0037262941538784094, "phrase": "account_memory_capacity"}, {"score": 0.0036788184374592706, "phrase": "bandwidth_constraints"}, {"score": 0.003608732492631878, "phrase": "new_strategy"}, {"score": 0.0035627492415494216, "phrase": "aggregation_data_traffic"}, {"score": 0.0035173498506324476, "phrase": "disjointed_subgroups"}, {"score": 0.00334144503360907, "phrase": "internode_layers"}, {"score": 0.003215295260684715, "phrase": "run_time"}, {"score": 0.0031743093007496736, "phrase": "memory_consumption"}, {"score": 0.0029203055813347874, "phrase": "commonly_used_benchmarks"}, {"score": 0.0028100102841877835, "phrase": "evaluation_results"}, {"score": 0.002635339648135844, "phrase": "memory_pressure"}, {"score": 0.002535779689260244, "phrase": "memory_bandwidth"}, {"score": 0.0024243586247372087, "phrase": "projected_extreme-scale_systems"}, {"score": 0.0023178219772486868, "phrase": "increasingly_data-intensive_workloads"}, {"score": 0.0022302306304023602, "phrase": "increasingly_larger_scale_hpc_systems"}, {"score": 0.0021322065604537617, "phrase": "significant_positive_impact"}, {"score": 0.0021049977753042253, "phrase": "scientific_discovery_productivity"}], "paper_keywords": ["Exascale system", " parallel input", " output", " collective input", " output", " many-core architecture", " data-intensive computing", " high-performance computing"], "paper_abstract": "Compared with current high-performance computing (HPC) systems, exascale systems are expected to have much less memory per node, which can significantly reduce necessary collective input/output (I/O) performance. In this study, we introduce a memory-conscious collective I/O strategy that takes into account memory capacity and bandwidth constraints. The new strategy restricts aggregation data traffic within disjointed subgroups, coordinates I/O accesses in intranode and internode layers, and determines I/O aggregators at run time considering memory consumption among processes. We have prototyped the design and evaluated it with commonly used benchmarks to verify its potential. The evaluation results demonstrate that this strategy holds promise in mitigating the memory pressure, alleviating the contention for memory bandwidth, and improving the I/O performance for projected extreme-scale systems. Given the importance of supporting increasingly data-intensive workloads and projected memory constraints on increasingly larger scale HPC systems, this new memory-conscious collective I/O can have a significant positive impact on scientific discovery productivity.", "paper_title": "Collective input/output under memory constraints", "paper_id": "WOS:000349452000003"}