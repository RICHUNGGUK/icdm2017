{"auto_keywords": [{"score": 0.00481495049065317, "phrase": "h-infinity_filtering"}, {"score": 0.004248294537944227, "phrase": "efficient_training_and_pruning_method"}, {"score": 0.0040916230716372265, "phrase": "h_infinity_filtering_algorithm"}, {"score": 0.00389164348807591, "phrase": "feedforward_neural_networks"}, {"score": 0.0036097844103129043, "phrase": "fnns'_weight_importance_measure"}, {"score": 0.00347657813672945, "phrase": "prediction_error_sensitivity"}, {"score": 0.0031448288291084, "phrase": "weight_salience"}, {"score": 0.0027741761880779535, "phrase": "extensive_experimentation"}, {"score": 0.0026384167183586015, "phrase": "proposed_method"}, {"score": 0.0025730425700096365, "phrase": "better_pruning_results"}, {"score": 0.002477998427152547, "phrase": "training_process"}, {"score": 0.002158505888557746, "phrase": "robust_global_optimization_training_algorithm"}], "paper_keywords": [""], "paper_abstract": "An efficient training and pruning method based on H infinity filtering algorithm is proposed for Feedforward neural networks (FNNs). A FNNs' weight importance measure linking up prediction error sensitivity obtained from H. filtering training and a weight salience based pruning technique are derived. The results of extensive experimentation indicate that the proposed method provides better pruning results during the training process of the network without losing its generalization capacity, also provides a robust global optimization training algorithm for given arbitrary network Structures.", "paper_title": "On H-infinity filtering in feedforward neural networks training and pruning", "paper_id": "WOS:000238112000077"}