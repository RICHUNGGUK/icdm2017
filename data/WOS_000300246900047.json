{"auto_keywords": [{"score": 0.049651030276363126, "phrase": "input_dimension"}, {"score": 0.030027520448339416, "phrase": "target_functions"}, {"score": 0.00481495049065317, "phrase": "computational_models"}, {"score": 0.0042650992966174065, "phrase": "d-variable_functions"}, {"score": 0.0041703614123283165, "phrase": "adjustable_computational_units"}, {"score": 0.0038810583785936505, "phrase": "linear_combination"}, {"score": 0.003677280504320636, "phrase": "particular_attention"}, {"score": 0.0035794251590584563, "phrase": "worst-case_error"}, {"score": 0.0034529760173586583, "phrase": "factorized_form"}, {"score": 0.0031845067058084613, "phrase": "target_sets"}, {"score": 0.003071965703296204, "phrase": "function_xi"}, {"score": 0.0029901699209266435, "phrase": "important_cases"}, {"score": 0.0024202176034746337, "phrase": "square-integrable_partial_derivatives"}, {"score": 0.00216263228969761, "phrase": "optimization_problems"}, {"score": 0.002143247921132179, "phrase": "neural_networks"}, {"score": 0.0021049977753042253, "phrase": "gaussian_radial_computational_units"}], "paper_keywords": ["Dictionary-based computational models", " high-dimensional approximation and optimization", " model complexity", " polynomial upper bounds"], "paper_abstract": "The role of input dimension d is studied in approximating, in various norms, target sets of d-variable functions using linear combinations of adjustable computational units. Results from the literature, which emphasize the number n of terms in the linear combination, are reformulated, and in some cases improved, with particular attention to dependence on d. For worst-case error, upper bounds are given in the factorized form xi(d)kappa(n), where kappa is nonincreasing (typically kappa(n) similar to n(-1/2)). Target sets of functions are described for which the function xi is a polynomial. Some important cases are highlighted where xi decreases to zero as d -> infinity. For target functions, extent (e.g., the size of domains in where they are defined), scale (e.g., maximum norms of target functions), and smoothness (e.g., the order of square-integrable partial derivatives) may depend on, and the influence of such dimension-dependent parameters on model complexity is considered. Results are applied to approximation and solution of optimization problems by neural networks with perceptron and Gaussian radial computational units.", "paper_title": "Dependence of Computational Models on Input Dimension: Tractability of Approximation and Optimization Tasks", "paper_id": "WOS:000300246900047"}