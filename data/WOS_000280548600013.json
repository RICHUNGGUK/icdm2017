{"auto_keywords": [{"score": 0.04340653256317277, "phrase": "cache_performance"}, {"score": 0.00481495049065317, "phrase": "cache-conscious_placement_of_data"}, {"score": 0.004586531354697466, "phrase": "memory_accesses"}, {"score": 0.004507594400447103, "phrase": "frequently_accessed_data"}, {"score": 0.00436890075128947, "phrase": "increasing_gap"}, {"score": 0.004338661611644755, "phrase": "processor_speed"}, {"score": 0.004308630865024719, "phrase": "memory_access_latency"}, {"score": 0.004190563478825626, "phrase": "program_performance"}, {"score": 0.0037107679833206773, "phrase": "compile-time_data_placement_techniques"}, {"score": 0.003308649946463136, "phrase": "finite_set"}, {"score": 0.003285725064532174, "phrase": "data_objects"}, {"score": 0.0030331993611107328, "phrase": "data_accesses"}, {"score": 0.002991300390411948, "phrase": "compile_time"}, {"score": 0.0028890603352364273, "phrase": "direct-mapped_cache"}, {"score": 0.0028195727965553367, "phrase": "data_access_sequence"}, {"score": 0.0025578967205807843, "phrase": "minimal_number"}, {"score": 0.002248899833549883, "phrase": "cache_forces_conflict"}, {"score": 0.0021049977753042253, "phrase": "original_assignment"}], "paper_keywords": ["Algorithms", " Measurement", " Performance", " Offline Algorithms", " Memory Management", " Cache Consciousness", " Cache Optimization", " Data Placement in Cache"], "paper_abstract": "Caches were designed to amortize the cost of memory accesses by moving copies of frequently accessed data closer to the processor. Over the years the increasing gap between processor speed and memory access latency has made the cache a bottleneck for program performance. Enhancing cache performance has been instrumental in speeding up programs. For this reason several hardware and software techniques have been proposed by researchers to optimize the cache for minimizing the number of misses. Among these are compile-time data placement techniques in memory which improve cache performance. For the purpose of this work, we concern ourselves with the problem of laying out data in memory given the sequence of accesses on a finite set of data objects such that cache-misses are minimized. The problem has been shown to be hard to solve optimally even if the sequence of data accesses is known at compile time. In this paper we show that given a direct-mapped cache, its size, and the data access sequence, it is possible to identify the instances where there are no conflict misses. We describe an algorithm that can assign the data to cache for minimal number of misses if there exists a way in which conflict misses can be avoided altogether. We also describe the implementation of a heuristic for assigning data to cache for instances where the size of the cache forces conflict misses. Experiments show that our technique results in a 30% reduction in the number of cache misses compared to the original assignment.", "paper_title": "A Graph Theoretic Approach to Cache-Conscious Placement of Data for Direct Mapped Caches", "paper_id": "WOS:000280548600013"}