{"auto_keywords": [{"score": 0.05007852962010532, "phrase": "mixed_reality"}, {"score": 0.004591202593942391, "phrase": "virtual_objects"}, {"score": 0.004551647527068771, "phrase": "captured_video"}, {"score": 0.004473552224535518, "phrase": "perceived_unification"}, {"score": 0.0042656009036320585, "phrase": "virtual_actors"}, {"score": 0.004084920064588169, "phrase": "real_objects"}, {"score": 0.003997458586709491, "phrase": "spatial_relationships"}, {"score": 0.003945879572348638, "phrase": "resulting_world"}, {"score": 0.0034204548167213545, "phrase": "environment_preparation"}, {"score": 0.0033909518548844047, "phrase": "commercial_products"}, {"score": 0.0033471722682967046, "phrase": "interactive_mr_domains"}, {"score": 0.003261295948815592, "phrase": "video_camera_hardware"}, {"score": 0.0029264925857346497, "phrase": "relatively_low_camera_quality"}, {"score": 0.002863762666256937, "phrase": "multiple_camera_sources"}, {"score": 0.002754208576828914, "phrase": "required_processing_speed"}, {"score": 0.0026603411931700556, "phrase": "fast_and_affordable_solution"}, {"score": 0.0025696647013416863, "phrase": "chroma_key"}, {"score": 0.0025364615261136655, "phrase": "principal_component_analysis"}, {"score": 0.0025148403527932807, "phrase": "pca"}, {"score": 0.0024713335323674223, "phrase": "usable_alpha_mattes"}, {"score": 0.002449997042686432, "phrase": "video_streams"}, {"score": 0.0024288443150616056, "phrase": "real-time_oil_commodity_graphics_processing_units"}, {"score": 0.0022857899334246946, "phrase": "off-line_commercial_keying_tools"}, {"score": 0.002169882514603539, "phrase": "video_stream"}, {"score": 0.0021049977753042253, "phrase": "john_wiley"}], "paper_keywords": ["mixed reality", " chroma keying", " GPU", " shader", " blue screening", " matting", " video processing", " real-time"], "paper_abstract": "In Mixed Reality (MR) applications, immersion of virtual objects in captured video contributes to the perceived unification of two worlds, one real, one synthetic. Since virtual actors and surround may appear both closer and farther than real objects, compositing must consider spatial relationships in the resulting world. Chroma keying, often called blue screening or green screening, is one common solution to this problem. This method is under-constrained and most commonly addressed through a combination of environment preparation and commercial products. In interactive MR domains that impose restrictions oil the video camera hardware, such as in experiences using video see-through (VST) head-mounted displays (HMD), chroma keying becomes even more difficult due to the relatively low camera quality, the use of multiple camera sources (one per eye), and the required processing speed. Dealing with these constraints requires a fast and affordable solution. In our approach, we precondition the chroma key by using principal component analysis (PCA) to obtain usable alpha mattes from video streams in real-time oil commodity graphics processing units (GPUs). In addition, we demonstrate how our method compares to off-line commercial keying tools and how it performs with respect to signal noise within the video stream. Copyright (C) 2009 John Wiley & Sons, Ltd.", "paper_title": "Interactive chroma keying for mixed reality", "paper_id": "WOS:000268110700033"}