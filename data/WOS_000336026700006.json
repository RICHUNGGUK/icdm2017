{"auto_keywords": [{"score": 0.03498718165642814, "phrase": "network_weights"}, {"score": 0.00481495049065317, "phrase": "boundedness_and_convergence_of_split-complex"}, {"score": 0.004593912914752708, "phrase": "momentum"}, {"score": 0.004298666679374568, "phrase": "split-complex_back-propagation_algorithm"}, {"score": 0.004061584718427419, "phrase": "complex-valued_neural_networks"}, {"score": 0.003236596168242036, "phrase": "sufficient_conditions"}, {"score": 0.003158776195052182, "phrase": "learning_rate"}, {"score": 0.002984373546099842, "phrase": "penalty_coefficient"}, {"score": 0.0028890603352364273, "phrase": "activation_functions"}, {"score": 0.002751751956416832, "phrase": "theoretical_results"}, {"score": 0.002436289099444074, "phrase": "training_process"}, {"score": 0.002246292543825748, "phrase": "convergence_analysis"}, {"score": 0.0021049977753042253, "phrase": "error_function"}], "paper_keywords": ["Complex-valued neural networks", " Split-complex back-propagation algorithm", " Momentum", " Penalty", " Boundedness", " Convergence"], "paper_abstract": "This paper investigates the split-complex back-propagation algorithm with momentum and penalty for training complex-valued neural networks. Here the momentum are used to accelerate the convergence of the algorithm and the penalty are used to control the magnitude of the network weights. The sufficient conditions for the learning rate, the momentum factor, the penalty coefficient, and the activation functions are proposed to establish the theoretical results of the algorithm. We theoretically prove the boundedness of the network weights during the training process, which is usually used as a precondition for convergence analysis in literatures. The monotonicity of the error function and the convergence of the algorithm are also guaranteed.", "paper_title": "Boundedness and Convergence of Split-Complex Back-Propagation Algorithm with Momentum and Penalty", "paper_id": "WOS:000336026700006"}