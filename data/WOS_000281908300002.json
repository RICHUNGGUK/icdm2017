{"auto_keywords": [{"score": 0.03455018268948866, "phrase": "hilbert_curves"}, {"score": 0.015476927634660503, "phrase": "self-organizing_maps"}, {"score": 0.00481495049065317, "phrase": "high-quality_mapping"}, {"score": 0.004415675459182871, "phrase": "random_vectors"}, {"score": 0.0042119653427658025, "phrase": "implicit_problem"}, {"score": 0.00414616342377235, "phrase": "random_initialization"}, {"score": 0.0035699363258657212, "phrase": "new_method"}, {"score": 0.0033518704336033874, "phrase": "self-similar_curves"}, {"score": 0.003097865379563127, "phrase": "network_size"}, {"score": 0.0028857130140890787, "phrase": "simple_recursive"}, {"score": 0.0024842242921857705, "phrase": "hilbert_curve_vector"}, {"score": 0.0023507916951658455, "phrase": "classical_som_algorithm"}, {"score": 0.0022777800735119405, "phrase": "parallel-growing_algorithm"}, {"score": 0.0021724831184390192, "phrase": "neural_network"}, {"score": 0.0021384748235753425, "phrase": "better_coverage"}, {"score": 0.0021049977753042253, "phrase": "faster_organization"}], "paper_keywords": ["Hilbert curves", " Self-organizing maps", " Initialization", " Neural networks"], "paper_abstract": "Initialization of self-organizing maps is typically based on random vectors within the given input space. The implicit problem with random initialization is the overlap (entanglement) of connections between neurons. In this paper, we present a new method of initialization based on a set of self-similar curves known as Hilbert curves. Hilbert curves can be scaled in network size for the number of neurons based on a simple recursive (fractal) technique, implicit in the properties of Hilbert curves. We have shown that when using Hilbert curve vector (HCV) initialization in both classical SOM algorithm and in a parallel-growing algorithm (ParaSOM), the neural network reaches better coverage and faster organization.", "paper_title": "Fractal initialization for high-quality mapping with self-organizing maps", "paper_id": "WOS:000281908300002"}