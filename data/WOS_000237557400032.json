{"auto_keywords": [{"score": 0.04771533004845802, "phrase": "gaussians"}, {"score": 0.00481495049065317, "phrase": "density_estimation"}, {"score": 0.004278807087784626, "phrase": "new_density_estimation_algorithm"}, {"score": 0.003965975628742746, "phrase": "new_algorithm"}, {"score": 0.0037701851296383405, "phrase": "popular_expectation_maximization_algorithm"}, {"score": 0.0035539019235553897, "phrase": "new_model_selection_criterion"}, {"score": 0.0031577303835881964, "phrase": "jensen-shannon_divergence"}, {"score": 0.002805597755796506, "phrase": "expectation_maximization"}, {"score": 0.0026895647154863405, "phrase": "better_structure_inference"}, {"score": 0.00257831812581194, "phrase": "locally_linear_search"}, {"score": 0.002471661547432869, "phrase": "penalty-less_information_criterion"}, {"score": 0.002349467661235186, "phrase": "underlying_density"}, {"score": 0.0021049977753042253, "phrase": "real_color_images"}], "paper_keywords": [""], "paper_abstract": "In this paper we present a new density estimation algorithm using mixtures of mixtures of Gaussians. The new algorithm overcomes the limitations of the popular Expectation Maximization algorithm. The paper first introduces a new model selection criterion called the Penalty-less Information Criterion, which is based on the Jensen-Shannon divergence. Mean-shift is used to automatically initialize the means and covariances of the Expectation Maximization in order to obtain better structure inference. Finally, a locally linear search is performed using the Penalty-less Information Criterion in order to infer the underlying density of the data. The validity of the algorithm is verified using real color images.", "paper_title": "Density estimation using mixtures of mixtures of Gaussians", "paper_id": "WOS:000237557400032"}