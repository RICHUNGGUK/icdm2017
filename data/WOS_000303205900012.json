{"auto_keywords": [{"score": 0.047510470298773616, "phrase": "coverage_closure"}, {"score": 0.04137315141208966, "phrase": "candidate_assertions"}, {"score": 0.00481495049065317, "phrase": "test_coverage_closure"}, {"score": 0.004615202066192795, "phrase": "input_stimulus"}, {"score": 0.004518448308225923, "phrase": "goldmine"}, {"score": 0.004349337717774093, "phrase": "data_mining"}, {"score": 0.004312622975366676, "phrase": "formal_verification"}, {"score": 0.00422218060227958, "phrase": "simulation_traces"}, {"score": 0.00416882434439484, "phrase": "behavioral_register_transfer_level"}, {"score": 0.004046923261950549, "phrase": "decision_tree"}, {"score": 0.003813669883040509, "phrase": "formal_verification_engine"}, {"score": 0.0037495207047193034, "phrase": "candidate_assertion"}, {"score": 0.003670843919846253, "phrase": "counterexample_trace"}, {"score": 0.003503497128638099, "phrase": "counterexample_traces"}, {"score": 0.0034299649219748513, "phrase": "original_simulation_trace_data"}, {"score": 0.0033579708256295847, "phrase": "incremental_decision_tree"}, {"score": 0.003301461490509176, "phrase": "new_traces"}, {"score": 0.0029817668105720924, "phrase": "complete_functionality"}, {"score": 0.0029067881142952664, "phrase": "sequential_design"}, {"score": 0.002762423953243486, "phrase": "monotonic_increase"}, {"score": 0.0027390682208834013, "phrase": "simulation_coverage"}, {"score": 0.0026701760128830573, "phrase": "output-centric_notion"}, {"score": 0.0024320326084093465, "phrase": "technique_step"}, {"score": 0.002380934815435267, "phrase": "nontrivial_arbiter_design"}, {"score": 0.002360796860462937, "phrase": "experimental_results"}, {"score": 0.0022722611219378663, "phrase": "rigel"}, {"score": 0.0022530375696567136, "phrase": "openrisc"}, {"score": 0.002224510044064184, "phrase": "spacewire"}, {"score": 0.002196342933346204, "phrase": "practical_limitations"}, {"score": 0.0021229583685841405, "phrase": "final_decision_tree"}, {"score": 0.0021049977753042253, "phrase": "binary_decision_diagram"}], "paper_keywords": ["Assertion", " data mining", " design validation", " static analysis"], "paper_abstract": "We propose a methodology to generate input stimulus to achieve coverage closure using GoldMine, an automatic assertion generation engine that uses data mining and formal verification. GoldMine mines the simulation traces of a behavioral register transfer level (RTL) design using a decision tree based learning algorithm to produce candidate assertions. These candidate assertions are passed to a formal verification engine. If a candidate assertion is false, a counterexample trace is generated. In this paper, we feed these counterexample traces to iteratively refine the original simulation trace data. We introduce an incremental decision tree to mine the new traces in each iteration. The algorithm converges when all the candidate assertions are true. We formally prove that our algorithm will always converge and capture the complete functionality of each output of a sequential design on convergence. We show that our method always results in a monotonic increase in simulation coverage. We also present an output-centric notion of coverage, and argue that we can attain coverage closure with respect to this notion of coverage. We elaborate the technique step by step using a nontrivial arbiter design. Experimental results to validate our arguments are presented on several designs from Rigel, OpenRisc, and SpaceWire. Some practical limitations to achieve 100% coverage and the differences between final decision tree and binary decision diagram are discussed.", "paper_title": "A Technique for Test Coverage Closure Using GoldMine", "paper_id": "WOS:000303205900012"}