{"auto_keywords": [{"score": 0.03983926434466607, "phrase": "evolutionary_probabilistic_neural_networks"}, {"score": 0.00481495049065317, "phrase": "neural_networks"}, {"score": 0.004554488671294504, "phrase": "prior_probabilities"}, {"score": 0.004342430078306461, "phrase": "novel_approaches"}, {"score": 0.004010624853427534, "phrase": "probabilistic_neural_networks"}, {"score": 0.0036747384051186937, "phrase": "spread_parameters"}, {"score": 0.003531474887552889, "phrase": "different_values"}, {"score": 0.0030847461428168614, "phrase": "particle_swarm_optimization"}, {"score": 0.0027159094186967247, "phrase": "bagging_technique"}, {"score": 0.0024101837218440834, "phrase": "model's_performance"}, {"score": 0.002138799283553239, "phrase": "benchmark_problems"}, {"score": 0.0021049977753042253, "phrase": "promising_results"}], "paper_keywords": ["probabilistic neural network", " particle swarm Optimization", " spread parameters", " prior probabilities", " bagging"], "paper_abstract": "In this contribution, novel approaches are proposed for the improvement of the performance of Probabilistic Neural Networks as well as the recently proposed Evolutionary Probabilistic Neural Networks. The Evolutionary Probabilistic Neural Network's matrix of spread parameters is allowed to have different values in each class of neurons, resulting in a more flexible model that fits the data better and Particle Swarm Optimization is also employed for the estimation of the Probabilistic Neural Networks's prior probabilities of each class. Moreover, the bagging technique is used to create an ensemble of Evolutionary Probabilistic Neural Networks in order to further improve the model's performance. The above approaches have been applied to several well-known and widely used benchmark problems with promising results.", "paper_title": "Novel approaches to probabilistic neural networks through bagging and evolutionary estimating of prior probabilities", "paper_id": "WOS:000253529100005"}