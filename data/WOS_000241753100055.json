{"auto_keywords": [{"score": 0.04490388164168672, "phrase": "noisy_environments"}, {"score": 0.01444480161099063, "phrase": "audio_and_visual_features"}, {"score": 0.009930597493494514, "phrase": "speech_recognition"}, {"score": 0.009056396790788663, "phrase": "contextual_information"}, {"score": 0.00481495049065317, "phrase": "multi-modal_features"}, {"score": 0.004713162564945179, "phrase": "neural_networks"}, {"score": 0.004646496622257368, "phrase": "recent_researches"}, {"score": 0.004357927940322685, "phrase": "reliable_speech_recognition"}, {"score": 0.004029359223675788, "phrase": "neural_network"}, {"score": 0.004000741805312148, "phrase": "based_model"}, {"score": 0.003944112858235306, "phrase": "robust_speech_recognition"}, {"score": 0.0038060092376105414, "phrase": "bimodal_neural_network"}, {"score": 0.003752126270661821, "phrase": "bmnn"}, {"score": 0.003646629717560631, "phrase": "multi-layer_perceptron"}, {"score": 0.0033001333942688778, "phrase": "audio_information"}, {"score": 0.0027025233739857374, "phrase": "sequential_patterns"}, {"score": 0.002445514186654732, "phrase": "single_mode_models"}, {"score": 0.0021049977753042253, "phrase": "significant_improvement"}], "paper_keywords": ["speech recognition", " neural network", " post-processing", " contextual information", " sequential pattern"], "paper_abstract": "Recent researches have been focusing on fusion of audio and visual features for reliable speech recognition in noisy environments. In this paper, we propose a neural network based model of robust speech recognition by integrating audio, visual, and contextual information. Bimodal Neural Network (BMNN) is a multi-layer perceptron of 4 layers, which combines audio and visual features of speech to compensate loss of audio information caused by noise. In order to improve the accuracy of speech recognition in noisy environments, we also propose a post-processing based on contextual information which are sequential patterns of words spoken by a user. Our experimental results show that our model outperforms any single mode models. Particularly, when we use the contextual information, we can obtain over 90% recognition accuracy even in noisy environments, which is a significant improvement compared with the state of art in speech recognition.", "paper_title": "Speech recognition with multi-modal features based on neural networks", "paper_id": "WOS:000241753100055"}