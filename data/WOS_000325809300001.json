{"auto_keywords": [{"score": 0.03354474230316615, "phrase": "sparse_representation"}, {"score": 0.014677487213124027, "phrase": "k-nn"}, {"score": 0.010647322481243074, "phrase": "smda"}, {"score": 0.008078901202554813, "phrase": "proposed_method"}, {"score": 0.00481495049065317, "phrase": "feature_extraction"}, {"score": 0.004732215871738028, "phrase": "existing_margin-based_discriminant_analysis_methods"}, {"score": 0.004544629724830453, "phrase": "k-nearest_neighbor"}, {"score": 0.004264697351852424, "phrase": "manifold_learning-based_methods"}, {"score": 0.004095567486538121, "phrase": "local_structure"}, {"score": 0.003955926499405168, "phrase": "common_problem"}, {"score": 0.0038210283935447473, "phrase": "nearest_neighbor_parameter"}, {"score": 0.0035648266669315943, "phrase": "optimal_k"}, {"score": 0.003503497128638102, "phrase": "theoretically_difficult_problem"}, {"score": 0.0033257460346754687, "phrase": "new_margin_characterization_method"}, {"score": 0.003287482882222731, "phrase": "sparse_margin-based_discriminant_analysis"}, {"score": 0.0030141556259370675, "phrase": "parameter_selection"}, {"score": 0.0028446460307503343, "phrase": "k-nn_technique"}, {"score": 0.0027795345823932406, "phrase": "test_sample"}, {"score": 0.0026691455928407022, "phrase": "training_samples"}, {"score": 0.002391232019308273, "phrase": "ar"}, {"score": 0.002363532907211947, "phrase": "extended_yale_b_database"}, {"score": 0.002309408211203032, "phrase": "cenparmi_handwritten_numeral_database"}], "paper_keywords": ["Sparse margin", " Dimensional reduction", " Feature extraction"], "paper_abstract": "The existing margin-based discriminant analysis methods such as nonparametric discriminant analysis use K-nearest neighbor (K-NN) technique to characterize the margin. The manifold learning-based methods use K-NN technique to characterize the local structure. These methods encounter a common problem, that is, the nearest neighbor parameter K should be chosen in advance. How to choose an optimal K is a theoretically difficult problem. In this paper, we present a new margin characterization method named sparse margin-based discriminant analysis (SMDA) using the sparse representation. SMDA can successfully avoid the difficulty of parameter selection. Sparse representation can be considered as a generalization of K-NN technique. For a test sample, it can adaptively select the training samples that give the most compact representation. We characterize the margin by sparse representation. The proposed method is evaluated by using AR, Extended Yale B database, and the CENPARMI handwritten numeral database. Experimental results show the effectiveness of the proposed method; its performance is better than some other state-of-the-art feature extraction methods.", "paper_title": "Sparse margin-based discriminant analysis for feature extraction", "paper_id": "WOS:000325809300001"}