Related Papers: 

Doc id:  WOS:000331966900021
Doc Title:  Optimization Decomposition for Scheduling and System Configuration in Wireless Networks
Doc Abstract:  Who gets to use radio spectrum, and when, where, and how? Scheduling (who, where, when) and system configuration (how) are fundamental problems in radio communication and wireless networking. Optimization decomposition based on Lagrangian relaxation of signal quality requirements provides a mathematical framework for solving this type of combined problem. This paper demonstrates the technique as a solution to spatial reuse time-division multiple access (STDMA) scheduling with reconfigurable antennas. The joint beam steering and scheduling (JBSS) problem offers both a challenging mathematical structure and significant practical value. We present algorithms for JBSS and describe an implemented system based on these algorithms. We achieve up to 600% of the throughput of TDMA with a mean of 234% in our experiments. The decomposition approach leads to a working distributed protocol producing optimal solutions in an amount of time that is at worst linear in the size of the input. This is, to the best of our knowledge, the first actually implemented wireless scheduling system based on dual decomposition. We identify and briefly address some of the challenges that arise in taking such a system from theory to reality.

------------------------

Doc id:  WOS:000250580800003
Doc Title:  Finding optimal hardware/software partitions
Doc Abstract:  Most previous approaches to hardware/software partitioning considered heuristic solutions. In contrast, this paper presents an exact algorithm for the problem based on branch-and-bound. Several techniques are investigated to speed up the algorithm, including bounds based on linear programming, a custom inference engine to make the most out of the inferred information, advanced necessary conditions for partial solutions, and different heuristics to obtain high-quality initial solutions. It is demonstrated with empirical measurements that the resulting algorithm can solve highly complex partitioning problems in reasonable time. Moreover, it is about ten times faster than a previous exact algorithm based on integer linear programming. The presented methods can also be useful in other related optimization problems.

------------------------

Doc id:  WOS:000259322900008
Doc Title:  Approximation algorithm based on chain implication for constrained minimum vertex covers in bipartite graphs
Doc Abstract:  The constrained minimum vertex cover problem on bipartite graphs (the Min-CVCB problem) is an important NP-complete problem. This paper presents a polynomial time approximation algorithm for the problem based on the technique of chain implication. For any given constant epsilon > 0, if an instance of the Min-CVCB problem has a minimum vertex cover of size (k(u), k(t)), our algorithm constructs a vertex cover of size (k(u)*, k(t)*), satisfying max {k(u)*/k(u), k(t)*/k(t)} <= 1 + epsilon.

------------------------

Doc id:  WOS:000286472700026
Doc Title:  Vector Addition System Reachability Problem A Short Self-Contained Proof
Doc Abstract:  The reachability problem for Vector Addition Systems (VASs) is a central problem of net theory. The general problem is known decidable by algorithms exclusively based on the classical Kosaraju-Lambert-Mayr-Sacerdote-Tenney decomposition (KLMTS decomposition). Recently from this decomposition, we deduced that a final configuration is not reachable from an initial one if and only if there exists a Presburger inductive invariant that contains the initial configuration but not the final one. Since we can decide if a Preburger formula denotes an inductive invariant, we deduce from this result that there exist checkable certificates of non-reachability in the Presburger arithmetic. In particular, there exists a simple algorithm for deciding the general VAS reachability problem based on two semi-algorithms. A first one that tries to prove the reachability by enumerating finite sequences of actions and a second one that tries to prove the non-reachability by enumerating Presburger formulas. In this paper we provide the first proof of the VAS reachability problem that is not based on the KLMST decomposition. The proof is based on the notion of production relations inspired from Hauschildt that directly provides the existence of Presburger inductive invariants.

------------------------

Doc id:  WOS:000298388200010
Doc Title:  Fast Arc-Annotated Subsequence Matching in Linear Space
Doc Abstract:  An arc-annotated string is a string of characters, called bases, augmented with a set of pairs, called arcs, each connecting two bases. Given arc-annotated strings P and Q the arc-preserving subsequence problem is to determine if P can be obtained from Q by deleting bases from Q. Whenever a base is deleted any arc with an endpoint in that base is also deleted. Arc-annotated strings where the arcs are "nested" are a natural model of RNA molecules that captures both the primary and secondary structure of these. The arc-preserving subsequence problem for nested arc-annotated strings is basic primitive for investigating the function of RNA molecules. Gramm et al. (ACM Trans. Algorithms 2(1): 44-65, 2006) gave an algorithm for this problem using O(nm) time and space, where m and n are the lengths of P and Q, respectively. In this paper we present a new algorithm using O(nm) time and O(n+m) space, thereby matching the previous time bound while significantly reducing the space from a quadratic term to linear. This is essential to process large RNA molecules where the space is likely to be a bottleneck. To obtain our result we introduce several novel ideas which may be of independent interest for related problems on arc-annotated strings.

------------------------

Doc id:  WOS:000356517700008
Doc Title:  Locating Multiple Optimal Solutions of Nonlinear Equation Systems Based on Multiobjective Optimization
Doc Abstract:  Nonlinear equation systems may have multiple optimal solutions. The main task of solving nonlinear equation systems is to simultaneously locate these optimal solutions in a single run. When solving nonlinear equation systems by evolutionary algorithms, usually a nonlinear equation system should be transformed into a kind of optimization problem. At present, various transformation techniques have been proposed. This paper presents a simple and generic transformation technique based on multiobjective optimization for nonlinear equation systems. Unlike the previous work, our transformation technique transforms a nonlinear equation system into a biobjective optimization problem that can be decomposed into two parts. The advantages of our transformation technique are twofold: 1) all the optimal solutions of a nonlinear equation system are the Pareto optimal solutions of the transformed problem, which are mapped into diverse points in the objective space, and 2) multiobjective evolutionary algorithms can be directly applied to handle the transformed problem. In order to verify the effectiveness of our transformation technique, it has been integrated with non-dominated sorting genetic algorithm II to solve nonlinear equation systems. The experimental results have demonstrated that, overall, our transformation technique outperforms another state-of-the-art multiobjective optimization based transformation technique and four single-objective optimization based approaches on a set of test instances. The influence of the types of Pareto front on the performance of our transformation technique has been investigated empirically. Moreover, the limitation of our transformation technique has also been identified and discussed in this paper.

------------------------

Doc id:  WOS:000241446400022
Doc Title:  A multi-level memetic/exact hybrid algorithm for the still life problem
Doc Abstract:  Bucket elimination (BE) is an exact technique based on variable elimination. It has been recently used with encouraging results as a mechanism for recombining solutions in a memetic algorithm (MA) for the still life problem, a hard constraint optimization problem based on Conway's game of life. This paper studies expanded multi-level models in which this exact/metaheuristic hybrid is further hybridized with branch-and-bound techniques. A novel variable clustering based recombination operator is also explored, with the aim of reducing the inherent time complexity of BE. Multi-parent recombination issues are analyzed as well. The obtained results are of higher quality than any previous metaheuristic approach, with large instances being solved to optimality.

------------------------

Doc id:  WOS:000248670900013
Doc Title:  Solution of large quadratic knapsack problems through aggressive reduction
Doc Abstract:  The quadratic knapsack problem (QKP) calls for maximizing a quadratic objective function subject to a knapsack constraint. All coefficients are assumed to be nonnegative and all decision variables are binary. A new exact algorithm is presented, which makes use of aggressive reduction techniques to decrease the size of the instance to a manageable size. A cascade of upper bounds is used for the reduction, including an improved version of the Caprara-Pisinger-Toth bound based on upper planes and reformulation, and the Billionnet-Faye-Soutif bound based on Lagrangian decomposition. Generalized reduction techniques based on implicit enumeration are used to fix variables at their optimal values. In order to obtain lower bounds of high quality for the reduction, a core problem is solved, defined on a subset of variables. The core is chosen by merging numerous heuristic solutions found during the subgradient-optimization phase. The upper and lower bounding phases are repeated several times, each time improving the subgradient method used for finding the Lagrangian multipliers associated with the upper bounds. Having reduced the instance to a (hopefully) reasonable size, a branch and bound algorithm based on the Caprara-Pisinger-Toth framework is applied. Computational experiments are presented showing that several instances with up to 1,500 binary variables can be reduced to fewer than 100 variables. The remaining set of variables are easily handled through the exact branch and bound algorithm. In comparison to previous algorithms the framework does not only solve larger instances, but the algorithm also works well for instances with smaller densities of the profit matrix, which appear frequently when modeling various graph problems as quadratic knapsack problems.

------------------------

Doc id:  WOS:000325021400001
Doc Title:  Underestimating the cost of a soft constraint is dangerous: revisiting the edit-distance based soft regular constraint
Doc Abstract:  Many real-life problems are over-constrained, so that no solution satisfying all their constraints exists. Soft constraints, with costs denoting how much the constraints are violated, are used to solve these problems. We use the edit-distance based SoftRegular constraint as an example to show that a propagation algorithm that sometimes underestimates the cost may guide the search to incorrect (non-optimal) solutions to an over-constrained problem. To compute correctly the cost for the edit-distance based SoftRegular constraint, we present a quadratic-time propagation algorithm based on dynamic programming and a proof of its correctness. We also give an improved propagation algorithm using an idea of computing the edit distance between two strings, which may also be applied to other constraints with propagators based on dynamic programming. The asymptotic time complexity of our improved propagator is always at least as good as the one of our quadratic-time propagator, but significantly better when the edit distance is small. Our propagators achieve domain consistency on the problem variables and bounds consistency on the cost variable. Our method can also be adapted for the violation measure of the edit-distance based Regular constraint for constraint-based local search.

------------------------

Doc id:  WOS:000308370100005
Doc Title:  Deductive Inference for the Interiors and Exteriors of Horn Theories
Doc Abstract:  In this article, we investigate deductive inference for interiors and exteriors of Horn knowledge bases, where interiors and exteriors were introduced by Makino and Ibaraki [1996] to study stability properties of knowledge bases. We present a linear time algorithm for deduction for interiors and show that deduction is coNP-complete for exteriors. Under model-based representation, we show that the deduction problem for interiors is NP-complete while the one for exteriors is coNP-complete. As for Horn envelopes of exteriors, we show that it is linearly solvable under model-based representation, while it is coNP-complete under formula-based representation. We also discuss polynomially solvable cases for all the intractable problems.

------------------------

Doc id:  WOS:000276685300008
Doc Title:  Constrained Relay Node Placement in Wireless Sensor Networks: Formulation and Approximations
Doc Abstract:  One approach to prolong the lifetime of a wireless sensor network (WSN) is to deploy some relay nodes to communicate with the sensor nodes, other relay nodes, and the base stations. The relay node placement problem for wireless sensor networks is concerned with placing a minimum number of relay nodes into a wireless sensor network to meet certain connectivity or survivability requirements. Previous studies have concentrated on the unconstrained version of the problem in the sense that relay nodes can be placed anywhere. In practice, there may be some physical constraints on the placement of relay nodes. To address this issue, we study constrained versions of the relay node placement problem, where relay nodes can only be placed at a set of candidate locations. In the connected relay node placement problem, we want to place a minimum number of relay nodes to ensure that each sensor node is connected with a base station through a bidirectional path. In the survivable relay node placement problem, we want to place a minimum number of relay nodes to ensure that each sensor node is connected with two base stations (or the only base station in case there is only one base station) through two node-disjoint bidirectional paths. For each of the two problems, we discuss its computational complexity and present a framework of polynomial time O(1)-approximation algorithms with small approximation ratios. Extensive numerical results show that our approximation algorithms can produce solutions very close to optimal solutions.

------------------------

Doc id:  WOS:000334922500008
Doc Title:  A Memetic Algorithm for Resource Allocation Problem Based on Node-Weighted Graphs
Doc Abstract:  

------------------------

Doc id:  WOS:000348425100001
Doc Title:  A novel crossover operator based on variable importance for evolutionary multi-objective optimization with tree representation
Doc Abstract:  Selecting reliable predictors has always been crucial in classification. Especially decision trees are very popular for solving supervised variable selection and classification problems. When variable selection has to be performed with regard to acquisition costs, which have to be paid whenever the respective variable is extracted for a new observation, the problem of balancing the predictive power of the model against its costs describes a multi-objective optimization problem which can be solved with meta-heuristics such as evolutionary multi-objective algorithms. In this paper, we present a non-hierarchical evolutionary multi-objective tree learner (NHEMOtree) based on genetic programming using a binary decision tree representation to handle multi-objective optimization problems with equitable optimization criteria. This tree learner is applied to a multi-objective classification problem from medicine as well as to simulated data to evaluate its performance relative to two wrapper approaches based on either NSGA-II or SMS-EMOA with bitstring representation and CART as the enclosed classification algorithm. Moreover, a novel crossover operator based on a multi-objective variable importance measure is introduced. Using this crossover operator, NHEMOtree can be improved.

------------------------

Doc id:  WOS:000287066400013
Doc Title:  Real-time particle swarm optimization based current harmonic cancellation
Doc Abstract:  As a powerful optimization algorithm, particle swarm optimization (PSO) has been widely applied to power system researches. However, most existing applications of PSO can only be implemented offline. The difficulties of online implementation mainly come from the unavoidable lengthy simulation time to evaluate a candidate solution. Recently, PSO was implemented online that can identify parameters in a motor control systems. In this paper, the real-time PSO (RT-PSO) based identification technique is applied to cancel current harmonics in power systems. By transforming the identification problem to optimization problem. RT-PSO can simultaneously identify four parameters associated with fundamental current from measurement. In this way, there is no need to identify the fundamental frequency separately or construct fundamental signal from identified harmonic information. The identification algorithm can be applied to three-phases independently, even for unbalanced system or single-phase system. The identified fundamental signal is then used as the reference for current harmonics cancellation. The RT-PSO based harmonic cancellation is realized with an active filter and used to compensate harmonic current created by a nonlinear load. Simulation results demonstrate that the RT-PSO algorithm can provide accurate identification of the fundamental current which in turn will result in good harmonic cancellation performance. As a capable online optimization technique, RT-PSO can be extensively applied to many optimization and control problems. Published by Elsevier Ltd.

------------------------

Doc id:  WOS:000309353500005
Doc Title:  Hybrid solving algorithms for an extended dynamic constraint satisfaction problem based configuration system
Doc Abstract:  In modern manufacturing, constraint satisfaction problem based product configuration systems have been recognized as an effective and promising approach to represent and solve product family design tasks. In this article, based on an extended dynamic constraint satisfaction problem based product configuration system, a hybrid constraint satisfaction problem solving algorithm with forward checking and backjumping with fail-first heuristic is proposed. To control backtracking occurrence in this hybrid solving algorithm when new active variables are introduced into dynamic constraint satisfaction problem, a hybrid heuristic (a combination of an amended most-constrained heuristic and fail-first heuristic) is integrated with forward checking and backjumping for better solution efficiency. Experiments on both algorithms have been performed on a dynamic constraint satisfaction problem based PC configuration task.

------------------------

Doc id:  WOS:000284636400016
Doc Title:  Distributed full-order optimal fusion filters and smoothers for discrete-time stochastic singular systems
Doc Abstract:  The optimal fusion problem for the state estimation of discrete-time stochastic singular systems is considered. The key idea is to convert a stochastic singular system with multiple sensors and correlated noises into an equivalent group of non-singular systems. Based on the state estimation for each local non-singular system, the optimal full-order filters and smoothers with a three-layer fusion structure are obtained for the original system using the optimal weighted fusion algorithms in the linear minimum variance sense. A simulation example shows that the fusion estimator is better than each local one.

------------------------

Doc id:  WOS:000334480500006
Doc Title:  Autonomous UAV based search operations using Constrained Sampling Evolutionary Algorithms
Doc Abstract:  This paper introduces and studies the application of Constrained Sampling Evolutionary Algorithms in the framework of an UAV based search and rescue scenario. These algorithms have been developed as a way to harness the power of Evolutionary Algorithms (EA) when operating in complex, noisy, multimodal optimization problems and transfer the advantages of their approach to real time real world problems that can be transformed into search and optimization challenges. These types of problems are denoted as Constrained Sampling problems and are characterized by the fact that the physical limitations of reality do not allow for an instantaneous determination of the fitness of the points present in the population that must be evolved. A general approach to address these problems is presented and a particular implementation using Differential Evolution as an example of CS-EA is created and evaluated using teams of UAVs in search and rescue missions. The results are compared to those of a Swarm Intelligence based strategy in the same type of problem as this approach has been widely used within the UAV path planning field in different variants by many authors. (C) 2013 Elsevier B.V. All rights reserved.

------------------------

Doc id:  WOS:000336524000004
Doc Title:  Maximum spanning tree based linkage learner
Doc Abstract:  Linkage learning in evolutionary algorithms is identifying the structure of the dependencies between variables of a problem in order to find the optimum solution of the problem. It is a necessary process for optimizing the hard problems that can not be optimized randomly via common recombination operators of simple genetic algorithm. This paper presents a simple yet effective linkage learner that works based on graph theory. A graph is used as the structure to keep the pairwise dependencies between variables of the problem. We call this graph 'the underlying dependency graph of the problem' (UDGP). Maximum spanning tree (MST) of the UDGP is then found. It is shown that MST contains all the necessary linkages if the dependency graph is built upon sufficient population. In this approach, pairwise dependencies that are mutual information between each pair of variables, are used to find linkage information. The proposed approach has the advantage of being capable of learning the linkage without the need for the costly fit-to-data evaluations of model search. It is parameter free and the algorithm description is straight forward. The proposed technique is tested on several benchmark problems and it is shown to be able to compete with similar approaches. Based on the experimental results it can successfully find the linkage groups in a polynomial number of fitness evaluations.

------------------------

Doc id:  WOS:000311406800005
Doc Title:  Consistency and repair for XML write-access control policies
Doc Abstract:  XML access control policies involving updates may contain security flaws, here called inconsistencies, in which a forbidden operation may be simulated by performing a sequence of allowed operations. This article investigates the problem of deciding whether a policy is consistent, and if not, how its inconsistencies can be repaired. We consider total and partial policies expressed in terms of annotated schemas defining which operations are allowed or denied for the XML trees that are instances of the schema. We show that consistency is decidable in PTIME for such policies and that consistent partial policies can be extended to unique least-privilege consistent total policies. We also consider repair problems based on deleting privileges to restore consistency, show that finding minimal repairs is NP-complete, and give heuristics for finding repairs. Finally, we experimentally evaluate these algorithms in comparison with an exact approach based on answer-set programming.

------------------------

