Related papers

Paper Id: WOS:000342256200008
Distance: 0.18843194842338562
Similarity: 0.8115680515766144
Title: Exudate detection in color retinal images for mass screening of diabetic retinopathy
Abstract: The automatic detection of exudates in color eye fundus images is an important task in applications such as diabetic retinopathy screening. The presented work has been undertaken in the framework of the Tele-Ophta project, whose main objective is to automatically detect normal exams in a tele-ophthalmology network, thus reducing the burden on the readers. A new clinical database, e-ophtha EX, containing precisely manually contoured exudates, is introduced. As opposed to previously available databases, e-ophtha EX is very heterogeneous. It contains images gathered within the OPHDIAT telemedicine network for diabetic retinopathy screening. Image definition, quality, as well as patients condition or the retinograph used for the acquisition, for example, are subject to important changes between different examinations. The proposed exudate detection method has been designed for this complex situation. We propose new preprocessing methods, which perform not only normalization and denoising tasks, but also detect reflections and artifacts in the image. A new candidates segmentation method, based on mathematical morphology, is proposed. These candidates are characterized using classical features, but also novel contextual features. Finally, a random forest algorithm is used to detect the exudates among the candidates. The method has been validated on the e-ophtha EX database, obtaining an AUC of 0.95. It has been also validated on other databases, obtaining an AUC between 0.93 and 0.95, outperforming state-of-the-art methods. (C) 2014 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000332194600009
Distance: 0.18877525627613068
Similarity: 0.8112247437238693
Title: Evaluation of prostate segmentation algorithms for MRI: The PROMISE12 challenge
Abstract: Prostate MRI image segmentation has been an area of intense research due to the increased use of MRI as a modality for the clinical workup of prostate cancer. Segmentation is useful for various tasks, e.g. to accurately localize prostate boundaries for radiotherapy or to initialize multi-modal registration algorithms. In the past, it has been difficult for research groups to evaluate prostate segmentation algorithms on multi-center, multi-vendor and multi-protocol data. Especially because we are dealing with MR images, image appearance, resolution and the presence of artifacts are affected by differences in scanners and/or protocols, which in turn can have a large influence on algorithm accuracy. The Prostate MR Image Segmentation (PROMISE12) challenge was setup to allow a fair and meaningful comparison of segmentation methods on the basis of performance and robustness. In this work we will discuss the initial results of the online PROMISE12 challenge, and the results obtained in the live challenge workshop hosted by the MICCAI2012 conference. In the challenge, 100 prostate MR cases from 4 different centers were included, with differences in scanner manufacturer, field strength and protocol. A total of 11 teams from academic research groups and industry participated. Algorithms showed a wide variety in methods and implementation, including active appearance models, atlas registration and level sets. Evaluation was performed using boundary and volume based metrics which were combined into a single score relating the metrics to human expert performance. The winners of the challenge where the algorithms by teams Imorphics and ScrAutoProstate, with scores of 85.72 and 84.29 overall. Both algorithms where significantly better than all other algorithms in the challenge (p < 0.05) and had an efficient implementation with a run time of 8 min and 3 s per case respectively. Overall, active appearance model based approaches seemed to outperform other approaches like multi-atlas registration, both on accuracy and computation time. Although average algorithm performance was good to excellent and the Imorphics algorithm outperformed the second observer on average, we showed that algorithm combination might lead to further improvement, indicating that optimal performance for prostate segmentation is not yet obtained. All results are available online at http://promise12.grand-challenge.org/. (C) 2013 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000264182800058
Distance: 0.1913587898015976
Similarity: 0.8086412101984024
Title: Object-oriented change detection for the city of Harare, Zimbabwe
Abstract: Object building and the extraction of homogeneous landscape units on which spatial statistics can be applied is useful in assessing land use and land cover change. Object-oriented processing techniques are becoming more popular compared to traditional pixel-based image analysis. A hierarchical image segmentation approach was adopted to extract the objects from multi-temporal Landsat images over Zimbabwe. The spatial arrangement of t(0) and t(1) objects was independent as the segmentation process was independently applied, although object change of t(1) was based on t(0) boundaries. We applied a Standardized, Object Oriented, Automatic Classification (SOOAC) method based on fuzzy logic. The error matrix for the TM image had an overall accuracy of 95.6% and a KIA value of 94.7%, the ETM showed slightly lower overall accuracy. Various LULC changes were identified over the 13 year period per object and also per class, mainly vegetation decrease. Object-oriented change information is necessary in decision support systems and uncertainty management strategies. This approach addresses some of the major issues in object-based GIS change analysis as it is based on stable object geometry. (C) 2007 Published by Elsevier Ltd.

------------

Paper Id: WOS:000272432300076
Distance: 0.195231631398201
Similarity: 0.804768368601799
Title: Fusion of systems for automated cell phenotype image classification
Abstract: Automated cell phenotype image classification is related to the problem of determining locations of protein expression within living cells. Localization of proteins in cells is directly related to their functions and it is crucial for several applications ranging from early diagnosis of a disease to monitoring of therapeutic effectiveness of drugs. Recent advances in imaging instruments and biological reagents have allowed fluorescence microscopy to be extensively used as a too[ to understand biology at the cellular level by means of the visualization of biological activity within cells. However, human classification of fluorescence cell micrographs is still subjective and very time consuming, thus an automated approach for the systematic determination of protein subcellular locations from fluorescence microscopy images is required. Existing approaches concentrated on designing a set of optimal features and then applying standard machine-learning algorithms. This paper takes into consideration the best methods proposed in the literature and Focuses on the study of ensemble machine learning techniques for cell phenotype image classification. Two techniques are tested for the classification: a random subspace of Levenberg-Marquardt neural networks and a variant of the AdaBoost. Each of these two methods are tested with different feature sets, moreover the fusion between the two ensembles is studied. The best ensemble tested in this work obtains an outstanding 97.5% accuracy in the 2D-Hela dataset, which to the best of our knowledge is the best performance obtained on this dataset (the most used benchmark for comparing automated cell phenotype image classification approaches). (C) 2009 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000250284100002
Distance: 0.19692553579807281
Similarity: 0.8030744642019272
Title: Image analytical determination of particle size distribution characteristics of natural and industrial bulk aggregates
Abstract: Image Analysis combined with multivariate regression on Angle Measure Technique (AMT) transformed imagery and the Theory of Sampling (TOS) is here presented as a comprehensive for Image Analysis Sampling (IAS), which takes all aspects of sampling representativity into account especially 2-dimensional image versus 3-dimensioanl bulk compositions issues. Every IAS application has to be based on optimized image acquisition parameters: camera and illumination type, illumination angle, sample thickness as well as image post-processing, which are all examined here in order to delineate the general requirements for optimal prediction models for particle size distribution of natural and industrial bulk solid aggregates. We present a complete optimization study in order to show its intrinsic problem-dependentnature. This optimization allowed an original 60-sample data set to be compressed to an essential 22 natural coastal sands array with equally varying composition ranges - which was subjected to IAS in order to characterize the specific particle size distribution curves. In addition to D-50 (50%-tile), six other size classes were successfully predicted, while extreme size classes (extreme low or high particle sizes) showed a too narrow training data set span, illustrating a critical grain size contrast which will always bracket successful models of particulate matter being imaged for grain size characterization. All classes with a satisfactory (representative) calibration interval span can be quantitatively predicted due to the powerful scale-dependency of the central AMT feature extraction combined with PLS multivariate calibration. The present application to natural sand aggregate size distributions forms a vehicle to illustrate the full potential of image analysis in general, IAS in particular, also for technological/industrial manufacturing on-line product and process monitoring applications, or quality control purposes, with similar grain-size prediction objectives. There is a significant carrying-over potential to parallel industrial scenarios. (c) 2007 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000270628900012
Distance: 0.19722720980644226
Similarity: 0.8027727901935577
Title: Visual computing for medical diagnosis and treatment
Abstract: Diagnostic algorithms and efficient visualization techniques are of major importance for preoperative decisions, intra-operative imaging and image-guided surgery. Complex diagnostic decisions are characterized by a high information flow and fast decisions, requiring efficient and intuitive presentation of complex medical data and precision in the visualization. For intra-operative medical treatment, the pre-operative visualization results of the diagnostic systems have to be transferred to the patient on the operation room table. Via augmented reality, additional information of the hidden regions can be displayed virtually. This state-of-the-art report summarizes visual computing algorithms for medical diagnosis and treatment. After starting with direct volume rendering and tagged volume rendering as general techniques for visualizing anatomical structures, we go into more detail by focusing on the visualization of tissue and vessel structures. Afterwards, algorithms and techniques that are used for medical treatment in the context of image-guided surgery, intra-operative imaging and augmented reality are discussed and reviewed. (C) 2009 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000309378200006
Distance: 0.20025837421417236
Similarity: 0.7997416257858276
Title: genEnsemble: A new model for the combination of classifiers and integration of biological knowledge applied to genomic data
Abstract: In the last years, microarray technology has become widely used in relevant biomedical areas such as drug target identification, pharmacogenomics or clinical research. However, the necessary prerequisites for the development of valuable translational microarray-based diagnostic tools are (i) a solid understanding of the relative strengths and weaknesses of underlying classification methods and (ii) a biologically plausible and understandable behaviour of such models from a biological point of view. In this paper we propose a novel classifier able to combine the advantages of ensemble approaches with the benefits obtained from the true integration of biological knowledge in the classification process of different microarray samples. The aim of the current work is to guarantee the robustness of the proposed classification model when applied to several microarray data in an inter-dataset scenario. The comparative experimental results demonstrated that our proposal working with biological knowledge outperforms other well-known simple classifiers and ensemble alternatives in binary and multiclass cancer prediction problems using publicly available data. (C) 2012 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000302434300015
Distance: 0.2009245604276657
Similarity: 0.7990754395723343
Title: Cranial Vault and its CRAVE tools: A clinical computer assistance system for deep brain stimulation (DBS) therapy
Abstract: A number of methods have been developed to assist surgeons at various stages of deep brain stimulation (DBS) therapy. These include construction of anatomical atlases, functional databases, and electrophysiological atlases and maps. But, a complete system that can be integrated into the clinical workflow has not been developed. In this paper we present a system designed to assist physicians in pre-operative target planning, intra-operative target refinement and implantation, and post-operative DBS lead programming. The purpose of this system is to centralize the data acquired a the various stages of the procedure, reduce the amount of time needed at each stage of the therapy, and maximize the efficiency of the entire process. The system consists of a central repository (CranialVault), of a suite of software modules called CRAnialVault Explorer (CRAVE) that permit data entry and data visualization at each stage of the therapy, and of a series of algorithms that permit the automatic processing of the data. The central repository contains image data for more than 400 patients with the related pre-operative plans and position of the final implants and about 10,550 electrophysiological data points (micro-electrode recordings or responses to stimulations) recorded from 222 of these patients. The system has reached the stage of a clinical prototype that is being evaluated clinically at our institution. A preliminary quantitative validation of the planning component of the system performed on 80 patients who underwent the procedure between January 2009 and December 2009 shows that the system provides both timely and valuable information. (C) 2010 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000327919700024
Distance: 0.20149795711040497
Similarity: 0.798502042889595
Title: Machine vision to identify broiler breeder behavior
Abstract: Animal behavioral parameters can be used to assess welfare status in commercial broiler breeders. Behavioral parameters can be monitored with a variety of sensing devices, for instance, the use of video cameras allows comprehensive assessment of animal behavioral expressions. Nevertheless, the development of efficient methods and algorithms to continuously identify and differentiate animal behavior patterns is needed. The objective this study was to provide a methodology to identify hen white broiler breeder behavior using combined techniques of image processing and computer vision. These techniques were applied to differentiate body shapes from a sequence of frames as the birds expressed their behaviors. The method was comprised of four stages: (1) identification of body positions and their relationship with typical behaviors. For this stage, the number of frames required to identify each behavior was determined; (2) collection of image samples, with the isolation of the birds that expressed a behavior of interest; (3) image processing and analysis using a filter developed to separate white birds from the dark background; and finally (4) construction and validation of a behavioral classification tree, using the software tool Weka (model 148). The constructed tree was structured in 8 levels and 27 leaves, and it was validated using two modes: the "set training" mode with an overall rate of success of 96.7%, and the "cross validation" mode with an overall rate of success of 70.3%. The results presented here confirmed the feasibility of the method developed to identify white broiler breeder behavior for a particular group of study. Nevertheless, more improvements in the method can be made in order to increase the validation overall rate of success. (C) 2013 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000268430700004
Distance: 0.2019018828868866
Similarity: 0.7980981171131134
Title: PCHM: A bioinformatic resource for high-throughput human mitochondrial proteome searching and comparison
Abstract: Mitochondrial proteins associated with a wide spectrum of human diseases and currently large amounts of tissue or organ specific human mitochondrial proteome datasets are generated. However, high-throughput comparative proteomic methods have yet to be applied to extract subtle differences among mitochondria from different tissues or muscle types. The aim of this work was to provide an integrated way to identify and compare huge mitochondrial protein or peptide mass spectral data sets acquired from expert mitochondrial proteome or biomarker discovery community. Proteome comparison of human mitochondria (PCHM) is a web-based analysis environment for manual or automatic analysis of individual peptide mass fingerprints alongside a database of proteins and peptides identified in various organs for human mitochondrial proteins. PCHM provides a suite of graphical tools that allow the virtual plot of peptide mass fingerprinting (PMF) spectra and a fully automatic protein function classification based on gene ontology (GO) annotation system. The new virtual PMF plot is very useful to validate fragmented ion loses of any identical proteins and to remove unwanted foreign ion peaks. Fully automatic protein function classifier provides an easier way to compare the subtle differences of compositionally biased mitochondrial protein functions. PCHM also provides a variety of query algorithms aid in browsing, searching, and accessing complete annotations of data relevant to each mitochondrial protein of interest, which link external databases and users. PCHM will be a useful tool for the systematic and functional characterization of the mitochondrial proteins in relation to human diseases or biological research applications. PCHM can be accessed freely via a web interface http://pchm.inje.ac.kr. (C) 2009 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000294081200007
Distance: 0.20197248458862305
Similarity: 0.798027515411377
Title: Enterprise architecture patterns for business process support analysis
Abstract: The field of enterprise architectures lacks architecture patterns that would support analysis of a given enterprise architecture, comparison of different enterprise architecture solutions and provide guidelines for development of a target enterprise architecture based on the analysis of existing enterprise architecture. In this paper, we focus on business process support analysis using information derived from enterprise architecture description. We give a systematic overview of important aspects. We establish and formally define foundational enterprise architecture patterns for business process support analysis. They are implementation independent and enable more efficient qualitative architecture analysis of business process support, which is the basis for achieving more optimal business operation. We have defined the patterns using the standard enterprise architecture language - ArchiMate. They are formalized in a way that enables their implementation in enterprise architecture tools. This is an important characteristic that allows for efficient work by automatic detection of different, more or less suitable, architecture structures. We have derived the patterns based on real-world enterprise architecture descriptions and have used and verified them in enterprise architecture analysis and planning projects for four large organizations. The enterprise architecture analysis patterns address an important research issue in the field of enterprise architectures that has so far not been systematically researched. (C) 2011 Elsevier Inc. All rights reserved.

------------

Paper Id: WOS:000270122600008
Distance: 0.20212693512439728
Similarity: 0.7978730648756027
Title: VDM-RS: A visual data mining system for exploring and classifying remotely sensed images
Abstract: Remotely sensed imagery has become increasingly important in several applications domains, such as environmental monitoring, change detection, fire risk mapping and land use, to name only a few. Several advanced image classification techniques have been developed to analyze such imagery and in particular to improve the accuracy of classifying images in the context of such applications. However, most of the proposed classifiers remain a black box to users, leaving them with little to no means to explore and thus further improve the classification process, in particular for misclassified pixel samples. In this paper, we present the concepts, design and implementation of VDM-RS, a visual data mining system for classifying remotely sensed images and exploring image classification processes. The system provides users with two classes of components. First, visual components are offered that are specific to classifying remotely sensed images and provide traditional interfaces, such as a map view and an error matrix view. Second, the decision tree classifier view provides users with the functionality to trace and explore the classification process of individual pixel samples. This feature allows users to inspect how a sample has been correctly classified using the classifier, but more importantly, it also allows for a detailed exploration of the steps in which a sample has been misclassified. The integration of these features into a coherent, user-friendly system not only helps users in getting more insights into the data, but also to better understand and subsequently improve a classifier for remotely sensed images. We demonstrate the functionality of the system's components and their interaction for classifying imagery using a hyperspectral image dataset. (c) 2009 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000363826900007
Distance: 0.20264337956905365
Similarity: 0.7973566204309464
Title: Boosting drug named entity recognition using an aggregate classifier
Abstract: Objective: Drug named entity recognition (NER) is a critical step for complex biomedical NLP tasks such as the extraction of pharmacogenomic, pharmacodynamic and pharmacokinetic parameters. Large quantities of high quality training data are almost always a prerequisite for employing supervised machine-learning techniques to achieve high classification performance. However, the human labour needed to produce and maintain such resources is a significant limitation. In this study, we improve the performance of drug NER without relying exclusively on manual annotations. Methods: We perform drug NER using either a small gold-standard corpus (120 abstracts) or no corpus at all. In our approach, we develop a voting system to combine a number of heterogeneous models, based on dictionary knowledge, gold-standard corpora and silver annotations, to enhance performance. To improve recall, we employed genetic programming to evolve 11 regular-expression patterns that capture common drug suffixes and used them as an extra means for recognition. Materials: Our approach uses a dictionary of drug names, i.e. DrugBank, a small manually annotated corpus, i.e. the pharmacokinetic corpus, and a part of the UKPMC database, as raw biomedical text. Gold-standard and silver annotated data are used to train maximum entropy and multinomial logistic regression classifiers. Results: Aggregating drug NER methods, based on gold-standard annotations, dictionary knowledge and patterns, improved the performance on models trained on gold-standard annotations, only, achieving a maximum F-score of 95%. In addition, combining models trained on silver annotations, dictionary knowledge and patterns are shown to achieve comparable performance to models trained exclusively on gold-standard data. The main reason appears to be the morphological similarities shared among drug names. Conclusion: We conclude that gold-standard data are not a hard requirement for drug NER. Combining heterogeneous models build on dictionary knowledge can achieve similar or comparable classification performance with that of the best performing model trained on gold-standard annotations. (C) 2015 The Authors. Published by Elsevier B.V.

------------

Paper Id: WOS:000285947000004
Distance: 0.2036406695842743
Similarity: 0.7963593304157257
Title: Performance evaluation of a region growing procedure for mammographic breast lesion identification
Abstract: At present, mammography is the most effective examination for an early diagnosis of breast cancer. Nevertheless, the detection of cancer signs in mammograms is a difficult procedure owing to the great number of non-pathological structures which are also present in the image. Recent statistics show that in current breast cancer screenings 10%-25% of the tumors are missed by the radiologists. For this reason, a lot of research is currently being done to develop systems for Computer Aided Detection (CADe). Probably, some causes of the false-negative screening examinations are that tumoral masses have varying dimension and irregular shape, their borders are often ill-defined and their contrast is very low, thus making difficult the discrimination from parenchymal structures. Therefore, in a CADe system a preliminary segmentation procedure has to be implemented in order to separate the mass from the background tissue. In this way, various characteristics of the segmented mass can be evaluated and used in a classification step to discriminate benign and malignant cases. In this paper, we describe an effective algorithm for massive lesions segmentation based on a region-growing technique and we provide full details the performance evaluation procedure used in this specific context. (C) 2010 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000328590700006
Distance: 0.2038155198097229
Similarity: 0.7961844801902771
Title: Computer generated images vs. digital photographs: A synergetic feature and classifier combination approach
Abstract: The development of powerful and low-cost hardware devices allied with great advances on content editing and authoring tools have promoted the creation of computer generated images (CG) to a degree of unrivaled realism. Differentiating a photo-realistic computer generated image from a real photograph (PG) can be a difficult task to naked eyes. Digital forensics techniques can play a significant role in this task. As a matter of fact, important research has been made by the scientific community in this regard. Most of the approaches focus on single image features aiming at detecting differences between real and computer generated images. However, with the current technology advances, there is no universal image characterization technique that completely solves this problem. In our work, we (1) present a complete study of several CG versus PG approaches; (2) create a large and heterogeneous dataset to be used as a training and validation database; (3) implement representative methods of the literature; and (4) devise automatic ways for combining the best approaches. We compared the implemented methods using the same validation environment showing their pros and cons with a common benchmark protocol. We collected approximately 4850 photographs and 4850 CGs with large diversity of image content and quality. We implemented a total of 13 methods. Results show that this set of methods can achieve up to 93% of accuracy when used without any form of machine learning fusion. The same methods, when combined through the implemented fusion schemes, can achieve an accuracy rate of 97%, representing a reduction of 57% of the classification error over the best individual result. (C) 2013 Elsevier Inc. All rights reserved.

------------

Paper Id: WOS:000281368200006
Distance: 0.20383411645889282
Similarity: 0.7961658835411072
Title: Detecting bird sounds in a complex acoustic environment and application to bioacoustic monitoring
Abstract: Trends in bird population sizes are an important indicator in nature conservation but measuring such sizes is a very difficult, labour intensive process. Enormous progress in audio signal processing and pattern recognition in recent years makes it possible to incorporate automated methods into the detection of bird vocalisations. These methods can be employed to support the census of population sizes. We report about a study testing the feasibility of bird monitoring supported by automatic bird song detection. In particular, we describe novel algorithms for the detection of the vocalisations of two endangered bird species and show how these can be used in automatic habitat mapping. These methods are based on detecting temporal patterns in a given frequency band typical for the species. Special effort is put into the suppression of the noise present in real-world audio scenes. Our results show that even in real-world recording conditions high recognition rates with a tolerable rate of false positive detections are possible. (C) 2009 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000339534500002
Distance: 0.20384952425956726
Similarity: 0.7961504757404327
Title: Recognition of candidate aptamer sequences for human hepatocellular carcinoma in SELEX screening using structure-activity relationships
Abstract: Selecting and synthesizing aptamers for human hepatic carcinoma (HCC) cells with high affinity and specificity would be of critical importance for diagnosing liver cancer early. This paper is the first report on pattern recognition used for SELEX-based aptamer screening by applying a support vector classification (SVC) technique for a two-class problem. The candidate aptamer sequences that show different degrees of affinity and specificity for SMMC-7721 liver carcinoma cells were selected through whole cell-SELEX. After calculating 1670 molecular descriptors, 13 descriptors were selected, which were compressed to 6 latent variables used as the inputs for classification models. The predicted fractions of winner aptamers from the SELEX selection of the 3rd, 5th, 7th, 9th, 11th, and 13th rounds are 0.033, 0.427, 0.678, 0.828, 0.912 and 0.983, respectively, which conform to the aptamer evolutionary principles of SELEX based screening. By the pattern recognition analysis based on a structure-activity relationship (SAR) model, 6 DNA candidate aptamer sequences belonging to the class of sequences with high affinity and specificity have experimental dissociation constants K-d in the nanomolar range. The feasibility of applying pattern recognition for the design and selection of aptamers has been demonstrated. (C) 2014 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000327578400018
Distance: 0.20388594269752502
Similarity: 0.796114057302475
Title: IVUSAngio Tool: A publicly available software for fast and accurate 3D reconstruction of coronary arteries
Abstract: There is an ongoing research and clinical interest in the development of reliable and easily accessible software for the 3D reconstruction of coronary arteries. In this work, we present the architecture and validation of IVUSAngio Tool, an application which performs fast and accurate 3D reconstruction of the coronary arteries by using intravascular ultrasound (IVUS) and biplane angiography data. The 3D reconstruction is based on the fusion of the detected arterial boundaries in IVUS images with the 3D IVUS catheter path derived from the biplane angiography. The IVUSAngio Tool suite integrates all the intermediate processing and computational steps and provides a user-friendly interface. It also offers additional functionality, such as automatic selection of the end-diastolic IVUS images, semi-automatic and automatic IVUS segmentation, vascular morphometric measurements, graphical visualization of the 3D model and export in a format compatible with other computer-aided design applications. Our software was applied and validated in 31 human coronary arteries yielding quite promising results. Collectively, the use of IVUSAngio Tool significantly reduces the total processing time for 3D coronary reconstruction. IVUSAngio Tool is distributed as free software, publicly available to download and use. (C) 2013 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000353746900026
Distance: 0.20474445819854736
Similarity: 0.7952555418014526
Title: Image based computer aided diagnosis system for cancer detection
Abstract: Cancer is one of the major causes of non-accidental death in human. Early diagnosis of the disease allows clinician to administer suitable treatment, and can improve the patient's survival rate. Traditional diagnosis involves trained clinicians to visually examine the respective medical images for any signs of nodule development in the body. However due to the large scale of the medical image data, this manual diagnosis is often laborious and can be highly subjective due to inter-observer variability. Inspired by the advanced computing technology which is capable of performing complex image processing and machine learning, researches had been carried out in the past few decades to develop computer aided diagnosis (CAD) systems to assist clinicians detecting different forms of cancer. This paper reviews computer vision techniques adopted in medical image analysis, in particular, for cancer detection. The review focused on the detection of the most common form of cancer types, namely breast cancer, prostate cancer, lung cancer and skin cancer. A recent proposed cloud computing frame work has inspired the researchers to utilize the existing works on image based cancer research and develop a more versatile CAD system for detection. (C) 2015 Elsevier Ltd. All rights reserved.

------------


###################################

