Related papers

Paper Id: WOS:000332194600009
Distance: 0.17756089568138123
Similarity: 0.8224391043186188
Title: Evaluation of prostate segmentation algorithms for MRI: The PROMISE12 challenge
Abstract: Prostate MRI image segmentation has been an area of intense research due to the increased use of MRI as a modality for the clinical workup of prostate cancer. Segmentation is useful for various tasks, e.g. to accurately localize prostate boundaries for radiotherapy or to initialize multi-modal registration algorithms. In the past, it has been difficult for research groups to evaluate prostate segmentation algorithms on multi-center, multi-vendor and multi-protocol data. Especially because we are dealing with MR images, image appearance, resolution and the presence of artifacts are affected by differences in scanners and/or protocols, which in turn can have a large influence on algorithm accuracy. The Prostate MR Image Segmentation (PROMISE12) challenge was setup to allow a fair and meaningful comparison of segmentation methods on the basis of performance and robustness. In this work we will discuss the initial results of the online PROMISE12 challenge, and the results obtained in the live challenge workshop hosted by the MICCAI2012 conference. In the challenge, 100 prostate MR cases from 4 different centers were included, with differences in scanner manufacturer, field strength and protocol. A total of 11 teams from academic research groups and industry participated. Algorithms showed a wide variety in methods and implementation, including active appearance models, atlas registration and level sets. Evaluation was performed using boundary and volume based metrics which were combined into a single score relating the metrics to human expert performance. The winners of the challenge where the algorithms by teams Imorphics and ScrAutoProstate, with scores of 85.72 and 84.29 overall. Both algorithms where significantly better than all other algorithms in the challenge (p < 0.05) and had an efficient implementation with a run time of 8 min and 3 s per case respectively. Overall, active appearance model based approaches seemed to outperform other approaches like multi-atlas registration, both on accuracy and computation time. Although average algorithm performance was good to excellent and the Imorphics algorithm outperformed the second observer on average, we showed that algorithm combination might lead to further improvement, indicating that optimal performance for prostate segmentation is not yet obtained. All results are available online at http://promise12.grand-challenge.org/. (C) 2013 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000259660200005
Distance: 0.1971256583929062
Similarity: 0.8028743416070938
Title: Grid computing of spatial statistics: using the TeraGrid for G(i)*(d) analysis
Abstract: The massive quantities of geographic information that are collected by modern sensing technologies are difficult to use and understand without data reduction methods that summarize distributions and report salient trends. Statistical analyses, therefore, are increasingly, being used to analyze large geographic data sets over a broad spectrum of spatial and temporal scales. Computational Grids coordinate the use of distributed computational resources to form a large virtual supercomputer that can be applied to solve computationally intensive problems in science, engineering, and commerce. This paper presents a solution to computing a spatial statistic, G(i)*(d) using Grids. Our approach is based on a quadtree-based domain decomposition that uses task-scbeduling algorithms based on GridShell and Condor. Computational experiments carried out on the TeraGrid were designed to evaluate the performance of solution processes. The Grid-based approach to computing values for G(i)*(d) shows improved performance over the sequential algorithm while also solving larger problem sizes. The solution demonstrated not only advances knowledge about the application of the Grid in spatial statistics applications but also provides insights into the design of Grid middleware for other computationally intensive applications. Copyright (C) 2008 John Wiley & Sons, Ltd.

------------

Paper Id: WOS:000349592000015
Distance: 0.20825576782226562
Similarity: 0.7917442321777344
Title: Segmentation of tongue muscles from super-resolution magnetic resonance images
Abstract: Imaging and quantification of tongue anatomy is helpful in surgical planning, post-operative rehabilitation of tongue cancer patients, and studying of how humans adapt and learn new strategies for breathing, swallowing and speaking to compensate for changes in function caused by disease, medical interventions or aging. In vivo acquisition of high-resolution three-dimensional (3D) magnetic resonance (MR) images with clearly visible tongue muscles is currently not feasible because of breathing and involuntary swallowing motions that occur over lengthy imaging times. However, recent advances in image reconstruction now allow the generation of super-resolution 3D MR images from sets of orthogonal images, acquired at a high in-plane resolution and combined using super-resolution techniques. This paper presents, to the best of our knowledge, the first attempt towards automatic tongue muscle segmentation from MR images. We devised a database of ten super-resolution 3D MR images, in which the genioglossus and inferior longitudinalis tongue muscles were manually segmented and annotated with landmarks. We demonstrate the feasibility of segmenting the muscles of interest automatically by applying the landmark-based game-theoretic framework (GTF), where a landmark detector based on Haar-like features and an optimal assignment-based shape representation were integrated. The obtained segmentation results were validated against an independent manual segmentation performed by a second observer, as well as against B-splines and demons atlasing approaches. The segmentation performance resulted in mean Dice coefficients of 85.3%, 81.8%, 78.8% and 75.8% for the second observer, GTF, B-splines atlasing and demons atlasing, respectively. The obtained level of segmentation accuracy indicates that computerized tongue muscle segmentation may be used in surgical planning and treatment outcome analysis of tongue cancer patients, and in studies of normal subjects and subjects with speech and swallowing problems. (C) 2014 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000362858100014
Distance: 0.214542418718338
Similarity: 0.785457581281662
Title: Flow-based fabrication: An integrated computational workflow for design and digital additive manufacturing of multifunctional heterogeneously structured objects
Abstract: Structural hierarchy and material organization in design are traditionally achieved by combining discrete homogeneous parts into functional assemblies where the shape or surface is the determining factor in achieving function. In contrast, biological structures express higher levels of functionality on a finer scale through volumetric cellular constructs that are heterogeneous and complex. Despite recent advancements in additive manufacturing of functionally graded materials, the limitations associated with computational design and digital fabrication of heterogeneous materials and structures frame and limit further progress. Conventional computer-aided design tools typically contain geometric and topologic data of virtual constructs, but lack robust means to integrate material composition properties within virtual models. We present a seamless computational workflow for the design and direct digital fabrication of multi-material and multi-scale structured objects. The workflow encodes for and integrates domain-specific meta-data relating to local, regional and global feature resolution of heterogeneous material organizations. We focus on water-based materials and demonstrate our approach by additively manufacturing diverse constructs associating shape-informing variable flow rates and material properties to mesh-free geometric primitives. The proposed workflow enables virtual-to-physical control of constructs where structural, mechanical and optical gradients are achieved through a seamless design-to-fabrication tool with localized control. An enabling technology combining a robotic arm and a multisyringe multi nozzle deposition system is presented. Proposed methodology is implemented and full-scale demonstrations are included. (C) 2015 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000353830400007
Distance: 0.21618179976940155
Similarity: 0.7838182002305984
Title: DietCam: Multi-view regular shape food recognition with a camera phone
Abstract: This paper presents an automatic multi-view food classification of a food intake assessment system on a smart phone. Food intake assessment plays important roles in obesity management, which has shown significant impacts on public healthcare. Conventional dietary record-based food intake assessment methods are not popularly applied due to their inconvenience and high reliance on human interactions. This paper presents a smart phone application, named DietCam, to recognize food intakes automatically. The major difficulties in food recognition from images come from uncertainties of food appearances and deformable nature of food especially when they are on a complex background environment. The proposed DietCam system utilizes a multi-view recognition method that separates every food by estimating the best perspective and recognizing them using a probabilistic method. The implemented DietCam system on an iPhone 4 platform showed improved performance compared with baseline methods for food recognition, with an average accuracy of 84% for the selective regular shape foods. (C) 2014 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000257924400006
Distance: 0.21662603318691254
Similarity: 0.7833739668130875
Title: Cross-generation and cross-laboratory predictions of Affymetrix microarrays by rank-based methods
Abstract: Past experiments of the popular Affymetrix (Affy) microarrays have accumulated a huge amount of public data sets. To apply them for more wide studies, the comparability across generations and experimental environments is an important research topic. This paper particularly investigates the issue of cross-generation/laboratory predictions. That is, whether models built upon data of one generation (laboratory) can differentiate data of another. We consider eight public sets of three cancers. They are from different laboratories and are across various generations of Affy human microarrays. Each cancer has certain subtypes, and we investigate if a model trained from one set correctly differentiates another. We propose a simple rank-based approach to make data from different sources more comparable. Results show that it leads to higher prediction accuracy than using expression values. We further investigate normalization issues in preparing training/testing data. In addition, we discuss some pitfalls in evaluating cross-generation/laboratory predictions. To use data from various sources one must be cautious on some important but easily neglected steps. (C) 2007 Elsevier Inc. All rights reserved.

------------

Paper Id: WOS:000356128800002
Distance: 0.21708865463733673
Similarity: 0.7829113453626633
Title: A review of depression and suicide risk assessment using speech analysis
Abstract: This paper is the first review into the automatic analysis of speech for use as an objective predictor of depression and suicidality. Both conditions are major public health concerns; depression has long been recognised as a prominent cause of disability and burden worldwide, whilst suicide is a misunderstood and complex course of death that strongly impacts the quality of life and mental health of the families and communities left behind. Despite this prevalence the diagnosis of depression and assessment of suicide risk, due to their complex clinical characterisations, are difficult tasks, nominally achieved by the categorical assessment of a set of specific symptoms. However many of the key symptoms of either condition, such as altered mood and motivation, are not physical in nature; therefore assigning a categorical score to them introduces a range of subjective biases to the diagnostic procedure. Due to these difficulties, research into finding a set of biological, physiological and behavioural markers to aid clinical assessment is gaining in popularity. This review starts by building the case for speech to be considered a key objective marker for both conditions; reviewing current diagnostic and assessment methods for depression and suicidality including key non-speech biological, physiological and behavioural markers and highlighting the expected cognitive and physiological changes associated with both conditions which affect speech production. We then review the key characteristics; size, associated clinical scores and collection paradigm, of active depressed and suicidal speech databases. The main focus of this paper is on how common paralinguistic speech characteristics are affected by depression and suicidality and the application of this information in classification and prediction systems. The paper concludes with an in-depth discussion on the key challenges - improving the generalisability through greater research collaboration and increased standardisation of data collection, and the mitigating unwanted sources of variability that will shape the future research directions of this rapidly growing field of speech processing research. (C) 2015 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000349504700014
Distance: 0.21788282692432404
Similarity: 0.782117173075676
Title: Fuzzy human motion analysis: A review
Abstract: Human Motion Analysis (HMA) is currently one of the most popularly active research domains as such significant research interests are motivated by a number of real world applications such as video surveillance, sports analysis, healthcare monitoring and so on. However, most of these real world applications face high levels of uncertainties that can affect the operations of such applications. Hence, the fuzzy set theory has been applied and showed great success in the recent past. In this paper, we aim at reviewing the fuzzy set oriented approaches for HMA, individuating how the fuzzy set may improve the HMA, envisaging and delineating the future perspectives. To the best of our knowledge, there is not found a single survey in the current literature that has discussed and reviewed fuzzy approaches towards the HMA. For ease of understanding, we conceptually classify the human motion into three broad levels: Low-Level (LoL), Mid-Level (MiL), and High-Level (HiL) HMA. (C) 2014 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000303094300005
Distance: 0.21795083582401276
Similarity: 0.7820491641759872
Title: Surrogate models to compute optimal air quality planning policies at a regional scale
Abstract: Secondary pollutants (such as PM10) derives from complex non-linear reactions involving precursor emissions, namely VOC, NOx, NH3, primary PM and SO2. Due to difficulty to cope with this complexity, Decision Support Systems (DSSs) are essential tools to help Environmental Authorities to plan air quality policies that fulfill EU Directive 2008/50 requirements in a cost-efficient way. To implement these DSSs the common approach is to describe the air quality indices using linear models, derived through model reduction techniques starting from deterministic Chemical Transport Model simulations. This linear approach limits the applicability of these surrogate models, and while these may work properly at coarse spatial resolutions (continental/national), where average values over large areas are of interest, they often prove inadequate at sub national scales, where the impact of non linearities on air quality are usually higher. The objective of this work is to identify air quality models able to properly describe the relation between emissions and air quality indices, at a sub national scale. In this context, artificial neural networks, identified processing long-term simulation output of a 3D deterministic multi-phase modelling system, are used to describe the non-linear relations between the control variables (precursor emissions reduction) and a pollution index. These models can then be used with a reasonable computing effort to solve a multi-objective (air quality and emission reduction costs) optimization problem, that requires thousands of model runs and thus would be unfeasible using the original process-based model. A case study of Northern Italy is presented. (C) 2011 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000293436000005
Distance: 0.21844719350337982
Similarity: 0.7815528064966202
Title: Industrial assembly of parts with dimensional variations. Case study: Assembling vehicle headlamps
Abstract: Presently, it is quite common, because of their benefits, to find plastic parts as the main elements of diverse commercial products. However, plastic components also present some drawbacks, such as their typical dimensional variations (especially in parts with complex geometry or with considerable size), making difficult, or even impossible, the correct assembly of the parts. This paper introduces a new methodology of dynamic assembly for an industrial application that requires an adaptive positioning of the parts that are to be assembled. In addition, this work presents a successful example of an industrial prototype where different technologies, which aim to solve different problems, have to be analyzed and tested. In particular, different approaches were studied: surface measurement sensors for transparent and deformable objects, actuation systems that could modify the assembly position of the parts, and control algorithms that could carry out this adaptive assembly automatically. The final goal of this work was to obtain a robust industrial prototype for vehicle headlamp assembly that could solve the high dimensional variations of the main plastic parts. To demonstrate the performance of the proposed solution, a wide set of experimental test was carried out in both a research lab and in the assembly line of a vehicle headlamp factory. The new prototype solves the problem of assembling vehicle headlamps, achieves a final product with minimum dimensional errors and offers an example of a solution to the problem of the assembly of pieces with dimensional errors. (C) 2011 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000270629200005
Distance: 0.2184963822364807
Similarity: 0.7815036177635193
Title: A functional perspective on map generalisation
Abstract: In the context of map generalisation, the ambition is to store once and then maintain a very detailed geographic database. Using a mix of modelling and cartographic generalisation techniques, the intention is to derive map products at varying levels of detail - from the fine scale to the highly synoptic. We argue that in modelling this process, it is highly advantageous to take a 'functional perspective' on map generalisation - rather than a geometric one. In other words to model the function as it manifests itself in the shapes and patterns of distribution of the phenomena being mapped - whether it be hospitals, airports, or cities. By modelling the functional composition of such features we can create relationships (partonomic, taxonomic and topological) that lend themselves directly to modelling, to analysis and most importantly to the process of generalisation. Borrowing from ideas in robotic vision this paper presents an approach for the automatic identification of functional sites (a collection of topographic features that perform a collective function) and demonstrates their utility in multi-scale representation and generalisation. (C) 2009 Omair Z. Chaudhry. Published by Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000281368200006
Distance: 0.2185000628232956
Similarity: 0.7814999371767044
Title: Detecting bird sounds in a complex acoustic environment and application to bioacoustic monitoring
Abstract: Trends in bird population sizes are an important indicator in nature conservation but measuring such sizes is a very difficult, labour intensive process. Enormous progress in audio signal processing and pattern recognition in recent years makes it possible to incorporate automated methods into the detection of bird vocalisations. These methods can be employed to support the census of population sizes. We report about a study testing the feasibility of bird monitoring supported by automatic bird song detection. In particular, we describe novel algorithms for the detection of the vocalisations of two endangered bird species and show how these can be used in automatic habitat mapping. These methods are based on detecting temporal patterns in a given frequency band typical for the species. Special effort is put into the suppression of the noise present in real-world audio scenes. Our results show that even in real-world recording conditions high recognition rates with a tolerable rate of false positive detections are possible. (C) 2009 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000309785000021
Distance: 0.21996359527111053
Similarity: 0.7800364047288895
Title: An extensive comparative study of cluster validity indices
Abstract: The validation of the results obtained by clustering algorithms is a fundamental part of the clustering process. The most used approaches for cluster validation are based on internal cluster validity indices. Although many indices have been proposed, there is no recent extensive comparative study of their performance. In this paper we show the results of an experimental work that compares 30 cluster validity indices in many different environments with different characteristics. These results can serve as a guideline for selecting the most suitable index for each possible application and provide a deep insight into the performance differences between the currently available indices. (C) 2012 Elsevier Ltd. All rights reserved.

------------

Paper Id: WOS:000258848100003
Distance: 0.2200189083814621
Similarity: 0.7799810916185379
Title: On detecting spatial outliers
Abstract: The ever-increasing volume of spatial data has greatly challenged our ability to extract useful but implicit knowledge from them. As an important branch of spatial data mining, spatial outlier detection aims to discover the objects whose non-spatial attribute values are significantly different from the values of their spatial neighbors. These objects, called spatial outliers, may reveal important phenomena in a number of applications including traffic control, satellite image analysis, weather forecast, and medical diagnosis. Most of the existing spatial outlier detection algorithms mainly focus on identifying single attribute outliers and could potentially misclassify normal objects as outliers when their neighborhoods contain real spatial outliers with very large or small attribute values. In addition, many spatial applications contain multiple non-spatial attributes which should be processed altogether to identify outliers. To address these two issues, we formulate the spatial outlier detection problem in a general way, design two robust detection algorithms, one for single attribute and the other for multiple attributes, and analyze their computational complexities. Experiments were conducted on a real-world data set, West Nile virus data, to validate the effectiveness of the proposed algorithms.

------------

Paper Id: WOS:000279301000002
Distance: 0.2203371226787567
Similarity: 0.7796628773212433
Title: A content based image retrieval system for a biological specimen collection
Abstract: Digital photography and decreasing cost of storing data in digital form has led to an explosion of large digital image repositories. Since the number of images in image databases can be large (millions in some cases) it is important to develop automated tools to search them. In this paper, we present a content based image retrieval system for a database of parasite specimen images. Unlike most content based image retrieval systems, where the database consists of objects that vary widely in shape and size, the objects in our database are fairly uniform. These objects are characterized by flexible body shapes, but with fairly rigid ends. We define such shapes to be FleBoRE (Flexible Body Rigid Extremities) objects, and present a shape model for this class of objects. We have defined similarity functions to compute the degree of likeness between two FleBoRE objects and developed automated methods to extract them from specimen images. The system has been tested with a collection of parasite images from the Harold W. Manter Laboratory for Parasitology. Empirical and expert-based evaluations show that query by shape approach is effective in retrieving specimens of the same class. (C) 2010 Elsevier Inc. All rights reserved.

------------

Paper Id: WOS:000356466800005
Distance: 0.22048740088939667
Similarity: 0.7795125991106033
Title: On the effectiveness of soft biometrics for increasing face verification rates
Abstract: The term soft biometrics typically refers to attributes of people such as their gender, the shape of their head or the color of their hair. There is growing interest in soft biometrics as a means of improving automated face recognition since they hold the promise of significantly reducing recognition errors, in part by ruling out illogical choices. This paper concentrates specifically on soft biometrics as opposed to extended attributes, and presents the results from three experiments quantifying performance gains on a difficult face recognition task when standard face recognition algorithms are augmented using soft biometrics. These experiments include (I) a best-case analysis using perfect knowledge of gender and race, (2) support vector machine-based soft biometric classifiers and (3) face shape expressed through an active shape model. All three experiments indicate small improvements may be made when soft biometrics augment an existing algorithm. However, in all cases, the gains were modest. One reason is that false matches are more likely between faces of people sharing the same soft biometric traits. This is to be expected, since face recognition algorithms utilize appearance information, which is the same information used by algorithms designed to assign soft biometric labels to face images. (C) 2015 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000336770700015
Distance: 0.22052554786205292
Similarity: 0.7794744521379471
Title: An optimal and stable feature selection approach for traffic classification based on multi-criterion fusion
Abstract: There is significant interest in the network management community about the need to identify the most optimal and stable features for network traffic data. In practice, feature selection techniques are used as a pre-processing step to eliminate meaningless features, and also as a tool to reveal the set of optimal features. Unfortunately, such techniques are often sensitive to a small variation in the traffic data. Thus, obtaining a stable feature set is crucial in enhancing the confidence of network operators. This paper proposes an robust approach, called the Global Optimization Approach (GOA), to identify both optimal and stable features, relying on multi-criterion fusion-based feature selection technique and an information-theoretic method. The proposed GOA first combines multiple well-known FS techniques to yield a possible optimal feature subsets across different traffic datasets; then the proposed adaptive threshold, which is based on entropy to extract the stable features. A new goodness measure is proposed within a Random Forest framework to estimate the final optimum feature subset. Experimental studies on network traffic data in spatial and temporal domains show that the proposed GOA approach outperforms the commonly used feature selection techniques for traffic classification task. (C) 2013 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000261295100012
Distance: 0.22058790922164917
Similarity: 0.7794120907783508
Title: Multiple object tracking in molecular bioimaging by Rao-Blackwellized marginal particle filtering
Abstract: Time-lapse fluorescence microscopy imaging has rapidly evolved in the past decade and has opened new avenues for studying intracellular processes in vivo. Such studies generate vast amounts of noisy image data that cannot be analyzed efficiently and reliably by means of manual processing. Many popular tracking techniques exist but often fail to yield satisfactory results in the case of high object densities, high noise levels, and complex motion patterns. Probabilistic tracking algorithms, based on Bayesian estimation, have recently been shown to offer several improvements over classical approaches, by better integration of spatial and temporal information, and the possibility to more effectively incorporate prior knowledge about object dynamics and image formation. In this paper, we extend our previous work in this area and propose an improved, fully automated particle filtering algorithm for the tracking of many subresolution objects in fluorescence microscopy image sequences. It involves a new track management procedure and allows the use of multiple dynamics models. The accuracy and reliability of the algorithm are further improved by applying marginalization concepts. Experiments on synthetic as well as real image data from three different biological applications clearly demonstrate the superiority of the algorithm compared to previous particle filtering solutions. (C) 2008 Elsevier B.V. All rights reserved.

------------

Paper Id: WOS:000272432300076
Distance: 0.2221001237630844
Similarity: 0.7778998762369156
Title: Fusion of systems for automated cell phenotype image classification
Abstract: Automated cell phenotype image classification is related to the problem of determining locations of protein expression within living cells. Localization of proteins in cells is directly related to their functions and it is crucial for several applications ranging from early diagnosis of a disease to monitoring of therapeutic effectiveness of drugs. Recent advances in imaging instruments and biological reagents have allowed fluorescence microscopy to be extensively used as a too[ to understand biology at the cellular level by means of the visualization of biological activity within cells. However, human classification of fluorescence cell micrographs is still subjective and very time consuming, thus an automated approach for the systematic determination of protein subcellular locations from fluorescence microscopy images is required. Existing approaches concentrated on designing a set of optimal features and then applying standard machine-learning algorithms. This paper takes into consideration the best methods proposed in the literature and Focuses on the study of ensemble machine learning techniques for cell phenotype image classification. Two techniques are tested for the classification: a random subspace of Levenberg-Marquardt neural networks and a variant of the AdaBoost. Each of these two methods are tested with different feature sets, moreover the fusion between the two ensembles is studied. The best ensemble tested in this work obtains an outstanding 97.5% accuracy in the 2D-Hela dataset, which to the best of our knowledge is the best performance obtained on this dataset (the most used benchmark for comparing automated cell phenotype image classification approaches). (C) 2009 Elsevier Ltd. All rights reserved.

------------


###################################

